{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abe15dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.getdata import smiles2graph\n",
    "from model.CL_model_vas_info import GNNModelWithNewLoss\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fea3686",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/vsa.csv\")  \n",
    "smiles_list = df[\"SMILES\"].tolist()\n",
    "smr_vsa_list = [list(map(float, row.split())) for row in df[\"SMR_VSA\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "652499ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_vsa_data(vsa_file):\n",
    "    df = pd.read_csv(vsa_file)\n",
    "\n",
    "    def parse_vsa(s):\n",
    "        try:\n",
    "            return list(map(float, s.strip('[]').split()))\n",
    "        except:\n",
    "            return []\n",
    "\n",
    "    smr_arrays = df[\"SMR_VSA\"].apply(parse_vsa).tolist()          \n",
    "    slogp_arrays = df[\"SlogP_VSA\"].apply(parse_vsa).tolist()     \n",
    "    peoe_arrays = df[\"PEOE_VSA\"].apply(parse_vsa).tolist()       \n",
    "\n",
    "    properties = list(zip(smr_arrays, slogp_arrays, peoe_arrays))\n",
    "    \n",
    "    return df[\"SMILES\"].tolist(), properties\n",
    "\n",
    "x_smiles, properties = read_vsa_data(\"./data/vsa.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ead4c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = smiles2graph(\n",
    "    x_smiles,\n",
    "    properties=properties,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d56a71e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[21, 133], edge_index=[2, 44], edge_attr=[44, 14], global_features=[1, 8], smiles='Cc1cccc(C2=CCN(C(=O)NCCCC#N)CC2)c1', property_0=[1, 10], property_1=[1, 10], property_2=[1, 14])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffbfd7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133 14 8\n"
     ]
    }
   ],
   "source": [
    "print(data_list[0].x.shape[1],\n",
    "    data_list[0].edge_attr.shape[1],\n",
    "    data_list[0].global_features.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe8f7538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import DataLoader\n",
    "devices = [\"cuda\" if torch.cuda.is_available() else \"cpu\"]\n",
    "model1 = GNNModelWithNewLoss(\n",
    "        num_node_features=data_list[0].x.shape[1],\n",
    "        num_edge_features=data_list[0].edge_attr.shape[1],\n",
    "        num_global_features=0,\n",
    "        hidden_dim=512,\n",
    "        dropout_rate=0.1,\n",
    "        property_index=0 ,\n",
    "        save_path= 'premodels_new_og/3/0' \n",
    "    ).to(devices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b1f8b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/easter/.conda/envs/chemprop/lib/python3.11/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training will be saved to: premodels_new_og/3/0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8016 | Actual Loss: 2.6816\n",
      "Baseline Loss: 2.8204 | Actual Loss: 2.6645\n",
      "Baseline Loss: 2.8575 | Actual Loss: 2.6630\n",
      "Baseline Loss: 2.8586 | Actual Loss: 2.5623\n",
      "Baseline Loss: 2.7727 | Actual Loss: 2.3531\n",
      "Baseline Loss: 2.7248 | Actual Loss: 2.3591\n",
      "Baseline Loss: 2.8394 | Actual Loss: 2.2396\n",
      "Baseline Loss: 2.8780 | Actual Loss: 2.1564\n",
      "Baseline Loss: 2.8386 | Actual Loss: 2.1780\n",
      "Baseline Loss: 2.8467 | Actual Loss: 1.9122\n",
      "Baseline Loss: 2.7690 | Actual Loss: 1.7497\n",
      "Baseline Loss: 2.7997 | Actual Loss: 1.8421\n",
      "Baseline Loss: 2.8616 | Actual Loss: 1.7760\n",
      "Baseline Loss: 2.8423 | Actual Loss: 1.7907\n",
      "Baseline Loss: 2.8177 | Actual Loss: 1.7006\n",
      "Baseline Loss: 2.6430 | Actual Loss: 1.3533\n",
      "Baseline Loss: 2.8702 | Actual Loss: 1.6692\n",
      "Baseline Loss: 2.8345 | Actual Loss: 1.5230\n",
      "Baseline Loss: 2.7737 | Actual Loss: 1.6900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 1/1000 [00:00<09:57,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7548 | Actual Loss: 1.6786\n",
      "Epoch 1/1000: Train Loss: 2.1239, Val Loss: 1.6402\n",
      "New best validation loss: 1.6402\n",
      "Baseline Loss: 2.9103 | Actual Loss: 1.6146\n",
      "Baseline Loss: 2.8455 | Actual Loss: 1.6739\n",
      "Baseline Loss: 2.8203 | Actual Loss: 1.5829\n",
      "Baseline Loss: 2.8441 | Actual Loss: 1.5480\n",
      "Baseline Loss: 2.8084 | Actual Loss: 1.8152\n",
      "Baseline Loss: 2.8543 | Actual Loss: 1.5105\n",
      "Baseline Loss: 2.9294 | Actual Loss: 1.7612\n",
      "Baseline Loss: 2.8542 | Actual Loss: 1.2899\n",
      "Baseline Loss: 2.8127 | Actual Loss: 1.4127\n",
      "Baseline Loss: 2.7983 | Actual Loss: 1.6341\n",
      "Baseline Loss: 2.7682 | Actual Loss: 1.2543\n",
      "Baseline Loss: 2.8233 | Actual Loss: 1.4392\n",
      "Baseline Loss: 2.8257 | Actual Loss: 1.4933\n",
      "Baseline Loss: 2.7994 | Actual Loss: 1.3472\n",
      "Baseline Loss: 2.8040 | Actual Loss: 1.4485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 2/1000 [00:00<07:14,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.4675 | Actual Loss: 1.0777\n",
      "Baseline Loss: 2.8702 | Actual Loss: 1.3952\n",
      "Baseline Loss: 2.8345 | Actual Loss: 1.3801\n",
      "Baseline Loss: 2.7737 | Actual Loss: 1.2939\n",
      "Baseline Loss: 2.7548 | Actual Loss: 1.2550\n",
      "Epoch 2/1000: Train Loss: 1.4940, Val Loss: 1.3310\n",
      "New best validation loss: 1.3310\n",
      "Baseline Loss: 2.8501 | Actual Loss: 1.3670\n",
      "Baseline Loss: 2.7752 | Actual Loss: 1.3644\n",
      "Baseline Loss: 2.7516 | Actual Loss: 1.2408\n",
      "Baseline Loss: 2.8198 | Actual Loss: 1.3548\n",
      "Baseline Loss: 2.8846 | Actual Loss: 1.2484\n",
      "Baseline Loss: 2.8108 | Actual Loss: 1.2272\n",
      "Baseline Loss: 2.8144 | Actual Loss: 1.0117\n",
      "Baseline Loss: 2.8331 | Actual Loss: 1.2966\n",
      "Baseline Loss: 2.8671 | Actual Loss: 1.1115\n",
      "Baseline Loss: 2.8732 | Actual Loss: 1.2476\n",
      "Baseline Loss: 2.8111 | Actual Loss: 1.2881\n",
      "Baseline Loss: 2.7645 | Actual Loss: 1.0694\n",
      "Baseline Loss: 2.8624 | Actual Loss: 1.1602\n",
      "Baseline Loss: 2.8700 | Actual Loss: 1.3196\n",
      "Baseline Loss: 2.7729 | Actual Loss: 1.3723\n",
      "Baseline Loss: 2.6266 | Actual Loss: 1.0474\n",
      "Baseline Loss: 2.8702 | Actual Loss: 1.3175\n",
      "Baseline Loss: 2.8345 | Actual Loss: 1.0884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 3/1000 [00:01<06:48,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7737 | Actual Loss: 1.1636\n",
      "Baseline Loss: 2.7548 | Actual Loss: 1.2044\n",
      "Epoch 3/1000: Train Loss: 1.2329, Val Loss: 1.1935\n",
      "New best validation loss: 1.1935\n",
      "Baseline Loss: 2.8553 | Actual Loss: 1.0966\n",
      "Baseline Loss: 2.8262 | Actual Loss: 1.0437\n",
      "Baseline Loss: 2.8514 | Actual Loss: 1.3058\n",
      "Baseline Loss: 2.6919 | Actual Loss: 1.0218\n",
      "Baseline Loss: 2.7740 | Actual Loss: 1.0691\n",
      "Baseline Loss: 2.8960 | Actual Loss: 1.1994\n",
      "Baseline Loss: 2.8156 | Actual Loss: 1.2027\n",
      "Baseline Loss: 2.8375 | Actual Loss: 0.9767\n",
      "Baseline Loss: 2.8342 | Actual Loss: 0.9391\n",
      "Baseline Loss: 2.8494 | Actual Loss: 1.0937\n",
      "Baseline Loss: 2.7739 | Actual Loss: 0.9345\n",
      "Baseline Loss: 2.7937 | Actual Loss: 0.9136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 4/1000 [00:01<06:05,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9013 | Actual Loss: 0.7453\n",
      "Baseline Loss: 2.8264 | Actual Loss: 1.0149\n",
      "Baseline Loss: 2.7735 | Actual Loss: 1.0207\n",
      "Baseline Loss: 2.7395 | Actual Loss: 1.0270\n",
      "Baseline Loss: 2.8702 | Actual Loss: 1.1173\n",
      "Baseline Loss: 2.8345 | Actual Loss: 1.1061\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.9003\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.9598\n",
      "Epoch 4/1000: Train Loss: 1.0378, Val Loss: 1.0209\n",
      "New best validation loss: 1.0209\n",
      "Baseline Loss: 2.7794 | Actual Loss: 0.8361\n",
      "Baseline Loss: 2.7855 | Actual Loss: 0.8797\n",
      "Baseline Loss: 2.8449 | Actual Loss: 1.0042\n",
      "Baseline Loss: 2.8268 | Actual Loss: 0.8177\n",
      "Baseline Loss: 2.8579 | Actual Loss: 0.9367\n",
      "Baseline Loss: 2.8976 | Actual Loss: 0.9937\n",
      "Baseline Loss: 2.7826 | Actual Loss: 1.0207\n",
      "Baseline Loss: 2.8929 | Actual Loss: 1.1249\n",
      "Baseline Loss: 2.9405 | Actual Loss: 0.9716\n",
      "Baseline Loss: 2.8299 | Actual Loss: 0.8520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 5/1000 [00:01<06:07,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8568 | Actual Loss: 0.8906\n",
      "Baseline Loss: 2.9708 | Actual Loss: 1.1773\n",
      "Baseline Loss: 2.8342 | Actual Loss: 1.0144\n",
      "Baseline Loss: 2.8183 | Actual Loss: 1.0604\n",
      "Baseline Loss: 2.7973 | Actual Loss: 1.0431\n",
      "Baseline Loss: 2.4774 | Actual Loss: 0.6344\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.8981\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.8343\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.8975\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.9510\n",
      "Epoch 5/1000: Train Loss: 0.9536, Val Loss: 0.8953\n",
      "New best validation loss: 0.8953\n",
      "Baseline Loss: 2.8001 | Actual Loss: 0.6567\n",
      "Baseline Loss: 2.8627 | Actual Loss: 0.8148\n",
      "Baseline Loss: 2.7687 | Actual Loss: 0.9586\n",
      "Baseline Loss: 2.7923 | Actual Loss: 0.8444\n",
      "Baseline Loss: 2.7713 | Actual Loss: 1.0364\n",
      "Baseline Loss: 2.8142 | Actual Loss: 0.8204\n",
      "Baseline Loss: 2.8363 | Actual Loss: 0.9655\n",
      "Baseline Loss: 2.7906 | Actual Loss: 0.9327\n",
      "Baseline Loss: 2.7828 | Actual Loss: 1.1470\n",
      "Baseline Loss: 2.8909 | Actual Loss: 0.7299\n",
      "Baseline Loss: 2.8218 | Actual Loss: 0.9199\n",
      "Baseline Loss: 2.8633 | Actual Loss: 1.0253\n",
      "Baseline Loss: 2.9680 | Actual Loss: 0.8044\n",
      "Baseline Loss: 2.8247 | Actual Loss: 0.8034\n",
      "Baseline Loss: 2.7864 | Actual Loss: 0.8540\n",
      "Baseline Loss: 2.7398 | Actual Loss: 0.4421\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.8783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 6/1000 [00:02<06:15,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8345 | Actual Loss: 0.8542\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.9019\n",
      "Baseline Loss: 2.7548 | Actual Loss: 1.0744\n",
      "Epoch 6/1000: Train Loss: 0.8597, Val Loss: 0.9272\n",
      "Baseline Loss: 2.7794 | Actual Loss: 0.9872\n",
      "Baseline Loss: 2.8686 | Actual Loss: 0.7929\n",
      "Baseline Loss: 2.8549 | Actual Loss: 0.8503\n",
      "Baseline Loss: 2.8635 | Actual Loss: 0.7894\n",
      "Baseline Loss: 2.7920 | Actual Loss: 0.6894\n",
      "Baseline Loss: 2.7797 | Actual Loss: 0.8554\n",
      "Baseline Loss: 2.8391 | Actual Loss: 0.7913\n",
      "Baseline Loss: 2.8639 | Actual Loss: 0.7945\n",
      "Baseline Loss: 2.9081 | Actual Loss: 0.9240\n",
      "Baseline Loss: 2.7804 | Actual Loss: 0.6405\n",
      "Baseline Loss: 2.7862 | Actual Loss: 0.6289\n",
      "Baseline Loss: 2.8067 | Actual Loss: 0.7950\n",
      "Baseline Loss: 2.8467 | Actual Loss: 0.9118\n",
      "Baseline Loss: 2.8481 | Actual Loss: 0.6192\n",
      "Baseline Loss: 2.8540 | Actual Loss: 0.5447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 7/1000 [00:02<05:48,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.4947 | Actual Loss: 0.6780\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.8323\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.6241\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.7287\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.8926\n",
      "Epoch 7/1000: Train Loss: 0.7683, Val Loss: 0.7694\n",
      "New best validation loss: 0.7694\n",
      "Baseline Loss: 2.7993 | Actual Loss: 0.6717\n",
      "Baseline Loss: 2.8993 | Actual Loss: 0.7829\n",
      "Baseline Loss: 2.8607 | Actual Loss: 0.5841\n",
      "Baseline Loss: 2.7757 | Actual Loss: 0.7010\n",
      "Baseline Loss: 2.8149 | Actual Loss: 0.6112\n",
      "Baseline Loss: 2.8414 | Actual Loss: 0.9850\n",
      "Baseline Loss: 2.8406 | Actual Loss: 0.8736\n",
      "Baseline Loss: 2.8659 | Actual Loss: 0.7488\n",
      "Baseline Loss: 2.8020 | Actual Loss: 0.7832\n",
      "Baseline Loss: 2.8058 | Actual Loss: 0.7095\n",
      "Baseline Loss: 2.7832 | Actual Loss: 0.6151\n",
      "Baseline Loss: 2.8357 | Actual Loss: 0.7425\n",
      "Baseline Loss: 2.8095 | Actual Loss: 0.9058\n",
      "Baseline Loss: 2.8626 | Actual Loss: 0.7101\n",
      "Baseline Loss: 2.8400 | Actual Loss: 0.7570\n",
      "Baseline Loss: 2.4729 | Actual Loss: 0.5599\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.8087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 8/1000 [00:03<05:57,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8345 | Actual Loss: 0.7471\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.6549\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.9261\n",
      "Epoch 8/1000: Train Loss: 0.7338, Val Loss: 0.7842\n",
      "Baseline Loss: 2.8560 | Actual Loss: 0.6536\n",
      "Baseline Loss: 2.8092 | Actual Loss: 0.8855\n",
      "Baseline Loss: 2.8254 | Actual Loss: 0.6968\n",
      "Baseline Loss: 2.7988 | Actual Loss: 0.7425\n",
      "Baseline Loss: 2.8921 | Actual Loss: 0.5051\n",
      "Baseline Loss: 2.8248 | Actual Loss: 0.7343\n",
      "Baseline Loss: 2.7990 | Actual Loss: 0.5415\n",
      "Baseline Loss: 2.8494 | Actual Loss: 0.8922\n",
      "Baseline Loss: 2.7842 | Actual Loss: 0.9206\n",
      "Baseline Loss: 2.8629 | Actual Loss: 0.8038\n",
      "Baseline Loss: 2.8027 | Actual Loss: 0.7201\n",
      "Baseline Loss: 2.8931 | Actual Loss: 0.5802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 9/1000 [00:03<05:36,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7946 | Actual Loss: 0.6983\n",
      "Baseline Loss: 2.8012 | Actual Loss: 0.7641\n",
      "Baseline Loss: 2.8298 | Actual Loss: 0.8084\n",
      "Baseline Loss: 2.4469 | Actual Loss: 0.4051\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.6856\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.7255\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.6786\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.8256\n",
      "Epoch 9/1000: Train Loss: 0.7095, Val Loss: 0.7288\n",
      "New best validation loss: 0.7288\n",
      "Baseline Loss: 2.8154 | Actual Loss: 0.6621\n",
      "Baseline Loss: 2.7997 | Actual Loss: 0.5719\n",
      "Baseline Loss: 2.8082 | Actual Loss: 0.8346\n",
      "Baseline Loss: 2.8756 | Actual Loss: 0.6429\n",
      "Baseline Loss: 2.8979 | Actual Loss: 0.6116\n",
      "Baseline Loss: 2.8549 | Actual Loss: 0.6240\n",
      "Baseline Loss: 2.9257 | Actual Loss: 0.8519\n",
      "Baseline Loss: 2.7638 | Actual Loss: 0.5913\n",
      "Baseline Loss: 2.7994 | Actual Loss: 0.6045\n",
      "Baseline Loss: 2.8539 | Actual Loss: 0.6364\n",
      "Baseline Loss: 2.7930 | Actual Loss: 0.6960\n",
      "Baseline Loss: 2.7689 | Actual Loss: 0.6946\n",
      "Baseline Loss: 2.8923 | Actual Loss: 0.6883\n",
      "Baseline Loss: 2.8425 | Actual Loss: 0.5399\n",
      "Baseline Loss: 2.7841 | Actual Loss: 0.4315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 10/1000 [00:03<05:47,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.4834 | Actual Loss: 0.4966\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.6578\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.7710\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.6938\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.8048\n",
      "Epoch 10/1000: Train Loss: 0.6361, Val Loss: 0.7319\n",
      "Baseline Loss: 2.8123 | Actual Loss: 0.5880\n",
      "Baseline Loss: 2.7622 | Actual Loss: 0.7220\n",
      "Baseline Loss: 2.8600 | Actual Loss: 0.8330\n",
      "Baseline Loss: 2.8391 | Actual Loss: 0.5475\n",
      "Baseline Loss: 2.7435 | Actual Loss: 0.5007\n",
      "Baseline Loss: 2.7991 | Actual Loss: 0.5467\n",
      "Baseline Loss: 2.8109 | Actual Loss: 0.5080\n",
      "Baseline Loss: 2.8587 | Actual Loss: 0.5879\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.6530\n",
      "Baseline Loss: 2.8156 | Actual Loss: 0.3099\n",
      "Baseline Loss: 2.8294 | Actual Loss: 0.8215\n",
      "Baseline Loss: 2.8189 | Actual Loss: 1.1169\n",
      "Baseline Loss: 2.7949 | Actual Loss: 0.6498\n",
      "Baseline Loss: 2.9205 | Actual Loss: 0.8557\n",
      "Baseline Loss: 2.8679 | Actual Loss: 0.5150\n",
      "Baseline Loss: 2.6028 | Actual Loss: 0.5335\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.7124\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.6662\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.6247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 11/1000 [00:04<05:59,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7548 | Actual Loss: 0.8611\n",
      "Epoch 11/1000: Train Loss: 0.6431, Val Loss: 0.7161\n",
      "New best validation loss: 0.7161\n",
      "Baseline Loss: 2.8444 | Actual Loss: 0.9368\n",
      "Baseline Loss: 2.8355 | Actual Loss: 0.7157\n",
      "Baseline Loss: 2.8838 | Actual Loss: 0.4718\n",
      "Baseline Loss: 2.9229 | Actual Loss: 0.8697\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5343\n",
      "Baseline Loss: 2.8170 | Actual Loss: 0.5227\n",
      "Baseline Loss: 2.7765 | Actual Loss: 0.5733\n",
      "Baseline Loss: 2.8249 | Actual Loss: 0.6309\n",
      "Baseline Loss: 2.7938 | Actual Loss: 0.7378\n",
      "Baseline Loss: 2.8295 | Actual Loss: 0.6780\n",
      "Baseline Loss: 2.8547 | Actual Loss: 0.8257\n",
      "Baseline Loss: 2.7916 | Actual Loss: 0.9304\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.6810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 12/1000 [00:04<05:37,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8242 | Actual Loss: 0.7924\n",
      "Baseline Loss: 2.8086 | Actual Loss: 0.7057\n",
      "Baseline Loss: 2.6171 | Actual Loss: 0.4777\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.7090\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.7887\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.5915\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.8272\n",
      "Epoch 12/1000: Train Loss: 0.6928, Val Loss: 0.7291\n",
      "Baseline Loss: 2.7869 | Actual Loss: 0.4949\n",
      "Baseline Loss: 2.8426 | Actual Loss: 0.4643\n",
      "Baseline Loss: 2.8263 | Actual Loss: 0.5666\n",
      "Baseline Loss: 2.7746 | Actual Loss: 0.6799\n",
      "Baseline Loss: 2.8020 | Actual Loss: 0.4105\n",
      "Baseline Loss: 2.8634 | Actual Loss: 0.5852\n",
      "Baseline Loss: 2.9386 | Actual Loss: 0.6916\n",
      "Baseline Loss: 2.8671 | Actual Loss: 0.4575\n",
      "Baseline Loss: 2.8384 | Actual Loss: 0.4354\n",
      "Baseline Loss: 2.7825 | Actual Loss: 0.7075\n",
      "Baseline Loss: 2.7783 | Actual Loss: 0.5045\n",
      "Baseline Loss: 2.8423 | Actual Loss: 0.7488\n",
      "Baseline Loss: 2.8484 | Actual Loss: 0.7233\n",
      "Baseline Loss: 2.7816 | Actual Loss: 0.4177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏         | 13/1000 [00:04<05:43,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8364 | Actual Loss: 0.5295\n",
      "Baseline Loss: 2.6278 | Actual Loss: 0.8860\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.6838\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.6546\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.6669\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.9375\n",
      "Epoch 13/1000: Train Loss: 0.5814, Val Loss: 0.7357\n",
      "Baseline Loss: 2.8382 | Actual Loss: 0.6040\n",
      "Baseline Loss: 2.8069 | Actual Loss: 0.5894\n",
      "Baseline Loss: 2.8168 | Actual Loss: 0.4936\n",
      "Baseline Loss: 2.7428 | Actual Loss: 0.6215\n",
      "Baseline Loss: 2.7663 | Actual Loss: 0.4504\n",
      "Baseline Loss: 2.8976 | Actual Loss: 0.4586\n",
      "Baseline Loss: 2.8110 | Actual Loss: 0.4518\n",
      "Baseline Loss: 2.8558 | Actual Loss: 0.8102\n",
      "Baseline Loss: 2.8098 | Actual Loss: 0.5933\n",
      "Baseline Loss: 2.8558 | Actual Loss: 0.8327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏         | 14/1000 [00:05<05:34,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8352 | Actual Loss: 0.7353\n",
      "Baseline Loss: 2.8500 | Actual Loss: 0.5022\n",
      "Baseline Loss: 2.8104 | Actual Loss: 0.4704\n",
      "Baseline Loss: 2.8656 | Actual Loss: 0.3938\n",
      "Baseline Loss: 2.8524 | Actual Loss: 0.7663\n",
      "Baseline Loss: 2.6504 | Actual Loss: 0.4265\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.7017\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.6958\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.5746\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.7337\n",
      "Epoch 14/1000: Train Loss: 0.5750, Val Loss: 0.6765\n",
      "New best validation loss: 0.6765\n",
      "Baseline Loss: 2.7835 | Actual Loss: 0.3826\n",
      "Baseline Loss: 2.8233 | Actual Loss: 0.5202\n",
      "Baseline Loss: 2.8119 | Actual Loss: 0.6846\n",
      "Baseline Loss: 2.8242 | Actual Loss: 0.6108\n",
      "Baseline Loss: 2.8961 | Actual Loss: 0.4676\n",
      "Baseline Loss: 2.8620 | Actual Loss: 0.8027\n",
      "Baseline Loss: 2.8592 | Actual Loss: 0.4964\n",
      "Baseline Loss: 2.8505 | Actual Loss: 0.2946\n",
      "Baseline Loss: 2.7722 | Actual Loss: 0.4810\n",
      "Baseline Loss: 2.8745 | Actual Loss: 0.7224\n",
      "Baseline Loss: 2.7891 | Actual Loss: 0.6077\n",
      "Baseline Loss: 2.7662 | Actual Loss: 0.5331\n",
      "Baseline Loss: 2.9079 | Actual Loss: 0.7270\n",
      "Baseline Loss: 2.8585 | Actual Loss: 0.4455\n",
      "Baseline Loss: 2.7410 | Actual Loss: 0.4043\n",
      "Baseline Loss: 2.4922 | Actual Loss: 0.4379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 15/1000 [00:05<05:45,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8702 | Actual Loss: 0.6295\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.6598\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.5771\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.8242\n",
      "Epoch 15/1000: Train Loss: 0.5387, Val Loss: 0.6726\n",
      "New best validation loss: 0.6726\n",
      "Baseline Loss: 2.8429 | Actual Loss: 0.5906\n",
      "Baseline Loss: 2.8406 | Actual Loss: 0.4432\n",
      "Baseline Loss: 2.8596 | Actual Loss: 0.6683\n",
      "Baseline Loss: 2.7774 | Actual Loss: 0.4266\n",
      "Baseline Loss: 2.7997 | Actual Loss: 0.4890\n",
      "Baseline Loss: 2.8655 | Actual Loss: 0.3474\n",
      "Baseline Loss: 2.8139 | Actual Loss: 0.4665\n",
      "Baseline Loss: 2.8054 | Actual Loss: 0.5909\n",
      "Baseline Loss: 2.8423 | Actual Loss: 0.6390\n",
      "Baseline Loss: 2.8260 | Actual Loss: 0.4375\n",
      "Baseline Loss: 2.8760 | Actual Loss: 0.8533\n",
      "Baseline Loss: 2.8796 | Actual Loss: 0.7164\n",
      "Baseline Loss: 2.8230 | Actual Loss: 0.3776\n",
      "Baseline Loss: 2.8683 | Actual Loss: 0.4662\n",
      "Baseline Loss: 2.8231 | Actual Loss: 0.5348\n",
      "Baseline Loss: 2.4230 | Actual Loss: 0.7426\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.5780\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.5772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 16/1000 [00:05<06:00,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7737 | Actual Loss: 0.6940\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.6698\n",
      "Epoch 16/1000: Train Loss: 0.5494, Val Loss: 0.6298\n",
      "New best validation loss: 0.6298\n",
      "Baseline Loss: 2.9112 | Actual Loss: 0.5328\n",
      "Baseline Loss: 2.8360 | Actual Loss: 0.4886\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5496\n",
      "Baseline Loss: 2.7620 | Actual Loss: 0.4657\n",
      "Baseline Loss: 2.8024 | Actual Loss: 0.4664\n",
      "Baseline Loss: 2.8379 | Actual Loss: 0.4928\n",
      "Baseline Loss: 2.8430 | Actual Loss: 0.9561\n",
      "Baseline Loss: 2.8348 | Actual Loss: 0.5053\n",
      "Baseline Loss: 2.7840 | Actual Loss: 0.6503\n",
      "Baseline Loss: 2.8360 | Actual Loss: 0.7169\n",
      "Baseline Loss: 2.8423 | Actual Loss: 0.3250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 17/1000 [00:06<05:42,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8315 | Actual Loss: 0.5291\n",
      "Baseline Loss: 2.7919 | Actual Loss: 0.5798\n",
      "Baseline Loss: 2.7776 | Actual Loss: 0.5709\n",
      "Baseline Loss: 2.8008 | Actual Loss: 0.6376\n",
      "Baseline Loss: 2.7182 | Actual Loss: 0.4986\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.6358\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.7104\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.6311\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.8935\n",
      "Epoch 17/1000: Train Loss: 0.5603, Val Loss: 0.7177\n",
      "Baseline Loss: 2.8454 | Actual Loss: 0.6179\n",
      "Baseline Loss: 2.8127 | Actual Loss: 0.4381\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.5925\n",
      "Baseline Loss: 2.8251 | Actual Loss: 0.6084\n",
      "Baseline Loss: 2.8015 | Actual Loss: 0.5718\n",
      "Baseline Loss: 2.8122 | Actual Loss: 0.5589\n",
      "Baseline Loss: 2.8485 | Actual Loss: 0.4167\n",
      "Baseline Loss: 2.8517 | Actual Loss: 0.3870\n",
      "Baseline Loss: 2.8349 | Actual Loss: 1.1348\n",
      "Baseline Loss: 2.8658 | Actual Loss: 1.0222\n",
      "Baseline Loss: 2.8270 | Actual Loss: 0.6138\n",
      "Baseline Loss: 2.8742 | Actual Loss: 0.6159\n",
      "Baseline Loss: 2.8382 | Actual Loss: 0.4222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 18/1000 [00:06<05:53,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7805 | Actual Loss: 0.8029\n",
      "Baseline Loss: 2.8348 | Actual Loss: 0.4885\n",
      "Baseline Loss: 2.6061 | Actual Loss: 0.4048\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.6864\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.5264\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.6426\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.7094\n",
      "Epoch 18/1000: Train Loss: 0.6060, Val Loss: 0.6412\n",
      "Baseline Loss: 2.9030 | Actual Loss: 1.0924\n",
      "Baseline Loss: 2.8391 | Actual Loss: 0.5594\n",
      "Baseline Loss: 2.7943 | Actual Loss: 0.5528\n",
      "Baseline Loss: 2.8662 | Actual Loss: 0.5166\n",
      "Baseline Loss: 2.7985 | Actual Loss: 0.5079\n",
      "Baseline Loss: 2.7593 | Actual Loss: 0.7250\n",
      "Baseline Loss: 2.8018 | Actual Loss: 0.5517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 19/1000 [00:06<05:40,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8978 | Actual Loss: 0.7687\n",
      "Baseline Loss: 2.8072 | Actual Loss: 0.5065\n",
      "Baseline Loss: 2.8130 | Actual Loss: 0.3002\n",
      "Baseline Loss: 2.8519 | Actual Loss: 0.5774\n",
      "Baseline Loss: 2.9040 | Actual Loss: 0.5347\n",
      "Baseline Loss: 2.8002 | Actual Loss: 0.4138\n",
      "Baseline Loss: 2.7656 | Actual Loss: 0.4969\n",
      "Baseline Loss: 2.8084 | Actual Loss: 0.4419\n",
      "Baseline Loss: 2.5129 | Actual Loss: 0.3319\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.5823\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.5622\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.7351\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.9586\n",
      "Epoch 19/1000: Train Loss: 0.5549, Val Loss: 0.7095\n",
      "Baseline Loss: 2.8630 | Actual Loss: 0.5914\n",
      "Baseline Loss: 2.8015 | Actual Loss: 0.5793\n",
      "Baseline Loss: 2.7824 | Actual Loss: 0.5026\n",
      "Baseline Loss: 2.8174 | Actual Loss: 0.7640\n",
      "Baseline Loss: 2.7499 | Actual Loss: 0.4060\n",
      "Baseline Loss: 2.8295 | Actual Loss: 0.5245\n",
      "Baseline Loss: 2.7709 | Actual Loss: 0.5558\n",
      "Baseline Loss: 2.8277 | Actual Loss: 0.4128\n",
      "Baseline Loss: 2.7727 | Actual Loss: 0.5079\n",
      "Baseline Loss: 2.8296 | Actual Loss: 0.9116\n",
      "Baseline Loss: 2.8446 | Actual Loss: 0.6142\n",
      "Baseline Loss: 2.8080 | Actual Loss: 0.5922\n",
      "Baseline Loss: 2.8721 | Actual Loss: 0.4973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 20/1000 [00:07<05:52,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8350 | Actual Loss: 0.5554\n",
      "Baseline Loss: 2.8908 | Actual Loss: 0.4672\n",
      "Baseline Loss: 2.5604 | Actual Loss: 0.5689\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.5458\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.5601\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.5854\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.8749\n",
      "Epoch 20/1000: Train Loss: 0.5657, Val Loss: 0.6416\n",
      "Baseline Loss: 2.8216 | Actual Loss: 0.4523\n",
      "Baseline Loss: 2.8492 | Actual Loss: 0.3397\n",
      "Baseline Loss: 2.8507 | Actual Loss: 0.7573\n",
      "Baseline Loss: 2.8154 | Actual Loss: 0.6992\n",
      "Baseline Loss: 2.8496 | Actual Loss: 0.4716\n",
      "Baseline Loss: 2.8055 | Actual Loss: 0.3937\n",
      "Baseline Loss: 2.8131 | Actual Loss: 0.4190\n",
      "Baseline Loss: 2.8696 | Actual Loss: 0.5021\n",
      "Baseline Loss: 2.7934 | Actual Loss: 0.3486\n",
      "Baseline Loss: 2.8182 | Actual Loss: 0.4699\n",
      "Baseline Loss: 2.7859 | Actual Loss: 0.5121\n",
      "Baseline Loss: 2.8053 | Actual Loss: 0.7370\n",
      "Baseline Loss: 2.8289 | Actual Loss: 0.4032\n",
      "Baseline Loss: 2.8565 | Actual Loss: 0.3039\n",
      "Baseline Loss: 2.8475 | Actual Loss: 0.4044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 21/1000 [00:07<05:56,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5692 | Actual Loss: 0.4938\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.5045\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.5107\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.6012\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.7269\n",
      "Epoch 21/1000: Train Loss: 0.4817, Val Loss: 0.5858\n",
      "New best validation loss: 0.5858\n",
      "Baseline Loss: 2.8331 | Actual Loss: 0.3835\n",
      "Baseline Loss: 2.8721 | Actual Loss: 0.5468\n",
      "Baseline Loss: 2.8215 | Actual Loss: 0.6765\n",
      "Baseline Loss: 2.7638 | Actual Loss: 0.3341\n",
      "Baseline Loss: 2.7615 | Actual Loss: 0.4328\n",
      "Baseline Loss: 2.8474 | Actual Loss: 0.5981\n",
      "Baseline Loss: 2.8809 | Actual Loss: 0.4923\n",
      "Baseline Loss: 2.8977 | Actual Loss: 0.3851\n",
      "Baseline Loss: 2.8237 | Actual Loss: 0.2534\n",
      "Baseline Loss: 2.8122 | Actual Loss: 0.5684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 22/1000 [00:07<05:54,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7070 | Actual Loss: 0.3660\n",
      "Baseline Loss: 2.9518 | Actual Loss: 0.6906\n",
      "Baseline Loss: 2.8097 | Actual Loss: 0.9448\n",
      "Baseline Loss: 2.8064 | Actual Loss: 0.5552\n",
      "Baseline Loss: 2.7892 | Actual Loss: 0.4488\n",
      "Baseline Loss: 2.5317 | Actual Loss: 0.6887\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.5035\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.6240\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.6919\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.6691\n",
      "Epoch 22/1000: Train Loss: 0.5228, Val Loss: 0.6221\n",
      "Baseline Loss: 2.7545 | Actual Loss: 0.3494\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5247\n",
      "Baseline Loss: 2.7950 | Actual Loss: 0.8036\n",
      "Baseline Loss: 2.8309 | Actual Loss: 0.5647\n",
      "Baseline Loss: 2.8624 | Actual Loss: 0.4182\n",
      "Baseline Loss: 2.9051 | Actual Loss: 0.4372\n",
      "Baseline Loss: 2.8052 | Actual Loss: 0.6572\n",
      "Baseline Loss: 2.8104 | Actual Loss: 0.4629\n",
      "Baseline Loss: 2.8698 | Actual Loss: 0.4455\n",
      "Baseline Loss: 2.8004 | Actual Loss: 0.4890\n",
      "Baseline Loss: 2.8149 | Actual Loss: 0.3758\n",
      "Baseline Loss: 2.7648 | Actual Loss: 0.2662\n",
      "Baseline Loss: 2.8542 | Actual Loss: 0.5447\n",
      "Baseline Loss: 2.7881 | Actual Loss: 0.5348\n",
      "Baseline Loss: 2.8735 | Actual Loss: 0.3203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 23/1000 [00:08<05:24,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5868 | Actual Loss: 0.2743\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.5602\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.5614\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.5641\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.8539\n",
      "Epoch 23/1000: Train Loss: 0.4668, Val Loss: 0.6349\n",
      "Baseline Loss: 2.8538 | Actual Loss: 0.4610\n",
      "Baseline Loss: 2.7984 | Actual Loss: 0.6466\n",
      "Baseline Loss: 2.7997 | Actual Loss: 0.3426\n",
      "Baseline Loss: 2.8586 | Actual Loss: 0.4201\n",
      "Baseline Loss: 2.7484 | Actual Loss: 0.5833\n",
      "Baseline Loss: 2.8586 | Actual Loss: 0.7651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 24/1000 [00:08<05:27,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7944 | Actual Loss: 0.3554\n",
      "Baseline Loss: 2.8889 | Actual Loss: 0.5129\n",
      "Baseline Loss: 2.9123 | Actual Loss: 0.4529\n",
      "Baseline Loss: 2.8653 | Actual Loss: 0.5226\n",
      "Baseline Loss: 2.8029 | Actual Loss: 0.4648\n",
      "Baseline Loss: 2.8289 | Actual Loss: 0.6394\n",
      "Baseline Loss: 2.8753 | Actual Loss: 0.5551\n",
      "Baseline Loss: 2.9104 | Actual Loss: 0.2989\n",
      "Baseline Loss: 2.8331 | Actual Loss: 0.4862\n",
      "Baseline Loss: 2.5039 | Actual Loss: 0.6032\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.4494\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.5649\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.4728\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.6599\n",
      "Epoch 24/1000: Train Loss: 0.5069, Val Loss: 0.5367\n",
      "New best validation loss: 0.5367\n",
      "Baseline Loss: 2.9374 | Actual Loss: 0.3507\n",
      "Baseline Loss: 2.8149 | Actual Loss: 0.6265\n",
      "Baseline Loss: 2.8472 | Actual Loss: 0.5870\n",
      "Baseline Loss: 2.8223 | Actual Loss: 0.6086\n",
      "Baseline Loss: 2.8647 | Actual Loss: 0.3305\n",
      "Baseline Loss: 2.8489 | Actual Loss: 0.4534\n",
      "Baseline Loss: 2.8428 | Actual Loss: 0.4117\n",
      "Baseline Loss: 2.7573 | Actual Loss: 0.3210\n",
      "Baseline Loss: 2.8053 | Actual Loss: 0.5439\n",
      "Baseline Loss: 2.8087 | Actual Loss: 0.5707\n",
      "Baseline Loss: 2.8495 | Actual Loss: 0.3418\n",
      "Baseline Loss: 2.8057 | Actual Loss: 0.5935\n",
      "Baseline Loss: 2.8169 | Actual Loss: 0.5358\n",
      "Baseline Loss: 2.8493 | Actual Loss: 0.4297\n",
      "Baseline Loss: 2.8103 | Actual Loss: 0.4039\n",
      "Baseline Loss: 2.5522 | Actual Loss: 0.3133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▎         | 25/1000 [00:08<05:36,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8702 | Actual Loss: 0.4204\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.5262\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.5636\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.6289\n",
      "Epoch 25/1000: Train Loss: 0.4639, Val Loss: 0.5348\n",
      "New best validation loss: 0.5348\n",
      "Baseline Loss: 2.8290 | Actual Loss: 0.5636\n",
      "Baseline Loss: 2.7778 | Actual Loss: 0.6160\n",
      "Baseline Loss: 2.8496 | Actual Loss: 0.6260\n",
      "Baseline Loss: 2.9007 | Actual Loss: 0.6334\n",
      "Baseline Loss: 2.8349 | Actual Loss: 0.4444\n",
      "Baseline Loss: 2.8176 | Actual Loss: 0.3693\n",
      "Baseline Loss: 2.8402 | Actual Loss: 0.3426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 26/1000 [00:09<05:10,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8812 | Actual Loss: 0.5059\n",
      "Baseline Loss: 2.7266 | Actual Loss: 0.3274\n",
      "Baseline Loss: 2.7656 | Actual Loss: 0.5777\n",
      "Baseline Loss: 2.8719 | Actual Loss: 0.3005\n",
      "Baseline Loss: 2.7981 | Actual Loss: 0.3492\n",
      "Baseline Loss: 2.9023 | Actual Loss: 0.3581\n",
      "Baseline Loss: 2.8340 | Actual Loss: 0.2889\n",
      "Baseline Loss: 2.8490 | Actual Loss: 0.5571\n",
      "Baseline Loss: 2.5454 | Actual Loss: 0.1617\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.4891\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.5874\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.4833\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.5906\n",
      "Epoch 26/1000: Train Loss: 0.4389, Val Loss: 0.5376\n",
      "Baseline Loss: 2.7956 | Actual Loss: 0.5734\n",
      "Baseline Loss: 2.8010 | Actual Loss: 0.3778\n",
      "Baseline Loss: 2.8315 | Actual Loss: 0.4148\n",
      "Baseline Loss: 2.8443 | Actual Loss: 0.4267\n",
      "Baseline Loss: 2.8652 | Actual Loss: 0.6793\n",
      "Baseline Loss: 2.7865 | Actual Loss: 0.4391\n",
      "Baseline Loss: 2.7704 | Actual Loss: 0.3810\n",
      "Baseline Loss: 2.8654 | Actual Loss: 0.5271\n",
      "Baseline Loss: 2.8547 | Actual Loss: 0.3828\n",
      "Baseline Loss: 2.8573 | Actual Loss: 0.7028\n",
      "Baseline Loss: 2.8376 | Actual Loss: 0.6291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 27/1000 [00:09<05:22,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8432 | Actual Loss: 0.3303\n",
      "Baseline Loss: 2.8725 | Actual Loss: 0.2786\n",
      "Baseline Loss: 2.7893 | Actual Loss: 0.5294\n",
      "Baseline Loss: 2.8160 | Actual Loss: 0.3954\n",
      "Baseline Loss: 2.5452 | Actual Loss: 0.2727\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.4790\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.4929\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.5731\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.6477\n",
      "Epoch 27/1000: Train Loss: 0.4588, Val Loss: 0.5482\n",
      "Baseline Loss: 2.8786 | Actual Loss: 0.3274\n",
      "Baseline Loss: 2.8664 | Actual Loss: 0.3560\n",
      "Baseline Loss: 2.7990 | Actual Loss: 0.3797\n",
      "Baseline Loss: 2.8111 | Actual Loss: 0.3501\n",
      "Baseline Loss: 2.8375 | Actual Loss: 0.5367\n",
      "Baseline Loss: 2.8119 | Actual Loss: 0.7143\n",
      "Baseline Loss: 2.7881 | Actual Loss: 0.4483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 28/1000 [00:09<05:07,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8627 | Actual Loss: 0.4420\n",
      "Baseline Loss: 2.8865 | Actual Loss: 0.4543\n",
      "Baseline Loss: 2.7693 | Actual Loss: 0.4354\n",
      "Baseline Loss: 2.8966 | Actual Loss: 0.5279\n",
      "Baseline Loss: 2.8244 | Actual Loss: 0.5320\n",
      "Baseline Loss: 2.8232 | Actual Loss: 0.4367\n",
      "Baseline Loss: 2.7898 | Actual Loss: 0.7645\n",
      "Baseline Loss: 2.8607 | Actual Loss: 0.4636\n",
      "Baseline Loss: 2.5965 | Actual Loss: 0.3105\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.5219\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.5436\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.5289\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.4853\n",
      "Epoch 28/1000: Train Loss: 0.4675, Val Loss: 0.5199\n",
      "New best validation loss: 0.5199\n",
      "Baseline Loss: 2.8156 | Actual Loss: 0.4531\n",
      "Baseline Loss: 2.8728 | Actual Loss: 0.5207\n",
      "Baseline Loss: 2.9454 | Actual Loss: 0.3193\n",
      "Baseline Loss: 2.8867 | Actual Loss: 0.4854\n",
      "Baseline Loss: 2.8493 | Actual Loss: 0.4698\n",
      "Baseline Loss: 2.8037 | Actual Loss: 0.4983\n",
      "Baseline Loss: 2.8664 | Actual Loss: 0.4449\n",
      "Baseline Loss: 2.7528 | Actual Loss: 0.4453\n",
      "Baseline Loss: 2.8027 | Actual Loss: 0.5412\n",
      "Baseline Loss: 2.7827 | Actual Loss: 0.4444\n",
      "Baseline Loss: 2.8163 | Actual Loss: 0.3388\n",
      "Baseline Loss: 2.8930 | Actual Loss: 0.4045\n",
      "Baseline Loss: 2.8485 | Actual Loss: 0.4968\n",
      "Baseline Loss: 2.8762 | Actual Loss: 0.4662\n",
      "Baseline Loss: 2.8599 | Actual Loss: 0.6541\n",
      "Baseline Loss: 2.5167 | Actual Loss: 0.4421\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.4476\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.4782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 29/1000 [00:10<05:16,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7737 | Actual Loss: 0.4682\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.6616\n",
      "Epoch 29/1000: Train Loss: 0.4641, Val Loss: 0.5139\n",
      "New best validation loss: 0.5139\n",
      "Baseline Loss: 2.8705 | Actual Loss: 0.3345\n",
      "Baseline Loss: 2.8469 | Actual Loss: 0.5013\n",
      "Baseline Loss: 2.9058 | Actual Loss: 0.1858\n",
      "Baseline Loss: 2.8367 | Actual Loss: 0.4232\n",
      "Baseline Loss: 2.8368 | Actual Loss: 0.3655\n",
      "Baseline Loss: 2.7796 | Actual Loss: 0.3529\n",
      "Baseline Loss: 2.8128 | Actual Loss: 0.4340\n",
      "Baseline Loss: 2.7734 | Actual Loss: 0.5484\n",
      "Baseline Loss: 2.8021 | Actual Loss: 0.3610\n",
      "Baseline Loss: 2.7494 | Actual Loss: 0.3997\n",
      "Baseline Loss: 2.8254 | Actual Loss: 0.4135\n",
      "Baseline Loss: 2.7925 | Actual Loss: 0.4377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 30/1000 [00:10<05:01,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8962 | Actual Loss: 0.3703\n",
      "Baseline Loss: 2.8571 | Actual Loss: 0.3376\n",
      "Baseline Loss: 2.8165 | Actual Loss: 0.3988\n",
      "Baseline Loss: 2.5370 | Actual Loss: 0.4465\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3692\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.4675\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.4468\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.6807\n",
      "Epoch 30/1000: Train Loss: 0.3944, Val Loss: 0.4911\n",
      "New best validation loss: 0.4911\n",
      "Baseline Loss: 2.8770 | Actual Loss: 0.4866\n",
      "Baseline Loss: 2.8761 | Actual Loss: 0.3717\n",
      "Baseline Loss: 2.7940 | Actual Loss: 0.3157\n",
      "Baseline Loss: 2.8016 | Actual Loss: 0.3506\n",
      "Baseline Loss: 2.9043 | Actual Loss: 0.2937\n",
      "Baseline Loss: 2.8891 | Actual Loss: 0.2362\n",
      "Baseline Loss: 2.8265 | Actual Loss: 0.3423\n",
      "Baseline Loss: 2.7870 | Actual Loss: 0.3365\n",
      "Baseline Loss: 2.8513 | Actual Loss: 0.2958\n",
      "Baseline Loss: 2.8044 | Actual Loss: 0.2791\n",
      "Baseline Loss: 2.7949 | Actual Loss: 0.5135\n",
      "Baseline Loss: 2.8081 | Actual Loss: 0.3821\n",
      "Baseline Loss: 2.8517 | Actual Loss: 0.4244\n",
      "Baseline Loss: 2.8468 | Actual Loss: 0.5101\n",
      "Baseline Loss: 2.8386 | Actual Loss: 0.4902\n",
      "Baseline Loss: 2.5092 | Actual Loss: 0.5135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 31/1000 [00:10<05:13,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8702 | Actual Loss: 0.3669\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3960\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.5173\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.9008\n",
      "Epoch 31/1000: Train Loss: 0.3839, Val Loss: 0.5452\n",
      "Baseline Loss: 2.8264 | Actual Loss: 0.2764\n",
      "Baseline Loss: 2.8964 | Actual Loss: 0.4380\n",
      "Baseline Loss: 2.8267 | Actual Loss: 0.4517\n",
      "Baseline Loss: 2.7843 | Actual Loss: 0.7268\n",
      "Baseline Loss: 2.8558 | Actual Loss: 0.5290\n",
      "Baseline Loss: 2.8567 | Actual Loss: 0.2523\n",
      "Baseline Loss: 2.8264 | Actual Loss: 0.2684\n",
      "Baseline Loss: 2.8475 | Actual Loss: 0.9644\n",
      "Baseline Loss: 2.8461 | Actual Loss: 0.3699\n",
      "Baseline Loss: 2.7757 | Actual Loss: 0.3174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 32/1000 [00:11<05:19,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7535 | Actual Loss: 0.6161\n",
      "Baseline Loss: 2.8333 | Actual Loss: 0.3915\n",
      "Baseline Loss: 2.8009 | Actual Loss: 0.3544\n",
      "Baseline Loss: 2.8016 | Actual Loss: 0.2908\n",
      "Baseline Loss: 2.7427 | Actual Loss: 0.4240\n",
      "Baseline Loss: 2.6212 | Actual Loss: 0.2850\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.4958\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.5190\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.5308\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.6534\n",
      "Epoch 32/1000: Train Loss: 0.4348, Val Loss: 0.5497\n",
      "Baseline Loss: 2.7784 | Actual Loss: 0.3787\n",
      "Baseline Loss: 2.8160 | Actual Loss: 0.3774\n",
      "Baseline Loss: 2.7890 | Actual Loss: 0.2756\n",
      "Baseline Loss: 2.8704 | Actual Loss: 0.3669\n",
      "Baseline Loss: 2.8727 | Actual Loss: 0.5287\n",
      "Baseline Loss: 2.7806 | Actual Loss: 0.4062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 33/1000 [00:11<05:02,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8206 | Actual Loss: 0.2663\n",
      "Baseline Loss: 2.8618 | Actual Loss: 0.2810\n",
      "Baseline Loss: 2.8725 | Actual Loss: 0.4686\n",
      "Baseline Loss: 2.8670 | Actual Loss: 0.6524\n",
      "Baseline Loss: 2.8223 | Actual Loss: 0.3774\n",
      "Baseline Loss: 2.8354 | Actual Loss: 1.3495\n",
      "Baseline Loss: 2.8655 | Actual Loss: 0.7049\n",
      "Baseline Loss: 2.8191 | Actual Loss: 0.2912\n",
      "Baseline Loss: 2.8744 | Actual Loss: 0.3335\n",
      "Baseline Loss: 2.5562 | Actual Loss: 0.1899\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.4288\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.4023\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.4769\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.8609\n",
      "Epoch 33/1000: Train Loss: 0.4530, Val Loss: 0.5422\n",
      "Baseline Loss: 2.8772 | Actual Loss: 0.3880\n",
      "Baseline Loss: 2.8502 | Actual Loss: 0.5657\n",
      "Baseline Loss: 2.9034 | Actual Loss: 0.3029\n",
      "Baseline Loss: 2.8228 | Actual Loss: 0.5130\n",
      "Baseline Loss: 2.7872 | Actual Loss: 0.4278\n",
      "Baseline Loss: 2.8098 | Actual Loss: 0.2643\n",
      "Baseline Loss: 2.7831 | Actual Loss: 0.5434\n",
      "Baseline Loss: 2.8313 | Actual Loss: 0.6414\n",
      "Baseline Loss: 2.8746 | Actual Loss: 0.4388\n",
      "Baseline Loss: 2.8409 | Actual Loss: 0.3159\n",
      "Baseline Loss: 2.8710 | Actual Loss: 0.2414\n",
      "Baseline Loss: 2.7642 | Actual Loss: 0.2389\n",
      "Baseline Loss: 2.7795 | Actual Loss: 0.3045\n",
      "Baseline Loss: 2.7552 | Actual Loss: 0.7605\n",
      "Baseline Loss: 2.8924 | Actual Loss: 0.4316\n",
      "Baseline Loss: 2.5729 | Actual Loss: 0.5379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 34/1000 [00:11<05:16,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8702 | Actual Loss: 0.4956\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.4769\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3645\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.7399\n",
      "Epoch 34/1000: Train Loss: 0.4322, Val Loss: 0.5192\n",
      "Baseline Loss: 2.8038 | Actual Loss: 0.2794\n",
      "Baseline Loss: 2.8173 | Actual Loss: 0.3489\n",
      "Baseline Loss: 2.7634 | Actual Loss: 0.3570\n",
      "Baseline Loss: 2.9024 | Actual Loss: 0.4359\n",
      "Baseline Loss: 2.8448 | Actual Loss: 0.4575\n",
      "Baseline Loss: 2.8049 | Actual Loss: 0.3038\n",
      "Baseline Loss: 2.8210 | Actual Loss: 0.4348\n",
      "Baseline Loss: 2.9025 | Actual Loss: 0.5108\n",
      "Baseline Loss: 2.8138 | Actual Loss: 0.2678\n",
      "Baseline Loss: 2.8867 | Actual Loss: 0.2990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 35/1000 [00:12<05:31,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8287 | Actual Loss: 0.4820\n",
      "Baseline Loss: 2.7595 | Actual Loss: 0.2554\n",
      "Baseline Loss: 2.8491 | Actual Loss: 0.4135\n",
      "Baseline Loss: 2.7765 | Actual Loss: 0.3068\n",
      "Baseline Loss: 2.7656 | Actual Loss: 0.1875\n",
      "Baseline Loss: 2.5460 | Actual Loss: 0.3448\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3556\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.5417\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.4017\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.7753\n",
      "Epoch 35/1000: Train Loss: 0.3553, Val Loss: 0.5186\n",
      "Baseline Loss: 2.7959 | Actual Loss: 0.4087\n",
      "Baseline Loss: 2.8282 | Actual Loss: 0.4326\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.4634\n",
      "Baseline Loss: 2.8171 | Actual Loss: 0.3575\n",
      "Baseline Loss: 2.8437 | Actual Loss: 0.3275\n",
      "Baseline Loss: 2.7240 | Actual Loss: 0.3519\n",
      "Baseline Loss: 2.9844 | Actual Loss: 0.4412\n",
      "Baseline Loss: 2.8797 | Actual Loss: 0.4778\n",
      "Baseline Loss: 2.8209 | Actual Loss: 0.2558\n",
      "Baseline Loss: 2.7982 | Actual Loss: 0.2648\n",
      "Baseline Loss: 2.8773 | Actual Loss: 0.3600\n",
      "Baseline Loss: 2.8153 | Actual Loss: 0.2844\n",
      "Baseline Loss: 2.8252 | Actual Loss: 0.4935\n",
      "Baseline Loss: 2.8776 | Actual Loss: 0.3337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 36/1000 [00:12<05:14,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8700 | Actual Loss: 0.4472\n",
      "Baseline Loss: 2.5412 | Actual Loss: 0.3399\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.4949\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.4148\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.4565\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.6364\n",
      "Epoch 36/1000: Train Loss: 0.3775, Val Loss: 0.5006\n",
      "Baseline Loss: 2.8090 | Actual Loss: 0.3426\n",
      "Baseline Loss: 2.8326 | Actual Loss: 0.3351\n",
      "Baseline Loss: 2.8019 | Actual Loss: 0.4085\n",
      "Baseline Loss: 2.8461 | Actual Loss: 0.4386\n",
      "Baseline Loss: 2.8487 | Actual Loss: 0.3452\n",
      "Baseline Loss: 2.8654 | Actual Loss: 0.3347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 37/1000 [00:12<05:22,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8137 | Actual Loss: 0.5305\n",
      "Baseline Loss: 2.7994 | Actual Loss: 0.3538\n",
      "Baseline Loss: 3.0024 | Actual Loss: 0.9595\n",
      "Baseline Loss: 2.8452 | Actual Loss: 0.2417\n",
      "Baseline Loss: 2.7832 | Actual Loss: 0.2723\n",
      "Baseline Loss: 2.8247 | Actual Loss: 0.3464\n",
      "Baseline Loss: 2.8494 | Actual Loss: 0.2854\n",
      "Baseline Loss: 2.8946 | Actual Loss: 0.3762\n",
      "Baseline Loss: 2.7885 | Actual Loss: 0.3934\n",
      "Baseline Loss: 2.6682 | Actual Loss: 0.2203\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.4690\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.4929\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.4961\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.8725\n",
      "Epoch 37/1000: Train Loss: 0.3865, Val Loss: 0.5826\n",
      "Baseline Loss: 2.7133 | Actual Loss: 0.4946\n",
      "Baseline Loss: 2.8595 | Actual Loss: 0.2331\n",
      "Baseline Loss: 2.8503 | Actual Loss: 0.2235\n",
      "Baseline Loss: 2.8156 | Actual Loss: 0.3584\n",
      "Baseline Loss: 2.8150 | Actual Loss: 0.5665\n",
      "Baseline Loss: 2.8590 | Actual Loss: 0.4242\n",
      "Baseline Loss: 2.7893 | Actual Loss: 0.3021\n",
      "Baseline Loss: 2.8910 | Actual Loss: 0.2811\n",
      "Baseline Loss: 2.8225 | Actual Loss: 0.5632\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3522\n",
      "Baseline Loss: 2.8071 | Actual Loss: 0.4644\n",
      "Baseline Loss: 2.9488 | Actual Loss: 0.6188\n",
      "Baseline Loss: 2.8100 | Actual Loss: 0.2380\n",
      "Baseline Loss: 2.7776 | Actual Loss: 0.4322\n",
      "Baseline Loss: 2.9224 | Actual Loss: 0.3440\n",
      "Baseline Loss: 2.6400 | Actual Loss: 0.3527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 38/1000 [00:13<05:09,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8702 | Actual Loss: 0.4277\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.4591\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.4348\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.5539\n",
      "Epoch 38/1000: Train Loss: 0.3906, Val Loss: 0.4689\n",
      "New best validation loss: 0.4689\n",
      "Baseline Loss: 2.9136 | Actual Loss: 0.2764\n",
      "Baseline Loss: 2.9075 | Actual Loss: 0.3696\n",
      "Baseline Loss: 2.8798 | Actual Loss: 0.3799\n",
      "Baseline Loss: 2.8507 | Actual Loss: 0.1818\n",
      "Baseline Loss: 2.8053 | Actual Loss: 0.2329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 39/1000 [00:13<05:20,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8178 | Actual Loss: 0.2872\n",
      "Baseline Loss: 2.8438 | Actual Loss: 0.3532\n",
      "Baseline Loss: 2.7780 | Actual Loss: 0.4244\n",
      "Baseline Loss: 2.8369 | Actual Loss: 0.2409\n",
      "Baseline Loss: 2.8486 | Actual Loss: 0.5261\n",
      "Baseline Loss: 2.7746 | Actual Loss: 0.3235\n",
      "Baseline Loss: 2.7897 | Actual Loss: 0.3183\n",
      "Baseline Loss: 2.7462 | Actual Loss: 0.6183\n",
      "Baseline Loss: 2.7871 | Actual Loss: 0.3723\n",
      "Baseline Loss: 2.8617 | Actual Loss: 0.3203\n",
      "Baseline Loss: 2.5219 | Actual Loss: 0.2334\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.4046\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.4466\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3786\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.5971\n",
      "Epoch 39/1000: Train Loss: 0.3412, Val Loss: 0.4567\n",
      "New best validation loss: 0.4567\n",
      "Baseline Loss: 2.8440 | Actual Loss: 0.4015\n",
      "Baseline Loss: 2.9086 | Actual Loss: 0.5266\n",
      "Baseline Loss: 2.8900 | Actual Loss: 0.3623\n",
      "Baseline Loss: 2.8374 | Actual Loss: 0.5543\n",
      "Baseline Loss: 2.7811 | Actual Loss: 0.3340\n",
      "Baseline Loss: 2.7739 | Actual Loss: 0.2469\n",
      "Baseline Loss: 2.7478 | Actual Loss: 0.4302\n",
      "Baseline Loss: 2.8489 | Actual Loss: 0.4194\n",
      "Baseline Loss: 2.8870 | Actual Loss: 0.8245\n",
      "Baseline Loss: 2.7865 | Actual Loss: 0.3732\n",
      "Baseline Loss: 2.8598 | Actual Loss: 0.2766\n",
      "Baseline Loss: 2.8354 | Actual Loss: 0.3595\n",
      "Baseline Loss: 2.8035 | Actual Loss: 0.3390\n",
      "Baseline Loss: 2.8805 | Actual Loss: 0.4319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 40/1000 [00:13<05:00,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8892 | Actual Loss: 0.3184\n",
      "Baseline Loss: 2.4983 | Actual Loss: 0.3724\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.4495\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.4705\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.4035\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.5889\n",
      "Epoch 40/1000: Train Loss: 0.4107, Val Loss: 0.4781\n",
      "Baseline Loss: 2.8209 | Actual Loss: 0.3008\n",
      "Baseline Loss: 2.7508 | Actual Loss: 0.2199\n",
      "Baseline Loss: 2.8398 | Actual Loss: 0.2791\n",
      "Baseline Loss: 2.8701 | Actual Loss: 0.3019\n",
      "Baseline Loss: 2.8532 | Actual Loss: 0.3705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 41/1000 [00:14<05:11,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8778 | Actual Loss: 0.3805\n",
      "Baseline Loss: 2.9391 | Actual Loss: 0.4289\n",
      "Baseline Loss: 2.8092 | Actual Loss: 0.2906\n",
      "Baseline Loss: 2.8197 | Actual Loss: 0.4588\n",
      "Baseline Loss: 2.7543 | Actual Loss: 0.3257\n",
      "Baseline Loss: 2.8212 | Actual Loss: 0.1560\n",
      "Baseline Loss: 2.8036 | Actual Loss: 0.3693\n",
      "Baseline Loss: 2.7909 | Actual Loss: 0.2764\n",
      "Baseline Loss: 2.8399 | Actual Loss: 0.2793\n",
      "Baseline Loss: 2.8628 | Actual Loss: 0.4148\n",
      "Baseline Loss: 2.5096 | Actual Loss: 0.2455\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.4118\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.4378\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.4465\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.9153\n",
      "Epoch 41/1000: Train Loss: 0.3186, Val Loss: 0.5528\n",
      "Baseline Loss: 2.8287 | Actual Loss: 0.2618\n",
      "Baseline Loss: 2.8150 | Actual Loss: 0.3671\n",
      "Baseline Loss: 2.7544 | Actual Loss: 0.2835\n",
      "Baseline Loss: 2.8189 | Actual Loss: 0.5763\n",
      "Baseline Loss: 2.8666 | Actual Loss: 0.3982\n",
      "Baseline Loss: 2.8099 | Actual Loss: 0.3590\n",
      "Baseline Loss: 2.8368 | Actual Loss: 0.2543\n",
      "Baseline Loss: 2.8537 | Actual Loss: 0.2886\n",
      "Baseline Loss: 2.8444 | Actual Loss: 0.3728\n",
      "Baseline Loss: 2.8269 | Actual Loss: 0.4322\n",
      "Baseline Loss: 2.8170 | Actual Loss: 0.2243\n",
      "Baseline Loss: 2.8633 | Actual Loss: 0.3692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 42/1000 [00:14<05:29,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8977 | Actual Loss: 0.5334\n",
      "Baseline Loss: 2.8166 | Actual Loss: 0.5897\n",
      "Baseline Loss: 2.8624 | Actual Loss: 0.8980\n",
      "Baseline Loss: 2.3758 | Actual Loss: 0.2499\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.5591\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3490\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.4352\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.5949\n",
      "Epoch 42/1000: Train Loss: 0.4036, Val Loss: 0.4845\n",
      "Baseline Loss: 2.7453 | Actual Loss: 0.2569\n",
      "Baseline Loss: 2.9095 | Actual Loss: 0.4414\n",
      "Baseline Loss: 2.7812 | Actual Loss: 0.3171\n",
      "Baseline Loss: 2.8668 | Actual Loss: 0.4312\n",
      "Baseline Loss: 2.7864 | Actual Loss: 0.3001\n",
      "Baseline Loss: 2.8404 | Actual Loss: 0.3130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 43/1000 [00:14<05:13,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7987 | Actual Loss: 0.5049\n",
      "Baseline Loss: 2.8337 | Actual Loss: 0.3185\n",
      "Baseline Loss: 2.8451 | Actual Loss: 0.3897\n",
      "Baseline Loss: 2.8730 | Actual Loss: 0.3736\n",
      "Baseline Loss: 2.8267 | Actual Loss: 0.5341\n",
      "Baseline Loss: 2.8318 | Actual Loss: 0.3857\n",
      "Baseline Loss: 2.7894 | Actual Loss: 0.4557\n",
      "Baseline Loss: 2.7896 | Actual Loss: 0.3629\n",
      "Baseline Loss: 2.9311 | Actual Loss: 0.2763\n",
      "Baseline Loss: 2.5370 | Actual Loss: 0.6553\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.4814\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.4604\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.5500\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.5204\n",
      "Epoch 43/1000: Train Loss: 0.3948, Val Loss: 0.5030\n",
      "Baseline Loss: 2.8089 | Actual Loss: 0.2460\n",
      "Baseline Loss: 2.7612 | Actual Loss: 0.4700\n",
      "Baseline Loss: 2.7718 | Actual Loss: 0.3191\n",
      "Baseline Loss: 2.8029 | Actual Loss: 0.3017\n",
      "Baseline Loss: 2.8381 | Actual Loss: 0.3436\n",
      "Baseline Loss: 2.8271 | Actual Loss: 0.2544\n",
      "Baseline Loss: 2.8537 | Actual Loss: 0.3590\n",
      "Baseline Loss: 2.7560 | Actual Loss: 0.3416\n",
      "Baseline Loss: 2.8999 | Actual Loss: 0.3727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 44/1000 [00:15<05:20,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8982 | Actual Loss: 0.6814\n",
      "Baseline Loss: 2.8700 | Actual Loss: 0.5277\n",
      "Baseline Loss: 2.7991 | Actual Loss: 0.3543\n",
      "Baseline Loss: 2.8710 | Actual Loss: 0.4347\n",
      "Baseline Loss: 2.8239 | Actual Loss: 0.3938\n",
      "Baseline Loss: 2.8445 | Actual Loss: 0.3646\n",
      "Baseline Loss: 2.6470 | Actual Loss: 0.6576\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3997\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.4035\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.5744\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.6268\n",
      "Epoch 44/1000: Train Loss: 0.4014, Val Loss: 0.5011\n",
      "Baseline Loss: 2.7928 | Actual Loss: 0.2534\n",
      "Baseline Loss: 2.8006 | Actual Loss: 0.2765\n",
      "Baseline Loss: 2.8669 | Actual Loss: 0.3810\n",
      "Baseline Loss: 2.8645 | Actual Loss: 0.2160\n",
      "Baseline Loss: 2.7983 | Actual Loss: 0.3202\n",
      "Baseline Loss: 2.8138 | Actual Loss: 0.2792\n",
      "Baseline Loss: 2.8056 | Actual Loss: 0.3839\n",
      "Baseline Loss: 2.8114 | Actual Loss: 0.3544\n",
      "Baseline Loss: 2.8513 | Actual Loss: 0.4152\n",
      "Baseline Loss: 2.8335 | Actual Loss: 0.4678\n",
      "Baseline Loss: 2.9019 | Actual Loss: 0.4097\n",
      "Baseline Loss: 2.7886 | Actual Loss: 0.2943\n",
      "Baseline Loss: 2.8067 | Actual Loss: 0.1758\n",
      "Baseline Loss: 2.8741 | Actual Loss: 0.3147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 45/1000 [00:15<05:27,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7574 | Actual Loss: 0.2781\n",
      "Baseline Loss: 2.5797 | Actual Loss: 0.5144\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3821\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3611\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.4185\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.6696\n",
      "Epoch 45/1000: Train Loss: 0.3334, Val Loss: 0.4579\n",
      "Baseline Loss: 2.7871 | Actual Loss: 0.2898\n",
      "Baseline Loss: 2.7823 | Actual Loss: 0.2601\n",
      "Baseline Loss: 2.8886 | Actual Loss: 0.4041\n",
      "Baseline Loss: 2.8768 | Actual Loss: 0.6591\n",
      "Baseline Loss: 2.8935 | Actual Loss: 0.5014\n",
      "Baseline Loss: 2.8536 | Actual Loss: 0.4148\n",
      "Baseline Loss: 2.8869 | Actual Loss: 0.2056\n",
      "Baseline Loss: 2.8282 | Actual Loss: 0.4475\n",
      "Baseline Loss: 2.7976 | Actual Loss: 0.3211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 46/1000 [00:15<05:10,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8352 | Actual Loss: 0.2924\n",
      "Baseline Loss: 2.8449 | Actual Loss: 0.3406\n",
      "Baseline Loss: 2.7787 | Actual Loss: 0.4056\n",
      "Baseline Loss: 2.7965 | Actual Loss: 0.1645\n",
      "Baseline Loss: 2.8372 | Actual Loss: 0.3306\n",
      "Baseline Loss: 2.8152 | Actual Loss: 0.3922\n",
      "Baseline Loss: 2.4702 | Actual Loss: 0.2821\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.4587\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3449\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3730\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.5998\n",
      "Epoch 46/1000: Train Loss: 0.3570, Val Loss: 0.4441\n",
      "New best validation loss: 0.4441\n",
      "Baseline Loss: 2.8300 | Actual Loss: 0.3002\n",
      "Baseline Loss: 2.7458 | Actual Loss: 0.2197\n",
      "Baseline Loss: 2.7460 | Actual Loss: 0.2902\n",
      "Baseline Loss: 2.9863 | Actual Loss: 0.5051\n",
      "Baseline Loss: 2.8268 | Actual Loss: 0.4517\n",
      "Baseline Loss: 2.8425 | Actual Loss: 0.3307\n",
      "Baseline Loss: 2.8339 | Actual Loss: 0.3360\n",
      "Baseline Loss: 2.7375 | Actual Loss: 0.4962\n",
      "Baseline Loss: 2.7582 | Actual Loss: 0.3862\n",
      "Baseline Loss: 2.8238 | Actual Loss: 0.3781\n",
      "Baseline Loss: 2.7765 | Actual Loss: 0.2764\n",
      "Baseline Loss: 2.8608 | Actual Loss: 0.3052\n",
      "Baseline Loss: 2.8425 | Actual Loss: 0.2178\n",
      "Baseline Loss: 2.8469 | Actual Loss: 0.5688\n",
      "Baseline Loss: 2.8306 | Actual Loss: 0.3840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 47/1000 [00:16<05:22,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7921 | Actual Loss: 0.3346\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.4340\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3847\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.4388\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.5960\n",
      "Epoch 47/1000: Train Loss: 0.3613, Val Loss: 0.4634\n",
      "Baseline Loss: 2.8140 | Actual Loss: 0.4072\n",
      "Baseline Loss: 2.8630 | Actual Loss: 0.2559\n",
      "Baseline Loss: 2.7803 | Actual Loss: 0.2970\n",
      "Baseline Loss: 2.7817 | Actual Loss: 0.5516\n",
      "Baseline Loss: 2.7932 | Actual Loss: 0.3238\n",
      "Baseline Loss: 2.7880 | Actual Loss: 0.3073\n",
      "Baseline Loss: 2.8687 | Actual Loss: 0.3827\n",
      "Baseline Loss: 2.8101 | Actual Loss: 0.4172\n",
      "Baseline Loss: 2.8794 | Actual Loss: 0.1367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 48/1000 [00:16<05:23,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7978 | Actual Loss: 0.4159\n",
      "Baseline Loss: 2.9656 | Actual Loss: 0.2902\n",
      "Baseline Loss: 2.8174 | Actual Loss: 0.4847\n",
      "Baseline Loss: 2.8593 | Actual Loss: 0.3138\n",
      "Baseline Loss: 2.8369 | Actual Loss: 0.2480\n",
      "Baseline Loss: 2.7851 | Actual Loss: 0.3050\n",
      "Baseline Loss: 2.5092 | Actual Loss: 0.1840\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.4554\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3779\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3515\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.6640\n",
      "Epoch 48/1000: Train Loss: 0.3326, Val Loss: 0.4622\n",
      "Baseline Loss: 2.8123 | Actual Loss: 0.2578\n",
      "Baseline Loss: 2.7746 | Actual Loss: 0.2617\n",
      "Baseline Loss: 2.8069 | Actual Loss: 0.2778\n",
      "Baseline Loss: 2.8093 | Actual Loss: 0.3302\n",
      "Baseline Loss: 2.9372 | Actual Loss: 0.2589\n",
      "Baseline Loss: 2.8050 | Actual Loss: 0.4235\n",
      "Baseline Loss: 2.8236 | Actual Loss: 0.4042\n",
      "Baseline Loss: 2.7943 | Actual Loss: 0.3534\n",
      "Baseline Loss: 2.9156 | Actual Loss: 0.4571\n",
      "Baseline Loss: 2.8148 | Actual Loss: 0.3712\n",
      "Baseline Loss: 2.8193 | Actual Loss: 0.3978\n",
      "Baseline Loss: 2.8680 | Actual Loss: 0.2406\n",
      "Baseline Loss: 2.7968 | Actual Loss: 0.3921\n",
      "Baseline Loss: 2.8245 | Actual Loss: 0.1274\n",
      "Baseline Loss: 2.8387 | Actual Loss: 0.4374\n",
      "Baseline Loss: 2.6064 | Actual Loss: 0.1616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 49/1000 [00:16<05:03,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8702 | Actual Loss: 0.4073\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3972\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.4360\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.6517\n",
      "Epoch 49/1000: Train Loss: 0.3220, Val Loss: 0.4731\n",
      "Baseline Loss: 2.8546 | Actual Loss: 0.2602\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.3130\n",
      "Baseline Loss: 2.8292 | Actual Loss: 0.9241\n",
      "Baseline Loss: 2.8818 | Actual Loss: 0.2844\n",
      "Baseline Loss: 2.7954 | Actual Loss: 0.3949\n",
      "Baseline Loss: 2.8419 | Actual Loss: 0.3491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 50/1000 [00:17<05:03,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8050 | Actual Loss: 0.2462\n",
      "Baseline Loss: 2.8561 | Actual Loss: 0.2518\n",
      "Baseline Loss: 2.7790 | Actual Loss: 0.1941\n",
      "Baseline Loss: 2.8205 | Actual Loss: 0.2322\n",
      "Baseline Loss: 2.8633 | Actual Loss: 0.4781\n",
      "Baseline Loss: 2.8799 | Actual Loss: 0.2965\n",
      "Baseline Loss: 2.8545 | Actual Loss: 0.2977\n",
      "Baseline Loss: 2.7812 | Actual Loss: 0.5293\n",
      "Baseline Loss: 2.8490 | Actual Loss: 0.2202\n",
      "Baseline Loss: 2.4392 | Actual Loss: 0.2654\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3889\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3467\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.4685\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.4515\n",
      "Epoch 50/1000: Train Loss: 0.3461, Val Loss: 0.4139\n",
      "New best validation loss: 0.4139\n",
      "Baseline Loss: 2.8063 | Actual Loss: 0.2795\n",
      "Baseline Loss: 2.8886 | Actual Loss: 0.2516\n",
      "Baseline Loss: 2.8075 | Actual Loss: 0.1962\n",
      "Baseline Loss: 2.8143 | Actual Loss: 0.1759\n",
      "Baseline Loss: 2.9430 | Actual Loss: 0.2776\n",
      "Baseline Loss: 2.8394 | Actual Loss: 0.2690\n",
      "Baseline Loss: 2.7795 | Actual Loss: 0.4351\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.2273\n",
      "Baseline Loss: 2.8217 | Actual Loss: 0.3450\n",
      "Baseline Loss: 2.7456 | Actual Loss: 0.2781\n",
      "Baseline Loss: 2.8578 | Actual Loss: 0.1741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 51/1000 [00:17<05:18,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8702 | Actual Loss: 0.3306\n",
      "Baseline Loss: 2.7381 | Actual Loss: 0.2610\n",
      "Baseline Loss: 2.8858 | Actual Loss: 0.4883\n",
      "Baseline Loss: 2.7703 | Actual Loss: 0.2517\n",
      "Baseline Loss: 2.4762 | Actual Loss: 0.4961\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.4529\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.5013\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.4126\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.4679\n",
      "Epoch 51/1000: Train Loss: 0.2961, Val Loss: 0.4587\n",
      "Baseline Loss: 2.8189 | Actual Loss: 0.5189\n",
      "Baseline Loss: 2.8092 | Actual Loss: 0.4329\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2730\n",
      "Baseline Loss: 2.8641 | Actual Loss: 0.5440\n",
      "Baseline Loss: 2.7896 | Actual Loss: 0.4442\n",
      "Baseline Loss: 2.8362 | Actual Loss: 0.3628\n",
      "Baseline Loss: 2.8223 | Actual Loss: 0.2902\n",
      "Baseline Loss: 2.8323 | Actual Loss: 0.2001\n",
      "Baseline Loss: 2.7824 | Actual Loss: 0.3137\n",
      "Baseline Loss: 2.8031 | Actual Loss: 0.2393\n",
      "Baseline Loss: 2.8555 | Actual Loss: 0.4998\n",
      "Baseline Loss: 2.7949 | Actual Loss: 0.2033\n",
      "Baseline Loss: 2.8869 | Actual Loss: 0.3245\n",
      "Baseline Loss: 2.8250 | Actual Loss: 0.1778\n",
      "Baseline Loss: 2.8679 | Actual Loss: 0.2084\n",
      "Baseline Loss: 2.5984 | Actual Loss: 0.2102\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.4383\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3626\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 52/1000 [00:17<05:13,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7548 | Actual Loss: 0.5082\n",
      "Epoch 52/1000: Train Loss: 0.3277, Val Loss: 0.4252\n",
      "Baseline Loss: 2.7535 | Actual Loss: 0.2766\n",
      "Baseline Loss: 2.8382 | Actual Loss: 0.3043\n",
      "Baseline Loss: 2.7745 | Actual Loss: 0.3315\n",
      "Baseline Loss: 2.8537 | Actual Loss: 0.2457\n",
      "Baseline Loss: 2.8612 | Actual Loss: 0.5873\n",
      "Baseline Loss: 2.8144 | Actual Loss: 0.2993\n",
      "Baseline Loss: 2.8799 | Actual Loss: 0.2889\n",
      "Baseline Loss: 2.8115 | Actual Loss: 0.3385\n",
      "Baseline Loss: 2.8183 | Actual Loss: 0.2719\n",
      "Baseline Loss: 2.8505 | Actual Loss: 0.3421\n",
      "Baseline Loss: 2.8159 | Actual Loss: 0.1919\n",
      "Baseline Loss: 2.8671 | Actual Loss: 0.4909\n",
      "Baseline Loss: 2.8607 | Actual Loss: 0.2272\n",
      "Baseline Loss: 2.8279 | Actual Loss: 0.4660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 53/1000 [00:18<04:52,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8036 | Actual Loss: 0.1965\n",
      "Baseline Loss: 2.6126 | Actual Loss: 0.3931\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.4482\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.4014\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.4747\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.6054\n",
      "Epoch 53/1000: Train Loss: 0.3282, Val Loss: 0.4824\n",
      "Baseline Loss: 2.7886 | Actual Loss: 0.5343\n",
      "Baseline Loss: 2.9405 | Actual Loss: 0.5212\n",
      "Baseline Loss: 2.8518 | Actual Loss: 0.3394\n",
      "Baseline Loss: 2.9007 | Actual Loss: 0.1798\n",
      "Baseline Loss: 2.7911 | Actual Loss: 0.2594\n",
      "Baseline Loss: 2.8333 | Actual Loss: 0.4553\n",
      "Baseline Loss: 2.8393 | Actual Loss: 0.3766\n",
      "Baseline Loss: 2.8767 | Actual Loss: 0.2163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 54/1000 [00:18<04:57,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7695 | Actual Loss: 0.3405\n",
      "Baseline Loss: 2.8711 | Actual Loss: 0.6281\n",
      "Baseline Loss: 2.8192 | Actual Loss: 0.3299\n",
      "Baseline Loss: 2.8287 | Actual Loss: 0.2965\n",
      "Baseline Loss: 2.7910 | Actual Loss: 0.2628\n",
      "Baseline Loss: 2.8429 | Actual Loss: 0.1581\n",
      "Baseline Loss: 2.7734 | Actual Loss: 0.3944\n",
      "Baseline Loss: 2.5412 | Actual Loss: 0.1788\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.4034\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.5181\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.4719\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.4035\n",
      "Epoch 54/1000: Train Loss: 0.3419, Val Loss: 0.4492\n",
      "Baseline Loss: 2.8175 | Actual Loss: 0.2972\n",
      "Baseline Loss: 2.8206 | Actual Loss: 0.2826\n",
      "Baseline Loss: 2.8143 | Actual Loss: 0.3144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 55/1000 [00:18<04:39,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8608 | Actual Loss: 0.3527\n",
      "Baseline Loss: 2.8238 | Actual Loss: 0.5494\n",
      "Baseline Loss: 2.8150 | Actual Loss: 0.3074\n",
      "Baseline Loss: 2.8108 | Actual Loss: 0.3276\n",
      "Baseline Loss: 2.7988 | Actual Loss: 0.2301\n",
      "Baseline Loss: 2.8343 | Actual Loss: 0.2232\n",
      "Baseline Loss: 2.9178 | Actual Loss: 0.1443\n",
      "Baseline Loss: 2.9373 | Actual Loss: 0.2562\n",
      "Baseline Loss: 2.7881 | Actual Loss: 0.3187\n",
      "Baseline Loss: 2.8500 | Actual Loss: 0.3735\n",
      "Baseline Loss: 2.7248 | Actual Loss: 0.3672\n",
      "Baseline Loss: 2.9358 | Actual Loss: 0.3548\n",
      "Baseline Loss: 2.5797 | Actual Loss: 0.2538\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2774\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3795\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3589\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.5267\n",
      "Epoch 55/1000: Train Loss: 0.3096, Val Loss: 0.3856\n",
      "New best validation loss: 0.3856\n",
      "Baseline Loss: 2.7860 | Actual Loss: 0.3541\n",
      "Baseline Loss: 2.8396 | Actual Loss: 0.3153\n",
      "Baseline Loss: 2.8238 | Actual Loss: 0.2760\n",
      "Baseline Loss: 2.8265 | Actual Loss: 0.3782\n",
      "Baseline Loss: 2.8352 | Actual Loss: 0.2182\n",
      "Baseline Loss: 2.8485 | Actual Loss: 0.5565\n",
      "Baseline Loss: 2.8311 | Actual Loss: 0.3811\n",
      "Baseline Loss: 2.8826 | Actual Loss: 0.2005\n",
      "Baseline Loss: 2.7972 | Actual Loss: 0.2263\n",
      "Baseline Loss: 2.8504 | Actual Loss: 0.6739\n",
      "Baseline Loss: 2.8380 | Actual Loss: 0.1027\n",
      "Baseline Loss: 2.8767 | Actual Loss: 0.2192\n",
      "Baseline Loss: 2.8879 | Actual Loss: 0.2010\n",
      "Baseline Loss: 2.8121 | Actual Loss: 0.3332\n",
      "Baseline Loss: 2.8679 | Actual Loss: 0.3813\n",
      "Baseline Loss: 2.4317 | Actual Loss: 0.2492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 56/1000 [00:18<04:56,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8702 | Actual Loss: 0.3222\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3571\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3776\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.4594\n",
      "Epoch 56/1000: Train Loss: 0.3167, Val Loss: 0.3791\n",
      "New best validation loss: 0.3791\n",
      "Baseline Loss: 2.8363 | Actual Loss: 0.1877\n",
      "Baseline Loss: 2.8425 | Actual Loss: 0.2619\n",
      "Baseline Loss: 2.7856 | Actual Loss: 0.5496\n",
      "Baseline Loss: 2.8567 | Actual Loss: 0.3441\n",
      "Baseline Loss: 2.8133 | Actual Loss: 0.3378\n",
      "Baseline Loss: 2.8059 | Actual Loss: 0.2345\n",
      "Baseline Loss: 2.8358 | Actual Loss: 0.2370\n",
      "Baseline Loss: 2.9019 | Actual Loss: 0.2984\n",
      "Baseline Loss: 2.8306 | Actual Loss: 0.2661\n",
      "Baseline Loss: 2.9031 | Actual Loss: 0.4830\n",
      "Baseline Loss: 2.7586 | Actual Loss: 0.2472\n",
      "Baseline Loss: 2.8516 | Actual Loss: 0.2590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 57/1000 [00:19<05:01,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7955 | Actual Loss: 0.3519\n",
      "Baseline Loss: 2.8270 | Actual Loss: 0.3962\n",
      "Baseline Loss: 2.8953 | Actual Loss: 0.3812\n",
      "Baseline Loss: 2.4374 | Actual Loss: 0.2717\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2979\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3949\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3761\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.5557\n",
      "Epoch 57/1000: Train Loss: 0.3192, Val Loss: 0.4061\n",
      "Baseline Loss: 2.8451 | Actual Loss: 0.3581\n",
      "Baseline Loss: 2.8536 | Actual Loss: 0.2730\n",
      "Baseline Loss: 2.8011 | Actual Loss: 0.3114\n",
      "Baseline Loss: 2.8258 | Actual Loss: 0.3945\n",
      "Baseline Loss: 2.8286 | Actual Loss: 0.4377\n",
      "Baseline Loss: 2.8668 | Actual Loss: 0.3949\n",
      "Baseline Loss: 2.8584 | Actual Loss: 0.2926\n",
      "Baseline Loss: 2.7323 | Actual Loss: 0.2744\n",
      "Baseline Loss: 2.7867 | Actual Loss: 0.1943\n",
      "Baseline Loss: 2.7415 | Actual Loss: 0.2679\n",
      "Baseline Loss: 2.7593 | Actual Loss: 0.3248\n",
      "Baseline Loss: 2.8677 | Actual Loss: 0.5065\n",
      "Baseline Loss: 2.8403 | Actual Loss: 0.2972\n",
      "Baseline Loss: 2.9322 | Actual Loss: 0.3123\n",
      "Baseline Loss: 2.8700 | Actual Loss: 0.3418\n",
      "Baseline Loss: 2.5856 | Actual Loss: 0.4053\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2766\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 58/1000 [00:19<04:42,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7737 | Actual Loss: 0.4733\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.4733\n",
      "Epoch 58/1000: Train Loss: 0.3367, Val Loss: 0.4053\n",
      "Baseline Loss: 2.8384 | Actual Loss: 0.2718\n",
      "Baseline Loss: 2.8411 | Actual Loss: 0.5461\n",
      "Baseline Loss: 2.8922 | Actual Loss: 0.1306\n",
      "Baseline Loss: 2.7879 | Actual Loss: 0.1865\n",
      "Baseline Loss: 2.8172 | Actual Loss: 0.2500\n",
      "Baseline Loss: 2.8705 | Actual Loss: 0.1453\n",
      "Baseline Loss: 2.8176 | Actual Loss: 0.3287\n",
      "Baseline Loss: 2.8363 | Actual Loss: 0.3962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 59/1000 [00:19<04:50,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9533 | Actual Loss: 0.3217\n",
      "Baseline Loss: 2.7976 | Actual Loss: 0.2421\n",
      "Baseline Loss: 2.7873 | Actual Loss: 0.4037\n",
      "Baseline Loss: 2.8653 | Actual Loss: 0.5169\n",
      "Baseline Loss: 2.8405 | Actual Loss: 0.4198\n",
      "Baseline Loss: 2.8337 | Actual Loss: 0.2363\n",
      "Baseline Loss: 2.7962 | Actual Loss: 0.3552\n",
      "Baseline Loss: 2.4354 | Actual Loss: 0.5007\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2958\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3749\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3774\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3583\n",
      "Epoch 59/1000: Train Loss: 0.3282, Val Loss: 0.3516\n",
      "New best validation loss: 0.3516\n",
      "Baseline Loss: 2.8553 | Actual Loss: 0.3155\n",
      "Baseline Loss: 2.9080 | Actual Loss: 0.3414\n",
      "Baseline Loss: 2.7956 | Actual Loss: 0.2575\n",
      "Baseline Loss: 2.8074 | Actual Loss: 0.3453\n",
      "Baseline Loss: 2.8406 | Actual Loss: 0.2941\n",
      "Baseline Loss: 2.8799 | Actual Loss: 0.2848\n",
      "Baseline Loss: 2.8428 | Actual Loss: 0.5773\n",
      "Baseline Loss: 2.8434 | Actual Loss: 0.3072\n",
      "Baseline Loss: 2.8502 | Actual Loss: 0.3317\n",
      "Baseline Loss: 2.8448 | Actual Loss: 0.2276\n",
      "Baseline Loss: 2.7988 | Actual Loss: 0.3803\n",
      "Baseline Loss: 2.7181 | Actual Loss: 0.2825\n",
      "Baseline Loss: 2.8699 | Actual Loss: 0.2174\n",
      "Baseline Loss: 2.8208 | Actual Loss: 0.5015\n",
      "Baseline Loss: 2.8184 | Actual Loss: 0.4316\n",
      "Baseline Loss: 2.5868 | Actual Loss: 0.1496\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 60/1000 [00:20<04:57,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8345 | Actual Loss: 0.3978\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2667\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.4724\n",
      "Epoch 60/1000: Train Loss: 0.3278, Val Loss: 0.3624\n",
      "Baseline Loss: 2.8979 | Actual Loss: 0.3894\n",
      "Baseline Loss: 2.8466 | Actual Loss: 0.3104\n",
      "Baseline Loss: 2.8747 | Actual Loss: 0.3295\n",
      "Baseline Loss: 2.7205 | Actual Loss: 0.2298\n",
      "Baseline Loss: 2.8599 | Actual Loss: 0.3918\n",
      "Baseline Loss: 2.8175 | Actual Loss: 0.3966\n",
      "Baseline Loss: 2.7927 | Actual Loss: 0.3476\n",
      "Baseline Loss: 2.7721 | Actual Loss: 0.3503\n",
      "Baseline Loss: 2.8756 | Actual Loss: 0.4705\n",
      "Baseline Loss: 2.7921 | Actual Loss: 0.1210\n",
      "Baseline Loss: 2.8827 | Actual Loss: 0.3726\n",
      "Baseline Loss: 2.8466 | Actual Loss: 0.3930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 61/1000 [00:20<04:42,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8118 | Actual Loss: 0.3305\n",
      "Baseline Loss: 2.7622 | Actual Loss: 0.2015\n",
      "Baseline Loss: 2.8720 | Actual Loss: 0.3613\n",
      "Baseline Loss: 2.5480 | Actual Loss: 0.3289\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3341\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.4573\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3507\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.5550\n",
      "Epoch 61/1000: Train Loss: 0.3328, Val Loss: 0.4243\n",
      "Baseline Loss: 2.8787 | Actual Loss: 0.2214\n",
      "Baseline Loss: 2.8190 | Actual Loss: 0.2545\n",
      "Baseline Loss: 2.7741 | Actual Loss: 0.1486\n",
      "Baseline Loss: 2.8711 | Actual Loss: 0.2334\n",
      "Baseline Loss: 2.8084 | Actual Loss: 0.2056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 62/1000 [00:20<04:51,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7726 | Actual Loss: 0.2579\n",
      "Baseline Loss: 2.8887 | Actual Loss: 0.3038\n",
      "Baseline Loss: 2.7634 | Actual Loss: 0.3836\n",
      "Baseline Loss: 2.8182 | Actual Loss: 0.2585\n",
      "Baseline Loss: 2.9417 | Actual Loss: 0.3811\n",
      "Baseline Loss: 2.8989 | Actual Loss: 0.7239\n",
      "Baseline Loss: 2.7462 | Actual Loss: 0.2863\n",
      "Baseline Loss: 2.7993 | Actual Loss: 0.2120\n",
      "Baseline Loss: 2.8075 | Actual Loss: 0.2309\n",
      "Baseline Loss: 2.8627 | Actual Loss: 0.3418\n",
      "Baseline Loss: 2.5794 | Actual Loss: 0.1825\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2882\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3400\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3613\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.4243\n",
      "Epoch 62/1000: Train Loss: 0.2891, Val Loss: 0.3534\n",
      "Baseline Loss: 2.8475 | Actual Loss: 0.3407\n",
      "Baseline Loss: 2.8381 | Actual Loss: 0.2439\n",
      "Baseline Loss: 2.8470 | Actual Loss: 0.1452\n",
      "Baseline Loss: 2.8007 | Actual Loss: 0.2853\n",
      "Baseline Loss: 2.7523 | Actual Loss: 0.2718\n",
      "Baseline Loss: 2.8062 | Actual Loss: 0.3771\n",
      "Baseline Loss: 2.8145 | Actual Loss: 0.2066\n",
      "Baseline Loss: 2.8085 | Actual Loss: 0.3141\n",
      "Baseline Loss: 2.8600 | Actual Loss: 0.3781\n",
      "Baseline Loss: 2.8914 | Actual Loss: 0.1918\n",
      "Baseline Loss: 2.8242 | Actual Loss: 0.3682\n",
      "Baseline Loss: 2.8271 | Actual Loss: 0.1452\n",
      "Baseline Loss: 2.8740 | Actual Loss: 0.3460\n",
      "Baseline Loss: 2.8726 | Actual Loss: 0.2735\n",
      "Baseline Loss: 2.8535 | Actual Loss: 0.1809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 63/1000 [00:21<04:58,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.3673 | Actual Loss: 0.3245\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3982\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.4129\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3195\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.6259\n",
      "Epoch 63/1000: Train Loss: 0.2746, Val Loss: 0.4391\n",
      "Baseline Loss: 2.7631 | Actual Loss: 0.2056\n",
      "Baseline Loss: 2.8279 | Actual Loss: 0.3588\n",
      "Baseline Loss: 2.8404 | Actual Loss: 0.4798\n",
      "Baseline Loss: 2.8633 | Actual Loss: 0.3035\n",
      "Baseline Loss: 2.8788 | Actual Loss: 0.2715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 64/1000 [00:21<04:45,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8149 | Actual Loss: 0.1784\n",
      "Baseline Loss: 2.8399 | Actual Loss: 0.2095\n",
      "Baseline Loss: 2.9235 | Actual Loss: 0.1777\n",
      "Baseline Loss: 2.8806 | Actual Loss: 0.2950\n",
      "Baseline Loss: 2.8269 | Actual Loss: 0.2585\n",
      "Baseline Loss: 2.9255 | Actual Loss: 0.4575\n",
      "Baseline Loss: 2.7577 | Actual Loss: 0.2430\n",
      "Baseline Loss: 2.8620 | Actual Loss: 0.4544\n",
      "Baseline Loss: 2.7630 | Actual Loss: 0.3681\n",
      "Baseline Loss: 2.7817 | Actual Loss: 0.3081\n",
      "Baseline Loss: 2.4792 | Actual Loss: 0.4065\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3099\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3663\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3082\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.5722\n",
      "Epoch 64/1000: Train Loss: 0.3110, Val Loss: 0.3892\n",
      "Baseline Loss: 2.8515 | Actual Loss: 0.4067\n",
      "Baseline Loss: 2.8137 | Actual Loss: 0.2861\n",
      "Baseline Loss: 2.8170 | Actual Loss: 0.2286\n",
      "Baseline Loss: 2.8271 | Actual Loss: 0.3268\n",
      "Baseline Loss: 2.9196 | Actual Loss: 0.2724\n",
      "Baseline Loss: 2.8423 | Actual Loss: 0.2587\n",
      "Baseline Loss: 2.8056 | Actual Loss: 0.2510\n",
      "Baseline Loss: 2.7879 | Actual Loss: 0.2624\n",
      "Baseline Loss: 2.8369 | Actual Loss: 0.3212\n",
      "Baseline Loss: 2.7800 | Actual Loss: 0.2530\n",
      "Baseline Loss: 2.8117 | Actual Loss: 0.3746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 65/1000 [00:21<04:51,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8238 | Actual Loss: 0.5182\n",
      "Baseline Loss: 2.8460 | Actual Loss: 0.2303\n",
      "Baseline Loss: 2.8140 | Actual Loss: 0.5786\n",
      "Baseline Loss: 2.8978 | Actual Loss: 0.2592\n",
      "Baseline Loss: 2.6476 | Actual Loss: 0.2436\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3810\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.5738\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.4370\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.5047\n",
      "Epoch 65/1000: Train Loss: 0.3170, Val Loss: 0.4741\n",
      "Baseline Loss: 2.8406 | Actual Loss: 0.2889\n",
      "Baseline Loss: 2.8512 | Actual Loss: 0.4256\n",
      "Baseline Loss: 2.8030 | Actual Loss: 0.2802\n",
      "Baseline Loss: 2.8066 | Actual Loss: 0.2816\n",
      "Baseline Loss: 2.7955 | Actual Loss: 0.2272\n",
      "Baseline Loss: 2.7922 | Actual Loss: 0.1727\n",
      "Baseline Loss: 2.8307 | Actual Loss: 0.4393\n",
      "Baseline Loss: 2.8032 | Actual Loss: 0.3128\n",
      "Baseline Loss: 2.8456 | Actual Loss: 0.2531\n",
      "Baseline Loss: 2.8735 | Actual Loss: 0.3247\n",
      "Baseline Loss: 2.8283 | Actual Loss: 0.4205\n",
      "Baseline Loss: 2.8270 | Actual Loss: 0.2227\n",
      "Baseline Loss: 2.8333 | Actual Loss: 0.3092\n",
      "Baseline Loss: 2.7738 | Actual Loss: 0.2001\n",
      "Baseline Loss: 2.7975 | Actual Loss: 0.2155\n",
      "Baseline Loss: 2.5665 | Actual Loss: 0.2313\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 66/1000 [00:22<04:59,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8345 | Actual Loss: 0.3162\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3268\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.5976\n",
      "Epoch 66/1000: Train Loss: 0.2878, Val Loss: 0.3887\n",
      "Baseline Loss: 2.8327 | Actual Loss: 0.1916\n",
      "Baseline Loss: 2.8317 | Actual Loss: 0.1511\n",
      "Baseline Loss: 2.7652 | Actual Loss: 0.1790\n",
      "Baseline Loss: 2.8351 | Actual Loss: 0.3546\n",
      "Baseline Loss: 2.8773 | Actual Loss: 0.4635\n",
      "Baseline Loss: 2.7899 | Actual Loss: 0.4583\n",
      "Baseline Loss: 2.9281 | Actual Loss: 0.4436\n",
      "Baseline Loss: 2.8358 | Actual Loss: 0.1874\n",
      "Baseline Loss: 2.8355 | Actual Loss: 0.2164\n",
      "Baseline Loss: 2.8577 | Actual Loss: 0.2611\n",
      "Baseline Loss: 2.7801 | Actual Loss: 0.4271\n",
      "Baseline Loss: 2.8333 | Actual Loss: 0.2751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 67/1000 [00:22<04:44,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7815 | Actual Loss: 0.1026\n",
      "Baseline Loss: 2.8486 | Actual Loss: 0.3500\n",
      "Baseline Loss: 2.8502 | Actual Loss: 0.1933\n",
      "Baseline Loss: 2.7247 | Actual Loss: 0.4362\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3309\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3742\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3238\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.6495\n",
      "Epoch 67/1000: Train Loss: 0.2932, Val Loss: 0.4196\n",
      "Baseline Loss: 2.9252 | Actual Loss: 0.3220\n",
      "Baseline Loss: 2.7614 | Actual Loss: 0.4839\n",
      "Baseline Loss: 2.7930 | Actual Loss: 0.2017\n",
      "Baseline Loss: 2.8087 | Actual Loss: 0.2933\n",
      "Baseline Loss: 2.9118 | Actual Loss: 0.2401\n",
      "Baseline Loss: 2.7764 | Actual Loss: 0.3329\n",
      "Baseline Loss: 2.8078 | Actual Loss: 0.2717\n",
      "Baseline Loss: 2.7528 | Actual Loss: 0.3137\n",
      "Baseline Loss: 2.8023 | Actual Loss: 0.1536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 68/1000 [00:22<04:49,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8154 | Actual Loss: 0.2263\n",
      "Baseline Loss: 2.8693 | Actual Loss: 0.3242\n",
      "Baseline Loss: 2.7865 | Actual Loss: 0.3056\n",
      "Baseline Loss: 2.8160 | Actual Loss: 0.2105\n",
      "Baseline Loss: 2.8342 | Actual Loss: 0.3387\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2526\n",
      "Baseline Loss: 2.6729 | Actual Loss: 0.5058\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3673\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3753\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.4330\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.4936\n",
      "Epoch 68/1000: Train Loss: 0.2985, Val Loss: 0.4173\n",
      "Baseline Loss: 2.7741 | Actual Loss: 0.4637\n",
      "Baseline Loss: 2.7953 | Actual Loss: 0.2237\n",
      "Baseline Loss: 2.9064 | Actual Loss: 0.3215\n",
      "Baseline Loss: 2.8125 | Actual Loss: 0.3906\n",
      "Baseline Loss: 2.8088 | Actual Loss: 0.2670\n",
      "Baseline Loss: 2.8901 | Actual Loss: 0.0959\n",
      "Baseline Loss: 2.8100 | Actual Loss: 0.2136\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2826\n",
      "Baseline Loss: 2.8314 | Actual Loss: 0.3883\n",
      "Baseline Loss: 2.8517 | Actual Loss: 0.2109\n",
      "Baseline Loss: 2.7751 | Actual Loss: 0.3714\n",
      "Baseline Loss: 2.8597 | Actual Loss: 0.4166\n",
      "Baseline Loss: 2.7348 | Actual Loss: 0.1853\n",
      "Baseline Loss: 2.8109 | Actual Loss: 0.3298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 69/1000 [00:22<04:39,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8019 | Actual Loss: 0.3189\n",
      "Baseline Loss: 2.6318 | Actual Loss: 0.7678\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.4149\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.4018\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3459\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.6129\n",
      "Epoch 69/1000: Train Loss: 0.3280, Val Loss: 0.4438\n",
      "Baseline Loss: 2.8653 | Actual Loss: 0.1648\n",
      "Baseline Loss: 2.7527 | Actual Loss: 0.2705\n",
      "Baseline Loss: 2.7644 | Actual Loss: 0.2732\n",
      "Baseline Loss: 2.9013 | Actual Loss: 0.3956\n",
      "Baseline Loss: 2.8144 | Actual Loss: 0.2196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 70/1000 [00:23<04:55,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8841 | Actual Loss: 0.1690\n",
      "Baseline Loss: 2.8437 | Actual Loss: 0.2920\n",
      "Baseline Loss: 2.8378 | Actual Loss: 0.5740\n",
      "Baseline Loss: 2.8843 | Actual Loss: 0.3108\n",
      "Baseline Loss: 2.7895 | Actual Loss: 0.1854\n",
      "Baseline Loss: 2.8184 | Actual Loss: 0.2001\n",
      "Baseline Loss: 2.7885 | Actual Loss: 0.2327\n",
      "Baseline Loss: 2.8186 | Actual Loss: 0.2271\n",
      "Baseline Loss: 2.8589 | Actual Loss: 0.2393\n",
      "Baseline Loss: 2.8209 | Actual Loss: 0.2431\n",
      "Baseline Loss: 2.5781 | Actual Loss: 0.3489\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2956\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2522\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3013\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.5351\n",
      "Epoch 70/1000: Train Loss: 0.2716, Val Loss: 0.3461\n",
      "New best validation loss: 0.3461\n",
      "Baseline Loss: 2.8101 | Actual Loss: 0.2572\n",
      "Baseline Loss: 2.8950 | Actual Loss: 0.2015\n",
      "Baseline Loss: 2.7777 | Actual Loss: 0.3550\n",
      "Baseline Loss: 2.8034 | Actual Loss: 0.2026\n",
      "Baseline Loss: 2.8247 | Actual Loss: 0.3881\n",
      "Baseline Loss: 2.8747 | Actual Loss: 0.3090\n",
      "Baseline Loss: 2.8207 | Actual Loss: 0.2274\n",
      "Baseline Loss: 2.7500 | Actual Loss: 0.3081\n",
      "Baseline Loss: 2.8502 | Actual Loss: 0.1078\n",
      "Baseline Loss: 2.8148 | Actual Loss: 0.3144\n",
      "Baseline Loss: 2.8343 | Actual Loss: 0.2453\n",
      "Baseline Loss: 2.9265 | Actual Loss: 0.3727\n",
      "Baseline Loss: 2.9100 | Actual Loss: 0.3049\n",
      "Baseline Loss: 2.8739 | Actual Loss: 0.3105\n",
      "Baseline Loss: 2.8098 | Actual Loss: 0.1587\n",
      "Baseline Loss: 2.4813 | Actual Loss: 0.4260\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 71/1000 [00:23<05:01,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8345 | Actual Loss: 0.3021\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3636\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.4594\n",
      "Epoch 71/1000: Train Loss: 0.2806, Val Loss: 0.3448\n",
      "New best validation loss: 0.3448\n",
      "Baseline Loss: 2.8600 | Actual Loss: 0.4222\n",
      "Baseline Loss: 2.8028 | Actual Loss: 0.1741\n",
      "Baseline Loss: 2.7614 | Actual Loss: 0.3313\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.1804\n",
      "Baseline Loss: 2.8142 | Actual Loss: 0.2368\n",
      "Baseline Loss: 2.9061 | Actual Loss: 0.2336\n",
      "Baseline Loss: 2.8630 | Actual Loss: 0.3099\n",
      "Baseline Loss: 2.8300 | Actual Loss: 0.3602\n",
      "Baseline Loss: 2.8817 | Actual Loss: 0.3053\n",
      "Baseline Loss: 2.8159 | Actual Loss: 0.4092\n",
      "Baseline Loss: 2.8193 | Actual Loss: 0.1811\n",
      "Baseline Loss: 2.7932 | Actual Loss: 0.2489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 72/1000 [00:23<04:46,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8357 | Actual Loss: 0.2468\n",
      "Baseline Loss: 2.7776 | Actual Loss: 0.1652\n",
      "Baseline Loss: 2.7787 | Actual Loss: 0.2618\n",
      "Baseline Loss: 2.5138 | Actual Loss: 0.1609\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3667\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3204\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3374\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.4379\n",
      "Epoch 72/1000: Train Loss: 0.2642, Val Loss: 0.3656\n",
      "Baseline Loss: 2.8080 | Actual Loss: 0.2891\n",
      "Baseline Loss: 2.8223 | Actual Loss: 0.2450\n",
      "Baseline Loss: 2.8677 | Actual Loss: 0.4984\n",
      "Baseline Loss: 2.8694 | Actual Loss: 0.2811\n",
      "Baseline Loss: 2.8524 | Actual Loss: 0.1764\n",
      "Baseline Loss: 2.7722 | Actual Loss: 0.3049\n",
      "Baseline Loss: 2.8337 | Actual Loss: 0.1547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 73/1000 [00:24<04:52,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7828 | Actual Loss: 0.3292\n",
      "Baseline Loss: 2.8084 | Actual Loss: 0.5038\n",
      "Baseline Loss: 2.8675 | Actual Loss: 0.1914\n",
      "Baseline Loss: 2.7837 | Actual Loss: 0.3285\n",
      "Baseline Loss: 2.9085 | Actual Loss: 0.1965\n",
      "Baseline Loss: 2.8019 | Actual Loss: 0.2768\n",
      "Baseline Loss: 2.8124 | Actual Loss: 0.2621\n",
      "Baseline Loss: 2.8128 | Actual Loss: 0.1900\n",
      "Baseline Loss: 2.6073 | Actual Loss: 0.3434\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3260\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2839\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3534\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.4278\n",
      "Epoch 73/1000: Train Loss: 0.2857, Val Loss: 0.3478\n",
      "Baseline Loss: 2.8382 | Actual Loss: 0.2006\n",
      "Baseline Loss: 2.8584 | Actual Loss: 0.1301\n",
      "Baseline Loss: 2.8397 | Actual Loss: 0.2393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 74/1000 [00:24<04:35,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7674 | Actual Loss: 0.2674\n",
      "Baseline Loss: 2.8730 | Actual Loss: 0.3604\n",
      "Baseline Loss: 2.8288 | Actual Loss: 0.2936\n",
      "Baseline Loss: 2.7577 | Actual Loss: 0.2471\n",
      "Baseline Loss: 2.8201 | Actual Loss: 0.3046\n",
      "Baseline Loss: 2.8629 | Actual Loss: 0.3406\n",
      "Baseline Loss: 2.7910 | Actual Loss: 0.1759\n",
      "Baseline Loss: 2.8125 | Actual Loss: 0.2989\n",
      "Baseline Loss: 2.8885 | Actual Loss: 0.1934\n",
      "Baseline Loss: 2.8546 | Actual Loss: 0.1950\n",
      "Baseline Loss: 2.8063 | Actual Loss: 0.2834\n",
      "Baseline Loss: 2.8474 | Actual Loss: 0.1792\n",
      "Baseline Loss: 2.5662 | Actual Loss: 0.2950\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2675\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2846\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3167\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.5829\n",
      "Epoch 74/1000: Train Loss: 0.2503, Val Loss: 0.3629\n",
      "Baseline Loss: 2.7867 | Actual Loss: 0.2653\n",
      "Baseline Loss: 2.8113 | Actual Loss: 0.1741\n",
      "Baseline Loss: 2.7958 | Actual Loss: 0.2763\n",
      "Baseline Loss: 2.8417 | Actual Loss: 0.2436\n",
      "Baseline Loss: 2.8718 | Actual Loss: 0.2674\n",
      "Baseline Loss: 2.8664 | Actual Loss: 0.2455\n",
      "Baseline Loss: 2.8726 | Actual Loss: 0.2450\n",
      "Baseline Loss: 2.9063 | Actual Loss: 0.2949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 75/1000 [00:24<04:51,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8123 | Actual Loss: 0.2085\n",
      "Baseline Loss: 2.8305 | Actual Loss: 0.2414\n",
      "Baseline Loss: 2.7624 | Actual Loss: 0.3299\n",
      "Baseline Loss: 2.8453 | Actual Loss: 0.2498\n",
      "Baseline Loss: 2.8453 | Actual Loss: 0.1684\n",
      "Baseline Loss: 2.8133 | Actual Loss: 0.2990\n",
      "Baseline Loss: 2.8210 | Actual Loss: 0.3563\n",
      "Baseline Loss: 2.6153 | Actual Loss: 0.0973\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3486\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.4284\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.4002\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.5599\n",
      "Epoch 75/1000: Train Loss: 0.2477, Val Loss: 0.4343\n",
      "Baseline Loss: 2.8026 | Actual Loss: 0.3295\n",
      "Baseline Loss: 2.8489 | Actual Loss: 0.2226\n",
      "Baseline Loss: 2.8695 | Actual Loss: 0.2255\n",
      "Baseline Loss: 2.8503 | Actual Loss: 0.3232\n",
      "Baseline Loss: 2.7798 | Actual Loss: 0.3865\n",
      "Baseline Loss: 2.8086 | Actual Loss: 0.2476\n",
      "Baseline Loss: 2.8877 | Actual Loss: 0.2519\n",
      "Baseline Loss: 2.8174 | Actual Loss: 0.3420\n",
      "Baseline Loss: 2.8148 | Actual Loss: 0.3131\n",
      "Baseline Loss: 2.8060 | Actual Loss: 0.2856\n",
      "Baseline Loss: 2.8006 | Actual Loss: 0.3369\n",
      "Baseline Loss: 2.7703 | Actual Loss: 0.3055\n",
      "Baseline Loss: 2.9189 | Actual Loss: 0.1895\n",
      "Baseline Loss: 2.8327 | Actual Loss: 0.2551\n",
      "Baseline Loss: 2.8506 | Actual Loss: 0.5482\n",
      "Baseline Loss: 2.5227 | Actual Loss: 0.1492\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2785\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.4110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 76/1000 [00:25<05:00,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7737 | Actual Loss: 0.3402\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3976\n",
      "Epoch 76/1000: Train Loss: 0.2945, Val Loss: 0.3568\n",
      "Baseline Loss: 2.7879 | Actual Loss: 0.2916\n",
      "Baseline Loss: 2.8138 | Actual Loss: 0.2625\n",
      "Baseline Loss: 2.8183 | Actual Loss: 0.1775\n",
      "Baseline Loss: 2.9283 | Actual Loss: 0.3460\n",
      "Baseline Loss: 2.8839 | Actual Loss: 0.2888\n",
      "Baseline Loss: 2.7882 | Actual Loss: 0.1731\n",
      "Baseline Loss: 2.8873 | Actual Loss: 0.3540\n",
      "Baseline Loss: 2.7447 | Actual Loss: 0.2187\n",
      "Baseline Loss: 2.8645 | Actual Loss: 0.1342\n",
      "Baseline Loss: 2.7793 | Actual Loss: 0.2470\n",
      "Baseline Loss: 2.7758 | Actual Loss: 0.2415\n",
      "Baseline Loss: 2.8282 | Actual Loss: 0.5442\n",
      "Baseline Loss: 2.8097 | Actual Loss: 0.3342\n",
      "Baseline Loss: 2.9532 | Actual Loss: 0.5273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 77/1000 [00:25<04:40,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8117 | Actual Loss: 0.4019\n",
      "Baseline Loss: 2.5089 | Actual Loss: 0.1973\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2928\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3721\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3480\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.4912\n",
      "Epoch 77/1000: Train Loss: 0.2962, Val Loss: 0.3760\n",
      "Baseline Loss: 2.8706 | Actual Loss: 0.1918\n",
      "Baseline Loss: 2.7982 | Actual Loss: 0.3095\n",
      "Baseline Loss: 2.8356 | Actual Loss: 0.2688\n",
      "Baseline Loss: 2.8301 | Actual Loss: 0.4949\n",
      "Baseline Loss: 2.7507 | Actual Loss: 0.2539\n",
      "Baseline Loss: 2.7752 | Actual Loss: 0.2345\n",
      "Baseline Loss: 2.8609 | Actual Loss: 0.1708\n",
      "Baseline Loss: 2.9045 | Actual Loss: 0.1684\n",
      "Baseline Loss: 2.8457 | Actual Loss: 0.2274\n",
      "Baseline Loss: 2.7885 | Actual Loss: 0.1832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 78/1000 [00:25<04:53,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7731 | Actual Loss: 0.3473\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.2207\n",
      "Baseline Loss: 2.8706 | Actual Loss: 0.2617\n",
      "Baseline Loss: 2.9125 | Actual Loss: 0.2375\n",
      "Baseline Loss: 2.8768 | Actual Loss: 0.2416\n",
      "Baseline Loss: 2.5026 | Actual Loss: 0.2333\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3262\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3484\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3187\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.4369\n",
      "Epoch 78/1000: Train Loss: 0.2528, Val Loss: 0.3576\n",
      "Baseline Loss: 2.7843 | Actual Loss: 0.2675\n",
      "Baseline Loss: 2.8194 | Actual Loss: 0.1471\n",
      "Baseline Loss: 2.9156 | Actual Loss: 0.2668\n",
      "Baseline Loss: 2.8276 | Actual Loss: 0.1504\n",
      "Baseline Loss: 2.8610 | Actual Loss: 0.1787\n",
      "Baseline Loss: 2.8638 | Actual Loss: 0.3758\n",
      "Baseline Loss: 2.7759 | Actual Loss: 0.2214\n",
      "Baseline Loss: 2.8782 | Actual Loss: 0.3935\n",
      "Baseline Loss: 2.8557 | Actual Loss: 0.1435\n",
      "Baseline Loss: 2.7846 | Actual Loss: 0.2167\n",
      "Baseline Loss: 2.8231 | Actual Loss: 0.3658\n",
      "Baseline Loss: 2.8559 | Actual Loss: 0.2146\n",
      "Baseline Loss: 2.7629 | Actual Loss: 0.2704\n",
      "Baseline Loss: 2.9086 | Actual Loss: 0.3795\n",
      "Baseline Loss: 2.8153 | Actual Loss: 0.2013\n",
      "Baseline Loss: 2.5433 | Actual Loss: 0.2819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 79/1000 [00:26<04:36,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8702 | Actual Loss: 0.2632\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3306\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2620\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.6697\n",
      "Epoch 79/1000: Train Loss: 0.2547, Val Loss: 0.3814\n",
      "Baseline Loss: 2.9533 | Actual Loss: 0.2867\n",
      "Baseline Loss: 2.9131 | Actual Loss: 0.3630\n",
      "Baseline Loss: 2.8251 | Actual Loss: 0.1460\n",
      "Baseline Loss: 2.7690 | Actual Loss: 0.2856\n",
      "Baseline Loss: 2.7760 | Actual Loss: 0.4588\n",
      "Baseline Loss: 2.8071 | Actual Loss: 0.2203\n",
      "Baseline Loss: 2.8075 | Actual Loss: 0.1776\n",
      "Baseline Loss: 2.8269 | Actual Loss: 0.2496\n",
      "Baseline Loss: 2.8497 | Actual Loss: 0.3264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 80/1000 [00:26<04:44,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8245 | Actual Loss: 0.4011\n",
      "Baseline Loss: 2.7932 | Actual Loss: 0.2674\n",
      "Baseline Loss: 2.8308 | Actual Loss: 0.2146\n",
      "Baseline Loss: 2.8964 | Actual Loss: 0.1534\n",
      "Baseline Loss: 2.7274 | Actual Loss: 0.1899\n",
      "Baseline Loss: 2.7713 | Actual Loss: 0.1736\n",
      "Baseline Loss: 2.5550 | Actual Loss: 0.2024\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3425\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3856\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3543\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.4759\n",
      "Epoch 80/1000: Train Loss: 0.2573, Val Loss: 0.3896\n",
      "Baseline Loss: 2.8589 | Actual Loss: 0.2584\n",
      "Baseline Loss: 2.8563 | Actual Loss: 0.2540\n",
      "Baseline Loss: 2.8451 | Actual Loss: 0.2157\n",
      "Baseline Loss: 2.8277 | Actual Loss: 0.2385\n",
      "Baseline Loss: 2.9035 | Actual Loss: 0.1831\n",
      "Baseline Loss: 2.8131 | Actual Loss: 0.1006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 81/1000 [00:26<04:39,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8080 | Actual Loss: 0.1737\n",
      "Baseline Loss: 2.8421 | Actual Loss: 0.3199\n",
      "Baseline Loss: 2.8030 | Actual Loss: 0.3591\n",
      "Baseline Loss: 2.7382 | Actual Loss: 0.2285\n",
      "Baseline Loss: 2.7928 | Actual Loss: 0.2282\n",
      "Baseline Loss: 2.9240 | Actual Loss: 0.3269\n",
      "Baseline Loss: 2.9119 | Actual Loss: 0.3148\n",
      "Baseline Loss: 2.8038 | Actual Loss: 0.2363\n",
      "Baseline Loss: 2.8055 | Actual Loss: 0.3622\n",
      "Baseline Loss: 2.5148 | Actual Loss: 0.1094\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2825\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2782\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2865\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3911\n",
      "Epoch 81/1000: Train Loss: 0.2443, Val Loss: 0.3096\n",
      "New best validation loss: 0.3096\n",
      "Baseline Loss: 2.8093 | Actual Loss: 0.1151\n",
      "Baseline Loss: 2.8032 | Actual Loss: 0.1511\n",
      "Baseline Loss: 2.8296 | Actual Loss: 0.1953\n",
      "Baseline Loss: 2.8408 | Actual Loss: 0.2493\n",
      "Baseline Loss: 2.8361 | Actual Loss: 0.2571\n",
      "Baseline Loss: 2.8661 | Actual Loss: 0.2497\n",
      "Baseline Loss: 2.8208 | Actual Loss: 0.2105\n",
      "Baseline Loss: 2.9381 | Actual Loss: 0.3538\n",
      "Baseline Loss: 2.7979 | Actual Loss: 0.4408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 82/1000 [00:27<04:51,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7875 | Actual Loss: 0.3094\n",
      "Baseline Loss: 2.9081 | Actual Loss: 0.3286\n",
      "Baseline Loss: 2.8621 | Actual Loss: 0.3371\n",
      "Baseline Loss: 2.8154 | Actual Loss: 0.3428\n",
      "Baseline Loss: 2.7847 | Actual Loss: 0.3414\n",
      "Baseline Loss: 2.8361 | Actual Loss: 0.1785\n",
      "Baseline Loss: 2.5095 | Actual Loss: 0.2418\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2936\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.4432\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3405\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.4574\n",
      "Epoch 82/1000: Train Loss: 0.2689, Val Loss: 0.3837\n",
      "Baseline Loss: 2.9195 | Actual Loss: 0.1864\n",
      "Baseline Loss: 2.9072 | Actual Loss: 0.2073\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.3715\n",
      "Baseline Loss: 2.7938 | Actual Loss: 0.1579\n",
      "Baseline Loss: 2.7642 | Actual Loss: 0.3270\n",
      "Baseline Loss: 2.8504 | Actual Loss: 0.2137\n",
      "Baseline Loss: 2.8332 | Actual Loss: 0.2173\n",
      "Baseline Loss: 2.7495 | Actual Loss: 0.2055\n",
      "Baseline Loss: 2.8614 | Actual Loss: 0.3154\n",
      "Baseline Loss: 2.7621 | Actual Loss: 0.2979\n",
      "Baseline Loss: 2.8249 | Actual Loss: 0.2478\n",
      "Baseline Loss: 2.8508 | Actual Loss: 0.2615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 83/1000 [00:27<05:00,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8315 | Actual Loss: 0.2981\n",
      "Baseline Loss: 2.8149 | Actual Loss: 0.2042\n",
      "Baseline Loss: 2.8710 | Actual Loss: 0.2623\n",
      "Baseline Loss: 2.7257 | Actual Loss: 0.5970\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3651\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3153\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2763\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3951\n",
      "Epoch 83/1000: Train Loss: 0.2732, Val Loss: 0.3379\n",
      "Baseline Loss: 2.8625 | Actual Loss: 0.3331\n",
      "Baseline Loss: 2.8110 | Actual Loss: 0.4511\n",
      "Baseline Loss: 2.8127 | Actual Loss: 0.1834\n",
      "Baseline Loss: 2.8090 | Actual Loss: 0.2496\n",
      "Baseline Loss: 2.8502 | Actual Loss: 0.4477\n",
      "Baseline Loss: 2.8158 | Actual Loss: 0.1883\n",
      "Baseline Loss: 2.7721 | Actual Loss: 0.2174\n",
      "Baseline Loss: 2.7744 | Actual Loss: 0.2526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 84/1000 [00:27<04:47,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8100 | Actual Loss: 0.2845\n",
      "Baseline Loss: 2.7806 | Actual Loss: 0.2965\n",
      "Baseline Loss: 2.8941 | Actual Loss: 0.1580\n",
      "Baseline Loss: 2.8611 | Actual Loss: 0.3898\n",
      "Baseline Loss: 2.8131 | Actual Loss: 0.2252\n",
      "Baseline Loss: 2.8078 | Actual Loss: 0.1837\n",
      "Baseline Loss: 2.8724 | Actual Loss: 0.2738\n",
      "Baseline Loss: 2.5918 | Actual Loss: 0.1627\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3661\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2967\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2709\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.2984\n",
      "Epoch 84/1000: Train Loss: 0.2686, Val Loss: 0.3080\n",
      "New best validation loss: 0.3080\n",
      "Baseline Loss: 2.8898 | Actual Loss: 0.2208\n",
      "Baseline Loss: 2.8325 | Actual Loss: 0.1327\n",
      "Baseline Loss: 2.8823 | Actual Loss: 0.2894\n",
      "Baseline Loss: 2.8146 | Actual Loss: 0.2323\n",
      "Baseline Loss: 2.9075 | Actual Loss: 0.2218\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2031\n",
      "Baseline Loss: 2.8385 | Actual Loss: 0.2569\n",
      "Baseline Loss: 2.8240 | Actual Loss: 0.2485\n",
      "Baseline Loss: 2.8643 | Actual Loss: 0.2329\n",
      "Baseline Loss: 2.7498 | Actual Loss: 0.2359\n",
      "Baseline Loss: 2.8228 | Actual Loss: 0.2239\n",
      "Baseline Loss: 2.8570 | Actual Loss: 0.7664\n",
      "Baseline Loss: 2.8539 | Actual Loss: 0.2426\n",
      "Baseline Loss: 2.7876 | Actual Loss: 0.1424\n",
      "Baseline Loss: 2.8354 | Actual Loss: 0.3092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 85/1000 [00:28<04:54,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5729 | Actual Loss: 0.1760\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3595\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.4032\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3935\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3306\n",
      "Epoch 85/1000: Train Loss: 0.2584, Val Loss: 0.3717\n",
      "Baseline Loss: 2.8731 | Actual Loss: 0.1016\n",
      "Baseline Loss: 2.8368 | Actual Loss: 0.4546\n",
      "Baseline Loss: 2.7478 | Actual Loss: 0.1934\n",
      "Baseline Loss: 2.8504 | Actual Loss: 0.1717\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1579\n",
      "Baseline Loss: 2.7874 | Actual Loss: 0.2445\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.3517\n",
      "Baseline Loss: 2.8336 | Actual Loss: 0.2549\n",
      "Baseline Loss: 2.8752 | Actual Loss: 0.3699\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.5309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▊         | 86/1000 [00:28<04:55,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7607 | Actual Loss: 0.2895\n",
      "Baseline Loss: 2.8311 | Actual Loss: 0.1100\n",
      "Baseline Loss: 2.8832 | Actual Loss: 0.2547\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3066\n",
      "Baseline Loss: 2.8189 | Actual Loss: 0.2729\n",
      "Baseline Loss: 2.6099 | Actual Loss: 0.1373\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2923\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.4711\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3540\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3324\n",
      "Epoch 86/1000: Train Loss: 0.2626, Val Loss: 0.3625\n",
      "Baseline Loss: 2.8658 | Actual Loss: 0.3750\n",
      "Baseline Loss: 2.8194 | Actual Loss: 0.2406\n",
      "Baseline Loss: 2.8301 | Actual Loss: 0.2416\n",
      "Baseline Loss: 2.9027 | Actual Loss: 0.1761\n",
      "Baseline Loss: 2.7716 | Actual Loss: 0.2492\n",
      "Baseline Loss: 2.8441 | Actual Loss: 0.4511\n",
      "Baseline Loss: 2.7915 | Actual Loss: 0.2270\n",
      "Baseline Loss: 2.7836 | Actual Loss: 0.2152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▊         | 87/1000 [00:28<04:40,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8621 | Actual Loss: 0.1924\n",
      "Baseline Loss: 2.7953 | Actual Loss: 0.2703\n",
      "Baseline Loss: 2.8230 | Actual Loss: 0.1321\n",
      "Baseline Loss: 2.8653 | Actual Loss: 0.2571\n",
      "Baseline Loss: 2.7900 | Actual Loss: 0.1173\n",
      "Baseline Loss: 2.8332 | Actual Loss: 0.2103\n",
      "Baseline Loss: 2.8614 | Actual Loss: 0.1722\n",
      "Baseline Loss: 2.5370 | Actual Loss: 0.0870\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3905\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3069\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3741\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3889\n",
      "Epoch 87/1000: Train Loss: 0.2259, Val Loss: 0.3651\n",
      "Baseline Loss: 2.8873 | Actual Loss: 0.2641\n",
      "Baseline Loss: 2.8599 | Actual Loss: 0.3651\n",
      "Baseline Loss: 2.8335 | Actual Loss: 0.2050\n",
      "Baseline Loss: 2.7939 | Actual Loss: 0.2389\n",
      "Baseline Loss: 2.7691 | Actual Loss: 0.1536\n",
      "Baseline Loss: 2.8135 | Actual Loss: 0.1575\n",
      "Baseline Loss: 2.8651 | Actual Loss: 0.2552\n",
      "Baseline Loss: 2.8290 | Actual Loss: 0.3861\n",
      "Baseline Loss: 2.7445 | Actual Loss: 0.2229\n",
      "Baseline Loss: 2.8253 | Actual Loss: 0.1787\n",
      "Baseline Loss: 2.8111 | Actual Loss: 0.2001\n",
      "Baseline Loss: 2.7209 | Actual Loss: 0.2270\n",
      "Baseline Loss: 2.8473 | Actual Loss: 0.1555\n",
      "Baseline Loss: 2.8391 | Actual Loss: 0.2884\n",
      "Baseline Loss: 2.8088 | Actual Loss: 0.2185\n",
      "Baseline Loss: 2.8610 | Actual Loss: 0.3213\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3101\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 88/1000 [00:28<04:46,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7737 | Actual Loss: 0.3571\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3599\n",
      "Epoch 88/1000: Train Loss: 0.2399, Val Loss: 0.3443\n",
      "Baseline Loss: 2.9043 | Actual Loss: 0.1719\n",
      "Baseline Loss: 2.8638 | Actual Loss: 0.2959\n",
      "Baseline Loss: 2.8237 | Actual Loss: 0.2000\n",
      "Baseline Loss: 2.8197 | Actual Loss: 0.2403\n",
      "Baseline Loss: 2.8053 | Actual Loss: 0.1257\n",
      "Baseline Loss: 2.8372 | Actual Loss: 0.2853\n",
      "Baseline Loss: 2.7914 | Actual Loss: 0.2525\n",
      "Baseline Loss: 2.9055 | Actual Loss: 0.3132\n",
      "Baseline Loss: 2.8340 | Actual Loss: 0.1804\n",
      "Baseline Loss: 2.8594 | Actual Loss: 0.2326\n",
      "Baseline Loss: 2.8249 | Actual Loss: 0.1221\n",
      "Baseline Loss: 2.7597 | Actual Loss: 0.1689\n",
      "Baseline Loss: 2.7301 | Actual Loss: 0.5221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 89/1000 [00:29<04:56,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8776 | Actual Loss: 0.2644\n",
      "Baseline Loss: 2.8720 | Actual Loss: 0.2004\n",
      "Baseline Loss: 2.5148 | Actual Loss: 0.1888\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3373\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3523\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3830\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3752\n",
      "Epoch 89/1000: Train Loss: 0.2353, Val Loss: 0.3619\n",
      "Baseline Loss: 2.8857 | Actual Loss: 0.2239\n",
      "Baseline Loss: 2.8947 | Actual Loss: 0.2554\n",
      "Baseline Loss: 2.8447 | Actual Loss: 0.4748\n",
      "Baseline Loss: 2.8074 | Actual Loss: 0.3145\n",
      "Baseline Loss: 2.9129 | Actual Loss: 0.1138\n",
      "Baseline Loss: 2.8673 | Actual Loss: 0.2125\n",
      "Baseline Loss: 2.7968 | Actual Loss: 0.2329\n",
      "Baseline Loss: 2.7940 | Actual Loss: 0.3023\n",
      "Baseline Loss: 2.8071 | Actual Loss: 0.1708\n",
      "Baseline Loss: 2.8172 | Actual Loss: 0.2239\n",
      "Baseline Loss: 2.8010 | Actual Loss: 0.1935\n",
      "Baseline Loss: 2.8290 | Actual Loss: 0.2773\n",
      "Baseline Loss: 2.8202 | Actual Loss: 0.2333\n",
      "Baseline Loss: 2.8267 | Actual Loss: 0.1339\n",
      "Baseline Loss: 2.7725 | Actual Loss: 0.2848\n",
      "Baseline Loss: 2.5852 | Actual Loss: 0.4177\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3003\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3141\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 90/1000 [00:29<04:37,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7548 | Actual Loss: 0.3577\n",
      "Epoch 90/1000: Train Loss: 0.2541, Val Loss: 0.3120\n",
      "Baseline Loss: 2.7886 | Actual Loss: 0.1833\n",
      "Baseline Loss: 2.9104 | Actual Loss: 0.2446\n",
      "Baseline Loss: 2.8024 | Actual Loss: 0.3535\n",
      "Baseline Loss: 2.7956 | Actual Loss: 0.1674\n",
      "Baseline Loss: 2.8300 | Actual Loss: 0.1813\n",
      "Baseline Loss: 2.7942 | Actual Loss: 0.5594\n",
      "Baseline Loss: 2.8517 | Actual Loss: 0.1970\n",
      "Baseline Loss: 2.7993 | Actual Loss: 0.2584\n",
      "Baseline Loss: 2.7662 | Actual Loss: 0.2200\n",
      "Baseline Loss: 2.8081 | Actual Loss: 0.2615\n",
      "Baseline Loss: 2.8044 | Actual Loss: 0.2254\n",
      "Baseline Loss: 2.7675 | Actual Loss: 0.2959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 91/1000 [00:29<04:53,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9007 | Actual Loss: 0.3298\n",
      "Baseline Loss: 2.7435 | Actual Loss: 0.1991\n",
      "Baseline Loss: 2.7834 | Actual Loss: 0.3238\n",
      "Baseline Loss: 2.5607 | Actual Loss: 0.1337\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2917\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3349\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2733\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.4192\n",
      "Epoch 91/1000: Train Loss: 0.2584, Val Loss: 0.3298\n",
      "Baseline Loss: 2.8402 | Actual Loss: 0.2316\n",
      "Baseline Loss: 2.7765 | Actual Loss: 0.1447\n",
      "Baseline Loss: 2.8143 | Actual Loss: 0.3143\n",
      "Baseline Loss: 2.9323 | Actual Loss: 0.2293\n",
      "Baseline Loss: 2.8196 | Actual Loss: 0.2514\n",
      "Baseline Loss: 2.8071 | Actual Loss: 0.1858\n",
      "Baseline Loss: 2.7999 | Actual Loss: 0.1686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 92/1000 [00:30<04:42,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8386 | Actual Loss: 0.2668\n",
      "Baseline Loss: 2.7630 | Actual Loss: 0.2963\n",
      "Baseline Loss: 2.8699 | Actual Loss: 0.1979\n",
      "Baseline Loss: 2.8299 | Actual Loss: 0.2625\n",
      "Baseline Loss: 2.8624 | Actual Loss: 0.2971\n",
      "Baseline Loss: 2.7933 | Actual Loss: 0.1873\n",
      "Baseline Loss: 2.8567 | Actual Loss: 0.1527\n",
      "Baseline Loss: 2.8248 | Actual Loss: 0.4157\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.2057\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2768\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3622\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3567\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3615\n",
      "Epoch 92/1000: Train Loss: 0.2380, Val Loss: 0.3393\n",
      "Baseline Loss: 2.8382 | Actual Loss: 0.3507\n",
      "Baseline Loss: 2.8302 | Actual Loss: 0.2003\n",
      "Baseline Loss: 2.8323 | Actual Loss: 0.2514\n",
      "Baseline Loss: 2.7985 | Actual Loss: 0.1812\n",
      "Baseline Loss: 2.8502 | Actual Loss: 0.2379\n",
      "Baseline Loss: 2.8311 | Actual Loss: 0.2672\n",
      "Baseline Loss: 2.8317 | Actual Loss: 0.4317\n",
      "Baseline Loss: 2.7983 | Actual Loss: 0.2520\n",
      "Baseline Loss: 2.8055 | Actual Loss: 0.1709\n",
      "Baseline Loss: 2.8203 | Actual Loss: 0.2415\n",
      "Baseline Loss: 2.8451 | Actual Loss: 0.1377\n",
      "Baseline Loss: 2.8739 | Actual Loss: 0.1947\n",
      "Baseline Loss: 2.8314 | Actual Loss: 0.2763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 93/1000 [00:30<04:47,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8751 | Actual Loss: 0.2944\n",
      "Baseline Loss: 2.8082 | Actual Loss: 0.2729\n",
      "Baseline Loss: 2.5248 | Actual Loss: 0.2033\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3001\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2884\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3758\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.4180\n",
      "Epoch 93/1000: Train Loss: 0.2478, Val Loss: 0.3456\n",
      "Baseline Loss: 2.9019 | Actual Loss: 0.3147\n",
      "Baseline Loss: 2.7745 | Actual Loss: 0.1805\n",
      "Baseline Loss: 2.8567 | Actual Loss: 0.4389\n",
      "Baseline Loss: 2.7983 | Actual Loss: 0.2536\n",
      "Baseline Loss: 2.9116 | Actual Loss: 0.2294\n",
      "Baseline Loss: 2.9063 | Actual Loss: 0.3947\n",
      "Baseline Loss: 2.8335 | Actual Loss: 0.2333\n",
      "Baseline Loss: 2.8496 | Actual Loss: 0.1219\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.1747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 94/1000 [00:30<04:33,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8052 | Actual Loss: 0.2917\n",
      "Baseline Loss: 2.8089 | Actual Loss: 0.2322\n",
      "Baseline Loss: 2.7792 | Actual Loss: 0.2781\n",
      "Baseline Loss: 2.8367 | Actual Loss: 0.1953\n",
      "Baseline Loss: 2.9116 | Actual Loss: 0.1739\n",
      "Baseline Loss: 2.7959 | Actual Loss: 0.2337\n",
      "Baseline Loss: 2.4003 | Actual Loss: 0.3225\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2519\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2399\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3582\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3247\n",
      "Epoch 94/1000: Train Loss: 0.2543, Val Loss: 0.2937\n",
      "New best validation loss: 0.2937\n",
      "Baseline Loss: 2.8773 | Actual Loss: 0.3604\n",
      "Baseline Loss: 2.7592 | Actual Loss: 0.2146\n",
      "Baseline Loss: 2.8294 | Actual Loss: 0.3673\n",
      "Baseline Loss: 2.8734 | Actual Loss: 0.2960\n",
      "Baseline Loss: 2.8710 | Actual Loss: 0.0701\n",
      "Baseline Loss: 2.8976 | Actual Loss: 0.1568\n",
      "Baseline Loss: 2.7875 | Actual Loss: 0.3353\n",
      "Baseline Loss: 2.8051 | Actual Loss: 0.2217\n",
      "Baseline Loss: 2.8337 | Actual Loss: 0.1947\n",
      "Baseline Loss: 2.8417 | Actual Loss: 0.2855\n",
      "Baseline Loss: 2.7905 | Actual Loss: 0.4391\n",
      "Baseline Loss: 2.8246 | Actual Loss: 0.2329\n",
      "Baseline Loss: 2.7732 | Actual Loss: 0.3052\n",
      "Baseline Loss: 2.8663 | Actual Loss: 0.2429\n",
      "Baseline Loss: 2.8476 | Actual Loss: 0.1417\n",
      "Baseline Loss: 2.5769 | Actual Loss: 0.1146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 95/1000 [00:31<04:45,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8702 | Actual Loss: 0.2612\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3393\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2809\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.2969\n",
      "Epoch 95/1000: Train Loss: 0.2487, Val Loss: 0.2946\n",
      "Baseline Loss: 2.8024 | Actual Loss: 0.3892\n",
      "Baseline Loss: 2.8208 | Actual Loss: 0.3423\n",
      "Baseline Loss: 2.8527 | Actual Loss: 0.2919\n",
      "Baseline Loss: 2.8414 | Actual Loss: 0.2921\n",
      "Baseline Loss: 2.9157 | Actual Loss: 0.1351\n",
      "Baseline Loss: 2.8672 | Actual Loss: 0.2456\n",
      "Baseline Loss: 2.7101 | Actual Loss: 0.2513\n",
      "Baseline Loss: 2.7390 | Actual Loss: 0.2084\n",
      "Baseline Loss: 2.8071 | Actual Loss: 0.1806\n",
      "Baseline Loss: 2.7990 | Actual Loss: 0.2783\n",
      "Baseline Loss: 2.8040 | Actual Loss: 0.2595\n",
      "Baseline Loss: 2.8734 | Actual Loss: 0.1744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 96/1000 [00:31<04:53,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7891 | Actual Loss: 0.1806\n",
      "Baseline Loss: 2.8791 | Actual Loss: 0.2914\n",
      "Baseline Loss: 2.8918 | Actual Loss: 0.2230\n",
      "Baseline Loss: 2.5909 | Actual Loss: 0.0910\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3058\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2869\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3019\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.5540\n",
      "Epoch 96/1000: Train Loss: 0.2397, Val Loss: 0.3622\n",
      "Baseline Loss: 2.8100 | Actual Loss: 0.1627\n",
      "Baseline Loss: 2.8607 | Actual Loss: 0.3350\n",
      "Baseline Loss: 2.7703 | Actual Loss: 0.1317\n",
      "Baseline Loss: 2.7922 | Actual Loss: 0.3287\n",
      "Baseline Loss: 2.9353 | Actual Loss: 0.2523\n",
      "Baseline Loss: 2.8717 | Actual Loss: 0.1910\n",
      "Baseline Loss: 2.8314 | Actual Loss: 0.2933\n",
      "Baseline Loss: 2.8149 | Actual Loss: 0.2459\n",
      "Baseline Loss: 2.7769 | Actual Loss: 0.2464\n",
      "Baseline Loss: 2.9086 | Actual Loss: 0.1798\n",
      "Baseline Loss: 2.7756 | Actual Loss: 0.2433\n",
      "Baseline Loss: 2.8438 | Actual Loss: 0.1699\n",
      "Baseline Loss: 2.7652 | Actual Loss: 0.1884\n",
      "Baseline Loss: 2.7905 | Actual Loss: 0.3584\n",
      "Baseline Loss: 2.8711 | Actual Loss: 0.2747\n",
      "Baseline Loss: 2.3874 | Actual Loss: 0.1368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 97/1000 [00:31<04:41,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8702 | Actual Loss: 0.3292\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3149\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.4363\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3710\n",
      "Epoch 97/1000: Train Loss: 0.2336, Val Loss: 0.3629\n",
      "Baseline Loss: 2.8154 | Actual Loss: 0.2535\n",
      "Baseline Loss: 2.9065 | Actual Loss: 0.2239\n",
      "Baseline Loss: 2.8775 | Actual Loss: 0.3654\n",
      "Baseline Loss: 2.8440 | Actual Loss: 0.1642\n",
      "Baseline Loss: 2.8067 | Actual Loss: 0.1603\n",
      "Baseline Loss: 2.8581 | Actual Loss: 0.3003\n",
      "Baseline Loss: 2.8403 | Actual Loss: 0.2051\n",
      "Baseline Loss: 2.7824 | Actual Loss: 0.2187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 98/1000 [00:32<04:51,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8464 | Actual Loss: 0.1514\n",
      "Baseline Loss: 2.8507 | Actual Loss: 0.2407\n",
      "Baseline Loss: 2.8845 | Actual Loss: 0.2317\n",
      "Baseline Loss: 2.8076 | Actual Loss: 0.1731\n",
      "Baseline Loss: 2.8434 | Actual Loss: 0.3007\n",
      "Baseline Loss: 2.7939 | Actual Loss: 0.2562\n",
      "Baseline Loss: 2.8751 | Actual Loss: 0.2294\n",
      "Baseline Loss: 2.4416 | Actual Loss: 0.1557\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2790\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3733\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2687\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.6124\n",
      "Epoch 98/1000: Train Loss: 0.2269, Val Loss: 0.3833\n",
      "Baseline Loss: 2.8370 | Actual Loss: 0.1406\n",
      "Baseline Loss: 2.7749 | Actual Loss: 0.1776\n",
      "Baseline Loss: 2.8788 | Actual Loss: 0.5967\n",
      "Baseline Loss: 2.7926 | Actual Loss: 0.1302\n",
      "Baseline Loss: 2.7747 | Actual Loss: 0.1370\n",
      "Baseline Loss: 2.8208 | Actual Loss: 0.0724\n",
      "Baseline Loss: 2.8648 | Actual Loss: 0.3305\n",
      "Baseline Loss: 2.8090 | Actual Loss: 0.3598\n",
      "Baseline Loss: 2.7865 | Actual Loss: 0.1466\n",
      "Baseline Loss: 2.8134 | Actual Loss: 0.2789\n",
      "Baseline Loss: 2.8956 | Actual Loss: 0.4207\n",
      "Baseline Loss: 2.8138 | Actual Loss: 0.3175\n",
      "Baseline Loss: 2.8545 | Actual Loss: 0.2918\n",
      "Baseline Loss: 2.8711 | Actual Loss: 0.3430\n",
      "Baseline Loss: 2.8218 | Actual Loss: 0.3107\n",
      "Baseline Loss: 2.6449 | Actual Loss: 0.1822\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2652\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.4095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 99/1000 [00:32<04:57,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7737 | Actual Loss: 0.2587\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3533\n",
      "Epoch 99/1000: Train Loss: 0.2648, Val Loss: 0.3217\n",
      "Baseline Loss: 2.8425 | Actual Loss: 0.2167\n",
      "Baseline Loss: 2.8728 | Actual Loss: 0.2057\n",
      "Baseline Loss: 2.7819 | Actual Loss: 0.1117\n",
      "Baseline Loss: 2.8601 | Actual Loss: 0.1853\n",
      "Baseline Loss: 2.8716 | Actual Loss: 0.2433\n",
      "Baseline Loss: 2.7675 | Actual Loss: 0.4680\n",
      "Baseline Loss: 2.8513 | Actual Loss: 0.2337\n",
      "Baseline Loss: 2.8437 | Actual Loss: 0.1651\n",
      "Baseline Loss: 2.7724 | Actual Loss: 0.1603\n",
      "Baseline Loss: 2.8392 | Actual Loss: 0.1270\n",
      "Baseline Loss: 2.8635 | Actual Loss: 0.3679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 100/1000 [00:32<04:47,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8300 | Actual Loss: 0.2202\n",
      "Baseline Loss: 2.8929 | Actual Loss: 0.0742\n",
      "Baseline Loss: 2.8223 | Actual Loss: 0.1724\n",
      "Baseline Loss: 2.8148 | Actual Loss: 0.3232\n",
      "Baseline Loss: 2.5427 | Actual Loss: 0.1377\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3275\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3735\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2498\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.5270\n",
      "Epoch 100/1000: Train Loss: 0.2133, Val Loss: 0.3694\n",
      "Baseline Loss: 2.8633 | Actual Loss: 0.3698\n",
      "Baseline Loss: 2.7347 | Actual Loss: 0.2205\n",
      "Baseline Loss: 2.7889 | Actual Loss: 0.1983\n",
      "Baseline Loss: 2.7807 | Actual Loss: 0.3662\n",
      "Baseline Loss: 2.7649 | Actual Loss: 0.1904\n",
      "Baseline Loss: 2.9047 | Actual Loss: 0.2588\n",
      "Baseline Loss: 2.8144 | Actual Loss: 0.2480\n",
      "Baseline Loss: 2.8579 | Actual Loss: 0.2573\n",
      "Baseline Loss: 2.8620 | Actual Loss: 0.2714\n",
      "Baseline Loss: 2.9205 | Actual Loss: 0.2138\n",
      "Baseline Loss: 2.8194 | Actual Loss: 0.2542\n",
      "Baseline Loss: 2.8716 | Actual Loss: 0.1625\n",
      "Baseline Loss: 2.8026 | Actual Loss: 0.2217\n",
      "Baseline Loss: 2.8628 | Actual Loss: 0.2868\n",
      "Baseline Loss: 2.7458 | Actual Loss: 0.2334\n",
      "Baseline Loss: 2.4910 | Actual Loss: 0.1048\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 101/1000 [00:33<04:52,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8345 | Actual Loss: 0.2848\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3498\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3452\n",
      "Epoch 101/1000: Train Loss: 0.2411, Val Loss: 0.3107\n",
      "Baseline Loss: 2.8510 | Actual Loss: 0.2728\n",
      "Baseline Loss: 2.8279 | Actual Loss: 0.1499\n",
      "Baseline Loss: 2.8584 | Actual Loss: 0.1435\n",
      "Baseline Loss: 2.8612 | Actual Loss: 0.2348\n",
      "Baseline Loss: 2.7555 | Actual Loss: 0.2700\n",
      "Baseline Loss: 2.7545 | Actual Loss: 0.2693\n",
      "Baseline Loss: 2.8555 | Actual Loss: 0.3131\n",
      "Baseline Loss: 2.8912 | Actual Loss: 0.2478\n",
      "Baseline Loss: 2.8015 | Actual Loss: 0.3025\n",
      "Baseline Loss: 2.8171 | Actual Loss: 0.3109\n",
      "Baseline Loss: 2.8512 | Actual Loss: 0.1932\n",
      "Baseline Loss: 2.8658 | Actual Loss: 0.3131\n",
      "Baseline Loss: 2.8941 | Actual Loss: 0.3142\n",
      "Baseline Loss: 2.8158 | Actual Loss: 0.1823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 102/1000 [00:33<04:32,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8243 | Actual Loss: 0.1902\n",
      "Baseline Loss: 2.5288 | Actual Loss: 0.1252\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2699\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2600\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.4358\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3325\n",
      "Epoch 102/1000: Train Loss: 0.2396, Val Loss: 0.3245\n",
      "Baseline Loss: 2.7735 | Actual Loss: 0.1509\n",
      "Baseline Loss: 2.7491 | Actual Loss: 0.2112\n",
      "Baseline Loss: 2.7971 | Actual Loss: 0.3199\n",
      "Baseline Loss: 2.8558 | Actual Loss: 0.2464\n",
      "Baseline Loss: 2.8211 | Actual Loss: 0.2873\n",
      "Baseline Loss: 2.8651 | Actual Loss: 0.2050\n",
      "Baseline Loss: 2.8422 | Actual Loss: 0.4094\n",
      "Baseline Loss: 2.8512 | Actual Loss: 0.3821\n",
      "Baseline Loss: 2.8246 | Actual Loss: 0.3018\n",
      "Baseline Loss: 2.8441 | Actual Loss: 0.1949\n",
      "Baseline Loss: 2.8249 | Actual Loss: 0.2537\n",
      "Baseline Loss: 2.7893 | Actual Loss: 0.3495\n",
      "Baseline Loss: 2.9785 | Actual Loss: 0.1625\n",
      "Baseline Loss: 2.8253 | Actual Loss: 0.3765\n",
      "Baseline Loss: 2.8589 | Actual Loss: 0.1617\n",
      "Baseline Loss: 2.6031 | Actual Loss: 0.1626\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3483\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3274\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 103/1000 [00:33<04:45,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7548 | Actual Loss: 0.3834\n",
      "Epoch 103/1000: Train Loss: 0.2610, Val Loss: 0.3335\n",
      "Baseline Loss: 2.8185 | Actual Loss: 0.2121\n",
      "Baseline Loss: 2.7864 | Actual Loss: 0.1451\n",
      "Baseline Loss: 2.7875 | Actual Loss: 0.1943\n",
      "Baseline Loss: 2.8668 | Actual Loss: 0.1739\n",
      "Baseline Loss: 2.7677 | Actual Loss: 0.1660\n",
      "Baseline Loss: 2.8563 | Actual Loss: 0.1541\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2685\n",
      "Baseline Loss: 2.8675 | Actual Loss: 0.2426\n",
      "Baseline Loss: 2.7732 | Actual Loss: 0.2872\n",
      "Baseline Loss: 2.8039 | Actual Loss: 0.1645\n",
      "Baseline Loss: 2.8537 | Actual Loss: 0.2064\n",
      "Baseline Loss: 2.8376 | Actual Loss: 0.1608\n",
      "Baseline Loss: 2.8423 | Actual Loss: 0.2115\n",
      "Baseline Loss: 2.8172 | Actual Loss: 0.1733\n",
      "Baseline Loss: 2.8733 | Actual Loss: 0.2587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 104/1000 [00:33<04:29,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6266 | Actual Loss: 0.2232\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3199\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2410\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3573\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3783\n",
      "Epoch 104/1000: Train Loss: 0.2026, Val Loss: 0.3241\n",
      "Baseline Loss: 2.8302 | Actual Loss: 0.2326\n",
      "Baseline Loss: 2.8179 | Actual Loss: 0.1683\n",
      "Baseline Loss: 2.8651 | Actual Loss: 0.1545\n",
      "Baseline Loss: 2.8608 | Actual Loss: 0.2690\n",
      "Baseline Loss: 2.8362 | Actual Loss: 0.2104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 105/1000 [00:34<04:41,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7752 | Actual Loss: 0.3503\n",
      "Baseline Loss: 2.8885 | Actual Loss: 0.2939\n",
      "Baseline Loss: 2.8563 | Actual Loss: 0.2198\n",
      "Baseline Loss: 2.8555 | Actual Loss: 0.5399\n",
      "Baseline Loss: 2.7937 | Actual Loss: 0.1846\n",
      "Baseline Loss: 2.8160 | Actual Loss: 0.1812\n",
      "Baseline Loss: 2.7970 | Actual Loss: 0.2587\n",
      "Baseline Loss: 2.8109 | Actual Loss: 0.5165\n",
      "Baseline Loss: 2.8472 | Actual Loss: 0.2398\n",
      "Baseline Loss: 2.8738 | Actual Loss: 0.2080\n",
      "Baseline Loss: 2.5247 | Actual Loss: 0.0354\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3968\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3427\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3173\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3896\n",
      "Epoch 105/1000: Train Loss: 0.2539, Val Loss: 0.3616\n",
      "Baseline Loss: 2.7813 | Actual Loss: 0.2172\n",
      "Baseline Loss: 2.7536 | Actual Loss: 0.1419\n",
      "Baseline Loss: 2.8590 | Actual Loss: 0.2372\n",
      "Baseline Loss: 2.8641 | Actual Loss: 0.5002\n",
      "Baseline Loss: 2.9538 | Actual Loss: 0.2305\n",
      "Baseline Loss: 2.8451 | Actual Loss: 0.2075\n",
      "Baseline Loss: 2.8234 | Actual Loss: 0.2452\n",
      "Baseline Loss: 2.8929 | Actual Loss: 0.2402\n",
      "Baseline Loss: 2.8333 | Actual Loss: 0.1668\n",
      "Baseline Loss: 2.8231 | Actual Loss: 0.2795\n",
      "Baseline Loss: 2.8275 | Actual Loss: 0.2297\n",
      "Baseline Loss: 2.7918 | Actual Loss: 0.2845\n",
      "Baseline Loss: 2.8350 | Actual Loss: 0.1594\n",
      "Baseline Loss: 2.7731 | Actual Loss: 0.2279\n",
      "Baseline Loss: 2.8500 | Actual Loss: 0.2306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 106/1000 [00:34<04:53,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6563 | Actual Loss: 0.0819\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.4148\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3259\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3783\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3366\n",
      "Epoch 106/1000: Train Loss: 0.2300, Val Loss: 0.3639\n",
      "Baseline Loss: 2.8650 | Actual Loss: 0.1429\n",
      "Baseline Loss: 2.8256 | Actual Loss: 0.2681\n",
      "Baseline Loss: 2.8338 | Actual Loss: 0.3733\n",
      "Baseline Loss: 2.8776 | Actual Loss: 0.1468\n",
      "Baseline Loss: 2.7211 | Actual Loss: 0.2163\n",
      "Baseline Loss: 2.7732 | Actual Loss: 0.2076\n",
      "Baseline Loss: 2.8349 | Actual Loss: 0.1731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 107/1000 [00:34<04:33,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8216 | Actual Loss: 0.1707\n",
      "Baseline Loss: 2.8589 | Actual Loss: 0.1965\n",
      "Baseline Loss: 2.8340 | Actual Loss: 0.2688\n",
      "Baseline Loss: 2.8065 | Actual Loss: 0.1275\n",
      "Baseline Loss: 2.8649 | Actual Loss: 0.2885\n",
      "Baseline Loss: 2.8731 | Actual Loss: 0.0688\n",
      "Baseline Loss: 2.7830 | Actual Loss: 0.4039\n",
      "Baseline Loss: 2.8312 | Actual Loss: 0.3130\n",
      "Baseline Loss: 2.5729 | Actual Loss: 0.1274\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2590\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3122\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2166\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.5690\n",
      "Epoch 107/1000: Train Loss: 0.2183, Val Loss: 0.3392\n",
      "Baseline Loss: 2.7526 | Actual Loss: 0.2325\n",
      "Baseline Loss: 2.7873 | Actual Loss: 0.2073\n",
      "Baseline Loss: 2.8470 | Actual Loss: 0.1072\n",
      "Baseline Loss: 2.8776 | Actual Loss: 0.2761\n",
      "Baseline Loss: 2.8760 | Actual Loss: 0.1893\n",
      "Baseline Loss: 2.8155 | Actual Loss: 0.2053\n",
      "Baseline Loss: 2.8476 | Actual Loss: 0.2174\n",
      "Baseline Loss: 2.8349 | Actual Loss: 0.1402\n",
      "Baseline Loss: 2.8145 | Actual Loss: 0.3752\n",
      "Baseline Loss: 2.8075 | Actual Loss: 0.0867\n",
      "Baseline Loss: 2.8110 | Actual Loss: 0.3686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 108/1000 [00:35<04:42,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7976 | Actual Loss: 0.1705\n",
      "Baseline Loss: 2.8780 | Actual Loss: 0.1155\n",
      "Baseline Loss: 2.8875 | Actual Loss: 0.2480\n",
      "Baseline Loss: 2.7487 | Actual Loss: 0.1826\n",
      "Baseline Loss: 2.6057 | Actual Loss: 0.2291\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3717\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3502\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2738\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3771\n",
      "Epoch 108/1000: Train Loss: 0.2095, Val Loss: 0.3432\n",
      "Baseline Loss: 2.8839 | Actual Loss: 0.0738\n",
      "Baseline Loss: 2.8644 | Actual Loss: 0.1712\n",
      "Baseline Loss: 2.8363 | Actual Loss: 0.3522\n",
      "Baseline Loss: 2.7488 | Actual Loss: 0.1707\n",
      "Baseline Loss: 2.8375 | Actual Loss: 0.3406\n",
      "Baseline Loss: 2.8507 | Actual Loss: 0.2479\n",
      "Baseline Loss: 2.8519 | Actual Loss: 0.2601\n",
      "Baseline Loss: 2.7649 | Actual Loss: 0.1531\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 109/1000 [00:35<04:27,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8301 | Actual Loss: 0.2671\n",
      "Baseline Loss: 2.9236 | Actual Loss: 0.1933\n",
      "Baseline Loss: 2.7910 | Actual Loss: 0.1871\n",
      "Baseline Loss: 2.8519 | Actual Loss: 0.2179\n",
      "Baseline Loss: 2.8311 | Actual Loss: 0.2981\n",
      "Baseline Loss: 2.8177 | Actual Loss: 0.1082\n",
      "Baseline Loss: 2.5268 | Actual Loss: 0.1695\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.4316\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3707\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3159\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3937\n",
      "Epoch 109/1000: Train Loss: 0.2142, Val Loss: 0.3780\n",
      "Baseline Loss: 2.8455 | Actual Loss: 0.2139\n",
      "Baseline Loss: 2.8308 | Actual Loss: 0.3224\n",
      "Baseline Loss: 2.7817 | Actual Loss: 0.1790\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.1622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 110/1000 [00:35<04:40,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8141 | Actual Loss: 0.1590\n",
      "Baseline Loss: 2.8656 | Actual Loss: 0.2657\n",
      "Baseline Loss: 2.8223 | Actual Loss: 0.1865\n",
      "Baseline Loss: 2.8125 | Actual Loss: 0.2214\n",
      "Baseline Loss: 2.8118 | Actual Loss: 0.2378\n",
      "Baseline Loss: 2.8888 | Actual Loss: 0.3521\n",
      "Baseline Loss: 2.8208 | Actual Loss: 0.1745\n",
      "Baseline Loss: 2.8751 | Actual Loss: 0.5724\n",
      "Baseline Loss: 2.8236 | Actual Loss: 0.2720\n",
      "Baseline Loss: 2.8129 | Actual Loss: 0.3653\n",
      "Baseline Loss: 2.8649 | Actual Loss: 0.2792\n",
      "Baseline Loss: 2.4831 | Actual Loss: 0.1193\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3092\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2679\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3226\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.4189\n",
      "Epoch 110/1000: Train Loss: 0.2552, Val Loss: 0.3297\n",
      "Baseline Loss: 2.7619 | Actual Loss: 0.1448\n",
      "Baseline Loss: 2.8080 | Actual Loss: 0.2688\n",
      "Baseline Loss: 2.8041 | Actual Loss: 0.1904\n",
      "Baseline Loss: 2.7955 | Actual Loss: 0.1114\n",
      "Baseline Loss: 2.9329 | Actual Loss: 0.2058\n",
      "Baseline Loss: 2.8959 | Actual Loss: 0.2839\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.1762\n",
      "Baseline Loss: 2.8428 | Actual Loss: 0.2684\n",
      "Baseline Loss: 2.8137 | Actual Loss: 0.3222\n",
      "Baseline Loss: 2.7824 | Actual Loss: 0.1710\n",
      "Baseline Loss: 2.8660 | Actual Loss: 0.2049\n",
      "Baseline Loss: 2.8516 | Actual Loss: 0.2652\n",
      "Baseline Loss: 2.8748 | Actual Loss: 0.2426\n",
      "Baseline Loss: 2.8284 | Actual Loss: 0.1817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 111/1000 [00:36<04:51,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7879 | Actual Loss: 0.1442\n",
      "Baseline Loss: 2.5499 | Actual Loss: 0.0707\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2761\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2650\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2854\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3953\n",
      "Epoch 111/1000: Train Loss: 0.2033, Val Loss: 0.3054\n",
      "Baseline Loss: 2.8605 | Actual Loss: 0.3798\n",
      "Baseline Loss: 2.7795 | Actual Loss: 0.2518\n",
      "Baseline Loss: 2.7333 | Actual Loss: 0.2906\n",
      "Baseline Loss: 2.8290 | Actual Loss: 0.2311\n",
      "Baseline Loss: 2.8194 | Actual Loss: 0.1586\n",
      "Baseline Loss: 2.8261 | Actual Loss: 0.3213\n",
      "Baseline Loss: 2.7994 | Actual Loss: 0.2123\n",
      "Baseline Loss: 2.8426 | Actual Loss: 0.3178\n",
      "Baseline Loss: 2.8579 | Actual Loss: 0.4438\n",
      "Baseline Loss: 2.8200 | Actual Loss: 0.2018\n",
      "Baseline Loss: 2.8568 | Actual Loss: 0.3558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 112/1000 [00:36<04:33,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8279 | Actual Loss: 0.1576\n",
      "Baseline Loss: 2.7894 | Actual Loss: 0.1824\n",
      "Baseline Loss: 2.8088 | Actual Loss: 0.1615\n",
      "Baseline Loss: 2.8205 | Actual Loss: 0.1607\n",
      "Baseline Loss: 2.5344 | Actual Loss: 0.0902\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2902\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3474\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3071\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.4156\n",
      "Epoch 112/1000: Train Loss: 0.2448, Val Loss: 0.3401\n",
      "Baseline Loss: 2.8451 | Actual Loss: 0.1534\n",
      "Baseline Loss: 2.7926 | Actual Loss: 0.2379\n",
      "Baseline Loss: 2.8493 | Actual Loss: 0.1137\n",
      "Baseline Loss: 2.8043 | Actual Loss: 0.2761\n",
      "Baseline Loss: 2.9061 | Actual Loss: 0.2556\n",
      "Baseline Loss: 2.8249 | Actual Loss: 0.2366\n",
      "Baseline Loss: 2.7968 | Actual Loss: 0.0956\n",
      "Baseline Loss: 2.8354 | Actual Loss: 0.0846\n",
      "Baseline Loss: 2.8364 | Actual Loss: 0.2789\n",
      "Baseline Loss: 2.7803 | Actual Loss: 0.2368\n",
      "Baseline Loss: 2.7669 | Actual Loss: 0.2100\n",
      "Baseline Loss: 2.8273 | Actual Loss: 0.2146\n",
      "Baseline Loss: 2.8216 | Actual Loss: 0.1309\n",
      "Baseline Loss: 2.7848 | Actual Loss: 0.6174\n",
      "Baseline Loss: 2.8804 | Actual Loss: 0.2805\n",
      "Baseline Loss: 2.5653 | Actual Loss: 0.1015\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3152\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3025\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█▏        | 113/1000 [00:36<04:49,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7548 | Actual Loss: 0.3018\n",
      "Epoch 113/1000: Train Loss: 0.2203, Val Loss: 0.3067\n",
      "Baseline Loss: 2.8050 | Actual Loss: 0.3184\n",
      "Baseline Loss: 2.8478 | Actual Loss: 0.2794\n",
      "Baseline Loss: 2.7925 | Actual Loss: 0.2391\n",
      "Baseline Loss: 2.7940 | Actual Loss: 0.3227\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.1830\n",
      "Baseline Loss: 2.8243 | Actual Loss: 0.2560\n",
      "Baseline Loss: 2.8487 | Actual Loss: 0.1987\n",
      "Baseline Loss: 2.7866 | Actual Loss: 0.2250\n",
      "Baseline Loss: 2.8439 | Actual Loss: 0.2118\n",
      "Baseline Loss: 2.8526 | Actual Loss: 0.1452\n",
      "Baseline Loss: 2.8496 | Actual Loss: 0.3287\n",
      "Baseline Loss: 2.8114 | Actual Loss: 0.1604\n",
      "Baseline Loss: 2.8897 | Actual Loss: 0.1503\n",
      "Baseline Loss: 2.9108 | Actual Loss: 0.2271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█▏        | 114/1000 [00:37<04:52,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7608 | Actual Loss: 0.2539\n",
      "Baseline Loss: 2.5421 | Actual Loss: 0.3766\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.4548\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3278\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3954\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3696\n",
      "Epoch 114/1000: Train Loss: 0.2423, Val Loss: 0.3869\n",
      "Baseline Loss: 2.7759 | Actual Loss: 0.1725\n",
      "Baseline Loss: 2.8918 | Actual Loss: 0.1932\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2926\n",
      "Baseline Loss: 2.8432 | Actual Loss: 0.2987\n",
      "Baseline Loss: 2.8228 | Actual Loss: 0.1208\n",
      "Baseline Loss: 2.8849 | Actual Loss: 0.2443\n",
      "Baseline Loss: 2.8677 | Actual Loss: 0.1042\n",
      "Baseline Loss: 2.7932 | Actual Loss: 0.2215\n",
      "Baseline Loss: 2.7752 | Actual Loss: 0.2142\n",
      "Baseline Loss: 2.8758 | Actual Loss: 0.2389\n",
      "Baseline Loss: 2.8030 | Actual Loss: 0.2890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 115/1000 [00:37<04:38,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9442 | Actual Loss: 0.2395\n",
      "Baseline Loss: 2.8547 | Actual Loss: 0.1594\n",
      "Baseline Loss: 2.8807 | Actual Loss: 0.1278\n",
      "Baseline Loss: 2.9030 | Actual Loss: 0.4158\n",
      "Baseline Loss: 2.4613 | Actual Loss: 0.2709\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3296\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3100\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2500\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3958\n",
      "Epoch 115/1000: Train Loss: 0.2252, Val Loss: 0.3214\n",
      "Baseline Loss: 2.9388 | Actual Loss: 0.1581\n",
      "Baseline Loss: 2.8596 | Actual Loss: 0.3018\n",
      "Baseline Loss: 2.8461 | Actual Loss: 0.2751\n",
      "Baseline Loss: 2.8211 | Actual Loss: 0.2462\n",
      "Baseline Loss: 2.8086 | Actual Loss: 0.2754\n",
      "Baseline Loss: 2.7728 | Actual Loss: 0.1693\n",
      "Baseline Loss: 2.7859 | Actual Loss: 0.2050\n",
      "Baseline Loss: 2.8614 | Actual Loss: 0.2856\n",
      "Baseline Loss: 2.8195 | Actual Loss: 0.2275\n",
      "Baseline Loss: 2.8813 | Actual Loss: 0.2042\n",
      "Baseline Loss: 2.8570 | Actual Loss: 0.3012\n",
      "Baseline Loss: 2.8730 | Actual Loss: 0.3069\n",
      "Baseline Loss: 2.7869 | Actual Loss: 0.2307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 116/1000 [00:37<04:48,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8349 | Actual Loss: 0.2164\n",
      "Baseline Loss: 2.8236 | Actual Loss: 0.3191\n",
      "Baseline Loss: 2.6076 | Actual Loss: 0.0673\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2406\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3184\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3347\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3722\n",
      "Epoch 116/1000: Train Loss: 0.2369, Val Loss: 0.3165\n",
      "Baseline Loss: 2.8559 | Actual Loss: 0.3079\n",
      "Baseline Loss: 2.8898 | Actual Loss: 0.2704\n",
      "Baseline Loss: 2.8219 | Actual Loss: 0.1808\n",
      "Baseline Loss: 2.8133 | Actual Loss: 0.1282\n",
      "Baseline Loss: 2.8399 | Actual Loss: 0.1671\n",
      "Baseline Loss: 2.8007 | Actual Loss: 0.1539\n",
      "Baseline Loss: 2.8660 | Actual Loss: 0.3407\n",
      "Baseline Loss: 2.7261 | Actual Loss: 0.1985\n",
      "Baseline Loss: 2.8417 | Actual Loss: 0.2036\n",
      "Baseline Loss: 2.8308 | Actual Loss: 0.2591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 117/1000 [00:38<04:33,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8651 | Actual Loss: 0.3265\n",
      "Baseline Loss: 2.7961 | Actual Loss: 0.2471\n",
      "Baseline Loss: 2.8081 | Actual Loss: 0.1450\n",
      "Baseline Loss: 2.8954 | Actual Loss: 0.2237\n",
      "Baseline Loss: 2.7880 | Actual Loss: 0.1369\n",
      "Baseline Loss: 2.5643 | Actual Loss: 0.4168\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3295\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2658\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2810\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.5230\n",
      "Epoch 117/1000: Train Loss: 0.2316, Val Loss: 0.3498\n",
      "Baseline Loss: 2.8928 | Actual Loss: 0.1156\n",
      "Baseline Loss: 2.8496 | Actual Loss: 0.1036\n",
      "Baseline Loss: 2.8478 | Actual Loss: 0.1825\n",
      "Baseline Loss: 2.9019 | Actual Loss: 0.2319\n",
      "Baseline Loss: 2.8742 | Actual Loss: 0.1531\n",
      "Baseline Loss: 2.8095 | Actual Loss: 0.2834\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.1764\n",
      "Baseline Loss: 2.8504 | Actual Loss: 0.2463\n",
      "Baseline Loss: 2.8312 | Actual Loss: 0.1668\n",
      "Baseline Loss: 2.7441 | Actual Loss: 0.2309\n",
      "Baseline Loss: 2.8034 | Actual Loss: 0.3463\n",
      "Baseline Loss: 2.8487 | Actual Loss: 0.2568\n",
      "Baseline Loss: 2.8292 | Actual Loss: 0.2407\n",
      "Baseline Loss: 2.8346 | Actual Loss: 0.1774\n",
      "Baseline Loss: 2.7830 | Actual Loss: 0.1903\n",
      "Baseline Loss: 2.4510 | Actual Loss: 0.1777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 118/1000 [00:38<04:41,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8702 | Actual Loss: 0.3008\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2693\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3548\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.2448\n",
      "Epoch 118/1000: Train Loss: 0.2050, Val Loss: 0.2924\n",
      "New best validation loss: 0.2924\n",
      "Baseline Loss: 2.7793 | Actual Loss: 0.1444\n",
      "Baseline Loss: 2.7961 | Actual Loss: 0.1933\n",
      "Baseline Loss: 2.9336 | Actual Loss: 0.3312\n",
      "Baseline Loss: 2.8478 | Actual Loss: 0.1971\n",
      "Baseline Loss: 2.7716 | Actual Loss: 0.2018\n",
      "Baseline Loss: 2.8561 | Actual Loss: 0.3930\n",
      "Baseline Loss: 2.7839 | Actual Loss: 0.1225\n",
      "Baseline Loss: 2.9090 | Actual Loss: 0.2552\n",
      "Baseline Loss: 2.8357 | Actual Loss: 0.1964\n",
      "Baseline Loss: 2.8474 | Actual Loss: 0.2579\n",
      "Baseline Loss: 2.8851 | Actual Loss: 0.2282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 119/1000 [00:38<04:31,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7602 | Actual Loss: 0.2203\n",
      "Baseline Loss: 2.8129 | Actual Loss: 0.2988\n",
      "Baseline Loss: 2.8125 | Actual Loss: 0.1895\n",
      "Baseline Loss: 2.8373 | Actual Loss: 0.2037\n",
      "Baseline Loss: 2.5306 | Actual Loss: 0.2539\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2062\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2523\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3271\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3078\n",
      "Epoch 119/1000: Train Loss: 0.2304, Val Loss: 0.2734\n",
      "New best validation loss: 0.2734\n",
      "Baseline Loss: 2.8550 | Actual Loss: 0.1905\n",
      "Baseline Loss: 2.8854 | Actual Loss: 0.1124\n",
      "Baseline Loss: 2.7866 | Actual Loss: 0.1943\n",
      "Baseline Loss: 2.7863 | Actual Loss: 0.2213\n",
      "Baseline Loss: 2.8224 | Actual Loss: 0.2687\n",
      "Baseline Loss: 2.8016 | Actual Loss: 0.3114\n",
      "Baseline Loss: 2.8797 | Actual Loss: 0.1608\n",
      "Baseline Loss: 2.7818 | Actual Loss: 0.1589\n",
      "Baseline Loss: 2.8405 | Actual Loss: 0.2199\n",
      "Baseline Loss: 2.9197 | Actual Loss: 0.2500\n",
      "Baseline Loss: 2.8705 | Actual Loss: 0.1814\n",
      "Baseline Loss: 2.8683 | Actual Loss: 0.3063\n",
      "Baseline Loss: 2.8301 | Actual Loss: 0.2380\n",
      "Baseline Loss: 2.8016 | Actual Loss: 0.1737\n",
      "Baseline Loss: 2.7370 | Actual Loss: 0.1764\n",
      "Baseline Loss: 2.5221 | Actual Loss: 0.3692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 120/1000 [00:39<04:44,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8702 | Actual Loss: 0.2307\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2795\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3132\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3368\n",
      "Epoch 120/1000: Train Loss: 0.2208, Val Loss: 0.2901\n",
      "Baseline Loss: 2.9024 | Actual Loss: 0.1928\n",
      "Baseline Loss: 2.8151 | Actual Loss: 0.1612\n",
      "Baseline Loss: 2.8605 | Actual Loss: 0.1703\n",
      "Baseline Loss: 2.8375 | Actual Loss: 0.1600\n",
      "Baseline Loss: 2.7481 | Actual Loss: 0.1943\n",
      "Baseline Loss: 2.8051 | Actual Loss: 0.1986\n",
      "Baseline Loss: 2.8519 | Actual Loss: 0.1930\n",
      "Baseline Loss: 2.8129 | Actual Loss: 0.2783\n",
      "Baseline Loss: 2.8267 | Actual Loss: 0.2338\n",
      "Baseline Loss: 2.9033 | Actual Loss: 0.2669\n",
      "Baseline Loss: 2.7811 | Actual Loss: 0.1371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 121/1000 [00:39<04:52,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7829 | Actual Loss: 0.1661\n",
      "Baseline Loss: 2.7975 | Actual Loss: 0.2564\n",
      "Baseline Loss: 2.8282 | Actual Loss: 0.3181\n",
      "Baseline Loss: 2.8100 | Actual Loss: 0.2472\n",
      "Baseline Loss: 2.6479 | Actual Loss: 0.1404\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3137\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3137\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2525\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3140\n",
      "Epoch 121/1000: Train Loss: 0.2072, Val Loss: 0.2985\n",
      "Baseline Loss: 2.8594 | Actual Loss: 0.3073\n",
      "Baseline Loss: 2.7599 | Actual Loss: 0.2958\n",
      "Baseline Loss: 2.9092 | Actual Loss: 0.1567\n",
      "Baseline Loss: 2.7905 | Actual Loss: 0.0863\n",
      "Baseline Loss: 2.8192 | Actual Loss: 0.2114\n",
      "Baseline Loss: 2.8615 | Actual Loss: 0.2937\n",
      "Baseline Loss: 2.8358 | Actual Loss: 0.4241\n",
      "Baseline Loss: 2.8555 | Actual Loss: 0.1941\n",
      "Baseline Loss: 2.8539 | Actual Loss: 0.1281\n",
      "Baseline Loss: 2.8119 | Actual Loss: 0.2471\n",
      "Baseline Loss: 2.8668 | Actual Loss: 0.1122\n",
      "Baseline Loss: 2.8038 | Actual Loss: 0.1185\n",
      "Baseline Loss: 2.7631 | Actual Loss: 0.1866\n",
      "Baseline Loss: 2.7870 | Actual Loss: 0.1102\n",
      "Baseline Loss: 2.9059 | Actual Loss: 0.3210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 122/1000 [00:39<04:37,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5080 | Actual Loss: 0.6077\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2923\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3614\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.4177\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.4617\n",
      "Epoch 122/1000: Train Loss: 0.2376, Val Loss: 0.3833\n",
      "Baseline Loss: 2.7979 | Actual Loss: 0.2081\n",
      "Baseline Loss: 2.8354 | Actual Loss: 0.1483\n",
      "Baseline Loss: 2.8046 | Actual Loss: 0.2536\n",
      "Baseline Loss: 2.8710 | Actual Loss: 0.2977\n",
      "Baseline Loss: 2.9181 | Actual Loss: 0.1308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 123/1000 [00:40<04:46,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8366 | Actual Loss: 0.3395\n",
      "Baseline Loss: 2.8020 | Actual Loss: 0.1278\n",
      "Baseline Loss: 2.8043 | Actual Loss: 0.2541\n",
      "Baseline Loss: 2.8339 | Actual Loss: 0.2856\n",
      "Baseline Loss: 2.8325 | Actual Loss: 0.1555\n",
      "Baseline Loss: 2.7923 | Actual Loss: 0.2459\n",
      "Baseline Loss: 2.8026 | Actual Loss: 0.1962\n",
      "Baseline Loss: 2.8385 | Actual Loss: 0.2813\n",
      "Baseline Loss: 2.7978 | Actual Loss: 0.2019\n",
      "Baseline Loss: 2.8378 | Actual Loss: 0.1317\n",
      "Baseline Loss: 2.4849 | Actual Loss: 0.0751\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3151\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3192\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3312\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.4458\n",
      "Epoch 123/1000: Train Loss: 0.2083, Val Loss: 0.3528\n",
      "Baseline Loss: 2.8699 | Actual Loss: 0.1826\n",
      "Baseline Loss: 2.8785 | Actual Loss: 0.1465\n",
      "Baseline Loss: 2.7926 | Actual Loss: 0.1935\n",
      "Baseline Loss: 2.8157 | Actual Loss: 0.3077\n",
      "Baseline Loss: 2.7817 | Actual Loss: 0.1388\n",
      "Baseline Loss: 2.8771 | Actual Loss: 0.1714\n",
      "Baseline Loss: 2.8766 | Actual Loss: 0.2103\n",
      "Baseline Loss: 2.8394 | Actual Loss: 0.1065\n",
      "Baseline Loss: 2.8190 | Actual Loss: 0.4795\n",
      "Baseline Loss: 2.8491 | Actual Loss: 0.2537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 124/1000 [00:40<04:50,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7832 | Actual Loss: 0.1915\n",
      "Baseline Loss: 2.8231 | Actual Loss: 0.2387\n",
      "Baseline Loss: 2.8222 | Actual Loss: 0.1346\n",
      "Baseline Loss: 2.8294 | Actual Loss: 0.1876\n",
      "Baseline Loss: 2.8006 | Actual Loss: 0.4332\n",
      "Baseline Loss: 2.4953 | Actual Loss: 0.1465\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2849\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2621\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3100\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3762\n",
      "Epoch 124/1000: Train Loss: 0.2202, Val Loss: 0.3083\n",
      "Baseline Loss: 2.7632 | Actual Loss: 0.1267\n",
      "Baseline Loss: 2.8659 | Actual Loss: 0.1849\n",
      "Baseline Loss: 2.7643 | Actual Loss: 0.1230\n",
      "Baseline Loss: 2.8125 | Actual Loss: 0.1857\n",
      "Baseline Loss: 2.7944 | Actual Loss: 0.2345\n",
      "Baseline Loss: 2.8146 | Actual Loss: 0.2548\n",
      "Baseline Loss: 2.8523 | Actual Loss: 0.1460\n",
      "Baseline Loss: 2.8972 | Actual Loss: 0.1290\n",
      "Baseline Loss: 2.9066 | Actual Loss: 0.2257\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.3263\n",
      "Baseline Loss: 2.8320 | Actual Loss: 0.2319\n",
      "Baseline Loss: 2.9136 | Actual Loss: 0.2531\n",
      "Baseline Loss: 2.8492 | Actual Loss: 0.1571\n",
      "Baseline Loss: 2.7405 | Actual Loss: 0.0925\n",
      "Baseline Loss: 2.8655 | Actual Loss: 0.0926\n",
      "Baseline Loss: 2.5469 | Actual Loss: 0.1281\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▎        | 125/1000 [00:40<04:54,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8345 | Actual Loss: 0.3305\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3477\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.4454\n",
      "Epoch 125/1000: Train Loss: 0.1807, Val Loss: 0.3457\n",
      "Baseline Loss: 2.7777 | Actual Loss: 0.0678\n",
      "Baseline Loss: 2.8490 | Actual Loss: 0.1162\n",
      "Baseline Loss: 2.8894 | Actual Loss: 0.1966\n",
      "Baseline Loss: 2.7528 | Actual Loss: 0.1731\n",
      "Baseline Loss: 2.8269 | Actual Loss: 0.1428\n",
      "Baseline Loss: 2.8060 | Actual Loss: 0.1837\n",
      "Baseline Loss: 2.8382 | Actual Loss: 0.1555\n",
      "Baseline Loss: 2.8418 | Actual Loss: 0.1965\n",
      "Baseline Loss: 2.8005 | Actual Loss: 0.2790\n",
      "Baseline Loss: 2.8689 | Actual Loss: 0.1924\n",
      "Baseline Loss: 2.8108 | Actual Loss: 0.2715\n",
      "Baseline Loss: 2.7952 | Actual Loss: 0.1946\n",
      "Baseline Loss: 2.8707 | Actual Loss: 0.2114\n",
      "Baseline Loss: 2.8156 | Actual Loss: 0.2478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 126/1000 [00:41<04:34,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9578 | Actual Loss: 0.4593\n",
      "Baseline Loss: 2.5008 | Actual Loss: 0.0887\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2846\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2294\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3221\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.4276\n",
      "Epoch 126/1000: Train Loss: 0.1986, Val Loss: 0.3159\n",
      "Baseline Loss: 2.9100 | Actual Loss: 0.1638\n",
      "Baseline Loss: 2.8501 | Actual Loss: 0.2841\n",
      "Baseline Loss: 2.8309 | Actual Loss: 0.1482\n",
      "Baseline Loss: 2.8111 | Actual Loss: 0.2046\n",
      "Baseline Loss: 2.7845 | Actual Loss: 0.1887\n",
      "Baseline Loss: 2.8037 | Actual Loss: 0.0757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 127/1000 [00:41<04:37,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8027 | Actual Loss: 0.1689\n",
      "Baseline Loss: 2.8139 | Actual Loss: 0.1692\n",
      "Baseline Loss: 2.7865 | Actual Loss: 0.1924\n",
      "Baseline Loss: 2.7738 | Actual Loss: 0.2219\n",
      "Baseline Loss: 2.8150 | Actual Loss: 0.1202\n",
      "Baseline Loss: 2.7729 | Actual Loss: 0.1886\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.1280\n",
      "Baseline Loss: 2.8466 | Actual Loss: 0.3117\n",
      "Baseline Loss: 2.9098 | Actual Loss: 0.1010\n",
      "Baseline Loss: 2.5616 | Actual Loss: 0.0518\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2932\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2339\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3422\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3243\n",
      "Epoch 127/1000: Train Loss: 0.1699, Val Loss: 0.2984\n",
      "Baseline Loss: 2.7930 | Actual Loss: 0.1084\n",
      "Baseline Loss: 2.8071 | Actual Loss: 0.1151\n",
      "Baseline Loss: 2.8022 | Actual Loss: 0.2723\n",
      "Baseline Loss: 2.8009 | Actual Loss: 0.1712\n",
      "Baseline Loss: 2.8255 | Actual Loss: 0.1593\n",
      "Baseline Loss: 2.8003 | Actual Loss: 0.3552\n",
      "Baseline Loss: 2.8935 | Actual Loss: 0.1428\n",
      "Baseline Loss: 2.9049 | Actual Loss: 0.1891\n",
      "Baseline Loss: 2.8474 | Actual Loss: 0.3926\n",
      "Baseline Loss: 2.8479 | Actual Loss: 0.1716\n",
      "Baseline Loss: 2.8638 | Actual Loss: 0.2462\n",
      "Baseline Loss: 2.8555 | Actual Loss: 0.3115\n",
      "Baseline Loss: 2.8393 | Actual Loss: 0.2671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 128/1000 [00:41<04:42,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7900 | Actual Loss: 0.1737\n",
      "Baseline Loss: 2.8229 | Actual Loss: 0.1254\n",
      "Baseline Loss: 2.6863 | Actual Loss: 0.2030\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3125\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2626\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3841\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.2207\n",
      "Epoch 128/1000: Train Loss: 0.2128, Val Loss: 0.2950\n",
      "Baseline Loss: 2.8903 | Actual Loss: 0.2799\n",
      "Baseline Loss: 2.8326 | Actual Loss: 0.2824\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2257\n",
      "Baseline Loss: 2.8380 | Actual Loss: 0.1851\n",
      "Baseline Loss: 2.8662 | Actual Loss: 0.2005\n",
      "Baseline Loss: 2.8512 | Actual Loss: 0.4780\n",
      "Baseline Loss: 2.7818 | Actual Loss: 0.2376\n",
      "Baseline Loss: 2.7716 | Actual Loss: 0.4324\n",
      "Baseline Loss: 2.8229 | Actual Loss: 0.2110\n",
      "Baseline Loss: 2.8122 | Actual Loss: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 129/1000 [00:42<04:29,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8124 | Actual Loss: 0.1599\n",
      "Baseline Loss: 2.8203 | Actual Loss: 0.1722\n",
      "Baseline Loss: 2.8062 | Actual Loss: 0.2123\n",
      "Baseline Loss: 2.7832 | Actual Loss: 0.1529\n",
      "Baseline Loss: 2.8302 | Actual Loss: 0.2770\n",
      "Baseline Loss: 2.5204 | Actual Loss: 0.1280\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3902\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2504\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2261\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.2131\n",
      "Epoch 129/1000: Train Loss: 0.2428, Val Loss: 0.2700\n",
      "New best validation loss: 0.2700\n",
      "Baseline Loss: 2.8127 | Actual Loss: 0.1600\n",
      "Baseline Loss: 2.8372 | Actual Loss: 0.4636\n",
      "Baseline Loss: 2.8216 | Actual Loss: 0.1167\n",
      "Baseline Loss: 2.8618 | Actual Loss: 0.1435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 130/1000 [00:42<04:34,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8172 | Actual Loss: 0.1285\n",
      "Baseline Loss: 2.8247 | Actual Loss: 0.2251\n",
      "Baseline Loss: 2.7743 | Actual Loss: 0.1219\n",
      "Baseline Loss: 2.8348 | Actual Loss: 0.1350\n",
      "Baseline Loss: 2.7962 | Actual Loss: 0.1539\n",
      "Baseline Loss: 2.8675 | Actual Loss: 0.2208\n",
      "Baseline Loss: 2.8428 | Actual Loss: 0.1965\n",
      "Baseline Loss: 2.8163 | Actual Loss: 0.1626\n",
      "Baseline Loss: 2.7891 | Actual Loss: 0.2084\n",
      "Baseline Loss: 2.8159 | Actual Loss: 0.2074\n",
      "Baseline Loss: 2.8276 | Actual Loss: 0.2835\n",
      "Baseline Loss: 2.7445 | Actual Loss: 0.1972\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3479\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2496\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.4051\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.2533\n",
      "Epoch 130/1000: Train Loss: 0.1953, Val Loss: 0.3140\n",
      "Baseline Loss: 2.8251 | Actual Loss: 0.2830\n",
      "Baseline Loss: 2.8073 | Actual Loss: 0.0799\n",
      "Baseline Loss: 2.7981 | Actual Loss: 0.1783\n",
      "Baseline Loss: 2.8617 | Actual Loss: 0.1862\n",
      "Baseline Loss: 2.8149 | Actual Loss: 0.1516\n",
      "Baseline Loss: 2.9034 | Actual Loss: 0.2425\n",
      "Baseline Loss: 2.8155 | Actual Loss: 0.2032\n",
      "Baseline Loss: 2.8289 | Actual Loss: 0.1676\n",
      "Baseline Loss: 2.7892 | Actual Loss: 0.2117\n",
      "Baseline Loss: 2.8409 | Actual Loss: 0.1820\n",
      "Baseline Loss: 2.8113 | Actual Loss: 0.2764\n",
      "Baseline Loss: 2.8764 | Actual Loss: 0.2391\n",
      "Baseline Loss: 2.7650 | Actual Loss: 0.1752\n",
      "Baseline Loss: 2.8354 | Actual Loss: 0.2156\n",
      "Baseline Loss: 2.8564 | Actual Loss: 0.1687\n",
      "Baseline Loss: 2.6140 | Actual Loss: 0.2631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 131/1000 [00:42<04:24,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8702 | Actual Loss: 0.2815\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2161\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2880\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.2886\n",
      "Epoch 131/1000: Train Loss: 0.2015, Val Loss: 0.2686\n",
      "New best validation loss: 0.2686\n",
      "Baseline Loss: 2.8165 | Actual Loss: 0.2438\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.1963\n",
      "Baseline Loss: 2.8737 | Actual Loss: 0.1397\n",
      "Baseline Loss: 2.8989 | Actual Loss: 0.2104\n",
      "Baseline Loss: 2.8528 | Actual Loss: 0.1803\n",
      "Baseline Loss: 2.8074 | Actual Loss: 0.2842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 132/1000 [00:42<04:39,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8084 | Actual Loss: 0.1671\n",
      "Baseline Loss: 2.7359 | Actual Loss: 0.1263\n",
      "Baseline Loss: 2.7749 | Actual Loss: 0.1476\n",
      "Baseline Loss: 2.8152 | Actual Loss: 0.1799\n",
      "Baseline Loss: 2.8959 | Actual Loss: 0.3442\n",
      "Baseline Loss: 2.8274 | Actual Loss: 0.1662\n",
      "Baseline Loss: 2.8412 | Actual Loss: 0.1800\n",
      "Baseline Loss: 2.8363 | Actual Loss: 0.1768\n",
      "Baseline Loss: 2.8128 | Actual Loss: 0.3539\n",
      "Baseline Loss: 2.5846 | Actual Loss: 0.1212\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2650\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2880\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2775\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3201\n",
      "Epoch 132/1000: Train Loss: 0.2011, Val Loss: 0.2876\n",
      "Baseline Loss: 2.8140 | Actual Loss: 0.1863\n",
      "Baseline Loss: 2.8535 | Actual Loss: 0.3012\n",
      "Baseline Loss: 2.8214 | Actual Loss: 0.1985\n",
      "Baseline Loss: 2.7925 | Actual Loss: 0.1338\n",
      "Baseline Loss: 2.8618 | Actual Loss: 0.1792\n",
      "Baseline Loss: 2.7926 | Actual Loss: 0.2209\n",
      "Baseline Loss: 2.8075 | Actual Loss: 0.2758\n",
      "Baseline Loss: 2.7740 | Actual Loss: 0.3369\n",
      "Baseline Loss: 2.8985 | Actual Loss: 0.2259\n",
      "Baseline Loss: 2.8444 | Actual Loss: 0.1464\n",
      "Baseline Loss: 2.8343 | Actual Loss: 0.1556\n",
      "Baseline Loss: 2.7716 | Actual Loss: 0.4998\n",
      "Baseline Loss: 2.8146 | Actual Loss: 0.2108\n",
      "Baseline Loss: 2.8826 | Actual Loss: 0.1894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 133/1000 [00:43<04:47,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7699 | Actual Loss: 0.1809\n",
      "Baseline Loss: 2.6541 | Actual Loss: 0.0915\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3122\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2994\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3721\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3463\n",
      "Epoch 133/1000: Train Loss: 0.2208, Val Loss: 0.3325\n",
      "Baseline Loss: 2.7710 | Actual Loss: 0.2745\n",
      "Baseline Loss: 2.8986 | Actual Loss: 0.1643\n",
      "Baseline Loss: 2.8413 | Actual Loss: 0.2395\n",
      "Baseline Loss: 2.8335 | Actual Loss: 0.1369\n",
      "Baseline Loss: 2.8349 | Actual Loss: 0.2724\n",
      "Baseline Loss: 2.9532 | Actual Loss: 0.1887\n",
      "Baseline Loss: 2.7648 | Actual Loss: 0.2504\n",
      "Baseline Loss: 2.8312 | Actual Loss: 0.1556\n",
      "Baseline Loss: 2.7897 | Actual Loss: 0.1298\n",
      "Baseline Loss: 2.8283 | Actual Loss: 0.1889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 134/1000 [00:43<04:32,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8690 | Actual Loss: 0.2616\n",
      "Baseline Loss: 2.8427 | Actual Loss: 0.1185\n",
      "Baseline Loss: 2.7619 | Actual Loss: 0.1683\n",
      "Baseline Loss: 2.7814 | Actual Loss: 0.1538\n",
      "Baseline Loss: 2.8007 | Actual Loss: 0.1560\n",
      "Baseline Loss: 2.5714 | Actual Loss: 0.1052\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3828\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2601\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3082\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.2568\n",
      "Epoch 134/1000: Train Loss: 0.1853, Val Loss: 0.3020\n",
      "Baseline Loss: 2.8104 | Actual Loss: 0.1664\n",
      "Baseline Loss: 2.9046 | Actual Loss: 0.1903\n",
      "Baseline Loss: 2.7982 | Actual Loss: 0.2755\n",
      "Baseline Loss: 2.8185 | Actual Loss: 0.1320\n",
      "Baseline Loss: 2.8090 | Actual Loss: 0.2519\n",
      "Baseline Loss: 2.8827 | Actual Loss: 0.1234\n",
      "Baseline Loss: 2.8605 | Actual Loss: 0.2421\n",
      "Baseline Loss: 2.8744 | Actual Loss: 0.1763\n",
      "Baseline Loss: 2.8346 | Actual Loss: 0.1675\n",
      "Baseline Loss: 2.8154 | Actual Loss: 0.1718\n",
      "Baseline Loss: 2.8581 | Actual Loss: 0.1664\n",
      "Baseline Loss: 2.8041 | Actual Loss: 0.2434\n",
      "Baseline Loss: 2.7886 | Actual Loss: 0.2649\n",
      "Baseline Loss: 2.7858 | Actual Loss: 0.2527\n",
      "Baseline Loss: 2.7896 | Actual Loss: 0.5405\n",
      "Baseline Loss: 2.5969 | Actual Loss: 0.0788\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2928\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3351\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▎        | 135/1000 [00:43<04:35,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7548 | Actual Loss: 0.2641\n",
      "Epoch 135/1000: Train Loss: 0.2152, Val Loss: 0.2999\n",
      "Baseline Loss: 2.8287 | Actual Loss: 0.1396\n",
      "Baseline Loss: 2.9078 | Actual Loss: 0.2273\n",
      "Baseline Loss: 2.8104 | Actual Loss: 0.1769\n",
      "Baseline Loss: 2.8268 | Actual Loss: 0.2905\n",
      "Baseline Loss: 2.7651 | Actual Loss: 0.2164\n",
      "Baseline Loss: 2.8208 | Actual Loss: 0.1125\n",
      "Baseline Loss: 2.8474 | Actual Loss: 0.2274\n",
      "Baseline Loss: 2.8725 | Actual Loss: 0.2776\n",
      "Baseline Loss: 2.8925 | Actual Loss: 0.1924\n",
      "Baseline Loss: 2.8468 | Actual Loss: 0.0986\n",
      "Baseline Loss: 2.7814 | Actual Loss: 0.0772\n",
      "Baseline Loss: 2.7881 | Actual Loss: 0.1982\n",
      "Baseline Loss: 2.7968 | Actual Loss: 0.1869\n",
      "Baseline Loss: 2.8050 | Actual Loss: 0.2013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▎        | 136/1000 [00:44<04:23,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8325 | Actual Loss: 0.2422\n",
      "Baseline Loss: 2.5374 | Actual Loss: 0.0950\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2809\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2564\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2481\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3060\n",
      "Epoch 136/1000: Train Loss: 0.1850, Val Loss: 0.2728\n",
      "Baseline Loss: 2.8229 | Actual Loss: 0.1872\n",
      "Baseline Loss: 2.8391 | Actual Loss: 0.2845\n",
      "Baseline Loss: 2.8955 | Actual Loss: 0.3518\n",
      "Baseline Loss: 2.8633 | Actual Loss: 0.2968\n",
      "Baseline Loss: 2.8122 | Actual Loss: 0.1577\n",
      "Baseline Loss: 2.8387 | Actual Loss: 0.2444\n",
      "Baseline Loss: 2.7587 | Actual Loss: 0.1736\n",
      "Baseline Loss: 2.8333 | Actual Loss: 0.1020\n",
      "Baseline Loss: 2.8773 | Actual Loss: 0.2082\n",
      "Baseline Loss: 2.8174 | Actual Loss: 0.2940\n",
      "Baseline Loss: 2.8757 | Actual Loss: 0.2649\n",
      "Baseline Loss: 2.7477 | Actual Loss: 0.2860\n",
      "Baseline Loss: 2.7671 | Actual Loss: 0.1482\n",
      "Baseline Loss: 2.8315 | Actual Loss: 0.1116\n",
      "Baseline Loss: 2.8005 | Actual Loss: 0.1377\n",
      "Baseline Loss: 2.6412 | Actual Loss: 0.0975\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3242\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2196\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▎        | 137/1000 [00:44<04:35,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7548 | Actual Loss: 0.3393\n",
      "Epoch 137/1000: Train Loss: 0.2091, Val Loss: 0.2866\n",
      "Baseline Loss: 2.8239 | Actual Loss: 0.1755\n",
      "Baseline Loss: 2.8801 | Actual Loss: 0.3036\n",
      "Baseline Loss: 2.8809 | Actual Loss: 0.2716\n",
      "Baseline Loss: 2.8119 | Actual Loss: 0.2244\n",
      "Baseline Loss: 2.8166 | Actual Loss: 0.2630\n",
      "Baseline Loss: 2.8133 | Actual Loss: 0.2424\n",
      "Baseline Loss: 2.8122 | Actual Loss: 0.1543\n",
      "Baseline Loss: 2.8211 | Actual Loss: 0.1678\n",
      "Baseline Loss: 2.7729 | Actual Loss: 0.1263\n",
      "Baseline Loss: 2.8705 | Actual Loss: 0.1973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 138/1000 [00:44<04:37,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8605 | Actual Loss: 0.1232\n",
      "Baseline Loss: 2.8018 | Actual Loss: 0.2129\n",
      "Baseline Loss: 2.8845 | Actual Loss: 0.2935\n",
      "Baseline Loss: 2.8587 | Actual Loss: 0.1453\n",
      "Baseline Loss: 2.8718 | Actual Loss: 0.1451\n",
      "Baseline Loss: 2.4076 | Actual Loss: 0.1751\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3437\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2330\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2471\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3837\n",
      "Epoch 138/1000: Train Loss: 0.2013, Val Loss: 0.3019\n",
      "Baseline Loss: 2.8676 | Actual Loss: 0.2568\n",
      "Baseline Loss: 2.8502 | Actual Loss: 0.1315\n",
      "Baseline Loss: 2.8620 | Actual Loss: 0.2657\n",
      "Baseline Loss: 2.8327 | Actual Loss: 0.1289\n",
      "Baseline Loss: 2.8040 | Actual Loss: 0.2107\n",
      "Baseline Loss: 2.7959 | Actual Loss: 0.1958\n",
      "Baseline Loss: 2.8157 | Actual Loss: 0.2111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 139/1000 [00:45<04:24,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8668 | Actual Loss: 0.2254\n",
      "Baseline Loss: 2.8522 | Actual Loss: 0.1607\n",
      "Baseline Loss: 2.8261 | Actual Loss: 0.1427\n",
      "Baseline Loss: 2.7811 | Actual Loss: 0.2102\n",
      "Baseline Loss: 2.8942 | Actual Loss: 0.2427\n",
      "Baseline Loss: 2.7682 | Actual Loss: 0.1406\n",
      "Baseline Loss: 2.8352 | Actual Loss: 0.2353\n",
      "Baseline Loss: 2.7726 | Actual Loss: 0.2410\n",
      "Baseline Loss: 2.5729 | Actual Loss: 0.1151\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3150\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2378\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3392\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3419\n",
      "Epoch 139/1000: Train Loss: 0.1946, Val Loss: 0.3085\n",
      "Baseline Loss: 2.8480 | Actual Loss: 0.2468\n",
      "Baseline Loss: 2.7891 | Actual Loss: 0.1494\n",
      "Baseline Loss: 2.8193 | Actual Loss: 0.2003\n",
      "Baseline Loss: 2.7227 | Actual Loss: 0.1577\n",
      "Baseline Loss: 2.7770 | Actual Loss: 0.2252\n",
      "Baseline Loss: 2.8629 | Actual Loss: 0.1700\n",
      "Baseline Loss: 2.8283 | Actual Loss: 0.1254\n",
      "Baseline Loss: 2.8674 | Actual Loss: 0.1796\n",
      "Baseline Loss: 2.8036 | Actual Loss: 0.1919\n",
      "Baseline Loss: 2.8212 | Actual Loss: 0.1722\n",
      "Baseline Loss: 2.8177 | Actual Loss: 0.1539\n",
      "Baseline Loss: 2.8502 | Actual Loss: 0.1579\n",
      "Baseline Loss: 2.7900 | Actual Loss: 0.1313\n",
      "Baseline Loss: 2.8821 | Actual Loss: 0.2379\n",
      "Baseline Loss: 2.8537 | Actual Loss: 0.1501\n",
      "Baseline Loss: 2.6111 | Actual Loss: 0.1629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 140/1000 [00:45<04:30,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8702 | Actual Loss: 0.2460\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2409\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2957\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3736\n",
      "Epoch 140/1000: Train Loss: 0.1758, Val Loss: 0.2891\n",
      "Baseline Loss: 2.7823 | Actual Loss: 0.1290\n",
      "Baseline Loss: 2.8281 | Actual Loss: 0.2027\n",
      "Baseline Loss: 2.7996 | Actual Loss: 0.3299\n",
      "Baseline Loss: 2.8248 | Actual Loss: 0.2444\n",
      "Baseline Loss: 2.7732 | Actual Loss: 0.1588\n",
      "Baseline Loss: 2.7408 | Actual Loss: 0.1599\n",
      "Baseline Loss: 2.8602 | Actual Loss: 0.2398\n",
      "Baseline Loss: 2.7767 | Actual Loss: 0.1690\n",
      "Baseline Loss: 2.8989 | Actual Loss: 0.1458\n",
      "Baseline Loss: 2.8901 | Actual Loss: 0.1940\n",
      "Baseline Loss: 2.8172 | Actual Loss: 0.2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 141/1000 [00:45<04:33,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8289 | Actual Loss: 0.2116\n",
      "Baseline Loss: 2.7591 | Actual Loss: 0.2568\n",
      "Baseline Loss: 2.8910 | Actual Loss: 0.3005\n",
      "Baseline Loss: 2.9246 | Actual Loss: 0.2134\n",
      "Baseline Loss: 2.6604 | Actual Loss: 0.1626\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3586\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2743\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.1774\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.2956\n",
      "Epoch 141/1000: Train Loss: 0.2075, Val Loss: 0.2765\n",
      "Baseline Loss: 2.8840 | Actual Loss: 0.1757\n",
      "Baseline Loss: 2.8623 | Actual Loss: 0.1773\n",
      "Baseline Loss: 2.8337 | Actual Loss: 0.2321\n",
      "Baseline Loss: 2.8256 | Actual Loss: 0.3595\n",
      "Baseline Loss: 2.7807 | Actual Loss: 0.3474\n",
      "Baseline Loss: 2.8295 | Actual Loss: 0.1543\n",
      "Baseline Loss: 2.8570 | Actual Loss: 0.1920\n",
      "Baseline Loss: 2.8681 | Actual Loss: 0.1690\n",
      "Baseline Loss: 2.8518 | Actual Loss: 0.1422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 142/1000 [00:46<04:22,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8425 | Actual Loss: 0.1840\n",
      "Baseline Loss: 2.7600 | Actual Loss: 0.2085\n",
      "Baseline Loss: 2.8255 | Actual Loss: 0.1286\n",
      "Baseline Loss: 2.8231 | Actual Loss: 0.1530\n",
      "Baseline Loss: 2.8376 | Actual Loss: 0.2736\n",
      "Baseline Loss: 2.7643 | Actual Loss: 0.2463\n",
      "Baseline Loss: 2.4774 | Actual Loss: 0.1649\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3206\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2334\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3260\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.1770\n",
      "Epoch 142/1000: Train Loss: 0.2068, Val Loss: 0.2642\n",
      "New best validation loss: 0.2642\n",
      "Baseline Loss: 2.8388 | Actual Loss: 0.2348\n",
      "Baseline Loss: 2.8056 | Actual Loss: 0.2560\n",
      "Baseline Loss: 2.8905 | Actual Loss: 0.2761\n",
      "Baseline Loss: 2.8549 | Actual Loss: 0.1852\n",
      "Baseline Loss: 2.8151 | Actual Loss: 0.1529\n",
      "Baseline Loss: 2.8391 | Actual Loss: 0.1864\n",
      "Baseline Loss: 2.8139 | Actual Loss: 0.1567\n",
      "Baseline Loss: 2.7560 | Actual Loss: 0.2484\n",
      "Baseline Loss: 2.9003 | Actual Loss: 0.2682\n",
      "Baseline Loss: 2.8787 | Actual Loss: 0.2232\n",
      "Baseline Loss: 2.7986 | Actual Loss: 0.1969\n",
      "Baseline Loss: 2.8040 | Actual Loss: 0.1615\n",
      "Baseline Loss: 2.8343 | Actual Loss: 0.1489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 143/1000 [00:46<04:32,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8370 | Actual Loss: 0.3312\n",
      "Baseline Loss: 2.8212 | Actual Loss: 0.2762\n",
      "Baseline Loss: 2.5565 | Actual Loss: 0.2806\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2477\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2530\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2071\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3012\n",
      "Epoch 143/1000: Train Loss: 0.2240, Val Loss: 0.2523\n",
      "New best validation loss: 0.2523\n",
      "Baseline Loss: 2.8432 | Actual Loss: 0.2015\n",
      "Baseline Loss: 2.7683 | Actual Loss: 0.2110\n",
      "Baseline Loss: 2.7591 | Actual Loss: 0.1966\n",
      "Baseline Loss: 2.8880 | Actual Loss: 0.3088\n",
      "Baseline Loss: 2.8084 | Actual Loss: 0.1786\n",
      "Baseline Loss: 2.8314 | Actual Loss: 0.1548\n",
      "Baseline Loss: 2.7933 | Actual Loss: 0.0639\n",
      "Baseline Loss: 2.8665 | Actual Loss: 0.1624\n",
      "Baseline Loss: 2.7733 | Actual Loss: 0.2501\n",
      "Baseline Loss: 2.8410 | Actual Loss: 0.2395\n",
      "Baseline Loss: 2.7827 | Actual Loss: 0.1104\n",
      "Baseline Loss: 2.7938 | Actual Loss: 0.1773\n",
      "Baseline Loss: 2.8961 | Actual Loss: 0.3079\n",
      "Baseline Loss: 2.7724 | Actual Loss: 0.4229\n",
      "Baseline Loss: 2.8708 | Actual Loss: 0.2597\n",
      "Baseline Loss: 2.4630 | Actual Loss: 0.2533\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2839\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 144/1000 [00:46<04:38,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7737 | Actual Loss: 0.2658\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3410\n",
      "Epoch 144/1000: Train Loss: 0.2187, Val Loss: 0.2798\n",
      "Baseline Loss: 2.8237 | Actual Loss: 0.1689\n",
      "Baseline Loss: 2.7579 | Actual Loss: 0.1674\n",
      "Baseline Loss: 2.8571 | Actual Loss: 0.2891\n",
      "Baseline Loss: 2.7616 | Actual Loss: 0.1053\n",
      "Baseline Loss: 2.8244 | Actual Loss: 0.2765\n",
      "Baseline Loss: 2.8745 | Actual Loss: 0.1919\n",
      "Baseline Loss: 2.8543 | Actual Loss: 0.1574\n",
      "Baseline Loss: 2.8198 | Actual Loss: 0.2005\n",
      "Baseline Loss: 2.8500 | Actual Loss: 0.2323\n",
      "Baseline Loss: 2.8090 | Actual Loss: 0.3462\n",
      "Baseline Loss: 2.8549 | Actual Loss: 0.0746\n",
      "Baseline Loss: 2.8050 | Actual Loss: 0.2062\n",
      "Baseline Loss: 2.8344 | Actual Loss: 0.2293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 145/1000 [00:47<04:21,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7987 | Actual Loss: 0.2898\n",
      "Baseline Loss: 2.7921 | Actual Loss: 0.2221\n",
      "Baseline Loss: 2.5950 | Actual Loss: 0.1202\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2997\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3226\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2107\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.2971\n",
      "Epoch 145/1000: Train Loss: 0.2049, Val Loss: 0.2825\n",
      "Baseline Loss: 2.8814 | Actual Loss: 0.2419\n",
      "Baseline Loss: 2.8168 | Actual Loss: 0.2258\n",
      "Baseline Loss: 2.8355 | Actual Loss: 0.1406\n",
      "Baseline Loss: 2.8528 | Actual Loss: 0.1923\n",
      "Baseline Loss: 2.7968 | Actual Loss: 0.1871\n",
      "Baseline Loss: 2.7940 | Actual Loss: 0.2222\n",
      "Baseline Loss: 2.9097 | Actual Loss: 0.1525\n",
      "Baseline Loss: 2.8638 | Actual Loss: 0.1704\n",
      "Baseline Loss: 2.8194 | Actual Loss: 0.1992\n",
      "Baseline Loss: 2.7896 | Actual Loss: 0.2247\n",
      "Baseline Loss: 2.7695 | Actual Loss: 0.2437\n",
      "Baseline Loss: 2.8472 | Actual Loss: 0.2521\n",
      "Baseline Loss: 2.8540 | Actual Loss: 0.1653\n",
      "Baseline Loss: 2.8177 | Actual Loss: 0.2426\n",
      "Baseline Loss: 2.9153 | Actual Loss: 0.2325\n",
      "Baseline Loss: 2.4711 | Actual Loss: 0.0755\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2879\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2597\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 146/1000 [00:47<04:32,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7548 | Actual Loss: 0.3855\n",
      "Epoch 146/1000: Train Loss: 0.1980, Val Loss: 0.3020\n",
      "Baseline Loss: 2.8495 | Actual Loss: 0.2346\n",
      "Baseline Loss: 2.8235 | Actual Loss: 0.3125\n",
      "Baseline Loss: 2.8623 | Actual Loss: 0.1789\n",
      "Baseline Loss: 2.8484 | Actual Loss: 0.2675\n",
      "Baseline Loss: 2.7733 | Actual Loss: 0.2254\n",
      "Baseline Loss: 2.8930 | Actual Loss: 0.2365\n",
      "Baseline Loss: 2.8600 | Actual Loss: 0.2089\n",
      "Baseline Loss: 2.8114 | Actual Loss: 0.1621\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.3773\n",
      "Baseline Loss: 2.8560 | Actual Loss: 0.2059\n",
      "Baseline Loss: 2.8339 | Actual Loss: 0.2793\n",
      "Baseline Loss: 2.8058 | Actual Loss: 0.3368\n",
      "Baseline Loss: 2.8253 | Actual Loss: 0.2935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 147/1000 [00:47<04:20,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8277 | Actual Loss: 0.1820\n",
      "Baseline Loss: 2.9805 | Actual Loss: 0.3722\n",
      "Baseline Loss: 2.4498 | Actual Loss: 0.0854\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3614\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.4120\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3356\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3602\n",
      "Epoch 147/1000: Train Loss: 0.2474, Val Loss: 0.3673\n",
      "Baseline Loss: 2.8142 | Actual Loss: 0.1059\n",
      "Baseline Loss: 2.8275 | Actual Loss: 0.2826\n",
      "Baseline Loss: 2.7655 | Actual Loss: 0.2733\n",
      "Baseline Loss: 2.8509 | Actual Loss: 0.2207\n",
      "Baseline Loss: 2.8568 | Actual Loss: 0.3577\n",
      "Baseline Loss: 2.8077 | Actual Loss: 0.1838\n",
      "Baseline Loss: 2.8975 | Actual Loss: 0.2473\n",
      "Baseline Loss: 2.8627 | Actual Loss: 0.2207\n",
      "Baseline Loss: 2.7657 | Actual Loss: 0.2598\n",
      "Baseline Loss: 2.8736 | Actual Loss: 0.2107\n",
      "Baseline Loss: 2.8110 | Actual Loss: 0.2572\n",
      "Baseline Loss: 2.7987 | Actual Loss: 0.1895\n",
      "Baseline Loss: 2.8419 | Actual Loss: 0.2066\n",
      "Baseline Loss: 2.8287 | Actual Loss: 0.1054\n",
      "Baseline Loss: 2.8955 | Actual Loss: 0.1439\n",
      "Baseline Loss: 2.5380 | Actual Loss: 0.4662\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.4026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 148/1000 [00:48<04:33,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8345 | Actual Loss: 0.3767\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2376\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3226\n",
      "Epoch 148/1000: Train Loss: 0.2332, Val Loss: 0.3349\n",
      "Baseline Loss: 2.8329 | Actual Loss: 0.1571\n",
      "Baseline Loss: 2.8793 | Actual Loss: 0.1877\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.2456\n",
      "Baseline Loss: 2.8696 | Actual Loss: 0.1890\n",
      "Baseline Loss: 2.7584 | Actual Loss: 0.2521\n",
      "Baseline Loss: 2.8168 | Actual Loss: 0.1477\n",
      "Baseline Loss: 2.7763 | Actual Loss: 0.2097\n",
      "Baseline Loss: 2.8064 | Actual Loss: 0.1336\n",
      "Baseline Loss: 2.8486 | Actual Loss: 0.1346\n",
      "Baseline Loss: 2.8366 | Actual Loss: 0.1543\n",
      "Baseline Loss: 2.7948 | Actual Loss: 0.1045\n",
      "Baseline Loss: 2.7752 | Actual Loss: 0.3753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 149/1000 [00:48<04:40,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9136 | Actual Loss: 0.1596\n",
      "Baseline Loss: 2.8156 | Actual Loss: 0.1751\n",
      "Baseline Loss: 2.8523 | Actual Loss: 0.3045\n",
      "Baseline Loss: 2.6131 | Actual Loss: 0.1298\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2631\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2477\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2271\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.2219\n",
      "Epoch 149/1000: Train Loss: 0.1913, Val Loss: 0.2399\n",
      "New best validation loss: 0.2399\n",
      "Baseline Loss: 2.7908 | Actual Loss: 0.2240\n",
      "Baseline Loss: 2.8036 | Actual Loss: 0.0936\n",
      "Baseline Loss: 2.8604 | Actual Loss: 0.2357\n",
      "Baseline Loss: 2.8001 | Actual Loss: 0.3100\n",
      "Baseline Loss: 2.8029 | Actual Loss: 0.2689\n",
      "Baseline Loss: 2.8178 | Actual Loss: 0.1504\n",
      "Baseline Loss: 2.8348 | Actual Loss: 0.2172\n",
      "Baseline Loss: 2.8375 | Actual Loss: 0.1539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 150/1000 [00:48<04:25,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7949 | Actual Loss: 0.2457\n",
      "Baseline Loss: 2.8602 | Actual Loss: 0.2479\n",
      "Baseline Loss: 2.8456 | Actual Loss: 0.2042\n",
      "Baseline Loss: 2.8473 | Actual Loss: 0.2226\n",
      "Baseline Loss: 2.7690 | Actual Loss: 0.2798\n",
      "Baseline Loss: 2.8952 | Actual Loss: 0.1929\n",
      "Baseline Loss: 2.8555 | Actual Loss: 0.1688\n",
      "Baseline Loss: 2.5480 | Actual Loss: 0.0938\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2764\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2358\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2636\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3489\n",
      "Epoch 150/1000: Train Loss: 0.2068, Val Loss: 0.2812\n",
      "Baseline Loss: 2.7424 | Actual Loss: 0.2311\n",
      "Baseline Loss: 2.7841 | Actual Loss: 0.3219\n",
      "Baseline Loss: 2.8117 | Actual Loss: 0.1864\n",
      "Baseline Loss: 2.9357 | Actual Loss: 0.1914\n",
      "Baseline Loss: 2.8045 | Actual Loss: 0.1830\n",
      "Baseline Loss: 2.8140 | Actual Loss: 0.2537\n",
      "Baseline Loss: 2.8242 | Actual Loss: 0.2014\n",
      "Baseline Loss: 2.7988 | Actual Loss: 0.1631\n",
      "Baseline Loss: 2.8748 | Actual Loss: 0.1082\n",
      "Baseline Loss: 2.8051 | Actual Loss: 0.1613\n",
      "Baseline Loss: 2.8535 | Actual Loss: 0.1767\n",
      "Baseline Loss: 2.8232 | Actual Loss: 0.2985\n",
      "Baseline Loss: 2.8548 | Actual Loss: 0.1136\n",
      "Baseline Loss: 2.8754 | Actual Loss: 0.1802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 151/1000 [00:49<04:36,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7789 | Actual Loss: 0.1863\n",
      "Baseline Loss: 2.6188 | Actual Loss: 0.0544\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2608\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.1921\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2431\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.2647\n",
      "Epoch 151/1000: Train Loss: 0.1882, Val Loss: 0.2402\n",
      "Baseline Loss: 2.8068 | Actual Loss: 0.1363\n",
      "Baseline Loss: 2.9318 | Actual Loss: 0.2566\n",
      "Baseline Loss: 2.8786 | Actual Loss: 0.5448\n",
      "Baseline Loss: 2.8146 | Actual Loss: 0.1163\n",
      "Baseline Loss: 2.8817 | Actual Loss: 0.1109\n",
      "Baseline Loss: 2.8194 | Actual Loss: 0.1808\n",
      "Baseline Loss: 2.8422 | Actual Loss: 0.2752\n",
      "Baseline Loss: 2.7596 | Actual Loss: 0.1564\n",
      "Baseline Loss: 2.7735 | Actual Loss: 0.2021\n",
      "Baseline Loss: 2.8904 | Actual Loss: 0.2381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 152/1000 [00:49<04:42,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8304 | Actual Loss: 0.1689\n",
      "Baseline Loss: 2.7646 | Actual Loss: 0.2129\n",
      "Baseline Loss: 2.8481 | Actual Loss: 0.1594\n",
      "Baseline Loss: 2.7976 | Actual Loss: 0.0544\n",
      "Baseline Loss: 2.8960 | Actual Loss: 0.3074\n",
      "Baseline Loss: 2.4159 | Actual Loss: 0.3202\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3820\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2476\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2460\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3056\n",
      "Epoch 152/1000: Train Loss: 0.2151, Val Loss: 0.2953\n",
      "Baseline Loss: 2.8192 | Actual Loss: 0.1216\n",
      "Baseline Loss: 2.8838 | Actual Loss: 0.1180\n",
      "Baseline Loss: 2.7993 | Actual Loss: 0.1890\n",
      "Baseline Loss: 2.8109 | Actual Loss: 0.1638\n",
      "Baseline Loss: 2.8568 | Actual Loss: 0.3353\n",
      "Baseline Loss: 2.8685 | Actual Loss: 0.2264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 153/1000 [00:49<04:26,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9020 | Actual Loss: 0.1186\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.3973\n",
      "Baseline Loss: 2.8256 | Actual Loss: 0.2567\n",
      "Baseline Loss: 2.7853 | Actual Loss: 0.2740\n",
      "Baseline Loss: 2.8344 | Actual Loss: 0.2062\n",
      "Baseline Loss: 2.8656 | Actual Loss: 0.2191\n",
      "Baseline Loss: 2.8765 | Actual Loss: 0.3478\n",
      "Baseline Loss: 2.8397 | Actual Loss: 0.3035\n",
      "Baseline Loss: 2.7709 | Actual Loss: 0.1986\n",
      "Baseline Loss: 2.5791 | Actual Loss: 0.0931\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2294\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3049\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3085\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3211\n",
      "Epoch 153/1000: Train Loss: 0.2231, Val Loss: 0.2910\n",
      "Baseline Loss: 2.8062 | Actual Loss: 0.1946\n",
      "Baseline Loss: 2.8150 | Actual Loss: 0.1454\n",
      "Baseline Loss: 2.8953 | Actual Loss: 0.2258\n",
      "Baseline Loss: 2.8101 | Actual Loss: 0.1083\n",
      "Baseline Loss: 2.7925 | Actual Loss: 0.1686\n",
      "Baseline Loss: 2.7670 | Actual Loss: 0.2049\n",
      "Baseline Loss: 2.8343 | Actual Loss: 0.1508\n",
      "Baseline Loss: 2.8662 | Actual Loss: 0.2766\n",
      "Baseline Loss: 2.9446 | Actual Loss: 0.3809\n",
      "Baseline Loss: 2.8429 | Actual Loss: 0.1076\n",
      "Baseline Loss: 2.7632 | Actual Loss: 0.1640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 154/1000 [00:49<04:35,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7731 | Actual Loss: 0.2074\n",
      "Baseline Loss: 2.8846 | Actual Loss: 0.1160\n",
      "Baseline Loss: 2.8983 | Actual Loss: 0.1809\n",
      "Baseline Loss: 2.7835 | Actual Loss: 0.0879\n",
      "Baseline Loss: 2.5230 | Actual Loss: 0.1218\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3262\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3199\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3063\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.1917\n",
      "Epoch 154/1000: Train Loss: 0.1776, Val Loss: 0.2861\n",
      "Baseline Loss: 2.8499 | Actual Loss: 0.2772\n",
      "Baseline Loss: 2.8156 | Actual Loss: 0.1694\n",
      "Baseline Loss: 2.7947 | Actual Loss: 0.1726\n",
      "Baseline Loss: 2.8158 | Actual Loss: 0.1407\n",
      "Baseline Loss: 2.8519 | Actual Loss: 0.1162\n",
      "Baseline Loss: 2.8073 | Actual Loss: 0.1865\n",
      "Baseline Loss: 2.7984 | Actual Loss: 0.1992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 155/1000 [00:50<04:21,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7933 | Actual Loss: 0.2386\n",
      "Baseline Loss: 2.9364 | Actual Loss: 0.1897\n",
      "Baseline Loss: 2.7812 | Actual Loss: 0.2471\n",
      "Baseline Loss: 2.8251 | Actual Loss: 0.1962\n",
      "Baseline Loss: 2.8589 | Actual Loss: 0.1456\n",
      "Baseline Loss: 2.8147 | Actual Loss: 0.2047\n",
      "Baseline Loss: 2.8437 | Actual Loss: 0.1640\n",
      "Baseline Loss: 2.8794 | Actual Loss: 0.2256\n",
      "Baseline Loss: 2.6685 | Actual Loss: 0.1118\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2855\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2045\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3187\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.2487\n",
      "Epoch 155/1000: Train Loss: 0.1866, Val Loss: 0.2644\n",
      "Baseline Loss: 2.8494 | Actual Loss: 0.1969\n",
      "Baseline Loss: 2.8699 | Actual Loss: 0.1339\n",
      "Baseline Loss: 2.7854 | Actual Loss: 0.1915\n",
      "Baseline Loss: 2.7681 | Actual Loss: 0.1599\n",
      "Baseline Loss: 2.7987 | Actual Loss: 0.2087\n",
      "Baseline Loss: 2.8128 | Actual Loss: 0.2089\n",
      "Baseline Loss: 2.8236 | Actual Loss: 0.2556\n",
      "Baseline Loss: 2.8642 | Actual Loss: 0.1638\n",
      "Baseline Loss: 2.7528 | Actual Loss: 0.1337\n",
      "Baseline Loss: 2.8432 | Actual Loss: 0.0720\n",
      "Baseline Loss: 2.8183 | Actual Loss: 0.1108\n",
      "Baseline Loss: 2.8691 | Actual Loss: 0.1170\n",
      "Baseline Loss: 2.8750 | Actual Loss: 0.1205\n",
      "Baseline Loss: 2.7770 | Actual Loss: 0.2560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 156/1000 [00:50<04:31,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8085 | Actual Loss: 0.1133\n",
      "Baseline Loss: 2.5507 | Actual Loss: 0.1954\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3248\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2540\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2365\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3018\n",
      "Epoch 156/1000: Train Loss: 0.1649, Val Loss: 0.2793\n",
      "Baseline Loss: 2.8433 | Actual Loss: 0.1941\n",
      "Baseline Loss: 2.8856 | Actual Loss: 0.0719\n",
      "Baseline Loss: 2.7925 | Actual Loss: 0.1868\n",
      "Baseline Loss: 2.8419 | Actual Loss: 0.2128\n",
      "Baseline Loss: 2.8720 | Actual Loss: 0.1602\n",
      "Baseline Loss: 2.8516 | Actual Loss: 0.1425\n",
      "Baseline Loss: 2.7863 | Actual Loss: 0.1092\n",
      "Baseline Loss: 2.8020 | Actual Loss: 0.1758\n",
      "Baseline Loss: 2.8229 | Actual Loss: 0.1674\n",
      "Baseline Loss: 2.7847 | Actual Loss: 0.1428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 157/1000 [00:50<04:37,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8426 | Actual Loss: 0.1176\n",
      "Baseline Loss: 2.8662 | Actual Loss: 0.1541\n",
      "Baseline Loss: 2.7917 | Actual Loss: 0.1168\n",
      "Baseline Loss: 2.8473 | Actual Loss: 0.1962\n",
      "Baseline Loss: 2.7893 | Actual Loss: 0.1893\n",
      "Baseline Loss: 2.4843 | Actual Loss: 0.1035\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2689\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.1709\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2181\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.2265\n",
      "Epoch 157/1000: Train Loss: 0.1526, Val Loss: 0.2211\n",
      "New best validation loss: 0.2211\n",
      "Baseline Loss: 2.8348 | Actual Loss: 0.1224\n",
      "Baseline Loss: 2.8599 | Actual Loss: 0.2366\n",
      "Baseline Loss: 2.8793 | Actual Loss: 0.2197\n",
      "Baseline Loss: 2.8500 | Actual Loss: 0.1350\n",
      "Baseline Loss: 2.8200 | Actual Loss: 0.1218\n",
      "Baseline Loss: 2.7940 | Actual Loss: 0.1826\n",
      "Baseline Loss: 2.7620 | Actual Loss: 0.1107\n",
      "Baseline Loss: 2.8534 | Actual Loss: 0.1378\n",
      "Baseline Loss: 2.7725 | Actual Loss: 0.2291\n",
      "Baseline Loss: 2.8153 | Actual Loss: 0.1439\n",
      "Baseline Loss: 2.8670 | Actual Loss: 0.1928\n",
      "Baseline Loss: 2.8143 | Actual Loss: 0.1377\n",
      "Baseline Loss: 2.8373 | Actual Loss: 0.2542\n",
      "Baseline Loss: 2.8400 | Actual Loss: 0.2617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 158/1000 [00:51<04:22,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8028 | Actual Loss: 0.0819\n",
      "Baseline Loss: 2.5150 | Actual Loss: 0.2635\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3458\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2916\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3048\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.2551\n",
      "Epoch 158/1000: Train Loss: 0.1770, Val Loss: 0.2993\n",
      "Baseline Loss: 2.7970 | Actual Loss: 0.2880\n",
      "Baseline Loss: 2.8030 | Actual Loss: 0.2130\n",
      "Baseline Loss: 2.8230 | Actual Loss: 0.1463\n",
      "Baseline Loss: 2.8943 | Actual Loss: 0.1944\n",
      "Baseline Loss: 2.8284 | Actual Loss: 0.2480\n",
      "Baseline Loss: 2.8130 | Actual Loss: 0.2389\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.2204\n",
      "Baseline Loss: 2.8804 | Actual Loss: 0.1208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 159/1000 [00:51<04:26,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7534 | Actual Loss: 0.1275\n",
      "Baseline Loss: 2.7759 | Actual Loss: 0.1350\n",
      "Baseline Loss: 2.7721 | Actual Loss: 0.3357\n",
      "Baseline Loss: 2.8064 | Actual Loss: 0.3123\n",
      "Baseline Loss: 2.8408 | Actual Loss: 0.2509\n",
      "Baseline Loss: 2.8755 | Actual Loss: 0.1918\n",
      "Baseline Loss: 2.7911 | Actual Loss: 0.2102\n",
      "Baseline Loss: 2.6191 | Actual Loss: 0.1571\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3227\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2420\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2524\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3584\n",
      "Epoch 159/1000: Train Loss: 0.2119, Val Loss: 0.2939\n",
      "Baseline Loss: 2.8130 | Actual Loss: 0.2228\n",
      "Baseline Loss: 2.8043 | Actual Loss: 0.1656\n",
      "Baseline Loss: 2.8044 | Actual Loss: 0.0919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 160/1000 [00:51<04:09,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7956 | Actual Loss: 0.3820\n",
      "Baseline Loss: 2.8055 | Actual Loss: 0.2539\n",
      "Baseline Loss: 2.7932 | Actual Loss: 0.1548\n",
      "Baseline Loss: 2.8494 | Actual Loss: 0.1544\n",
      "Baseline Loss: 2.8660 | Actual Loss: 0.2044\n",
      "Baseline Loss: 2.8049 | Actual Loss: 0.1649\n",
      "Baseline Loss: 2.8800 | Actual Loss: 0.1373\n",
      "Baseline Loss: 2.7599 | Actual Loss: 0.1872\n",
      "Baseline Loss: 2.7950 | Actual Loss: 0.1518\n",
      "Baseline Loss: 2.8671 | Actual Loss: 0.1531\n",
      "Baseline Loss: 2.8277 | Actual Loss: 0.2195\n",
      "Baseline Loss: 2.8100 | Actual Loss: 0.2281\n",
      "Baseline Loss: 2.5155 | Actual Loss: 0.1354\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2738\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3694\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3086\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.2465\n",
      "Epoch 160/1000: Train Loss: 0.1879, Val Loss: 0.2996\n",
      "Baseline Loss: 2.8172 | Actual Loss: 0.1673\n",
      "Baseline Loss: 2.8584 | Actual Loss: 0.2645\n",
      "Baseline Loss: 2.7767 | Actual Loss: 0.1695\n",
      "Baseline Loss: 2.7721 | Actual Loss: 0.1805\n",
      "Baseline Loss: 2.7593 | Actual Loss: 0.0920\n",
      "Baseline Loss: 2.8441 | Actual Loss: 0.1592\n",
      "Baseline Loss: 2.9126 | Actual Loss: 0.2208\n",
      "Baseline Loss: 2.7267 | Actual Loss: 0.1495\n",
      "Baseline Loss: 2.8111 | Actual Loss: 0.2058\n",
      "Baseline Loss: 2.9026 | Actual Loss: 0.2590\n",
      "Baseline Loss: 2.7971 | Actual Loss: 0.1484\n",
      "Baseline Loss: 2.8838 | Actual Loss: 0.3902\n",
      "Baseline Loss: 2.8123 | Actual Loss: 0.1843\n",
      "Baseline Loss: 2.7618 | Actual Loss: 0.1973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 161/1000 [00:52<04:24,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9117 | Actual Loss: 0.2129\n",
      "Baseline Loss: 2.6041 | Actual Loss: 0.0984\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2798\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2384\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2279\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3691\n",
      "Epoch 161/1000: Train Loss: 0.1937, Val Loss: 0.2788\n",
      "Baseline Loss: 2.8023 | Actual Loss: 0.2947\n",
      "Baseline Loss: 2.7896 | Actual Loss: 0.1378\n",
      "Baseline Loss: 2.8230 | Actual Loss: 0.1703\n",
      "Baseline Loss: 2.8804 | Actual Loss: 0.1471\n",
      "Baseline Loss: 2.7852 | Actual Loss: 0.2096\n",
      "Baseline Loss: 2.8628 | Actual Loss: 0.3299\n",
      "Baseline Loss: 2.8447 | Actual Loss: 0.2075\n",
      "Baseline Loss: 2.8372 | Actual Loss: 0.1306\n",
      "Baseline Loss: 2.7792 | Actual Loss: 0.1060\n",
      "Baseline Loss: 2.8198 | Actual Loss: 0.1504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 162/1000 [00:52<04:25,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8232 | Actual Loss: 0.1231\n",
      "Baseline Loss: 2.8262 | Actual Loss: 0.1282\n",
      "Baseline Loss: 2.8230 | Actual Loss: 0.0682\n",
      "Baseline Loss: 2.8955 | Actual Loss: 0.3268\n",
      "Baseline Loss: 2.8192 | Actual Loss: 0.1981\n",
      "Baseline Loss: 2.5950 | Actual Loss: 0.0507\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2008\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2347\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2392\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3382\n",
      "Epoch 162/1000: Train Loss: 0.1737, Val Loss: 0.2532\n",
      "Baseline Loss: 2.8187 | Actual Loss: 0.1639\n",
      "Baseline Loss: 2.7825 | Actual Loss: 0.1200\n",
      "Baseline Loss: 2.7964 | Actual Loss: 0.3479\n",
      "Baseline Loss: 2.8064 | Actual Loss: 0.2300\n",
      "Baseline Loss: 2.8645 | Actual Loss: 0.2935\n",
      "Baseline Loss: 2.8824 | Actual Loss: 0.1651\n",
      "Baseline Loss: 2.8519 | Actual Loss: 0.1500\n",
      "Baseline Loss: 2.8778 | Actual Loss: 0.2146\n",
      "Baseline Loss: 2.7665 | Actual Loss: 0.1528\n",
      "Baseline Loss: 2.8540 | Actual Loss: 0.1728\n",
      "Baseline Loss: 2.8203 | Actual Loss: 0.2719\n",
      "Baseline Loss: 2.7793 | Actual Loss: 0.0983\n",
      "Baseline Loss: 2.8841 | Actual Loss: 0.1380\n",
      "Baseline Loss: 2.8069 | Actual Loss: 0.1736\n",
      "Baseline Loss: 2.8152 | Actual Loss: 0.2303\n",
      "Baseline Loss: 2.4672 | Actual Loss: 0.0481\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2045\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▋        | 163/1000 [00:52<04:31,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7737 | Actual Loss: 0.2033\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.2286\n",
      "Epoch 163/1000: Train Loss: 0.1857, Val Loss: 0.2166\n",
      "New best validation loss: 0.2166\n",
      "Baseline Loss: 2.7609 | Actual Loss: 0.1679\n",
      "Baseline Loss: 2.8080 | Actual Loss: 0.1748\n",
      "Baseline Loss: 2.8349 | Actual Loss: 0.1260\n",
      "Baseline Loss: 2.8757 | Actual Loss: 0.2071\n",
      "Baseline Loss: 2.7710 | Actual Loss: 0.0984\n",
      "Baseline Loss: 2.8427 | Actual Loss: 0.1677\n",
      "Baseline Loss: 2.8541 | Actual Loss: 0.1472\n",
      "Baseline Loss: 2.8318 | Actual Loss: 0.2229\n",
      "Baseline Loss: 2.7865 | Actual Loss: 0.1547\n",
      "Baseline Loss: 2.7928 | Actual Loss: 0.1747\n",
      "Baseline Loss: 2.8481 | Actual Loss: 0.2599\n",
      "Baseline Loss: 2.8940 | Actual Loss: 0.1588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▋        | 164/1000 [00:53<04:18,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8472 | Actual Loss: 0.1514\n",
      "Baseline Loss: 2.8565 | Actual Loss: 0.1772\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.1668\n",
      "Baseline Loss: 2.5978 | Actual Loss: 0.1929\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2754\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3561\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2843\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.2692\n",
      "Epoch 164/1000: Train Loss: 0.1718, Val Loss: 0.2962\n",
      "Baseline Loss: 2.8817 | Actual Loss: 0.2622\n",
      "Baseline Loss: 2.7814 | Actual Loss: 0.1511\n",
      "Baseline Loss: 2.9171 | Actual Loss: 0.2533\n",
      "Baseline Loss: 2.7840 | Actual Loss: 0.1344\n",
      "Baseline Loss: 2.8286 | Actual Loss: 0.2595\n",
      "Baseline Loss: 2.7836 | Actual Loss: 0.1625\n",
      "Baseline Loss: 2.7984 | Actual Loss: 0.2313\n",
      "Baseline Loss: 2.8670 | Actual Loss: 0.1479\n",
      "Baseline Loss: 2.8750 | Actual Loss: 0.1689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▋        | 165/1000 [00:53<04:21,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8352 | Actual Loss: 0.1759\n",
      "Baseline Loss: 2.7990 | Actual Loss: 0.2218\n",
      "Baseline Loss: 2.8684 | Actual Loss: 0.1997\n",
      "Baseline Loss: 2.8476 | Actual Loss: 0.1836\n",
      "Baseline Loss: 2.8226 | Actual Loss: 0.2642\n",
      "Baseline Loss: 2.7896 | Actual Loss: 0.1650\n",
      "Baseline Loss: 2.5984 | Actual Loss: 0.0674\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.4348\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2526\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2689\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.2243\n",
      "Epoch 165/1000: Train Loss: 0.1906, Val Loss: 0.2952\n",
      "Baseline Loss: 2.9118 | Actual Loss: 0.1326\n",
      "Baseline Loss: 2.8223 | Actual Loss: 0.1352\n",
      "Baseline Loss: 2.8065 | Actual Loss: 0.2223\n",
      "Baseline Loss: 2.8713 | Actual Loss: 0.2188\n",
      "Baseline Loss: 2.8257 | Actual Loss: 0.1797\n",
      "Baseline Loss: 2.7909 | Actual Loss: 0.1773\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.1200\n",
      "Baseline Loss: 2.8573 | Actual Loss: 0.2126\n",
      "Baseline Loss: 2.8404 | Actual Loss: 0.0693\n",
      "Baseline Loss: 2.7794 | Actual Loss: 0.1869\n",
      "Baseline Loss: 2.8641 | Actual Loss: 0.1387\n",
      "Baseline Loss: 2.8464 | Actual Loss: 0.2479\n",
      "Baseline Loss: 2.8307 | Actual Loss: 0.1577\n",
      "Baseline Loss: 2.8882 | Actual Loss: 0.2060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 166/1000 [00:53<04:10,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7624 | Actual Loss: 0.3335\n",
      "Baseline Loss: 2.5906 | Actual Loss: 0.3559\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2710\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.1833\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3060\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3944\n",
      "Epoch 166/1000: Train Loss: 0.1934, Val Loss: 0.2887\n",
      "Baseline Loss: 2.8722 | Actual Loss: 0.1323\n",
      "Baseline Loss: 2.7818 | Actual Loss: 0.0944\n",
      "Baseline Loss: 2.8675 | Actual Loss: 0.3687\n",
      "Baseline Loss: 2.7519 | Actual Loss: 0.1982\n",
      "Baseline Loss: 2.8090 | Actual Loss: 0.1351\n",
      "Baseline Loss: 2.8467 | Actual Loss: 0.0737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 167/1000 [00:54<04:18,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7851 | Actual Loss: 0.2668\n",
      "Baseline Loss: 2.8916 | Actual Loss: 0.3949\n",
      "Baseline Loss: 2.7854 | Actual Loss: 0.1430\n",
      "Baseline Loss: 2.8857 | Actual Loss: 0.2422\n",
      "Baseline Loss: 2.8025 | Actual Loss: 0.2584\n",
      "Baseline Loss: 2.7853 | Actual Loss: 0.1750\n",
      "Baseline Loss: 2.8507 | Actual Loss: 0.1670\n",
      "Baseline Loss: 2.8773 | Actual Loss: 0.2454\n",
      "Baseline Loss: 2.8606 | Actual Loss: 0.1105\n",
      "Baseline Loss: 2.6360 | Actual Loss: 0.0585\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2193\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2191\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2436\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3093\n",
      "Epoch 167/1000: Train Loss: 0.1915, Val Loss: 0.2478\n",
      "Baseline Loss: 2.8296 | Actual Loss: 0.1964\n",
      "Baseline Loss: 2.8952 | Actual Loss: 0.1031\n",
      "Baseline Loss: 2.8354 | Actual Loss: 0.1670\n",
      "Baseline Loss: 2.7999 | Actual Loss: 0.3028\n",
      "Baseline Loss: 2.8409 | Actual Loss: 0.1593\n",
      "Baseline Loss: 2.7775 | Actual Loss: 0.1812\n",
      "Baseline Loss: 2.8364 | Actual Loss: 0.2938\n",
      "Baseline Loss: 2.7778 | Actual Loss: 0.2042\n",
      "Baseline Loss: 2.8241 | Actual Loss: 0.1825\n",
      "Baseline Loss: 2.8452 | Actual Loss: 0.1894\n",
      "Baseline Loss: 2.8593 | Actual Loss: 0.2768\n",
      "Baseline Loss: 2.8203 | Actual Loss: 0.1912\n",
      "Baseline Loss: 2.7914 | Actual Loss: 0.1175\n",
      "Baseline Loss: 2.8337 | Actual Loss: 0.1477\n",
      "Baseline Loss: 2.7546 | Actual Loss: 0.2184\n",
      "Baseline Loss: 2.6102 | Actual Loss: 0.0539\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 168/1000 [00:54<04:07,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8345 | Actual Loss: 0.1959\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2758\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.2986\n",
      "Epoch 168/1000: Train Loss: 0.1866, Val Loss: 0.2573\n",
      "Baseline Loss: 2.8350 | Actual Loss: 0.1232\n",
      "Baseline Loss: 2.9718 | Actual Loss: 0.1936\n",
      "Baseline Loss: 2.8028 | Actual Loss: 0.2196\n",
      "Baseline Loss: 2.8286 | Actual Loss: 0.2456\n",
      "Baseline Loss: 2.8263 | Actual Loss: 0.0953\n",
      "Baseline Loss: 2.7872 | Actual Loss: 0.1694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 169/1000 [00:54<04:20,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8069 | Actual Loss: 0.1385\n",
      "Baseline Loss: 2.7956 | Actual Loss: 0.1320\n",
      "Baseline Loss: 2.7486 | Actual Loss: 0.1259\n",
      "Baseline Loss: 2.8288 | Actual Loss: 0.2921\n",
      "Baseline Loss: 2.8721 | Actual Loss: 0.1004\n",
      "Baseline Loss: 2.8647 | Actual Loss: 0.1626\n",
      "Baseline Loss: 2.8384 | Actual Loss: 0.2461\n",
      "Baseline Loss: 2.8265 | Actual Loss: 0.0962\n",
      "Baseline Loss: 2.8117 | Actual Loss: 0.2796\n",
      "Baseline Loss: 2.5729 | Actual Loss: 0.3104\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2835\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2409\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2280\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3255\n",
      "Epoch 169/1000: Train Loss: 0.1832, Val Loss: 0.2695\n",
      "Baseline Loss: 2.7780 | Actual Loss: 0.2583\n",
      "Baseline Loss: 2.8731 | Actual Loss: 0.0990\n",
      "Baseline Loss: 2.7897 | Actual Loss: 0.1595\n",
      "Baseline Loss: 2.7690 | Actual Loss: 0.3104\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.0695\n",
      "Baseline Loss: 2.9018 | Actual Loss: 0.2970\n",
      "Baseline Loss: 2.8349 | Actual Loss: 0.1495\n",
      "Baseline Loss: 2.7640 | Actual Loss: 0.1826\n",
      "Baseline Loss: 2.8150 | Actual Loss: 0.1256\n",
      "Baseline Loss: 2.8811 | Actual Loss: 0.0950\n",
      "Baseline Loss: 2.8190 | Actual Loss: 0.1078\n",
      "Baseline Loss: 2.9226 | Actual Loss: 0.1817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 170/1000 [00:54<04:24,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9142 | Actual Loss: 0.1311\n",
      "Baseline Loss: 2.8067 | Actual Loss: 0.1817\n",
      "Baseline Loss: 2.8158 | Actual Loss: 0.2498\n",
      "Baseline Loss: 2.5083 | Actual Loss: 0.0467\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2833\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2457\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2195\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.2913\n",
      "Epoch 170/1000: Train Loss: 0.1653, Val Loss: 0.2599\n",
      "Baseline Loss: 2.9018 | Actual Loss: 0.1792\n",
      "Baseline Loss: 2.8142 | Actual Loss: 0.1157\n",
      "Baseline Loss: 2.8429 | Actual Loss: 0.1349\n",
      "Baseline Loss: 2.8541 | Actual Loss: 0.1144\n",
      "Baseline Loss: 2.7933 | Actual Loss: 0.1568\n",
      "Baseline Loss: 2.7714 | Actual Loss: 0.1361\n",
      "Baseline Loss: 2.7925 | Actual Loss: 0.1991\n",
      "Baseline Loss: 2.9278 | Actual Loss: 0.1159\n",
      "Baseline Loss: 2.8035 | Actual Loss: 0.2360\n",
      "Baseline Loss: 2.8224 | Actual Loss: 0.1891\n",
      "Baseline Loss: 2.8035 | Actual Loss: 0.2412\n",
      "Baseline Loss: 2.8046 | Actual Loss: 0.1458\n",
      "Baseline Loss: 2.7925 | Actual Loss: 0.1426\n",
      "Baseline Loss: 2.8867 | Actual Loss: 0.2265\n",
      "Baseline Loss: 2.8411 | Actual Loss: 0.2010\n",
      "Baseline Loss: 2.4610 | Actual Loss: 0.3031\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2756\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2462\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 171/1000 [00:55<04:29,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7548 | Actual Loss: 0.3342\n",
      "Epoch 171/1000: Train Loss: 0.1773, Val Loss: 0.2708\n",
      "Baseline Loss: 2.8053 | Actual Loss: 0.1826\n",
      "Baseline Loss: 2.8255 | Actual Loss: 0.2795\n",
      "Baseline Loss: 2.7639 | Actual Loss: 0.2917\n",
      "Baseline Loss: 2.8852 | Actual Loss: 0.1265\n",
      "Baseline Loss: 2.7975 | Actual Loss: 0.1820\n",
      "Baseline Loss: 2.8151 | Actual Loss: 0.2531\n",
      "Baseline Loss: 2.8002 | Actual Loss: 0.1783\n",
      "Baseline Loss: 2.8408 | Actual Loss: 0.1215\n",
      "Baseline Loss: 2.7988 | Actual Loss: 0.2917\n",
      "Baseline Loss: 2.8305 | Actual Loss: 0.3494\n",
      "Baseline Loss: 2.8256 | Actual Loss: 0.1871\n",
      "Baseline Loss: 2.7983 | Actual Loss: 0.2322\n",
      "Baseline Loss: 2.8251 | Actual Loss: 0.1039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 172/1000 [00:55<04:13,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8003 | Actual Loss: 0.1180\n",
      "Baseline Loss: 2.9166 | Actual Loss: 0.1834\n",
      "Baseline Loss: 2.7170 | Actual Loss: 0.0930\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2724\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.1776\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2350\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.2750\n",
      "Epoch 172/1000: Train Loss: 0.1984, Val Loss: 0.2400\n",
      "Baseline Loss: 2.7629 | Actual Loss: 0.1464\n",
      "Baseline Loss: 2.8014 | Actual Loss: 0.2151\n",
      "Baseline Loss: 2.7741 | Actual Loss: 0.2637\n",
      "Baseline Loss: 2.8691 | Actual Loss: 0.0946\n",
      "Baseline Loss: 2.8842 | Actual Loss: 0.1514\n",
      "Baseline Loss: 2.7902 | Actual Loss: 0.1823\n",
      "Baseline Loss: 2.7761 | Actual Loss: 0.1874\n",
      "Baseline Loss: 2.8386 | Actual Loss: 0.2053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 173/1000 [00:55<04:24,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8410 | Actual Loss: 0.1670\n",
      "Baseline Loss: 2.9364 | Actual Loss: 0.1261\n",
      "Baseline Loss: 2.8338 | Actual Loss: 0.1937\n",
      "Baseline Loss: 2.8130 | Actual Loss: 0.1610\n",
      "Baseline Loss: 2.7613 | Actual Loss: 0.0922\n",
      "Baseline Loss: 2.8269 | Actual Loss: 0.1801\n",
      "Baseline Loss: 2.8633 | Actual Loss: 0.1565\n",
      "Baseline Loss: 2.5326 | Actual Loss: 0.1534\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2625\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.1928\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2919\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3204\n",
      "Epoch 173/1000: Train Loss: 0.1673, Val Loss: 0.2669\n",
      "Baseline Loss: 2.8286 | Actual Loss: 0.2154\n",
      "Baseline Loss: 2.8332 | Actual Loss: 0.2264\n",
      "Baseline Loss: 2.8480 | Actual Loss: 0.1497\n",
      "Baseline Loss: 2.8772 | Actual Loss: 0.2127\n",
      "Baseline Loss: 2.7396 | Actual Loss: 0.1257\n",
      "Baseline Loss: 2.9259 | Actual Loss: 0.1056\n",
      "Baseline Loss: 2.8491 | Actual Loss: 0.1811\n",
      "Baseline Loss: 2.8309 | Actual Loss: 0.1981\n",
      "Baseline Loss: 2.9161 | Actual Loss: 0.0935\n",
      "Baseline Loss: 2.7865 | Actual Loss: 0.1019\n",
      "Baseline Loss: 2.8854 | Actual Loss: 0.1328\n",
      "Baseline Loss: 2.7718 | Actual Loss: 0.1832\n",
      "Baseline Loss: 2.8286 | Actual Loss: 0.1634\n",
      "Baseline Loss: 2.7944 | Actual Loss: 0.1924\n",
      "Baseline Loss: 2.7758 | Actual Loss: 0.0989\n",
      "Baseline Loss: 2.7329 | Actual Loss: 0.2362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 174/1000 [00:56<04:28,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8702 | Actual Loss: 0.2801\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3223\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2774\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.2956\n",
      "Epoch 174/1000: Train Loss: 0.1636, Val Loss: 0.2938\n",
      "Baseline Loss: 2.8824 | Actual Loss: 0.1526\n",
      "Baseline Loss: 2.7893 | Actual Loss: 0.1108\n",
      "Baseline Loss: 2.7848 | Actual Loss: 0.2159\n",
      "Baseline Loss: 2.7945 | Actual Loss: 0.2258\n",
      "Baseline Loss: 2.8776 | Actual Loss: 0.2842\n",
      "Baseline Loss: 2.8414 | Actual Loss: 0.2122\n",
      "Baseline Loss: 2.7991 | Actual Loss: 0.1382\n",
      "Baseline Loss: 2.9346 | Actual Loss: 0.1978\n",
      "Baseline Loss: 2.8721 | Actual Loss: 0.2038\n",
      "Baseline Loss: 2.7743 | Actual Loss: 0.1467\n",
      "Baseline Loss: 2.8638 | Actual Loss: 0.1982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 175/1000 [00:56<04:16,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8498 | Actual Loss: 0.1937\n",
      "Baseline Loss: 2.8776 | Actual Loss: 0.1710\n",
      "Baseline Loss: 2.7984 | Actual Loss: 0.2677\n",
      "Baseline Loss: 2.8541 | Actual Loss: 0.1008\n",
      "Baseline Loss: 2.6028 | Actual Loss: 0.0608\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3431\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3018\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.1900\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.4325\n",
      "Epoch 175/1000: Train Loss: 0.1800, Val Loss: 0.3169\n",
      "Baseline Loss: 2.8166 | Actual Loss: 0.2043\n",
      "Baseline Loss: 2.7786 | Actual Loss: 0.1726\n",
      "Baseline Loss: 2.7920 | Actual Loss: 0.1322\n",
      "Baseline Loss: 2.7780 | Actual Loss: 0.2616\n",
      "Baseline Loss: 2.8020 | Actual Loss: 0.1130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 176/1000 [00:56<04:25,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8367 | Actual Loss: 0.1546\n",
      "Baseline Loss: 2.8339 | Actual Loss: 0.1419\n",
      "Baseline Loss: 2.8305 | Actual Loss: 0.0767\n",
      "Baseline Loss: 2.8281 | Actual Loss: 0.1115\n",
      "Baseline Loss: 2.8545 | Actual Loss: 0.1149\n",
      "Baseline Loss: 2.8901 | Actual Loss: 0.2084\n",
      "Baseline Loss: 2.7386 | Actual Loss: 0.2094\n",
      "Baseline Loss: 2.8182 | Actual Loss: 0.1067\n",
      "Baseline Loss: 2.8704 | Actual Loss: 0.4234\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.1966\n",
      "Baseline Loss: 2.6278 | Actual Loss: 0.1187\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2628\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2290\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3172\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3267\n",
      "Epoch 176/1000: Train Loss: 0.1716, Val Loss: 0.2840\n",
      "Baseline Loss: 2.8458 | Actual Loss: 0.0990\n",
      "Baseline Loss: 2.7870 | Actual Loss: 0.0862\n",
      "Baseline Loss: 2.7981 | Actual Loss: 0.2398\n",
      "Baseline Loss: 2.8528 | Actual Loss: 0.2434\n",
      "Baseline Loss: 2.8876 | Actual Loss: 0.1389\n",
      "Baseline Loss: 2.8081 | Actual Loss: 0.2797\n",
      "Baseline Loss: 2.8528 | Actual Loss: 0.2281\n",
      "Baseline Loss: 2.8034 | Actual Loss: 0.0765\n",
      "Baseline Loss: 2.8784 | Actual Loss: 0.2861\n",
      "Baseline Loss: 2.8146 | Actual Loss: 0.1896\n",
      "Baseline Loss: 2.8695 | Actual Loss: 0.0752\n",
      "Baseline Loss: 2.8820 | Actual Loss: 0.1681\n",
      "Baseline Loss: 2.8168 | Actual Loss: 0.1668\n",
      "Baseline Loss: 2.8449 | Actual Loss: 0.1822\n",
      "Baseline Loss: 2.7693 | Actual Loss: 0.1491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 177/1000 [00:57<04:08,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.4416 | Actual Loss: 0.1992\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2646\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2411\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2176\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.4624\n",
      "Epoch 177/1000: Train Loss: 0.1755, Val Loss: 0.2964\n",
      "Baseline Loss: 2.9030 | Actual Loss: 0.1725\n",
      "Baseline Loss: 2.7590 | Actual Loss: 0.1927\n",
      "Baseline Loss: 2.8684 | Actual Loss: 0.2106\n",
      "Baseline Loss: 2.8064 | Actual Loss: 0.1496\n",
      "Baseline Loss: 2.7537 | Actual Loss: 0.1853\n",
      "Baseline Loss: 2.8622 | Actual Loss: 0.1558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 178/1000 [00:57<04:20,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8065 | Actual Loss: 0.1779\n",
      "Baseline Loss: 2.8752 | Actual Loss: 0.1713\n",
      "Baseline Loss: 2.8232 | Actual Loss: 0.1617\n",
      "Baseline Loss: 2.8124 | Actual Loss: 0.1462\n",
      "Baseline Loss: 2.8792 | Actual Loss: 0.1271\n",
      "Baseline Loss: 2.7794 | Actual Loss: 0.2388\n",
      "Baseline Loss: 2.7881 | Actual Loss: 0.2830\n",
      "Baseline Loss: 2.8829 | Actual Loss: 0.1054\n",
      "Baseline Loss: 2.8249 | Actual Loss: 0.1918\n",
      "Baseline Loss: 2.6038 | Actual Loss: 0.1227\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3362\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.1926\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3159\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3092\n",
      "Epoch 178/1000: Train Loss: 0.1745, Val Loss: 0.2885\n",
      "Baseline Loss: 2.8541 | Actual Loss: 0.1642\n",
      "Baseline Loss: 2.8274 | Actual Loss: 0.1923\n",
      "Baseline Loss: 2.8651 | Actual Loss: 0.2069\n",
      "Baseline Loss: 2.8689 | Actual Loss: 0.1701\n",
      "Baseline Loss: 2.7693 | Actual Loss: 0.1721\n",
      "Baseline Loss: 2.9036 | Actual Loss: 0.2202\n",
      "Baseline Loss: 2.7693 | Actual Loss: 0.2856\n",
      "Baseline Loss: 2.8503 | Actual Loss: 0.1062\n",
      "Baseline Loss: 2.8692 | Actual Loss: 0.2561\n",
      "Baseline Loss: 2.8226 | Actual Loss: 0.1720\n",
      "Baseline Loss: 2.7917 | Actual Loss: 0.2290\n",
      "Baseline Loss: 2.8105 | Actual Loss: 0.1328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 179/1000 [00:57<04:22,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8522 | Actual Loss: 0.2442\n",
      "Baseline Loss: 2.8990 | Actual Loss: 0.2411\n",
      "Baseline Loss: 2.8374 | Actual Loss: 0.1930\n",
      "Baseline Loss: 2.5883 | Actual Loss: 0.1164\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2864\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2429\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2895\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.2906\n",
      "Epoch 179/1000: Train Loss: 0.1939, Val Loss: 0.2773\n",
      "Baseline Loss: 2.8333 | Actual Loss: 0.3183\n",
      "Baseline Loss: 2.8208 | Actual Loss: 0.1290\n",
      "Baseline Loss: 2.8101 | Actual Loss: 0.1339\n",
      "Baseline Loss: 2.8669 | Actual Loss: 0.1256\n",
      "Baseline Loss: 2.8427 | Actual Loss: 0.2028\n",
      "Baseline Loss: 2.7770 | Actual Loss: 0.2291\n",
      "Baseline Loss: 2.7848 | Actual Loss: 0.1941\n",
      "Baseline Loss: 2.8402 | Actual Loss: 0.1601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 180/1000 [00:58<04:08,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8406 | Actual Loss: 0.2608\n",
      "Baseline Loss: 2.8370 | Actual Loss: 0.1779\n",
      "Baseline Loss: 2.9120 | Actual Loss: 0.1717\n",
      "Baseline Loss: 2.7975 | Actual Loss: 0.1833\n",
      "Baseline Loss: 2.8614 | Actual Loss: 0.1274\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2216\n",
      "Baseline Loss: 2.8656 | Actual Loss: 0.1646\n",
      "Baseline Loss: 2.4753 | Actual Loss: 0.1259\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2972\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2345\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2757\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3895\n",
      "Epoch 180/1000: Train Loss: 0.1829, Val Loss: 0.2992\n",
      "Baseline Loss: 2.8450 | Actual Loss: 0.2855\n",
      "Baseline Loss: 2.8412 | Actual Loss: 0.1884\n",
      "Baseline Loss: 2.8669 | Actual Loss: 0.1781\n",
      "Baseline Loss: 2.8064 | Actual Loss: 0.2564\n",
      "Baseline Loss: 2.7848 | Actual Loss: 0.0991\n",
      "Baseline Loss: 2.8945 | Actual Loss: 0.0924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 181/1000 [00:58<04:12,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8524 | Actual Loss: 0.1664\n",
      "Baseline Loss: 2.7949 | Actual Loss: 0.1133\n",
      "Baseline Loss: 2.8277 | Actual Loss: 0.2262\n",
      "Baseline Loss: 2.8157 | Actual Loss: 0.1760\n",
      "Baseline Loss: 2.8261 | Actual Loss: 0.1524\n",
      "Baseline Loss: 2.8736 | Actual Loss: 0.1611\n",
      "Baseline Loss: 2.8325 | Actual Loss: 0.2422\n",
      "Baseline Loss: 2.8103 | Actual Loss: 0.1004\n",
      "Baseline Loss: 2.8455 | Actual Loss: 0.1407\n",
      "Baseline Loss: 2.4565 | Actual Loss: 0.2172\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2415\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.1991\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2725\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.2323\n",
      "Epoch 181/1000: Train Loss: 0.1747, Val Loss: 0.2364\n",
      "Baseline Loss: 2.8666 | Actual Loss: 0.1695\n",
      "Baseline Loss: 2.8170 | Actual Loss: 0.2554\n",
      "Baseline Loss: 2.7982 | Actual Loss: 0.1556\n",
      "Baseline Loss: 2.7905 | Actual Loss: 0.1607\n",
      "Baseline Loss: 2.7732 | Actual Loss: 0.1375\n",
      "Baseline Loss: 2.8171 | Actual Loss: 0.2087\n",
      "Baseline Loss: 2.7992 | Actual Loss: 0.1580\n",
      "Baseline Loss: 2.8298 | Actual Loss: 0.1089\n",
      "Baseline Loss: 2.7568 | Actual Loss: 0.2814\n",
      "Baseline Loss: 2.9153 | Actual Loss: 0.1340\n",
      "Baseline Loss: 2.8634 | Actual Loss: 0.1138\n",
      "Baseline Loss: 2.7632 | Actual Loss: 0.1696\n",
      "Baseline Loss: 2.8654 | Actual Loss: 0.2141\n",
      "Baseline Loss: 2.8754 | Actual Loss: 0.2374\n",
      "Baseline Loss: 2.8294 | Actual Loss: 0.1339\n",
      "Baseline Loss: 2.4408 | Actual Loss: 0.0883\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 182/1000 [00:58<04:18,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8345 | Actual Loss: 0.1920\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2600\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3661\n",
      "Epoch 182/1000: Train Loss: 0.1704, Val Loss: 0.2712\n",
      "Baseline Loss: 2.8066 | Actual Loss: 0.0927\n",
      "Baseline Loss: 2.8391 | Actual Loss: 0.0895\n",
      "Baseline Loss: 2.8937 | Actual Loss: 0.1540\n",
      "Baseline Loss: 2.7890 | Actual Loss: 0.2675\n",
      "Baseline Loss: 2.8722 | Actual Loss: 0.1131\n",
      "Baseline Loss: 2.8039 | Actual Loss: 0.1454\n",
      "Baseline Loss: 2.8753 | Actual Loss: 0.1292\n",
      "Baseline Loss: 2.7883 | Actual Loss: 0.2464\n",
      "Baseline Loss: 2.7803 | Actual Loss: 0.1637\n",
      "Baseline Loss: 2.8559 | Actual Loss: 0.2085\n",
      "Baseline Loss: 2.7840 | Actual Loss: 0.2252\n",
      "Baseline Loss: 2.7920 | Actual Loss: 0.1392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 183/1000 [00:59<04:06,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9113 | Actual Loss: 0.1708\n",
      "Baseline Loss: 2.8379 | Actual Loss: 0.1294\n",
      "Baseline Loss: 2.8071 | Actual Loss: 0.1870\n",
      "Baseline Loss: 2.5519 | Actual Loss: 0.1208\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2492\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2054\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2420\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.2805\n",
      "Epoch 183/1000: Train Loss: 0.1614, Val Loss: 0.2443\n",
      "Baseline Loss: 2.8101 | Actual Loss: 0.1946\n",
      "Baseline Loss: 2.8502 | Actual Loss: 0.1877\n",
      "Baseline Loss: 2.8441 | Actual Loss: 0.1366\n",
      "Baseline Loss: 2.8771 | Actual Loss: 0.1737\n",
      "Baseline Loss: 2.8446 | Actual Loss: 0.3527\n",
      "Baseline Loss: 2.8274 | Actual Loss: 0.1946\n",
      "Baseline Loss: 2.7896 | Actual Loss: 0.1914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 184/1000 [00:59<04:13,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7662 | Actual Loss: 0.0844\n",
      "Baseline Loss: 2.8017 | Actual Loss: 0.1749\n",
      "Baseline Loss: 2.8486 | Actual Loss: 0.1872\n",
      "Baseline Loss: 2.8468 | Actual Loss: 0.1039\n",
      "Baseline Loss: 2.7804 | Actual Loss: 0.1527\n",
      "Baseline Loss: 2.7499 | Actual Loss: 0.1649\n",
      "Baseline Loss: 2.8342 | Actual Loss: 0.0979\n",
      "Baseline Loss: 2.8546 | Actual Loss: 0.2810\n",
      "Baseline Loss: 2.5457 | Actual Loss: 0.1217\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3631\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2194\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.1977\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.2391\n",
      "Epoch 184/1000: Train Loss: 0.1750, Val Loss: 0.2548\n",
      "Baseline Loss: 2.9039 | Actual Loss: 0.1280\n",
      "Baseline Loss: 2.8021 | Actual Loss: 0.2710\n",
      "Baseline Loss: 2.7875 | Actual Loss: 0.1602\n",
      "Baseline Loss: 2.8466 | Actual Loss: 0.1079\n",
      "Baseline Loss: 2.8164 | Actual Loss: 0.1504\n",
      "Baseline Loss: 2.8447 | Actual Loss: 0.2103\n",
      "Baseline Loss: 2.8818 | Actual Loss: 0.1522\n",
      "Baseline Loss: 2.8542 | Actual Loss: 0.2217\n",
      "Baseline Loss: 2.7792 | Actual Loss: 0.1682\n",
      "Baseline Loss: 2.7255 | Actual Loss: 0.2251\n",
      "Baseline Loss: 2.7931 | Actual Loss: 0.1955\n",
      "Baseline Loss: 2.8123 | Actual Loss: 0.4083\n",
      "Baseline Loss: 2.7407 | Actual Loss: 0.1498\n",
      "Baseline Loss: 2.8837 | Actual Loss: 0.1812\n",
      "Baseline Loss: 2.8421 | Actual Loss: 0.1005\n",
      "Baseline Loss: 2.4728 | Actual Loss: 0.0573\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3095\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 185/1000 [00:59<04:20,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7737 | Actual Loss: 0.1812\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.4245\n",
      "Epoch 185/1000: Train Loss: 0.1805, Val Loss: 0.2851\n",
      "Baseline Loss: 2.8663 | Actual Loss: 0.1269\n",
      "Baseline Loss: 2.8410 | Actual Loss: 0.1355\n",
      "Baseline Loss: 2.7921 | Actual Loss: 0.1135\n",
      "Baseline Loss: 2.8458 | Actual Loss: 0.1171\n",
      "Baseline Loss: 2.7656 | Actual Loss: 0.1695\n",
      "Baseline Loss: 2.8006 | Actual Loss: 0.2107\n",
      "Baseline Loss: 2.8304 | Actual Loss: 0.1512\n",
      "Baseline Loss: 2.8502 | Actual Loss: 0.1356\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.1721\n",
      "Baseline Loss: 2.8148 | Actual Loss: 0.1739\n",
      "Baseline Loss: 2.8707 | Actual Loss: 0.1957\n",
      "Baseline Loss: 2.8131 | Actual Loss: 0.2339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▊        | 186/1000 [00:59<04:09,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8274 | Actual Loss: 0.2112\n",
      "Baseline Loss: 2.8509 | Actual Loss: 0.1732\n",
      "Baseline Loss: 2.7769 | Actual Loss: 0.3415\n",
      "Baseline Loss: 2.5968 | Actual Loss: 0.1542\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2368\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2285\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3436\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.2806\n",
      "Epoch 186/1000: Train Loss: 0.1760, Val Loss: 0.2724\n",
      "Baseline Loss: 2.8782 | Actual Loss: 0.0941\n",
      "Baseline Loss: 2.8772 | Actual Loss: 0.1860\n",
      "Baseline Loss: 2.8977 | Actual Loss: 0.1268\n",
      "Baseline Loss: 2.7959 | Actual Loss: 0.1255\n",
      "Baseline Loss: 2.9017 | Actual Loss: 0.3254\n",
      "Baseline Loss: 2.8797 | Actual Loss: 0.1812\n",
      "Baseline Loss: 2.7782 | Actual Loss: 0.1876\n",
      "Baseline Loss: 2.7840 | Actual Loss: 0.1141\n",
      "Baseline Loss: 2.8117 | Actual Loss: 0.1668\n",
      "Baseline Loss: 2.7907 | Actual Loss: 0.1878\n",
      "Baseline Loss: 2.8487 | Actual Loss: 0.2108\n",
      "Baseline Loss: 2.8476 | Actual Loss: 0.1244\n",
      "Baseline Loss: 2.8926 | Actual Loss: 0.1345\n",
      "Baseline Loss: 2.7638 | Actual Loss: 0.2211\n",
      "Baseline Loss: 2.9275 | Actual Loss: 0.1877\n",
      "Baseline Loss: 2.5825 | Actual Loss: 0.3810\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3031\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2497\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▊        | 187/1000 [01:00<04:14,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7548 | Actual Loss: 0.2645\n",
      "Epoch 187/1000: Train Loss: 0.1847, Val Loss: 0.2728\n",
      "Baseline Loss: 2.8109 | Actual Loss: 0.1205\n",
      "Baseline Loss: 2.8469 | Actual Loss: 0.1425\n",
      "Baseline Loss: 2.8307 | Actual Loss: 0.2885\n",
      "Baseline Loss: 2.8864 | Actual Loss: 0.2552\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.1372\n",
      "Baseline Loss: 2.8260 | Actual Loss: 0.1372\n",
      "Baseline Loss: 2.8473 | Actual Loss: 0.1999\n",
      "Baseline Loss: 2.8640 | Actual Loss: 0.1958\n",
      "Baseline Loss: 2.8324 | Actual Loss: 0.1733\n",
      "Baseline Loss: 2.8402 | Actual Loss: 0.1097\n",
      "Baseline Loss: 2.8756 | Actual Loss: 0.1859\n",
      "Baseline Loss: 2.7816 | Actual Loss: 0.1556\n",
      "Baseline Loss: 2.7911 | Actual Loss: 0.1843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 188/1000 [01:00<04:20,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8186 | Actual Loss: 0.1537\n",
      "Baseline Loss: 2.7918 | Actual Loss: 0.1692\n",
      "Baseline Loss: 2.6161 | Actual Loss: 0.1988\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2618\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2065\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2664\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.2668\n",
      "Epoch 188/1000: Train Loss: 0.1754, Val Loss: 0.2504\n",
      "Baseline Loss: 2.8056 | Actual Loss: 0.1144\n",
      "Baseline Loss: 2.8307 | Actual Loss: 0.1253\n",
      "Baseline Loss: 2.8230 | Actual Loss: 0.1838\n",
      "Baseline Loss: 2.7763 | Actual Loss: 0.1505\n",
      "Baseline Loss: 2.7638 | Actual Loss: 0.1463\n",
      "Baseline Loss: 2.8650 | Actual Loss: 0.2350\n",
      "Baseline Loss: 2.8910 | Actual Loss: 0.1306\n",
      "Baseline Loss: 2.8235 | Actual Loss: 0.1692\n",
      "Baseline Loss: 2.8005 | Actual Loss: 0.2193\n",
      "Baseline Loss: 2.8040 | Actual Loss: 0.2043\n",
      "Baseline Loss: 2.9102 | Actual Loss: 0.4490\n",
      "Baseline Loss: 2.7681 | Actual Loss: 0.1700\n",
      "Baseline Loss: 2.8612 | Actual Loss: 0.1966\n",
      "Baseline Loss: 2.7876 | Actual Loss: 0.1902\n",
      "Baseline Loss: 2.8498 | Actual Loss: 0.1201\n",
      "Baseline Loss: 2.5996 | Actual Loss: 0.4220\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2763\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2623\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 189/1000 [01:00<04:10,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7548 | Actual Loss: 0.4865\n",
      "Epoch 189/1000: Train Loss: 0.2017, Val Loss: 0.3508\n",
      "Baseline Loss: 2.8651 | Actual Loss: 0.1578\n",
      "Baseline Loss: 2.8572 | Actual Loss: 0.1537\n",
      "Baseline Loss: 2.8739 | Actual Loss: 0.1143\n",
      "Baseline Loss: 2.9287 | Actual Loss: 0.2119\n",
      "Baseline Loss: 2.7974 | Actual Loss: 0.1768\n",
      "Baseline Loss: 2.8428 | Actual Loss: 0.2248\n",
      "Baseline Loss: 2.8585 | Actual Loss: 0.1453\n",
      "Baseline Loss: 2.7964 | Actual Loss: 0.1843\n",
      "Baseline Loss: 2.8991 | Actual Loss: 0.0913\n",
      "Baseline Loss: 2.8935 | Actual Loss: 0.1638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 190/1000 [01:01<04:14,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7949 | Actual Loss: 0.1574\n",
      "Baseline Loss: 2.8198 | Actual Loss: 0.1224\n",
      "Baseline Loss: 2.8174 | Actual Loss: 0.1905\n",
      "Baseline Loss: 2.7988 | Actual Loss: 0.1586\n",
      "Baseline Loss: 2.7904 | Actual Loss: 0.1902\n",
      "Baseline Loss: 2.4941 | Actual Loss: 0.3538\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2372\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2329\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.3247\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3539\n",
      "Epoch 190/1000: Train Loss: 0.1748, Val Loss: 0.2872\n",
      "Baseline Loss: 2.8025 | Actual Loss: 0.1005\n",
      "Baseline Loss: 2.8229 | Actual Loss: 0.1130\n",
      "Baseline Loss: 2.9081 | Actual Loss: 0.1778\n",
      "Baseline Loss: 2.7799 | Actual Loss: 0.1972\n",
      "Baseline Loss: 2.7915 | Actual Loss: 0.3163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 191/1000 [01:01<04:01,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8748 | Actual Loss: 0.1122\n",
      "Baseline Loss: 2.8489 | Actual Loss: 0.2121\n",
      "Baseline Loss: 2.8382 | Actual Loss: 0.1510\n",
      "Baseline Loss: 2.8906 | Actual Loss: 0.1793\n",
      "Baseline Loss: 2.8241 | Actual Loss: 0.2167\n",
      "Baseline Loss: 2.7620 | Actual Loss: 0.1389\n",
      "Baseline Loss: 2.9078 | Actual Loss: 0.2493\n",
      "Baseline Loss: 2.8797 | Actual Loss: 0.0549\n",
      "Baseline Loss: 2.9052 | Actual Loss: 0.1513\n",
      "Baseline Loss: 2.8269 | Actual Loss: 0.1151\n",
      "Baseline Loss: 2.4302 | Actual Loss: 0.1320\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3017\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.1680\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.1988\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.2243\n",
      "Epoch 191/1000: Train Loss: 0.1636, Val Loss: 0.2232\n",
      "Baseline Loss: 2.8478 | Actual Loss: 0.2011\n",
      "Baseline Loss: 2.7346 | Actual Loss: 0.2238\n",
      "Baseline Loss: 2.8292 | Actual Loss: 0.2258\n",
      "Baseline Loss: 2.9169 | Actual Loss: 0.2798\n",
      "Baseline Loss: 2.8257 | Actual Loss: 0.1303\n",
      "Baseline Loss: 2.8990 | Actual Loss: 0.1632\n",
      "Baseline Loss: 2.8140 | Actual Loss: 0.0844\n",
      "Baseline Loss: 2.9196 | Actual Loss: 0.1595\n",
      "Baseline Loss: 2.8525 | Actual Loss: 0.1022\n",
      "Baseline Loss: 2.8469 | Actual Loss: 0.2115\n",
      "Baseline Loss: 2.7952 | Actual Loss: 0.1961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 192/1000 [01:01<04:09,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8577 | Actual Loss: 0.2587\n",
      "Baseline Loss: 2.8216 | Actual Loss: 0.1303\n",
      "Baseline Loss: 2.7584 | Actual Loss: 0.2185\n",
      "Baseline Loss: 2.8339 | Actual Loss: 0.1785\n",
      "Baseline Loss: 2.6443 | Actual Loss: 0.1679\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2327\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.1963\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2496\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3156\n",
      "Epoch 192/1000: Train Loss: 0.1832, Val Loss: 0.2486\n",
      "Baseline Loss: 2.8323 | Actual Loss: 0.1775\n",
      "Baseline Loss: 2.7974 | Actual Loss: 0.0918\n",
      "Baseline Loss: 2.9221 | Actual Loss: 0.1232\n",
      "Baseline Loss: 2.8140 | Actual Loss: 0.1565\n",
      "Baseline Loss: 2.8245 | Actual Loss: 0.1331\n",
      "Baseline Loss: 2.8466 | Actual Loss: 0.0859\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.2006\n",
      "Baseline Loss: 2.8032 | Actual Loss: 0.1351\n",
      "Baseline Loss: 2.8000 | Actual Loss: 0.0937\n",
      "Baseline Loss: 2.7999 | Actual Loss: 0.1156\n",
      "Baseline Loss: 2.8564 | Actual Loss: 0.1147\n",
      "Baseline Loss: 2.8674 | Actual Loss: 0.1589\n",
      "Baseline Loss: 2.8235 | Actual Loss: 0.1329\n",
      "Baseline Loss: 2.8130 | Actual Loss: 0.1251\n",
      "Baseline Loss: 2.8327 | Actual Loss: 0.1328\n",
      "Baseline Loss: 2.4215 | Actual Loss: 0.2967\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2316\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 193/1000 [01:02<04:19,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7737 | Actual Loss: 0.2631\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.2889\n",
      "Epoch 193/1000: Train Loss: 0.1421, Val Loss: 0.2491\n",
      "Baseline Loss: 2.8072 | Actual Loss: 0.1682\n",
      "Baseline Loss: 2.9276 | Actual Loss: 0.1249\n",
      "Baseline Loss: 2.8453 | Actual Loss: 0.1653\n",
      "Baseline Loss: 2.7744 | Actual Loss: 0.2605\n",
      "Baseline Loss: 2.7847 | Actual Loss: 0.1852\n",
      "Baseline Loss: 2.7835 | Actual Loss: 0.1026\n",
      "Baseline Loss: 2.7570 | Actual Loss: 0.0940\n",
      "Baseline Loss: 2.8463 | Actual Loss: 0.1109\n",
      "Baseline Loss: 2.8790 | Actual Loss: 0.1448\n",
      "Baseline Loss: 2.8708 | Actual Loss: 0.1246\n",
      "Baseline Loss: 2.9058 | Actual Loss: 0.1431\n",
      "Baseline Loss: 2.8031 | Actual Loss: 0.1477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 194/1000 [01:02<04:08,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8242 | Actual Loss: 0.0654\n",
      "Baseline Loss: 2.8651 | Actual Loss: 0.1710\n",
      "Baseline Loss: 2.8216 | Actual Loss: 0.1429\n",
      "Baseline Loss: 2.5760 | Actual Loss: 0.1518\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2694\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2101\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2269\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.1999\n",
      "Epoch 194/1000: Train Loss: 0.1439, Val Loss: 0.2266\n",
      "Baseline Loss: 2.8466 | Actual Loss: 0.1066\n",
      "Baseline Loss: 2.7490 | Actual Loss: 0.2811\n",
      "Baseline Loss: 2.8835 | Actual Loss: 0.2192\n",
      "Baseline Loss: 2.8126 | Actual Loss: 0.1599\n",
      "Baseline Loss: 2.9273 | Actual Loss: 0.1128\n",
      "Baseline Loss: 2.7325 | Actual Loss: 0.0983\n",
      "Baseline Loss: 2.8040 | Actual Loss: 0.1430\n",
      "Baseline Loss: 2.8553 | Actual Loss: 0.2628\n",
      "Baseline Loss: 2.8782 | Actual Loss: 0.0851\n",
      "Baseline Loss: 2.8009 | Actual Loss: 0.1665\n",
      "Baseline Loss: 2.7965 | Actual Loss: 0.1498\n",
      "Baseline Loss: 2.7989 | Actual Loss: 0.1189\n",
      "Baseline Loss: 2.7684 | Actual Loss: 0.1245\n",
      "Baseline Loss: 2.9355 | Actual Loss: 0.1510\n",
      "Baseline Loss: 2.9263 | Actual Loss: 0.1562\n",
      "Baseline Loss: 2.4386 | Actual Loss: 0.0519\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2388\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.1865\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 195/1000 [01:02<04:11,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7548 | Actual Loss: 0.4041\n",
      "Epoch 195/1000: Train Loss: 0.1492, Val Loss: 0.2659\n",
      "Baseline Loss: 2.8593 | Actual Loss: 0.1242\n",
      "Baseline Loss: 2.8719 | Actual Loss: 0.1723\n",
      "Baseline Loss: 2.8283 | Actual Loss: 0.1289\n",
      "Baseline Loss: 2.8386 | Actual Loss: 0.1468\n",
      "Baseline Loss: 2.7960 | Actual Loss: 0.0883\n",
      "Baseline Loss: 2.7910 | Actual Loss: 0.1861\n",
      "Baseline Loss: 2.8166 | Actual Loss: 0.1029\n",
      "Baseline Loss: 2.8378 | Actual Loss: 0.0579\n",
      "Baseline Loss: 2.7953 | Actual Loss: 0.0967\n",
      "Baseline Loss: 2.8279 | Actual Loss: 0.0982\n",
      "Baseline Loss: 2.7808 | Actual Loss: 0.1240\n",
      "Baseline Loss: 2.7760 | Actual Loss: 0.2405\n",
      "Baseline Loss: 2.7910 | Actual Loss: 0.1526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 196/1000 [01:03<03:59,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8024 | Actual Loss: 0.1022\n",
      "Baseline Loss: 2.8689 | Actual Loss: 0.1050\n",
      "Baseline Loss: 2.6953 | Actual Loss: 0.2932\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2521\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.1929\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2719\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.2328\n",
      "Epoch 196/1000: Train Loss: 0.1387, Val Loss: 0.2374\n",
      "Baseline Loss: 2.9012 | Actual Loss: 0.1055\n",
      "Baseline Loss: 2.7288 | Actual Loss: 0.1425\n",
      "Baseline Loss: 2.8726 | Actual Loss: 0.1461\n",
      "Baseline Loss: 2.8456 | Actual Loss: 0.2285\n",
      "Baseline Loss: 2.8235 | Actual Loss: 0.1691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 197/1000 [01:03<04:06,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8643 | Actual Loss: 0.1587\n",
      "Baseline Loss: 2.8425 | Actual Loss: 0.1645\n",
      "Baseline Loss: 2.7682 | Actual Loss: 0.1519\n",
      "Baseline Loss: 2.8171 | Actual Loss: 0.1742\n",
      "Baseline Loss: 2.8584 | Actual Loss: 0.2009\n",
      "Baseline Loss: 2.8558 | Actual Loss: 0.1718\n",
      "Baseline Loss: 2.8355 | Actual Loss: 0.1025\n",
      "Baseline Loss: 2.8670 | Actual Loss: 0.1557\n",
      "Baseline Loss: 2.8759 | Actual Loss: 0.1001\n",
      "Baseline Loss: 2.7746 | Actual Loss: 0.2694\n",
      "Baseline Loss: 2.3955 | Actual Loss: 0.1090\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2408\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2115\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2918\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.2788\n",
      "Epoch 197/1000: Train Loss: 0.1594, Val Loss: 0.2557\n",
      "Baseline Loss: 2.7728 | Actual Loss: 0.2063\n",
      "Baseline Loss: 2.8354 | Actual Loss: 0.0767\n",
      "Baseline Loss: 2.8825 | Actual Loss: 0.3474\n",
      "Baseline Loss: 2.7943 | Actual Loss: 0.1343\n",
      "Baseline Loss: 2.8504 | Actual Loss: 0.0785\n",
      "Baseline Loss: 2.8332 | Actual Loss: 0.1188\n",
      "Baseline Loss: 2.8164 | Actual Loss: 0.2579\n",
      "Baseline Loss: 2.8075 | Actual Loss: 0.1447\n",
      "Baseline Loss: 2.8099 | Actual Loss: 0.1848\n",
      "Baseline Loss: 2.7834 | Actual Loss: 0.0982\n",
      "Baseline Loss: 2.8015 | Actual Loss: 0.1451\n",
      "Baseline Loss: 2.8342 | Actual Loss: 0.1156\n",
      "Baseline Loss: 2.9088 | Actual Loss: 0.2430\n",
      "Baseline Loss: 2.8817 | Actual Loss: 0.1085\n",
      "Baseline Loss: 2.7637 | Actual Loss: 0.2523\n",
      "Baseline Loss: 2.6090 | Actual Loss: 0.0785\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 198/1000 [01:03<04:13,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8345 | Actual Loss: 0.2308\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2441\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.2856\n",
      "Epoch 198/1000: Train Loss: 0.1619, Val Loss: 0.2491\n",
      "Baseline Loss: 2.8276 | Actual Loss: 0.1660\n",
      "Baseline Loss: 2.8059 | Actual Loss: 0.1945\n",
      "Baseline Loss: 2.8592 | Actual Loss: 0.1165\n",
      "Baseline Loss: 2.8061 | Actual Loss: 0.1081\n",
      "Baseline Loss: 2.8844 | Actual Loss: 0.0678\n",
      "Baseline Loss: 2.8175 | Actual Loss: 0.1471\n",
      "Baseline Loss: 2.7917 | Actual Loss: 0.1204\n",
      "Baseline Loss: 2.7862 | Actual Loss: 0.0628\n",
      "Baseline Loss: 2.8446 | Actual Loss: 0.0911\n",
      "Baseline Loss: 2.8125 | Actual Loss: 0.2020\n",
      "Baseline Loss: 2.7808 | Actual Loss: 0.0920\n",
      "Baseline Loss: 2.7646 | Actual Loss: 0.1056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 199/1000 [01:03<04:00,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8073 | Actual Loss: 0.1818\n",
      "Baseline Loss: 2.8050 | Actual Loss: 0.1488\n",
      "Baseline Loss: 2.9297 | Actual Loss: 0.1611\n",
      "Baseline Loss: 2.5934 | Actual Loss: 0.1103\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3179\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2028\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2891\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3016\n",
      "Epoch 199/1000: Train Loss: 0.1297, Val Loss: 0.2779\n",
      "Baseline Loss: 2.8100 | Actual Loss: 0.0726\n",
      "Baseline Loss: 2.9102 | Actual Loss: 0.1468\n",
      "Baseline Loss: 2.8169 | Actual Loss: 0.0703\n",
      "Baseline Loss: 2.9027 | Actual Loss: 0.2073\n",
      "Baseline Loss: 2.7528 | Actual Loss: 0.1318\n",
      "Baseline Loss: 2.7877 | Actual Loss: 0.2898\n",
      "Baseline Loss: 2.8612 | Actual Loss: 0.0645\n",
      "Baseline Loss: 2.8624 | Actual Loss: 0.2526\n",
      "Baseline Loss: 2.8461 | Actual Loss: 0.1222\n",
      "Baseline Loss: 2.8253 | Actual Loss: 0.1289\n",
      "Baseline Loss: 2.8196 | Actual Loss: 0.1637\n",
      "Baseline Loss: 2.8584 | Actual Loss: 0.1054\n",
      "Baseline Loss: 2.8518 | Actual Loss: 0.1294\n",
      "Baseline Loss: 2.8524 | Actual Loss: 0.1731\n",
      "Baseline Loss: 2.8338 | Actual Loss: 0.1180\n",
      "Baseline Loss: 2.4512 | Actual Loss: 0.0601\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2989\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2141\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 200/1000 [01:04<04:08,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7548 | Actual Loss: 0.2771\n",
      "Epoch 200/1000: Train Loss: 0.1398, Val Loss: 0.2685\n",
      "Baseline Loss: 2.8151 | Actual Loss: 0.1808\n",
      "Baseline Loss: 2.8543 | Actual Loss: 0.1608\n",
      "Baseline Loss: 2.8245 | Actual Loss: 0.1092\n",
      "Baseline Loss: 2.7823 | Actual Loss: 0.2226\n",
      "Baseline Loss: 2.8885 | Actual Loss: 0.1484\n",
      "Baseline Loss: 2.7774 | Actual Loss: 0.0839\n",
      "Baseline Loss: 2.8131 | Actual Loss: 0.1108\n",
      "Baseline Loss: 2.9043 | Actual Loss: 0.1880\n",
      "Baseline Loss: 2.8094 | Actual Loss: 0.2702\n",
      "Baseline Loss: 2.7818 | Actual Loss: 0.1402\n",
      "Baseline Loss: 2.8677 | Actual Loss: 0.0763\n",
      "Baseline Loss: 2.9068 | Actual Loss: 0.1954\n",
      "Baseline Loss: 2.7592 | Actual Loss: 0.1564\n",
      "Baseline Loss: 2.7622 | Actual Loss: 0.0983\n",
      "Baseline Loss: 2.9088 | Actual Loss: 0.2159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 201/1000 [01:04<03:54,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7041 | Actual Loss: 0.1165\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2458\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.1351\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2488\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3129\n",
      "Epoch 201/1000: Train Loss: 0.1546, Val Loss: 0.2356\n",
      "Baseline Loss: 2.8183 | Actual Loss: 0.2074\n",
      "Baseline Loss: 2.8088 | Actual Loss: 0.1961\n",
      "Baseline Loss: 2.8007 | Actual Loss: 0.1232\n",
      "Baseline Loss: 2.7837 | Actual Loss: 0.1581\n",
      "Baseline Loss: 2.7837 | Actual Loss: 0.1259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 202/1000 [01:04<04:05,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8940 | Actual Loss: 0.1204\n",
      "Baseline Loss: 2.8506 | Actual Loss: 0.1388\n",
      "Baseline Loss: 2.8454 | Actual Loss: 0.1453\n",
      "Baseline Loss: 2.7101 | Actual Loss: 0.0800\n",
      "Baseline Loss: 2.9244 | Actual Loss: 0.1865\n",
      "Baseline Loss: 2.8386 | Actual Loss: 0.1730\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.1183\n",
      "Baseline Loss: 2.8500 | Actual Loss: 0.1971\n",
      "Baseline Loss: 2.8807 | Actual Loss: 0.1658\n",
      "Baseline Loss: 2.7978 | Actual Loss: 0.1572\n",
      "Baseline Loss: 2.5227 | Actual Loss: 0.3777\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2529\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2045\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2867\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.2527\n",
      "Epoch 202/1000: Train Loss: 0.1669, Val Loss: 0.2492\n",
      "Baseline Loss: 2.8101 | Actual Loss: 0.1420\n",
      "Baseline Loss: 2.8056 | Actual Loss: 0.1156\n",
      "Baseline Loss: 2.8257 | Actual Loss: 0.1918\n",
      "Baseline Loss: 2.7871 | Actual Loss: 0.2334\n",
      "Baseline Loss: 2.7727 | Actual Loss: 0.1416\n",
      "Baseline Loss: 2.8653 | Actual Loss: 0.2381\n",
      "Baseline Loss: 2.8664 | Actual Loss: 0.1801\n",
      "Baseline Loss: 2.8131 | Actual Loss: 0.1694\n",
      "Baseline Loss: 2.7911 | Actual Loss: 0.1849\n",
      "Baseline Loss: 2.8143 | Actual Loss: 0.1307\n",
      "Baseline Loss: 2.8990 | Actual Loss: 0.1423\n",
      "Baseline Loss: 2.8636 | Actual Loss: 0.3455\n",
      "Baseline Loss: 2.8716 | Actual Loss: 0.1243\n",
      "Baseline Loss: 2.8203 | Actual Loss: 0.1153\n",
      "Baseline Loss: 2.8793 | Actual Loss: 0.1558\n",
      "Baseline Loss: 2.5903 | Actual Loss: 0.0833\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 203/1000 [01:05<04:10,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8345 | Actual Loss: 0.1922\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.1958\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3982\n",
      "Epoch 203/1000: Train Loss: 0.1684, Val Loss: 0.2478\n",
      "Baseline Loss: 2.8433 | Actual Loss: 0.2239\n",
      "Baseline Loss: 2.7867 | Actual Loss: 0.1498\n",
      "Baseline Loss: 2.8355 | Actual Loss: 0.1441\n",
      "Baseline Loss: 2.8644 | Actual Loss: 0.1726\n",
      "Baseline Loss: 2.8660 | Actual Loss: 0.1438\n",
      "Baseline Loss: 2.8635 | Actual Loss: 0.2217\n",
      "Baseline Loss: 2.8440 | Actual Loss: 0.1052\n",
      "Baseline Loss: 2.8386 | Actual Loss: 0.1450\n",
      "Baseline Loss: 2.8065 | Actual Loss: 0.1468\n",
      "Baseline Loss: 2.7839 | Actual Loss: 0.1219\n",
      "Baseline Loss: 2.8463 | Actual Loss: 0.1688\n",
      "Baseline Loss: 2.9292 | Actual Loss: 0.1618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 204/1000 [01:05<03:55,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8014 | Actual Loss: 0.1206\n",
      "Baseline Loss: 2.8056 | Actual Loss: 0.2156\n",
      "Baseline Loss: 2.8154 | Actual Loss: 0.1624\n",
      "Baseline Loss: 2.5825 | Actual Loss: 0.1455\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2182\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2425\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2718\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.2235\n",
      "Epoch 204/1000: Train Loss: 0.1593, Val Loss: 0.2390\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1468\n",
      "Baseline Loss: 2.7870 | Actual Loss: 0.1135\n",
      "Baseline Loss: 2.7974 | Actual Loss: 0.1465\n",
      "Baseline Loss: 2.7993 | Actual Loss: 0.0919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 205/1000 [01:05<04:07,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8120 | Actual Loss: 0.0666\n",
      "Baseline Loss: 2.8698 | Actual Loss: 0.1960\n",
      "Baseline Loss: 2.8820 | Actual Loss: 0.1703\n",
      "Baseline Loss: 2.8364 | Actual Loss: 0.1411\n",
      "Baseline Loss: 2.8870 | Actual Loss: 0.2833\n",
      "Baseline Loss: 2.8677 | Actual Loss: 0.3203\n",
      "Baseline Loss: 2.8271 | Actual Loss: 0.1466\n",
      "Baseline Loss: 2.8380 | Actual Loss: 0.1962\n",
      "Baseline Loss: 2.8672 | Actual Loss: 0.1061\n",
      "Baseline Loss: 2.8166 | Actual Loss: 0.1514\n",
      "Baseline Loss: 2.8239 | Actual Loss: 0.2344\n",
      "Baseline Loss: 2.4405 | Actual Loss: 0.0340\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3208\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2464\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2709\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3147\n",
      "Epoch 205/1000: Train Loss: 0.1591, Val Loss: 0.2882\n",
      "Baseline Loss: 2.8042 | Actual Loss: 0.1580\n",
      "Baseline Loss: 2.8396 | Actual Loss: 0.1246\n",
      "Baseline Loss: 2.8874 | Actual Loss: 0.0983\n",
      "Baseline Loss: 2.8571 | Actual Loss: 0.2149\n",
      "Baseline Loss: 2.8443 | Actual Loss: 0.2112\n",
      "Baseline Loss: 2.8163 | Actual Loss: 0.1428\n",
      "Baseline Loss: 2.7921 | Actual Loss: 0.1814\n",
      "Baseline Loss: 2.8634 | Actual Loss: 0.1757\n",
      "Baseline Loss: 2.8072 | Actual Loss: 0.1234\n",
      "Baseline Loss: 2.8104 | Actual Loss: 0.1364\n",
      "Baseline Loss: 2.8959 | Actual Loss: 0.1049\n",
      "Baseline Loss: 2.8433 | Actual Loss: 0.0759\n",
      "Baseline Loss: 2.8148 | Actual Loss: 0.2184\n",
      "Baseline Loss: 2.8585 | Actual Loss: 0.1323\n",
      "Baseline Loss: 2.8584 | Actual Loss: 0.1528\n",
      "Baseline Loss: 2.6594 | Actual Loss: 0.0744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 206/1000 [01:06<04:12,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8702 | Actual Loss: 0.2413\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3060\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.1985\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.2998\n",
      "Epoch 206/1000: Train Loss: 0.1453, Val Loss: 0.2614\n",
      "Baseline Loss: 2.7271 | Actual Loss: 0.1367\n",
      "Baseline Loss: 2.8707 | Actual Loss: 0.1205\n",
      "Baseline Loss: 2.9485 | Actual Loss: 0.2428\n",
      "Baseline Loss: 2.7775 | Actual Loss: 0.1463\n",
      "Baseline Loss: 2.7649 | Actual Loss: 0.1308\n",
      "Baseline Loss: 2.8067 | Actual Loss: 0.1775\n",
      "Baseline Loss: 2.8346 | Actual Loss: 0.1635\n",
      "Baseline Loss: 2.8691 | Actual Loss: 0.1384\n",
      "Baseline Loss: 2.8354 | Actual Loss: 0.1753\n",
      "Baseline Loss: 2.9951 | Actual Loss: 0.0950\n",
      "Baseline Loss: 2.7947 | Actual Loss: 0.0936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 207/1000 [01:06<03:58,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7732 | Actual Loss: 0.1377\n",
      "Baseline Loss: 2.8360 | Actual Loss: 0.0608\n",
      "Baseline Loss: 2.8206 | Actual Loss: 0.0559\n",
      "Baseline Loss: 2.8016 | Actual Loss: 0.1788\n",
      "Baseline Loss: 2.6204 | Actual Loss: 0.1592\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2349\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.1400\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2297\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.4332\n",
      "Epoch 207/1000: Train Loss: 0.1383, Val Loss: 0.2594\n",
      "Baseline Loss: 2.8658 | Actual Loss: 0.0635\n",
      "Baseline Loss: 2.8727 | Actual Loss: 0.2116\n",
      "Baseline Loss: 2.8220 | Actual Loss: 0.0639\n",
      "Baseline Loss: 2.8881 | Actual Loss: 0.2560\n",
      "Baseline Loss: 2.7914 | Actual Loss: 0.1351\n",
      "Baseline Loss: 2.8228 | Actual Loss: 0.1157\n",
      "Baseline Loss: 2.8877 | Actual Loss: 0.1762\n",
      "Baseline Loss: 2.8855 | Actual Loss: 0.1459\n",
      "Baseline Loss: 2.8222 | Actual Loss: 0.1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 208/1000 [01:06<04:05,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7873 | Actual Loss: 0.1596\n",
      "Baseline Loss: 2.8730 | Actual Loss: 0.1732\n",
      "Baseline Loss: 2.8012 | Actual Loss: 0.2023\n",
      "Baseline Loss: 2.7997 | Actual Loss: 0.2014\n",
      "Baseline Loss: 2.8139 | Actual Loss: 0.1856\n",
      "Baseline Loss: 2.8047 | Actual Loss: 0.1952\n",
      "Baseline Loss: 2.5474 | Actual Loss: 0.0349\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.3339\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2021\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2216\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.2718\n",
      "Epoch 208/1000: Train Loss: 0.1568, Val Loss: 0.2573\n",
      "Baseline Loss: 2.8439 | Actual Loss: 0.1405\n",
      "Baseline Loss: 2.8281 | Actual Loss: 0.2080\n",
      "Baseline Loss: 2.8434 | Actual Loss: 0.1201\n",
      "Baseline Loss: 2.8016 | Actual Loss: 0.1078\n",
      "Baseline Loss: 2.8122 | Actual Loss: 0.1607\n",
      "Baseline Loss: 2.9154 | Actual Loss: 0.1451\n",
      "Baseline Loss: 2.8127 | Actual Loss: 0.2345\n",
      "Baseline Loss: 2.8530 | Actual Loss: 0.1462\n",
      "Baseline Loss: 2.7987 | Actual Loss: 0.1856\n",
      "Baseline Loss: 2.8426 | Actual Loss: 0.1305\n",
      "Baseline Loss: 2.8404 | Actual Loss: 0.1365\n",
      "Baseline Loss: 2.8141 | Actual Loss: 0.2083\n",
      "Baseline Loss: 2.8205 | Actual Loss: 0.1418\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.1438\n",
      "Baseline Loss: 2.8473 | Actual Loss: 0.0853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 209/1000 [01:07<03:51,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5005 | Actual Loss: 0.0845\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2214\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.1596\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2667\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.2246\n",
      "Epoch 209/1000: Train Loss: 0.1487, Val Loss: 0.2181\n",
      "Baseline Loss: 2.8486 | Actual Loss: 0.1924\n",
      "Baseline Loss: 2.8089 | Actual Loss: 0.1615\n",
      "Baseline Loss: 2.9106 | Actual Loss: 0.0876\n",
      "Baseline Loss: 2.9288 | Actual Loss: 0.2437\n",
      "Baseline Loss: 2.7441 | Actual Loss: 0.1585\n",
      "Baseline Loss: 2.7319 | Actual Loss: 0.1767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 210/1000 [01:07<04:02,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9466 | Actual Loss: 0.0962\n",
      "Baseline Loss: 2.8774 | Actual Loss: 0.3271\n",
      "Baseline Loss: 2.7822 | Actual Loss: 0.1122\n",
      "Baseline Loss: 2.7843 | Actual Loss: 0.0948\n",
      "Baseline Loss: 2.8244 | Actual Loss: 0.1001\n",
      "Baseline Loss: 2.7852 | Actual Loss: 0.2560\n",
      "Baseline Loss: 2.8258 | Actual Loss: 0.0678\n",
      "Baseline Loss: 2.8506 | Actual Loss: 0.1601\n",
      "Baseline Loss: 2.8281 | Actual Loss: 0.1280\n",
      "Baseline Loss: 2.4183 | Actual Loss: 0.1502\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2294\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.1774\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2647\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.2261\n",
      "Epoch 210/1000: Train Loss: 0.1571, Val Loss: 0.2244\n",
      "Baseline Loss: 2.8627 | Actual Loss: 0.2245\n",
      "Baseline Loss: 2.7952 | Actual Loss: 0.2043\n",
      "Baseline Loss: 2.8479 | Actual Loss: 0.1370\n",
      "Baseline Loss: 2.8220 | Actual Loss: 0.1722\n",
      "Baseline Loss: 2.7674 | Actual Loss: 0.0943\n",
      "Baseline Loss: 2.7979 | Actual Loss: 0.1129\n",
      "Baseline Loss: 2.9035 | Actual Loss: 0.0987\n",
      "Baseline Loss: 2.8416 | Actual Loss: 0.2679\n",
      "Baseline Loss: 2.8342 | Actual Loss: 0.2126\n",
      "Baseline Loss: 2.7896 | Actual Loss: 0.1612\n",
      "Baseline Loss: 2.7239 | Actual Loss: 0.3126\n",
      "Baseline Loss: 2.8393 | Actual Loss: 0.1046\n",
      "Baseline Loss: 2.8312 | Actual Loss: 0.1152\n",
      "Baseline Loss: 2.8427 | Actual Loss: 0.0631\n",
      "Baseline Loss: 2.8088 | Actual Loss: 0.1510\n",
      "Baseline Loss: 2.5921 | Actual Loss: 0.1394\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2491\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 211/1000 [01:07<03:51,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7737 | Actual Loss: 0.2712\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3071\n",
      "Epoch 211/1000: Train Loss: 0.1607, Val Loss: 0.2636\n",
      "Baseline Loss: 2.9162 | Actual Loss: 0.1510\n",
      "Baseline Loss: 2.8056 | Actual Loss: 0.0831\n",
      "Baseline Loss: 2.8518 | Actual Loss: 0.1685\n",
      "Baseline Loss: 2.8565 | Actual Loss: 0.1846\n",
      "Baseline Loss: 2.7554 | Actual Loss: 0.2001\n",
      "Baseline Loss: 2.7928 | Actual Loss: 0.0746\n",
      "Baseline Loss: 2.8123 | Actual Loss: 0.1580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 212/1000 [01:07<04:03,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8305 | Actual Loss: 0.2284\n",
      "Baseline Loss: 2.8251 | Actual Loss: 0.1308\n",
      "Baseline Loss: 2.8265 | Actual Loss: 0.1687\n",
      "Baseline Loss: 2.9209 | Actual Loss: 0.1696\n",
      "Baseline Loss: 2.8066 | Actual Loss: 0.1161\n",
      "Baseline Loss: 2.8784 | Actual Loss: 0.1019\n",
      "Baseline Loss: 2.8732 | Actual Loss: 0.1549\n",
      "Baseline Loss: 2.7620 | Actual Loss: 0.2252\n",
      "Baseline Loss: 2.6613 | Actual Loss: 0.1838\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2682\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.1906\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2936\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.2847\n",
      "Epoch 212/1000: Train Loss: 0.1562, Val Loss: 0.2593\n",
      "Baseline Loss: 2.9215 | Actual Loss: 0.1546\n",
      "Baseline Loss: 2.8552 | Actual Loss: 0.1001\n",
      "Baseline Loss: 2.7749 | Actual Loss: 0.2506\n",
      "Baseline Loss: 2.8816 | Actual Loss: 0.1063\n",
      "Baseline Loss: 2.7945 | Actual Loss: 0.2826\n",
      "Baseline Loss: 2.7951 | Actual Loss: 0.2079\n",
      "Baseline Loss: 2.7738 | Actual Loss: 0.3343\n",
      "Baseline Loss: 2.7789 | Actual Loss: 0.1609\n",
      "Baseline Loss: 2.7950 | Actual Loss: 0.1247\n",
      "Baseline Loss: 2.8545 | Actual Loss: 0.0942\n",
      "Baseline Loss: 2.8312 | Actual Loss: 0.2332\n",
      "Baseline Loss: 2.9201 | Actual Loss: 0.1498\n",
      "Baseline Loss: 2.7919 | Actual Loss: 0.1010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 212/1000 [01:08<04:13,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8090 | Actual Loss: 0.1443\n",
      "Baseline Loss: 2.7822 | Actual Loss: 0.1710\n",
      "Baseline Loss: 2.6455 | Actual Loss: 0.1626\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2773\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2253\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2531\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3413\n",
      "Epoch 213/1000: Train Loss: 0.1736, Val Loss: 0.2743\n",
      "\n",
      "Early stopping at epoch 213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.21656262129545212"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.train_model(\n",
    "    data_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35fe71e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = GNNModelWithNewLoss(\n",
    "        num_node_features=data_list[0].x.shape[1],\n",
    "        num_edge_features=data_list[0].edge_attr.shape[1],\n",
    "        num_global_features=0,\n",
    "        hidden_dim=512,\n",
    "        dropout_rate=0.1,\n",
    "        property_index=1 ,\n",
    "        save_path= 'premodels_new_og/3/1'\n",
    "    ).to(devices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48b63c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training will be saved to: premodels_new_og/3/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6555 | Actual Loss: 2.6100\n",
      "Baseline Loss: 2.6552 | Actual Loss: 2.5978\n",
      "Baseline Loss: 2.6139 | Actual Loss: 2.5602\n",
      "Baseline Loss: 2.6859 | Actual Loss: 2.5940\n",
      "Baseline Loss: 2.6628 | Actual Loss: 2.5085\n",
      "Baseline Loss: 2.7033 | Actual Loss: 2.5613\n",
      "Baseline Loss: 2.6687 | Actual Loss: 2.5128\n",
      "Baseline Loss: 2.7030 | Actual Loss: 2.4199\n",
      "Baseline Loss: 2.6791 | Actual Loss: 2.3991\n",
      "Baseline Loss: 2.6952 | Actual Loss: 2.3386\n",
      "Baseline Loss: 2.7069 | Actual Loss: 2.2307\n",
      "Baseline Loss: 2.7084 | Actual Loss: 2.2981\n",
      "Baseline Loss: 2.6850 | Actual Loss: 2.1422\n",
      "Baseline Loss: 2.6903 | Actual Loss: 2.1361\n",
      "Baseline Loss: 2.6538 | Actual Loss: 2.1534\n",
      "Baseline Loss: 2.2644 | Actual Loss: 1.6479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 1/1000 [00:00<04:16,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6853 | Actual Loss: 2.0545\n",
      "Baseline Loss: 2.6474 | Actual Loss: 1.8241\n",
      "Baseline Loss: 2.6861 | Actual Loss: 2.0299\n",
      "Baseline Loss: 2.5615 | Actual Loss: 1.7832\n",
      "Epoch 1/1000: Train Loss: 2.3569, Val Loss: 1.9229\n",
      "New best validation loss: 1.9229\n",
      "Baseline Loss: 2.6730 | Actual Loss: 1.8055\n",
      "Baseline Loss: 2.6773 | Actual Loss: 1.9584\n",
      "Baseline Loss: 2.6649 | Actual Loss: 1.8858\n",
      "Baseline Loss: 2.7273 | Actual Loss: 2.0307\n",
      "Baseline Loss: 2.6573 | Actual Loss: 1.9070\n",
      "Baseline Loss: 2.7088 | Actual Loss: 1.9377\n",
      "Baseline Loss: 2.6663 | Actual Loss: 1.7658\n",
      "Baseline Loss: 2.6796 | Actual Loss: 1.7151\n",
      "Baseline Loss: 2.6554 | Actual Loss: 1.9272\n",
      "Baseline Loss: 2.6666 | Actual Loss: 1.7944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 2/1000 [00:00<05:20,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6703 | Actual Loss: 1.8100\n",
      "Baseline Loss: 2.6581 | Actual Loss: 1.7223\n",
      "Baseline Loss: 2.6872 | Actual Loss: 1.6884\n",
      "Baseline Loss: 2.6786 | Actual Loss: 1.5613\n",
      "Baseline Loss: 2.6727 | Actual Loss: 1.5349\n",
      "Baseline Loss: 2.2844 | Actual Loss: 1.6379\n",
      "Baseline Loss: 2.6853 | Actual Loss: 1.6472\n",
      "Baseline Loss: 2.6474 | Actual Loss: 1.6217\n",
      "Baseline Loss: 2.6861 | Actual Loss: 1.7211\n",
      "Baseline Loss: 2.5615 | Actual Loss: 1.6294\n",
      "Epoch 2/1000: Train Loss: 1.7927, Val Loss: 1.6549\n",
      "New best validation loss: 1.6549\n",
      "Baseline Loss: 2.6724 | Actual Loss: 1.6060\n",
      "Baseline Loss: 2.6716 | Actual Loss: 1.7019\n",
      "Baseline Loss: 2.7217 | Actual Loss: 1.7735\n",
      "Baseline Loss: 2.6637 | Actual Loss: 1.6244\n",
      "Baseline Loss: 2.6870 | Actual Loss: 1.5444\n",
      "Baseline Loss: 2.6815 | Actual Loss: 1.3812\n",
      "Baseline Loss: 2.6618 | Actual Loss: 1.4303\n",
      "Baseline Loss: 2.6500 | Actual Loss: 1.3576\n",
      "Baseline Loss: 2.6716 | Actual Loss: 1.4868\n",
      "Baseline Loss: 2.6752 | Actual Loss: 1.4299\n",
      "Baseline Loss: 2.7021 | Actual Loss: 1.7788\n",
      "Baseline Loss: 2.6561 | Actual Loss: 1.4359\n",
      "Baseline Loss: 2.6658 | Actual Loss: 1.3719\n",
      "Baseline Loss: 2.6781 | Actual Loss: 1.3912\n",
      "Baseline Loss: 2.6775 | Actual Loss: 1.4313\n",
      "Baseline Loss: 2.2110 | Actual Loss: 1.0350\n",
      "Baseline Loss: 2.6853 | Actual Loss: 1.4369\n",
      "Baseline Loss: 2.6474 | Actual Loss: 1.3439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 3/1000 [00:00<05:29,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6861 | Actual Loss: 1.3002\n",
      "Baseline Loss: 2.5615 | Actual Loss: 1.2518\n",
      "Epoch 3/1000: Train Loss: 1.4863, Val Loss: 1.3332\n",
      "New best validation loss: 1.3332\n",
      "Baseline Loss: 2.6487 | Actual Loss: 1.3610\n",
      "Baseline Loss: 2.7227 | Actual Loss: 1.2476\n",
      "Baseline Loss: 2.6926 | Actual Loss: 1.4215\n",
      "Baseline Loss: 2.7101 | Actual Loss: 1.2665\n",
      "Baseline Loss: 2.6881 | Actual Loss: 1.4128\n",
      "Baseline Loss: 2.6794 | Actual Loss: 1.6155\n",
      "Baseline Loss: 2.6755 | Actual Loss: 1.3146\n",
      "Baseline Loss: 2.6444 | Actual Loss: 1.2675\n",
      "Baseline Loss: 2.6579 | Actual Loss: 1.1443\n",
      "Baseline Loss: 2.6664 | Actual Loss: 1.5705\n",
      "Baseline Loss: 2.7071 | Actual Loss: 1.3140\n",
      "Baseline Loss: 2.6573 | Actual Loss: 1.0792\n",
      "Baseline Loss: 2.6832 | Actual Loss: 1.3331\n",
      "Baseline Loss: 2.6558 | Actual Loss: 1.1752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 4/1000 [00:01<04:57,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6803 | Actual Loss: 1.1965\n",
      "Baseline Loss: 2.2452 | Actual Loss: 1.0385\n",
      "Baseline Loss: 2.6853 | Actual Loss: 1.2468\n",
      "Baseline Loss: 2.6474 | Actual Loss: 1.0702\n",
      "Baseline Loss: 2.6861 | Actual Loss: 1.2181\n",
      "Baseline Loss: 2.5615 | Actual Loss: 1.1039\n",
      "Epoch 4/1000: Train Loss: 1.2974, Val Loss: 1.1598\n",
      "New best validation loss: 1.1598\n",
      "Baseline Loss: 2.6777 | Actual Loss: 1.1902\n",
      "Baseline Loss: 2.6800 | Actual Loss: 1.1970\n",
      "Baseline Loss: 2.6531 | Actual Loss: 1.3846\n",
      "Baseline Loss: 2.6489 | Actual Loss: 1.0216\n",
      "Baseline Loss: 2.6391 | Actual Loss: 1.2991\n",
      "Baseline Loss: 2.6476 | Actual Loss: 1.2425\n",
      "Baseline Loss: 2.6918 | Actual Loss: 1.0134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 5/1000 [00:01<05:20,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7006 | Actual Loss: 1.1230\n",
      "Baseline Loss: 2.6928 | Actual Loss: 1.1747\n",
      "Baseline Loss: 2.6708 | Actual Loss: 1.0328\n",
      "Baseline Loss: 2.7235 | Actual Loss: 1.0063\n",
      "Baseline Loss: 2.6587 | Actual Loss: 1.4178\n",
      "Baseline Loss: 2.6962 | Actual Loss: 1.0818\n",
      "Baseline Loss: 2.6750 | Actual Loss: 1.0173\n",
      "Baseline Loss: 2.6231 | Actual Loss: 1.0296\n",
      "Baseline Loss: 2.2768 | Actual Loss: 0.7533\n",
      "Baseline Loss: 2.6853 | Actual Loss: 1.1246\n",
      "Baseline Loss: 2.6474 | Actual Loss: 1.0776\n",
      "Baseline Loss: 2.6861 | Actual Loss: 1.0458\n",
      "Baseline Loss: 2.5615 | Actual Loss: 1.0816\n",
      "Epoch 5/1000: Train Loss: 1.1241, Val Loss: 1.0824\n",
      "New best validation loss: 1.0824\n",
      "Baseline Loss: 2.7116 | Actual Loss: 1.0227\n",
      "Baseline Loss: 2.6308 | Actual Loss: 0.9270\n",
      "Baseline Loss: 2.7091 | Actual Loss: 1.0867\n",
      "Baseline Loss: 2.6326 | Actual Loss: 0.9539\n",
      "Baseline Loss: 2.6967 | Actual Loss: 1.0911\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.9644\n",
      "Baseline Loss: 2.6588 | Actual Loss: 1.0190\n",
      "Baseline Loss: 2.6915 | Actual Loss: 0.9692\n",
      "Baseline Loss: 2.6807 | Actual Loss: 0.9523\n",
      "Baseline Loss: 2.6896 | Actual Loss: 1.0380\n",
      "Baseline Loss: 2.6570 | Actual Loss: 1.1695\n",
      "Baseline Loss: 2.6803 | Actual Loss: 0.9975\n",
      "Baseline Loss: 2.6606 | Actual Loss: 0.9710\n",
      "Baseline Loss: 2.6864 | Actual Loss: 0.9902\n",
      "Baseline Loss: 2.6550 | Actual Loss: 0.8134\n",
      "Baseline Loss: 2.2249 | Actual Loss: 0.5673\n",
      "Baseline Loss: 2.6853 | Actual Loss: 1.0600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 6/1000 [00:01<05:24,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6474 | Actual Loss: 1.0626\n",
      "Baseline Loss: 2.6861 | Actual Loss: 1.0380\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.8792\n",
      "Epoch 6/1000: Train Loss: 0.9708, Val Loss: 1.0100\n",
      "New best validation loss: 1.0100\n",
      "Baseline Loss: 2.6961 | Actual Loss: 1.1686\n",
      "Baseline Loss: 2.6756 | Actual Loss: 1.0975\n",
      "Baseline Loss: 2.6812 | Actual Loss: 0.7994\n",
      "Baseline Loss: 2.6710 | Actual Loss: 0.8374\n",
      "Baseline Loss: 2.7503 | Actual Loss: 0.8987\n",
      "Baseline Loss: 2.7066 | Actual Loss: 1.1152\n",
      "Baseline Loss: 2.6735 | Actual Loss: 0.9816\n",
      "Baseline Loss: 2.6509 | Actual Loss: 0.7580\n",
      "Baseline Loss: 2.6808 | Actual Loss: 1.0299\n",
      "Baseline Loss: 2.6604 | Actual Loss: 0.7856\n",
      "Baseline Loss: 2.6323 | Actual Loss: 0.7886\n",
      "Baseline Loss: 2.6473 | Actual Loss: 1.0773\n",
      "Baseline Loss: 2.6607 | Actual Loss: 0.8313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 7/1000 [00:02<04:58,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6799 | Actual Loss: 0.8322\n",
      "Baseline Loss: 2.6866 | Actual Loss: 0.8415\n",
      "Baseline Loss: 2.2783 | Actual Loss: 0.5636\n",
      "Baseline Loss: 2.6853 | Actual Loss: 1.0405\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.9570\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.8018\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.8637\n",
      "Epoch 7/1000: Train Loss: 0.9004, Val Loss: 0.9158\n",
      "New best validation loss: 0.9158\n",
      "Baseline Loss: 2.6366 | Actual Loss: 0.9383\n",
      "Baseline Loss: 2.6950 | Actual Loss: 1.0241\n",
      "Baseline Loss: 2.6610 | Actual Loss: 0.9133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 8/1000 [00:02<05:08,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6818 | Actual Loss: 0.7498\n",
      "Baseline Loss: 2.6814 | Actual Loss: 0.9296\n",
      "Baseline Loss: 2.6624 | Actual Loss: 0.7332\n",
      "Baseline Loss: 2.6340 | Actual Loss: 0.7850\n",
      "Baseline Loss: 2.6808 | Actual Loss: 0.8955\n",
      "Baseline Loss: 2.6849 | Actual Loss: 0.9685\n",
      "Baseline Loss: 2.6561 | Actual Loss: 0.7394\n",
      "Baseline Loss: 2.6410 | Actual Loss: 1.1711\n",
      "Baseline Loss: 2.6884 | Actual Loss: 0.8309\n",
      "Baseline Loss: 2.6727 | Actual Loss: 0.9018\n",
      "Baseline Loss: 2.6937 | Actual Loss: 0.9029\n",
      "Baseline Loss: 2.6974 | Actual Loss: 0.8918\n",
      "Baseline Loss: 2.3341 | Actual Loss: 0.5462\n",
      "Baseline Loss: 2.6853 | Actual Loss: 1.0056\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.9014\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.8893\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.7997\n",
      "Epoch 8/1000: Train Loss: 0.8701, Val Loss: 0.8990\n",
      "New best validation loss: 0.8990\n",
      "Baseline Loss: 2.6763 | Actual Loss: 0.6675\n",
      "Baseline Loss: 2.6639 | Actual Loss: 1.0465\n",
      "Baseline Loss: 2.6514 | Actual Loss: 0.9134\n",
      "Baseline Loss: 2.7286 | Actual Loss: 0.8870\n",
      "Baseline Loss: 2.6917 | Actual Loss: 0.9063\n",
      "Baseline Loss: 2.7330 | Actual Loss: 1.1545\n",
      "Baseline Loss: 2.6706 | Actual Loss: 0.8017\n",
      "Baseline Loss: 2.7001 | Actual Loss: 0.8293\n",
      "Baseline Loss: 2.6868 | Actual Loss: 0.7162\n",
      "Baseline Loss: 2.6843 | Actual Loss: 0.8863\n",
      "Baseline Loss: 2.6464 | Actual Loss: 0.6803\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.8252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 9/1000 [00:02<05:25,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6545 | Actual Loss: 0.8241\n",
      "Baseline Loss: 2.6732 | Actual Loss: 0.7371\n",
      "Baseline Loss: 2.6370 | Actual Loss: 0.8621\n",
      "Baseline Loss: 2.2713 | Actual Loss: 0.7384\n",
      "Baseline Loss: 2.6853 | Actual Loss: 1.0119\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.6724\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.7715\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.8052\n",
      "Epoch 9/1000: Train Loss: 0.8422, Val Loss: 0.8152\n",
      "New best validation loss: 0.8152\n",
      "Baseline Loss: 2.6661 | Actual Loss: 1.0664\n",
      "Baseline Loss: 2.6768 | Actual Loss: 0.8421\n",
      "Baseline Loss: 2.6682 | Actual Loss: 1.1013\n",
      "Baseline Loss: 2.6582 | Actual Loss: 0.5072\n",
      "Baseline Loss: 2.6860 | Actual Loss: 0.8952\n",
      "Baseline Loss: 2.6726 | Actual Loss: 0.9442\n",
      "Baseline Loss: 2.6585 | Actual Loss: 0.7083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 10/1000 [00:03<05:02,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6835 | Actual Loss: 0.5575\n",
      "Baseline Loss: 2.6188 | Actual Loss: 0.9681\n",
      "Baseline Loss: 2.6740 | Actual Loss: 0.8544\n",
      "Baseline Loss: 2.6880 | Actual Loss: 0.9319\n",
      "Baseline Loss: 2.6721 | Actual Loss: 0.7638\n",
      "Baseline Loss: 2.7433 | Actual Loss: 0.6451\n",
      "Baseline Loss: 2.6741 | Actual Loss: 0.7778\n",
      "Baseline Loss: 2.6731 | Actual Loss: 0.8167\n",
      "Baseline Loss: 2.3433 | Actual Loss: 0.6067\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.8006\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.9052\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.7768\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.7719\n",
      "Epoch 10/1000: Train Loss: 0.8117, Val Loss: 0.8136\n",
      "New best validation loss: 0.8136\n",
      "Baseline Loss: 2.6841 | Actual Loss: 0.7503\n",
      "Baseline Loss: 2.7065 | Actual Loss: 0.9288\n",
      "Baseline Loss: 2.6982 | Actual Loss: 0.7102\n",
      "Baseline Loss: 2.6870 | Actual Loss: 0.6963\n",
      "Baseline Loss: 2.6773 | Actual Loss: 0.6659\n",
      "Baseline Loss: 2.6399 | Actual Loss: 0.8211\n",
      "Baseline Loss: 2.6443 | Actual Loss: 0.6971\n",
      "Baseline Loss: 2.6573 | Actual Loss: 0.8320\n",
      "Baseline Loss: 2.6676 | Actual Loss: 0.6920\n",
      "Baseline Loss: 2.7011 | Actual Loss: 0.8129\n",
      "Baseline Loss: 2.6692 | Actual Loss: 0.6680\n",
      "Baseline Loss: 2.6880 | Actual Loss: 1.0711\n",
      "Baseline Loss: 2.7030 | Actual Loss: 0.7218\n",
      "Baseline Loss: 2.6761 | Actual Loss: 0.8131\n",
      "Baseline Loss: 2.6797 | Actual Loss: 0.8689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 11/1000 [00:03<05:08,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.3397 | Actual Loss: 0.3680\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.9032\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.8219\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.8599\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.7967\n",
      "Epoch 11/1000: Train Loss: 0.7573, Val Loss: 0.8454\n",
      "Baseline Loss: 2.6847 | Actual Loss: 0.6696\n",
      "Baseline Loss: 2.6874 | Actual Loss: 0.6780\n",
      "Baseline Loss: 2.7258 | Actual Loss: 0.5566\n",
      "Baseline Loss: 2.6569 | Actual Loss: 0.8611\n",
      "Baseline Loss: 2.6934 | Actual Loss: 0.6959\n",
      "Baseline Loss: 2.6339 | Actual Loss: 1.0764\n",
      "Baseline Loss: 2.6334 | Actual Loss: 0.7199\n",
      "Baseline Loss: 2.6972 | Actual Loss: 0.6516\n",
      "Baseline Loss: 2.6625 | Actual Loss: 0.5375\n",
      "Baseline Loss: 2.6884 | Actual Loss: 0.6672\n",
      "Baseline Loss: 2.6654 | Actual Loss: 0.6673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 12/1000 [00:03<05:25,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6731 | Actual Loss: 0.7176\n",
      "Baseline Loss: 2.6303 | Actual Loss: 0.5426\n",
      "Baseline Loss: 2.6368 | Actual Loss: 0.5561\n",
      "Baseline Loss: 2.6598 | Actual Loss: 0.9089\n",
      "Baseline Loss: 2.2381 | Actual Loss: 0.3365\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.9560\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.7265\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.7237\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.7428\n",
      "Epoch 12/1000: Train Loss: 0.6777, Val Loss: 0.7872\n",
      "New best validation loss: 0.7872\n",
      "Baseline Loss: 2.6576 | Actual Loss: 0.8343\n",
      "Baseline Loss: 2.6580 | Actual Loss: 0.6782\n",
      "Baseline Loss: 2.6524 | Actual Loss: 0.6544\n",
      "Baseline Loss: 2.7050 | Actual Loss: 0.6418\n",
      "Baseline Loss: 2.6424 | Actual Loss: 0.7345\n",
      "Baseline Loss: 2.6873 | Actual Loss: 0.7633\n",
      "Baseline Loss: 2.6668 | Actual Loss: 0.8437\n",
      "Baseline Loss: 2.7225 | Actual Loss: 0.7472\n",
      "Baseline Loss: 2.6760 | Actual Loss: 0.6179\n",
      "Baseline Loss: 2.6809 | Actual Loss: 0.7133\n",
      "Baseline Loss: 2.6956 | Actual Loss: 0.5052\n",
      "Baseline Loss: 2.6562 | Actual Loss: 0.4695\n",
      "Baseline Loss: 2.6552 | Actual Loss: 0.8176\n",
      "Baseline Loss: 2.6579 | Actual Loss: 0.6605\n",
      "Baseline Loss: 2.6835 | Actual Loss: 0.8835\n",
      "Baseline Loss: 2.3275 | Actual Loss: 0.5506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏         | 13/1000 [00:04<05:02,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6853 | Actual Loss: 0.9097\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.6116\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.7160\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.6228\n",
      "Epoch 13/1000: Train Loss: 0.6947, Val Loss: 0.7150\n",
      "New best validation loss: 0.7150\n",
      "Baseline Loss: 2.6475 | Actual Loss: 0.6360\n",
      "Baseline Loss: 2.6444 | Actual Loss: 0.7892\n",
      "Baseline Loss: 2.6790 | Actual Loss: 0.6945\n",
      "Baseline Loss: 2.7304 | Actual Loss: 0.7871\n",
      "Baseline Loss: 2.6479 | Actual Loss: 0.5054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏         | 14/1000 [00:04<05:18,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6839 | Actual Loss: 0.8384\n",
      "Baseline Loss: 2.6422 | Actual Loss: 0.5488\n",
      "Baseline Loss: 2.6904 | Actual Loss: 0.6585\n",
      "Baseline Loss: 2.6937 | Actual Loss: 1.0359\n",
      "Baseline Loss: 2.6532 | Actual Loss: 0.6784\n",
      "Baseline Loss: 2.6750 | Actual Loss: 0.5179\n",
      "Baseline Loss: 2.6945 | Actual Loss: 0.7660\n",
      "Baseline Loss: 2.6480 | Actual Loss: 0.7531\n",
      "Baseline Loss: 2.6874 | Actual Loss: 0.9243\n",
      "Baseline Loss: 2.6705 | Actual Loss: 0.9488\n",
      "Baseline Loss: 2.2978 | Actual Loss: 0.2830\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.7922\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.7125\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.8136\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.6675\n",
      "Epoch 14/1000: Train Loss: 0.7103, Val Loss: 0.7464\n",
      "Baseline Loss: 2.6817 | Actual Loss: 0.7046\n",
      "Baseline Loss: 2.6453 | Actual Loss: 0.9330\n",
      "Baseline Loss: 2.6775 | Actual Loss: 0.8257\n",
      "Baseline Loss: 2.7006 | Actual Loss: 0.5374\n",
      "Baseline Loss: 2.6452 | Actual Loss: 0.7363\n",
      "Baseline Loss: 2.6871 | Actual Loss: 0.7207\n",
      "Baseline Loss: 2.6516 | Actual Loss: 0.9766\n",
      "Baseline Loss: 2.7119 | Actual Loss: 0.5725\n",
      "Baseline Loss: 2.6647 | Actual Loss: 0.7907\n",
      "Baseline Loss: 2.6879 | Actual Loss: 0.8372\n",
      "Baseline Loss: 2.6940 | Actual Loss: 0.8144\n",
      "Baseline Loss: 2.6529 | Actual Loss: 0.5272\n",
      "Baseline Loss: 2.6706 | Actual Loss: 0.6554\n",
      "Baseline Loss: 2.6975 | Actual Loss: 0.6570\n",
      "Baseline Loss: 2.6673 | Actual Loss: 0.6012\n",
      "Baseline Loss: 2.3135 | Actual Loss: 0.6492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 15/1000 [00:04<05:21,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6853 | Actual Loss: 0.8939\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.7813\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.7008\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.7219\n",
      "Epoch 15/1000: Train Loss: 0.7212, Val Loss: 0.7745\n",
      "Baseline Loss: 2.6728 | Actual Loss: 0.5094\n",
      "Baseline Loss: 2.6278 | Actual Loss: 0.6461\n",
      "Baseline Loss: 2.7012 | Actual Loss: 0.9412\n",
      "Baseline Loss: 2.6709 | Actual Loss: 0.5244\n",
      "Baseline Loss: 2.6669 | Actual Loss: 0.6503\n",
      "Baseline Loss: 2.7320 | Actual Loss: 0.7945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 16/1000 [00:05<04:57,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6719 | Actual Loss: 0.5261\n",
      "Baseline Loss: 2.6552 | Actual Loss: 0.5664\n",
      "Baseline Loss: 2.6927 | Actual Loss: 0.5532\n",
      "Baseline Loss: 2.7185 | Actual Loss: 0.6638\n",
      "Baseline Loss: 2.6216 | Actual Loss: 0.9946\n",
      "Baseline Loss: 2.6614 | Actual Loss: 0.5970\n",
      "Baseline Loss: 2.7328 | Actual Loss: 0.8294\n",
      "Baseline Loss: 2.6527 | Actual Loss: 0.6883\n",
      "Baseline Loss: 2.6782 | Actual Loss: 1.0654\n",
      "Baseline Loss: 2.2788 | Actual Loss: 0.2864\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.8491\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.7567\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.7500\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.6982\n",
      "Epoch 16/1000: Train Loss: 0.6773, Val Loss: 0.7635\n",
      "Baseline Loss: 2.6520 | Actual Loss: 0.7690\n",
      "Baseline Loss: 2.6386 | Actual Loss: 0.6120\n",
      "Baseline Loss: 2.6525 | Actual Loss: 0.6671\n",
      "Baseline Loss: 2.6645 | Actual Loss: 0.6819\n",
      "Baseline Loss: 2.6734 | Actual Loss: 0.8115\n",
      "Baseline Loss: 2.6769 | Actual Loss: 0.5970\n",
      "Baseline Loss: 2.6993 | Actual Loss: 0.5673\n",
      "Baseline Loss: 2.6667 | Actual Loss: 0.7497\n",
      "Baseline Loss: 2.6869 | Actual Loss: 0.8076\n",
      "Baseline Loss: 2.6653 | Actual Loss: 0.8456\n",
      "Baseline Loss: 2.7054 | Actual Loss: 0.6554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 17/1000 [00:05<05:15,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7032 | Actual Loss: 0.7511\n",
      "Baseline Loss: 2.6388 | Actual Loss: 0.8371\n",
      "Baseline Loss: 2.6702 | Actual Loss: 0.8297\n",
      "Baseline Loss: 2.7157 | Actual Loss: 0.5401\n",
      "Baseline Loss: 2.2780 | Actual Loss: 0.4790\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.8568\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.7281\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.7665\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.7345\n",
      "Epoch 17/1000: Train Loss: 0.7001, Val Loss: 0.7715\n",
      "Baseline Loss: 2.6851 | Actual Loss: 0.6850\n",
      "Baseline Loss: 2.6588 | Actual Loss: 0.5881\n",
      "Baseline Loss: 2.6561 | Actual Loss: 0.5354\n",
      "Baseline Loss: 2.7297 | Actual Loss: 0.5750\n",
      "Baseline Loss: 2.6480 | Actual Loss: 0.4359\n",
      "Baseline Loss: 2.6947 | Actual Loss: 0.5681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 18/1000 [00:05<04:53,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6906 | Actual Loss: 0.7791\n",
      "Baseline Loss: 2.6659 | Actual Loss: 0.8843\n",
      "Baseline Loss: 2.7057 | Actual Loss: 0.8736\n",
      "Baseline Loss: 2.6263 | Actual Loss: 0.6235\n",
      "Baseline Loss: 2.6577 | Actual Loss: 0.3265\n",
      "Baseline Loss: 2.7051 | Actual Loss: 0.6152\n",
      "Baseline Loss: 2.7154 | Actual Loss: 0.6827\n",
      "Baseline Loss: 2.6749 | Actual Loss: 0.5079\n",
      "Baseline Loss: 2.6697 | Actual Loss: 0.7161\n",
      "Baseline Loss: 2.2547 | Actual Loss: 0.4293\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.8081\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.7042\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.7735\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.7588\n",
      "Epoch 18/1000: Train Loss: 0.6141, Val Loss: 0.7612\n",
      "Baseline Loss: 2.6541 | Actual Loss: 0.7729\n",
      "Baseline Loss: 2.6468 | Actual Loss: 0.5873\n",
      "Baseline Loss: 2.6522 | Actual Loss: 0.4302\n",
      "Baseline Loss: 2.6708 | Actual Loss: 0.6889\n",
      "Baseline Loss: 2.7418 | Actual Loss: 0.5436\n",
      "Baseline Loss: 2.6992 | Actual Loss: 0.8802\n",
      "Baseline Loss: 2.6912 | Actual Loss: 0.5997\n",
      "Baseline Loss: 2.6834 | Actual Loss: 0.7362\n",
      "Baseline Loss: 2.7028 | Actual Loss: 0.6413\n",
      "Baseline Loss: 2.6464 | Actual Loss: 0.5855\n",
      "Baseline Loss: 2.6888 | Actual Loss: 0.6401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 19/1000 [00:05<05:12,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6882 | Actual Loss: 0.6427\n",
      "Baseline Loss: 2.6714 | Actual Loss: 0.5234\n",
      "Baseline Loss: 2.6267 | Actual Loss: 0.7531\n",
      "Baseline Loss: 2.6950 | Actual Loss: 0.6578\n",
      "Baseline Loss: 2.3014 | Actual Loss: 0.3086\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.7353\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.6713\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.6410\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.5701\n",
      "Epoch 19/1000: Train Loss: 0.6245, Val Loss: 0.6544\n",
      "New best validation loss: 0.6544\n",
      "Baseline Loss: 2.6954 | Actual Loss: 0.5633\n",
      "Baseline Loss: 2.6188 | Actual Loss: 0.5381\n",
      "Baseline Loss: 2.6813 | Actual Loss: 0.5507\n",
      "Baseline Loss: 2.6701 | Actual Loss: 0.6245\n",
      "Baseline Loss: 2.6796 | Actual Loss: 0.5712\n",
      "Baseline Loss: 2.6605 | Actual Loss: 0.6144\n",
      "Baseline Loss: 2.6820 | Actual Loss: 0.5335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 20/1000 [00:06<04:56,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6512 | Actual Loss: 0.7156\n",
      "Baseline Loss: 2.6989 | Actual Loss: 0.7029\n",
      "Baseline Loss: 2.6878 | Actual Loss: 0.7055\n",
      "Baseline Loss: 2.6765 | Actual Loss: 0.6558\n",
      "Baseline Loss: 2.6508 | Actual Loss: 0.7866\n",
      "Baseline Loss: 2.7199 | Actual Loss: 0.4841\n",
      "Baseline Loss: 2.7096 | Actual Loss: 0.7467\n",
      "Baseline Loss: 2.6355 | Actual Loss: 0.5143\n",
      "Baseline Loss: 2.2859 | Actual Loss: 0.2372\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.7360\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.5543\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.6440\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.6089\n",
      "Epoch 20/1000: Train Loss: 0.5965, Val Loss: 0.6358\n",
      "New best validation loss: 0.6358\n",
      "Baseline Loss: 2.6466 | Actual Loss: 0.6483\n",
      "Baseline Loss: 2.6744 | Actual Loss: 0.6367\n",
      "Baseline Loss: 2.6738 | Actual Loss: 0.5857\n",
      "Baseline Loss: 2.6485 | Actual Loss: 0.4370\n",
      "Baseline Loss: 2.6693 | Actual Loss: 0.4553\n",
      "Baseline Loss: 2.6745 | Actual Loss: 0.3775\n",
      "Baseline Loss: 2.6750 | Actual Loss: 0.5340\n",
      "Baseline Loss: 2.6572 | Actual Loss: 0.4635\n",
      "Baseline Loss: 2.7237 | Actual Loss: 0.4779\n",
      "Baseline Loss: 2.6819 | Actual Loss: 0.5980\n",
      "Baseline Loss: 2.6802 | Actual Loss: 0.6342\n",
      "Baseline Loss: 2.7071 | Actual Loss: 0.6081\n",
      "Baseline Loss: 2.6583 | Actual Loss: 0.6423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 21/1000 [00:06<05:05,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7122 | Actual Loss: 0.6197\n",
      "Baseline Loss: 2.6768 | Actual Loss: 0.5046\n",
      "Baseline Loss: 2.1957 | Actual Loss: 0.3347\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.7569\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.6082\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.7118\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.6407\n",
      "Epoch 21/1000: Train Loss: 0.5348, Val Loss: 0.6794\n",
      "Baseline Loss: 2.6579 | Actual Loss: 0.6849\n",
      "Baseline Loss: 2.6815 | Actual Loss: 0.5213\n",
      "Baseline Loss: 2.6859 | Actual Loss: 0.5513\n",
      "Baseline Loss: 2.7046 | Actual Loss: 0.6026\n",
      "Baseline Loss: 2.6846 | Actual Loss: 0.5099\n",
      "Baseline Loss: 2.6797 | Actual Loss: 0.6806\n",
      "Baseline Loss: 2.6609 | Actual Loss: 0.5752\n",
      "Baseline Loss: 2.6475 | Actual Loss: 0.4681\n",
      "Baseline Loss: 2.6869 | Actual Loss: 0.6730\n",
      "Baseline Loss: 2.6747 | Actual Loss: 0.5763\n",
      "Baseline Loss: 2.6952 | Actual Loss: 0.4812\n",
      "Baseline Loss: 2.6685 | Actual Loss: 0.5987\n",
      "Baseline Loss: 2.6514 | Actual Loss: 0.6740\n",
      "Baseline Loss: 2.7026 | Actual Loss: 0.8029\n",
      "Baseline Loss: 2.6581 | Actual Loss: 0.4843\n",
      "Baseline Loss: 2.2903 | Actual Loss: 0.5791\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.7700\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.6800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 22/1000 [00:06<05:17,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6861 | Actual Loss: 0.6852\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.5097\n",
      "Epoch 22/1000: Train Loss: 0.5915, Val Loss: 0.6612\n",
      "Baseline Loss: 2.6588 | Actual Loss: 0.5219\n",
      "Baseline Loss: 2.6737 | Actual Loss: 0.3831\n",
      "Baseline Loss: 2.6875 | Actual Loss: 0.5415\n",
      "Baseline Loss: 2.7158 | Actual Loss: 0.6358\n",
      "Baseline Loss: 2.6700 | Actual Loss: 0.5464\n",
      "Baseline Loss: 2.6641 | Actual Loss: 0.5677\n",
      "Baseline Loss: 2.6781 | Actual Loss: 0.5732\n",
      "Baseline Loss: 2.6826 | Actual Loss: 0.6408\n",
      "Baseline Loss: 2.6656 | Actual Loss: 0.8057\n",
      "Baseline Loss: 2.6724 | Actual Loss: 0.5711\n",
      "Baseline Loss: 2.6763 | Actual Loss: 0.5267\n",
      "Baseline Loss: 2.6420 | Actual Loss: 0.7310\n",
      "Baseline Loss: 2.7145 | Actual Loss: 0.3747\n",
      "Baseline Loss: 2.6980 | Actual Loss: 0.5248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 23/1000 [00:07<04:56,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6842 | Actual Loss: 0.5926\n",
      "Baseline Loss: 2.2612 | Actual Loss: 0.3231\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.7090\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.6732\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.6565\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.6215\n",
      "Epoch 23/1000: Train Loss: 0.5538, Val Loss: 0.6651\n",
      "Baseline Loss: 2.6846 | Actual Loss: 0.4632\n",
      "Baseline Loss: 2.7135 | Actual Loss: 0.5607\n",
      "Baseline Loss: 2.6763 | Actual Loss: 0.4538\n",
      "Baseline Loss: 2.6727 | Actual Loss: 0.6620\n",
      "Baseline Loss: 2.6550 | Actual Loss: 0.6410\n",
      "Baseline Loss: 2.6431 | Actual Loss: 0.4450\n",
      "Baseline Loss: 2.6454 | Actual Loss: 0.4958\n",
      "Baseline Loss: 2.6660 | Actual Loss: 0.5170\n",
      "Baseline Loss: 2.6747 | Actual Loss: 0.4867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 24/1000 [00:07<05:06,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6625 | Actual Loss: 0.4833\n",
      "Baseline Loss: 2.6375 | Actual Loss: 0.5313\n",
      "Baseline Loss: 2.7132 | Actual Loss: 0.7738\n",
      "Baseline Loss: 2.6715 | Actual Loss: 0.3718\n",
      "Baseline Loss: 2.6684 | Actual Loss: 0.5290\n",
      "Baseline Loss: 2.7165 | Actual Loss: 0.5411\n",
      "Baseline Loss: 2.3169 | Actual Loss: 0.6949\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.6237\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.5695\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.6785\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.4844\n",
      "Epoch 24/1000: Train Loss: 0.5406, Val Loss: 0.5890\n",
      "New best validation loss: 0.5890\n",
      "Baseline Loss: 2.6493 | Actual Loss: 0.6320\n",
      "Baseline Loss: 2.6556 | Actual Loss: 0.4166\n",
      "Baseline Loss: 2.6565 | Actual Loss: 0.4295\n",
      "Baseline Loss: 2.7276 | Actual Loss: 0.3291\n",
      "Baseline Loss: 2.6944 | Actual Loss: 0.7046\n",
      "Baseline Loss: 2.6863 | Actual Loss: 0.5993\n",
      "Baseline Loss: 2.6529 | Actual Loss: 0.4427\n",
      "Baseline Loss: 2.7004 | Actual Loss: 0.5788\n",
      "Baseline Loss: 2.6911 | Actual Loss: 0.4205\n",
      "Baseline Loss: 2.6564 | Actual Loss: 0.5444\n",
      "Baseline Loss: 2.6524 | Actual Loss: 0.5564\n",
      "Baseline Loss: 2.6741 | Actual Loss: 0.3646\n",
      "Baseline Loss: 2.6868 | Actual Loss: 0.4891\n",
      "Baseline Loss: 2.6482 | Actual Loss: 0.3040\n",
      "Baseline Loss: 2.6322 | Actual Loss: 0.6757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▎         | 25/1000 [00:07<04:50,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.3236 | Actual Loss: 0.4164\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.6582\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.6386\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.6103\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.5530\n",
      "Epoch 25/1000: Train Loss: 0.4940, Val Loss: 0.6150\n",
      "Baseline Loss: 2.6692 | Actual Loss: 0.6450\n",
      "Baseline Loss: 2.6839 | Actual Loss: 0.5754\n",
      "Baseline Loss: 2.6753 | Actual Loss: 0.6231\n",
      "Baseline Loss: 2.6508 | Actual Loss: 0.6644\n",
      "Baseline Loss: 2.7077 | Actual Loss: 0.6291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 26/1000 [00:08<05:00,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6889 | Actual Loss: 0.2532\n",
      "Baseline Loss: 2.6993 | Actual Loss: 0.5629\n",
      "Baseline Loss: 2.6608 | Actual Loss: 0.5336\n",
      "Baseline Loss: 2.7111 | Actual Loss: 0.5902\n",
      "Baseline Loss: 2.6855 | Actual Loss: 0.5242\n",
      "Baseline Loss: 2.6248 | Actual Loss: 0.4798\n",
      "Baseline Loss: 2.6749 | Actual Loss: 0.5145\n",
      "Baseline Loss: 2.6659 | Actual Loss: 0.4370\n",
      "Baseline Loss: 2.6676 | Actual Loss: 0.5694\n",
      "Baseline Loss: 2.6604 | Actual Loss: 0.3702\n",
      "Baseline Loss: 2.3172 | Actual Loss: 0.4427\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.7414\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.6292\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.6361\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.5818\n",
      "Epoch 26/1000: Train Loss: 0.5259, Val Loss: 0.6471\n",
      "Baseline Loss: 2.6645 | Actual Loss: 0.5793\n",
      "Baseline Loss: 2.6739 | Actual Loss: 0.5275\n",
      "Baseline Loss: 2.6631 | Actual Loss: 0.4625\n",
      "Baseline Loss: 2.6819 | Actual Loss: 0.5143\n",
      "Baseline Loss: 2.6578 | Actual Loss: 0.4153\n",
      "Baseline Loss: 2.6688 | Actual Loss: 0.4821\n",
      "Baseline Loss: 2.6856 | Actual Loss: 0.4525\n",
      "Baseline Loss: 2.6761 | Actual Loss: 0.4073\n",
      "Baseline Loss: 2.6652 | Actual Loss: 0.5193\n",
      "Baseline Loss: 2.6710 | Actual Loss: 0.5716\n",
      "Baseline Loss: 2.6862 | Actual Loss: 0.4659\n",
      "Baseline Loss: 2.6971 | Actual Loss: 0.6985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 27/1000 [00:08<05:14,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6580 | Actual Loss: 0.5500\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5630\n",
      "Baseline Loss: 2.6473 | Actual Loss: 0.6056\n",
      "Baseline Loss: 2.2797 | Actual Loss: 0.5020\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.6592\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.6090\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.5923\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.5221\n",
      "Epoch 27/1000: Train Loss: 0.5198, Val Loss: 0.5957\n",
      "Baseline Loss: 2.6719 | Actual Loss: 0.5778\n",
      "Baseline Loss: 2.6631 | Actual Loss: 0.4994\n",
      "Baseline Loss: 2.6906 | Actual Loss: 0.6007\n",
      "Baseline Loss: 2.6676 | Actual Loss: 0.4472\n",
      "Baseline Loss: 2.6442 | Actual Loss: 0.5731\n",
      "Baseline Loss: 2.7002 | Actual Loss: 0.4553\n",
      "Baseline Loss: 2.6589 | Actual Loss: 0.5858\n",
      "Baseline Loss: 2.6648 | Actual Loss: 0.6462\n",
      "Baseline Loss: 2.6799 | Actual Loss: 0.4647\n",
      "Baseline Loss: 2.6637 | Actual Loss: 0.4296\n",
      "Baseline Loss: 2.6766 | Actual Loss: 0.5093\n",
      "Baseline Loss: 2.7007 | Actual Loss: 0.4485\n",
      "Baseline Loss: 2.6768 | Actual Loss: 0.4355\n",
      "Baseline Loss: 2.6709 | Actual Loss: 0.5728\n",
      "Baseline Loss: 2.6806 | Actual Loss: 0.5418\n",
      "Baseline Loss: 2.2225 | Actual Loss: 0.5103\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.6697\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.5536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 28/1000 [00:08<05:18,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6861 | Actual Loss: 0.5668\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.4882\n",
      "Epoch 28/1000: Train Loss: 0.5186, Val Loss: 0.5696\n",
      "New best validation loss: 0.5696\n",
      "Baseline Loss: 2.6806 | Actual Loss: 0.4781\n",
      "Baseline Loss: 2.6724 | Actual Loss: 0.3229\n",
      "Baseline Loss: 2.6688 | Actual Loss: 0.4415\n",
      "Baseline Loss: 2.6538 | Actual Loss: 0.2558\n",
      "Baseline Loss: 2.6541 | Actual Loss: 0.4005\n",
      "Baseline Loss: 2.6890 | Actual Loss: 0.5636\n",
      "Baseline Loss: 2.6682 | Actual Loss: 0.3297\n",
      "Baseline Loss: 2.6889 | Actual Loss: 0.5754\n",
      "Baseline Loss: 2.6878 | Actual Loss: 0.4014\n",
      "Baseline Loss: 2.7005 | Actual Loss: 1.2191\n",
      "Baseline Loss: 2.6733 | Actual Loss: 0.4822\n",
      "Baseline Loss: 2.6436 | Actual Loss: 0.3070\n",
      "Baseline Loss: 2.6923 | Actual Loss: 0.5606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 29/1000 [00:09<04:53,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6982 | Actual Loss: 0.5606\n",
      "Baseline Loss: 2.7128 | Actual Loss: 0.3553\n",
      "Baseline Loss: 2.2177 | Actual Loss: 0.5319\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.6875\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.6507\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.6664\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.5390\n",
      "Epoch 29/1000: Train Loss: 0.4866, Val Loss: 0.6359\n",
      "Baseline Loss: 2.7084 | Actual Loss: 0.5480\n",
      "Baseline Loss: 2.7040 | Actual Loss: 0.4830\n",
      "Baseline Loss: 2.6468 | Actual Loss: 0.5615\n",
      "Baseline Loss: 2.7091 | Actual Loss: 0.5366\n",
      "Baseline Loss: 2.6414 | Actual Loss: 0.4732\n",
      "Baseline Loss: 2.6500 | Actual Loss: 0.4034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 30/1000 [00:09<05:12,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6919 | Actual Loss: 0.4958\n",
      "Baseline Loss: 2.6660 | Actual Loss: 0.5111\n",
      "Baseline Loss: 2.6781 | Actual Loss: 0.3801\n",
      "Baseline Loss: 2.6967 | Actual Loss: 0.4200\n",
      "Baseline Loss: 2.6891 | Actual Loss: 0.5903\n",
      "Baseline Loss: 2.6847 | Actual Loss: 0.6540\n",
      "Baseline Loss: 2.6793 | Actual Loss: 0.3734\n",
      "Baseline Loss: 2.6599 | Actual Loss: 0.4863\n",
      "Baseline Loss: 2.6676 | Actual Loss: 0.6505\n",
      "Baseline Loss: 2.3294 | Actual Loss: 0.3133\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.6113\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.5384\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.5779\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.4465\n",
      "Epoch 30/1000: Train Loss: 0.4925, Val Loss: 0.5435\n",
      "New best validation loss: 0.5435\n",
      "Baseline Loss: 2.6429 | Actual Loss: 0.5121\n",
      "Baseline Loss: 2.7060 | Actual Loss: 0.6843\n",
      "Baseline Loss: 2.6302 | Actual Loss: 0.5247\n",
      "Baseline Loss: 2.6716 | Actual Loss: 0.4640\n",
      "Baseline Loss: 2.6769 | Actual Loss: 0.5203\n",
      "Baseline Loss: 2.6598 | Actual Loss: 0.3377\n",
      "Baseline Loss: 2.6793 | Actual Loss: 0.4890\n",
      "Baseline Loss: 2.7048 | Actual Loss: 0.3908\n",
      "Baseline Loss: 2.6376 | Actual Loss: 0.3358\n",
      "Baseline Loss: 2.7004 | Actual Loss: 0.4313\n",
      "Baseline Loss: 2.6631 | Actual Loss: 0.4967\n",
      "Baseline Loss: 2.7246 | Actual Loss: 0.5398\n",
      "Baseline Loss: 2.6604 | Actual Loss: 0.4632\n",
      "Baseline Loss: 2.7122 | Actual Loss: 0.3761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 31/1000 [00:09<05:12,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7298 | Actual Loss: 0.4439\n",
      "Baseline Loss: 2.2841 | Actual Loss: 0.4094\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.6680\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.5090\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.6003\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.5464\n",
      "Epoch 31/1000: Train Loss: 0.4637, Val Loss: 0.5809\n",
      "Baseline Loss: 2.6517 | Actual Loss: 0.3973\n",
      "Baseline Loss: 2.6827 | Actual Loss: 0.4497\n",
      "Baseline Loss: 2.6460 | Actual Loss: 0.3165\n",
      "Baseline Loss: 2.6899 | Actual Loss: 0.3175\n",
      "Baseline Loss: 2.6641 | Actual Loss: 0.4584\n",
      "Baseline Loss: 2.6927 | Actual Loss: 0.2830\n",
      "Baseline Loss: 2.6909 | Actual Loss: 0.4804\n",
      "Baseline Loss: 2.6592 | Actual Loss: 0.4473\n",
      "Baseline Loss: 2.6915 | Actual Loss: 0.6674\n",
      "Baseline Loss: 2.6698 | Actual Loss: 0.5081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 32/1000 [00:10<04:56,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6993 | Actual Loss: 0.6140\n",
      "Baseline Loss: 2.6744 | Actual Loss: 0.4889\n",
      "Baseline Loss: 2.6743 | Actual Loss: 0.4565\n",
      "Baseline Loss: 2.6727 | Actual Loss: 0.4857\n",
      "Baseline Loss: 2.6875 | Actual Loss: 0.5018\n",
      "Baseline Loss: 2.2282 | Actual Loss: 0.1755\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.6732\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.6007\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.6399\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.5536\n",
      "Epoch 32/1000: Train Loss: 0.4405, Val Loss: 0.6168\n",
      "Baseline Loss: 2.6679 | Actual Loss: 0.4914\n",
      "Baseline Loss: 2.7103 | Actual Loss: 0.5863\n",
      "Baseline Loss: 2.6476 | Actual Loss: 0.6715\n",
      "Baseline Loss: 2.6439 | Actual Loss: 0.5191\n",
      "Baseline Loss: 2.6705 | Actual Loss: 0.5128\n",
      "Baseline Loss: 2.6790 | Actual Loss: 0.7299\n",
      "Baseline Loss: 2.6692 | Actual Loss: 0.4882\n",
      "Baseline Loss: 2.6752 | Actual Loss: 0.4681\n",
      "Baseline Loss: 2.6412 | Actual Loss: 0.5290\n",
      "Baseline Loss: 2.6683 | Actual Loss: 0.4874\n",
      "Baseline Loss: 2.6225 | Actual Loss: 0.4480\n",
      "Baseline Loss: 2.7038 | Actual Loss: 0.3384\n",
      "Baseline Loss: 2.7070 | Actual Loss: 0.3977\n",
      "Baseline Loss: 2.6707 | Actual Loss: 0.5867\n",
      "Baseline Loss: 2.7297 | Actual Loss: 0.4575\n",
      "Baseline Loss: 2.3189 | Actual Loss: 0.2281\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.6976\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.5053\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.6039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 33/1000 [00:10<05:07,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5615 | Actual Loss: 0.4199\n",
      "Epoch 33/1000: Train Loss: 0.4963, Val Loss: 0.5567\n",
      "Baseline Loss: 2.6497 | Actual Loss: 0.4316\n",
      "Baseline Loss: 2.6854 | Actual Loss: 0.5025\n",
      "Baseline Loss: 2.6602 | Actual Loss: 0.4220\n",
      "Baseline Loss: 2.6960 | Actual Loss: 0.3860\n",
      "Baseline Loss: 2.6880 | Actual Loss: 0.4940\n",
      "Baseline Loss: 2.6958 | Actual Loss: 0.5765\n",
      "Baseline Loss: 2.6512 | Actual Loss: 0.5685\n",
      "Baseline Loss: 2.6512 | Actual Loss: 0.7709\n",
      "Baseline Loss: 2.6803 | Actual Loss: 0.4197\n",
      "Baseline Loss: 2.6303 | Actual Loss: 0.3482\n",
      "Baseline Loss: 2.6796 | Actual Loss: 0.4515\n",
      "Baseline Loss: 2.6856 | Actual Loss: 0.4166\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.5300\n",
      "Baseline Loss: 2.7467 | Actual Loss: 0.4558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 34/1000 [00:10<05:19,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6870 | Actual Loss: 0.3287\n",
      "Baseline Loss: 2.2516 | Actual Loss: 0.5568\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5371\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.5862\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.5651\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.4670\n",
      "Epoch 34/1000: Train Loss: 0.4787, Val Loss: 0.5388\n",
      "New best validation loss: 0.5388\n",
      "Baseline Loss: 2.6616 | Actual Loss: 0.3790\n",
      "Baseline Loss: 2.6316 | Actual Loss: 0.4313\n",
      "Baseline Loss: 2.6909 | Actual Loss: 0.5036\n",
      "Baseline Loss: 2.6676 | Actual Loss: 0.4963\n",
      "Baseline Loss: 2.6426 | Actual Loss: 0.4426\n",
      "Baseline Loss: 2.6787 | Actual Loss: 0.3584\n",
      "Baseline Loss: 2.6550 | Actual Loss: 0.3719\n",
      "Baseline Loss: 2.6855 | Actual Loss: 0.4538\n",
      "Baseline Loss: 2.6739 | Actual Loss: 0.6091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 35/1000 [00:11<05:03,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6835 | Actual Loss: 0.3963\n",
      "Baseline Loss: 2.7447 | Actual Loss: 0.4078\n",
      "Baseline Loss: 2.7000 | Actual Loss: 0.5531\n",
      "Baseline Loss: 2.6552 | Actual Loss: 0.4753\n",
      "Baseline Loss: 2.6883 | Actual Loss: 0.3325\n",
      "Baseline Loss: 2.6459 | Actual Loss: 0.6238\n",
      "Baseline Loss: 2.2326 | Actual Loss: 0.2396\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5609\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.5076\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4764\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.5904\n",
      "Epoch 35/1000: Train Loss: 0.4421, Val Loss: 0.5338\n",
      "New best validation loss: 0.5338\n",
      "Baseline Loss: 2.6993 | Actual Loss: 0.5252\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.4093\n",
      "Baseline Loss: 2.6520 | Actual Loss: 0.4633\n",
      "Baseline Loss: 2.6597 | Actual Loss: 0.4305\n",
      "Baseline Loss: 2.6737 | Actual Loss: 0.4606\n",
      "Baseline Loss: 2.6354 | Actual Loss: 0.8004\n",
      "Baseline Loss: 2.6649 | Actual Loss: 0.5856\n",
      "Baseline Loss: 2.6438 | Actual Loss: 0.3182\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.5879\n",
      "Baseline Loss: 2.6864 | Actual Loss: 0.4933\n",
      "Baseline Loss: 2.7064 | Actual Loss: 0.5022\n",
      "Baseline Loss: 2.6490 | Actual Loss: 0.3713\n",
      "Baseline Loss: 2.6665 | Actual Loss: 0.4314\n",
      "Baseline Loss: 2.6955 | Actual Loss: 0.3973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 36/1000 [00:11<05:09,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6475 | Actual Loss: 0.3811\n",
      "Baseline Loss: 2.2886 | Actual Loss: 0.2970\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.6358\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.5041\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.5583\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.4361\n",
      "Epoch 36/1000: Train Loss: 0.4659, Val Loss: 0.5336\n",
      "New best validation loss: 0.5336\n",
      "Baseline Loss: 2.7210 | Actual Loss: 0.5249\n",
      "Baseline Loss: 2.6686 | Actual Loss: 0.3967\n",
      "Baseline Loss: 2.6307 | Actual Loss: 0.3608\n",
      "Baseline Loss: 2.6509 | Actual Loss: 0.4247\n",
      "Baseline Loss: 2.6814 | Actual Loss: 0.6794\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4247\n",
      "Baseline Loss: 2.6504 | Actual Loss: 0.3535\n",
      "Baseline Loss: 2.6478 | Actual Loss: 0.4014\n",
      "Baseline Loss: 2.6727 | Actual Loss: 0.4760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 37/1000 [00:11<04:49,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6942 | Actual Loss: 0.3936\n",
      "Baseline Loss: 2.6529 | Actual Loss: 0.4218\n",
      "Baseline Loss: 2.6787 | Actual Loss: 0.4719\n",
      "Baseline Loss: 2.6926 | Actual Loss: 0.4517\n",
      "Baseline Loss: 2.6295 | Actual Loss: 0.3828\n",
      "Baseline Loss: 2.7256 | Actual Loss: 0.4508\n",
      "Baseline Loss: 2.2640 | Actual Loss: 0.3716\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.6250\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.5410\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4955\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.4534\n",
      "Epoch 37/1000: Train Loss: 0.4366, Val Loss: 0.5287\n",
      "New best validation loss: 0.5287\n",
      "Baseline Loss: 2.6739 | Actual Loss: 0.2410\n",
      "Baseline Loss: 2.6740 | Actual Loss: 0.2857\n",
      "Baseline Loss: 2.6367 | Actual Loss: 0.4654\n",
      "Baseline Loss: 2.6751 | Actual Loss: 0.4086\n",
      "Baseline Loss: 2.7053 | Actual Loss: 0.3564\n",
      "Baseline Loss: 2.6860 | Actual Loss: 0.5459\n",
      "Baseline Loss: 2.6791 | Actual Loss: 0.3701\n",
      "Baseline Loss: 2.7376 | Actual Loss: 0.6457\n",
      "Baseline Loss: 2.6296 | Actual Loss: 0.4201\n",
      "Baseline Loss: 2.6689 | Actual Loss: 0.3752\n",
      "Baseline Loss: 2.6556 | Actual Loss: 0.4621\n",
      "Baseline Loss: 2.6506 | Actual Loss: 0.3452\n",
      "Baseline Loss: 2.6646 | Actual Loss: 0.3166\n",
      "Baseline Loss: 2.6935 | Actual Loss: 0.4288\n",
      "Baseline Loss: 2.6792 | Actual Loss: 0.3908\n",
      "Baseline Loss: 2.2483 | Actual Loss: 0.1997\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.6224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 38/1000 [00:11<05:06,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6474 | Actual Loss: 0.4701\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.5553\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.3797\n",
      "Epoch 38/1000: Train Loss: 0.3911, Val Loss: 0.5069\n",
      "New best validation loss: 0.5069\n",
      "Baseline Loss: 2.6823 | Actual Loss: 0.7046\n",
      "Baseline Loss: 2.6499 | Actual Loss: 0.4967\n",
      "Baseline Loss: 2.6639 | Actual Loss: 0.3337\n",
      "Baseline Loss: 2.6756 | Actual Loss: 0.4621\n",
      "Baseline Loss: 2.6805 | Actual Loss: 0.3928\n",
      "Baseline Loss: 2.7281 | Actual Loss: 0.5236\n",
      "Baseline Loss: 2.6504 | Actual Loss: 0.3088\n",
      "Baseline Loss: 2.6669 | Actual Loss: 0.5212\n",
      "Baseline Loss: 2.6827 | Actual Loss: 0.5099\n",
      "Baseline Loss: 2.6776 | Actual Loss: 0.5238\n",
      "Baseline Loss: 2.6835 | Actual Loss: 0.3487\n",
      "Baseline Loss: 2.6560 | Actual Loss: 0.5360\n",
      "Baseline Loss: 2.7188 | Actual Loss: 0.3540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 39/1000 [00:12<04:50,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6899 | Actual Loss: 0.3334\n",
      "Baseline Loss: 2.6585 | Actual Loss: 0.3603\n",
      "Baseline Loss: 2.2540 | Actual Loss: 0.9029\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5307\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.6189\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.5545\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.4523\n",
      "Epoch 39/1000: Train Loss: 0.4758, Val Loss: 0.5391\n",
      "Baseline Loss: 2.6437 | Actual Loss: 0.3481\n",
      "Baseline Loss: 2.6918 | Actual Loss: 0.4447\n",
      "Baseline Loss: 2.7021 | Actual Loss: 0.5825\n",
      "Baseline Loss: 2.7136 | Actual Loss: 0.5573\n",
      "Baseline Loss: 2.6820 | Actual Loss: 0.4358\n",
      "Baseline Loss: 2.6456 | Actual Loss: 0.6101\n",
      "Baseline Loss: 2.6538 | Actual Loss: 0.9726\n",
      "Baseline Loss: 2.6536 | Actual Loss: 0.6478\n",
      "Baseline Loss: 2.6961 | Actual Loss: 0.4593\n",
      "Baseline Loss: 2.6778 | Actual Loss: 0.3943\n",
      "Baseline Loss: 2.7013 | Actual Loss: 0.4285\n",
      "Baseline Loss: 2.6635 | Actual Loss: 0.3577\n",
      "Baseline Loss: 2.6653 | Actual Loss: 0.3118\n",
      "Baseline Loss: 2.6581 | Actual Loss: 0.4900\n",
      "Baseline Loss: 2.6794 | Actual Loss: 0.3198\n",
      "Baseline Loss: 2.3153 | Actual Loss: 0.2919\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.7267\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 40/1000 [00:12<05:02,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6861 | Actual Loss: 0.4495\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.4748\n",
      "Epoch 40/1000: Train Loss: 0.4783, Val Loss: 0.5321\n",
      "Baseline Loss: 2.6621 | Actual Loss: 0.6208\n",
      "Baseline Loss: 2.6630 | Actual Loss: 0.4690\n",
      "Baseline Loss: 2.6783 | Actual Loss: 0.4448\n",
      "Baseline Loss: 2.6876 | Actual Loss: 0.3704\n",
      "Baseline Loss: 2.6749 | Actual Loss: 0.3773\n",
      "Baseline Loss: 2.6701 | Actual Loss: 0.6158\n",
      "Baseline Loss: 2.6827 | Actual Loss: 0.5774\n",
      "Baseline Loss: 2.7077 | Actual Loss: 0.2468\n",
      "Baseline Loss: 2.6708 | Actual Loss: 0.4712\n",
      "Baseline Loss: 2.6888 | Actual Loss: 0.2805\n",
      "Baseline Loss: 2.6753 | Actual Loss: 0.3923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 41/1000 [00:12<05:09,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6640 | Actual Loss: 0.7253\n",
      "Baseline Loss: 2.6832 | Actual Loss: 0.4866\n",
      "Baseline Loss: 2.6552 | Actual Loss: 0.3717\n",
      "Baseline Loss: 2.6436 | Actual Loss: 0.3776\n",
      "Baseline Loss: 2.2868 | Actual Loss: 0.3574\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.6867\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.5335\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.5960\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.3898\n",
      "Epoch 41/1000: Train Loss: 0.4491, Val Loss: 0.5515\n",
      "Baseline Loss: 2.7067 | Actual Loss: 0.3746\n",
      "Baseline Loss: 2.6262 | Actual Loss: 0.4537\n",
      "Baseline Loss: 2.6898 | Actual Loss: 0.4592\n",
      "Baseline Loss: 2.6914 | Actual Loss: 0.3723\n",
      "Baseline Loss: 2.6492 | Actual Loss: 0.4546\n",
      "Baseline Loss: 2.6555 | Actual Loss: 0.4012\n",
      "Baseline Loss: 2.6954 | Actual Loss: 0.3337\n",
      "Baseline Loss: 2.6436 | Actual Loss: 0.5227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 42/1000 [00:13<04:50,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6578 | Actual Loss: 0.4494\n",
      "Baseline Loss: 2.7052 | Actual Loss: 0.4479\n",
      "Baseline Loss: 2.6715 | Actual Loss: 0.4853\n",
      "Baseline Loss: 2.6938 | Actual Loss: 0.5292\n",
      "Baseline Loss: 2.6426 | Actual Loss: 0.3767\n",
      "Baseline Loss: 2.6625 | Actual Loss: 0.6458\n",
      "Baseline Loss: 2.6387 | Actual Loss: 0.4460\n",
      "Baseline Loss: 2.3544 | Actual Loss: 0.2600\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.6257\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4904\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.5053\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.4414\n",
      "Epoch 42/1000: Train Loss: 0.4383, Val Loss: 0.5157\n",
      "Baseline Loss: 2.6455 | Actual Loss: 0.4806\n",
      "Baseline Loss: 2.7152 | Actual Loss: 0.5104\n",
      "Baseline Loss: 2.6568 | Actual Loss: 0.5208\n",
      "Baseline Loss: 2.6613 | Actual Loss: 0.3202\n",
      "Baseline Loss: 2.7033 | Actual Loss: 0.3401\n",
      "Baseline Loss: 2.7164 | Actual Loss: 0.4333\n",
      "Baseline Loss: 2.6778 | Actual Loss: 0.2893\n",
      "Baseline Loss: 2.6597 | Actual Loss: 0.5969\n",
      "Baseline Loss: 2.7034 | Actual Loss: 0.4368\n",
      "Baseline Loss: 2.6692 | Actual Loss: 0.5436\n",
      "Baseline Loss: 2.6869 | Actual Loss: 0.5194\n",
      "Baseline Loss: 2.6412 | Actual Loss: 0.3139\n",
      "Baseline Loss: 2.6804 | Actual Loss: 0.3684\n",
      "Baseline Loss: 2.6834 | Actual Loss: 0.5191\n",
      "Baseline Loss: 2.6503 | Actual Loss: 0.5262\n",
      "Baseline Loss: 2.3104 | Actual Loss: 0.5137\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4917\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.5149\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4353\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.4923\n",
      "Epoch 43/1000: Train Loss: 0.4520, Val Loss: 0.4836\n",
      "New best validation loss: 0.4836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 43/1000 [00:13<04:58,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6858 | Actual Loss: 0.5925\n",
      "Baseline Loss: 2.6905 | Actual Loss: 0.5561\n",
      "Baseline Loss: 2.6891 | Actual Loss: 0.3166\n",
      "Baseline Loss: 2.6820 | Actual Loss: 0.5225\n",
      "Baseline Loss: 2.7210 | Actual Loss: 0.4786\n",
      "Baseline Loss: 2.6488 | Actual Loss: 0.4051\n",
      "Baseline Loss: 2.6741 | Actual Loss: 0.2067\n",
      "Baseline Loss: 2.6375 | Actual Loss: 0.3876\n",
      "Baseline Loss: 2.6549 | Actual Loss: 0.3613\n",
      "Baseline Loss: 2.6581 | Actual Loss: 0.4937\n",
      "Baseline Loss: 2.6355 | Actual Loss: 0.4638\n",
      "Baseline Loss: 2.6904 | Actual Loss: 0.3727\n",
      "Baseline Loss: 2.7028 | Actual Loss: 0.4057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 44/1000 [00:13<05:08,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6883 | Actual Loss: 0.2884\n",
      "Baseline Loss: 2.6901 | Actual Loss: 0.5054\n",
      "Baseline Loss: 2.2815 | Actual Loss: 0.2501\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.6201\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4192\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4950\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.4733\n",
      "Epoch 44/1000: Train Loss: 0.4129, Val Loss: 0.5019\n",
      "Baseline Loss: 2.6534 | Actual Loss: 0.3643\n",
      "Baseline Loss: 2.6714 | Actual Loss: 0.3148\n",
      "Baseline Loss: 2.7175 | Actual Loss: 0.4420\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4401\n",
      "Baseline Loss: 2.7007 | Actual Loss: 0.2859\n",
      "Baseline Loss: 2.6613 | Actual Loss: 0.4372\n",
      "Baseline Loss: 2.6980 | Actual Loss: 0.4621\n",
      "Baseline Loss: 2.6915 | Actual Loss: 0.1496\n",
      "Baseline Loss: 2.7022 | Actual Loss: 0.5857\n",
      "Baseline Loss: 2.6494 | Actual Loss: 0.3476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 45/1000 [00:14<04:52,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6608 | Actual Loss: 0.5355\n",
      "Baseline Loss: 2.6741 | Actual Loss: 0.3026\n",
      "Baseline Loss: 2.6619 | Actual Loss: 0.5426\n",
      "Baseline Loss: 2.6680 | Actual Loss: 0.3278\n",
      "Baseline Loss: 2.6595 | Actual Loss: 0.4212\n",
      "Baseline Loss: 2.3404 | Actual Loss: 0.3846\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5256\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4563\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4911\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.3536\n",
      "Epoch 45/1000: Train Loss: 0.3965, Val Loss: 0.4566\n",
      "New best validation loss: 0.4566\n",
      "Baseline Loss: 2.6704 | Actual Loss: 0.2336\n",
      "Baseline Loss: 2.6812 | Actual Loss: 0.3216\n",
      "Baseline Loss: 2.6511 | Actual Loss: 0.3174\n",
      "Baseline Loss: 2.7092 | Actual Loss: 0.4739\n",
      "Baseline Loss: 2.6608 | Actual Loss: 0.4521\n",
      "Baseline Loss: 2.6844 | Actual Loss: 0.7833\n",
      "Baseline Loss: 2.6603 | Actual Loss: 0.4214\n",
      "Baseline Loss: 2.6808 | Actual Loss: 0.4364\n",
      "Baseline Loss: 2.6706 | Actual Loss: 0.4484\n",
      "Baseline Loss: 2.6683 | Actual Loss: 0.3613\n",
      "Baseline Loss: 2.6606 | Actual Loss: 0.4995\n",
      "Baseline Loss: 2.6569 | Actual Loss: 0.3307\n",
      "Baseline Loss: 2.6972 | Actual Loss: 0.3035\n",
      "Baseline Loss: 2.6550 | Actual Loss: 0.3108\n",
      "Baseline Loss: 2.7274 | Actual Loss: 0.5707\n",
      "Baseline Loss: 2.2996 | Actual Loss: 0.2341\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5823\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 46/1000 [00:14<04:58,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6861 | Actual Loss: 0.5219\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.4659\n",
      "Epoch 46/1000: Train Loss: 0.4062, Val Loss: 0.5138\n",
      "Baseline Loss: 2.6702 | Actual Loss: 0.3850\n",
      "Baseline Loss: 2.6802 | Actual Loss: 0.2697\n",
      "Baseline Loss: 2.6391 | Actual Loss: 0.3954\n",
      "Baseline Loss: 2.7020 | Actual Loss: 0.4426\n",
      "Baseline Loss: 2.6890 | Actual Loss: 0.2814\n",
      "Baseline Loss: 2.6534 | Actual Loss: 0.4679\n",
      "Baseline Loss: 2.6610 | Actual Loss: 0.2563\n",
      "Baseline Loss: 2.6733 | Actual Loss: 0.6579\n",
      "Baseline Loss: 2.6842 | Actual Loss: 0.3315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 47/1000 [00:14<05:03,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6630 | Actual Loss: 0.3420\n",
      "Baseline Loss: 2.7502 | Actual Loss: 0.3770\n",
      "Baseline Loss: 2.6926 | Actual Loss: 0.5574\n",
      "Baseline Loss: 2.6896 | Actual Loss: 0.3320\n",
      "Baseline Loss: 2.6515 | Actual Loss: 0.6422\n",
      "Baseline Loss: 2.6863 | Actual Loss: 0.4477\n",
      "Baseline Loss: 2.2493 | Actual Loss: 0.4965\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4630\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.5730\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4671\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.5001\n",
      "Epoch 47/1000: Train Loss: 0.4177, Val Loss: 0.5008\n",
      "Baseline Loss: 2.7047 | Actual Loss: 0.5101\n",
      "Baseline Loss: 2.6544 | Actual Loss: 0.5132\n",
      "Baseline Loss: 2.6543 | Actual Loss: 0.4230\n",
      "Baseline Loss: 2.6769 | Actual Loss: 0.4814\n",
      "Baseline Loss: 2.7273 | Actual Loss: 0.3832\n",
      "Baseline Loss: 2.7248 | Actual Loss: 0.5517\n",
      "Baseline Loss: 2.6920 | Actual Loss: 0.4604\n",
      "Baseline Loss: 2.6401 | Actual Loss: 0.4707\n",
      "Baseline Loss: 2.6643 | Actual Loss: 0.3855\n",
      "Baseline Loss: 2.7097 | Actual Loss: 0.3986\n",
      "Baseline Loss: 2.6466 | Actual Loss: 0.5292\n",
      "Baseline Loss: 2.6508 | Actual Loss: 0.4343\n",
      "Baseline Loss: 2.6922 | Actual Loss: 0.2323\n",
      "Baseline Loss: 2.6618 | Actual Loss: 0.4824\n",
      "Baseline Loss: 2.6545 | Actual Loss: 0.7737\n",
      "Baseline Loss: 2.2555 | Actual Loss: 0.2400\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 48/1000 [00:15<05:09,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6474 | Actual Loss: 0.4510\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4651\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.3477\n",
      "Epoch 48/1000: Train Loss: 0.4544, Val Loss: 0.4560\n",
      "New best validation loss: 0.4560\n",
      "Baseline Loss: 2.6977 | Actual Loss: 0.5592\n",
      "Baseline Loss: 2.7260 | Actual Loss: 0.2584\n",
      "Baseline Loss: 2.6641 | Actual Loss: 0.3596\n",
      "Baseline Loss: 2.6812 | Actual Loss: 0.3957\n",
      "Baseline Loss: 2.6917 | Actual Loss: 0.4587\n",
      "Baseline Loss: 2.6988 | Actual Loss: 0.3310\n",
      "Baseline Loss: 2.6463 | Actual Loss: 0.3803\n",
      "Baseline Loss: 2.6191 | Actual Loss: 0.3017\n",
      "Baseline Loss: 2.6769 | Actual Loss: 0.1231\n",
      "Baseline Loss: 2.6597 | Actual Loss: 0.2490\n",
      "Baseline Loss: 2.6574 | Actual Loss: 0.3442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 49/1000 [00:15<04:54,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6435 | Actual Loss: 0.2548\n",
      "Baseline Loss: 2.6671 | Actual Loss: 0.3417\n",
      "Baseline Loss: 2.6596 | Actual Loss: 0.4596\n",
      "Baseline Loss: 2.7070 | Actual Loss: 0.4343\n",
      "Baseline Loss: 2.2851 | Actual Loss: 0.1347\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5750\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4778\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.5106\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.4191\n",
      "Epoch 49/1000: Train Loss: 0.3366, Val Loss: 0.4956\n",
      "Baseline Loss: 2.6354 | Actual Loss: 0.6220\n",
      "Baseline Loss: 2.6802 | Actual Loss: 0.4174\n",
      "Baseline Loss: 2.6845 | Actual Loss: 0.4249\n",
      "Baseline Loss: 2.7182 | Actual Loss: 0.3810\n",
      "Baseline Loss: 2.6869 | Actual Loss: 0.3281\n",
      "Baseline Loss: 2.6681 | Actual Loss: 0.5406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 50/1000 [00:15<05:00,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6781 | Actual Loss: 0.3388\n",
      "Baseline Loss: 2.7085 | Actual Loss: 0.4645\n",
      "Baseline Loss: 2.6555 | Actual Loss: 0.3135\n",
      "Baseline Loss: 2.6583 | Actual Loss: 0.4591\n",
      "Baseline Loss: 2.6464 | Actual Loss: 0.5015\n",
      "Baseline Loss: 2.6808 | Actual Loss: 0.4096\n",
      "Baseline Loss: 2.6689 | Actual Loss: 0.3193\n",
      "Baseline Loss: 2.6607 | Actual Loss: 0.4594\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.4280\n",
      "Baseline Loss: 2.3301 | Actual Loss: 0.3992\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4104\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.5043\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.5218\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.4295\n",
      "Epoch 50/1000: Train Loss: 0.4254, Val Loss: 0.4665\n",
      "Baseline Loss: 2.6303 | Actual Loss: 0.4037\n",
      "Baseline Loss: 2.7117 | Actual Loss: 0.5817\n",
      "Baseline Loss: 2.6974 | Actual Loss: 0.6282\n",
      "Baseline Loss: 2.6923 | Actual Loss: 0.6544\n",
      "Baseline Loss: 2.6766 | Actual Loss: 0.2839\n",
      "Baseline Loss: 2.6720 | Actual Loss: 0.6636\n",
      "Baseline Loss: 2.6564 | Actual Loss: 0.4665\n",
      "Baseline Loss: 2.7242 | Actual Loss: 0.4843\n",
      "Baseline Loss: 2.6682 | Actual Loss: 0.6619\n",
      "Baseline Loss: 2.6624 | Actual Loss: 0.3803\n",
      "Baseline Loss: 2.6529 | Actual Loss: 0.2750\n",
      "Baseline Loss: 2.6914 | Actual Loss: 0.3803\n",
      "Baseline Loss: 2.7222 | Actual Loss: 0.4547\n",
      "Baseline Loss: 2.6503 | Actual Loss: 0.4411\n",
      "Baseline Loss: 2.6654 | Actual Loss: 0.3578\n",
      "Baseline Loss: 2.2675 | Actual Loss: 0.1238\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.6192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 51/1000 [00:16<05:05,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6474 | Actual Loss: 0.4245\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4815\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.4826\n",
      "Epoch 51/1000: Train Loss: 0.4526, Val Loss: 0.5019\n",
      "Baseline Loss: 2.7182 | Actual Loss: 0.5254\n",
      "Baseline Loss: 2.6616 | Actual Loss: 0.2575\n",
      "Baseline Loss: 2.6438 | Actual Loss: 0.4823\n",
      "Baseline Loss: 2.6651 | Actual Loss: 0.3994\n",
      "Baseline Loss: 2.6541 | Actual Loss: 0.2451\n",
      "Baseline Loss: 2.7232 | Actual Loss: 0.4995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 52/1000 [00:16<04:52,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6662 | Actual Loss: 0.3466\n",
      "Baseline Loss: 2.6512 | Actual Loss: 0.4039\n",
      "Baseline Loss: 2.6802 | Actual Loss: 0.3814\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.3859\n",
      "Baseline Loss: 2.6615 | Actual Loss: 0.3663\n",
      "Baseline Loss: 2.6786 | Actual Loss: 0.4248\n",
      "Baseline Loss: 2.6620 | Actual Loss: 0.2813\n",
      "Baseline Loss: 2.6855 | Actual Loss: 0.3101\n",
      "Baseline Loss: 2.6823 | Actual Loss: 0.4585\n",
      "Baseline Loss: 2.2850 | Actual Loss: 0.5024\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5656\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4489\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4724\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.3811\n",
      "Epoch 52/1000: Train Loss: 0.3919, Val Loss: 0.4670\n",
      "Baseline Loss: 2.6695 | Actual Loss: 0.2386\n",
      "Baseline Loss: 2.6897 | Actual Loss: 0.3289\n",
      "Baseline Loss: 2.6457 | Actual Loss: 0.4648\n",
      "Baseline Loss: 2.7035 | Actual Loss: 0.3022\n",
      "Baseline Loss: 2.6976 | Actual Loss: 0.3748\n",
      "Baseline Loss: 2.6498 | Actual Loss: 0.4781\n",
      "Baseline Loss: 2.6602 | Actual Loss: 0.3121\n",
      "Baseline Loss: 2.7146 | Actual Loss: 0.3568\n",
      "Baseline Loss: 2.7250 | Actual Loss: 0.4402\n",
      "Baseline Loss: 2.6971 | Actual Loss: 0.5520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 53/1000 [00:16<05:04,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6427 | Actual Loss: 0.2832\n",
      "Baseline Loss: 2.6487 | Actual Loss: 0.3860\n",
      "Baseline Loss: 2.6845 | Actual Loss: 0.8418\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.3432\n",
      "Baseline Loss: 2.6915 | Actual Loss: 0.3689\n",
      "Baseline Loss: 2.3095 | Actual Loss: 0.3705\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5957\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4451\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4962\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.4526\n",
      "Epoch 53/1000: Train Loss: 0.4026, Val Loss: 0.4974\n",
      "Baseline Loss: 2.6692 | Actual Loss: 0.3758\n",
      "Baseline Loss: 2.6870 | Actual Loss: 0.3084\n",
      "Baseline Loss: 2.6680 | Actual Loss: 0.2763\n",
      "Baseline Loss: 2.6924 | Actual Loss: 0.5135\n",
      "Baseline Loss: 2.6975 | Actual Loss: 0.3995\n",
      "Baseline Loss: 2.7095 | Actual Loss: 0.3329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 54/1000 [00:16<04:46,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6360 | Actual Loss: 0.3739\n",
      "Baseline Loss: 2.6610 | Actual Loss: 0.4024\n",
      "Baseline Loss: 2.6720 | Actual Loss: 0.3749\n",
      "Baseline Loss: 2.6655 | Actual Loss: 0.3899\n",
      "Baseline Loss: 2.6812 | Actual Loss: 0.2235\n",
      "Baseline Loss: 2.6679 | Actual Loss: 0.5185\n",
      "Baseline Loss: 2.6201 | Actual Loss: 0.3363\n",
      "Baseline Loss: 2.6312 | Actual Loss: 0.5664\n",
      "Baseline Loss: 2.6574 | Actual Loss: 0.5862\n",
      "Baseline Loss: 2.2877 | Actual Loss: 0.1323\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5175\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.5433\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4675\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.3376\n",
      "Epoch 54/1000: Train Loss: 0.3819, Val Loss: 0.4665\n",
      "Baseline Loss: 2.6436 | Actual Loss: 0.3510\n",
      "Baseline Loss: 2.6676 | Actual Loss: 0.3079\n",
      "Baseline Loss: 2.6593 | Actual Loss: 0.2718\n",
      "Baseline Loss: 2.6533 | Actual Loss: 0.4627\n",
      "Baseline Loss: 2.6809 | Actual Loss: 0.2618\n",
      "Baseline Loss: 2.6594 | Actual Loss: 0.4364\n",
      "Baseline Loss: 2.6890 | Actual Loss: 0.2202\n",
      "Baseline Loss: 2.6803 | Actual Loss: 0.3383\n",
      "Baseline Loss: 2.6601 | Actual Loss: 0.5637\n",
      "Baseline Loss: 2.6628 | Actual Loss: 0.3495\n",
      "Baseline Loss: 2.7067 | Actual Loss: 0.1937\n",
      "Baseline Loss: 2.6774 | Actual Loss: 0.3007\n",
      "Baseline Loss: 2.6887 | Actual Loss: 0.7183\n",
      "Baseline Loss: 2.6933 | Actual Loss: 0.2746\n",
      "Baseline Loss: 2.6696 | Actual Loss: 0.4387\n",
      "Baseline Loss: 2.3357 | Actual Loss: 0.4957\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4634\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 55/1000 [00:17<04:56,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6861 | Actual Loss: 0.4785\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.3476\n",
      "Epoch 55/1000: Train Loss: 0.3741, Val Loss: 0.4289\n",
      "New best validation loss: 0.4289\n",
      "Baseline Loss: 2.6846 | Actual Loss: 0.2341\n",
      "Baseline Loss: 2.7174 | Actual Loss: 0.5929\n",
      "Baseline Loss: 2.6646 | Actual Loss: 0.2896\n",
      "Baseline Loss: 2.6380 | Actual Loss: 0.3469\n",
      "Baseline Loss: 2.6734 | Actual Loss: 0.4941\n",
      "Baseline Loss: 2.6951 | Actual Loss: 0.4145\n",
      "Baseline Loss: 2.6893 | Actual Loss: 0.3877\n",
      "Baseline Loss: 2.6486 | Actual Loss: 0.3653\n",
      "Baseline Loss: 2.6518 | Actual Loss: 0.3490\n",
      "Baseline Loss: 2.6657 | Actual Loss: 0.4325\n",
      "Baseline Loss: 2.6855 | Actual Loss: 0.4314\n",
      "Baseline Loss: 2.6719 | Actual Loss: 0.2694\n",
      "Baseline Loss: 2.7162 | Actual Loss: 0.3506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 56/1000 [00:17<05:03,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6975 | Actual Loss: 0.5307\n",
      "Baseline Loss: 2.6799 | Actual Loss: 0.3687\n",
      "Baseline Loss: 2.2611 | Actual Loss: 0.2169\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4934\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4442\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4856\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.4604\n",
      "Epoch 56/1000: Train Loss: 0.3796, Val Loss: 0.4709\n",
      "Baseline Loss: 2.6791 | Actual Loss: 0.3254\n",
      "Baseline Loss: 2.6638 | Actual Loss: 0.2567\n",
      "Baseline Loss: 2.6529 | Actual Loss: 0.5386\n",
      "Baseline Loss: 2.6913 | Actual Loss: 0.3881\n",
      "Baseline Loss: 2.6895 | Actual Loss: 0.3327\n",
      "Baseline Loss: 2.6467 | Actual Loss: 0.3748\n",
      "Baseline Loss: 2.6621 | Actual Loss: 0.3252\n",
      "Baseline Loss: 2.6458 | Actual Loss: 0.3057\n",
      "Baseline Loss: 2.6502 | Actual Loss: 0.6778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 57/1000 [00:17<04:47,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6965 | Actual Loss: 0.5826\n",
      "Baseline Loss: 2.6499 | Actual Loss: 0.3284\n",
      "Baseline Loss: 2.6856 | Actual Loss: 0.4118\n",
      "Baseline Loss: 2.6726 | Actual Loss: 0.3466\n",
      "Baseline Loss: 2.6929 | Actual Loss: 0.4284\n",
      "Baseline Loss: 2.7298 | Actual Loss: 0.3738\n",
      "Baseline Loss: 2.3230 | Actual Loss: 0.2335\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4883\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4224\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.5080\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.3684\n",
      "Epoch 57/1000: Train Loss: 0.3894, Val Loss: 0.4468\n",
      "Baseline Loss: 2.6946 | Actual Loss: 0.3981\n",
      "Baseline Loss: 2.6721 | Actual Loss: 0.4644\n",
      "Baseline Loss: 2.6637 | Actual Loss: 0.3114\n",
      "Baseline Loss: 2.6852 | Actual Loss: 0.3950\n",
      "Baseline Loss: 2.7000 | Actual Loss: 0.3138\n",
      "Baseline Loss: 2.6301 | Actual Loss: 0.4254\n",
      "Baseline Loss: 2.6379 | Actual Loss: 0.4232\n",
      "Baseline Loss: 2.6904 | Actual Loss: 0.4142\n",
      "Baseline Loss: 2.6523 | Actual Loss: 0.4044\n",
      "Baseline Loss: 2.6796 | Actual Loss: 0.3090\n",
      "Baseline Loss: 2.6576 | Actual Loss: 0.5462\n",
      "Baseline Loss: 2.6731 | Actual Loss: 0.3544\n",
      "Baseline Loss: 2.6625 | Actual Loss: 0.2850\n",
      "Baseline Loss: 2.6994 | Actual Loss: 0.4653\n",
      "Baseline Loss: 2.6920 | Actual Loss: 0.3013\n",
      "Baseline Loss: 2.2169 | Actual Loss: 0.2375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 58/1000 [00:18<04:54,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6853 | Actual Loss: 0.5236\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.5004\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4181\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.3570\n",
      "Epoch 58/1000: Train Loss: 0.3780, Val Loss: 0.4498\n",
      "Baseline Loss: 2.6871 | Actual Loss: 0.2581\n",
      "Baseline Loss: 2.7081 | Actual Loss: 0.3117\n",
      "Baseline Loss: 2.6980 | Actual Loss: 0.3764\n",
      "Baseline Loss: 2.6780 | Actual Loss: 0.3418\n",
      "Baseline Loss: 2.6665 | Actual Loss: 0.3077\n",
      "Baseline Loss: 2.6690 | Actual Loss: 0.4334\n",
      "Baseline Loss: 2.7026 | Actual Loss: 0.4751\n",
      "Baseline Loss: 2.6537 | Actual Loss: 0.2968\n",
      "Baseline Loss: 2.6742 | Actual Loss: 0.2511\n",
      "Baseline Loss: 2.6533 | Actual Loss: 0.4043\n",
      "Baseline Loss: 2.6835 | Actual Loss: 0.4559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 59/1000 [00:18<04:37,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6987 | Actual Loss: 0.3505\n",
      "Baseline Loss: 2.6643 | Actual Loss: 0.3772\n",
      "Baseline Loss: 2.6558 | Actual Loss: 0.4072\n",
      "Baseline Loss: 2.6570 | Actual Loss: 0.6120\n",
      "Baseline Loss: 2.2930 | Actual Loss: 0.1820\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4488\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.5255\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4546\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.4033\n",
      "Epoch 59/1000: Train Loss: 0.3651, Val Loss: 0.4581\n",
      "Baseline Loss: 2.6408 | Actual Loss: 0.4334\n",
      "Baseline Loss: 2.7031 | Actual Loss: 0.3451\n",
      "Baseline Loss: 2.6467 | Actual Loss: 0.2970\n",
      "Baseline Loss: 2.7046 | Actual Loss: 0.3821\n",
      "Baseline Loss: 2.6915 | Actual Loss: 0.2770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 60/1000 [00:18<04:51,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7067 | Actual Loss: 0.4816\n",
      "Baseline Loss: 2.7156 | Actual Loss: 0.2905\n",
      "Baseline Loss: 2.6899 | Actual Loss: 0.2835\n",
      "Baseline Loss: 2.6664 | Actual Loss: 0.4042\n",
      "Baseline Loss: 2.6921 | Actual Loss: 0.3585\n",
      "Baseline Loss: 2.6698 | Actual Loss: 0.6832\n",
      "Baseline Loss: 2.6827 | Actual Loss: 0.2553\n",
      "Baseline Loss: 2.6506 | Actual Loss: 0.3804\n",
      "Baseline Loss: 2.6512 | Actual Loss: 0.2298\n",
      "Baseline Loss: 2.7071 | Actual Loss: 0.3573\n",
      "Baseline Loss: 2.3202 | Actual Loss: 0.2437\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4496\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.5310\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4803\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.4063\n",
      "Epoch 60/1000: Train Loss: 0.3564, Val Loss: 0.4668\n",
      "Baseline Loss: 2.6855 | Actual Loss: 0.4517\n",
      "Baseline Loss: 2.6622 | Actual Loss: 0.3172\n",
      "Baseline Loss: 2.6667 | Actual Loss: 0.3500\n",
      "Baseline Loss: 2.6891 | Actual Loss: 0.3845\n",
      "Baseline Loss: 2.6534 | Actual Loss: 0.3623\n",
      "Baseline Loss: 2.6603 | Actual Loss: 0.4176\n",
      "Baseline Loss: 2.6933 | Actual Loss: 0.2729\n",
      "Baseline Loss: 2.7012 | Actual Loss: 0.2184\n",
      "Baseline Loss: 2.6505 | Actual Loss: 0.3785\n",
      "Baseline Loss: 2.7045 | Actual Loss: 0.2909\n",
      "Baseline Loss: 2.7096 | Actual Loss: 0.5976\n",
      "Baseline Loss: 2.6834 | Actual Loss: 0.4237\n",
      "Baseline Loss: 2.6546 | Actual Loss: 0.2647\n",
      "Baseline Loss: 2.6437 | Actual Loss: 0.3459\n",
      "Baseline Loss: 2.6914 | Actual Loss: 0.2927\n",
      "Baseline Loss: 2.2649 | Actual Loss: 0.1410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 61/1000 [00:19<04:58,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6853 | Actual Loss: 0.5323\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4885\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4024\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.3334\n",
      "Epoch 61/1000: Train Loss: 0.3444, Val Loss: 0.4391\n",
      "Baseline Loss: 2.6714 | Actual Loss: 0.1947\n",
      "Baseline Loss: 2.6579 | Actual Loss: 0.5374\n",
      "Baseline Loss: 2.6891 | Actual Loss: 0.4482\n",
      "Baseline Loss: 2.6667 | Actual Loss: 0.4671\n",
      "Baseline Loss: 2.6959 | Actual Loss: 0.4676\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.3022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 62/1000 [00:19<04:47,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7001 | Actual Loss: 0.2570\n",
      "Baseline Loss: 2.6416 | Actual Loss: 0.4424\n",
      "Baseline Loss: 2.6595 | Actual Loss: 0.3428\n",
      "Baseline Loss: 2.6860 | Actual Loss: 0.3747\n",
      "Baseline Loss: 2.6652 | Actual Loss: 0.2798\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.3893\n",
      "Baseline Loss: 2.6205 | Actual Loss: 0.2423\n",
      "Baseline Loss: 2.6939 | Actual Loss: 0.2836\n",
      "Baseline Loss: 2.6518 | Actual Loss: 0.2832\n",
      "Baseline Loss: 2.3412 | Actual Loss: 0.2435\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4005\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4270\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4307\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.3050\n",
      "Epoch 62/1000: Train Loss: 0.3472, Val Loss: 0.3908\n",
      "New best validation loss: 0.3908\n",
      "Baseline Loss: 2.6554 | Actual Loss: 0.4107\n",
      "Baseline Loss: 2.6726 | Actual Loss: 0.3878\n",
      "Baseline Loss: 2.6797 | Actual Loss: 0.2393\n",
      "Baseline Loss: 2.6945 | Actual Loss: 0.5415\n",
      "Baseline Loss: 2.6564 | Actual Loss: 0.4852\n",
      "Baseline Loss: 2.6539 | Actual Loss: 0.2977\n",
      "Baseline Loss: 2.6478 | Actual Loss: 0.3886\n",
      "Baseline Loss: 2.6725 | Actual Loss: 0.3209\n",
      "Baseline Loss: 2.6671 | Actual Loss: 0.4189\n",
      "Baseline Loss: 2.6787 | Actual Loss: 0.3576\n",
      "Baseline Loss: 2.6551 | Actual Loss: 0.1986\n",
      "Baseline Loss: 2.6660 | Actual Loss: 0.3461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 63/1000 [00:19<04:51,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6772 | Actual Loss: 0.3127\n",
      "Baseline Loss: 2.7521 | Actual Loss: 0.2319\n",
      "Baseline Loss: 2.6731 | Actual Loss: 0.3952\n",
      "Baseline Loss: 2.2948 | Actual Loss: 0.1333\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5221\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4246\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4840\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.3638\n",
      "Epoch 63/1000: Train Loss: 0.3416, Val Loss: 0.4486\n",
      "Baseline Loss: 2.6844 | Actual Loss: 0.2633\n",
      "Baseline Loss: 2.6809 | Actual Loss: 0.2746\n",
      "Baseline Loss: 2.6610 | Actual Loss: 0.2904\n",
      "Baseline Loss: 2.6527 | Actual Loss: 0.3226\n",
      "Baseline Loss: 2.6837 | Actual Loss: 0.3761\n",
      "Baseline Loss: 2.7128 | Actual Loss: 0.2316\n",
      "Baseline Loss: 2.6236 | Actual Loss: 0.3262\n",
      "Baseline Loss: 2.6846 | Actual Loss: 0.5880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 64/1000 [00:20<04:37,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6494 | Actual Loss: 0.3883\n",
      "Baseline Loss: 2.6937 | Actual Loss: 0.3958\n",
      "Baseline Loss: 2.6673 | Actual Loss: 0.3297\n",
      "Baseline Loss: 2.6808 | Actual Loss: 0.6181\n",
      "Baseline Loss: 2.6878 | Actual Loss: 0.1727\n",
      "Baseline Loss: 2.6211 | Actual Loss: 0.3607\n",
      "Baseline Loss: 2.6848 | Actual Loss: 0.4044\n",
      "Baseline Loss: 2.2753 | Actual Loss: 0.2064\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4263\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4758\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4571\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.4282\n",
      "Epoch 64/1000: Train Loss: 0.3468, Val Loss: 0.4468\n",
      "Baseline Loss: 2.6663 | Actual Loss: 0.2482\n",
      "Baseline Loss: 2.6909 | Actual Loss: 0.3640\n",
      "Baseline Loss: 2.6800 | Actual Loss: 0.3174\n",
      "Baseline Loss: 2.6591 | Actual Loss: 0.3770\n",
      "Baseline Loss: 2.7267 | Actual Loss: 0.4792\n",
      "Baseline Loss: 2.6937 | Actual Loss: 0.4677\n",
      "Baseline Loss: 2.6492 | Actual Loss: 0.4114\n",
      "Baseline Loss: 2.6812 | Actual Loss: 0.4289\n",
      "Baseline Loss: 2.6667 | Actual Loss: 0.5642\n",
      "Baseline Loss: 2.6816 | Actual Loss: 0.3782\n",
      "Baseline Loss: 2.6576 | Actual Loss: 0.2529\n",
      "Baseline Loss: 2.6368 | Actual Loss: 0.2728\n",
      "Baseline Loss: 2.6845 | Actual Loss: 0.3028\n",
      "Baseline Loss: 2.6616 | Actual Loss: 0.4044\n",
      "Baseline Loss: 2.6671 | Actual Loss: 0.3052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 65/1000 [00:20<04:54,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2621 | Actual Loss: 0.1385\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4889\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4584\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4328\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.3626\n",
      "Epoch 65/1000: Train Loss: 0.3570, Val Loss: 0.4357\n",
      "Baseline Loss: 2.6598 | Actual Loss: 0.3354\n",
      "Baseline Loss: 2.6932 | Actual Loss: 0.2979\n",
      "Baseline Loss: 2.6954 | Actual Loss: 0.3774\n",
      "Baseline Loss: 2.6627 | Actual Loss: 0.3816\n",
      "Baseline Loss: 2.6921 | Actual Loss: 0.3807\n",
      "Baseline Loss: 2.6637 | Actual Loss: 0.4027\n",
      "Baseline Loss: 2.7011 | Actual Loss: 0.4096\n",
      "Baseline Loss: 2.6665 | Actual Loss: 0.3524\n",
      "Baseline Loss: 2.6773 | Actual Loss: 0.2788\n",
      "Baseline Loss: 2.6744 | Actual Loss: 0.2265\n",
      "Baseline Loss: 2.6922 | Actual Loss: 0.4451\n",
      "Baseline Loss: 2.7146 | Actual Loss: 0.3715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 66/1000 [00:20<04:57,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6768 | Actual Loss: 0.2956\n",
      "Baseline Loss: 2.6914 | Actual Loss: 0.3322\n",
      "Baseline Loss: 2.6865 | Actual Loss: 0.3116\n",
      "Baseline Loss: 2.2850 | Actual Loss: 0.2736\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5049\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3870\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4402\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.3579\n",
      "Epoch 66/1000: Train Loss: 0.3421, Val Loss: 0.4225\n",
      "Baseline Loss: 2.6821 | Actual Loss: 0.2651\n",
      "Baseline Loss: 2.6953 | Actual Loss: 0.2585\n",
      "Baseline Loss: 2.6612 | Actual Loss: 0.2927\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5008\n",
      "Baseline Loss: 2.6617 | Actual Loss: 0.3736\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3331\n",
      "Baseline Loss: 2.6898 | Actual Loss: 0.3817\n",
      "Baseline Loss: 2.6393 | Actual Loss: 0.2891\n",
      "Baseline Loss: 2.6711 | Actual Loss: 0.2605\n",
      "Baseline Loss: 2.6768 | Actual Loss: 0.4506\n",
      "Baseline Loss: 2.6693 | Actual Loss: 0.3429\n",
      "Baseline Loss: 2.6535 | Actual Loss: 0.3589\n",
      "Baseline Loss: 2.6884 | Actual Loss: 0.3428\n",
      "Baseline Loss: 2.6558 | Actual Loss: 0.4544\n",
      "Baseline Loss: 2.6906 | Actual Loss: 0.2649\n",
      "Baseline Loss: 2.3276 | Actual Loss: 0.2620\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5027\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 67/1000 [00:21<05:03,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6861 | Actual Loss: 0.4632\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.3912\n",
      "Epoch 67/1000: Train Loss: 0.3395, Val Loss: 0.4528\n",
      "Baseline Loss: 2.6970 | Actual Loss: 0.4400\n",
      "Baseline Loss: 2.6211 | Actual Loss: 0.2877\n",
      "Baseline Loss: 2.7014 | Actual Loss: 0.2832\n",
      "Baseline Loss: 2.6407 | Actual Loss: 0.4304\n",
      "Baseline Loss: 2.6524 | Actual Loss: 0.3016\n",
      "Baseline Loss: 2.7000 | Actual Loss: 0.3699\n",
      "Baseline Loss: 2.7125 | Actual Loss: 0.2525\n",
      "Baseline Loss: 2.6731 | Actual Loss: 0.5131\n",
      "Baseline Loss: 2.6843 | Actual Loss: 0.3549\n",
      "Baseline Loss: 2.6868 | Actual Loss: 0.2540\n",
      "Baseline Loss: 2.6612 | Actual Loss: 0.2390\n",
      "Baseline Loss: 2.6969 | Actual Loss: 0.7166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 68/1000 [00:21<04:48,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7094 | Actual Loss: 0.4337\n",
      "Baseline Loss: 2.6310 | Actual Loss: 0.2587\n",
      "Baseline Loss: 2.6531 | Actual Loss: 0.3025\n",
      "Baseline Loss: 2.2559 | Actual Loss: 0.1606\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.6406\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3936\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4879\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.3163\n",
      "Epoch 68/1000: Train Loss: 0.3499, Val Loss: 0.4596\n",
      "Baseline Loss: 2.6326 | Actual Loss: 0.3624\n",
      "Baseline Loss: 2.6800 | Actual Loss: 0.3571\n",
      "Baseline Loss: 2.6724 | Actual Loss: 0.3847\n",
      "Baseline Loss: 2.6772 | Actual Loss: 0.4008\n",
      "Baseline Loss: 2.6777 | Actual Loss: 0.3281\n",
      "Baseline Loss: 2.6360 | Actual Loss: 0.2874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 69/1000 [00:21<04:52,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6897 | Actual Loss: 0.3139\n",
      "Baseline Loss: 2.6855 | Actual Loss: 0.2693\n",
      "Baseline Loss: 2.6591 | Actual Loss: 0.4514\n",
      "Baseline Loss: 2.7108 | Actual Loss: 0.2587\n",
      "Baseline Loss: 2.6890 | Actual Loss: 0.6797\n",
      "Baseline Loss: 2.6806 | Actual Loss: 0.3815\n",
      "Baseline Loss: 2.6532 | Actual Loss: 0.3590\n",
      "Baseline Loss: 2.6315 | Actual Loss: 0.3428\n",
      "Baseline Loss: 2.6760 | Actual Loss: 0.3625\n",
      "Baseline Loss: 2.2684 | Actual Loss: 0.1708\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4583\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4223\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4443\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.3085\n",
      "Epoch 69/1000: Train Loss: 0.3569, Val Loss: 0.4083\n",
      "Baseline Loss: 2.6769 | Actual Loss: 0.3107\n",
      "Baseline Loss: 2.6354 | Actual Loss: 0.3643\n",
      "Baseline Loss: 2.6625 | Actual Loss: 0.2998\n",
      "Baseline Loss: 2.6876 | Actual Loss: 0.2273\n",
      "Baseline Loss: 2.6625 | Actual Loss: 0.3929\n",
      "Baseline Loss: 2.6912 | Actual Loss: 0.3494\n",
      "Baseline Loss: 2.6684 | Actual Loss: 0.3353\n",
      "Baseline Loss: 2.6877 | Actual Loss: 0.2982\n",
      "Baseline Loss: 2.6855 | Actual Loss: 0.2648\n",
      "Baseline Loss: 2.6658 | Actual Loss: 0.2987\n",
      "Baseline Loss: 2.6814 | Actual Loss: 0.4010\n",
      "Baseline Loss: 2.6347 | Actual Loss: 0.4091\n",
      "Baseline Loss: 2.7184 | Actual Loss: 0.5718\n",
      "Baseline Loss: 2.6949 | Actual Loss: 0.6008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 70/1000 [00:21<04:54,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6847 | Actual Loss: 0.4363\n",
      "Baseline Loss: 2.2145 | Actual Loss: 0.1061\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5175\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4535\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4788\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.3142\n",
      "Epoch 70/1000: Train Loss: 0.3542, Val Loss: 0.4410\n",
      "Baseline Loss: 2.7012 | Actual Loss: 0.3094\n",
      "Baseline Loss: 2.6538 | Actual Loss: 0.4045\n",
      "Baseline Loss: 2.6944 | Actual Loss: 0.2854\n",
      "Baseline Loss: 2.6563 | Actual Loss: 0.2426\n",
      "Baseline Loss: 2.6639 | Actual Loss: 0.4033\n",
      "Baseline Loss: 2.6534 | Actual Loss: 0.2810\n",
      "Baseline Loss: 2.6429 | Actual Loss: 0.4769\n",
      "Baseline Loss: 2.6926 | Actual Loss: 0.2096\n",
      "Baseline Loss: 2.7078 | Actual Loss: 0.4692\n",
      "Baseline Loss: 2.6451 | Actual Loss: 0.2917\n",
      "Baseline Loss: 2.6236 | Actual Loss: 0.3415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 71/1000 [00:22<04:40,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6552 | Actual Loss: 0.3260\n",
      "Baseline Loss: 2.7451 | Actual Loss: 0.2392\n",
      "Baseline Loss: 2.6729 | Actual Loss: 0.2403\n",
      "Baseline Loss: 2.7536 | Actual Loss: 0.2704\n",
      "Baseline Loss: 2.2620 | Actual Loss: 0.5610\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.3898\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4249\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4684\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.3445\n",
      "Epoch 71/1000: Train Loss: 0.3345, Val Loss: 0.4069\n",
      "Baseline Loss: 2.6783 | Actual Loss: 0.4907\n",
      "Baseline Loss: 2.6490 | Actual Loss: 0.4897\n",
      "Baseline Loss: 2.7319 | Actual Loss: 0.5334\n",
      "Baseline Loss: 2.6871 | Actual Loss: 0.2796\n",
      "Baseline Loss: 2.6599 | Actual Loss: 0.4424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 72/1000 [00:22<04:55,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6795 | Actual Loss: 0.3297\n",
      "Baseline Loss: 2.6825 | Actual Loss: 0.3232\n",
      "Baseline Loss: 2.6917 | Actual Loss: 0.2647\n",
      "Baseline Loss: 2.6559 | Actual Loss: 0.3725\n",
      "Baseline Loss: 2.6750 | Actual Loss: 0.3519\n",
      "Baseline Loss: 2.6486 | Actual Loss: 0.3314\n",
      "Baseline Loss: 2.7029 | Actual Loss: 0.3426\n",
      "Baseline Loss: 2.6752 | Actual Loss: 0.2546\n",
      "Baseline Loss: 2.6767 | Actual Loss: 0.3114\n",
      "Baseline Loss: 2.6552 | Actual Loss: 0.3247\n",
      "Baseline Loss: 2.2912 | Actual Loss: 0.2349\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5442\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4219\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4680\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.3184\n",
      "Epoch 72/1000: Train Loss: 0.3548, Val Loss: 0.4381\n",
      "Baseline Loss: 2.6860 | Actual Loss: 0.3007\n",
      "Baseline Loss: 2.6213 | Actual Loss: 0.3300\n",
      "Baseline Loss: 2.6895 | Actual Loss: 0.3433\n",
      "Baseline Loss: 2.6876 | Actual Loss: 0.3707\n",
      "Baseline Loss: 2.7366 | Actual Loss: 0.2294\n",
      "Baseline Loss: 2.6529 | Actual Loss: 0.3412\n",
      "Baseline Loss: 2.6416 | Actual Loss: 0.2536\n",
      "Baseline Loss: 2.6867 | Actual Loss: 0.3332\n",
      "Baseline Loss: 2.6799 | Actual Loss: 0.2832\n",
      "Baseline Loss: 2.6901 | Actual Loss: 0.3201\n",
      "Baseline Loss: 2.6851 | Actual Loss: 0.4197\n",
      "Baseline Loss: 2.6662 | Actual Loss: 0.2674\n",
      "Baseline Loss: 2.7005 | Actual Loss: 0.3190\n",
      "Baseline Loss: 2.6808 | Actual Loss: 0.3628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 73/1000 [00:22<05:07,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6818 | Actual Loss: 0.4202\n",
      "Baseline Loss: 2.2742 | Actual Loss: 0.2002\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5075\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3524\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4323\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.3251\n",
      "Epoch 73/1000: Train Loss: 0.3184, Val Loss: 0.4043\n",
      "Baseline Loss: 2.6870 | Actual Loss: 0.2799\n",
      "Baseline Loss: 2.6708 | Actual Loss: 0.2547\n",
      "Baseline Loss: 2.6633 | Actual Loss: 0.2799\n",
      "Baseline Loss: 2.6632 | Actual Loss: 0.1965\n",
      "Baseline Loss: 2.6482 | Actual Loss: 0.3306\n",
      "Baseline Loss: 2.6851 | Actual Loss: 0.3478\n",
      "Baseline Loss: 2.6406 | Actual Loss: 0.2429\n",
      "Baseline Loss: 2.6670 | Actual Loss: 0.4640\n",
      "Baseline Loss: 2.6841 | Actual Loss: 0.3919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 74/1000 [00:23<04:51,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6593 | Actual Loss: 0.3231\n",
      "Baseline Loss: 2.6783 | Actual Loss: 0.2258\n",
      "Baseline Loss: 2.6728 | Actual Loss: 0.3286\n",
      "Baseline Loss: 2.7083 | Actual Loss: 0.2883\n",
      "Baseline Loss: 2.6923 | Actual Loss: 0.3498\n",
      "Baseline Loss: 2.6717 | Actual Loss: 0.3610\n",
      "Baseline Loss: 2.2041 | Actual Loss: 0.2235\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.3867\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4064\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4133\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.4024\n",
      "Epoch 74/1000: Train Loss: 0.3055, Val Loss: 0.4022\n",
      "Baseline Loss: 2.6985 | Actual Loss: 0.7012\n",
      "Baseline Loss: 2.6850 | Actual Loss: 0.5084\n",
      "Baseline Loss: 2.6521 | Actual Loss: 0.4061\n",
      "Baseline Loss: 2.6771 | Actual Loss: 0.4907\n",
      "Baseline Loss: 2.7275 | Actual Loss: 0.2219\n",
      "Baseline Loss: 2.6768 | Actual Loss: 0.2627\n",
      "Baseline Loss: 2.6835 | Actual Loss: 0.2346\n",
      "Baseline Loss: 2.6361 | Actual Loss: 0.4101\n",
      "Baseline Loss: 2.6432 | Actual Loss: 0.3052\n",
      "Baseline Loss: 2.6391 | Actual Loss: 0.2464\n",
      "Baseline Loss: 2.6397 | Actual Loss: 0.3825\n",
      "Baseline Loss: 2.6570 | Actual Loss: 0.2938\n",
      "Baseline Loss: 2.6712 | Actual Loss: 0.2701\n",
      "Baseline Loss: 2.7135 | Actual Loss: 0.2990\n",
      "Baseline Loss: 2.6795 | Actual Loss: 0.2849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 75/1000 [00:23<04:56,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2187 | Actual Loss: 0.3231\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5340\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4018\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4237\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.3239\n",
      "Epoch 75/1000: Train Loss: 0.3525, Val Loss: 0.4209\n",
      "Baseline Loss: 2.6677 | Actual Loss: 0.4090\n",
      "Baseline Loss: 2.6911 | Actual Loss: 0.3610\n",
      "Baseline Loss: 2.6714 | Actual Loss: 0.4080\n",
      "Baseline Loss: 2.6976 | Actual Loss: 0.4144\n",
      "Baseline Loss: 2.6530 | Actual Loss: 0.2706\n",
      "Baseline Loss: 2.6537 | Actual Loss: 0.3402\n",
      "Baseline Loss: 2.6889 | Actual Loss: 0.2881\n",
      "Baseline Loss: 2.6314 | Actual Loss: 0.2692\n",
      "Baseline Loss: 2.6819 | Actual Loss: 0.2444\n",
      "Baseline Loss: 2.6707 | Actual Loss: 0.2511\n",
      "Baseline Loss: 2.6646 | Actual Loss: 0.4285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 76/1000 [00:23<04:35,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7127 | Actual Loss: 0.3939\n",
      "Baseline Loss: 2.7319 | Actual Loss: 0.2743\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2331\n",
      "Baseline Loss: 2.6790 | Actual Loss: 0.5272\n",
      "Baseline Loss: 2.2814 | Actual Loss: 0.2441\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5574\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4358\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4066\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.3828\n",
      "Epoch 76/1000: Train Loss: 0.3348, Val Loss: 0.4456\n",
      "Baseline Loss: 2.6710 | Actual Loss: 0.1991\n",
      "Baseline Loss: 2.6744 | Actual Loss: 0.3121\n",
      "Baseline Loss: 2.6791 | Actual Loss: 0.3905\n",
      "Baseline Loss: 2.6786 | Actual Loss: 0.3365\n",
      "Baseline Loss: 2.6724 | Actual Loss: 0.3054\n",
      "Baseline Loss: 2.6350 | Actual Loss: 0.4388\n",
      "Baseline Loss: 2.6711 | Actual Loss: 0.3144\n",
      "Baseline Loss: 2.6954 | Actual Loss: 0.2668\n",
      "Baseline Loss: 2.6478 | Actual Loss: 0.1907\n",
      "Baseline Loss: 2.6808 | Actual Loss: 0.2886\n",
      "Baseline Loss: 2.6555 | Actual Loss: 0.4988\n",
      "Baseline Loss: 2.6416 | Actual Loss: 0.3342\n",
      "Baseline Loss: 2.6617 | Actual Loss: 0.3785\n",
      "Baseline Loss: 2.7109 | Actual Loss: 0.1996\n",
      "Baseline Loss: 2.6737 | Actual Loss: 0.2826\n",
      "Baseline Loss: 2.3609 | Actual Loss: 0.1596\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.6574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 77/1000 [00:24<04:50,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6474 | Actual Loss: 0.4114\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4292\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.3746\n",
      "Epoch 77/1000: Train Loss: 0.3060, Val Loss: 0.4681\n",
      "Baseline Loss: 2.6603 | Actual Loss: 0.2722\n",
      "Baseline Loss: 2.6566 | Actual Loss: 0.1679\n",
      "Baseline Loss: 2.6842 | Actual Loss: 0.3026\n",
      "Baseline Loss: 2.6743 | Actual Loss: 0.3841\n",
      "Baseline Loss: 2.6645 | Actual Loss: 0.3429\n",
      "Baseline Loss: 2.6476 | Actual Loss: 0.2994\n",
      "Baseline Loss: 2.6927 | Actual Loss: 0.4457\n",
      "Baseline Loss: 2.7110 | Actual Loss: 0.1971\n",
      "Baseline Loss: 2.6874 | Actual Loss: 0.5379\n",
      "Baseline Loss: 2.6730 | Actual Loss: 0.3920\n",
      "Baseline Loss: 2.6443 | Actual Loss: 0.2323\n",
      "Baseline Loss: 2.6868 | Actual Loss: 0.4187\n",
      "Baseline Loss: 2.6558 | Actual Loss: 0.5217\n",
      "Baseline Loss: 2.6588 | Actual Loss: 0.3321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 78/1000 [00:24<04:32,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6630 | Actual Loss: 0.3471\n",
      "Baseline Loss: 2.2363 | Actual Loss: 0.1023\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5695\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3952\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4497\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.3488\n",
      "Epoch 78/1000: Train Loss: 0.3310, Val Loss: 0.4408\n",
      "Baseline Loss: 2.6835 | Actual Loss: 0.2410\n",
      "Baseline Loss: 2.6915 | Actual Loss: 0.3689\n",
      "Baseline Loss: 2.6884 | Actual Loss: 0.3570\n",
      "Baseline Loss: 2.6947 | Actual Loss: 0.2316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 79/1000 [00:24<04:42,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6979 | Actual Loss: 0.2834\n",
      "Baseline Loss: 2.6604 | Actual Loss: 0.3059\n",
      "Baseline Loss: 2.6833 | Actual Loss: 0.4544\n",
      "Baseline Loss: 2.7007 | Actual Loss: 0.2825\n",
      "Baseline Loss: 2.7020 | Actual Loss: 0.6605\n",
      "Baseline Loss: 2.6651 | Actual Loss: 0.3007\n",
      "Baseline Loss: 2.6722 | Actual Loss: 0.3035\n",
      "Baseline Loss: 2.6856 | Actual Loss: 0.2588\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.2582\n",
      "Baseline Loss: 2.6330 | Actual Loss: 0.2299\n",
      "Baseline Loss: 2.6263 | Actual Loss: 0.1617\n",
      "Baseline Loss: 2.2744 | Actual Loss: 0.3394\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4302\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3819\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4249\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.3023\n",
      "Epoch 79/1000: Train Loss: 0.3148, Val Loss: 0.3848\n",
      "New best validation loss: 0.3848\n",
      "Baseline Loss: 2.6799 | Actual Loss: 0.4578\n",
      "Baseline Loss: 2.7280 | Actual Loss: 0.2772\n",
      "Baseline Loss: 2.6550 | Actual Loss: 0.3217\n",
      "Baseline Loss: 2.6379 | Actual Loss: 0.2189\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2748\n",
      "Baseline Loss: 2.6350 | Actual Loss: 0.2301\n",
      "Baseline Loss: 2.6705 | Actual Loss: 0.3572\n",
      "Baseline Loss: 2.6940 | Actual Loss: 0.2784\n",
      "Baseline Loss: 2.6910 | Actual Loss: 0.5549\n",
      "Baseline Loss: 2.6385 | Actual Loss: 0.4486\n",
      "Baseline Loss: 2.6414 | Actual Loss: 0.3185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 80/1000 [00:25<04:53,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7473 | Actual Loss: 0.2550\n",
      "Baseline Loss: 2.6565 | Actual Loss: 0.4378\n",
      "Baseline Loss: 2.7145 | Actual Loss: 0.2820\n",
      "Baseline Loss: 2.6668 | Actual Loss: 0.4885\n",
      "Baseline Loss: 2.2585 | Actual Loss: 0.0708\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5702\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4275\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4148\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.3097\n",
      "Epoch 80/1000: Train Loss: 0.3295, Val Loss: 0.4306\n",
      "Baseline Loss: 2.6717 | Actual Loss: 0.1690\n",
      "Baseline Loss: 2.7019 | Actual Loss: 0.2668\n",
      "Baseline Loss: 2.6407 | Actual Loss: 0.3452\n",
      "Baseline Loss: 2.6792 | Actual Loss: 0.1929\n",
      "Baseline Loss: 2.6541 | Actual Loss: 0.1832\n",
      "Baseline Loss: 2.6431 | Actual Loss: 0.7437\n",
      "Baseline Loss: 2.6702 | Actual Loss: 0.3309\n",
      "Baseline Loss: 2.6454 | Actual Loss: 0.4170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 81/1000 [00:25<04:36,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6772 | Actual Loss: 0.3419\n",
      "Baseline Loss: 2.6650 | Actual Loss: 0.3239\n",
      "Baseline Loss: 2.7252 | Actual Loss: 0.3036\n",
      "Baseline Loss: 2.6628 | Actual Loss: 0.3038\n",
      "Baseline Loss: 2.6940 | Actual Loss: 0.2678\n",
      "Baseline Loss: 2.6685 | Actual Loss: 0.2194\n",
      "Baseline Loss: 2.6737 | Actual Loss: 0.2399\n",
      "Baseline Loss: 2.2738 | Actual Loss: 0.1700\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4771\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3755\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3540\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.4088\n",
      "Epoch 81/1000: Train Loss: 0.3012, Val Loss: 0.4039\n",
      "Baseline Loss: 2.6816 | Actual Loss: 0.3255\n",
      "Baseline Loss: 2.6420 | Actual Loss: 0.4141\n",
      "Baseline Loss: 2.6933 | Actual Loss: 0.3605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 82/1000 [00:25<04:46,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6416 | Actual Loss: 0.4062\n",
      "Baseline Loss: 2.6622 | Actual Loss: 0.3044\n",
      "Baseline Loss: 2.6926 | Actual Loss: 0.3437\n",
      "Baseline Loss: 2.6933 | Actual Loss: 0.2565\n",
      "Baseline Loss: 2.6864 | Actual Loss: 0.2948\n",
      "Baseline Loss: 2.6781 | Actual Loss: 0.2829\n",
      "Baseline Loss: 2.6785 | Actual Loss: 0.3345\n",
      "Baseline Loss: 2.6488 | Actual Loss: 0.3511\n",
      "Baseline Loss: 2.6615 | Actual Loss: 0.4025\n",
      "Baseline Loss: 2.7204 | Actual Loss: 0.3146\n",
      "Baseline Loss: 2.6691 | Actual Loss: 0.2267\n",
      "Baseline Loss: 2.6469 | Actual Loss: 0.2136\n",
      "Baseline Loss: 2.2545 | Actual Loss: 0.2033\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4974\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3761\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4597\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.3198\n",
      "Epoch 82/1000: Train Loss: 0.3147, Val Loss: 0.4133\n",
      "Baseline Loss: 2.6505 | Actual Loss: 0.3917\n",
      "Baseline Loss: 2.7034 | Actual Loss: 0.3925\n",
      "Baseline Loss: 2.6813 | Actual Loss: 0.3693\n",
      "Baseline Loss: 2.7020 | Actual Loss: 0.2400\n",
      "Baseline Loss: 2.7008 | Actual Loss: 0.3644\n",
      "Baseline Loss: 2.6441 | Actual Loss: 0.3886\n",
      "Baseline Loss: 2.6957 | Actual Loss: 0.4444\n",
      "Baseline Loss: 2.6572 | Actual Loss: 0.3394\n",
      "Baseline Loss: 2.6983 | Actual Loss: 0.4425\n",
      "Baseline Loss: 2.6655 | Actual Loss: 0.2742\n",
      "Baseline Loss: 2.6584 | Actual Loss: 0.5471\n",
      "Baseline Loss: 2.6851 | Actual Loss: 0.2918\n",
      "Baseline Loss: 2.6550 | Actual Loss: 0.3423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 83/1000 [00:26<04:58,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6507 | Actual Loss: 0.3553\n",
      "Baseline Loss: 2.7075 | Actual Loss: 0.2654\n",
      "Baseline Loss: 2.2434 | Actual Loss: 0.3496\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.6335\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4673\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4427\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.4358\n",
      "Epoch 83/1000: Train Loss: 0.3624, Val Loss: 0.4948\n",
      "Baseline Loss: 2.6962 | Actual Loss: 0.2372\n",
      "Baseline Loss: 2.6753 | Actual Loss: 0.5398\n",
      "Baseline Loss: 2.6886 | Actual Loss: 0.4414\n",
      "Baseline Loss: 2.6457 | Actual Loss: 0.2679\n",
      "Baseline Loss: 2.6411 | Actual Loss: 0.1477\n",
      "Baseline Loss: 2.6659 | Actual Loss: 0.3805\n",
      "Baseline Loss: 2.7009 | Actual Loss: 0.3157\n",
      "Baseline Loss: 2.6545 | Actual Loss: 0.3489\n",
      "Baseline Loss: 2.7119 | Actual Loss: 0.3781\n",
      "Baseline Loss: 2.7102 | Actual Loss: 0.2538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 84/1000 [00:26<04:36,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6670 | Actual Loss: 0.2016\n",
      "Baseline Loss: 2.7129 | Actual Loss: 0.2852\n",
      "Baseline Loss: 2.6556 | Actual Loss: 0.2844\n",
      "Baseline Loss: 2.6637 | Actual Loss: 0.2222\n",
      "Baseline Loss: 2.6721 | Actual Loss: 0.2323\n",
      "Baseline Loss: 2.3227 | Actual Loss: 0.5096\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.3733\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4097\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4312\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.3373\n",
      "Epoch 84/1000: Train Loss: 0.3154, Val Loss: 0.3879\n",
      "Baseline Loss: 2.6917 | Actual Loss: 0.2380\n",
      "Baseline Loss: 2.6952 | Actual Loss: 0.1819\n",
      "Baseline Loss: 2.6808 | Actual Loss: 0.2697\n",
      "Baseline Loss: 2.6804 | Actual Loss: 0.4441\n",
      "Baseline Loss: 2.6690 | Actual Loss: 0.3974\n",
      "Baseline Loss: 2.6951 | Actual Loss: 0.3009\n",
      "Baseline Loss: 2.6721 | Actual Loss: 0.2682\n",
      "Baseline Loss: 2.6793 | Actual Loss: 0.4543\n",
      "Baseline Loss: 2.6847 | Actual Loss: 0.2492\n",
      "Baseline Loss: 2.6739 | Actual Loss: 0.2410\n",
      "Baseline Loss: 2.6698 | Actual Loss: 0.2723\n",
      "Baseline Loss: 2.6940 | Actual Loss: 0.3073\n",
      "Baseline Loss: 2.6991 | Actual Loss: 0.2706\n",
      "Baseline Loss: 2.6456 | Actual Loss: 0.3756\n",
      "Baseline Loss: 2.6889 | Actual Loss: 0.4857\n",
      "Baseline Loss: 2.2366 | Actual Loss: 0.3603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 85/1000 [00:26<04:48,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6853 | Actual Loss: 0.4631\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4008\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4450\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.3382\n",
      "Epoch 85/1000: Train Loss: 0.3198, Val Loss: 0.4118\n",
      "Baseline Loss: 2.6794 | Actual Loss: 0.4331\n",
      "Baseline Loss: 2.6662 | Actual Loss: 0.1888\n",
      "Baseline Loss: 2.6666 | Actual Loss: 0.3747\n",
      "Baseline Loss: 2.6517 | Actual Loss: 0.2002\n",
      "Baseline Loss: 2.7367 | Actual Loss: 0.2704\n",
      "Baseline Loss: 2.7095 | Actual Loss: 0.3726\n",
      "Baseline Loss: 2.6605 | Actual Loss: 0.3890\n",
      "Baseline Loss: 2.6951 | Actual Loss: 0.2850\n",
      "Baseline Loss: 2.6714 | Actual Loss: 0.3358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▊         | 86/1000 [00:26<04:59,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6861 | Actual Loss: 0.2655\n",
      "Baseline Loss: 2.7032 | Actual Loss: 0.2314\n",
      "Baseline Loss: 2.6830 | Actual Loss: 0.2623\n",
      "Baseline Loss: 2.6553 | Actual Loss: 0.2103\n",
      "Baseline Loss: 2.6879 | Actual Loss: 0.2867\n",
      "Baseline Loss: 2.6602 | Actual Loss: 0.2061\n",
      "Baseline Loss: 2.2389 | Actual Loss: 0.2344\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4502\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3902\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4227\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.3650\n",
      "Epoch 86/1000: Train Loss: 0.2841, Val Loss: 0.4071\n",
      "Baseline Loss: 2.6714 | Actual Loss: 0.3409\n",
      "Baseline Loss: 2.6505 | Actual Loss: 0.2765\n",
      "Baseline Loss: 2.7070 | Actual Loss: 0.3920\n",
      "Baseline Loss: 2.6701 | Actual Loss: 0.2774\n",
      "Baseline Loss: 2.6738 | Actual Loss: 0.3142\n",
      "Baseline Loss: 2.6879 | Actual Loss: 0.2737\n",
      "Baseline Loss: 2.6493 | Actual Loss: 0.4646\n",
      "Baseline Loss: 2.6445 | Actual Loss: 0.3089\n",
      "Baseline Loss: 2.6571 | Actual Loss: 0.2969\n",
      "Baseline Loss: 2.6768 | Actual Loss: 0.2875\n",
      "Baseline Loss: 2.7151 | Actual Loss: 0.2960\n",
      "Baseline Loss: 2.6953 | Actual Loss: 0.1719\n",
      "Baseline Loss: 2.6908 | Actual Loss: 0.3435\n",
      "Baseline Loss: 2.6551 | Actual Loss: 0.2662\n",
      "Baseline Loss: 2.7027 | Actual Loss: 0.3274\n",
      "Baseline Loss: 2.2692 | Actual Loss: 0.0675\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.3196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▊         | 87/1000 [00:27<05:02,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6474 | Actual Loss: 0.2897\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3972\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.3540\n",
      "Epoch 87/1000: Train Loss: 0.2941, Val Loss: 0.3401\n",
      "New best validation loss: 0.3401\n",
      "Baseline Loss: 2.6485 | Actual Loss: 0.2469\n",
      "Baseline Loss: 2.6392 | Actual Loss: 0.3904\n",
      "Baseline Loss: 2.6971 | Actual Loss: 0.2748\n",
      "Baseline Loss: 2.6832 | Actual Loss: 0.2841\n",
      "Baseline Loss: 2.6877 | Actual Loss: 0.2949\n",
      "Baseline Loss: 2.6970 | Actual Loss: 0.4298\n",
      "Baseline Loss: 2.6699 | Actual Loss: 0.3006\n",
      "Baseline Loss: 2.6238 | Actual Loss: 0.1996\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.3124\n",
      "Baseline Loss: 2.7350 | Actual Loss: 0.2919\n",
      "Baseline Loss: 2.6511 | Actual Loss: 0.5994\n",
      "Baseline Loss: 2.7005 | Actual Loss: 0.2745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 88/1000 [00:27<04:46,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6989 | Actual Loss: 0.2167\n",
      "Baseline Loss: 2.7083 | Actual Loss: 0.4861\n",
      "Baseline Loss: 2.6645 | Actual Loss: 0.2988\n",
      "Baseline Loss: 2.3074 | Actual Loss: 0.1995\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4341\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4417\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3802\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2923\n",
      "Epoch 88/1000: Train Loss: 0.3188, Val Loss: 0.3871\n",
      "Baseline Loss: 2.6855 | Actual Loss: 0.2425\n",
      "Baseline Loss: 2.6466 | Actual Loss: 0.3445\n",
      "Baseline Loss: 2.6646 | Actual Loss: 0.2125\n",
      "Baseline Loss: 2.6573 | Actual Loss: 0.3683\n",
      "Baseline Loss: 2.7032 | Actual Loss: 0.2917\n",
      "Baseline Loss: 2.6798 | Actual Loss: 0.2340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 89/1000 [00:27<04:56,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6689 | Actual Loss: 0.3481\n",
      "Baseline Loss: 2.7156 | Actual Loss: 0.3316\n",
      "Baseline Loss: 2.6523 | Actual Loss: 0.2586\n",
      "Baseline Loss: 2.6655 | Actual Loss: 0.2699\n",
      "Baseline Loss: 2.7637 | Actual Loss: 0.3937\n",
      "Baseline Loss: 2.6829 | Actual Loss: 0.3960\n",
      "Baseline Loss: 2.6818 | Actual Loss: 0.3014\n",
      "Baseline Loss: 2.6512 | Actual Loss: 0.3729\n",
      "Baseline Loss: 2.6540 | Actual Loss: 0.3025\n",
      "Baseline Loss: 2.2644 | Actual Loss: 0.0909\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4606\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3768\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3839\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.3057\n",
      "Epoch 89/1000: Train Loss: 0.2975, Val Loss: 0.3817\n",
      "Baseline Loss: 2.6495 | Actual Loss: 0.2417\n",
      "Baseline Loss: 2.6760 | Actual Loss: 0.3005\n",
      "Baseline Loss: 2.6742 | Actual Loss: 0.2794\n",
      "Baseline Loss: 2.6604 | Actual Loss: 0.2826\n",
      "Baseline Loss: 2.6648 | Actual Loss: 0.2586\n",
      "Baseline Loss: 2.7328 | Actual Loss: 0.2070\n",
      "Baseline Loss: 2.6493 | Actual Loss: 0.2398\n",
      "Baseline Loss: 2.6797 | Actual Loss: 0.3334\n",
      "Baseline Loss: 2.6772 | Actual Loss: 0.2422\n",
      "Baseline Loss: 2.6547 | Actual Loss: 0.3158\n",
      "Baseline Loss: 2.6813 | Actual Loss: 0.4131\n",
      "Baseline Loss: 2.6784 | Actual Loss: 0.2870\n",
      "Baseline Loss: 2.6515 | Actual Loss: 0.2506\n",
      "Baseline Loss: 2.7043 | Actual Loss: 0.3035\n",
      "Baseline Loss: 2.6369 | Actual Loss: 0.2531\n",
      "Baseline Loss: 2.2617 | Actual Loss: 0.2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 90/1000 [00:28<05:03,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6853 | Actual Loss: 0.4685\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3527\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4268\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2311\n",
      "Epoch 90/1000: Train Loss: 0.2757, Val Loss: 0.3698\n",
      "Baseline Loss: 2.6875 | Actual Loss: 0.2672\n",
      "Baseline Loss: 2.6608 | Actual Loss: 0.1724\n",
      "Baseline Loss: 2.6643 | Actual Loss: 0.3513\n",
      "Baseline Loss: 2.6910 | Actual Loss: 0.3819\n",
      "Baseline Loss: 2.7018 | Actual Loss: 0.2538\n",
      "Baseline Loss: 2.6629 | Actual Loss: 0.1835\n",
      "Baseline Loss: 2.6304 | Actual Loss: 0.2630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 91/1000 [00:28<04:47,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7062 | Actual Loss: 0.2150\n",
      "Baseline Loss: 2.6719 | Actual Loss: 0.1976\n",
      "Baseline Loss: 2.6975 | Actual Loss: 0.4101\n",
      "Baseline Loss: 2.6539 | Actual Loss: 0.2553\n",
      "Baseline Loss: 2.6654 | Actual Loss: 0.1675\n",
      "Baseline Loss: 2.6603 | Actual Loss: 0.3672\n",
      "Baseline Loss: 2.6757 | Actual Loss: 0.2494\n",
      "Baseline Loss: 2.6706 | Actual Loss: 0.2661\n",
      "Baseline Loss: 2.3014 | Actual Loss: 0.1819\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5328\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4702\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4269\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.3034\n",
      "Epoch 91/1000: Train Loss: 0.2615, Val Loss: 0.4333\n",
      "Baseline Loss: 2.6657 | Actual Loss: 0.2887\n",
      "Baseline Loss: 2.6565 | Actual Loss: 0.3692\n",
      "Baseline Loss: 2.6756 | Actual Loss: 0.2873\n",
      "Baseline Loss: 2.6671 | Actual Loss: 0.3667\n",
      "Baseline Loss: 2.6782 | Actual Loss: 0.1522\n",
      "Baseline Loss: 2.6660 | Actual Loss: 0.3263\n",
      "Baseline Loss: 2.6793 | Actual Loss: 0.4152\n",
      "Baseline Loss: 2.7137 | Actual Loss: 0.2348\n",
      "Baseline Loss: 2.6643 | Actual Loss: 0.3128\n",
      "Baseline Loss: 2.6784 | Actual Loss: 0.1674\n",
      "Baseline Loss: 2.6877 | Actual Loss: 0.2961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 92/1000 [00:28<04:55,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6714 | Actual Loss: 0.2443\n",
      "Baseline Loss: 2.6960 | Actual Loss: 0.2673\n",
      "Baseline Loss: 2.7085 | Actual Loss: 0.3208\n",
      "Baseline Loss: 2.6595 | Actual Loss: 0.2250\n",
      "Baseline Loss: 2.2978 | Actual Loss: 0.1331\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5098\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4629\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4523\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.3522\n",
      "Epoch 92/1000: Train Loss: 0.2755, Val Loss: 0.4443\n",
      "Baseline Loss: 2.6641 | Actual Loss: 0.2602\n",
      "Baseline Loss: 2.6946 | Actual Loss: 0.2804\n",
      "Baseline Loss: 2.6734 | Actual Loss: 0.2401\n",
      "Baseline Loss: 2.6732 | Actual Loss: 0.3563\n",
      "Baseline Loss: 2.6262 | Actual Loss: 0.2684\n",
      "Baseline Loss: 2.6433 | Actual Loss: 0.4959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 93/1000 [00:29<04:41,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6585 | Actual Loss: 0.1796\n",
      "Baseline Loss: 2.6891 | Actual Loss: 0.3037\n",
      "Baseline Loss: 2.6820 | Actual Loss: 0.2847\n",
      "Baseline Loss: 2.7129 | Actual Loss: 0.2813\n",
      "Baseline Loss: 2.7115 | Actual Loss: 0.3049\n",
      "Baseline Loss: 2.6736 | Actual Loss: 0.3417\n",
      "Baseline Loss: 2.6608 | Actual Loss: 0.2883\n",
      "Baseline Loss: 2.6607 | Actual Loss: 0.3485\n",
      "Baseline Loss: 2.7159 | Actual Loss: 0.3897\n",
      "Baseline Loss: 2.2368 | Actual Loss: 0.1666\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4289\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4502\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4280\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2852\n",
      "Epoch 93/1000: Train Loss: 0.2994, Val Loss: 0.3981\n",
      "Baseline Loss: 2.6500 | Actual Loss: 0.2071\n",
      "Baseline Loss: 2.7162 | Actual Loss: 0.2492\n",
      "Baseline Loss: 2.6750 | Actual Loss: 0.2768\n",
      "Baseline Loss: 2.6711 | Actual Loss: 0.2753\n",
      "Baseline Loss: 2.6770 | Actual Loss: 0.2846\n",
      "Baseline Loss: 2.7021 | Actual Loss: 0.2537\n",
      "Baseline Loss: 2.6457 | Actual Loss: 0.4099\n",
      "Baseline Loss: 2.6571 | Actual Loss: 0.4475\n",
      "Baseline Loss: 2.6608 | Actual Loss: 0.2470\n",
      "Baseline Loss: 2.6884 | Actual Loss: 0.4023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 94/1000 [00:29<04:53,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6865 | Actual Loss: 0.1928\n",
      "Baseline Loss: 2.6487 | Actual Loss: 0.3244\n",
      "Baseline Loss: 2.6775 | Actual Loss: 0.3334\n",
      "Baseline Loss: 2.6687 | Actual Loss: 0.2686\n",
      "Baseline Loss: 2.6765 | Actual Loss: 0.4049\n",
      "Baseline Loss: 2.3409 | Actual Loss: 0.2596\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4750\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3997\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3836\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.3089\n",
      "Epoch 94/1000: Train Loss: 0.3023, Val Loss: 0.3918\n",
      "Baseline Loss: 2.6560 | Actual Loss: 0.2862\n",
      "Baseline Loss: 2.7035 | Actual Loss: 0.2906\n",
      "Baseline Loss: 2.6673 | Actual Loss: 0.2208\n",
      "Baseline Loss: 2.6688 | Actual Loss: 0.1703\n",
      "Baseline Loss: 2.6786 | Actual Loss: 0.3006\n",
      "Baseline Loss: 2.6811 | Actual Loss: 0.2253\n",
      "Baseline Loss: 2.7270 | Actual Loss: 0.3036\n",
      "Baseline Loss: 2.7234 | Actual Loss: 0.1886\n",
      "Baseline Loss: 2.6646 | Actual Loss: 0.4437\n",
      "Baseline Loss: 2.6502 | Actual Loss: 0.3523\n",
      "Baseline Loss: 2.6891 | Actual Loss: 0.5177\n",
      "Baseline Loss: 2.6569 | Actual Loss: 0.2226\n",
      "Baseline Loss: 2.6694 | Actual Loss: 0.3231\n",
      "Baseline Loss: 2.6993 | Actual Loss: 0.1815\n",
      "Baseline Loss: 2.6595 | Actual Loss: 0.4357\n",
      "Baseline Loss: 2.2712 | Actual Loss: 0.0985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 95/1000 [00:29<04:56,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6853 | Actual Loss: 0.5634\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4642\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4033\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.3072\n",
      "Epoch 95/1000: Train Loss: 0.2851, Val Loss: 0.4345\n",
      "Baseline Loss: 2.6463 | Actual Loss: 0.3932\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.2380\n",
      "Baseline Loss: 2.6884 | Actual Loss: 0.3585\n",
      "Baseline Loss: 2.6650 | Actual Loss: 0.2945\n",
      "Baseline Loss: 2.6577 | Actual Loss: 0.2382\n",
      "Baseline Loss: 2.6892 | Actual Loss: 0.2224\n",
      "Baseline Loss: 2.6275 | Actual Loss: 0.4279\n",
      "Baseline Loss: 2.6750 | Actual Loss: 0.2722\n",
      "Baseline Loss: 2.6671 | Actual Loss: 0.2332\n",
      "Baseline Loss: 2.6569 | Actual Loss: 0.3088\n",
      "Baseline Loss: 2.6940 | Actual Loss: 0.3245\n",
      "Baseline Loss: 2.6356 | Actual Loss: 0.2615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 96/1000 [00:30<04:38,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7201 | Actual Loss: 0.2383\n",
      "Baseline Loss: 2.6869 | Actual Loss: 0.3108\n",
      "Baseline Loss: 2.6445 | Actual Loss: 0.1967\n",
      "Baseline Loss: 2.2999 | Actual Loss: 0.8777\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5155\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3655\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4362\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.3096\n",
      "Epoch 96/1000: Train Loss: 0.3248, Val Loss: 0.4067\n",
      "Baseline Loss: 2.7043 | Actual Loss: 0.5286\n",
      "Baseline Loss: 2.6813 | Actual Loss: 0.3501\n",
      "Baseline Loss: 2.6535 | Actual Loss: 0.3033\n",
      "Baseline Loss: 2.6701 | Actual Loss: 0.2788\n",
      "Baseline Loss: 2.6748 | Actual Loss: 0.4614\n",
      "Baseline Loss: 2.6765 | Actual Loss: 0.2333\n",
      "Baseline Loss: 2.6813 | Actual Loss: 0.2620\n",
      "Baseline Loss: 2.6479 | Actual Loss: 0.1561\n",
      "Baseline Loss: 2.7097 | Actual Loss: 0.2974\n",
      "Baseline Loss: 2.6605 | Actual Loss: 0.4322\n",
      "Baseline Loss: 2.6984 | Actual Loss: 0.2612\n",
      "Baseline Loss: 2.6959 | Actual Loss: 0.2147\n",
      "Baseline Loss: 2.6423 | Actual Loss: 0.2208\n",
      "Baseline Loss: 2.6571 | Actual Loss: 0.2855\n",
      "Baseline Loss: 2.6601 | Actual Loss: 0.2765\n",
      "Baseline Loss: 2.2701 | Actual Loss: 0.1405\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4401\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 97/1000 [00:30<04:46,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6861 | Actual Loss: 0.3909\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2704\n",
      "Epoch 97/1000: Train Loss: 0.2939, Val Loss: 0.3803\n",
      "Baseline Loss: 2.7199 | Actual Loss: 0.3404\n",
      "Baseline Loss: 2.6636 | Actual Loss: 0.3688\n",
      "Baseline Loss: 2.6972 | Actual Loss: 0.1679\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.2969\n",
      "Baseline Loss: 2.6821 | Actual Loss: 0.3447\n",
      "Baseline Loss: 2.6789 | Actual Loss: 0.2214\n",
      "Baseline Loss: 2.6752 | Actual Loss: 0.2837\n",
      "Baseline Loss: 2.6769 | Actual Loss: 0.2421\n",
      "Baseline Loss: 2.6771 | Actual Loss: 0.2633\n",
      "Baseline Loss: 2.6718 | Actual Loss: 0.2974\n",
      "Baseline Loss: 2.6584 | Actual Loss: 0.2647\n",
      "Baseline Loss: 2.6743 | Actual Loss: 0.3088\n",
      "Baseline Loss: 2.6739 | Actual Loss: 0.0845\n",
      "Baseline Loss: 2.6616 | Actual Loss: 0.2022\n",
      "Baseline Loss: 2.6743 | Actual Loss: 0.3312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 98/1000 [00:30<04:27,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2393 | Actual Loss: 0.2361\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4281\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4133\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4612\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2661\n",
      "Epoch 98/1000: Train Loss: 0.2659, Val Loss: 0.3922\n",
      "Baseline Loss: 2.6685 | Actual Loss: 0.3441\n",
      "Baseline Loss: 2.6482 | Actual Loss: 0.2539\n",
      "Baseline Loss: 2.6752 | Actual Loss: 0.2907\n",
      "Baseline Loss: 2.6845 | Actual Loss: 0.2905\n",
      "Baseline Loss: 2.6948 | Actual Loss: 0.3114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 99/1000 [00:31<04:43,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7184 | Actual Loss: 0.2222\n",
      "Baseline Loss: 2.6915 | Actual Loss: 0.4782\n",
      "Baseline Loss: 2.6627 | Actual Loss: 0.1841\n",
      "Baseline Loss: 2.6559 | Actual Loss: 0.1971\n",
      "Baseline Loss: 2.6855 | Actual Loss: 0.2486\n",
      "Baseline Loss: 2.6836 | Actual Loss: 0.1235\n",
      "Baseline Loss: 2.6789 | Actual Loss: 0.3013\n",
      "Baseline Loss: 2.7232 | Actual Loss: 0.2390\n",
      "Baseline Loss: 2.6670 | Actual Loss: 0.1691\n",
      "Baseline Loss: 2.6587 | Actual Loss: 0.2376\n",
      "Baseline Loss: 2.2277 | Actual Loss: 0.1425\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4901\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4841\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4483\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.3366\n",
      "Epoch 99/1000: Train Loss: 0.2521, Val Loss: 0.4398\n",
      "Baseline Loss: 2.6632 | Actual Loss: 0.3159\n",
      "Baseline Loss: 2.6367 | Actual Loss: 0.1903\n",
      "Baseline Loss: 2.6575 | Actual Loss: 0.3069\n",
      "Baseline Loss: 2.6660 | Actual Loss: 0.2934\n",
      "Baseline Loss: 2.6501 | Actual Loss: 0.2846\n",
      "Baseline Loss: 2.6723 | Actual Loss: 0.3297\n",
      "Baseline Loss: 2.6783 | Actual Loss: 0.2632\n",
      "Baseline Loss: 2.6353 | Actual Loss: 0.2870\n",
      "Baseline Loss: 2.6662 | Actual Loss: 0.4328\n",
      "Baseline Loss: 2.6921 | Actual Loss: 0.3250\n",
      "Baseline Loss: 2.6619 | Actual Loss: 0.2833\n",
      "Baseline Loss: 2.6815 | Actual Loss: 0.3378\n",
      "Baseline Loss: 2.7177 | Actual Loss: 0.2270\n",
      "Baseline Loss: 2.6827 | Actual Loss: 0.4099\n",
      "Baseline Loss: 2.6997 | Actual Loss: 0.2456\n",
      "Baseline Loss: 2.3095 | Actual Loss: 0.1849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 100/1000 [00:31<04:50,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6853 | Actual Loss: 0.4710\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3320\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3898\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2449\n",
      "Epoch 100/1000: Train Loss: 0.2948, Val Loss: 0.3594\n",
      "Baseline Loss: 2.6585 | Actual Loss: 0.1561\n",
      "Baseline Loss: 2.6776 | Actual Loss: 0.2551\n",
      "Baseline Loss: 2.6652 | Actual Loss: 0.3164\n",
      "Baseline Loss: 2.7169 | Actual Loss: 0.3635\n",
      "Baseline Loss: 2.6831 | Actual Loss: 0.2271\n",
      "Baseline Loss: 2.7008 | Actual Loss: 0.3555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 101/1000 [00:31<04:30,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6568 | Actual Loss: 0.2403\n",
      "Baseline Loss: 2.6278 | Actual Loss: 0.2348\n",
      "Baseline Loss: 2.6744 | Actual Loss: 0.2478\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.2543\n",
      "Baseline Loss: 2.6896 | Actual Loss: 0.2799\n",
      "Baseline Loss: 2.7032 | Actual Loss: 0.3164\n",
      "Baseline Loss: 2.7033 | Actual Loss: 0.2504\n",
      "Baseline Loss: 2.6436 | Actual Loss: 0.2344\n",
      "Baseline Loss: 2.6629 | Actual Loss: 0.1575\n",
      "Baseline Loss: 2.2224 | Actual Loss: 0.1383\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4527\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4384\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4202\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2670\n",
      "Epoch 101/1000: Train Loss: 0.2517, Val Loss: 0.3946\n",
      "Baseline Loss: 2.6670 | Actual Loss: 0.5940\n",
      "Baseline Loss: 2.7257 | Actual Loss: 0.3083\n",
      "Baseline Loss: 2.6985 | Actual Loss: 0.3218\n",
      "Baseline Loss: 2.6512 | Actual Loss: 0.1823\n",
      "Baseline Loss: 2.6805 | Actual Loss: 0.2929\n",
      "Baseline Loss: 2.6688 | Actual Loss: 0.2447\n",
      "Baseline Loss: 2.6693 | Actual Loss: 0.3017\n",
      "Baseline Loss: 2.6974 | Actual Loss: 0.2919\n",
      "Baseline Loss: 2.6417 | Actual Loss: 0.1979\n",
      "Baseline Loss: 2.6535 | Actual Loss: 0.3117\n",
      "Baseline Loss: 2.7115 | Actual Loss: 0.2536\n",
      "Baseline Loss: 2.6546 | Actual Loss: 0.2933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 102/1000 [00:32<04:44,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6410 | Actual Loss: 0.2168\n",
      "Baseline Loss: 2.6647 | Actual Loss: 0.2594\n",
      "Baseline Loss: 2.6445 | Actual Loss: 0.3757\n",
      "Baseline Loss: 2.3068 | Actual Loss: 0.7366\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4634\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3821\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4436\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.3107\n",
      "Epoch 102/1000: Train Loss: 0.3239, Val Loss: 0.4000\n",
      "Baseline Loss: 2.7037 | Actual Loss: 0.2451\n",
      "Baseline Loss: 2.6983 | Actual Loss: 0.1810\n",
      "Baseline Loss: 2.6457 | Actual Loss: 0.2538\n",
      "Baseline Loss: 2.7493 | Actual Loss: 0.2483\n",
      "Baseline Loss: 2.6416 | Actual Loss: 0.1704\n",
      "Baseline Loss: 2.6838 | Actual Loss: 0.0918\n",
      "Baseline Loss: 2.6675 | Actual Loss: 0.2941\n",
      "Baseline Loss: 2.6723 | Actual Loss: 0.2487\n",
      "Baseline Loss: 2.6842 | Actual Loss: 0.3263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 103/1000 [00:32<04:25,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6436 | Actual Loss: 0.2352\n",
      "Baseline Loss: 2.6702 | Actual Loss: 0.4693\n",
      "Baseline Loss: 2.6766 | Actual Loss: 0.3177\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2960\n",
      "Baseline Loss: 2.7048 | Actual Loss: 0.2163\n",
      "Baseline Loss: 2.6836 | Actual Loss: 0.2537\n",
      "Baseline Loss: 2.2859 | Actual Loss: 0.2261\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.3906\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4445\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3987\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2885\n",
      "Epoch 103/1000: Train Loss: 0.2546, Val Loss: 0.3806\n",
      "Baseline Loss: 2.6699 | Actual Loss: 0.5233\n",
      "Baseline Loss: 2.6467 | Actual Loss: 0.2605\n",
      "Baseline Loss: 2.7295 | Actual Loss: 0.2610\n",
      "Baseline Loss: 2.6793 | Actual Loss: 0.4292\n",
      "Baseline Loss: 2.6733 | Actual Loss: 0.3623\n",
      "Baseline Loss: 2.6389 | Actual Loss: 0.2589\n",
      "Baseline Loss: 2.6612 | Actual Loss: 0.3669\n",
      "Baseline Loss: 2.6885 | Actual Loss: 0.1826\n",
      "Baseline Loss: 2.7028 | Actual Loss: 0.2149\n",
      "Baseline Loss: 2.6397 | Actual Loss: 0.5406\n",
      "Baseline Loss: 2.7070 | Actual Loss: 0.1404\n",
      "Baseline Loss: 2.6666 | Actual Loss: 0.2441\n",
      "Baseline Loss: 2.6481 | Actual Loss: 0.2533\n",
      "Baseline Loss: 2.7048 | Actual Loss: 0.2565\n",
      "Baseline Loss: 2.6635 | Actual Loss: 0.2230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 104/1000 [00:32<04:37,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.3434 | Actual Loss: 0.2294\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4728\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3106\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4139\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2589\n",
      "Epoch 104/1000: Train Loss: 0.2967, Val Loss: 0.3641\n",
      "Baseline Loss: 2.7317 | Actual Loss: 0.2412\n",
      "Baseline Loss: 2.7263 | Actual Loss: 0.2782\n",
      "Baseline Loss: 2.6653 | Actual Loss: 0.3845\n",
      "Baseline Loss: 2.6284 | Actual Loss: 0.5304\n",
      "Baseline Loss: 2.6690 | Actual Loss: 0.2799\n",
      "Baseline Loss: 2.6829 | Actual Loss: 0.4666\n",
      "Baseline Loss: 2.6704 | Actual Loss: 0.2181\n",
      "Baseline Loss: 2.6405 | Actual Loss: 0.2603\n",
      "Baseline Loss: 2.6901 | Actual Loss: 0.2419\n",
      "Baseline Loss: 2.6533 | Actual Loss: 0.2408\n",
      "Baseline Loss: 2.6569 | Actual Loss: 0.3714\n",
      "Baseline Loss: 2.6707 | Actual Loss: 0.2765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 105/1000 [00:32<04:45,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6532 | Actual Loss: 0.2634\n",
      "Baseline Loss: 2.7195 | Actual Loss: 0.3739\n",
      "Baseline Loss: 2.6939 | Actual Loss: 0.2767\n",
      "Baseline Loss: 2.3071 | Actual Loss: 0.1631\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4226\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3638\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3492\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.3706\n",
      "Epoch 105/1000: Train Loss: 0.3042, Val Loss: 0.3765\n",
      "Baseline Loss: 2.6994 | Actual Loss: 0.2536\n",
      "Baseline Loss: 2.6974 | Actual Loss: 0.2349\n",
      "Baseline Loss: 2.6912 | Actual Loss: 0.2122\n",
      "Baseline Loss: 2.6334 | Actual Loss: 0.2405\n",
      "Baseline Loss: 2.6441 | Actual Loss: 0.2113\n",
      "Baseline Loss: 2.6531 | Actual Loss: 0.2798\n",
      "Baseline Loss: 2.6565 | Actual Loss: 0.3603\n",
      "Baseline Loss: 2.7038 | Actual Loss: 0.2910\n",
      "Baseline Loss: 2.7079 | Actual Loss: 0.2895\n",
      "Baseline Loss: 2.6469 | Actual Loss: 0.3112\n",
      "Baseline Loss: 2.7012 | Actual Loss: 0.3768\n",
      "Baseline Loss: 2.7131 | Actual Loss: 0.2753\n",
      "Baseline Loss: 2.6880 | Actual Loss: 0.1965\n",
      "Baseline Loss: 2.6671 | Actual Loss: 0.6656\n",
      "Baseline Loss: 2.6310 | Actual Loss: 0.3518\n",
      "Baseline Loss: 2.2514 | Actual Loss: 0.1557\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 106/1000 [00:33<04:52,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6474 | Actual Loss: 0.4716\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4077\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2345\n",
      "Epoch 106/1000: Train Loss: 0.2941, Val Loss: 0.4127\n",
      "Baseline Loss: 2.6832 | Actual Loss: 0.1907\n",
      "Baseline Loss: 2.6499 | Actual Loss: 0.2354\n",
      "Baseline Loss: 2.7036 | Actual Loss: 0.2434\n",
      "Baseline Loss: 2.6671 | Actual Loss: 0.3034\n",
      "Baseline Loss: 2.6365 | Actual Loss: 0.2454\n",
      "Baseline Loss: 2.6637 | Actual Loss: 0.2857\n",
      "Baseline Loss: 2.6524 | Actual Loss: 0.2613\n",
      "Baseline Loss: 2.6671 | Actual Loss: 0.4770\n",
      "Baseline Loss: 2.6795 | Actual Loss: 0.4238\n",
      "Baseline Loss: 2.7079 | Actual Loss: 0.2983\n",
      "Baseline Loss: 2.6736 | Actual Loss: 0.2598\n",
      "Baseline Loss: 2.6473 | Actual Loss: 0.1868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 107/1000 [00:33<04:38,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7382 | Actual Loss: 0.3326\n",
      "Baseline Loss: 2.7372 | Actual Loss: 0.2284\n",
      "Baseline Loss: 2.6508 | Actual Loss: 0.1356\n",
      "Baseline Loss: 2.2927 | Actual Loss: 0.2502\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4471\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3845\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3896\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2955\n",
      "Epoch 107/1000: Train Loss: 0.2724, Val Loss: 0.3792\n",
      "Baseline Loss: 2.6625 | Actual Loss: 0.3260\n",
      "Baseline Loss: 2.7050 | Actual Loss: 0.1980\n",
      "Baseline Loss: 2.6514 | Actual Loss: 0.3083\n",
      "Baseline Loss: 2.6996 | Actual Loss: 0.2414\n",
      "Baseline Loss: 2.7072 | Actual Loss: 0.4430\n",
      "Baseline Loss: 2.6423 | Actual Loss: 0.3207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 108/1000 [00:33<04:49,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6848 | Actual Loss: 0.3813\n",
      "Baseline Loss: 2.6976 | Actual Loss: 0.2455\n",
      "Baseline Loss: 2.6500 | Actual Loss: 0.3440\n",
      "Baseline Loss: 2.6424 | Actual Loss: 0.2514\n",
      "Baseline Loss: 2.6994 | Actual Loss: 0.5273\n",
      "Baseline Loss: 2.6693 | Actual Loss: 0.1750\n",
      "Baseline Loss: 2.6977 | Actual Loss: 0.3595\n",
      "Baseline Loss: 2.6456 | Actual Loss: 0.2898\n",
      "Baseline Loss: 2.6590 | Actual Loss: 0.5763\n",
      "Baseline Loss: 2.2832 | Actual Loss: 0.3254\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.6159\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4355\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.5066\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.3177\n",
      "Epoch 108/1000: Train Loss: 0.3321, Val Loss: 0.4689\n",
      "Baseline Loss: 2.7097 | Actual Loss: 0.2003\n",
      "Baseline Loss: 2.6838 | Actual Loss: 0.2199\n",
      "Baseline Loss: 2.6811 | Actual Loss: 0.3128\n",
      "Baseline Loss: 2.6903 | Actual Loss: 0.3063\n",
      "Baseline Loss: 2.6730 | Actual Loss: 0.4241\n",
      "Baseline Loss: 2.6621 | Actual Loss: 0.5067\n",
      "Baseline Loss: 2.6872 | Actual Loss: 0.3258\n",
      "Baseline Loss: 2.6948 | Actual Loss: 0.3075\n",
      "Baseline Loss: 2.6676 | Actual Loss: 0.1751\n",
      "Baseline Loss: 2.6617 | Actual Loss: 0.3621\n",
      "Baseline Loss: 2.6542 | Actual Loss: 0.3252\n",
      "Baseline Loss: 2.6783 | Actual Loss: 0.4039\n",
      "Baseline Loss: 2.6282 | Actual Loss: 0.3263\n",
      "Baseline Loss: 2.6821 | Actual Loss: 0.2505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 109/1000 [00:34<04:53,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6878 | Actual Loss: 0.2762\n",
      "Baseline Loss: 2.2706 | Actual Loss: 0.3122\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.3599\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3544\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3664\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.3142\n",
      "Epoch 109/1000: Train Loss: 0.3147, Val Loss: 0.3487\n",
      "Baseline Loss: 2.6527 | Actual Loss: 0.4137\n",
      "Baseline Loss: 2.6962 | Actual Loss: 0.2175\n",
      "Baseline Loss: 2.6629 | Actual Loss: 0.1570\n",
      "Baseline Loss: 2.7181 | Actual Loss: 0.3265\n",
      "Baseline Loss: 2.6624 | Actual Loss: 0.2115\n",
      "Baseline Loss: 2.6513 | Actual Loss: 0.3039\n",
      "Baseline Loss: 2.6654 | Actual Loss: 0.2254\n",
      "Baseline Loss: 2.6762 | Actual Loss: 0.2136\n",
      "Baseline Loss: 2.6987 | Actual Loss: 0.2456\n",
      "Baseline Loss: 2.6992 | Actual Loss: 0.1801\n",
      "Baseline Loss: 2.6911 | Actual Loss: 0.2720\n",
      "Baseline Loss: 2.6786 | Actual Loss: 0.4005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 110/1000 [00:34<04:36,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6457 | Actual Loss: 0.3079\n",
      "Baseline Loss: 2.6791 | Actual Loss: 0.2403\n",
      "Baseline Loss: 2.6698 | Actual Loss: 0.3347\n",
      "Baseline Loss: 2.2367 | Actual Loss: 0.1167\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.3759\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3688\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4071\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2091\n",
      "Epoch 110/1000: Train Loss: 0.2604, Val Loss: 0.3402\n",
      "Baseline Loss: 2.6392 | Actual Loss: 0.3291\n",
      "Baseline Loss: 2.6598 | Actual Loss: 0.2253\n",
      "Baseline Loss: 2.6975 | Actual Loss: 0.2845\n",
      "Baseline Loss: 2.6782 | Actual Loss: 0.2969\n",
      "Baseline Loss: 2.6609 | Actual Loss: 0.2270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 111/1000 [00:34<04:41,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6849 | Actual Loss: 0.3188\n",
      "Baseline Loss: 2.6688 | Actual Loss: 0.2447\n",
      "Baseline Loss: 2.6540 | Actual Loss: 0.2901\n",
      "Baseline Loss: 2.6795 | Actual Loss: 0.2812\n",
      "Baseline Loss: 2.7005 | Actual Loss: 0.3038\n",
      "Baseline Loss: 2.6694 | Actual Loss: 0.4370\n",
      "Baseline Loss: 2.6665 | Actual Loss: 0.2643\n",
      "Baseline Loss: 2.6708 | Actual Loss: 0.1911\n",
      "Baseline Loss: 2.6843 | Actual Loss: 0.2292\n",
      "Baseline Loss: 2.6581 | Actual Loss: 0.3071\n",
      "Baseline Loss: 2.3211 | Actual Loss: 0.2540\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.3930\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3624\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4002\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2402\n",
      "Epoch 111/1000: Train Loss: 0.2802, Val Loss: 0.3489\n",
      "Baseline Loss: 2.6544 | Actual Loss: 0.1634\n",
      "Baseline Loss: 2.6862 | Actual Loss: 0.2538\n",
      "Baseline Loss: 2.7253 | Actual Loss: 0.1872\n",
      "Baseline Loss: 2.6682 | Actual Loss: 0.2617\n",
      "Baseline Loss: 2.6534 | Actual Loss: 0.3101\n",
      "Baseline Loss: 2.6759 | Actual Loss: 0.2435\n",
      "Baseline Loss: 2.6704 | Actual Loss: 0.2210\n",
      "Baseline Loss: 2.6862 | Actual Loss: 0.2189\n",
      "Baseline Loss: 2.6883 | Actual Loss: 0.3514\n",
      "Baseline Loss: 2.6867 | Actual Loss: 0.3305\n",
      "Baseline Loss: 2.6879 | Actual Loss: 0.2654\n",
      "Baseline Loss: 2.6638 | Actual Loss: 0.2916\n",
      "Baseline Loss: 2.6749 | Actual Loss: 0.2399\n",
      "Baseline Loss: 2.6870 | Actual Loss: 0.2806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 112/1000 [00:35<04:46,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6747 | Actual Loss: 0.1980\n",
      "Baseline Loss: 2.2206 | Actual Loss: 0.1875\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.3783\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4025\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3970\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2974\n",
      "Epoch 112/1000: Train Loss: 0.2503, Val Loss: 0.3688\n",
      "Baseline Loss: 2.6746 | Actual Loss: 0.2410\n",
      "Baseline Loss: 2.6731 | Actual Loss: 0.3209\n",
      "Baseline Loss: 2.6806 | Actual Loss: 0.4659\n",
      "Baseline Loss: 2.6939 | Actual Loss: 0.4410\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.2439\n",
      "Baseline Loss: 2.6732 | Actual Loss: 0.1889\n",
      "Baseline Loss: 2.6568 | Actual Loss: 0.4407\n",
      "Baseline Loss: 2.6856 | Actual Loss: 0.3411\n",
      "Baseline Loss: 2.6614 | Actual Loss: 0.2455\n",
      "Baseline Loss: 2.6673 | Actual Loss: 0.2163\n",
      "Baseline Loss: 2.6939 | Actual Loss: 0.3050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█▏        | 113/1000 [00:35<04:29,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6753 | Actual Loss: 0.2510\n",
      "Baseline Loss: 2.6808 | Actual Loss: 0.3652\n",
      "Baseline Loss: 2.6633 | Actual Loss: 0.2138\n",
      "Baseline Loss: 2.6860 | Actual Loss: 0.1780\n",
      "Baseline Loss: 2.2750 | Actual Loss: 0.1870\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5023\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3875\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4445\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2845\n",
      "Epoch 113/1000: Train Loss: 0.2903, Val Loss: 0.4047\n",
      "Baseline Loss: 2.6740 | Actual Loss: 0.2690\n",
      "Baseline Loss: 2.6580 | Actual Loss: 0.2287\n",
      "Baseline Loss: 2.6515 | Actual Loss: 0.1862\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.2812\n",
      "Baseline Loss: 2.6759 | Actual Loss: 0.1182\n",
      "Baseline Loss: 2.6590 | Actual Loss: 0.2104\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4433\n",
      "Baseline Loss: 2.6738 | Actual Loss: 0.2522\n",
      "Baseline Loss: 2.6937 | Actual Loss: 0.2019\n",
      "Baseline Loss: 2.6813 | Actual Loss: 0.4410\n",
      "Baseline Loss: 2.6884 | Actual Loss: 0.1214\n",
      "Baseline Loss: 2.6621 | Actual Loss: 0.3040\n",
      "Baseline Loss: 2.6778 | Actual Loss: 0.3218\n",
      "Baseline Loss: 2.6864 | Actual Loss: 0.1873\n",
      "Baseline Loss: 2.6864 | Actual Loss: 0.2197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█▏        | 114/1000 [00:35<04:42,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2579 | Actual Loss: 0.0621\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4285\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3164\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4336\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2961\n",
      "Epoch 114/1000: Train Loss: 0.2405, Val Loss: 0.3687\n",
      "Baseline Loss: 2.7134 | Actual Loss: 0.1410\n",
      "Baseline Loss: 2.6723 | Actual Loss: 0.2907\n",
      "Baseline Loss: 2.6463 | Actual Loss: 0.4132\n",
      "Baseline Loss: 2.6678 | Actual Loss: 0.2794\n",
      "Baseline Loss: 2.6530 | Actual Loss: 0.2350\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.2911\n",
      "Baseline Loss: 2.6823 | Actual Loss: 0.1958\n",
      "Baseline Loss: 2.6719 | Actual Loss: 0.1504\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.2307\n",
      "Baseline Loss: 2.6793 | Actual Loss: 0.1999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 115/1000 [00:36<04:30,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6762 | Actual Loss: 0.2250\n",
      "Baseline Loss: 2.6626 | Actual Loss: 0.1973\n",
      "Baseline Loss: 2.6600 | Actual Loss: 0.3529\n",
      "Baseline Loss: 2.6708 | Actual Loss: 0.2672\n",
      "Baseline Loss: 2.6620 | Actual Loss: 0.1478\n",
      "Baseline Loss: 2.2978 | Actual Loss: 0.0981\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4826\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3423\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4489\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2905\n",
      "Epoch 115/1000: Train Loss: 0.2322, Val Loss: 0.3911\n",
      "Baseline Loss: 2.6575 | Actual Loss: 0.1852\n",
      "Baseline Loss: 2.6534 | Actual Loss: 0.0987\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.2755\n",
      "Baseline Loss: 2.6695 | Actual Loss: 0.3084\n",
      "Baseline Loss: 2.7264 | Actual Loss: 0.2333\n",
      "Baseline Loss: 2.6598 | Actual Loss: 0.2290\n",
      "Baseline Loss: 2.6811 | Actual Loss: 0.3639\n",
      "Baseline Loss: 2.7097 | Actual Loss: 0.1974\n",
      "Baseline Loss: 2.7122 | Actual Loss: 0.3562\n",
      "Baseline Loss: 2.6983 | Actual Loss: 0.1515\n",
      "Baseline Loss: 2.6695 | Actual Loss: 0.2222\n",
      "Baseline Loss: 2.6397 | Actual Loss: 0.1561\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.1537\n",
      "Baseline Loss: 2.6928 | Actual Loss: 0.1886\n",
      "Baseline Loss: 2.6682 | Actual Loss: 0.2444\n",
      "Baseline Loss: 2.2123 | Actual Loss: 0.2244\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4959\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 116/1000 [00:36<04:39,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6861 | Actual Loss: 0.3962\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2699\n",
      "Epoch 116/1000: Train Loss: 0.2243, Val Loss: 0.3830\n",
      "Baseline Loss: 2.6739 | Actual Loss: 0.2890\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.2740\n",
      "Baseline Loss: 2.6848 | Actual Loss: 0.2757\n",
      "Baseline Loss: 2.6705 | Actual Loss: 0.3304\n",
      "Baseline Loss: 2.6743 | Actual Loss: 0.2799\n",
      "Baseline Loss: 2.6622 | Actual Loss: 0.1669\n",
      "Baseline Loss: 2.6828 | Actual Loss: 0.2219\n",
      "Baseline Loss: 2.6756 | Actual Loss: 0.4593\n",
      "Baseline Loss: 2.6916 | Actual Loss: 0.1853\n",
      "Baseline Loss: 2.6921 | Actual Loss: 0.2157\n",
      "Baseline Loss: 2.6669 | Actual Loss: 0.2160\n",
      "Baseline Loss: 2.6365 | Actual Loss: 0.2674\n",
      "Baseline Loss: 2.6440 | Actual Loss: 0.3385\n",
      "Baseline Loss: 2.7176 | Actual Loss: 0.3394\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 117/1000 [00:36<04:19,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.3199 | Actual Loss: 0.0774\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5208\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3391\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4718\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2465\n",
      "Epoch 117/1000: Train Loss: 0.2666, Val Loss: 0.3946\n",
      "Baseline Loss: 2.6561 | Actual Loss: 0.1755\n",
      "Baseline Loss: 2.6781 | Actual Loss: 0.1295\n",
      "Baseline Loss: 2.6977 | Actual Loss: 0.1951\n",
      "Baseline Loss: 2.7030 | Actual Loss: 0.1693\n",
      "Baseline Loss: 2.6437 | Actual Loss: 0.2719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 118/1000 [00:37<04:34,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6882 | Actual Loss: 0.1484\n",
      "Baseline Loss: 2.6955 | Actual Loss: 0.3190\n",
      "Baseline Loss: 2.6779 | Actual Loss: 0.1710\n",
      "Baseline Loss: 2.6585 | Actual Loss: 0.2687\n",
      "Baseline Loss: 2.6550 | Actual Loss: 0.1522\n",
      "Baseline Loss: 2.6838 | Actual Loss: 0.4210\n",
      "Baseline Loss: 2.6719 | Actual Loss: 0.2608\n",
      "Baseline Loss: 2.6410 | Actual Loss: 0.1534\n",
      "Baseline Loss: 2.6870 | Actual Loss: 0.2575\n",
      "Baseline Loss: 2.6866 | Actual Loss: 0.2835\n",
      "Baseline Loss: 2.3583 | Actual Loss: 0.2086\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4556\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3737\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3899\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2635\n",
      "Epoch 118/1000: Train Loss: 0.2241, Val Loss: 0.3706\n",
      "Baseline Loss: 2.6762 | Actual Loss: 0.3306\n",
      "Baseline Loss: 2.6904 | Actual Loss: 0.3440\n",
      "Baseline Loss: 2.6446 | Actual Loss: 0.3176\n",
      "Baseline Loss: 2.6639 | Actual Loss: 0.2285\n",
      "Baseline Loss: 2.6426 | Actual Loss: 0.2078\n",
      "Baseline Loss: 2.6965 | Actual Loss: 0.1374\n",
      "Baseline Loss: 2.6423 | Actual Loss: 0.1695\n",
      "Baseline Loss: 2.6868 | Actual Loss: 0.1560\n",
      "Baseline Loss: 2.6612 | Actual Loss: 0.1426\n",
      "Baseline Loss: 2.6653 | Actual Loss: 0.1973\n",
      "Baseline Loss: 2.6342 | Actual Loss: 0.1781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 119/1000 [00:37<04:43,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6862 | Actual Loss: 0.2764\n",
      "Baseline Loss: 2.7008 | Actual Loss: 0.3393\n",
      "Baseline Loss: 2.6865 | Actual Loss: 0.2529\n",
      "Baseline Loss: 2.6604 | Actual Loss: 0.2028\n",
      "Baseline Loss: 2.3484 | Actual Loss: 0.2291\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5016\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3942\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4002\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2670\n",
      "Epoch 119/1000: Train Loss: 0.2319, Val Loss: 0.3908\n",
      "Baseline Loss: 2.6800 | Actual Loss: 0.2060\n",
      "Baseline Loss: 2.6627 | Actual Loss: 0.3406\n",
      "Baseline Loss: 2.6973 | Actual Loss: 0.2172\n",
      "Baseline Loss: 2.6550 | Actual Loss: 0.2415\n",
      "Baseline Loss: 2.7094 | Actual Loss: 0.1852\n",
      "Baseline Loss: 2.7033 | Actual Loss: 0.1441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 120/1000 [00:37<04:24,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6579 | Actual Loss: 0.2443\n",
      "Baseline Loss: 2.7108 | Actual Loss: 0.2058\n",
      "Baseline Loss: 2.6705 | Actual Loss: 0.2285\n",
      "Baseline Loss: 2.6689 | Actual Loss: 0.4477\n",
      "Baseline Loss: 2.6492 | Actual Loss: 0.2514\n",
      "Baseline Loss: 2.6762 | Actual Loss: 0.2691\n",
      "Baseline Loss: 2.6527 | Actual Loss: 0.3125\n",
      "Baseline Loss: 2.7033 | Actual Loss: 0.3129\n",
      "Baseline Loss: 2.6775 | Actual Loss: 0.1687\n",
      "Baseline Loss: 2.2835 | Actual Loss: 0.1674\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4229\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3307\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4296\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2635\n",
      "Epoch 120/1000: Train Loss: 0.2464, Val Loss: 0.3617\n",
      "Baseline Loss: 2.7117 | Actual Loss: 0.3849\n",
      "Baseline Loss: 2.6573 | Actual Loss: 0.2781\n",
      "Baseline Loss: 2.6450 | Actual Loss: 0.2997\n",
      "Baseline Loss: 2.6414 | Actual Loss: 0.2275\n",
      "Baseline Loss: 2.6405 | Actual Loss: 0.2409\n",
      "Baseline Loss: 2.6658 | Actual Loss: 0.2875\n",
      "Baseline Loss: 2.6724 | Actual Loss: 0.1805\n",
      "Baseline Loss: 2.6450 | Actual Loss: 0.2422\n",
      "Baseline Loss: 2.7088 | Actual Loss: 0.2767\n",
      "Baseline Loss: 2.6744 | Actual Loss: 0.4027\n",
      "Baseline Loss: 2.6827 | Actual Loss: 0.1670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 121/1000 [00:38<04:38,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6932 | Actual Loss: 0.1286\n",
      "Baseline Loss: 2.7009 | Actual Loss: 0.2655\n",
      "Baseline Loss: 2.6845 | Actual Loss: 0.1972\n",
      "Baseline Loss: 2.6923 | Actual Loss: 0.4120\n",
      "Baseline Loss: 2.2826 | Actual Loss: 0.0711\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4173\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3435\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4335\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2568\n",
      "Epoch 121/1000: Train Loss: 0.2539, Val Loss: 0.3628\n",
      "Baseline Loss: 2.6838 | Actual Loss: 0.3832\n",
      "Baseline Loss: 2.6580 | Actual Loss: 0.2401\n",
      "Baseline Loss: 2.6941 | Actual Loss: 0.1813\n",
      "Baseline Loss: 2.6734 | Actual Loss: 0.1692\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.2471\n",
      "Baseline Loss: 2.7053 | Actual Loss: 0.4687\n",
      "Baseline Loss: 2.6695 | Actual Loss: 0.2576\n",
      "Baseline Loss: 2.6998 | Actual Loss: 0.2686\n",
      "Baseline Loss: 2.6889 | Actual Loss: 0.2541\n",
      "Baseline Loss: 2.6821 | Actual Loss: 0.2593\n",
      "Baseline Loss: 2.6510 | Actual Loss: 0.3300\n",
      "Baseline Loss: 2.6782 | Actual Loss: 0.3524\n",
      "Baseline Loss: 2.6512 | Actual Loss: 0.1778\n",
      "Baseline Loss: 2.6471 | Actual Loss: 0.3129\n",
      "Baseline Loss: 2.6733 | Actual Loss: 0.2097\n",
      "Baseline Loss: 2.2111 | Actual Loss: 0.1633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 122/1000 [00:38<04:42,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6853 | Actual Loss: 0.5111\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4070\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4005\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2871\n",
      "Epoch 122/1000: Train Loss: 0.2672, Val Loss: 0.4015\n",
      "Baseline Loss: 2.6599 | Actual Loss: 0.3232\n",
      "Baseline Loss: 2.6956 | Actual Loss: 0.1386\n",
      "Baseline Loss: 2.6856 | Actual Loss: 0.2425\n",
      "Baseline Loss: 2.6657 | Actual Loss: 0.3136\n",
      "Baseline Loss: 2.6948 | Actual Loss: 0.2534\n",
      "Baseline Loss: 2.6664 | Actual Loss: 0.3476\n",
      "Baseline Loss: 2.7282 | Actual Loss: 0.1658\n",
      "Baseline Loss: 2.6905 | Actual Loss: 0.1727\n",
      "Baseline Loss: 2.6889 | Actual Loss: 0.3178\n",
      "Baseline Loss: 2.6503 | Actual Loss: 0.2927\n",
      "Baseline Loss: 2.6340 | Actual Loss: 0.2404\n",
      "Baseline Loss: 2.6772 | Actual Loss: 0.2928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 123/1000 [00:38<04:27,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6643 | Actual Loss: 0.2553\n",
      "Baseline Loss: 2.6925 | Actual Loss: 0.4067\n",
      "Baseline Loss: 2.7141 | Actual Loss: 0.2118\n",
      "Baseline Loss: 2.2359 | Actual Loss: 0.1682\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4510\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4095\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3941\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2471\n",
      "Epoch 123/1000: Train Loss: 0.2589, Val Loss: 0.3754\n",
      "Baseline Loss: 2.7028 | Actual Loss: 0.2421\n",
      "Baseline Loss: 2.7026 | Actual Loss: 0.2271\n",
      "Baseline Loss: 2.7107 | Actual Loss: 0.3022\n",
      "Baseline Loss: 2.6576 | Actual Loss: 0.2995\n",
      "Baseline Loss: 2.6752 | Actual Loss: 0.3536\n",
      "Baseline Loss: 2.6875 | Actual Loss: 0.2782\n",
      "Baseline Loss: 2.6585 | Actual Loss: 0.2215\n",
      "Baseline Loss: 2.6780 | Actual Loss: 0.3153\n",
      "Baseline Loss: 2.6657 | Actual Loss: 0.1867\n",
      "Baseline Loss: 2.6685 | Actual Loss: 0.2039\n",
      "Baseline Loss: 2.6535 | Actual Loss: 0.2895\n",
      "Baseline Loss: 2.6582 | Actual Loss: 0.1979\n",
      "Baseline Loss: 2.6766 | Actual Loss: 0.2585\n",
      "Baseline Loss: 2.6874 | Actual Loss: 0.1884\n",
      "Baseline Loss: 2.6766 | Actual Loss: 0.3196\n",
      "Baseline Loss: 2.2440 | Actual Loss: 0.1050\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4362\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.2451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 124/1000 [00:38<04:37,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6861 | Actual Loss: 0.4292\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2620\n",
      "Epoch 124/1000: Train Loss: 0.2493, Val Loss: 0.3431\n",
      "Baseline Loss: 2.6696 | Actual Loss: 0.1980\n",
      "Baseline Loss: 2.7247 | Actual Loss: 0.2152\n",
      "Baseline Loss: 2.6828 | Actual Loss: 0.2620\n",
      "Baseline Loss: 2.6673 | Actual Loss: 0.2605\n",
      "Baseline Loss: 2.6504 | Actual Loss: 0.1605\n",
      "Baseline Loss: 2.6411 | Actual Loss: 0.3530\n",
      "Baseline Loss: 2.6469 | Actual Loss: 0.3039\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.1544\n",
      "Baseline Loss: 2.6497 | Actual Loss: 0.1728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▎        | 125/1000 [00:39<04:37,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6888 | Actual Loss: 0.2382\n",
      "Baseline Loss: 2.6432 | Actual Loss: 0.2331\n",
      "Baseline Loss: 2.6759 | Actual Loss: 0.2431\n",
      "Baseline Loss: 2.6616 | Actual Loss: 0.2573\n",
      "Baseline Loss: 2.6559 | Actual Loss: 0.3796\n",
      "Baseline Loss: 2.7045 | Actual Loss: 0.2357\n",
      "Baseline Loss: 2.3196 | Actual Loss: 0.0815\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4290\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3933\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3967\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2731\n",
      "Epoch 125/1000: Train Loss: 0.2343, Val Loss: 0.3730\n",
      "Baseline Loss: 2.6866 | Actual Loss: 0.1959\n",
      "Baseline Loss: 2.6916 | Actual Loss: 0.2421\n",
      "Baseline Loss: 2.7217 | Actual Loss: 0.1690\n",
      "Baseline Loss: 2.6447 | Actual Loss: 0.1633\n",
      "Baseline Loss: 2.6695 | Actual Loss: 0.1808\n",
      "Baseline Loss: 2.6559 | Actual Loss: 0.2097\n",
      "Baseline Loss: 2.6582 | Actual Loss: 0.3743\n",
      "Baseline Loss: 2.6959 | Actual Loss: 0.2768\n",
      "Baseline Loss: 2.6917 | Actual Loss: 0.1494\n",
      "Baseline Loss: 2.6813 | Actual Loss: 0.2959\n",
      "Baseline Loss: 2.6418 | Actual Loss: 0.2951\n",
      "Baseline Loss: 2.6940 | Actual Loss: 0.2730\n",
      "Baseline Loss: 2.6588 | Actual Loss: 0.2074\n",
      "Baseline Loss: 2.6631 | Actual Loss: 0.3378\n",
      "Baseline Loss: 2.6624 | Actual Loss: 0.1673\n",
      "Baseline Loss: 2.2405 | Actual Loss: 0.1044\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 126/1000 [00:39<04:45,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6474 | Actual Loss: 0.3684\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3887\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2239\n",
      "Epoch 126/1000: Train Loss: 0.2276, Val Loss: 0.3527\n",
      "Baseline Loss: 2.6830 | Actual Loss: 0.2022\n",
      "Baseline Loss: 2.6500 | Actual Loss: 0.1458\n",
      "Baseline Loss: 2.6931 | Actual Loss: 0.1954\n",
      "Baseline Loss: 2.6887 | Actual Loss: 0.2591\n",
      "Baseline Loss: 2.6736 | Actual Loss: 0.2221\n",
      "Baseline Loss: 2.6459 | Actual Loss: 0.2665\n",
      "Baseline Loss: 2.6879 | Actual Loss: 0.2060\n",
      "Baseline Loss: 2.6639 | Actual Loss: 0.2973\n",
      "Baseline Loss: 2.6662 | Actual Loss: 0.1910\n",
      "Baseline Loss: 2.6924 | Actual Loss: 0.4242\n",
      "Baseline Loss: 2.6862 | Actual Loss: 0.2226\n",
      "Baseline Loss: 2.7009 | Actual Loss: 0.2131\n",
      "Baseline Loss: 2.6949 | Actual Loss: 0.1397\n",
      "Baseline Loss: 2.6903 | Actual Loss: 0.2687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 127/1000 [00:39<04:26,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6819 | Actual Loss: 0.1801\n",
      "Baseline Loss: 2.2202 | Actual Loss: 0.1079\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4930\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3611\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3969\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2184\n",
      "Epoch 127/1000: Train Loss: 0.2214, Val Loss: 0.3674\n",
      "Baseline Loss: 2.6533 | Actual Loss: 0.2644\n",
      "Baseline Loss: 2.6461 | Actual Loss: 0.1207\n",
      "Baseline Loss: 2.6526 | Actual Loss: 0.1216\n",
      "Baseline Loss: 2.6425 | Actual Loss: 0.1820\n",
      "Baseline Loss: 2.7215 | Actual Loss: 0.3972\n",
      "Baseline Loss: 2.6752 | Actual Loss: 0.5631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 128/1000 [00:40<04:38,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6646 | Actual Loss: 0.2406\n",
      "Baseline Loss: 2.6847 | Actual Loss: 0.1929\n",
      "Baseline Loss: 2.6991 | Actual Loss: 0.2446\n",
      "Baseline Loss: 2.6470 | Actual Loss: 0.2710\n",
      "Baseline Loss: 2.6642 | Actual Loss: 0.2794\n",
      "Baseline Loss: 2.6978 | Actual Loss: 0.1792\n",
      "Baseline Loss: 2.6973 | Actual Loss: 0.1778\n",
      "Baseline Loss: 2.6698 | Actual Loss: 0.2736\n",
      "Baseline Loss: 2.6869 | Actual Loss: 0.2822\n",
      "Baseline Loss: 2.2599 | Actual Loss: 0.3474\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4465\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3333\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3864\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2072\n",
      "Epoch 128/1000: Train Loss: 0.2586, Val Loss: 0.3433\n",
      "Baseline Loss: 2.6703 | Actual Loss: 0.1859\n",
      "Baseline Loss: 2.6626 | Actual Loss: 0.2236\n",
      "Baseline Loss: 2.6730 | Actual Loss: 0.3043\n",
      "Baseline Loss: 2.6539 | Actual Loss: 0.1798\n",
      "Baseline Loss: 2.6738 | Actual Loss: 0.1962\n",
      "Baseline Loss: 2.6945 | Actual Loss: 0.2931\n",
      "Baseline Loss: 2.6753 | Actual Loss: 0.2818\n",
      "Baseline Loss: 2.6658 | Actual Loss: 0.1897\n",
      "Baseline Loss: 2.7007 | Actual Loss: 0.2991\n",
      "Baseline Loss: 2.6347 | Actual Loss: 0.3353\n",
      "Baseline Loss: 2.6587 | Actual Loss: 0.2402\n",
      "Baseline Loss: 2.6621 | Actual Loss: 0.1114\n",
      "Baseline Loss: 2.6624 | Actual Loss: 0.3195\n",
      "Baseline Loss: 2.7152 | Actual Loss: 0.1994\n",
      "Baseline Loss: 2.6392 | Actual Loss: 0.2289\n",
      "Baseline Loss: 2.2829 | Actual Loss: 0.1534\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.3837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 129/1000 [00:40<04:43,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6474 | Actual Loss: 0.3290\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3744\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2694\n",
      "Epoch 129/1000: Train Loss: 0.2339, Val Loss: 0.3391\n",
      "New best validation loss: 0.3391\n",
      "Baseline Loss: 2.6482 | Actual Loss: 0.1912\n",
      "Baseline Loss: 2.6653 | Actual Loss: 0.4593\n",
      "Baseline Loss: 2.6400 | Actual Loss: 0.2084\n",
      "Baseline Loss: 2.6802 | Actual Loss: 0.3418\n",
      "Baseline Loss: 2.6642 | Actual Loss: 0.4163\n",
      "Baseline Loss: 2.6756 | Actual Loss: 0.1695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 130/1000 [00:40<04:26,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6993 | Actual Loss: 0.3225\n",
      "Baseline Loss: 2.6868 | Actual Loss: 0.2416\n",
      "Baseline Loss: 2.6648 | Actual Loss: 0.1625\n",
      "Baseline Loss: 2.6849 | Actual Loss: 0.2664\n",
      "Baseline Loss: 2.6999 | Actual Loss: 0.1753\n",
      "Baseline Loss: 2.6412 | Actual Loss: 0.2878\n",
      "Baseline Loss: 2.6727 | Actual Loss: 0.2425\n",
      "Baseline Loss: 2.6836 | Actual Loss: 0.2756\n",
      "Baseline Loss: 2.6606 | Actual Loss: 0.2403\n",
      "Baseline Loss: 2.2514 | Actual Loss: 0.1723\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4599\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3436\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4168\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2499\n",
      "Epoch 130/1000: Train Loss: 0.2608, Val Loss: 0.3675\n",
      "Baseline Loss: 2.6469 | Actual Loss: 0.1707\n",
      "Baseline Loss: 2.6582 | Actual Loss: 0.1588\n",
      "Baseline Loss: 2.6654 | Actual Loss: 0.2284\n",
      "Baseline Loss: 2.6736 | Actual Loss: 0.2416\n",
      "Baseline Loss: 2.6868 | Actual Loss: 0.2436\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.2465\n",
      "Baseline Loss: 2.6468 | Actual Loss: 0.2718\n",
      "Baseline Loss: 2.6878 | Actual Loss: 0.3516\n",
      "Baseline Loss: 2.6294 | Actual Loss: 0.2150\n",
      "Baseline Loss: 2.6887 | Actual Loss: 0.3268\n",
      "Baseline Loss: 2.7039 | Actual Loss: 0.3063\n",
      "Baseline Loss: 2.6838 | Actual Loss: 0.2930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 131/1000 [00:41<04:34,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7025 | Actual Loss: 0.2312\n",
      "Baseline Loss: 2.6969 | Actual Loss: 0.3725\n",
      "Baseline Loss: 2.6535 | Actual Loss: 0.1893\n",
      "Baseline Loss: 2.3117 | Actual Loss: 0.2338\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4976\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3586\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3858\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2097\n",
      "Epoch 131/1000: Train Loss: 0.2550, Val Loss: 0.3629\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.2428\n",
      "Baseline Loss: 2.6685 | Actual Loss: 0.1626\n",
      "Baseline Loss: 2.6700 | Actual Loss: 0.1473\n",
      "Baseline Loss: 2.6912 | Actual Loss: 0.1015\n",
      "Baseline Loss: 2.6565 | Actual Loss: 0.2712\n",
      "Baseline Loss: 2.6603 | Actual Loss: 0.2520\n",
      "Baseline Loss: 2.6673 | Actual Loss: 0.2140\n",
      "Baseline Loss: 2.6730 | Actual Loss: 0.1029\n",
      "Baseline Loss: 2.6618 | Actual Loss: 0.2707\n",
      "Baseline Loss: 2.6696 | Actual Loss: 0.5026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 132/1000 [00:41<04:19,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6200 | Actual Loss: 0.4161\n",
      "Baseline Loss: 2.6508 | Actual Loss: 0.0855\n",
      "Baseline Loss: 2.6658 | Actual Loss: 0.2502\n",
      "Baseline Loss: 2.6980 | Actual Loss: 0.2071\n",
      "Baseline Loss: 2.6584 | Actual Loss: 0.5463\n",
      "Baseline Loss: 2.2563 | Actual Loss: 0.1954\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4443\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3120\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4340\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2817\n",
      "Epoch 132/1000: Train Loss: 0.2480, Val Loss: 0.3680\n",
      "Baseline Loss: 2.6615 | Actual Loss: 0.1401\n",
      "Baseline Loss: 2.6480 | Actual Loss: 0.2075\n",
      "Baseline Loss: 2.7107 | Actual Loss: 0.3325\n",
      "Baseline Loss: 2.6803 | Actual Loss: 0.2458\n",
      "Baseline Loss: 2.6893 | Actual Loss: 0.1940\n",
      "Baseline Loss: 2.6811 | Actual Loss: 0.5001\n",
      "Baseline Loss: 2.6941 | Actual Loss: 0.2608\n",
      "Baseline Loss: 2.6774 | Actual Loss: 0.1992\n",
      "Baseline Loss: 2.6656 | Actual Loss: 0.1804\n",
      "Baseline Loss: 2.6296 | Actual Loss: 0.0956\n",
      "Baseline Loss: 2.6678 | Actual Loss: 0.2539\n",
      "Baseline Loss: 2.6680 | Actual Loss: 0.3791\n",
      "Baseline Loss: 2.6574 | Actual Loss: 0.2747\n",
      "Baseline Loss: 2.6968 | Actual Loss: 0.2044\n",
      "Baseline Loss: 2.6417 | Actual Loss: 0.3270\n",
      "Baseline Loss: 2.2782 | Actual Loss: 0.1218\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4550\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 133/1000 [00:41<04:33,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6861 | Actual Loss: 0.4302\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2511\n",
      "Epoch 133/1000: Train Loss: 0.2448, Val Loss: 0.3722\n",
      "Baseline Loss: 2.6748 | Actual Loss: 0.2777\n",
      "Baseline Loss: 2.6457 | Actual Loss: 0.1992\n",
      "Baseline Loss: 2.7235 | Actual Loss: 0.3196\n",
      "Baseline Loss: 2.6773 | Actual Loss: 0.2339\n",
      "Baseline Loss: 2.6467 | Actual Loss: 0.4969\n",
      "Baseline Loss: 2.6531 | Actual Loss: 0.2792\n",
      "Baseline Loss: 2.6520 | Actual Loss: 0.2140\n",
      "Baseline Loss: 2.7061 | Actual Loss: 0.1940\n",
      "Baseline Loss: 2.7077 | Actual Loss: 0.3039\n",
      "Baseline Loss: 2.7007 | Actual Loss: 0.2566\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.2140\n",
      "Baseline Loss: 2.6698 | Actual Loss: 0.1786\n",
      "Baseline Loss: 2.6715 | Actual Loss: 0.1617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 134/1000 [00:42<04:38,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6569 | Actual Loss: 0.2187\n",
      "Baseline Loss: 2.6871 | Actual Loss: 0.2634\n",
      "Baseline Loss: 2.2862 | Actual Loss: 0.3136\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4251\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3916\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4236\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2365\n",
      "Epoch 134/1000: Train Loss: 0.2578, Val Loss: 0.3692\n",
      "Baseline Loss: 2.6665 | Actual Loss: 0.1750\n",
      "Baseline Loss: 2.6664 | Actual Loss: 0.1884\n",
      "Baseline Loss: 2.6590 | Actual Loss: 0.4184\n",
      "Baseline Loss: 2.6354 | Actual Loss: 0.2556\n",
      "Baseline Loss: 2.6867 | Actual Loss: 0.1860\n",
      "Baseline Loss: 2.6804 | Actual Loss: 0.2087\n",
      "Baseline Loss: 2.7066 | Actual Loss: 0.1997\n",
      "Baseline Loss: 2.6698 | Actual Loss: 0.1848\n",
      "Baseline Loss: 2.6859 | Actual Loss: 0.3148\n",
      "Baseline Loss: 2.6688 | Actual Loss: 0.3026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▎        | 135/1000 [00:42<04:27,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6838 | Actual Loss: 0.1609\n",
      "Baseline Loss: 2.6595 | Actual Loss: 0.3065\n",
      "Baseline Loss: 2.7048 | Actual Loss: 0.2185\n",
      "Baseline Loss: 2.7076 | Actual Loss: 0.2171\n",
      "Baseline Loss: 2.6240 | Actual Loss: 0.2521\n",
      "Baseline Loss: 2.3366 | Actual Loss: 0.1886\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4237\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3719\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4042\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2399\n",
      "Epoch 135/1000: Train Loss: 0.2361, Val Loss: 0.3599\n",
      "Baseline Loss: 2.6750 | Actual Loss: 0.2013\n",
      "Baseline Loss: 2.6684 | Actual Loss: 0.2276\n",
      "Baseline Loss: 2.6658 | Actual Loss: 0.3024\n",
      "Baseline Loss: 2.6882 | Actual Loss: 0.2610\n",
      "Baseline Loss: 2.7071 | Actual Loss: 0.2303\n",
      "Baseline Loss: 2.6852 | Actual Loss: 0.4653\n",
      "Baseline Loss: 2.6210 | Actual Loss: 0.1914\n",
      "Baseline Loss: 2.6821 | Actual Loss: 0.1994\n",
      "Baseline Loss: 2.6346 | Actual Loss: 0.2639\n",
      "Baseline Loss: 2.6662 | Actual Loss: 0.1829\n",
      "Baseline Loss: 2.6998 | Actual Loss: 0.1634\n",
      "Baseline Loss: 2.6160 | Actual Loss: 0.3939\n",
      "Baseline Loss: 2.6941 | Actual Loss: 0.2547\n",
      "Baseline Loss: 2.6690 | Actual Loss: 0.1973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▎        | 136/1000 [00:42<04:37,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7153 | Actual Loss: 0.2062\n",
      "Baseline Loss: 2.2951 | Actual Loss: 0.1168\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4954\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3720\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4238\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2513\n",
      "Epoch 136/1000: Train Loss: 0.2411, Val Loss: 0.3856\n",
      "Baseline Loss: 2.6623 | Actual Loss: 0.3216\n",
      "Baseline Loss: 2.7013 | Actual Loss: 0.1966\n",
      "Baseline Loss: 2.6695 | Actual Loss: 0.2061\n",
      "Baseline Loss: 2.6507 | Actual Loss: 0.1252\n",
      "Baseline Loss: 2.6463 | Actual Loss: 0.2125\n",
      "Baseline Loss: 2.6802 | Actual Loss: 0.1913\n",
      "Baseline Loss: 2.6876 | Actual Loss: 0.4438\n",
      "Baseline Loss: 2.6876 | Actual Loss: 0.2092\n",
      "Baseline Loss: 2.6603 | Actual Loss: 0.1865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▎        | 137/1000 [00:43<04:25,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6998 | Actual Loss: 0.2915\n",
      "Baseline Loss: 2.6849 | Actual Loss: 0.2682\n",
      "Baseline Loss: 2.6896 | Actual Loss: 0.3941\n",
      "Baseline Loss: 2.6904 | Actual Loss: 0.1760\n",
      "Baseline Loss: 2.6603 | Actual Loss: 0.2406\n",
      "Baseline Loss: 2.6663 | Actual Loss: 0.2865\n",
      "Baseline Loss: 2.2332 | Actual Loss: 0.1557\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.3830\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3369\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3912\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.3144\n",
      "Epoch 137/1000: Train Loss: 0.2441, Val Loss: 0.3564\n",
      "Baseline Loss: 2.6771 | Actual Loss: 0.3755\n",
      "Baseline Loss: 2.6603 | Actual Loss: 0.1977\n",
      "Baseline Loss: 2.6798 | Actual Loss: 0.2758\n",
      "Baseline Loss: 2.6868 | Actual Loss: 0.1993\n",
      "Baseline Loss: 2.6821 | Actual Loss: 0.2337\n",
      "Baseline Loss: 2.6605 | Actual Loss: 0.2884\n",
      "Baseline Loss: 2.7109 | Actual Loss: 0.1548\n",
      "Baseline Loss: 2.6717 | Actual Loss: 0.3113\n",
      "Baseline Loss: 2.6679 | Actual Loss: 0.1641\n",
      "Baseline Loss: 2.6996 | Actual Loss: 0.3538\n",
      "Baseline Loss: 2.6408 | Actual Loss: 0.3419\n",
      "Baseline Loss: 2.6835 | Actual Loss: 0.3088\n",
      "Baseline Loss: 2.6412 | Actual Loss: 0.2124\n",
      "Baseline Loss: 2.6958 | Actual Loss: 0.1722\n",
      "Baseline Loss: 2.6658 | Actual Loss: 0.2181\n",
      "Baseline Loss: 2.2728 | Actual Loss: 0.1938\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4219\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.2727\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4359\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2903\n",
      "Epoch 138/1000: Train Loss: 0.2501, Val Loss: 0.3552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 138/1000 [00:43<04:34,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7079 | Actual Loss: 0.1870\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.2611\n",
      "Baseline Loss: 2.6635 | Actual Loss: 0.2519\n",
      "Baseline Loss: 2.6868 | Actual Loss: 0.3893\n",
      "Baseline Loss: 2.6978 | Actual Loss: 0.2483\n",
      "Baseline Loss: 2.6885 | Actual Loss: 0.2311\n",
      "Baseline Loss: 2.6776 | Actual Loss: 0.1529\n",
      "Baseline Loss: 2.6423 | Actual Loss: 0.1528\n",
      "Baseline Loss: 2.6722 | Actual Loss: 0.3440\n",
      "Baseline Loss: 2.6673 | Actual Loss: 0.1618\n",
      "Baseline Loss: 2.6733 | Actual Loss: 0.1939\n",
      "Baseline Loss: 2.6793 | Actual Loss: 0.2589\n",
      "Baseline Loss: 2.6842 | Actual Loss: 0.1903\n",
      "Baseline Loss: 2.6670 | Actual Loss: 0.2474\n",
      "Baseline Loss: 2.6673 | Actual Loss: 0.1018\n",
      "Baseline Loss: 2.2785 | Actual Loss: 0.2578\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 139/1000 [00:43<04:34,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6474 | Actual Loss: 0.3768\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4039\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2248\n",
      "Epoch 139/1000: Train Loss: 0.2269, Val Loss: 0.3566\n",
      "Baseline Loss: 2.6752 | Actual Loss: 0.3056\n",
      "Baseline Loss: 2.6311 | Actual Loss: 0.1670\n",
      "Baseline Loss: 2.6692 | Actual Loss: 0.2001\n",
      "Baseline Loss: 2.6827 | Actual Loss: 0.1671\n",
      "Baseline Loss: 2.6569 | Actual Loss: 0.2511\n",
      "Baseline Loss: 2.6859 | Actual Loss: 0.2139\n",
      "Baseline Loss: 2.6621 | Actual Loss: 0.3002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 140/1000 [00:43<04:25,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7097 | Actual Loss: 0.3281\n",
      "Baseline Loss: 2.6372 | Actual Loss: 0.2406\n",
      "Baseline Loss: 2.6981 | Actual Loss: 0.3727\n",
      "Baseline Loss: 2.6824 | Actual Loss: 0.1535\n",
      "Baseline Loss: 2.6877 | Actual Loss: 0.2704\n",
      "Baseline Loss: 2.6789 | Actual Loss: 0.2395\n",
      "Baseline Loss: 2.6610 | Actual Loss: 0.4570\n",
      "Baseline Loss: 2.6734 | Actual Loss: 0.1750\n",
      "Baseline Loss: 2.2859 | Actual Loss: 0.1636\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4282\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.2669\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4066\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2208\n",
      "Epoch 140/1000: Train Loss: 0.2503, Val Loss: 0.3306\n",
      "New best validation loss: 0.3306\n",
      "Baseline Loss: 2.6282 | Actual Loss: 0.3407\n",
      "Baseline Loss: 2.6721 | Actual Loss: 0.2524\n",
      "Baseline Loss: 2.7090 | Actual Loss: 0.1536\n",
      "Baseline Loss: 2.6715 | Actual Loss: 0.1614\n",
      "Baseline Loss: 2.6536 | Actual Loss: 0.3368\n",
      "Baseline Loss: 2.6897 | Actual Loss: 0.3384\n",
      "Baseline Loss: 2.6772 | Actual Loss: 0.3005\n",
      "Baseline Loss: 2.6880 | Actual Loss: 0.2720\n",
      "Baseline Loss: 2.6865 | Actual Loss: 0.2225\n",
      "Baseline Loss: 2.6598 | Actual Loss: 0.2023\n",
      "Baseline Loss: 2.6945 | Actual Loss: 0.2225\n",
      "Baseline Loss: 2.7205 | Actual Loss: 0.3582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 141/1000 [00:44<04:31,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6999 | Actual Loss: 0.1837\n",
      "Baseline Loss: 2.6618 | Actual Loss: 0.1410\n",
      "Baseline Loss: 2.6491 | Actual Loss: 0.1550\n",
      "Baseline Loss: 2.2888 | Actual Loss: 0.0988\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4491\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3537\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4031\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2230\n",
      "Epoch 141/1000: Train Loss: 0.2337, Val Loss: 0.3572\n",
      "Baseline Loss: 2.6645 | Actual Loss: 0.2728\n",
      "Baseline Loss: 2.6425 | Actual Loss: 0.1747\n",
      "Baseline Loss: 2.7013 | Actual Loss: 0.2431\n",
      "Baseline Loss: 2.6321 | Actual Loss: 0.2668\n",
      "Baseline Loss: 2.6871 | Actual Loss: 0.3258\n",
      "Baseline Loss: 2.7065 | Actual Loss: 0.3414\n",
      "Baseline Loss: 2.6775 | Actual Loss: 0.2228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 142/1000 [00:44<04:19,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6984 | Actual Loss: 0.2341\n",
      "Baseline Loss: 2.6591 | Actual Loss: 0.3006\n",
      "Baseline Loss: 2.6913 | Actual Loss: 0.2538\n",
      "Baseline Loss: 2.6494 | Actual Loss: 0.3280\n",
      "Baseline Loss: 2.6783 | Actual Loss: 0.2437\n",
      "Baseline Loss: 2.6782 | Actual Loss: 0.4803\n",
      "Baseline Loss: 2.6688 | Actual Loss: 0.2463\n",
      "Baseline Loss: 2.7239 | Actual Loss: 0.4317\n",
      "Baseline Loss: 2.2803 | Actual Loss: 0.1020\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4042\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3292\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3601\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.3012\n",
      "Epoch 142/1000: Train Loss: 0.2792, Val Loss: 0.3487\n",
      "Baseline Loss: 2.6563 | Actual Loss: 0.1953\n",
      "Baseline Loss: 2.6951 | Actual Loss: 0.2941\n",
      "Baseline Loss: 2.6813 | Actual Loss: 0.1965\n",
      "Baseline Loss: 2.6762 | Actual Loss: 0.2055\n",
      "Baseline Loss: 2.6464 | Actual Loss: 0.1881\n",
      "Baseline Loss: 2.6808 | Actual Loss: 0.3162\n",
      "Baseline Loss: 2.6701 | Actual Loss: 0.1916\n",
      "Baseline Loss: 2.6882 | Actual Loss: 0.1341\n",
      "Baseline Loss: 2.6805 | Actual Loss: 0.2605\n",
      "Baseline Loss: 2.6884 | Actual Loss: 0.2578\n",
      "Baseline Loss: 2.6429 | Actual Loss: 0.2515\n",
      "Baseline Loss: 2.6731 | Actual Loss: 0.2234\n",
      "Baseline Loss: 2.7101 | Actual Loss: 0.2806\n",
      "Baseline Loss: 2.6655 | Actual Loss: 0.2048\n",
      "Baseline Loss: 2.6608 | Actual Loss: 0.1631\n",
      "Baseline Loss: 2.2507 | Actual Loss: 0.6311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 143/1000 [00:44<04:31,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6853 | Actual Loss: 0.5579\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3274\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3622\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2767\n",
      "Epoch 143/1000: Train Loss: 0.2496, Val Loss: 0.3810\n",
      "Baseline Loss: 2.6742 | Actual Loss: 0.2172\n",
      "Baseline Loss: 2.6142 | Actual Loss: 0.2881\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.1472\n",
      "Baseline Loss: 2.6786 | Actual Loss: 0.2135\n",
      "Baseline Loss: 2.6999 | Actual Loss: 0.1904\n",
      "Baseline Loss: 2.6812 | Actual Loss: 0.2238\n",
      "Baseline Loss: 2.6835 | Actual Loss: 0.2452\n",
      "Baseline Loss: 2.6944 | Actual Loss: 0.3669\n",
      "Baseline Loss: 2.6909 | Actual Loss: 0.3684\n",
      "Baseline Loss: 2.6751 | Actual Loss: 0.2095\n",
      "Baseline Loss: 2.6392 | Actual Loss: 0.1230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 144/1000 [00:45<04:37,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6918 | Actual Loss: 0.1949\n",
      "Baseline Loss: 2.6527 | Actual Loss: 0.2130\n",
      "Baseline Loss: 2.7016 | Actual Loss: 0.1641\n",
      "Baseline Loss: 2.6975 | Actual Loss: 0.2047\n",
      "Baseline Loss: 2.2732 | Actual Loss: 0.1152\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4204\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3542\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4301\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2945\n",
      "Epoch 144/1000: Train Loss: 0.2178, Val Loss: 0.3748\n",
      "Baseline Loss: 2.6728 | Actual Loss: 0.1521\n",
      "Baseline Loss: 2.6719 | Actual Loss: 0.4009\n",
      "Baseline Loss: 2.6665 | Actual Loss: 0.2246\n",
      "Baseline Loss: 2.6532 | Actual Loss: 0.2970\n",
      "Baseline Loss: 2.6848 | Actual Loss: 0.4102\n",
      "Baseline Loss: 2.6392 | Actual Loss: 0.2507\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2103\n",
      "Baseline Loss: 2.7332 | Actual Loss: 0.2613\n",
      "Baseline Loss: 2.7024 | Actual Loss: 0.1931\n",
      "Baseline Loss: 2.6867 | Actual Loss: 0.3083\n",
      "Baseline Loss: 2.6878 | Actual Loss: 0.1794\n",
      "Baseline Loss: 2.6643 | Actual Loss: 0.3005\n",
      "Baseline Loss: 2.6699 | Actual Loss: 0.2081\n",
      "Baseline Loss: 2.6823 | Actual Loss: 0.2169\n",
      "Baseline Loss: 2.6361 | Actual Loss: 0.3962\n",
      "Baseline Loss: 2.2686 | Actual Loss: 0.1434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 145/1000 [00:45<04:42,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6853 | Actual Loss: 0.4279\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3794\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3641\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2852\n",
      "Epoch 145/1000: Train Loss: 0.2596, Val Loss: 0.3641\n",
      "Baseline Loss: 2.6449 | Actual Loss: 0.3463\n",
      "Baseline Loss: 2.7354 | Actual Loss: 0.2193\n",
      "Baseline Loss: 2.6737 | Actual Loss: 0.0855\n",
      "Baseline Loss: 2.6344 | Actual Loss: 0.1175\n",
      "Baseline Loss: 2.6734 | Actual Loss: 0.3284\n",
      "Baseline Loss: 2.6538 | Actual Loss: 0.1826\n",
      "Baseline Loss: 2.6620 | Actual Loss: 0.2103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 146/1000 [00:45<04:24,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6885 | Actual Loss: 0.2369\n",
      "Baseline Loss: 2.6441 | Actual Loss: 0.2101\n",
      "Baseline Loss: 2.7125 | Actual Loss: 0.2151\n",
      "Baseline Loss: 2.6670 | Actual Loss: 0.2210\n",
      "Baseline Loss: 2.6941 | Actual Loss: 0.2306\n",
      "Baseline Loss: 2.7327 | Actual Loss: 0.2882\n",
      "Baseline Loss: 2.6800 | Actual Loss: 0.3924\n",
      "Baseline Loss: 2.6541 | Actual Loss: 0.2735\n",
      "Baseline Loss: 2.3068 | Actual Loss: 0.1847\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4135\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3501\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3681\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2680\n",
      "Epoch 146/1000: Train Loss: 0.2339, Val Loss: 0.3499\n",
      "Baseline Loss: 2.6407 | Actual Loss: 0.2294\n",
      "Baseline Loss: 2.6587 | Actual Loss: 0.1566\n",
      "Baseline Loss: 2.6658 | Actual Loss: 0.2582\n",
      "Baseline Loss: 2.6878 | Actual Loss: 0.1684\n",
      "Baseline Loss: 2.6607 | Actual Loss: 0.2286\n",
      "Baseline Loss: 2.7163 | Actual Loss: 0.2022\n",
      "Baseline Loss: 2.6829 | Actual Loss: 0.1778\n",
      "Baseline Loss: 2.7162 | Actual Loss: 0.2335\n",
      "Baseline Loss: 2.6787 | Actual Loss: 0.1480\n",
      "Baseline Loss: 2.6348 | Actual Loss: 0.2642\n",
      "Baseline Loss: 2.6421 | Actual Loss: 0.1923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 147/1000 [00:46<04:31,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7072 | Actual Loss: 0.2420\n",
      "Baseline Loss: 2.7101 | Actual Loss: 0.3650\n",
      "Baseline Loss: 2.7129 | Actual Loss: 0.2623\n",
      "Baseline Loss: 2.6504 | Actual Loss: 0.1721\n",
      "Baseline Loss: 2.2297 | Actual Loss: 0.1057\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4522\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3521\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4121\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2837\n",
      "Epoch 147/1000: Train Loss: 0.2129, Val Loss: 0.3750\n",
      "Baseline Loss: 2.6642 | Actual Loss: 0.2427\n",
      "Baseline Loss: 2.6598 | Actual Loss: 0.3281\n",
      "Baseline Loss: 2.6787 | Actual Loss: 0.1968\n",
      "Baseline Loss: 2.6854 | Actual Loss: 0.3821\n",
      "Baseline Loss: 2.6469 | Actual Loss: 0.2170\n",
      "Baseline Loss: 2.6335 | Actual Loss: 0.3224\n",
      "Baseline Loss: 2.6725 | Actual Loss: 0.3099\n",
      "Baseline Loss: 2.6709 | Actual Loss: 0.4503\n",
      "Baseline Loss: 2.6674 | Actual Loss: 0.2556\n",
      "Baseline Loss: 2.6533 | Actual Loss: 0.1904\n",
      "Baseline Loss: 2.6997 | Actual Loss: 0.2825\n",
      "Baseline Loss: 2.7314 | Actual Loss: 0.2109\n",
      "Baseline Loss: 2.7104 | Actual Loss: 0.1144\n",
      "Baseline Loss: 2.6757 | Actual Loss: 0.2054\n",
      "Baseline Loss: 2.6648 | Actual Loss: 0.2683\n",
      "Baseline Loss: 2.2673 | Actual Loss: 0.1345\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5753\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 148/1000 [00:46<04:33,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6861 | Actual Loss: 0.4116\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2518\n",
      "Epoch 148/1000: Train Loss: 0.2570, Val Loss: 0.3882\n",
      "Baseline Loss: 2.6599 | Actual Loss: 0.2480\n",
      "Baseline Loss: 2.6476 | Actual Loss: 0.2971\n",
      "Baseline Loss: 2.6616 | Actual Loss: 0.1525\n",
      "Baseline Loss: 2.6191 | Actual Loss: 0.1737\n",
      "Baseline Loss: 2.6563 | Actual Loss: 0.2324\n",
      "Baseline Loss: 2.7091 | Actual Loss: 0.2708\n",
      "Baseline Loss: 2.6773 | Actual Loss: 0.2344\n",
      "Baseline Loss: 2.7173 | Actual Loss: 0.1675\n",
      "Baseline Loss: 2.6974 | Actual Loss: 0.2514\n",
      "Baseline Loss: 2.6522 | Actual Loss: 0.3238\n",
      "Baseline Loss: 2.7173 | Actual Loss: 0.1698\n",
      "Baseline Loss: 2.6588 | Actual Loss: 0.1778\n",
      "Baseline Loss: 2.6674 | Actual Loss: 0.3782\n",
      "Baseline Loss: 2.7153 | Actual Loss: 0.2455\n",
      "Baseline Loss: 2.6860 | Actual Loss: 0.2526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 149/1000 [00:46<04:16,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2372 | Actual Loss: 0.0845\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5241\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3764\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4398\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.3193\n",
      "Epoch 149/1000: Train Loss: 0.2288, Val Loss: 0.4149\n",
      "Baseline Loss: 2.6811 | Actual Loss: 0.1871\n",
      "Baseline Loss: 2.6963 | Actual Loss: 0.1643\n",
      "Baseline Loss: 2.6624 | Actual Loss: 0.2746\n",
      "Baseline Loss: 2.7011 | Actual Loss: 0.2498\n",
      "Baseline Loss: 2.6612 | Actual Loss: 0.2331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 150/1000 [00:47<04:26,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6308 | Actual Loss: 0.2120\n",
      "Baseline Loss: 2.6503 | Actual Loss: 0.1541\n",
      "Baseline Loss: 2.6943 | Actual Loss: 0.2137\n",
      "Baseline Loss: 2.6887 | Actual Loss: 0.1756\n",
      "Baseline Loss: 2.6690 | Actual Loss: 0.2642\n",
      "Baseline Loss: 2.6841 | Actual Loss: 0.8447\n",
      "Baseline Loss: 2.6475 | Actual Loss: 0.2259\n",
      "Baseline Loss: 2.6953 | Actual Loss: 0.3429\n",
      "Baseline Loss: 2.6906 | Actual Loss: 0.1095\n",
      "Baseline Loss: 2.6466 | Actual Loss: 0.1333\n",
      "Baseline Loss: 2.2691 | Actual Loss: 0.0949\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4403\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.2854\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3637\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2739\n",
      "Epoch 150/1000: Train Loss: 0.2425, Val Loss: 0.3408\n",
      "Baseline Loss: 2.6778 | Actual Loss: 0.2266\n",
      "Baseline Loss: 2.6633 | Actual Loss: 0.1787\n",
      "Baseline Loss: 2.6630 | Actual Loss: 0.2813\n",
      "Baseline Loss: 2.6679 | Actual Loss: 0.2178\n",
      "Baseline Loss: 2.6769 | Actual Loss: 0.3284\n",
      "Baseline Loss: 2.6940 | Actual Loss: 0.2507\n",
      "Baseline Loss: 2.6581 | Actual Loss: 0.2556\n",
      "Baseline Loss: 2.6841 | Actual Loss: 0.4422\n",
      "Baseline Loss: 2.6622 | Actual Loss: 0.1980\n",
      "Baseline Loss: 2.6489 | Actual Loss: 0.1875\n",
      "Baseline Loss: 2.6528 | Actual Loss: 0.2525\n",
      "Baseline Loss: 2.7102 | Actual Loss: 0.1916\n",
      "Baseline Loss: 2.6614 | Actual Loss: 0.2248\n",
      "Baseline Loss: 2.6821 | Actual Loss: 0.2362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 151/1000 [00:47<04:28,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6427 | Actual Loss: 0.2382\n",
      "Baseline Loss: 2.3146 | Actual Loss: 0.5230\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5024\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3222\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4399\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2362\n",
      "Epoch 151/1000: Train Loss: 0.2646, Val Loss: 0.3752\n",
      "Baseline Loss: 2.6830 | Actual Loss: 0.2504\n",
      "Baseline Loss: 2.7082 | Actual Loss: 0.1979\n",
      "Baseline Loss: 2.7157 | Actual Loss: 0.2351\n",
      "Baseline Loss: 2.6900 | Actual Loss: 0.2422\n",
      "Baseline Loss: 2.6498 | Actual Loss: 0.2005\n",
      "Baseline Loss: 2.6581 | Actual Loss: 0.2560\n",
      "Baseline Loss: 2.6766 | Actual Loss: 0.5532\n",
      "Baseline Loss: 2.6781 | Actual Loss: 0.1551\n",
      "Baseline Loss: 2.6568 | Actual Loss: 0.2954\n",
      "Baseline Loss: 2.6802 | Actual Loss: 0.2841\n",
      "Baseline Loss: 2.6689 | Actual Loss: 0.2154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 152/1000 [00:47<04:13,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6655 | Actual Loss: 0.2627\n",
      "Baseline Loss: 2.6845 | Actual Loss: 0.1711\n",
      "Baseline Loss: 2.6705 | Actual Loss: 0.1484\n",
      "Baseline Loss: 2.6687 | Actual Loss: 0.1755\n",
      "Baseline Loss: 2.2705 | Actual Loss: 0.0764\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4497\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4134\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4326\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2258\n",
      "Epoch 152/1000: Train Loss: 0.2325, Val Loss: 0.3804\n",
      "Baseline Loss: 2.6748 | Actual Loss: 0.3165\n",
      "Baseline Loss: 2.6433 | Actual Loss: 0.2853\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.1951\n",
      "Baseline Loss: 2.6715 | Actual Loss: 0.1495\n",
      "Baseline Loss: 2.6789 | Actual Loss: 0.2063\n",
      "Baseline Loss: 2.6493 | Actual Loss: 0.2873\n",
      "Baseline Loss: 2.6830 | Actual Loss: 0.3426\n",
      "Baseline Loss: 2.6761 | Actual Loss: 0.3004\n",
      "Baseline Loss: 2.6632 | Actual Loss: 0.2413\n",
      "Baseline Loss: 2.7159 | Actual Loss: 0.2026\n",
      "Baseline Loss: 2.6898 | Actual Loss: 0.2677\n",
      "Baseline Loss: 2.6420 | Actual Loss: 0.3802\n",
      "Baseline Loss: 2.6177 | Actual Loss: 0.2547\n",
      "Baseline Loss: 2.6854 | Actual Loss: 0.2775\n",
      "Baseline Loss: 2.6460 | Actual Loss: 0.3099\n",
      "Baseline Loss: 2.3461 | Actual Loss: 0.1305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 153/1000 [00:48<04:19,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6853 | Actual Loss: 0.5283\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3456\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3957\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2471\n",
      "Epoch 153/1000: Train Loss: 0.2592, Val Loss: 0.3792\n",
      "Baseline Loss: 2.6591 | Actual Loss: 0.1625\n",
      "Baseline Loss: 2.6660 | Actual Loss: 0.2568\n",
      "Baseline Loss: 2.7109 | Actual Loss: 0.3368\n",
      "Baseline Loss: 2.6382 | Actual Loss: 0.2243\n",
      "Baseline Loss: 2.6960 | Actual Loss: 0.2710\n",
      "Baseline Loss: 2.6787 | Actual Loss: 0.2825\n",
      "Baseline Loss: 2.6628 | Actual Loss: 0.1908\n",
      "Baseline Loss: 2.6413 | Actual Loss: 0.2121\n",
      "Baseline Loss: 2.6829 | Actual Loss: 0.2548\n",
      "Baseline Loss: 2.7427 | Actual Loss: 0.2310\n",
      "Baseline Loss: 2.6539 | Actual Loss: 0.2114\n",
      "Baseline Loss: 2.7083 | Actual Loss: 0.2491\n",
      "Baseline Loss: 2.6560 | Actual Loss: 0.1827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 154/1000 [00:48<04:09,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7009 | Actual Loss: 0.1665\n",
      "Baseline Loss: 2.6745 | Actual Loss: 0.4004\n",
      "Baseline Loss: 2.2129 | Actual Loss: 0.2301\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5363\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4057\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3876\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2583\n",
      "Epoch 154/1000: Train Loss: 0.2414, Val Loss: 0.3970\n",
      "Baseline Loss: 2.7420 | Actual Loss: 0.3009\n",
      "Baseline Loss: 2.6478 | Actual Loss: 0.1825\n",
      "Baseline Loss: 2.6385 | Actual Loss: 0.2741\n",
      "Baseline Loss: 2.6725 | Actual Loss: 0.2688\n",
      "Baseline Loss: 2.6896 | Actual Loss: 0.1954\n",
      "Baseline Loss: 2.6569 | Actual Loss: 0.2262\n",
      "Baseline Loss: 2.6688 | Actual Loss: 0.1381\n",
      "Baseline Loss: 2.7293 | Actual Loss: 0.2774\n",
      "Baseline Loss: 2.6871 | Actual Loss: 0.2006\n",
      "Baseline Loss: 2.6707 | Actual Loss: 0.3196\n",
      "Baseline Loss: 2.6494 | Actual Loss: 0.2612\n",
      "Baseline Loss: 2.6979 | Actual Loss: 0.2160\n",
      "Baseline Loss: 2.6448 | Actual Loss: 0.5589\n",
      "Baseline Loss: 2.6734 | Actual Loss: 0.2063\n",
      "Baseline Loss: 2.6438 | Actual Loss: 0.4838\n",
      "Baseline Loss: 2.2467 | Actual Loss: 0.1288\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4959\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 155/1000 [00:48<04:23,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6861 | Actual Loss: 0.4084\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2544\n",
      "Epoch 155/1000: Train Loss: 0.2649, Val Loss: 0.3679\n",
      "Baseline Loss: 2.6724 | Actual Loss: 0.3248\n",
      "Baseline Loss: 2.6299 | Actual Loss: 0.2234\n",
      "Baseline Loss: 2.6520 | Actual Loss: 0.3014\n",
      "Baseline Loss: 2.6839 | Actual Loss: 0.2416\n",
      "Baseline Loss: 2.6643 | Actual Loss: 0.2979\n",
      "Baseline Loss: 2.6729 | Actual Loss: 0.2519\n",
      "Baseline Loss: 2.7043 | Actual Loss: 0.1658\n",
      "Baseline Loss: 2.7186 | Actual Loss: 0.2123\n",
      "Baseline Loss: 2.6776 | Actual Loss: 0.1665\n",
      "Baseline Loss: 2.6724 | Actual Loss: 0.2040\n",
      "Baseline Loss: 2.7160 | Actual Loss: 0.2174\n",
      "Baseline Loss: 2.6967 | Actual Loss: 0.1192\n",
      "Baseline Loss: 2.6565 | Actual Loss: 0.3250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 156/1000 [00:48<04:14,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6924 | Actual Loss: 0.1991\n",
      "Baseline Loss: 2.6830 | Actual Loss: 0.5246\n",
      "Baseline Loss: 2.2684 | Actual Loss: 0.1384\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5049\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3072\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3813\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2513\n",
      "Epoch 156/1000: Train Loss: 0.2446, Val Loss: 0.3612\n",
      "Baseline Loss: 2.6751 | Actual Loss: 0.1610\n",
      "Baseline Loss: 2.6710 | Actual Loss: 0.3358\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.2109\n",
      "Baseline Loss: 2.6495 | Actual Loss: 0.2203\n",
      "Baseline Loss: 2.7420 | Actual Loss: 0.3065\n",
      "Baseline Loss: 2.6586 | Actual Loss: 0.3413\n",
      "Baseline Loss: 2.6436 | Actual Loss: 0.1890\n",
      "Baseline Loss: 2.6635 | Actual Loss: 0.2449\n",
      "Baseline Loss: 2.6682 | Actual Loss: 0.3144\n",
      "Baseline Loss: 2.6461 | Actual Loss: 0.1643\n",
      "Baseline Loss: 2.6487 | Actual Loss: 0.2580\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2247\n",
      "Baseline Loss: 2.6539 | Actual Loss: 0.2143\n",
      "Baseline Loss: 2.6965 | Actual Loss: 0.1682\n",
      "Baseline Loss: 2.6656 | Actual Loss: 0.1866\n",
      "Baseline Loss: 2.2871 | Actual Loss: 0.1090\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.3686\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 157/1000 [00:49<04:27,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6861 | Actual Loss: 0.4133\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.1895\n",
      "Epoch 157/1000: Train Loss: 0.2281, Val Loss: 0.3480\n",
      "Baseline Loss: 2.6615 | Actual Loss: 0.2735\n",
      "Baseline Loss: 2.6825 | Actual Loss: 0.1568\n",
      "Baseline Loss: 2.6699 | Actual Loss: 0.2328\n",
      "Baseline Loss: 2.6556 | Actual Loss: 0.3251\n",
      "Baseline Loss: 2.6580 | Actual Loss: 0.2512\n",
      "Baseline Loss: 2.6561 | Actual Loss: 0.2978\n",
      "Baseline Loss: 2.6705 | Actual Loss: 0.2564\n",
      "Baseline Loss: 2.6668 | Actual Loss: 0.3208\n",
      "Baseline Loss: 2.7009 | Actual Loss: 0.2316\n",
      "Baseline Loss: 2.7053 | Actual Loss: 0.3439\n",
      "Baseline Loss: 2.7125 | Actual Loss: 0.2213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 158/1000 [00:49<04:38,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6781 | Actual Loss: 0.3288\n",
      "Baseline Loss: 2.6244 | Actual Loss: 0.1885\n",
      "Baseline Loss: 2.6447 | Actual Loss: 0.3114\n",
      "Baseline Loss: 2.6583 | Actual Loss: 0.1450\n",
      "Baseline Loss: 2.3611 | Actual Loss: 0.1412\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5296\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4199\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3943\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.1879\n",
      "Epoch 158/1000: Train Loss: 0.2516, Val Loss: 0.3829\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.2705\n",
      "Baseline Loss: 2.6647 | Actual Loss: 0.1767\n",
      "Baseline Loss: 2.6479 | Actual Loss: 0.1228\n",
      "Baseline Loss: 2.6304 | Actual Loss: 0.2490\n",
      "Baseline Loss: 2.6927 | Actual Loss: 0.2808\n",
      "Baseline Loss: 2.6699 | Actual Loss: 0.2603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 159/1000 [00:49<04:23,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7126 | Actual Loss: 0.1936\n",
      "Baseline Loss: 2.6443 | Actual Loss: 0.2218\n",
      "Baseline Loss: 2.6581 | Actual Loss: 0.1989\n",
      "Baseline Loss: 2.6581 | Actual Loss: 0.2418\n",
      "Baseline Loss: 2.6905 | Actual Loss: 0.5819\n",
      "Baseline Loss: 2.6659 | Actual Loss: 0.2455\n",
      "Baseline Loss: 2.7127 | Actual Loss: 0.2325\n",
      "Baseline Loss: 2.7094 | Actual Loss: 0.2723\n",
      "Baseline Loss: 2.6573 | Actual Loss: 0.3147\n",
      "Baseline Loss: 2.2605 | Actual Loss: 0.3641\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.6473\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.2625\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4099\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2664\n",
      "Epoch 159/1000: Train Loss: 0.2642, Val Loss: 0.3965\n",
      "Baseline Loss: 2.6906 | Actual Loss: 0.2216\n",
      "Baseline Loss: 2.6601 | Actual Loss: 0.1917\n",
      "Baseline Loss: 2.6514 | Actual Loss: 0.3002\n",
      "Baseline Loss: 2.6326 | Actual Loss: 0.2699\n",
      "Baseline Loss: 2.6731 | Actual Loss: 0.3214\n",
      "Baseline Loss: 2.6850 | Actual Loss: 0.2278\n",
      "Baseline Loss: 2.6704 | Actual Loss: 0.1180\n",
      "Baseline Loss: 2.7084 | Actual Loss: 0.3630\n",
      "Baseline Loss: 2.6677 | Actual Loss: 0.2768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 160/1000 [00:50<04:37,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6797 | Actual Loss: 0.1881\n",
      "Baseline Loss: 2.6595 | Actual Loss: 0.3836\n",
      "Baseline Loss: 2.6909 | Actual Loss: 0.2069\n",
      "Baseline Loss: 2.6802 | Actual Loss: 0.2254\n",
      "Baseline Loss: 2.6714 | Actual Loss: 0.2027\n",
      "Baseline Loss: 2.6528 | Actual Loss: 0.2000\n",
      "Baseline Loss: 2.3107 | Actual Loss: 0.0894\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4506\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3937\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3670\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2207\n",
      "Epoch 160/1000: Train Loss: 0.2366, Val Loss: 0.3580\n",
      "Baseline Loss: 2.6631 | Actual Loss: 0.1907\n",
      "Baseline Loss: 2.6679 | Actual Loss: 0.2155\n",
      "Baseline Loss: 2.7195 | Actual Loss: 0.3195\n",
      "Baseline Loss: 2.6373 | Actual Loss: 0.2071\n",
      "Baseline Loss: 2.6654 | Actual Loss: 0.2376\n",
      "Baseline Loss: 2.6565 | Actual Loss: 0.2868\n",
      "Baseline Loss: 2.6933 | Actual Loss: 0.3325\n",
      "Baseline Loss: 2.6635 | Actual Loss: 0.2311\n",
      "Baseline Loss: 2.7066 | Actual Loss: 0.2359\n",
      "Baseline Loss: 2.6571 | Actual Loss: 0.2480\n",
      "Baseline Loss: 2.6666 | Actual Loss: 0.1966\n",
      "Baseline Loss: 2.6702 | Actual Loss: 0.2367\n",
      "Baseline Loss: 2.6942 | Actual Loss: 0.3107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 161/1000 [00:50<04:44,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6793 | Actual Loss: 0.1815\n",
      "Baseline Loss: 2.7067 | Actual Loss: 0.5627\n",
      "Baseline Loss: 2.2987 | Actual Loss: 0.1705\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4042\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3046\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3409\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.1909\n",
      "Epoch 161/1000: Train Loss: 0.2602, Val Loss: 0.3102\n",
      "New best validation loss: 0.3102\n",
      "Baseline Loss: 2.6706 | Actual Loss: 0.1995\n",
      "Baseline Loss: 2.6937 | Actual Loss: 0.1607\n",
      "Baseline Loss: 2.7261 | Actual Loss: 0.1533\n",
      "Baseline Loss: 2.7106 | Actual Loss: 0.1765\n",
      "Baseline Loss: 2.6392 | Actual Loss: 0.2106\n",
      "Baseline Loss: 2.7018 | Actual Loss: 0.3503\n",
      "Baseline Loss: 2.6742 | Actual Loss: 0.2348\n",
      "Baseline Loss: 2.6456 | Actual Loss: 0.1143\n",
      "Baseline Loss: 2.6463 | Actual Loss: 0.3280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 162/1000 [00:50<04:27,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6806 | Actual Loss: 0.1949\n",
      "Baseline Loss: 2.6538 | Actual Loss: 0.3041\n",
      "Baseline Loss: 2.7153 | Actual Loss: 0.2032\n",
      "Baseline Loss: 2.6430 | Actual Loss: 0.3552\n",
      "Baseline Loss: 2.6464 | Actual Loss: 0.2665\n",
      "Baseline Loss: 2.6685 | Actual Loss: 0.3221\n",
      "Baseline Loss: 2.3764 | Actual Loss: 0.1344\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4068\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3219\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3568\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.1611\n",
      "Epoch 162/1000: Train Loss: 0.2318, Val Loss: 0.3117\n",
      "Baseline Loss: 2.6867 | Actual Loss: 0.0853\n",
      "Baseline Loss: 2.6984 | Actual Loss: 0.3599\n",
      "Baseline Loss: 2.6530 | Actual Loss: 0.1777\n",
      "Baseline Loss: 2.7039 | Actual Loss: 0.1806\n",
      "Baseline Loss: 2.6786 | Actual Loss: 0.1448\n",
      "Baseline Loss: 2.6556 | Actual Loss: 0.3124\n",
      "Baseline Loss: 2.6794 | Actual Loss: 0.3587\n",
      "Baseline Loss: 2.6490 | Actual Loss: 0.2249\n",
      "Baseline Loss: 2.6567 | Actual Loss: 0.1997\n",
      "Baseline Loss: 2.6478 | Actual Loss: 0.1952\n",
      "Baseline Loss: 2.6558 | Actual Loss: 0.1861\n",
      "Baseline Loss: 2.6796 | Actual Loss: 0.3096\n",
      "Baseline Loss: 2.7335 | Actual Loss: 0.2797\n",
      "Baseline Loss: 2.6987 | Actual Loss: 0.2567\n",
      "Baseline Loss: 2.6563 | Actual Loss: 0.2915\n",
      "Baseline Loss: 2.3023 | Actual Loss: 0.3057\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4500\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▋        | 163/1000 [00:51<04:31,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6861 | Actual Loss: 0.3727\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2538\n",
      "Epoch 163/1000: Train Loss: 0.2418, Val Loss: 0.3558\n",
      "Baseline Loss: 2.6705 | Actual Loss: 0.2899\n",
      "Baseline Loss: 2.6902 | Actual Loss: 0.2740\n",
      "Baseline Loss: 2.6759 | Actual Loss: 0.2118\n",
      "Baseline Loss: 2.7215 | Actual Loss: 0.2740\n",
      "Baseline Loss: 2.6557 | Actual Loss: 0.2814\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3028\n",
      "Baseline Loss: 2.6382 | Actual Loss: 0.2615\n",
      "Baseline Loss: 2.6842 | Actual Loss: 0.1744\n",
      "Baseline Loss: 2.6986 | Actual Loss: 0.3677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▋        | 164/1000 [00:51<04:35,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6877 | Actual Loss: 0.2672\n",
      "Baseline Loss: 2.6499 | Actual Loss: 0.1760\n",
      "Baseline Loss: 2.7066 | Actual Loss: 0.2176\n",
      "Baseline Loss: 2.6710 | Actual Loss: 0.0912\n",
      "Baseline Loss: 2.6972 | Actual Loss: 0.2195\n",
      "Baseline Loss: 2.6959 | Actual Loss: 0.2947\n",
      "Baseline Loss: 2.3159 | Actual Loss: 0.0831\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5492\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3789\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3957\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2076\n",
      "Epoch 164/1000: Train Loss: 0.2367, Val Loss: 0.3829\n",
      "Baseline Loss: 2.6380 | Actual Loss: 0.1717\n",
      "Baseline Loss: 2.6959 | Actual Loss: 0.2583\n",
      "Baseline Loss: 2.6616 | Actual Loss: 0.2603\n",
      "Baseline Loss: 2.6260 | Actual Loss: 0.2153\n",
      "Baseline Loss: 2.6769 | Actual Loss: 0.2143\n",
      "Baseline Loss: 2.6553 | Actual Loss: 0.2218\n",
      "Baseline Loss: 2.7174 | Actual Loss: 0.1548\n",
      "Baseline Loss: 2.7119 | Actual Loss: 0.1845\n",
      "Baseline Loss: 2.6842 | Actual Loss: 0.2100\n",
      "Baseline Loss: 2.6768 | Actual Loss: 0.3290\n",
      "Baseline Loss: 2.7211 | Actual Loss: 0.2194\n",
      "Baseline Loss: 2.6549 | Actual Loss: 0.2125\n",
      "Baseline Loss: 2.6449 | Actual Loss: 0.2541\n",
      "Baseline Loss: 2.6442 | Actual Loss: 0.2461\n",
      "Baseline Loss: 2.6868 | Actual Loss: 0.3009\n",
      "Baseline Loss: 2.3044 | Actual Loss: 0.0846\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▋        | 165/1000 [00:51<04:38,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6474 | Actual Loss: 0.3961\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3905\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2270\n",
      "Epoch 165/1000: Train Loss: 0.2211, Val Loss: 0.3593\n",
      "Baseline Loss: 2.6502 | Actual Loss: 0.1980\n",
      "Baseline Loss: 2.6626 | Actual Loss: 0.1758\n",
      "Baseline Loss: 2.6680 | Actual Loss: 0.2900\n",
      "Baseline Loss: 2.7179 | Actual Loss: 0.4368\n",
      "Baseline Loss: 2.6731 | Actual Loss: 0.2663\n",
      "Baseline Loss: 2.6869 | Actual Loss: 0.1565\n",
      "Baseline Loss: 2.6842 | Actual Loss: 0.3973\n",
      "Baseline Loss: 2.6663 | Actual Loss: 0.3259\n",
      "Baseline Loss: 2.6451 | Actual Loss: 0.2346\n",
      "Baseline Loss: 2.6527 | Actual Loss: 0.1071\n",
      "Baseline Loss: 2.6653 | Actual Loss: 0.1902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 166/1000 [00:52<04:19,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6715 | Actual Loss: 0.1425\n",
      "Baseline Loss: 2.6713 | Actual Loss: 0.1163\n",
      "Baseline Loss: 2.6579 | Actual Loss: 0.3247\n",
      "Baseline Loss: 2.7275 | Actual Loss: 0.2167\n",
      "Baseline Loss: 2.3337 | Actual Loss: 0.4851\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5374\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3605\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4279\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2243\n",
      "Epoch 166/1000: Train Loss: 0.2540, Val Loss: 0.3876\n",
      "Baseline Loss: 2.6759 | Actual Loss: 0.5243\n",
      "Baseline Loss: 2.6825 | Actual Loss: 0.2760\n",
      "Baseline Loss: 2.6330 | Actual Loss: 0.2574\n",
      "Baseline Loss: 2.6634 | Actual Loss: 0.1120\n",
      "Baseline Loss: 2.6804 | Actual Loss: 0.2221\n",
      "Baseline Loss: 2.7094 | Actual Loss: 0.2206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 167/1000 [00:52<04:23,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6882 | Actual Loss: 0.1843\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.2477\n",
      "Baseline Loss: 2.6529 | Actual Loss: 0.1836\n",
      "Baseline Loss: 2.6663 | Actual Loss: 0.2018\n",
      "Baseline Loss: 2.6800 | Actual Loss: 0.1407\n",
      "Baseline Loss: 2.7117 | Actual Loss: 0.1669\n",
      "Baseline Loss: 2.6823 | Actual Loss: 0.2579\n",
      "Baseline Loss: 2.6711 | Actual Loss: 0.3616\n",
      "Baseline Loss: 2.6303 | Actual Loss: 0.2079\n",
      "Baseline Loss: 2.3517 | Actual Loss: 0.1446\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4022\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3217\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3971\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2290\n",
      "Epoch 167/1000: Train Loss: 0.2318, Val Loss: 0.3375\n",
      "Baseline Loss: 2.7096 | Actual Loss: 0.1892\n",
      "Baseline Loss: 2.7267 | Actual Loss: 0.3054\n",
      "Baseline Loss: 2.6744 | Actual Loss: 0.3141\n",
      "Baseline Loss: 2.6868 | Actual Loss: 0.2299\n",
      "Baseline Loss: 2.7037 | Actual Loss: 0.1552\n",
      "Baseline Loss: 2.6498 | Actual Loss: 0.1716\n",
      "Baseline Loss: 2.6575 | Actual Loss: 0.2746\n",
      "Baseline Loss: 2.6780 | Actual Loss: 0.1837\n",
      "Baseline Loss: 2.6835 | Actual Loss: 0.1920\n",
      "Baseline Loss: 2.6860 | Actual Loss: 0.2788\n",
      "Baseline Loss: 2.6452 | Actual Loss: 0.1412\n",
      "Baseline Loss: 2.6737 | Actual Loss: 0.3995\n",
      "Baseline Loss: 2.6508 | Actual Loss: 0.2785\n",
      "Baseline Loss: 2.6859 | Actual Loss: 0.3078\n",
      "Baseline Loss: 2.6730 | Actual Loss: 0.2190\n",
      "Baseline Loss: 2.3101 | Actual Loss: 0.2244\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4694\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 168/1000 [00:52<04:31,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6861 | Actual Loss: 0.4039\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2466\n",
      "Epoch 168/1000: Train Loss: 0.2416, Val Loss: 0.3697\n",
      "Baseline Loss: 2.6630 | Actual Loss: 0.2387\n",
      "Baseline Loss: 2.6892 | Actual Loss: 0.2266\n",
      "Baseline Loss: 2.6748 | Actual Loss: 0.2665\n",
      "Baseline Loss: 2.6979 | Actual Loss: 0.1553\n",
      "Baseline Loss: 2.6890 | Actual Loss: 0.1792\n",
      "Baseline Loss: 2.6681 | Actual Loss: 0.2045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 169/1000 [00:53<04:15,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6851 | Actual Loss: 0.3248\n",
      "Baseline Loss: 2.6334 | Actual Loss: 0.2896\n",
      "Baseline Loss: 2.6656 | Actual Loss: 0.2817\n",
      "Baseline Loss: 2.6890 | Actual Loss: 0.2401\n",
      "Baseline Loss: 2.6635 | Actual Loss: 0.2469\n",
      "Baseline Loss: 2.6502 | Actual Loss: 0.2641\n",
      "Baseline Loss: 2.6464 | Actual Loss: 0.2040\n",
      "Baseline Loss: 2.7122 | Actual Loss: 0.1888\n",
      "Baseline Loss: 2.6953 | Actual Loss: 0.2823\n",
      "Baseline Loss: 2.2363 | Actual Loss: 0.2572\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4500\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3766\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3392\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2074\n",
      "Epoch 169/1000: Train Loss: 0.2407, Val Loss: 0.3433\n",
      "Baseline Loss: 2.6815 | Actual Loss: 0.2033\n",
      "Baseline Loss: 2.6684 | Actual Loss: 0.2372\n",
      "Baseline Loss: 2.7039 | Actual Loss: 0.1624\n",
      "Baseline Loss: 2.6360 | Actual Loss: 0.2710\n",
      "Baseline Loss: 2.6775 | Actual Loss: 0.2551\n",
      "Baseline Loss: 2.7052 | Actual Loss: 0.2463\n",
      "Baseline Loss: 2.6618 | Actual Loss: 0.3591\n",
      "Baseline Loss: 2.6804 | Actual Loss: 0.1709\n",
      "Baseline Loss: 2.6773 | Actual Loss: 0.4132\n",
      "Baseline Loss: 2.7371 | Actual Loss: 0.1486\n",
      "Baseline Loss: 2.6714 | Actual Loss: 0.2065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 170/1000 [00:53<04:24,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6532 | Actual Loss: 0.2285\n",
      "Baseline Loss: 2.6773 | Actual Loss: 0.3004\n",
      "Baseline Loss: 2.6553 | Actual Loss: 0.3804\n",
      "Baseline Loss: 2.6641 | Actual Loss: 0.1288\n",
      "Baseline Loss: 2.3175 | Actual Loss: 0.1903\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4529\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4055\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3732\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2982\n",
      "Epoch 170/1000: Train Loss: 0.2439, Val Loss: 0.3825\n",
      "Baseline Loss: 2.6802 | Actual Loss: 0.2315\n",
      "Baseline Loss: 2.6450 | Actual Loss: 0.1625\n",
      "Baseline Loss: 2.7162 | Actual Loss: 0.3608\n",
      "Baseline Loss: 2.6786 | Actual Loss: 0.1643\n",
      "Baseline Loss: 2.6591 | Actual Loss: 0.3172\n",
      "Baseline Loss: 2.6731 | Actual Loss: 0.1787\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2341\n",
      "Baseline Loss: 2.6508 | Actual Loss: 0.1116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 171/1000 [00:53<04:10,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6578 | Actual Loss: 0.2622\n",
      "Baseline Loss: 2.6959 | Actual Loss: 0.2444\n",
      "Baseline Loss: 2.6915 | Actual Loss: 0.3045\n",
      "Baseline Loss: 2.6989 | Actual Loss: 0.1640\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.2653\n",
      "Baseline Loss: 2.6558 | Actual Loss: 0.1827\n",
      "Baseline Loss: 2.6714 | Actual Loss: 0.2593\n",
      "Baseline Loss: 2.3134 | Actual Loss: 0.2707\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4344\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3425\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4087\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.1991\n",
      "Epoch 171/1000: Train Loss: 0.2321, Val Loss: 0.3462\n",
      "Baseline Loss: 2.6492 | Actual Loss: 0.1699\n",
      "Baseline Loss: 2.6501 | Actual Loss: 0.2215\n",
      "Baseline Loss: 2.6688 | Actual Loss: 0.3314\n",
      "Baseline Loss: 2.6635 | Actual Loss: 0.2634\n",
      "Baseline Loss: 2.7128 | Actual Loss: 0.3311\n",
      "Baseline Loss: 2.6868 | Actual Loss: 0.1556\n",
      "Baseline Loss: 2.7116 | Actual Loss: 0.3450\n",
      "Baseline Loss: 2.7039 | Actual Loss: 0.2995\n",
      "Baseline Loss: 2.6482 | Actual Loss: 0.3568\n",
      "Baseline Loss: 2.6728 | Actual Loss: 0.1523\n",
      "Baseline Loss: 2.7191 | Actual Loss: 0.2052\n",
      "Baseline Loss: 2.7071 | Actual Loss: 0.2868\n",
      "Baseline Loss: 2.6718 | Actual Loss: 0.1985\n",
      "Baseline Loss: 2.6557 | Actual Loss: 0.2640\n",
      "Baseline Loss: 2.6571 | Actual Loss: 0.2185\n",
      "Baseline Loss: 2.2865 | Actual Loss: 0.1536\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5057\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3024\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 172/1000 [00:54<04:19,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5615 | Actual Loss: 0.2352\n",
      "Epoch 172/1000: Train Loss: 0.2471, Val Loss: 0.3575\n",
      "Baseline Loss: 2.7218 | Actual Loss: 0.1478\n",
      "Baseline Loss: 2.6875 | Actual Loss: 0.1756\n",
      "Baseline Loss: 2.6545 | Actual Loss: 0.1839\n",
      "Baseline Loss: 2.6558 | Actual Loss: 0.1711\n",
      "Baseline Loss: 2.6564 | Actual Loss: 0.2517\n",
      "Baseline Loss: 2.6720 | Actual Loss: 0.2392\n",
      "Baseline Loss: 2.6821 | Actual Loss: 0.3616\n",
      "Baseline Loss: 2.7133 | Actual Loss: 0.2753\n",
      "Baseline Loss: 2.7071 | Actual Loss: 0.3902\n",
      "Baseline Loss: 2.6824 | Actual Loss: 0.2744\n",
      "Baseline Loss: 2.6418 | Actual Loss: 0.2804\n",
      "Baseline Loss: 2.6785 | Actual Loss: 0.1814\n",
      "Baseline Loss: 2.6695 | Actual Loss: 0.2796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 173/1000 [00:54<04:24,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6607 | Actual Loss: 0.2668\n",
      "Baseline Loss: 2.6985 | Actual Loss: 0.2572\n",
      "Baseline Loss: 2.2520 | Actual Loss: 0.0382\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4585\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3458\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3923\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2267\n",
      "Epoch 173/1000: Train Loss: 0.2359, Val Loss: 0.3558\n",
      "Baseline Loss: 2.6971 | Actual Loss: 0.1862\n",
      "Baseline Loss: 2.6805 | Actual Loss: 0.1438\n",
      "Baseline Loss: 2.6612 | Actual Loss: 0.2330\n",
      "Baseline Loss: 2.6621 | Actual Loss: 0.2733\n",
      "Baseline Loss: 2.6875 | Actual Loss: 0.2406\n",
      "Baseline Loss: 2.6579 | Actual Loss: 0.3339\n",
      "Baseline Loss: 2.6796 | Actual Loss: 0.2614\n",
      "Baseline Loss: 2.6467 | Actual Loss: 0.2764\n",
      "Baseline Loss: 2.6400 | Actual Loss: 0.2072\n",
      "Baseline Loss: 2.7220 | Actual Loss: 0.2197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 174/1000 [00:54<04:13,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6650 | Actual Loss: 0.1522\n",
      "Baseline Loss: 2.6715 | Actual Loss: 0.1861\n",
      "Baseline Loss: 2.7122 | Actual Loss: 0.2575\n",
      "Baseline Loss: 2.6704 | Actual Loss: 0.3019\n",
      "Baseline Loss: 2.6400 | Actual Loss: 0.2848\n",
      "Baseline Loss: 2.2710 | Actual Loss: 0.1082\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4906\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3908\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4179\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2839\n",
      "Epoch 174/1000: Train Loss: 0.2291, Val Loss: 0.3958\n",
      "Baseline Loss: 2.6825 | Actual Loss: 0.2638\n",
      "Baseline Loss: 2.7140 | Actual Loss: 0.3049\n",
      "Baseline Loss: 2.6459 | Actual Loss: 0.0933\n",
      "Baseline Loss: 2.7722 | Actual Loss: 0.2620\n",
      "Baseline Loss: 2.6814 | Actual Loss: 0.2518\n",
      "Baseline Loss: 2.7084 | Actual Loss: 0.2101\n",
      "Baseline Loss: 2.6596 | Actual Loss: 0.3194\n",
      "Baseline Loss: 2.6756 | Actual Loss: 0.1424\n",
      "Baseline Loss: 2.6631 | Actual Loss: 0.3189\n",
      "Baseline Loss: 2.6648 | Actual Loss: 0.3714\n",
      "Baseline Loss: 2.6633 | Actual Loss: 0.2212\n",
      "Baseline Loss: 2.6663 | Actual Loss: 0.2683\n",
      "Baseline Loss: 2.6753 | Actual Loss: 0.2542\n",
      "Baseline Loss: 2.6373 | Actual Loss: 0.3760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 175/1000 [00:55<04:19,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6318 | Actual Loss: 0.3246\n",
      "Baseline Loss: 2.2835 | Actual Loss: 0.0911\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4096\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3560\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3552\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.3198\n",
      "Epoch 175/1000: Train Loss: 0.2546, Val Loss: 0.3601\n",
      "Baseline Loss: 2.6534 | Actual Loss: 0.2655\n",
      "Baseline Loss: 2.6773 | Actual Loss: 0.1816\n",
      "Baseline Loss: 2.6523 | Actual Loss: 0.1742\n",
      "Baseline Loss: 2.6776 | Actual Loss: 0.1604\n",
      "Baseline Loss: 2.7251 | Actual Loss: 0.1793\n",
      "Baseline Loss: 2.7098 | Actual Loss: 0.3832\n",
      "Baseline Loss: 2.6653 | Actual Loss: 0.3657\n",
      "Baseline Loss: 2.6610 | Actual Loss: 0.3421\n",
      "Baseline Loss: 2.6903 | Actual Loss: 0.1894\n",
      "Baseline Loss: 2.6672 | Actual Loss: 0.1717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 176/1000 [00:55<04:09,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6693 | Actual Loss: 0.2300\n",
      "Baseline Loss: 2.6602 | Actual Loss: 0.1544\n",
      "Baseline Loss: 2.6712 | Actual Loss: 0.2015\n",
      "Baseline Loss: 2.6615 | Actual Loss: 0.2705\n",
      "Baseline Loss: 2.6926 | Actual Loss: 0.1227\n",
      "Baseline Loss: 2.2541 | Actual Loss: 0.1671\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4948\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.2895\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3923\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2498\n",
      "Epoch 176/1000: Train Loss: 0.2225, Val Loss: 0.3566\n",
      "Baseline Loss: 2.7227 | Actual Loss: 0.1657\n",
      "Baseline Loss: 2.7123 | Actual Loss: 0.4041\n",
      "Baseline Loss: 2.6971 | Actual Loss: 0.3954\n",
      "Baseline Loss: 2.6568 | Actual Loss: 0.1145\n",
      "Baseline Loss: 2.6778 | Actual Loss: 0.2654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 177/1000 [00:55<04:20,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6998 | Actual Loss: 0.2657\n",
      "Baseline Loss: 2.6619 | Actual Loss: 0.1902\n",
      "Baseline Loss: 2.6413 | Actual Loss: 0.2643\n",
      "Baseline Loss: 2.6731 | Actual Loss: 0.2690\n",
      "Baseline Loss: 2.6662 | Actual Loss: 0.3751\n",
      "Baseline Loss: 2.6856 | Actual Loss: 0.1737\n",
      "Baseline Loss: 2.6520 | Actual Loss: 0.0993\n",
      "Baseline Loss: 2.6850 | Actual Loss: 0.2189\n",
      "Baseline Loss: 2.6555 | Actual Loss: 0.1731\n",
      "Baseline Loss: 2.6892 | Actual Loss: 0.2586\n",
      "Baseline Loss: 2.2818 | Actual Loss: 0.1278\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5757\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3203\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3529\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2538\n",
      "Epoch 177/1000: Train Loss: 0.2350, Val Loss: 0.3757\n",
      "Baseline Loss: 2.7075 | Actual Loss: 0.2287\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.2022\n",
      "Baseline Loss: 2.6656 | Actual Loss: 0.1134\n",
      "Baseline Loss: 2.6766 | Actual Loss: 0.2802\n",
      "Baseline Loss: 2.6714 | Actual Loss: 0.2068\n",
      "Baseline Loss: 2.7217 | Actual Loss: 0.2271\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3000\n",
      "Baseline Loss: 2.6628 | Actual Loss: 0.2797\n",
      "Baseline Loss: 2.6350 | Actual Loss: 0.1667\n",
      "Baseline Loss: 2.6385 | Actual Loss: 0.1426\n",
      "Baseline Loss: 2.6709 | Actual Loss: 0.2282\n",
      "Baseline Loss: 2.7022 | Actual Loss: 0.2174\n",
      "Baseline Loss: 2.6759 | Actual Loss: 0.3832\n",
      "Baseline Loss: 2.6816 | Actual Loss: 0.3594\n",
      "Baseline Loss: 2.6416 | Actual Loss: 0.1743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 178/1000 [00:56<04:29,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.3372 | Actual Loss: 0.1188\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.3972\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3742\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3931\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2464\n",
      "Epoch 178/1000: Train Loss: 0.2268, Val Loss: 0.3527\n",
      "Baseline Loss: 2.6787 | Actual Loss: 0.2713\n",
      "Baseline Loss: 2.7009 | Actual Loss: 0.2044\n",
      "Baseline Loss: 2.6385 | Actual Loss: 0.2090\n",
      "Baseline Loss: 2.6699 | Actual Loss: 0.1870\n",
      "Baseline Loss: 2.6546 | Actual Loss: 0.1293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 179/1000 [00:56<04:15,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7008 | Actual Loss: 0.2839\n",
      "Baseline Loss: 2.7089 | Actual Loss: 0.1558\n",
      "Baseline Loss: 2.6683 | Actual Loss: 0.2240\n",
      "Baseline Loss: 2.6987 | Actual Loss: 0.1070\n",
      "Baseline Loss: 2.6918 | Actual Loss: 0.2965\n",
      "Baseline Loss: 2.6780 | Actual Loss: 0.2870\n",
      "Baseline Loss: 2.6744 | Actual Loss: 0.1596\n",
      "Baseline Loss: 2.6768 | Actual Loss: 0.2741\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3008\n",
      "Baseline Loss: 2.6792 | Actual Loss: 0.5822\n",
      "Baseline Loss: 2.2476 | Actual Loss: 0.2978\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4214\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3032\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3697\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2328\n",
      "Epoch 179/1000: Train Loss: 0.2481, Val Loss: 0.3318\n",
      "Baseline Loss: 2.6558 | Actual Loss: 0.2032\n",
      "Baseline Loss: 2.6817 | Actual Loss: 0.2219\n",
      "Baseline Loss: 2.6597 | Actual Loss: 0.2987\n",
      "Baseline Loss: 2.6311 | Actual Loss: 0.1601\n",
      "Baseline Loss: 2.6421 | Actual Loss: 0.1883\n",
      "Baseline Loss: 2.6697 | Actual Loss: 0.1617\n",
      "Baseline Loss: 2.6444 | Actual Loss: 0.2404\n",
      "Baseline Loss: 2.6957 | Actual Loss: 0.3308\n",
      "Baseline Loss: 2.7033 | Actual Loss: 0.2798\n",
      "Baseline Loss: 2.7288 | Actual Loss: 0.2240\n",
      "Baseline Loss: 2.6675 | Actual Loss: 0.2041\n",
      "Baseline Loss: 2.7213 | Actual Loss: 0.1978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 180/1000 [00:56<04:25,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6413 | Actual Loss: 0.3447\n",
      "Baseline Loss: 2.6842 | Actual Loss: 0.2536\n",
      "Baseline Loss: 2.6765 | Actual Loss: 0.1871\n",
      "Baseline Loss: 2.3095 | Actual Loss: 0.1845\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5205\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3003\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4199\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2400\n",
      "Epoch 180/1000: Train Loss: 0.2300, Val Loss: 0.3701\n",
      "Baseline Loss: 2.7453 | Actual Loss: 0.2418\n",
      "Baseline Loss: 2.6790 | Actual Loss: 0.1926\n",
      "Baseline Loss: 2.6430 | Actual Loss: 0.2206\n",
      "Baseline Loss: 2.6319 | Actual Loss: 0.2097\n",
      "Baseline Loss: 2.6531 | Actual Loss: 0.3334\n",
      "Baseline Loss: 2.6622 | Actual Loss: 0.1819\n",
      "Baseline Loss: 2.6843 | Actual Loss: 0.1495\n",
      "Baseline Loss: 2.6827 | Actual Loss: 0.2617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 181/1000 [00:56<04:12,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6892 | Actual Loss: 0.1355\n",
      "Baseline Loss: 2.6995 | Actual Loss: 0.2943\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.1637\n",
      "Baseline Loss: 2.6978 | Actual Loss: 0.3350\n",
      "Baseline Loss: 2.6948 | Actual Loss: 0.3111\n",
      "Baseline Loss: 2.6971 | Actual Loss: 0.2466\n",
      "Baseline Loss: 2.6383 | Actual Loss: 0.1907\n",
      "Baseline Loss: 2.2821 | Actual Loss: 0.0851\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5327\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3218\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3613\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2314\n",
      "Epoch 181/1000: Train Loss: 0.2221, Val Loss: 0.3618\n",
      "Baseline Loss: 2.6627 | Actual Loss: 0.2987\n",
      "Baseline Loss: 2.6945 | Actual Loss: 0.2874\n",
      "Baseline Loss: 2.6847 | Actual Loss: 0.2489\n",
      "Baseline Loss: 2.6268 | Actual Loss: 0.3098\n",
      "Baseline Loss: 2.6455 | Actual Loss: 0.3163\n",
      "Baseline Loss: 2.6589 | Actual Loss: 0.1244\n",
      "Baseline Loss: 2.6779 | Actual Loss: 0.1761\n",
      "Baseline Loss: 2.7136 | Actual Loss: 0.2029\n",
      "Baseline Loss: 2.6333 | Actual Loss: 0.1767\n",
      "Baseline Loss: 2.6874 | Actual Loss: 0.1921\n",
      "Baseline Loss: 2.6751 | Actual Loss: 0.1744\n",
      "Baseline Loss: 2.6886 | Actual Loss: 0.3894\n",
      "Baseline Loss: 2.6721 | Actual Loss: 0.2020\n",
      "Baseline Loss: 2.6654 | Actual Loss: 0.1372\n",
      "Baseline Loss: 2.6275 | Actual Loss: 0.2991\n",
      "Baseline Loss: 2.2898 | Actual Loss: 0.1874\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 182/1000 [00:57<04:16,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6474 | Actual Loss: 0.3166\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3827\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2109\n",
      "Epoch 182/1000: Train Loss: 0.2327, Val Loss: 0.3279\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2086\n",
      "Baseline Loss: 2.6201 | Actual Loss: 0.3805\n",
      "Baseline Loss: 2.6737 | Actual Loss: 0.1333\n",
      "Baseline Loss: 2.7113 | Actual Loss: 0.4305\n",
      "Baseline Loss: 2.6701 | Actual Loss: 0.2415\n",
      "Baseline Loss: 2.7262 | Actual Loss: 0.1114\n",
      "Baseline Loss: 2.6733 | Actual Loss: 0.2672\n",
      "Baseline Loss: 2.6738 | Actual Loss: 0.2855\n",
      "Baseline Loss: 2.6704 | Actual Loss: 0.2141\n",
      "Baseline Loss: 2.6787 | Actual Loss: 0.2277\n",
      "Baseline Loss: 2.6459 | Actual Loss: 0.1402\n",
      "Baseline Loss: 2.7013 | Actual Loss: 0.4307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 183/1000 [00:57<04:23,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6856 | Actual Loss: 0.2360\n",
      "Baseline Loss: 2.6717 | Actual Loss: 0.2270\n",
      "Baseline Loss: 2.6565 | Actual Loss: 0.1724\n",
      "Baseline Loss: 2.2343 | Actual Loss: 0.1173\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5070\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3578\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4142\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2308\n",
      "Epoch 183/1000: Train Loss: 0.2390, Val Loss: 0.3774\n",
      "Baseline Loss: 2.6216 | Actual Loss: 0.1984\n",
      "Baseline Loss: 2.7120 | Actual Loss: 0.2596\n",
      "Baseline Loss: 2.6712 | Actual Loss: 0.2198\n",
      "Baseline Loss: 2.6720 | Actual Loss: 0.1828\n",
      "Baseline Loss: 2.7005 | Actual Loss: 0.2050\n",
      "Baseline Loss: 2.6515 | Actual Loss: 0.2396\n",
      "Baseline Loss: 2.7185 | Actual Loss: 0.2541\n",
      "Baseline Loss: 2.6597 | Actual Loss: 0.1897\n",
      "Baseline Loss: 2.6824 | Actual Loss: 0.2760\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3456\n",
      "Baseline Loss: 2.6855 | Actual Loss: 0.3407\n",
      "Baseline Loss: 2.6268 | Actual Loss: 0.2196\n",
      "Baseline Loss: 2.7103 | Actual Loss: 0.2478\n",
      "Baseline Loss: 2.6665 | Actual Loss: 0.3370\n",
      "Baseline Loss: 2.6877 | Actual Loss: 0.1696\n",
      "Baseline Loss: 2.2767 | Actual Loss: 0.1757\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5392\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 184/1000 [00:57<04:28,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6861 | Actual Loss: 0.4237\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2921\n",
      "Epoch 184/1000: Train Loss: 0.2413, Val Loss: 0.3941\n",
      "Baseline Loss: 2.6632 | Actual Loss: 0.2274\n",
      "Baseline Loss: 2.7256 | Actual Loss: 0.3122\n",
      "Baseline Loss: 2.6845 | Actual Loss: 0.1991\n",
      "Baseline Loss: 2.6721 | Actual Loss: 0.2988\n",
      "Baseline Loss: 2.6826 | Actual Loss: 0.1769\n",
      "Baseline Loss: 2.6676 | Actual Loss: 0.1195\n",
      "Baseline Loss: 2.6888 | Actual Loss: 0.2997\n",
      "Baseline Loss: 2.6799 | Actual Loss: 0.1806\n",
      "Baseline Loss: 2.6781 | Actual Loss: 0.1900\n",
      "Baseline Loss: 2.6655 | Actual Loss: 0.2578\n",
      "Baseline Loss: 2.6685 | Actual Loss: 0.1432\n",
      "Baseline Loss: 2.6584 | Actual Loss: 0.2430\n",
      "Baseline Loss: 2.6561 | Actual Loss: 0.1561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 185/1000 [00:58<04:09,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6378 | Actual Loss: 0.3414\n",
      "Baseline Loss: 2.6685 | Actual Loss: 0.1939\n",
      "Baseline Loss: 2.2626 | Actual Loss: 0.1103\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4265\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.2723\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3971\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2203\n",
      "Epoch 185/1000: Train Loss: 0.2156, Val Loss: 0.3291\n",
      "Baseline Loss: 2.6969 | Actual Loss: 0.2678\n",
      "Baseline Loss: 2.6511 | Actual Loss: 0.3122\n",
      "Baseline Loss: 2.6479 | Actual Loss: 0.2739\n",
      "Baseline Loss: 2.6702 | Actual Loss: 0.2526\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.1971\n",
      "Baseline Loss: 2.6726 | Actual Loss: 0.2363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▊        | 186/1000 [00:58<04:18,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6665 | Actual Loss: 0.2503\n",
      "Baseline Loss: 2.6341 | Actual Loss: 0.3425\n",
      "Baseline Loss: 2.6799 | Actual Loss: 0.1447\n",
      "Baseline Loss: 2.6753 | Actual Loss: 0.1446\n",
      "Baseline Loss: 2.6802 | Actual Loss: 0.1914\n",
      "Baseline Loss: 2.7120 | Actual Loss: 0.1636\n",
      "Baseline Loss: 2.6749 | Actual Loss: 0.2004\n",
      "Baseline Loss: 2.6512 | Actual Loss: 0.2153\n",
      "Baseline Loss: 2.7007 | Actual Loss: 0.2830\n",
      "Baseline Loss: 2.2480 | Actual Loss: 0.1563\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4376\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3623\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3419\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2253\n",
      "Epoch 186/1000: Train Loss: 0.2270, Val Loss: 0.3417\n",
      "Baseline Loss: 2.6877 | Actual Loss: 0.1917\n",
      "Baseline Loss: 2.6665 | Actual Loss: 0.2246\n",
      "Baseline Loss: 2.6550 | Actual Loss: 0.2395\n",
      "Baseline Loss: 2.6782 | Actual Loss: 0.1788\n",
      "Baseline Loss: 2.7091 | Actual Loss: 0.3113\n",
      "Baseline Loss: 2.6901 | Actual Loss: 0.1920\n",
      "Baseline Loss: 2.6920 | Actual Loss: 0.3221\n",
      "Baseline Loss: 2.6588 | Actual Loss: 0.2317\n",
      "Baseline Loss: 2.6486 | Actual Loss: 0.1358\n",
      "Baseline Loss: 2.6854 | Actual Loss: 0.2956\n",
      "Baseline Loss: 2.7025 | Actual Loss: 0.1441\n",
      "Baseline Loss: 2.6818 | Actual Loss: 0.2499\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.1623\n",
      "Baseline Loss: 2.6648 | Actual Loss: 0.2696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▊        | 187/1000 [00:58<04:23,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6584 | Actual Loss: 0.1902\n",
      "Baseline Loss: 2.2939 | Actual Loss: 0.3200\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4640\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.2963\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3610\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2267\n",
      "Epoch 187/1000: Train Loss: 0.2287, Val Loss: 0.3370\n",
      "Baseline Loss: 2.6444 | Actual Loss: 0.2731\n",
      "Baseline Loss: 2.6952 | Actual Loss: 0.3293\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.2020\n",
      "Baseline Loss: 2.6444 | Actual Loss: 0.2100\n",
      "Baseline Loss: 2.6603 | Actual Loss: 0.1630\n",
      "Baseline Loss: 2.6240 | Actual Loss: 0.1369\n",
      "Baseline Loss: 2.7060 | Actual Loss: 0.1553\n",
      "Baseline Loss: 2.7047 | Actual Loss: 0.2573\n",
      "Baseline Loss: 2.6682 | Actual Loss: 0.2629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 188/1000 [00:59<04:05,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6695 | Actual Loss: 0.1774\n",
      "Baseline Loss: 2.7102 | Actual Loss: 0.1561\n",
      "Baseline Loss: 2.7051 | Actual Loss: 0.2364\n",
      "Baseline Loss: 2.6557 | Actual Loss: 0.2246\n",
      "Baseline Loss: 2.6833 | Actual Loss: 0.2377\n",
      "Baseline Loss: 2.6597 | Actual Loss: 0.1802\n",
      "Baseline Loss: 2.1984 | Actual Loss: 0.0809\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4484\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3423\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4435\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2705\n",
      "Epoch 188/1000: Train Loss: 0.2052, Val Loss: 0.3762\n",
      "Baseline Loss: 2.6326 | Actual Loss: 0.2712\n",
      "Baseline Loss: 2.6917 | Actual Loss: 0.2971\n",
      "Baseline Loss: 2.6323 | Actual Loss: 0.1274\n",
      "Baseline Loss: 2.7247 | Actual Loss: 0.1831\n",
      "Baseline Loss: 2.6482 | Actual Loss: 0.1255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 189/1000 [00:59<04:14,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6708 | Actual Loss: 0.1665\n",
      "Baseline Loss: 2.7121 | Actual Loss: 0.3751\n",
      "Baseline Loss: 2.6989 | Actual Loss: 0.2166\n",
      "Baseline Loss: 2.6632 | Actual Loss: 0.2826\n",
      "Baseline Loss: 2.6412 | Actual Loss: 0.2335\n",
      "Baseline Loss: 2.7125 | Actual Loss: 0.2185\n",
      "Baseline Loss: 2.6897 | Actual Loss: 0.1994\n",
      "Baseline Loss: 2.7082 | Actual Loss: 0.3153\n",
      "Baseline Loss: 2.6646 | Actual Loss: 0.3611\n",
      "Baseline Loss: 2.6814 | Actual Loss: 0.2016\n",
      "Baseline Loss: 2.2692 | Actual Loss: 0.4024\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4641\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3937\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4091\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2732\n",
      "Epoch 189/1000: Train Loss: 0.2485, Val Loss: 0.3850\n",
      "Baseline Loss: 2.6410 | Actual Loss: 0.1132\n",
      "Baseline Loss: 2.6612 | Actual Loss: 0.1476\n",
      "Baseline Loss: 2.6555 | Actual Loss: 0.2942\n",
      "Baseline Loss: 2.6694 | Actual Loss: 0.3144\n",
      "Baseline Loss: 2.6509 | Actual Loss: 0.1262\n",
      "Baseline Loss: 2.6717 | Actual Loss: 0.3871\n",
      "Baseline Loss: 2.6617 | Actual Loss: 0.1664\n",
      "Baseline Loss: 2.6938 | Actual Loss: 0.3019\n",
      "Baseline Loss: 2.6698 | Actual Loss: 0.2963\n",
      "Baseline Loss: 2.6736 | Actual Loss: 0.1517\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.1864\n",
      "Baseline Loss: 2.6798 | Actual Loss: 0.2274\n",
      "Baseline Loss: 2.6655 | Actual Loss: 0.4309\n",
      "Baseline Loss: 2.6720 | Actual Loss: 0.3503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 190/1000 [00:59<04:24,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6899 | Actual Loss: 0.1949\n",
      "Baseline Loss: 2.3122 | Actual Loss: 0.1796\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5461\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.2975\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4550\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2756\n",
      "Epoch 190/1000: Train Loss: 0.2418, Val Loss: 0.3936\n",
      "Baseline Loss: 2.6795 | Actual Loss: 0.2714\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.2305\n",
      "Baseline Loss: 2.6827 | Actual Loss: 0.2575\n",
      "Baseline Loss: 2.6475 | Actual Loss: 0.2761\n",
      "Baseline Loss: 2.6961 | Actual Loss: 0.1854\n",
      "Baseline Loss: 2.6491 | Actual Loss: 0.2401\n",
      "Baseline Loss: 2.7071 | Actual Loss: 0.2082\n",
      "Baseline Loss: 2.6676 | Actual Loss: 0.1530\n",
      "Baseline Loss: 2.6566 | Actual Loss: 0.2697\n",
      "Baseline Loss: 2.6502 | Actual Loss: 0.1590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 191/1000 [01:00<04:04,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6595 | Actual Loss: 0.2091\n",
      "Baseline Loss: 2.6544 | Actual Loss: 0.2294\n",
      "Baseline Loss: 2.6772 | Actual Loss: 0.2627\n",
      "Baseline Loss: 2.6961 | Actual Loss: 0.2969\n",
      "Baseline Loss: 2.7063 | Actual Loss: 0.1366\n",
      "Baseline Loss: 2.2603 | Actual Loss: 0.1959\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4016\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4140\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4299\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2562\n",
      "Epoch 191/1000: Train Loss: 0.2239, Val Loss: 0.3754\n",
      "Baseline Loss: 2.7034 | Actual Loss: 0.3131\n",
      "Baseline Loss: 2.6955 | Actual Loss: 0.1889\n",
      "Baseline Loss: 2.6552 | Actual Loss: 0.1861\n",
      "Baseline Loss: 2.7072 | Actual Loss: 0.1896\n",
      "Baseline Loss: 2.6726 | Actual Loss: 0.2383\n",
      "Baseline Loss: 2.7120 | Actual Loss: 0.2663\n",
      "Baseline Loss: 2.6791 | Actual Loss: 0.2084\n",
      "Baseline Loss: 2.7108 | Actual Loss: 0.2868\n",
      "Baseline Loss: 2.6933 | Actual Loss: 0.2157\n",
      "Baseline Loss: 2.6795 | Actual Loss: 0.2415\n",
      "Baseline Loss: 2.6581 | Actual Loss: 0.2291\n",
      "Baseline Loss: 2.6506 | Actual Loss: 0.1367\n",
      "Baseline Loss: 2.6489 | Actual Loss: 0.3125\n",
      "Baseline Loss: 2.6768 | Actual Loss: 0.2644\n",
      "Baseline Loss: 2.6989 | Actual Loss: 0.2947\n",
      "Baseline Loss: 2.2498 | Actual Loss: 0.1795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 192/1000 [01:00<04:10,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6853 | Actual Loss: 0.3953\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3701\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3783\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2193\n",
      "Epoch 192/1000: Train Loss: 0.2345, Val Loss: 0.3407\n",
      "Baseline Loss: 2.6865 | Actual Loss: 0.2078\n",
      "Baseline Loss: 2.6734 | Actual Loss: 0.1359\n",
      "Baseline Loss: 2.7122 | Actual Loss: 0.1686\n",
      "Baseline Loss: 2.6546 | Actual Loss: 0.1771\n",
      "Baseline Loss: 2.6862 | Actual Loss: 0.2634\n",
      "Baseline Loss: 2.6616 | Actual Loss: 0.1864\n",
      "Baseline Loss: 2.6557 | Actual Loss: 0.2742\n",
      "Baseline Loss: 2.6864 | Actual Loss: 0.1138\n",
      "Baseline Loss: 2.6850 | Actual Loss: 0.3349\n",
      "Baseline Loss: 2.7091 | Actual Loss: 0.1902\n",
      "Baseline Loss: 2.6645 | Actual Loss: 0.1448\n",
      "Baseline Loss: 2.6699 | Actual Loss: 0.2385\n",
      "Baseline Loss: 2.7202 | Actual Loss: 0.2303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 193/1000 [01:00<03:59,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6609 | Actual Loss: 0.2520\n",
      "Baseline Loss: 2.6404 | Actual Loss: 0.1330\n",
      "Baseline Loss: 2.2567 | Actual Loss: 0.0879\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4156\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3490\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3529\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2401\n",
      "Epoch 193/1000: Train Loss: 0.1962, Val Loss: 0.3394\n",
      "Baseline Loss: 2.6448 | Actual Loss: 0.1745\n",
      "Baseline Loss: 2.6896 | Actual Loss: 0.2262\n",
      "Baseline Loss: 2.7058 | Actual Loss: 0.2194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 194/1000 [01:00<04:06,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7134 | Actual Loss: 0.2309\n",
      "Baseline Loss: 2.6425 | Actual Loss: 0.1310\n",
      "Baseline Loss: 2.6664 | Actual Loss: 0.2130\n",
      "Baseline Loss: 2.6701 | Actual Loss: 0.1564\n",
      "Baseline Loss: 2.6450 | Actual Loss: 0.2026\n",
      "Baseline Loss: 2.7242 | Actual Loss: 0.2520\n",
      "Baseline Loss: 2.6958 | Actual Loss: 0.2045\n",
      "Baseline Loss: 2.6808 | Actual Loss: 0.2307\n",
      "Baseline Loss: 2.6625 | Actual Loss: 0.1948\n",
      "Baseline Loss: 2.6598 | Actual Loss: 0.1952\n",
      "Baseline Loss: 2.6691 | Actual Loss: 0.1932\n",
      "Baseline Loss: 2.6951 | Actual Loss: 0.1721\n",
      "Baseline Loss: 2.2785 | Actual Loss: 0.2094\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4057\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3264\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3718\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2899\n",
      "Epoch 194/1000: Train Loss: 0.2004, Val Loss: 0.3484\n",
      "Baseline Loss: 2.6279 | Actual Loss: 0.2697\n",
      "Baseline Loss: 2.6773 | Actual Loss: 0.1460\n",
      "Baseline Loss: 2.6678 | Actual Loss: 0.1785\n",
      "Baseline Loss: 2.6636 | Actual Loss: 0.1212\n",
      "Baseline Loss: 2.7079 | Actual Loss: 0.1514\n",
      "Baseline Loss: 2.6417 | Actual Loss: 0.2045\n",
      "Baseline Loss: 2.6649 | Actual Loss: 0.3125\n",
      "Baseline Loss: 2.6975 | Actual Loss: 0.2618\n",
      "Baseline Loss: 2.6564 | Actual Loss: 0.2280\n",
      "Baseline Loss: 2.7108 | Actual Loss: 0.3391\n",
      "Baseline Loss: 2.6517 | Actual Loss: 0.3352\n",
      "Baseline Loss: 2.6776 | Actual Loss: 0.3273\n",
      "Baseline Loss: 2.6724 | Actual Loss: 0.1462\n",
      "Baseline Loss: 2.6784 | Actual Loss: 0.1561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 195/1000 [01:01<03:58,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6901 | Actual Loss: 0.2062\n",
      "Baseline Loss: 2.2788 | Actual Loss: 0.1877\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4571\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.2826\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3804\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2076\n",
      "Epoch 195/1000: Train Loss: 0.2232, Val Loss: 0.3319\n",
      "Baseline Loss: 2.6540 | Actual Loss: 0.2508\n",
      "Baseline Loss: 2.6741 | Actual Loss: 0.2347\n",
      "Baseline Loss: 2.7388 | Actual Loss: 0.1659\n",
      "Baseline Loss: 2.6827 | Actual Loss: 0.1590\n",
      "Baseline Loss: 2.6702 | Actual Loss: 0.2179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 196/1000 [01:01<04:10,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6818 | Actual Loss: 0.2139\n",
      "Baseline Loss: 2.6722 | Actual Loss: 0.1459\n",
      "Baseline Loss: 2.7120 | Actual Loss: 0.3321\n",
      "Baseline Loss: 2.6587 | Actual Loss: 0.3048\n",
      "Baseline Loss: 2.6703 | Actual Loss: 0.5503\n",
      "Baseline Loss: 2.6965 | Actual Loss: 0.2758\n",
      "Baseline Loss: 2.6478 | Actual Loss: 0.2947\n",
      "Baseline Loss: 2.6662 | Actual Loss: 0.2530\n",
      "Baseline Loss: 2.6580 | Actual Loss: 0.1584\n",
      "Baseline Loss: 2.6864 | Actual Loss: 0.2030\n",
      "Baseline Loss: 2.2541 | Actual Loss: 0.1587\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4386\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3424\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3466\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2171\n",
      "Epoch 196/1000: Train Loss: 0.2449, Val Loss: 0.3362\n",
      "Baseline Loss: 2.6497 | Actual Loss: 0.3311\n",
      "Baseline Loss: 2.7009 | Actual Loss: 0.2404\n",
      "Baseline Loss: 2.7290 | Actual Loss: 0.1913\n",
      "Baseline Loss: 2.6660 | Actual Loss: 0.1799\n",
      "Baseline Loss: 2.6996 | Actual Loss: 0.1523\n",
      "Baseline Loss: 2.6555 | Actual Loss: 0.2638\n",
      "Baseline Loss: 2.6725 | Actual Loss: 0.2259\n",
      "Baseline Loss: 2.6584 | Actual Loss: 0.2128\n",
      "Baseline Loss: 2.6592 | Actual Loss: 0.1773\n",
      "Baseline Loss: 2.6323 | Actual Loss: 0.2098\n",
      "Baseline Loss: 2.6569 | Actual Loss: 0.2876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 197/1000 [01:01<04:13,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6906 | Actual Loss: 0.3230\n",
      "Baseline Loss: 2.6524 | Actual Loss: 0.1386\n",
      "Baseline Loss: 2.7102 | Actual Loss: 0.2590\n",
      "Baseline Loss: 2.6740 | Actual Loss: 0.2864\n",
      "Baseline Loss: 2.3553 | Actual Loss: 0.0894\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4243\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3557\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4108\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2504\n",
      "Epoch 197/1000: Train Loss: 0.2230, Val Loss: 0.3603\n",
      "Baseline Loss: 2.6493 | Actual Loss: 0.1964\n",
      "Baseline Loss: 2.6603 | Actual Loss: 0.1680\n",
      "Baseline Loss: 2.6601 | Actual Loss: 0.2689\n",
      "Baseline Loss: 2.6987 | Actual Loss: 0.1991\n",
      "Baseline Loss: 2.6915 | Actual Loss: 0.2170\n",
      "Baseline Loss: 2.6659 | Actual Loss: 0.1672\n",
      "Baseline Loss: 2.6859 | Actual Loss: 0.3459\n",
      "Baseline Loss: 2.6945 | Actual Loss: 0.4480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 198/1000 [01:02<04:02,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6509 | Actual Loss: 0.2076\n",
      "Baseline Loss: 2.6615 | Actual Loss: 0.1850\n",
      "Baseline Loss: 2.6719 | Actual Loss: 0.1933\n",
      "Baseline Loss: 2.6461 | Actual Loss: 0.1991\n",
      "Baseline Loss: 2.6831 | Actual Loss: 0.1917\n",
      "Baseline Loss: 2.7192 | Actual Loss: 0.2359\n",
      "Baseline Loss: 2.6509 | Actual Loss: 0.6573\n",
      "Baseline Loss: 2.2903 | Actual Loss: 0.2041\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4673\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3435\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4085\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2355\n",
      "Epoch 198/1000: Train Loss: 0.2553, Val Loss: 0.3637\n",
      "Baseline Loss: 2.6747 | Actual Loss: 0.1483\n",
      "Baseline Loss: 2.6636 | Actual Loss: 0.2693\n",
      "Baseline Loss: 2.6731 | Actual Loss: 0.1982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 199/1000 [01:02<04:07,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7283 | Actual Loss: 0.1512\n",
      "Baseline Loss: 2.6701 | Actual Loss: 0.2540\n",
      "Baseline Loss: 2.6647 | Actual Loss: 0.2920\n",
      "Baseline Loss: 2.6764 | Actual Loss: 0.1751\n",
      "Baseline Loss: 2.7029 | Actual Loss: 0.1889\n",
      "Baseline Loss: 2.6698 | Actual Loss: 0.3450\n",
      "Baseline Loss: 2.6396 | Actual Loss: 0.3788\n",
      "Baseline Loss: 2.7008 | Actual Loss: 0.3643\n",
      "Baseline Loss: 2.6828 | Actual Loss: 0.2912\n",
      "Baseline Loss: 2.6284 | Actual Loss: 0.2790\n",
      "Baseline Loss: 2.6718 | Actual Loss: 0.2110\n",
      "Baseline Loss: 2.7013 | Actual Loss: 0.2645\n",
      "Baseline Loss: 2.2444 | Actual Loss: 0.2239\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4946\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.2753\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4194\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2550\n",
      "Epoch 199/1000: Train Loss: 0.2522, Val Loss: 0.3611\n",
      "Baseline Loss: 2.6890 | Actual Loss: 0.2584\n",
      "Baseline Loss: 2.6850 | Actual Loss: 0.1284\n",
      "Baseline Loss: 2.6752 | Actual Loss: 0.3302\n",
      "Baseline Loss: 2.6727 | Actual Loss: 0.2705\n",
      "Baseline Loss: 2.6790 | Actual Loss: 0.2398\n",
      "Baseline Loss: 2.7097 | Actual Loss: 0.1345\n",
      "Baseline Loss: 2.6645 | Actual Loss: 0.2100\n",
      "Baseline Loss: 2.6744 | Actual Loss: 0.2267\n",
      "Baseline Loss: 2.6932 | Actual Loss: 0.3086\n",
      "Baseline Loss: 2.6323 | Actual Loss: 0.1494\n",
      "Baseline Loss: 2.6855 | Actual Loss: 0.1864\n",
      "Baseline Loss: 2.6473 | Actual Loss: 0.2258\n",
      "Baseline Loss: 2.6625 | Actual Loss: 0.2812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 200/1000 [01:02<04:20,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7170 | Actual Loss: 0.2124\n",
      "Baseline Loss: 2.7085 | Actual Loss: 0.2789\n",
      "Baseline Loss: 2.2557 | Actual Loss: 0.1404\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5226\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3249\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3915\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2763\n",
      "Epoch 200/1000: Train Loss: 0.2239, Val Loss: 0.3788\n",
      "Baseline Loss: 2.6762 | Actual Loss: 0.2845\n",
      "Baseline Loss: 2.6649 | Actual Loss: 0.3126\n",
      "Baseline Loss: 2.6528 | Actual Loss: 0.1727\n",
      "Baseline Loss: 2.7056 | Actual Loss: 0.2132\n",
      "Baseline Loss: 2.6414 | Actual Loss: 0.1801\n",
      "Baseline Loss: 2.6423 | Actual Loss: 0.1848\n",
      "Baseline Loss: 2.6823 | Actual Loss: 0.4085\n",
      "Baseline Loss: 2.6451 | Actual Loss: 0.2132\n",
      "Baseline Loss: 2.6616 | Actual Loss: 0.1328\n",
      "Baseline Loss: 2.7088 | Actual Loss: 0.2636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 201/1000 [01:03<04:00,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6542 | Actual Loss: 0.2448\n",
      "Baseline Loss: 2.7404 | Actual Loss: 0.3174\n",
      "Baseline Loss: 2.6612 | Actual Loss: 0.2355\n",
      "Baseline Loss: 2.6824 | Actual Loss: 0.1873\n",
      "Baseline Loss: 2.6691 | Actual Loss: 0.2690\n",
      "Baseline Loss: 2.3156 | Actual Loss: 0.1487\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4616\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3309\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3606\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2290\n",
      "Epoch 201/1000: Train Loss: 0.2356, Val Loss: 0.3455\n",
      "Baseline Loss: 2.6563 | Actual Loss: 0.1684\n",
      "Baseline Loss: 2.7182 | Actual Loss: 0.1822\n",
      "Baseline Loss: 2.7108 | Actual Loss: 0.2256\n",
      "Baseline Loss: 2.6864 | Actual Loss: 0.1911\n",
      "Baseline Loss: 2.6849 | Actual Loss: 0.2096\n",
      "Baseline Loss: 2.6967 | Actual Loss: 0.2731\n",
      "Baseline Loss: 2.6845 | Actual Loss: 0.1749\n",
      "Baseline Loss: 2.6320 | Actual Loss: 0.2222\n",
      "Baseline Loss: 2.6954 | Actual Loss: 0.1792\n",
      "Baseline Loss: 2.6842 | Actual Loss: 0.4334\n",
      "Baseline Loss: 2.6461 | Actual Loss: 0.2884\n",
      "Baseline Loss: 2.6529 | Actual Loss: 0.2490\n",
      "Baseline Loss: 2.6708 | Actual Loss: 0.2329\n",
      "Baseline Loss: 2.6461 | Actual Loss: 0.2539\n",
      "Baseline Loss: 2.6942 | Actual Loss: 0.2079\n",
      "Baseline Loss: 2.2293 | Actual Loss: 0.1664\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 202/1000 [01:03<04:08,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6474 | Actual Loss: 0.3544\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4085\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.1974\n",
      "Epoch 202/1000: Train Loss: 0.2286, Val Loss: 0.3503\n",
      "Baseline Loss: 2.6680 | Actual Loss: 0.1367\n",
      "Baseline Loss: 2.6364 | Actual Loss: 0.2346\n",
      "Baseline Loss: 2.6668 | Actual Loss: 0.2100\n",
      "Baseline Loss: 2.6687 | Actual Loss: 0.2836\n",
      "Baseline Loss: 2.6801 | Actual Loss: 0.1353\n",
      "Baseline Loss: 2.7020 | Actual Loss: 0.1441\n",
      "Baseline Loss: 2.6672 | Actual Loss: 0.1557\n",
      "Baseline Loss: 2.6728 | Actual Loss: 0.2136\n",
      "Baseline Loss: 2.6772 | Actual Loss: 0.1794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 203/1000 [01:03<04:14,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6839 | Actual Loss: 0.1310\n",
      "Baseline Loss: 2.6573 | Actual Loss: 0.2892\n",
      "Baseline Loss: 2.6584 | Actual Loss: 0.2660\n",
      "Baseline Loss: 2.6744 | Actual Loss: 0.2461\n",
      "Baseline Loss: 2.6954 | Actual Loss: 0.2983\n",
      "Baseline Loss: 2.6740 | Actual Loss: 0.2290\n",
      "Baseline Loss: 2.2629 | Actual Loss: 0.1043\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.3978\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3186\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4233\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2890\n",
      "Epoch 203/1000: Train Loss: 0.2036, Val Loss: 0.3572\n",
      "Baseline Loss: 2.6744 | Actual Loss: 0.1680\n",
      "Baseline Loss: 2.6590 | Actual Loss: 0.2144\n",
      "Baseline Loss: 2.6606 | Actual Loss: 0.3114\n",
      "Baseline Loss: 2.6531 | Actual Loss: 0.2359\n",
      "Baseline Loss: 2.6763 | Actual Loss: 0.1862\n",
      "Baseline Loss: 2.7185 | Actual Loss: 0.1844\n",
      "Baseline Loss: 2.6720 | Actual Loss: 0.1985\n",
      "Baseline Loss: 2.7222 | Actual Loss: 0.2295\n",
      "Baseline Loss: 2.6650 | Actual Loss: 0.1644\n",
      "Baseline Loss: 2.7008 | Actual Loss: 0.1294\n",
      "Baseline Loss: 2.6825 | Actual Loss: 0.2768\n",
      "Baseline Loss: 2.6872 | Actual Loss: 0.1892\n",
      "Baseline Loss: 2.6738 | Actual Loss: 0.2182\n",
      "Baseline Loss: 2.6572 | Actual Loss: 0.1882\n",
      "Baseline Loss: 2.6766 | Actual Loss: 0.2258\n",
      "Baseline Loss: 2.2632 | Actual Loss: 0.1006\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 204/1000 [01:04<04:17,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6474 | Actual Loss: 0.3319\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3727\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2352\n",
      "Epoch 204/1000: Train Loss: 0.2013, Val Loss: 0.3390\n",
      "Baseline Loss: 2.6503 | Actual Loss: 0.2480\n",
      "Baseline Loss: 2.6946 | Actual Loss: 0.2413\n",
      "Baseline Loss: 2.6690 | Actual Loss: 0.3174\n",
      "Baseline Loss: 2.6673 | Actual Loss: 0.1928\n",
      "Baseline Loss: 2.6883 | Actual Loss: 0.1530\n",
      "Baseline Loss: 2.6941 | Actual Loss: 0.2537\n",
      "Baseline Loss: 2.6592 | Actual Loss: 0.2794\n",
      "Baseline Loss: 2.6821 | Actual Loss: 0.1558\n",
      "Baseline Loss: 2.6277 | Actual Loss: 0.2717\n",
      "Baseline Loss: 2.6527 | Actual Loss: 0.1761\n",
      "Baseline Loss: 2.6909 | Actual Loss: 0.2803\n",
      "Baseline Loss: 2.6783 | Actual Loss: 0.1781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 205/1000 [01:04<04:06,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7079 | Actual Loss: 0.1719\n",
      "Baseline Loss: 2.7075 | Actual Loss: 0.3047\n",
      "Baseline Loss: 2.6738 | Actual Loss: 0.2234\n",
      "Baseline Loss: 2.2794 | Actual Loss: 0.0928\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4505\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3709\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4850\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2098\n",
      "Epoch 205/1000: Train Loss: 0.2213, Val Loss: 0.3791\n",
      "Baseline Loss: 2.6376 | Actual Loss: 0.2892\n",
      "Baseline Loss: 2.6347 | Actual Loss: 0.2196\n",
      "Baseline Loss: 2.7141 | Actual Loss: 0.1688\n",
      "Baseline Loss: 2.6830 | Actual Loss: 0.3404\n",
      "Baseline Loss: 2.6685 | Actual Loss: 0.1401\n",
      "Baseline Loss: 2.6746 | Actual Loss: 0.2025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 206/1000 [01:04<04:13,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7269 | Actual Loss: 0.2140\n",
      "Baseline Loss: 2.6538 | Actual Loss: 0.2053\n",
      "Baseline Loss: 2.6875 | Actual Loss: 0.2545\n",
      "Baseline Loss: 2.7076 | Actual Loss: 0.2677\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.1691\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.2398\n",
      "Baseline Loss: 2.6639 | Actual Loss: 0.2145\n",
      "Baseline Loss: 2.6893 | Actual Loss: 0.3223\n",
      "Baseline Loss: 2.6574 | Actual Loss: 0.2037\n",
      "Baseline Loss: 2.3053 | Actual Loss: 0.1733\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4211\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3720\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3992\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2570\n",
      "Epoch 206/1000: Train Loss: 0.2265, Val Loss: 0.3623\n",
      "Baseline Loss: 2.6905 | Actual Loss: 0.3575\n",
      "Baseline Loss: 2.6740 | Actual Loss: 0.3496\n",
      "Baseline Loss: 2.6689 | Actual Loss: 0.1918\n",
      "Baseline Loss: 2.6797 | Actual Loss: 0.1384\n",
      "Baseline Loss: 2.6544 | Actual Loss: 0.2138\n",
      "Baseline Loss: 2.7138 | Actual Loss: 0.3973\n",
      "Baseline Loss: 2.6610 | Actual Loss: 0.4645\n",
      "Baseline Loss: 2.6682 | Actual Loss: 0.2734\n",
      "Baseline Loss: 2.6903 | Actual Loss: 0.2165\n",
      "Baseline Loss: 2.6678 | Actual Loss: 0.5295\n",
      "Baseline Loss: 2.6723 | Actual Loss: 0.1311\n",
      "Baseline Loss: 2.6802 | Actual Loss: 0.2247\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2112\n",
      "Baseline Loss: 2.6965 | Actual Loss: 0.3229\n",
      "Baseline Loss: 2.6783 | Actual Loss: 0.2756\n",
      "Baseline Loss: 2.2939 | Actual Loss: 0.6139\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 207/1000 [01:05<04:15,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6474 | Actual Loss: 0.3318\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3799\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2014\n",
      "Epoch 207/1000: Train Loss: 0.3070, Val Loss: 0.3537\n",
      "Baseline Loss: 2.6832 | Actual Loss: 0.2541\n",
      "Baseline Loss: 2.6851 | Actual Loss: 0.2572\n",
      "Baseline Loss: 2.6562 | Actual Loss: 0.0976\n",
      "Baseline Loss: 2.7073 | Actual Loss: 0.3026\n",
      "Baseline Loss: 2.6844 | Actual Loss: 0.3251\n",
      "Baseline Loss: 2.7024 | Actual Loss: 0.2650\n",
      "Baseline Loss: 2.6626 | Actual Loss: 0.1786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 208/1000 [01:05<04:03,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6388 | Actual Loss: 0.2314\n",
      "Baseline Loss: 2.6696 | Actual Loss: 0.2298\n",
      "Baseline Loss: 2.6715 | Actual Loss: 0.1063\n",
      "Baseline Loss: 2.6227 | Actual Loss: 0.3562\n",
      "Baseline Loss: 2.6703 | Actual Loss: 0.1585\n",
      "Baseline Loss: 2.6887 | Actual Loss: 0.1690\n",
      "Baseline Loss: 2.6774 | Actual Loss: 0.1046\n",
      "Baseline Loss: 2.6676 | Actual Loss: 0.2280\n",
      "Baseline Loss: 2.3144 | Actual Loss: 0.1414\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4332\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3092\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4047\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2617\n",
      "Epoch 208/1000: Train Loss: 0.2128, Val Loss: 0.3522\n",
      "Baseline Loss: 2.6646 | Actual Loss: 0.1395\n",
      "Baseline Loss: 2.6254 | Actual Loss: 0.3438\n",
      "Baseline Loss: 2.7002 | Actual Loss: 0.2002\n",
      "Baseline Loss: 2.6686 | Actual Loss: 0.1173\n",
      "Baseline Loss: 2.6837 | Actual Loss: 0.2866\n",
      "Baseline Loss: 2.6621 | Actual Loss: 0.1839\n",
      "Baseline Loss: 2.6692 | Actual Loss: 0.1746\n",
      "Baseline Loss: 2.6488 | Actual Loss: 0.2756\n",
      "Baseline Loss: 2.6693 | Actual Loss: 0.1560\n",
      "Baseline Loss: 2.6823 | Actual Loss: 0.1559\n",
      "Baseline Loss: 2.6910 | Actual Loss: 0.2389\n",
      "Baseline Loss: 2.6747 | Actual Loss: 0.2170\n",
      "Baseline Loss: 2.7060 | Actual Loss: 0.2347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 209/1000 [01:05<04:07,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6777 | Actual Loss: 0.1951\n",
      "Baseline Loss: 2.6515 | Actual Loss: 0.1850\n",
      "Baseline Loss: 2.2567 | Actual Loss: 0.1156\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4427\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3223\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3925\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2334\n",
      "Epoch 209/1000: Train Loss: 0.2012, Val Loss: 0.3477\n",
      "Baseline Loss: 2.6860 | Actual Loss: 0.1336\n",
      "Baseline Loss: 2.6442 | Actual Loss: 0.1745\n",
      "Baseline Loss: 2.6693 | Actual Loss: 0.1936\n",
      "Baseline Loss: 2.6718 | Actual Loss: 0.1097\n",
      "Baseline Loss: 2.6544 | Actual Loss: 0.1781\n",
      "Baseline Loss: 2.6714 | Actual Loss: 0.2754\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.2650\n",
      "Baseline Loss: 2.6705 | Actual Loss: 0.2963\n",
      "Baseline Loss: 2.6989 | Actual Loss: 0.3025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 210/1000 [01:05<03:52,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6522 | Actual Loss: 0.3195\n",
      "Baseline Loss: 2.6960 | Actual Loss: 0.2134\n",
      "Baseline Loss: 2.6467 | Actual Loss: 0.3946\n",
      "Baseline Loss: 2.6715 | Actual Loss: 0.1411\n",
      "Baseline Loss: 2.6527 | Actual Loss: 0.3044\n",
      "Baseline Loss: 2.6884 | Actual Loss: 0.1551\n",
      "Baseline Loss: 2.2681 | Actual Loss: 0.1406\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.3847\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3168\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4017\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.2283\n",
      "Epoch 210/1000: Train Loss: 0.2248, Val Loss: 0.3329\n",
      "Baseline Loss: 2.6616 | Actual Loss: 0.2908\n",
      "Baseline Loss: 2.7183 | Actual Loss: 0.0921\n",
      "Baseline Loss: 2.6382 | Actual Loss: 0.3048\n",
      "Baseline Loss: 2.6699 | Actual Loss: 0.2356\n",
      "Baseline Loss: 2.6888 | Actual Loss: 0.4780\n",
      "Baseline Loss: 2.6766 | Actual Loss: 0.2411\n",
      "Baseline Loss: 2.6564 | Actual Loss: 0.2760\n",
      "Baseline Loss: 2.6652 | Actual Loss: 0.2488\n",
      "Baseline Loss: 2.6823 | Actual Loss: 0.2852\n",
      "Baseline Loss: 2.6520 | Actual Loss: 0.2618\n",
      "Baseline Loss: 2.6684 | Actual Loss: 0.1309\n",
      "Baseline Loss: 2.6510 | Actual Loss: 0.2172\n",
      "Baseline Loss: 2.6903 | Actual Loss: 0.2942\n",
      "Baseline Loss: 2.6799 | Actual Loss: 0.3785\n",
      "Baseline Loss: 2.7072 | Actual Loss: 0.1960\n",
      "Baseline Loss: 2.2434 | Actual Loss: 0.0818\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4707\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 210/1000 [01:06<04:09,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6861 | Actual Loss: 0.3966\n",
      "Baseline Loss: 2.5615 | Actual Loss: 0.3022\n",
      "Epoch 211/1000: Train Loss: 0.2508, Val Loss: 0.3726\n",
      "\n",
      "Early stopping at epoch 211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.31015221774578094"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.train_model(\n",
    "    data_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e0fc12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = GNNModelWithNewLoss(\n",
    "        num_node_features=data_list[0].x.shape[1],\n",
    "        num_edge_features=data_list[0].edge_attr.shape[1],\n",
    "        num_global_features=0,\n",
    "        hidden_dim=512,\n",
    "        dropout_rate=0.1,\n",
    "        property_index=2,\n",
    "        save_path=\"premodels_new_og/3/2\"\n",
    "    ).to(devices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71b665fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training will be saved to: premodels_new_og/3/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5120 | Actual Loss: 3.4927\n",
      "Baseline Loss: 3.4970 | Actual Loss: 3.4437\n",
      "Baseline Loss: 3.4405 | Actual Loss: 3.3833\n",
      "Baseline Loss: 3.5453 | Actual Loss: 3.4805\n",
      "Baseline Loss: 3.6277 | Actual Loss: 3.5204\n",
      "Baseline Loss: 3.3440 | Actual Loss: 3.2459\n",
      "Baseline Loss: 3.4772 | Actual Loss: 3.3731\n",
      "Baseline Loss: 3.5880 | Actual Loss: 3.5300\n",
      "Baseline Loss: 3.4172 | Actual Loss: 3.2851\n",
      "Baseline Loss: 3.4280 | Actual Loss: 3.2694\n",
      "Baseline Loss: 3.4034 | Actual Loss: 3.2515\n",
      "Baseline Loss: 3.6049 | Actual Loss: 3.4559\n",
      "Baseline Loss: 3.6873 | Actual Loss: 3.3150\n",
      "Baseline Loss: 3.3279 | Actual Loss: 3.1228\n",
      "Baseline Loss: 3.4696 | Actual Loss: 3.1284\n",
      "Baseline Loss: 3.5838 | Actual Loss: 3.4695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 1/1000 [00:00<06:21,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6096 | Actual Loss: 3.0879\n",
      "Baseline Loss: 3.5877 | Actual Loss: 3.0253\n",
      "Baseline Loss: 3.2785 | Actual Loss: 2.7306\n",
      "Baseline Loss: 3.7994 | Actual Loss: 3.1544\n",
      "Epoch 1/1000: Train Loss: 3.3604, Val Loss: 2.9996\n",
      "New best validation loss: 2.9996\n",
      "Baseline Loss: 3.4104 | Actual Loss: 2.9185\n",
      "Baseline Loss: 3.4699 | Actual Loss: 2.8690\n",
      "Baseline Loss: 3.3964 | Actual Loss: 2.6157\n",
      "Baseline Loss: 3.8381 | Actual Loss: 3.0138\n",
      "Baseline Loss: 3.5247 | Actual Loss: 2.8265\n",
      "Baseline Loss: 3.5414 | Actual Loss: 3.1420\n",
      "Baseline Loss: 3.6838 | Actual Loss: 2.9426\n",
      "Baseline Loss: 3.3961 | Actual Loss: 2.5075\n",
      "Baseline Loss: 3.4248 | Actual Loss: 2.3633\n",
      "Baseline Loss: 3.6135 | Actual Loss: 2.3892\n",
      "Baseline Loss: 3.6277 | Actual Loss: 2.9353\n",
      "Baseline Loss: 3.4351 | Actual Loss: 2.3099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 2/1000 [00:00<05:01,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4329 | Actual Loss: 2.1090\n",
      "Baseline Loss: 3.3970 | Actual Loss: 2.1665\n",
      "Baseline Loss: 3.5134 | Actual Loss: 2.3930\n",
      "Baseline Loss: 3.2989 | Actual Loss: 2.2108\n",
      "Baseline Loss: 3.6096 | Actual Loss: 2.6202\n",
      "Baseline Loss: 3.5877 | Actual Loss: 2.7242\n",
      "Baseline Loss: 3.2785 | Actual Loss: 2.0155\n",
      "Baseline Loss: 3.7994 | Actual Loss: 2.4875\n",
      "Epoch 2/1000: Train Loss: 2.6070, Val Loss: 2.4618\n",
      "New best validation loss: 2.4618\n",
      "Baseline Loss: 3.6323 | Actual Loss: 1.9919\n",
      "Baseline Loss: 3.5458 | Actual Loss: 2.1518\n",
      "Baseline Loss: 3.5328 | Actual Loss: 1.8043\n",
      "Baseline Loss: 3.4434 | Actual Loss: 1.8749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 3/1000 [00:00<05:19,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4098 | Actual Loss: 2.1637\n",
      "Baseline Loss: 3.4505 | Actual Loss: 2.2404\n",
      "Baseline Loss: 3.5132 | Actual Loss: 2.3132\n",
      "Baseline Loss: 3.3237 | Actual Loss: 1.6525\n",
      "Baseline Loss: 3.5886 | Actual Loss: 2.0773\n",
      "Baseline Loss: 3.8543 | Actual Loss: 2.4709\n",
      "Baseline Loss: 3.6051 | Actual Loss: 2.0079\n",
      "Baseline Loss: 3.5459 | Actual Loss: 2.5966\n",
      "Baseline Loss: 3.5669 | Actual Loss: 2.1044\n",
      "Baseline Loss: 3.5167 | Actual Loss: 1.8743\n",
      "Baseline Loss: 3.4931 | Actual Loss: 1.9202\n",
      "Baseline Loss: 3.3143 | Actual Loss: 2.1234\n",
      "Baseline Loss: 3.6096 | Actual Loss: 2.4658\n",
      "Baseline Loss: 3.5877 | Actual Loss: 2.0620\n",
      "Baseline Loss: 3.2785 | Actual Loss: 1.7403\n",
      "Baseline Loss: 3.7994 | Actual Loss: 1.7678\n",
      "Epoch 3/1000: Train Loss: 2.0855, Val Loss: 2.0090\n",
      "New best validation loss: 2.0090\n",
      "Baseline Loss: 3.4812 | Actual Loss: 1.8296\n",
      "Baseline Loss: 3.6460 | Actual Loss: 2.4175\n",
      "Baseline Loss: 3.4507 | Actual Loss: 1.6732\n",
      "Baseline Loss: 3.5089 | Actual Loss: 1.6739\n",
      "Baseline Loss: 3.4661 | Actual Loss: 2.1270\n",
      "Baseline Loss: 3.5654 | Actual Loss: 2.0393\n",
      "Baseline Loss: 3.4549 | Actual Loss: 1.4584\n",
      "Baseline Loss: 3.4695 | Actual Loss: 2.2906\n",
      "Baseline Loss: 3.6358 | Actual Loss: 2.5602\n",
      "Baseline Loss: 3.3546 | Actual Loss: 1.9901\n",
      "Baseline Loss: 3.7026 | Actual Loss: 2.1200\n",
      "Baseline Loss: 3.5623 | Actual Loss: 2.3561\n",
      "Baseline Loss: 3.4070 | Actual Loss: 1.8582\n",
      "Baseline Loss: 3.4178 | Actual Loss: 1.9688\n",
      "Baseline Loss: 3.7180 | Actual Loss: 1.6491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 4/1000 [00:01<05:25,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6527 | Actual Loss: 2.4098\n",
      "Baseline Loss: 3.6096 | Actual Loss: 1.6475\n",
      "Baseline Loss: 3.5877 | Actual Loss: 2.2016\n",
      "Baseline Loss: 3.2785 | Actual Loss: 1.5921\n",
      "Baseline Loss: 3.7994 | Actual Loss: 1.7535\n",
      "Epoch 4/1000: Train Loss: 2.0264, Val Loss: 1.7987\n",
      "New best validation loss: 1.7987\n",
      "Baseline Loss: 3.4882 | Actual Loss: 1.5074\n",
      "Baseline Loss: 3.5415 | Actual Loss: 2.5190\n",
      "Baseline Loss: 3.4549 | Actual Loss: 1.9634\n",
      "Baseline Loss: 3.4427 | Actual Loss: 1.8735\n",
      "Baseline Loss: 3.3848 | Actual Loss: 1.5063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 5/1000 [00:01<04:55,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5968 | Actual Loss: 2.1193\n",
      "Baseline Loss: 3.4690 | Actual Loss: 2.0329\n",
      "Baseline Loss: 3.4584 | Actual Loss: 1.5979\n",
      "Baseline Loss: 3.5535 | Actual Loss: 1.8730\n",
      "Baseline Loss: 3.6003 | Actual Loss: 2.1975\n",
      "Baseline Loss: 3.5397 | Actual Loss: 2.1735\n",
      "Baseline Loss: 3.7371 | Actual Loss: 2.2923\n",
      "Baseline Loss: 3.4506 | Actual Loss: 1.7476\n",
      "Baseline Loss: 3.4430 | Actual Loss: 1.7969\n",
      "Baseline Loss: 3.5243 | Actual Loss: 1.3078\n",
      "Baseline Loss: 3.5198 | Actual Loss: 1.8998\n",
      "Baseline Loss: 3.6096 | Actual Loss: 1.8430\n",
      "Baseline Loss: 3.5877 | Actual Loss: 1.7164\n",
      "Baseline Loss: 3.2785 | Actual Loss: 1.5464\n",
      "Baseline Loss: 3.7994 | Actual Loss: 1.3128\n",
      "Epoch 5/1000: Train Loss: 1.9005, Val Loss: 1.6047\n",
      "New best validation loss: 1.6047\n",
      "Baseline Loss: 3.5091 | Actual Loss: 1.8465\n",
      "Baseline Loss: 3.4134 | Actual Loss: 1.3643\n",
      "Baseline Loss: 3.5493 | Actual Loss: 1.7755\n",
      "Baseline Loss: 3.4893 | Actual Loss: 1.5748\n",
      "Baseline Loss: 3.7373 | Actual Loss: 1.8190\n",
      "Baseline Loss: 3.5575 | Actual Loss: 1.6673\n",
      "Baseline Loss: 3.7365 | Actual Loss: 2.0217\n",
      "Baseline Loss: 3.5745 | Actual Loss: 2.1557\n",
      "Baseline Loss: 3.5375 | Actual Loss: 2.0257\n",
      "Baseline Loss: 3.5411 | Actual Loss: 1.4831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 6/1000 [00:01<05:17,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5842 | Actual Loss: 1.6199\n",
      "Baseline Loss: 3.6504 | Actual Loss: 1.5493\n",
      "Baseline Loss: 3.3649 | Actual Loss: 1.5699\n",
      "Baseline Loss: 3.3886 | Actual Loss: 2.3564\n",
      "Baseline Loss: 3.4581 | Actual Loss: 1.4634\n",
      "Baseline Loss: 3.1241 | Actual Loss: 1.2418\n",
      "Baseline Loss: 3.6096 | Actual Loss: 1.3570\n",
      "Baseline Loss: 3.5877 | Actual Loss: 1.8650\n",
      "Baseline Loss: 3.2785 | Actual Loss: 1.5941\n",
      "Baseline Loss: 3.7994 | Actual Loss: 1.3493\n",
      "Epoch 6/1000: Train Loss: 1.7209, Val Loss: 1.5414\n",
      "New best validation loss: 1.5414\n",
      "Baseline Loss: 3.4812 | Actual Loss: 1.8591\n",
      "Baseline Loss: 3.6596 | Actual Loss: 1.3782\n",
      "Baseline Loss: 3.6141 | Actual Loss: 2.1097\n",
      "Baseline Loss: 3.6648 | Actual Loss: 1.7611\n",
      "Baseline Loss: 3.2984 | Actual Loss: 1.3987\n",
      "Baseline Loss: 3.3109 | Actual Loss: 1.7678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 7/1000 [00:02<04:54,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5494 | Actual Loss: 1.7502\n",
      "Baseline Loss: 3.4514 | Actual Loss: 1.6548\n",
      "Baseline Loss: 3.7574 | Actual Loss: 1.6048\n",
      "Baseline Loss: 3.4390 | Actual Loss: 1.0539\n",
      "Baseline Loss: 3.5218 | Actual Loss: 1.7394\n",
      "Baseline Loss: 3.6367 | Actual Loss: 2.5234\n",
      "Baseline Loss: 3.4175 | Actual Loss: 1.5333\n",
      "Baseline Loss: 3.4659 | Actual Loss: 2.2497\n",
      "Baseline Loss: 3.5700 | Actual Loss: 1.7306\n",
      "Baseline Loss: 3.3397 | Actual Loss: 2.1361\n",
      "Baseline Loss: 3.6096 | Actual Loss: 1.2513\n",
      "Baseline Loss: 3.5877 | Actual Loss: 1.5894\n",
      "Baseline Loss: 3.2785 | Actual Loss: 1.4889\n",
      "Baseline Loss: 3.7994 | Actual Loss: 1.2126\n",
      "Epoch 7/1000: Train Loss: 1.7657, Val Loss: 1.3856\n",
      "New best validation loss: 1.3856\n",
      "Baseline Loss: 3.5086 | Actual Loss: 1.5936\n",
      "Baseline Loss: 3.6683 | Actual Loss: 1.6555\n",
      "Baseline Loss: 3.4549 | Actual Loss: 1.4819\n",
      "Baseline Loss: 3.4029 | Actual Loss: 1.4911\n",
      "Baseline Loss: 3.6365 | Actual Loss: 1.8327\n",
      "Baseline Loss: 3.4545 | Actual Loss: 1.4229\n",
      "Baseline Loss: 3.4885 | Actual Loss: 1.5538\n",
      "Baseline Loss: 3.5753 | Actual Loss: 1.3513\n",
      "Baseline Loss: 3.5008 | Actual Loss: 2.4031\n",
      "Baseline Loss: 3.5457 | Actual Loss: 2.6827\n",
      "Baseline Loss: 3.4172 | Actual Loss: 1.4506\n",
      "Baseline Loss: 3.2785 | Actual Loss: 1.5553\n",
      "Baseline Loss: 3.6131 | Actual Loss: 1.3642\n",
      "Baseline Loss: 3.6780 | Actual Loss: 1.1976\n",
      "Baseline Loss: 3.5581 | Actual Loss: 1.3509\n",
      "Baseline Loss: 3.3400 | Actual Loss: 1.1295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 8/1000 [00:02<05:15,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6096 | Actual Loss: 1.3028\n",
      "Baseline Loss: 3.5877 | Actual Loss: 1.6124\n",
      "Baseline Loss: 3.2785 | Actual Loss: 1.4774\n",
      "Baseline Loss: 3.7994 | Actual Loss: 1.0724\n",
      "Epoch 8/1000: Train Loss: 1.5948, Val Loss: 1.3663\n",
      "New best validation loss: 1.3663\n",
      "Baseline Loss: 3.4397 | Actual Loss: 1.6527\n",
      "Baseline Loss: 3.4470 | Actual Loss: 1.7706\n",
      "Baseline Loss: 3.6644 | Actual Loss: 1.5242\n",
      "Baseline Loss: 3.4697 | Actual Loss: 1.5608\n",
      "Baseline Loss: 3.5714 | Actual Loss: 2.4197\n",
      "Baseline Loss: 3.4443 | Actual Loss: 1.7869\n",
      "Baseline Loss: 3.3334 | Actual Loss: 1.3012\n",
      "Baseline Loss: 3.4774 | Actual Loss: 1.2105\n",
      "Baseline Loss: 3.6594 | Actual Loss: 1.7402\n",
      "Baseline Loss: 3.5119 | Actual Loss: 1.6676\n",
      "Baseline Loss: 3.4663 | Actual Loss: 1.3445\n",
      "Baseline Loss: 3.4284 | Actual Loss: 1.2323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 9/1000 [00:02<05:25,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6098 | Actual Loss: 1.6443\n",
      "Baseline Loss: 3.4620 | Actual Loss: 1.0486\n",
      "Baseline Loss: 3.4849 | Actual Loss: 1.4673\n",
      "Baseline Loss: 3.7933 | Actual Loss: 1.4156\n",
      "Baseline Loss: 3.6096 | Actual Loss: 1.1551\n",
      "Baseline Loss: 3.5877 | Actual Loss: 1.6848\n",
      "Baseline Loss: 3.2785 | Actual Loss: 1.4158\n",
      "Baseline Loss: 3.7994 | Actual Loss: 1.0259\n",
      "Epoch 9/1000: Train Loss: 1.5492, Val Loss: 1.3204\n",
      "New best validation loss: 1.3204\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.3932\n",
      "Baseline Loss: 3.4327 | Actual Loss: 1.6711\n",
      "Baseline Loss: 3.5574 | Actual Loss: 1.3700\n",
      "Baseline Loss: 3.6138 | Actual Loss: 1.2440\n",
      "Baseline Loss: 3.8211 | Actual Loss: 3.0995\n",
      "Baseline Loss: 3.4740 | Actual Loss: 1.7146\n",
      "Baseline Loss: 3.5125 | Actual Loss: 1.3924\n",
      "Baseline Loss: 3.3661 | Actual Loss: 1.5838\n",
      "Baseline Loss: 3.5168 | Actual Loss: 1.3305\n",
      "Baseline Loss: 3.4923 | Actual Loss: 1.4673\n",
      "Baseline Loss: 3.5911 | Actual Loss: 1.3594\n",
      "Baseline Loss: 3.4667 | Actual Loss: 1.0445\n",
      "Baseline Loss: 3.6140 | Actual Loss: 2.4016\n",
      "Baseline Loss: 3.5168 | Actual Loss: 0.8802\n",
      "Baseline Loss: 3.3004 | Actual Loss: 1.4368\n",
      "Baseline Loss: 3.3667 | Actual Loss: 1.2840\n",
      "Baseline Loss: 3.6096 | Actual Loss: 1.3946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 10/1000 [00:03<05:00,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5877 | Actual Loss: 1.5821\n",
      "Baseline Loss: 3.2785 | Actual Loss: 1.5986\n",
      "Baseline Loss: 3.7994 | Actual Loss: 1.2946\n",
      "Epoch 10/1000: Train Loss: 1.5421, Val Loss: 1.4675\n",
      "Baseline Loss: 3.6504 | Actual Loss: 1.0959\n",
      "Baseline Loss: 3.7269 | Actual Loss: 2.2153\n",
      "Baseline Loss: 3.6323 | Actual Loss: 2.0870\n",
      "Baseline Loss: 3.4183 | Actual Loss: 1.5054\n",
      "Baseline Loss: 3.4508 | Actual Loss: 1.4988\n",
      "Baseline Loss: 3.5972 | Actual Loss: 1.6554\n",
      "Baseline Loss: 3.4104 | Actual Loss: 2.0218\n",
      "Baseline Loss: 3.5131 | Actual Loss: 1.6631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 11/1000 [00:03<05:12,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4353 | Actual Loss: 1.2124\n",
      "Baseline Loss: 3.4399 | Actual Loss: 1.4045\n",
      "Baseline Loss: 3.5917 | Actual Loss: 1.3052\n",
      "Baseline Loss: 3.4210 | Actual Loss: 1.2974\n",
      "Baseline Loss: 3.3948 | Actual Loss: 1.3802\n",
      "Baseline Loss: 3.6359 | Actual Loss: 1.2572\n",
      "Baseline Loss: 3.4734 | Actual Loss: 2.2633\n",
      "Baseline Loss: 3.9902 | Actual Loss: 1.4407\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.9548\n",
      "Baseline Loss: 3.5877 | Actual Loss: 1.5061\n",
      "Baseline Loss: 3.2785 | Actual Loss: 1.2791\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.7630\n",
      "Epoch 11/1000: Train Loss: 1.5815, Val Loss: 1.1257\n",
      "New best validation loss: 1.1257\n",
      "Baseline Loss: 3.3372 | Actual Loss: 1.3327\n",
      "Baseline Loss: 3.5123 | Actual Loss: 1.0569\n",
      "Baseline Loss: 3.5612 | Actual Loss: 1.4063\n",
      "Baseline Loss: 3.6735 | Actual Loss: 1.3955\n",
      "Baseline Loss: 3.4542 | Actual Loss: 1.6670\n",
      "Baseline Loss: 3.6181 | Actual Loss: 1.4671\n",
      "Baseline Loss: 3.5362 | Actual Loss: 1.4357\n",
      "Baseline Loss: 3.5415 | Actual Loss: 1.4110\n",
      "Baseline Loss: 3.4143 | Actual Loss: 1.1912\n",
      "Baseline Loss: 3.3275 | Actual Loss: 1.1590\n",
      "Baseline Loss: 3.6098 | Actual Loss: 1.4883\n",
      "Baseline Loss: 3.5662 | Actual Loss: 1.1201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 12/1000 [00:03<05:24,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4551 | Actual Loss: 1.9221\n",
      "Baseline Loss: 3.5219 | Actual Loss: 2.5619\n",
      "Baseline Loss: 3.5922 | Actual Loss: 1.3030\n",
      "Baseline Loss: 3.1241 | Actual Loss: 1.1814\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.8689\n",
      "Baseline Loss: 3.5877 | Actual Loss: 1.4620\n",
      "Baseline Loss: 3.2785 | Actual Loss: 1.3918\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.6989\n",
      "Epoch 12/1000: Train Loss: 1.4437, Val Loss: 1.1054\n",
      "New best validation loss: 1.1054\n",
      "Baseline Loss: 3.6591 | Actual Loss: 1.0907\n",
      "Baseline Loss: 3.6502 | Actual Loss: 1.4983\n",
      "Baseline Loss: 3.3784 | Actual Loss: 1.4544\n",
      "Baseline Loss: 3.5739 | Actual Loss: 1.3482\n",
      "Baseline Loss: 3.4173 | Actual Loss: 1.3044\n",
      "Baseline Loss: 3.4694 | Actual Loss: 0.7197\n",
      "Baseline Loss: 3.5922 | Actual Loss: 1.3153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏         | 13/1000 [00:04<05:09,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5913 | Actual Loss: 1.3987\n",
      "Baseline Loss: 3.5618 | Actual Loss: 1.3277\n",
      "Baseline Loss: 3.5006 | Actual Loss: 1.1100\n",
      "Baseline Loss: 3.4211 | Actual Loss: 1.6167\n",
      "Baseline Loss: 3.4284 | Actual Loss: 0.9055\n",
      "Baseline Loss: 3.5213 | Actual Loss: 1.3088\n",
      "Baseline Loss: 3.5092 | Actual Loss: 1.3301\n",
      "Baseline Loss: 3.2916 | Actual Loss: 1.7365\n",
      "Baseline Loss: 3.3938 | Actual Loss: 2.1276\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.8811\n",
      "Baseline Loss: 3.5877 | Actual Loss: 1.1063\n",
      "Baseline Loss: 3.2785 | Actual Loss: 1.3641\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.7383\n",
      "Epoch 13/1000: Train Loss: 1.3495, Val Loss: 1.0224\n",
      "New best validation loss: 1.0224\n",
      "Baseline Loss: 3.4097 | Actual Loss: 1.2727\n",
      "Baseline Loss: 3.5375 | Actual Loss: 1.1499\n",
      "Baseline Loss: 3.3477 | Actual Loss: 1.5136\n",
      "Baseline Loss: 3.6361 | Actual Loss: 1.3332\n",
      "Baseline Loss: 3.3922 | Actual Loss: 0.8651\n",
      "Baseline Loss: 3.4573 | Actual Loss: 1.0865\n",
      "Baseline Loss: 3.6011 | Actual Loss: 1.5392\n",
      "Baseline Loss: 3.7679 | Actual Loss: 2.2530\n",
      "Baseline Loss: 3.7079 | Actual Loss: 1.1279\n",
      "Baseline Loss: 3.5091 | Actual Loss: 0.9157\n",
      "Baseline Loss: 3.5611 | Actual Loss: 1.3031\n",
      "Baseline Loss: 3.5290 | Actual Loss: 1.0718\n",
      "Baseline Loss: 3.5408 | Actual Loss: 1.1048\n",
      "Baseline Loss: 3.5574 | Actual Loss: 1.1579\n",
      "Baseline Loss: 3.3538 | Actual Loss: 1.3375\n",
      "Baseline Loss: 3.2342 | Actual Loss: 1.3575\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.8361\n",
      "Baseline Loss: 3.5877 | Actual Loss: 1.0549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏         | 14/1000 [00:04<05:21,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.2785 | Actual Loss: 1.2001\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.5775\n",
      "Epoch 14/1000: Train Loss: 1.2743, Val Loss: 0.9171\n",
      "New best validation loss: 0.9171\n",
      "Baseline Loss: 3.4319 | Actual Loss: 1.0452\n",
      "Baseline Loss: 3.5795 | Actual Loss: 0.8661\n",
      "Baseline Loss: 3.7418 | Actual Loss: 1.4407\n",
      "Baseline Loss: 3.6741 | Actual Loss: 2.3684\n",
      "Baseline Loss: 3.5919 | Actual Loss: 1.0855\n",
      "Baseline Loss: 3.5617 | Actual Loss: 1.6646\n",
      "Baseline Loss: 3.4771 | Actual Loss: 1.2628\n",
      "Baseline Loss: 3.3204 | Actual Loss: 1.2073\n",
      "Baseline Loss: 3.5124 | Actual Loss: 1.0769\n",
      "Baseline Loss: 3.7566 | Actual Loss: 1.9472\n",
      "Baseline Loss: 3.2579 | Actual Loss: 1.3980\n",
      "Baseline Loss: 3.6829 | Actual Loss: 0.8182\n",
      "Baseline Loss: 3.3203 | Actual Loss: 2.0696\n",
      "Baseline Loss: 3.5918 | Actual Loss: 0.9962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 15/1000 [00:04<05:22,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4575 | Actual Loss: 0.9804\n",
      "Baseline Loss: 3.1609 | Actual Loss: 0.9387\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.8073\n",
      "Baseline Loss: 3.5877 | Actual Loss: 1.0395\n",
      "Baseline Loss: 3.2785 | Actual Loss: 1.3255\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.5773\n",
      "Epoch 15/1000: Train Loss: 1.3229, Val Loss: 0.9374\n",
      "Baseline Loss: 3.4357 | Actual Loss: 1.0295\n",
      "Baseline Loss: 3.4468 | Actual Loss: 1.4522\n",
      "Baseline Loss: 3.5371 | Actual Loss: 0.7340\n",
      "Baseline Loss: 3.6009 | Actual Loss: 1.4754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 16/1000 [00:05<04:59,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6638 | Actual Loss: 0.9329\n",
      "Baseline Loss: 3.5213 | Actual Loss: 1.2645\n",
      "Baseline Loss: 3.5462 | Actual Loss: 1.8164\n",
      "Baseline Loss: 3.3816 | Actual Loss: 1.2415\n",
      "Baseline Loss: 3.3717 | Actual Loss: 2.0686\n",
      "Baseline Loss: 3.8774 | Actual Loss: 3.1768\n",
      "Baseline Loss: 3.4893 | Actual Loss: 1.2805\n",
      "Baseline Loss: 3.6367 | Actual Loss: 1.4377\n",
      "Baseline Loss: 3.3086 | Actual Loss: 1.1639\n",
      "Baseline Loss: 3.4178 | Actual Loss: 1.6363\n",
      "Baseline Loss: 3.6787 | Actual Loss: 1.1995\n",
      "Baseline Loss: 3.2115 | Actual Loss: 0.6659\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.8588\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.9542\n",
      "Baseline Loss: 3.2785 | Actual Loss: 1.3403\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.5542\n",
      "Epoch 16/1000: Train Loss: 1.4110, Val Loss: 0.9269\n",
      "Baseline Loss: 3.4357 | Actual Loss: 0.8642\n",
      "Baseline Loss: 3.4888 | Actual Loss: 1.5322\n",
      "Baseline Loss: 3.5998 | Actual Loss: 1.0785\n",
      "Baseline Loss: 3.7175 | Actual Loss: 1.4800\n",
      "Baseline Loss: 3.3605 | Actual Loss: 0.8772\n",
      "Baseline Loss: 3.7524 | Actual Loss: 0.9838\n",
      "Baseline Loss: 3.3854 | Actual Loss: 1.3065\n",
      "Baseline Loss: 3.2760 | Actual Loss: 1.0547\n",
      "Baseline Loss: 3.6547 | Actual Loss: 1.0903\n",
      "Baseline Loss: 3.4130 | Actual Loss: 1.0063\n",
      "Baseline Loss: 3.5792 | Actual Loss: 1.2568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 17/1000 [00:05<05:13,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5922 | Actual Loss: 1.1351\n",
      "Baseline Loss: 3.6044 | Actual Loss: 1.4614\n",
      "Baseline Loss: 3.6230 | Actual Loss: 1.1569\n",
      "Baseline Loss: 3.4578 | Actual Loss: 1.4564\n",
      "Baseline Loss: 3.4786 | Actual Loss: 0.6784\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.9680\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.9600\n",
      "Baseline Loss: 3.2785 | Actual Loss: 1.1173\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.5592\n",
      "Epoch 17/1000: Train Loss: 1.1512, Val Loss: 0.9011\n",
      "New best validation loss: 0.9011\n",
      "Baseline Loss: 3.6228 | Actual Loss: 0.7119\n",
      "Baseline Loss: 3.5923 | Actual Loss: 1.2024\n",
      "Baseline Loss: 3.4983 | Actual Loss: 0.6893\n",
      "Baseline Loss: 3.5370 | Actual Loss: 1.4903\n",
      "Baseline Loss: 3.4732 | Actual Loss: 0.6942\n",
      "Baseline Loss: 3.5613 | Actual Loss: 1.3915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 18/1000 [00:05<04:51,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5333 | Actual Loss: 1.4031\n",
      "Baseline Loss: 3.3405 | Actual Loss: 0.9478\n",
      "Baseline Loss: 3.4104 | Actual Loss: 0.9007\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.3865\n",
      "Baseline Loss: 3.4978 | Actual Loss: 0.9938\n",
      "Baseline Loss: 3.4510 | Actual Loss: 1.8258\n",
      "Baseline Loss: 3.5620 | Actual Loss: 1.5654\n",
      "Baseline Loss: 3.3715 | Actual Loss: 1.0215\n",
      "Baseline Loss: 3.6648 | Actual Loss: 1.8276\n",
      "Baseline Loss: 3.3479 | Actual Loss: 0.5329\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.7433\n",
      "Baseline Loss: 3.5877 | Actual Loss: 1.0458\n",
      "Baseline Loss: 3.2785 | Actual Loss: 1.1919\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.5329\n",
      "Epoch 18/1000: Train Loss: 1.1615, Val Loss: 0.8785\n",
      "New best validation loss: 0.8785\n",
      "Baseline Loss: 3.5079 | Actual Loss: 0.8689\n",
      "Baseline Loss: 3.8322 | Actual Loss: 0.9625\n",
      "Baseline Loss: 3.6634 | Actual Loss: 1.5183\n",
      "Baseline Loss: 3.3268 | Actual Loss: 0.7135\n",
      "Baseline Loss: 3.4023 | Actual Loss: 1.1894\n",
      "Baseline Loss: 3.5968 | Actual Loss: 1.1577\n",
      "Baseline Loss: 3.6014 | Actual Loss: 0.8917\n",
      "Baseline Loss: 3.5538 | Actual Loss: 0.8176\n",
      "Baseline Loss: 3.4578 | Actual Loss: 0.9251\n",
      "Baseline Loss: 3.4628 | Actual Loss: 1.1778\n",
      "Baseline Loss: 3.6689 | Actual Loss: 2.2966\n",
      "Baseline Loss: 3.5050 | Actual Loss: 1.5322\n",
      "Baseline Loss: 3.5333 | Actual Loss: 0.8492\n",
      "Baseline Loss: 3.3650 | Actual Loss: 1.6288\n",
      "Baseline Loss: 3.5008 | Actual Loss: 1.5074\n",
      "Baseline Loss: 3.1670 | Actual Loss: 1.1359\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.8089\n",
      "Baseline Loss: 3.5877 | Actual Loss: 1.3001\n",
      "Baseline Loss: 3.2785 | Actual Loss: 1.2693\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.7234\n",
      "Epoch 19/1000: Train Loss: 1.1983, Val Loss: 1.0254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 19/1000 [00:05<04:58,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4146 | Actual Loss: 1.1939\n",
      "Baseline Loss: 3.4211 | Actual Loss: 1.1773\n",
      "Baseline Loss: 3.8841 | Actual Loss: 0.8022\n",
      "Baseline Loss: 3.4396 | Actual Loss: 1.2059\n",
      "Baseline Loss: 3.4506 | Actual Loss: 1.3885\n",
      "Baseline Loss: 3.6454 | Actual Loss: 2.3070\n",
      "Baseline Loss: 3.3170 | Actual Loss: 0.9513\n",
      "Baseline Loss: 3.6925 | Actual Loss: 3.0983\n",
      "Baseline Loss: 3.7624 | Actual Loss: 0.8918\n",
      "Baseline Loss: 3.2895 | Actual Loss: 1.2868\n",
      "Baseline Loss: 3.5495 | Actual Loss: 0.7742\n",
      "Baseline Loss: 3.4243 | Actual Loss: 1.0501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 20/1000 [00:06<05:13,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5745 | Actual Loss: 1.0290\n",
      "Baseline Loss: 3.5658 | Actual Loss: 1.0671\n",
      "Baseline Loss: 3.6181 | Actual Loss: 1.7325\n",
      "Baseline Loss: 3.2498 | Actual Loss: 1.7992\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.7261\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.9592\n",
      "Baseline Loss: 3.2785 | Actual Loss: 1.0318\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.4434\n",
      "Epoch 20/1000: Train Loss: 1.3597, Val Loss: 0.7901\n",
      "New best validation loss: 0.7901\n",
      "Baseline Loss: 3.2913 | Actual Loss: 0.7583\n",
      "Baseline Loss: 3.6929 | Actual Loss: 0.6847\n",
      "Baseline Loss: 3.4617 | Actual Loss: 1.1878\n",
      "Baseline Loss: 3.5051 | Actual Loss: 1.9242\n",
      "Baseline Loss: 3.4177 | Actual Loss: 0.8413\n",
      "Baseline Loss: 3.5789 | Actual Loss: 0.6495\n",
      "Baseline Loss: 3.5083 | Actual Loss: 1.5018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 21/1000 [00:06<04:51,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5079 | Actual Loss: 1.4400\n",
      "Baseline Loss: 3.5539 | Actual Loss: 2.0723\n",
      "Baseline Loss: 3.7833 | Actual Loss: 1.1416\n",
      "Baseline Loss: 3.3042 | Actual Loss: 1.6376\n",
      "Baseline Loss: 3.7675 | Actual Loss: 1.4590\n",
      "Baseline Loss: 3.4931 | Actual Loss: 1.0714\n",
      "Baseline Loss: 3.6228 | Actual Loss: 1.0896\n",
      "Baseline Loss: 3.4725 | Actual Loss: 1.1158\n",
      "Baseline Loss: 3.1731 | Actual Loss: 0.8279\n",
      "Baseline Loss: 3.6096 | Actual Loss: 1.0349\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.9334\n",
      "Baseline Loss: 3.2785 | Actual Loss: 1.1482\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.6341\n",
      "Epoch 21/1000: Train Loss: 1.2127, Val Loss: 0.9377\n",
      "Baseline Loss: 3.8046 | Actual Loss: 1.1109\n",
      "Baseline Loss: 3.3509 | Actual Loss: 1.0684\n",
      "Baseline Loss: 3.6735 | Actual Loss: 1.5470\n",
      "Baseline Loss: 3.4171 | Actual Loss: 1.7853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 22/1000 [00:06<05:04,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4848 | Actual Loss: 1.8244\n",
      "Baseline Loss: 3.4216 | Actual Loss: 1.7826\n",
      "Baseline Loss: 3.4397 | Actual Loss: 2.6388\n",
      "Baseline Loss: 3.6008 | Actual Loss: 1.4750\n",
      "Baseline Loss: 3.3103 | Actual Loss: 0.7899\n",
      "Baseline Loss: 3.5043 | Actual Loss: 0.9844\n",
      "Baseline Loss: 3.4659 | Actual Loss: 0.8272\n",
      "Baseline Loss: 3.5293 | Actual Loss: 1.1267\n",
      "Baseline Loss: 3.5578 | Actual Loss: 0.7208\n",
      "Baseline Loss: 3.3614 | Actual Loss: 1.1040\n",
      "Baseline Loss: 3.4960 | Actual Loss: 1.4387\n",
      "Baseline Loss: 3.5835 | Actual Loss: 3.1763\n",
      "Baseline Loss: 3.6096 | Actual Loss: 1.3151\n",
      "Baseline Loss: 3.5877 | Actual Loss: 1.4719\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.8241\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.5866\n",
      "Epoch 22/1000: Train Loss: 1.4625, Val Loss: 1.0494\n",
      "Baseline Loss: 3.6046 | Actual Loss: 0.8683\n",
      "Baseline Loss: 3.4772 | Actual Loss: 1.8839\n",
      "Baseline Loss: 3.5324 | Actual Loss: 2.2696\n",
      "Baseline Loss: 3.5210 | Actual Loss: 0.8367\n",
      "Baseline Loss: 3.5545 | Actual Loss: 1.3504\n",
      "Baseline Loss: 3.3257 | Actual Loss: 1.1915\n",
      "Baseline Loss: 3.3605 | Actual Loss: 0.7507\n",
      "Baseline Loss: 3.6730 | Actual Loss: 1.2929\n",
      "Baseline Loss: 3.4246 | Actual Loss: 0.9906\n",
      "Baseline Loss: 3.4769 | Actual Loss: 1.4001\n",
      "Baseline Loss: 3.3018 | Actual Loss: 0.9541\n",
      "Baseline Loss: 3.4616 | Actual Loss: 1.2742\n",
      "Baseline Loss: 3.4735 | Actual Loss: 1.2313\n",
      "Baseline Loss: 3.6779 | Actual Loss: 1.1874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 23/1000 [00:07<05:15,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5614 | Actual Loss: 1.2640\n",
      "Baseline Loss: 3.7011 | Actual Loss: 1.7607\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.5130\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.9033\n",
      "Baseline Loss: 3.2785 | Actual Loss: 1.1768\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.4652\n",
      "Epoch 23/1000: Train Loss: 1.2817, Val Loss: 0.7646\n",
      "New best validation loss: 0.7646\n",
      "Baseline Loss: 3.4281 | Actual Loss: 0.7573\n",
      "Baseline Loss: 3.4585 | Actual Loss: 1.0666\n",
      "Baseline Loss: 3.5577 | Actual Loss: 1.3425\n",
      "Baseline Loss: 3.2798 | Actual Loss: 1.6159\n",
      "Baseline Loss: 3.6875 | Actual Loss: 1.1208\n",
      "Baseline Loss: 3.4971 | Actual Loss: 0.5946\n",
      "Baseline Loss: 3.4682 | Actual Loss: 2.1538\n",
      "Baseline Loss: 3.5135 | Actual Loss: 1.3287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 24/1000 [00:07<04:51,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6501 | Actual Loss: 1.2536\n",
      "Baseline Loss: 3.4001 | Actual Loss: 1.2502\n",
      "Baseline Loss: 3.6184 | Actual Loss: 1.2824\n",
      "Baseline Loss: 3.3465 | Actual Loss: 1.3736\n",
      "Baseline Loss: 3.5966 | Actual Loss: 0.9147\n",
      "Baseline Loss: 3.5182 | Actual Loss: 1.7887\n",
      "Baseline Loss: 3.5327 | Actual Loss: 1.0283\n",
      "Baseline Loss: 3.3476 | Actual Loss: 0.9146\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.8915\n",
      "Baseline Loss: 3.5877 | Actual Loss: 1.0356\n",
      "Baseline Loss: 3.2785 | Actual Loss: 1.3011\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.5693\n",
      "Epoch 24/1000: Train Loss: 1.2366, Val Loss: 0.9494\n",
      "Baseline Loss: 3.3686 | Actual Loss: 1.0105\n",
      "Baseline Loss: 3.4767 | Actual Loss: 1.2604\n",
      "Baseline Loss: 3.4425 | Actual Loss: 1.1445\n",
      "Baseline Loss: 3.4697 | Actual Loss: 1.0135\n",
      "Baseline Loss: 3.5706 | Actual Loss: 1.3118\n",
      "Baseline Loss: 3.6310 | Actual Loss: 1.6813\n",
      "Baseline Loss: 3.4584 | Actual Loss: 0.9655\n",
      "Baseline Loss: 3.4580 | Actual Loss: 2.2018\n",
      "Baseline Loss: 3.4431 | Actual Loss: 1.3612\n",
      "Baseline Loss: 3.5122 | Actual Loss: 1.0016\n",
      "Baseline Loss: 3.4392 | Actual Loss: 0.8037\n",
      "Baseline Loss: 3.5332 | Actual Loss: 0.9328\n",
      "Baseline Loss: 3.5009 | Actual Loss: 0.9004\n",
      "Baseline Loss: 3.6775 | Actual Loss: 1.1447\n",
      "Baseline Loss: 3.7838 | Actual Loss: 2.9506\n",
      "Baseline Loss: 3.5835 | Actual Loss: 1.1858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▎         | 25/1000 [00:07<05:07,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6096 | Actual Loss: 0.7369\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.8261\n",
      "Baseline Loss: 3.2785 | Actual Loss: 1.1313\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.3780\n",
      "Epoch 25/1000: Train Loss: 1.3044, Val Loss: 0.7681\n",
      "Baseline Loss: 3.4847 | Actual Loss: 0.8239\n",
      "Baseline Loss: 3.4779 | Actual Loss: 0.9936\n",
      "Baseline Loss: 3.4615 | Actual Loss: 1.0285\n",
      "Baseline Loss: 3.5666 | Actual Loss: 1.4319\n",
      "Baseline Loss: 3.6222 | Actual Loss: 0.9039\n",
      "Baseline Loss: 3.4814 | Actual Loss: 1.3616\n",
      "Baseline Loss: 3.5008 | Actual Loss: 0.9816\n",
      "Baseline Loss: 3.5327 | Actual Loss: 1.2219\n",
      "Baseline Loss: 3.6592 | Actual Loss: 1.9056\n",
      "Baseline Loss: 3.4624 | Actual Loss: 1.0263\n",
      "Baseline Loss: 3.4587 | Actual Loss: 0.9595\n",
      "Baseline Loss: 3.4580 | Actual Loss: 1.4681\n",
      "Baseline Loss: 3.5741 | Actual Loss: 1.8979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 26/1000 [00:08<04:46,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6063 | Actual Loss: 1.2721\n",
      "Baseline Loss: 3.6364 | Actual Loss: 1.0218\n",
      "Baseline Loss: 2.9771 | Actual Loss: 0.7066\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.6955\n",
      "Baseline Loss: 3.5877 | Actual Loss: 1.0198\n",
      "Baseline Loss: 3.2785 | Actual Loss: 1.0782\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.5793\n",
      "Epoch 26/1000: Train Loss: 1.1878, Val Loss: 0.8432\n",
      "Baseline Loss: 3.5411 | Actual Loss: 0.6916\n",
      "Baseline Loss: 3.3145 | Actual Loss: 1.2136\n",
      "Baseline Loss: 3.4101 | Actual Loss: 1.1888\n",
      "Baseline Loss: 3.7418 | Actual Loss: 1.9370\n",
      "Baseline Loss: 3.3409 | Actual Loss: 1.2768\n",
      "Baseline Loss: 3.5452 | Actual Loss: 0.9157\n",
      "Baseline Loss: 3.5411 | Actual Loss: 0.9431\n",
      "Baseline Loss: 3.5012 | Actual Loss: 2.6548\n",
      "Baseline Loss: 3.5922 | Actual Loss: 1.0537\n",
      "Baseline Loss: 3.5288 | Actual Loss: 1.2353\n",
      "Baseline Loss: 3.5877 | Actual Loss: 2.4824\n",
      "Baseline Loss: 3.5038 | Actual Loss: 0.8000\n",
      "Baseline Loss: 3.3990 | Actual Loss: 1.0710\n",
      "Baseline Loss: 3.4967 | Actual Loss: 0.7884\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.9036\n",
      "Baseline Loss: 3.5399 | Actual Loss: 1.1077\n",
      "Baseline Loss: 3.6096 | Actual Loss: 1.2641\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.8110\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.8837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 27/1000 [00:08<05:02,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7994 | Actual Loss: 0.4358\n",
      "Epoch 27/1000: Train Loss: 1.2665, Val Loss: 0.8487\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.7470\n",
      "Baseline Loss: 3.5789 | Actual Loss: 0.7524\n",
      "Baseline Loss: 3.4292 | Actual Loss: 1.0946\n",
      "Baseline Loss: 3.6503 | Actual Loss: 1.8511\n",
      "Baseline Loss: 3.7526 | Actual Loss: 0.9811\n",
      "Baseline Loss: 3.6412 | Actual Loss: 1.8290\n",
      "Baseline Loss: 3.5407 | Actual Loss: 1.5095\n",
      "Baseline Loss: 3.4089 | Actual Loss: 1.3692\n",
      "Baseline Loss: 3.7169 | Actual Loss: 1.6179\n",
      "Baseline Loss: 3.4783 | Actual Loss: 0.8549\n",
      "Baseline Loss: 3.2253 | Actual Loss: 1.2100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 28/1000 [00:08<05:09,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4169 | Actual Loss: 0.9795\n",
      "Baseline Loss: 3.5328 | Actual Loss: 1.5729\n",
      "Baseline Loss: 3.4592 | Actual Loss: 1.2663\n",
      "Baseline Loss: 3.6320 | Actual Loss: 1.5249\n",
      "Baseline Loss: 3.3574 | Actual Loss: 3.9030\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.7623\n",
      "Baseline Loss: 3.5877 | Actual Loss: 1.1121\n",
      "Baseline Loss: 3.2785 | Actual Loss: 1.2066\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.6143\n",
      "Epoch 28/1000: Train Loss: 1.4415, Val Loss: 0.9238\n",
      "Baseline Loss: 3.3044 | Actual Loss: 1.0998\n",
      "Baseline Loss: 3.5088 | Actual Loss: 1.7800\n",
      "Baseline Loss: 3.4250 | Actual Loss: 1.2307\n",
      "Baseline Loss: 3.5793 | Actual Loss: 1.2666\n",
      "Baseline Loss: 3.5574 | Actual Loss: 0.9685\n",
      "Baseline Loss: 3.5055 | Actual Loss: 0.6271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 29/1000 [00:09<04:53,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3889 | Actual Loss: 1.0019\n",
      "Baseline Loss: 3.4435 | Actual Loss: 1.0787\n",
      "Baseline Loss: 3.7269 | Actual Loss: 2.0402\n",
      "Baseline Loss: 3.5037 | Actual Loss: 1.7294\n",
      "Baseline Loss: 3.5709 | Actual Loss: 2.3220\n",
      "Baseline Loss: 3.6007 | Actual Loss: 0.9760\n",
      "Baseline Loss: 3.6315 | Actual Loss: 0.6732\n",
      "Baseline Loss: 3.5459 | Actual Loss: 1.2172\n",
      "Baseline Loss: 3.5051 | Actual Loss: 1.4513\n",
      "Baseline Loss: 3.5282 | Actual Loss: 2.0733\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.7972\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.9577\n",
      "Baseline Loss: 3.2785 | Actual Loss: 1.2267\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.6572\n",
      "Epoch 29/1000: Train Loss: 1.3460, Val Loss: 0.9097\n",
      "Baseline Loss: 3.3787 | Actual Loss: 1.0024\n",
      "Baseline Loss: 3.3925 | Actual Loss: 1.5150\n",
      "Baseline Loss: 3.5125 | Actual Loss: 1.0663\n",
      "Baseline Loss: 3.2794 | Actual Loss: 1.1153\n",
      "Baseline Loss: 3.5009 | Actual Loss: 1.2661\n",
      "Baseline Loss: 3.5249 | Actual Loss: 1.1372\n",
      "Baseline Loss: 3.4738 | Actual Loss: 1.7291\n",
      "Baseline Loss: 3.6225 | Actual Loss: 1.3163\n",
      "Baseline Loss: 3.6459 | Actual Loss: 0.9428\n",
      "Baseline Loss: 3.6592 | Actual Loss: 1.0592\n",
      "Baseline Loss: 3.5294 | Actual Loss: 1.7437\n",
      "Baseline Loss: 3.5293 | Actual Loss: 1.6020\n",
      "Baseline Loss: 3.8491 | Actual Loss: 1.3304\n",
      "Baseline Loss: 3.4700 | Actual Loss: 0.9837\n",
      "Baseline Loss: 3.5333 | Actual Loss: 0.9499\n",
      "Baseline Loss: 3.2569 | Actual Loss: 0.4036\n",
      "Baseline Loss: 3.6096 | Actual Loss: 1.0085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 30/1000 [00:09<05:07,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5877 | Actual Loss: 1.0571\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.9824\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.4681\n",
      "Epoch 30/1000: Train Loss: 1.1977, Val Loss: 0.8790\n",
      "Baseline Loss: 3.5578 | Actual Loss: 1.1336\n",
      "Baseline Loss: 3.5786 | Actual Loss: 1.9604\n",
      "Baseline Loss: 3.4097 | Actual Loss: 1.9730\n",
      "Baseline Loss: 3.4772 | Actual Loss: 1.0873\n",
      "Baseline Loss: 3.5457 | Actual Loss: 1.0131\n",
      "Baseline Loss: 3.3468 | Actual Loss: 1.3754\n",
      "Baseline Loss: 3.5012 | Actual Loss: 1.6856\n",
      "Baseline Loss: 3.5364 | Actual Loss: 1.0624\n",
      "Baseline Loss: 3.4627 | Actual Loss: 1.0740\n",
      "Baseline Loss: 3.3880 | Actual Loss: 1.1982\n",
      "Baseline Loss: 3.7782 | Actual Loss: 0.8078\n",
      "Baseline Loss: 3.4855 | Actual Loss: 1.1138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 31/1000 [00:09<05:18,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6320 | Actual Loss: 0.9116\n",
      "Baseline Loss: 3.4329 | Actual Loss: 1.2547\n",
      "Baseline Loss: 3.4929 | Actual Loss: 1.4100\n",
      "Baseline Loss: 2.9222 | Actual Loss: 1.1722\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.5809\n",
      "Baseline Loss: 3.5877 | Actual Loss: 1.1289\n",
      "Baseline Loss: 3.2785 | Actual Loss: 1.2072\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.7005\n",
      "Epoch 31/1000: Train Loss: 1.2646, Val Loss: 0.9044\n",
      "Baseline Loss: 3.4553 | Actual Loss: 1.3700\n",
      "Baseline Loss: 3.4773 | Actual Loss: 1.0113\n",
      "Baseline Loss: 3.6642 | Actual Loss: 1.1798\n",
      "Baseline Loss: 3.5830 | Actual Loss: 1.1630\n",
      "Baseline Loss: 3.4887 | Actual Loss: 0.5759\n",
      "Baseline Loss: 3.3510 | Actual Loss: 1.1529\n",
      "Baseline Loss: 3.6450 | Actual Loss: 1.2274\n",
      "Baseline Loss: 3.5658 | Actual Loss: 0.8271\n",
      "Baseline Loss: 3.5254 | Actual Loss: 1.0067\n",
      "Baseline Loss: 3.5822 | Actual Loss: 1.0997\n",
      "Baseline Loss: 3.3933 | Actual Loss: 0.9457\n",
      "Baseline Loss: 3.6190 | Actual Loss: 0.9922\n",
      "Baseline Loss: 3.6008 | Actual Loss: 1.2969\n",
      "Baseline Loss: 3.5924 | Actual Loss: 1.6599\n",
      "Baseline Loss: 3.6924 | Actual Loss: 1.2891\n",
      "Baseline Loss: 3.1962 | Actual Loss: 1.1995\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.7902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 32/1000 [00:10<05:02,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5877 | Actual Loss: 0.9588\n",
      "Baseline Loss: 3.2785 | Actual Loss: 1.1528\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.6882\n",
      "Epoch 32/1000: Train Loss: 1.1248, Val Loss: 0.8975\n",
      "Baseline Loss: 3.5008 | Actual Loss: 1.0105\n",
      "Baseline Loss: 3.4137 | Actual Loss: 1.1579\n",
      "Baseline Loss: 3.4929 | Actual Loss: 1.1475\n",
      "Baseline Loss: 3.7115 | Actual Loss: 0.8974\n",
      "Baseline Loss: 3.6187 | Actual Loss: 1.0802\n",
      "Baseline Loss: 3.5743 | Actual Loss: 1.4270\n",
      "Baseline Loss: 3.4359 | Actual Loss: 0.8017\n",
      "Baseline Loss: 3.6185 | Actual Loss: 1.1350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 33/1000 [00:10<05:08,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5669 | Actual Loss: 2.0261\n",
      "Baseline Loss: 3.4438 | Actual Loss: 2.0126\n",
      "Baseline Loss: 3.4517 | Actual Loss: 0.7846\n",
      "Baseline Loss: 3.6007 | Actual Loss: 1.4552\n",
      "Baseline Loss: 3.5408 | Actual Loss: 0.9111\n",
      "Baseline Loss: 3.5877 | Actual Loss: 1.5848\n",
      "Baseline Loss: 3.4776 | Actual Loss: 0.9439\n",
      "Baseline Loss: 3.2980 | Actual Loss: 1.9120\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.6579\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.8231\n",
      "Baseline Loss: 3.2785 | Actual Loss: 1.1617\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.4724\n",
      "Epoch 33/1000: Train Loss: 1.2680, Val Loss: 0.7788\n",
      "Baseline Loss: 3.3139 | Actual Loss: 1.1556\n",
      "Baseline Loss: 3.6411 | Actual Loss: 1.9336\n",
      "Baseline Loss: 3.5129 | Actual Loss: 0.9555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 34/1000 [00:10<04:47,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5163 | Actual Loss: 1.1928\n",
      "Baseline Loss: 3.3081 | Actual Loss: 1.2150\n",
      "Baseline Loss: 3.9070 | Actual Loss: 1.0557\n",
      "Baseline Loss: 3.4653 | Actual Loss: 0.7238\n",
      "Baseline Loss: 3.4823 | Actual Loss: 1.1134\n",
      "Baseline Loss: 3.4137 | Actual Loss: 0.9969\n",
      "Baseline Loss: 3.4069 | Actual Loss: 1.2912\n",
      "Baseline Loss: 3.7570 | Actual Loss: 1.2017\n",
      "Baseline Loss: 3.6060 | Actual Loss: 1.5878\n",
      "Baseline Loss: 3.5793 | Actual Loss: 1.3467\n",
      "Baseline Loss: 3.4855 | Actual Loss: 1.9406\n",
      "Baseline Loss: 3.4738 | Actual Loss: 1.6180\n",
      "Baseline Loss: 3.1663 | Actual Loss: 0.6213\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.6690\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.9189\n",
      "Baseline Loss: 3.2785 | Actual Loss: 1.0904\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.5502\n",
      "Epoch 34/1000: Train Loss: 1.2468, Val Loss: 0.8071\n",
      "Baseline Loss: 3.4893 | Actual Loss: 1.0108\n",
      "Baseline Loss: 3.2001 | Actual Loss: 1.2207\n",
      "Baseline Loss: 3.6973 | Actual Loss: 0.8537\n",
      "Baseline Loss: 3.6184 | Actual Loss: 0.8540\n",
      "Baseline Loss: 3.4512 | Actual Loss: 1.1530\n",
      "Baseline Loss: 3.4033 | Actual Loss: 1.1611\n",
      "Baseline Loss: 3.5701 | Actual Loss: 0.8845\n",
      "Baseline Loss: 3.5494 | Actual Loss: 0.6973\n",
      "Baseline Loss: 3.6149 | Actual Loss: 2.1624\n",
      "Baseline Loss: 3.4287 | Actual Loss: 0.6392\n",
      "Baseline Loss: 3.4967 | Actual Loss: 0.8970\n",
      "Baseline Loss: 3.4659 | Actual Loss: 0.8701\n",
      "Baseline Loss: 3.4214 | Actual Loss: 0.6213\n",
      "Baseline Loss: 3.5584 | Actual Loss: 0.9855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 35/1000 [00:10<05:01,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4290 | Actual Loss: 1.0865\n",
      "Baseline Loss: 3.5510 | Actual Loss: 3.1322\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.9571\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.7951\n",
      "Baseline Loss: 3.2785 | Actual Loss: 1.0674\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.5174\n",
      "Epoch 35/1000: Train Loss: 1.1393, Val Loss: 0.8342\n",
      "Baseline Loss: 3.4766 | Actual Loss: 1.3086\n",
      "Baseline Loss: 3.2610 | Actual Loss: 1.3728\n",
      "Baseline Loss: 3.5094 | Actual Loss: 1.0436\n",
      "Baseline Loss: 3.4550 | Actual Loss: 1.1246\n",
      "Baseline Loss: 3.4896 | Actual Loss: 0.9361\n",
      "Baseline Loss: 3.4894 | Actual Loss: 1.1550\n",
      "Baseline Loss: 3.3108 | Actual Loss: 1.0114\n",
      "Baseline Loss: 3.5620 | Actual Loss: 0.8734\n",
      "Baseline Loss: 3.5662 | Actual Loss: 1.2445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 36/1000 [00:11<05:07,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6504 | Actual Loss: 1.1242\n",
      "Baseline Loss: 3.7371 | Actual Loss: 1.1695\n",
      "Baseline Loss: 3.5710 | Actual Loss: 1.4949\n",
      "Baseline Loss: 3.6182 | Actual Loss: 2.3220\n",
      "Baseline Loss: 3.5004 | Actual Loss: 1.3743\n",
      "Baseline Loss: 3.4346 | Actual Loss: 0.8950\n",
      "Baseline Loss: 3.6768 | Actual Loss: 1.8564\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.8330\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.7992\n",
      "Baseline Loss: 3.2785 | Actual Loss: 1.0632\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.5187\n",
      "Epoch 36/1000: Train Loss: 1.2692, Val Loss: 0.8035\n",
      "Baseline Loss: 3.3412 | Actual Loss: 0.9348\n",
      "Baseline Loss: 3.5839 | Actual Loss: 1.1070\n",
      "Baseline Loss: 3.6399 | Actual Loss: 1.6750\n",
      "Baseline Loss: 3.4657 | Actual Loss: 1.0664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 37/1000 [00:11<04:47,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6551 | Actual Loss: 1.3482\n",
      "Baseline Loss: 3.3950 | Actual Loss: 0.8514\n",
      "Baseline Loss: 3.5167 | Actual Loss: 1.1967\n",
      "Baseline Loss: 3.6460 | Actual Loss: 0.6721\n",
      "Baseline Loss: 3.3958 | Actual Loss: 1.3016\n",
      "Baseline Loss: 3.4507 | Actual Loss: 1.4500\n",
      "Baseline Loss: 3.6832 | Actual Loss: 1.2557\n",
      "Baseline Loss: 3.6929 | Actual Loss: 0.7785\n",
      "Baseline Loss: 3.6736 | Actual Loss: 0.9105\n",
      "Baseline Loss: 3.6142 | Actual Loss: 1.3231\n",
      "Baseline Loss: 3.4435 | Actual Loss: 0.7609\n",
      "Baseline Loss: 3.3925 | Actual Loss: 0.7959\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.4829\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.8365\n",
      "Baseline Loss: 3.2785 | Actual Loss: 1.0452\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.5166\n",
      "Epoch 37/1000: Train Loss: 1.0892, Val Loss: 0.7203\n",
      "New best validation loss: 0.7203\n",
      "Baseline Loss: 3.6361 | Actual Loss: 1.7054\n",
      "Baseline Loss: 3.7623 | Actual Loss: 1.7031\n",
      "Baseline Loss: 3.6978 | Actual Loss: 0.7594\n",
      "Baseline Loss: 3.3613 | Actual Loss: 1.0774\n",
      "Baseline Loss: 3.5419 | Actual Loss: 1.0494\n",
      "Baseline Loss: 3.6235 | Actual Loss: 1.5516\n",
      "Baseline Loss: 3.4851 | Actual Loss: 1.2265\n",
      "Baseline Loss: 3.3136 | Actual Loss: 1.3441\n",
      "Baseline Loss: 3.4063 | Actual Loss: 0.9650\n",
      "Baseline Loss: 3.4258 | Actual Loss: 1.8798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 38/1000 [00:11<04:58,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4395 | Actual Loss: 0.7290\n",
      "Baseline Loss: 3.5537 | Actual Loss: 1.6548\n",
      "Baseline Loss: 3.3656 | Actual Loss: 0.9096\n",
      "Baseline Loss: 3.3720 | Actual Loss: 0.9892\n",
      "Baseline Loss: 3.4732 | Actual Loss: 1.6297\n",
      "Baseline Loss: 3.4024 | Actual Loss: 0.6788\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.6886\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.7889\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.7849\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.5101\n",
      "Epoch 38/1000: Train Loss: 1.2408, Val Loss: 0.6931\n",
      "New best validation loss: 0.6931\n",
      "Baseline Loss: 3.6538 | Actual Loss: 0.9607\n",
      "Baseline Loss: 3.5446 | Actual Loss: 1.3703\n",
      "Baseline Loss: 3.5494 | Actual Loss: 1.3723\n",
      "Baseline Loss: 3.5583 | Actual Loss: 0.8614\n",
      "Baseline Loss: 3.5249 | Actual Loss: 2.3383\n",
      "Baseline Loss: 3.6407 | Actual Loss: 1.0700\n",
      "Baseline Loss: 3.7020 | Actual Loss: 1.1823\n",
      "Baseline Loss: 3.5281 | Actual Loss: 0.6682\n",
      "Baseline Loss: 3.4619 | Actual Loss: 0.8313\n",
      "Baseline Loss: 3.5617 | Actual Loss: 0.6834\n",
      "Baseline Loss: 3.5372 | Actual Loss: 0.9337\n",
      "Baseline Loss: 3.4695 | Actual Loss: 1.3610\n",
      "Baseline Loss: 3.4849 | Actual Loss: 0.8005\n",
      "Baseline Loss: 3.2761 | Actual Loss: 1.0996\n",
      "Baseline Loss: 3.4932 | Actual Loss: 1.0268\n",
      "Baseline Loss: 3.3928 | Actual Loss: 0.6916\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.5645\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.7783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 39/1000 [00:12<05:08,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.2785 | Actual Loss: 0.9869\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.5576\n",
      "Epoch 39/1000: Train Loss: 1.0782, Val Loss: 0.7218\n",
      "Baseline Loss: 3.5672 | Actual Loss: 1.9164\n",
      "Baseline Loss: 3.8211 | Actual Loss: 1.7060\n",
      "Baseline Loss: 3.4548 | Actual Loss: 0.8066\n",
      "Baseline Loss: 3.7158 | Actual Loss: 1.0247\n",
      "Baseline Loss: 3.5125 | Actual Loss: 1.1565\n",
      "Baseline Loss: 3.4139 | Actual Loss: 0.8369\n",
      "Baseline Loss: 3.6922 | Actual Loss: 1.4506\n",
      "Baseline Loss: 3.3816 | Actual Loss: 1.0867\n",
      "Baseline Loss: 3.4468 | Actual Loss: 0.7163\n",
      "Baseline Loss: 3.5920 | Actual Loss: 0.7513\n",
      "Baseline Loss: 3.3820 | Actual Loss: 0.9032\n",
      "Baseline Loss: 3.6645 | Actual Loss: 1.5638\n",
      "Baseline Loss: 3.6404 | Actual Loss: 0.7600\n",
      "Baseline Loss: 3.2666 | Actual Loss: 0.7526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 40/1000 [00:12<04:47,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4403 | Actual Loss: 0.8508\n",
      "Baseline Loss: 3.4306 | Actual Loss: 1.6270\n",
      "Baseline Loss: 3.6096 | Actual Loss: 1.1144\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.7747\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.7767\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.5112\n",
      "Epoch 40/1000: Train Loss: 1.1194, Val Loss: 0.7943\n",
      "Baseline Loss: 3.3202 | Actual Loss: 0.7618\n",
      "Baseline Loss: 3.5482 | Actual Loss: 2.6382\n",
      "Baseline Loss: 3.5673 | Actual Loss: 1.4210\n",
      "Baseline Loss: 3.4549 | Actual Loss: 0.8397\n",
      "Baseline Loss: 3.5283 | Actual Loss: 1.8674\n",
      "Baseline Loss: 3.5171 | Actual Loss: 1.3050\n",
      "Baseline Loss: 3.5010 | Actual Loss: 0.7332\n",
      "Baseline Loss: 3.5625 | Actual Loss: 1.1753\n",
      "Baseline Loss: 3.5575 | Actual Loss: 1.2768\n",
      "Baseline Loss: 3.5872 | Actual Loss: 1.0436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 41/1000 [00:12<05:00,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3472 | Actual Loss: 1.0942\n",
      "Baseline Loss: 3.5788 | Actual Loss: 1.0887\n",
      "Baseline Loss: 3.4896 | Actual Loss: 0.9349\n",
      "Baseline Loss: 3.7419 | Actual Loss: 1.5061\n",
      "Baseline Loss: 3.6974 | Actual Loss: 0.7025\n",
      "Baseline Loss: 3.1041 | Actual Loss: 0.9685\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.6504\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.7774\n",
      "Baseline Loss: 3.2785 | Actual Loss: 1.0136\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.6478\n",
      "Epoch 41/1000: Train Loss: 1.2098, Val Loss: 0.7723\n",
      "Baseline Loss: 3.3536 | Actual Loss: 0.7952\n",
      "Baseline Loss: 3.6603 | Actual Loss: 1.8245\n",
      "Baseline Loss: 3.4434 | Actual Loss: 1.1857\n",
      "Baseline Loss: 3.6928 | Actual Loss: 0.8177\n",
      "Baseline Loss: 3.5213 | Actual Loss: 1.2786\n",
      "Baseline Loss: 3.4506 | Actual Loss: 1.2143\n",
      "Baseline Loss: 3.3749 | Actual Loss: 0.9144\n",
      "Baseline Loss: 3.8158 | Actual Loss: 1.4470\n",
      "Baseline Loss: 3.6325 | Actual Loss: 0.7171\n",
      "Baseline Loss: 3.4434 | Actual Loss: 1.6675\n",
      "Baseline Loss: 3.7945 | Actual Loss: 0.9122\n",
      "Baseline Loss: 3.2691 | Actual Loss: 0.9077\n",
      "Baseline Loss: 3.4152 | Actual Loss: 1.4067\n",
      "Baseline Loss: 3.6049 | Actual Loss: 0.6961\n",
      "Baseline Loss: 3.5789 | Actual Loss: 1.5477\n",
      "Baseline Loss: 3.2115 | Actual Loss: 0.8044\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.7239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 42/1000 [00:13<04:44,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5877 | Actual Loss: 0.8519\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.9364\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.6505\n",
      "Epoch 42/1000: Train Loss: 1.1336, Val Loss: 0.7907\n",
      "Baseline Loss: 3.5244 | Actual Loss: 1.0008\n",
      "Baseline Loss: 3.3512 | Actual Loss: 0.9717\n",
      "Baseline Loss: 3.5165 | Actual Loss: 1.8113\n",
      "Baseline Loss: 3.5208 | Actual Loss: 0.6862\n",
      "Baseline Loss: 3.6453 | Actual Loss: 0.8477\n",
      "Baseline Loss: 3.4074 | Actual Loss: 1.0036\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.3745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 43/1000 [00:13<04:54,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3338 | Actual Loss: 1.3207\n",
      "Baseline Loss: 3.5371 | Actual Loss: 0.6877\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.3964\n",
      "Baseline Loss: 3.6369 | Actual Loss: 0.8905\n",
      "Baseline Loss: 3.5419 | Actual Loss: 1.2883\n",
      "Baseline Loss: 3.7938 | Actual Loss: 0.8657\n",
      "Baseline Loss: 3.6458 | Actual Loss: 1.1582\n",
      "Baseline Loss: 3.4683 | Actual Loss: 1.1373\n",
      "Baseline Loss: 3.0976 | Actual Loss: 0.9271\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.6643\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.8332\n",
      "Baseline Loss: 3.2785 | Actual Loss: 1.0382\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.4696\n",
      "Epoch 43/1000: Train Loss: 1.0855, Val Loss: 0.7513\n",
      "Baseline Loss: 3.4325 | Actual Loss: 0.9568\n",
      "Baseline Loss: 3.5533 | Actual Loss: 0.8835\n",
      "Baseline Loss: 3.4240 | Actual Loss: 1.1688\n",
      "Baseline Loss: 3.5754 | Actual Loss: 0.9914\n",
      "Baseline Loss: 3.3926 | Actual Loss: 0.7577\n",
      "Baseline Loss: 3.4035 | Actual Loss: 1.0306\n",
      "Baseline Loss: 3.6920 | Actual Loss: 0.7380\n",
      "Baseline Loss: 3.4884 | Actual Loss: 0.7744\n",
      "Baseline Loss: 3.5747 | Actual Loss: 1.0139\n",
      "Baseline Loss: 3.4027 | Actual Loss: 1.0740\n",
      "Baseline Loss: 3.5834 | Actual Loss: 0.8998\n",
      "Baseline Loss: 3.5411 | Actual Loss: 0.6262\n",
      "Baseline Loss: 3.5832 | Actual Loss: 0.7229\n",
      "Baseline Loss: 3.3268 | Actual Loss: 1.9155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 44/1000 [00:13<04:58,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4735 | Actual Loss: 1.5602\n",
      "Baseline Loss: 3.5087 | Actual Loss: 0.8746\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.8532\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.8448\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.9625\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.5771\n",
      "Epoch 44/1000: Train Loss: 0.9993, Val Loss: 0.8094\n",
      "Baseline Loss: 3.4899 | Actual Loss: 1.2575\n",
      "Baseline Loss: 3.5163 | Actual Loss: 0.9027\n",
      "Baseline Loss: 3.5335 | Actual Loss: 0.9689\n",
      "Baseline Loss: 3.6863 | Actual Loss: 0.8854\n",
      "Baseline Loss: 3.3918 | Actual Loss: 1.1854\n",
      "Baseline Loss: 3.4360 | Actual Loss: 0.7883\n",
      "Baseline Loss: 3.5208 | Actual Loss: 1.0716\n",
      "Baseline Loss: 3.4384 | Actual Loss: 1.2598\n",
      "Baseline Loss: 3.5259 | Actual Loss: 1.1298\n",
      "Baseline Loss: 3.4071 | Actual Loss: 1.0349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 45/1000 [00:13<04:40,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4502 | Actual Loss: 1.0519\n",
      "Baseline Loss: 3.4554 | Actual Loss: 0.8797\n",
      "Baseline Loss: 3.4657 | Actual Loss: 1.2238\n",
      "Baseline Loss: 3.6363 | Actual Loss: 0.7689\n",
      "Baseline Loss: 3.7728 | Actual Loss: 1.9261\n",
      "Baseline Loss: 3.5091 | Actual Loss: 1.0222\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.8141\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.7603\n",
      "Baseline Loss: 3.2785 | Actual Loss: 1.1270\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.5862\n",
      "Epoch 45/1000: Train Loss: 1.0848, Val Loss: 0.8219\n",
      "Baseline Loss: 3.4513 | Actual Loss: 1.1645\n",
      "Baseline Loss: 3.5012 | Actual Loss: 1.2069\n",
      "Baseline Loss: 3.5669 | Actual Loss: 1.2633\n",
      "Baseline Loss: 3.5917 | Actual Loss: 1.0835\n",
      "Baseline Loss: 3.4893 | Actual Loss: 0.8303\n",
      "Baseline Loss: 3.8602 | Actual Loss: 0.9530\n",
      "Baseline Loss: 3.5922 | Actual Loss: 1.5429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 46/1000 [00:14<04:54,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4965 | Actual Loss: 1.4607\n",
      "Baseline Loss: 3.3861 | Actual Loss: 1.0473\n",
      "Baseline Loss: 3.4385 | Actual Loss: 0.7825\n",
      "Baseline Loss: 3.4666 | Actual Loss: 0.7698\n",
      "Baseline Loss: 3.5745 | Actual Loss: 0.9908\n",
      "Baseline Loss: 3.5799 | Actual Loss: 1.4981\n",
      "Baseline Loss: 3.3996 | Actual Loss: 0.7562\n",
      "Baseline Loss: 3.4742 | Actual Loss: 2.1015\n",
      "Baseline Loss: 3.9734 | Actual Loss: 0.5876\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.7783\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.6729\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.9694\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.5238\n",
      "Epoch 46/1000: Train Loss: 1.1274, Val Loss: 0.7361\n",
      "Baseline Loss: 3.4732 | Actual Loss: 0.7929\n",
      "Baseline Loss: 3.5092 | Actual Loss: 0.9633\n",
      "Baseline Loss: 3.3411 | Actual Loss: 0.7774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 47/1000 [00:14<04:37,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6547 | Actual Loss: 1.5015\n",
      "Baseline Loss: 3.3177 | Actual Loss: 1.0995\n",
      "Baseline Loss: 3.8163 | Actual Loss: 1.0368\n",
      "Baseline Loss: 3.5493 | Actual Loss: 1.0297\n",
      "Baseline Loss: 3.7470 | Actual Loss: 0.9744\n",
      "Baseline Loss: 3.5009 | Actual Loss: 1.0540\n",
      "Baseline Loss: 3.5085 | Actual Loss: 1.3507\n",
      "Baseline Loss: 3.4504 | Actual Loss: 1.1648\n",
      "Baseline Loss: 3.5365 | Actual Loss: 1.1408\n",
      "Baseline Loss: 3.4023 | Actual Loss: 1.3922\n",
      "Baseline Loss: 3.3611 | Actual Loss: 0.9886\n",
      "Baseline Loss: 3.3820 | Actual Loss: 1.4272\n",
      "Baseline Loss: 3.2900 | Actual Loss: 0.4277\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.7785\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.8618\n",
      "Baseline Loss: 3.2785 | Actual Loss: 1.1458\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.5652\n",
      "Epoch 47/1000: Train Loss: 1.0701, Val Loss: 0.8378\n",
      "Baseline Loss: 3.6314 | Actual Loss: 1.3524\n",
      "Baseline Loss: 3.4702 | Actual Loss: 1.0580\n",
      "Baseline Loss: 3.4738 | Actual Loss: 0.7609\n",
      "Baseline Loss: 3.3924 | Actual Loss: 1.1795\n",
      "Baseline Loss: 3.3970 | Actual Loss: 0.7362\n",
      "Baseline Loss: 3.3199 | Actual Loss: 1.1019\n",
      "Baseline Loss: 3.7171 | Actual Loss: 0.8627\n",
      "Baseline Loss: 3.5173 | Actual Loss: 0.6499\n",
      "Baseline Loss: 3.7022 | Actual Loss: 1.2795\n",
      "Baseline Loss: 3.3176 | Actual Loss: 1.2675\n",
      "Baseline Loss: 3.5834 | Actual Loss: 1.1860\n",
      "Baseline Loss: 3.5332 | Actual Loss: 1.1817\n",
      "Baseline Loss: 3.8835 | Actual Loss: 0.8110\n",
      "Baseline Loss: 3.5967 | Actual Loss: 1.6186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 48/1000 [00:14<05:05,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4140 | Actual Loss: 1.2844\n",
      "Baseline Loss: 3.2504 | Actual Loss: 0.4957\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.6313\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.7057\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.9105\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.4721\n",
      "Epoch 48/1000: Train Loss: 1.0516, Val Loss: 0.6799\n",
      "New best validation loss: 0.6799\n",
      "Baseline Loss: 3.4360 | Actual Loss: 1.2246\n",
      "Baseline Loss: 3.4583 | Actual Loss: 1.1487\n",
      "Baseline Loss: 3.5874 | Actual Loss: 0.8821\n",
      "Baseline Loss: 3.4208 | Actual Loss: 0.8859\n",
      "Baseline Loss: 3.6274 | Actual Loss: 1.1807\n",
      "Baseline Loss: 3.4505 | Actual Loss: 1.3453\n",
      "Baseline Loss: 3.3854 | Actual Loss: 1.5362\n",
      "Baseline Loss: 3.3891 | Actual Loss: 0.9930\n",
      "Baseline Loss: 3.5450 | Actual Loss: 0.9590\n",
      "Baseline Loss: 3.6101 | Actual Loss: 1.1979\n",
      "Baseline Loss: 3.5421 | Actual Loss: 0.8465\n",
      "Baseline Loss: 3.5015 | Actual Loss: 1.0096\n",
      "Baseline Loss: 3.6325 | Actual Loss: 0.9763\n",
      "Baseline Loss: 3.5329 | Actual Loss: 1.4278\n",
      "Baseline Loss: 3.4276 | Actual Loss: 0.9345\n",
      "Baseline Loss: 3.3316 | Actual Loss: 0.4423\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.5043\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.7364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 49/1000 [00:15<05:19,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.2785 | Actual Loss: 0.8204\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.4802\n",
      "Epoch 49/1000: Train Loss: 1.0619, Val Loss: 0.6354\n",
      "New best validation loss: 0.6354\n",
      "Baseline Loss: 3.5203 | Actual Loss: 0.9752\n",
      "Baseline Loss: 3.4348 | Actual Loss: 1.3367\n",
      "Baseline Loss: 3.4423 | Actual Loss: 1.5004\n",
      "Baseline Loss: 3.5328 | Actual Loss: 0.6373\n",
      "Baseline Loss: 3.5244 | Actual Loss: 0.8014\n",
      "Baseline Loss: 3.5048 | Actual Loss: 0.9575\n",
      "Baseline Loss: 3.3479 | Actual Loss: 1.0344\n",
      "Baseline Loss: 3.5008 | Actual Loss: 0.8331\n",
      "Baseline Loss: 3.4200 | Actual Loss: 1.2030\n",
      "Baseline Loss: 3.3506 | Actual Loss: 1.7565\n",
      "Baseline Loss: 3.7418 | Actual Loss: 0.8359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 50/1000 [00:15<04:51,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6320 | Actual Loss: 0.8506\n",
      "Baseline Loss: 3.6834 | Actual Loss: 1.1243\n",
      "Baseline Loss: 3.5705 | Actual Loss: 0.7393\n",
      "Baseline Loss: 3.5292 | Actual Loss: 0.8981\n",
      "Baseline Loss: 3.1458 | Actual Loss: 1.7481\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.5141\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.7048\n",
      "Baseline Loss: 3.2785 | Actual Loss: 1.1090\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.4578\n",
      "Epoch 50/1000: Train Loss: 1.0770, Val Loss: 0.6964\n",
      "Baseline Loss: 3.4855 | Actual Loss: 1.1450\n",
      "Baseline Loss: 3.6324 | Actual Loss: 0.8000\n",
      "Baseline Loss: 3.5130 | Actual Loss: 1.0051\n",
      "Baseline Loss: 3.2695 | Actual Loss: 1.1306\n",
      "Baseline Loss: 3.3145 | Actual Loss: 0.7623\n",
      "Baseline Loss: 3.5923 | Actual Loss: 1.3358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 51/1000 [00:15<05:04,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5282 | Actual Loss: 1.1595\n",
      "Baseline Loss: 3.5167 | Actual Loss: 1.0438\n",
      "Baseline Loss: 3.4884 | Actual Loss: 0.7999\n",
      "Baseline Loss: 3.5168 | Actual Loss: 1.0543\n",
      "Baseline Loss: 3.3745 | Actual Loss: 0.6660\n",
      "Baseline Loss: 3.6181 | Actual Loss: 0.6684\n",
      "Baseline Loss: 3.4209 | Actual Loss: 0.7802\n",
      "Baseline Loss: 3.5787 | Actual Loss: 1.5747\n",
      "Baseline Loss: 3.5845 | Actual Loss: 0.8345\n",
      "Baseline Loss: 3.4210 | Actual Loss: 2.7299\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.9103\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.6300\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.7248\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.5286\n",
      "Epoch 51/1000: Train Loss: 1.0931, Val Loss: 0.6984\n",
      "Baseline Loss: 3.4711 | Actual Loss: 1.8586\n",
      "Baseline Loss: 3.6093 | Actual Loss: 0.9081\n",
      "Baseline Loss: 3.5203 | Actual Loss: 1.2608\n",
      "Baseline Loss: 3.5212 | Actual Loss: 1.0861\n",
      "Baseline Loss: 3.4970 | Actual Loss: 0.7377\n",
      "Baseline Loss: 3.4884 | Actual Loss: 0.9179\n",
      "Baseline Loss: 3.5047 | Actual Loss: 0.7886\n",
      "Baseline Loss: 3.4534 | Actual Loss: 1.1467\n",
      "Baseline Loss: 3.5924 | Actual Loss: 1.0056\n",
      "Baseline Loss: 3.5961 | Actual Loss: 1.2818\n",
      "Baseline Loss: 3.4974 | Actual Loss: 0.9904\n",
      "Baseline Loss: 3.5000 | Actual Loss: 0.5313\n",
      "Baseline Loss: 3.7113 | Actual Loss: 0.8094\n",
      "Baseline Loss: 3.3102 | Actual Loss: 0.9647\n",
      "Baseline Loss: 3.6823 | Actual Loss: 0.5886\n",
      "Baseline Loss: 3.3839 | Actual Loss: 0.9369\n",
      "Baseline Loss: 3.6096 | Actual Loss: 1.1603\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.7077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 52/1000 [00:16<04:43,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.2785 | Actual Loss: 0.7495\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.4893\n",
      "Epoch 52/1000: Train Loss: 0.9883, Val Loss: 0.7767\n",
      "Baseline Loss: 3.6007 | Actual Loss: 1.0624\n",
      "Baseline Loss: 3.3092 | Actual Loss: 1.4357\n",
      "Baseline Loss: 3.5832 | Actual Loss: 0.8317\n",
      "Baseline Loss: 3.3518 | Actual Loss: 0.9586\n",
      "Baseline Loss: 3.4538 | Actual Loss: 0.6606\n",
      "Baseline Loss: 3.4723 | Actual Loss: 1.1703\n",
      "Baseline Loss: 3.4425 | Actual Loss: 0.8634\n",
      "Baseline Loss: 3.7026 | Actual Loss: 0.7384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 53/1000 [00:16<04:48,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6234 | Actual Loss: 1.0745\n",
      "Baseline Loss: 3.6634 | Actual Loss: 0.7810\n",
      "Baseline Loss: 3.4280 | Actual Loss: 0.9684\n",
      "Baseline Loss: 3.4620 | Actual Loss: 0.7736\n",
      "Baseline Loss: 3.7465 | Actual Loss: 1.6732\n",
      "Baseline Loss: 3.5328 | Actual Loss: 0.9134\n",
      "Baseline Loss: 3.4893 | Actual Loss: 0.8388\n",
      "Baseline Loss: 3.4786 | Actual Loss: 2.7351\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.7612\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.6555\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.9222\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.5582\n",
      "Epoch 53/1000: Train Loss: 1.0924, Val Loss: 0.7243\n",
      "Baseline Loss: 3.4435 | Actual Loss: 0.7494\n",
      "Baseline Loss: 3.4774 | Actual Loss: 1.1808\n",
      "Baseline Loss: 3.5705 | Actual Loss: 0.9143\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.8786\n",
      "Baseline Loss: 3.5452 | Actual Loss: 0.8000\n",
      "Baseline Loss: 3.4545 | Actual Loss: 1.3152\n",
      "Baseline Loss: 3.4363 | Actual Loss: 0.9267\n",
      "Baseline Loss: 3.4689 | Actual Loss: 0.9772\n",
      "Baseline Loss: 3.4396 | Actual Loss: 0.4847\n",
      "Baseline Loss: 3.4056 | Actual Loss: 1.0398\n",
      "Baseline Loss: 3.4928 | Actual Loss: 0.5991\n",
      "Baseline Loss: 3.4922 | Actual Loss: 0.8785\n",
      "Baseline Loss: 3.8322 | Actual Loss: 1.2117\n",
      "Baseline Loss: 3.7520 | Actual Loss: 1.7168\n",
      "Baseline Loss: 3.4280 | Actual Loss: 1.2091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 54/1000 [00:16<05:02,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4974 | Actual Loss: 0.5733\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.7614\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.6941\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.7730\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.5849\n",
      "Epoch 54/1000: Train Loss: 0.9660, Val Loss: 0.7033\n",
      "Baseline Loss: 3.5203 | Actual Loss: 0.6693\n",
      "Baseline Loss: 3.2473 | Actual Loss: 1.0453\n",
      "Baseline Loss: 3.4767 | Actual Loss: 0.8441\n",
      "Baseline Loss: 3.5128 | Actual Loss: 1.4010\n",
      "Baseline Loss: 3.9190 | Actual Loss: 0.5790\n",
      "Baseline Loss: 3.6736 | Actual Loss: 0.5101\n",
      "Baseline Loss: 3.4545 | Actual Loss: 1.0688\n",
      "Baseline Loss: 3.8373 | Actual Loss: 1.3812\n",
      "Baseline Loss: 3.4579 | Actual Loss: 2.4608\n",
      "Baseline Loss: 3.4625 | Actual Loss: 1.2148\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.8966\n",
      "Baseline Loss: 3.5256 | Actual Loss: 1.1508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 55/1000 [00:17<04:46,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4020 | Actual Loss: 0.8008\n",
      "Baseline Loss: 3.3374 | Actual Loss: 1.1595\n",
      "Baseline Loss: 3.6593 | Actual Loss: 0.6614\n",
      "Baseline Loss: 3.4296 | Actual Loss: 0.9897\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.5827\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.6847\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.8168\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.4810\n",
      "Epoch 55/1000: Train Loss: 1.0521, Val Loss: 0.6413\n",
      "Baseline Loss: 3.4806 | Actual Loss: 0.6702\n",
      "Baseline Loss: 3.6736 | Actual Loss: 1.4287\n",
      "Baseline Loss: 3.5795 | Actual Loss: 0.5498\n",
      "Baseline Loss: 3.4814 | Actual Loss: 0.7142\n",
      "Baseline Loss: 3.5922 | Actual Loss: 2.1287\n",
      "Baseline Loss: 3.4536 | Actual Loss: 1.1885\n",
      "Baseline Loss: 3.5839 | Actual Loss: 0.8461\n",
      "Baseline Loss: 3.5456 | Actual Loss: 1.3551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 56/1000 [00:17<04:51,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5883 | Actual Loss: 1.7394\n",
      "Baseline Loss: 3.3177 | Actual Loss: 1.0458\n",
      "Baseline Loss: 3.2663 | Actual Loss: 0.7933\n",
      "Baseline Loss: 3.5411 | Actual Loss: 0.6827\n",
      "Baseline Loss: 3.8268 | Actual Loss: 1.5574\n",
      "Baseline Loss: 3.5210 | Actual Loss: 1.2295\n",
      "Baseline Loss: 3.3610 | Actual Loss: 0.7587\n",
      "Baseline Loss: 3.6404 | Actual Loss: 2.6959\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.8119\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.8624\n",
      "Baseline Loss: 3.2785 | Actual Loss: 1.2426\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.6122\n",
      "Epoch 56/1000: Train Loss: 1.2115, Val Loss: 0.8823\n",
      "Baseline Loss: 3.5339 | Actual Loss: 0.9404\n",
      "Baseline Loss: 3.6593 | Actual Loss: 1.1227\n",
      "Baseline Loss: 3.4504 | Actual Loss: 1.0995\n",
      "Baseline Loss: 3.5122 | Actual Loss: 0.8656\n",
      "Baseline Loss: 3.5005 | Actual Loss: 0.9858\n",
      "Baseline Loss: 3.5540 | Actual Loss: 0.7775\n",
      "Baseline Loss: 3.7124 | Actual Loss: 1.4140\n",
      "Baseline Loss: 3.4110 | Actual Loss: 1.0056\n",
      "Baseline Loss: 3.4034 | Actual Loss: 0.4813\n",
      "Baseline Loss: 3.2786 | Actual Loss: 0.9280\n",
      "Baseline Loss: 3.3455 | Actual Loss: 1.2092\n",
      "Baseline Loss: 3.5493 | Actual Loss: 1.1036\n",
      "Baseline Loss: 3.5283 | Actual Loss: 0.5998\n",
      "Baseline Loss: 3.5748 | Actual Loss: 1.4493\n",
      "Baseline Loss: 3.5284 | Actual Loss: 2.0138\n",
      "Baseline Loss: 3.2047 | Actual Loss: 0.3936\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.7073\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.6895\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.7481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 57/1000 [00:17<04:43,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7994 | Actual Loss: 0.4334\n",
      "Epoch 57/1000: Train Loss: 1.0243, Val Loss: 0.6446\n",
      "Baseline Loss: 3.3997 | Actual Loss: 1.2410\n",
      "Baseline Loss: 3.3371 | Actual Loss: 0.5804\n",
      "Baseline Loss: 3.6509 | Actual Loss: 1.3449\n",
      "Baseline Loss: 3.4969 | Actual Loss: 0.7203\n",
      "Baseline Loss: 3.4777 | Actual Loss: 1.3050\n",
      "Baseline Loss: 3.6050 | Actual Loss: 0.9239\n",
      "Baseline Loss: 3.5289 | Actual Loss: 1.1412\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.4959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 58/1000 [00:18<04:59,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5006 | Actual Loss: 0.7806\n",
      "Baseline Loss: 3.8268 | Actual Loss: 1.6826\n",
      "Baseline Loss: 3.6055 | Actual Loss: 0.7144\n",
      "Baseline Loss: 3.5128 | Actual Loss: 1.2922\n",
      "Baseline Loss: 3.7837 | Actual Loss: 0.8877\n",
      "Baseline Loss: 3.3608 | Actual Loss: 0.8820\n",
      "Baseline Loss: 3.4630 | Actual Loss: 0.7146\n",
      "Baseline Loss: 3.3676 | Actual Loss: 1.5044\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.7007\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.5704\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.8045\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.5578\n",
      "Epoch 58/1000: Train Loss: 1.0132, Val Loss: 0.6583\n",
      "Baseline Loss: 3.3341 | Actual Loss: 1.1008\n",
      "Baseline Loss: 3.9190 | Actual Loss: 0.9027\n",
      "Baseline Loss: 3.4319 | Actual Loss: 1.6307\n",
      "Baseline Loss: 3.6507 | Actual Loss: 0.7928\n",
      "Baseline Loss: 3.4293 | Actual Loss: 1.1041\n",
      "Baseline Loss: 3.7577 | Actual Loss: 1.3285\n",
      "Baseline Loss: 3.3578 | Actual Loss: 0.5973\n",
      "Baseline Loss: 3.4923 | Actual Loss: 1.0397\n",
      "Baseline Loss: 3.4657 | Actual Loss: 0.9443\n",
      "Baseline Loss: 3.4393 | Actual Loss: 0.3886\n",
      "Baseline Loss: 3.5086 | Actual Loss: 2.1073\n",
      "Baseline Loss: 3.3512 | Actual Loss: 1.1208\n",
      "Baseline Loss: 3.4245 | Actual Loss: 0.8071\n",
      "Baseline Loss: 3.4772 | Actual Loss: 0.9062\n",
      "Baseline Loss: 3.5163 | Actual Loss: 0.6739\n",
      "Baseline Loss: 3.5838 | Actual Loss: 0.5448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 59/1000 [00:18<05:08,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6096 | Actual Loss: 0.6505\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.6840\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.9184\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.5615\n",
      "Epoch 59/1000: Train Loss: 0.9994, Val Loss: 0.7036\n",
      "Baseline Loss: 3.3829 | Actual Loss: 0.9127\n",
      "Baseline Loss: 3.6644 | Actual Loss: 1.1073\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.1489\n",
      "Baseline Loss: 3.8378 | Actual Loss: 0.6208\n",
      "Baseline Loss: 3.5833 | Actual Loss: 0.7279\n",
      "Baseline Loss: 3.4405 | Actual Loss: 0.8257\n",
      "Baseline Loss: 3.4474 | Actual Loss: 0.7500\n",
      "Baseline Loss: 3.3484 | Actual Loss: 0.8359\n",
      "Baseline Loss: 3.3492 | Actual Loss: 0.5041\n",
      "Baseline Loss: 3.5128 | Actual Loss: 1.1009\n",
      "Baseline Loss: 3.5488 | Actual Loss: 0.9148\n",
      "Baseline Loss: 3.6682 | Actual Loss: 0.7960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 60/1000 [00:18<04:53,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6132 | Actual Loss: 1.5272\n",
      "Baseline Loss: 3.4969 | Actual Loss: 0.8580\n",
      "Baseline Loss: 3.5249 | Actual Loss: 0.8866\n",
      "Baseline Loss: 3.6175 | Actual Loss: 0.8000\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.8053\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.5904\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.8931\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.5525\n",
      "Epoch 60/1000: Train Loss: 0.8948, Val Loss: 0.7103\n",
      "Baseline Loss: 3.6010 | Actual Loss: 0.9317\n",
      "Baseline Loss: 3.5166 | Actual Loss: 0.5718\n",
      "Baseline Loss: 3.3473 | Actual Loss: 0.6654\n",
      "Baseline Loss: 3.4362 | Actual Loss: 1.5661\n",
      "Baseline Loss: 3.4139 | Actual Loss: 1.1529\n",
      "Baseline Loss: 3.4688 | Actual Loss: 0.6216\n",
      "Baseline Loss: 3.4322 | Actual Loss: 0.6425\n",
      "Baseline Loss: 3.6182 | Actual Loss: 0.3246\n",
      "Baseline Loss: 3.5657 | Actual Loss: 1.0296\n",
      "Baseline Loss: 3.5414 | Actual Loss: 0.6132\n",
      "Baseline Loss: 3.5248 | Actual Loss: 1.3046\n",
      "Baseline Loss: 3.3786 | Actual Loss: 0.6350\n",
      "Baseline Loss: 3.5869 | Actual Loss: 0.8941\n",
      "Baseline Loss: 3.4620 | Actual Loss: 1.2443\n",
      "Baseline Loss: 3.6101 | Actual Loss: 1.2248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 61/1000 [00:19<05:06,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3657 | Actual Loss: 1.3432\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.6688\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.6696\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.8497\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.6654\n",
      "Epoch 61/1000: Train Loss: 0.9228, Val Loss: 0.7134\n",
      "Baseline Loss: 3.6784 | Actual Loss: 1.2510\n",
      "Baseline Loss: 3.5504 | Actual Loss: 1.1130\n",
      "Baseline Loss: 3.3652 | Actual Loss: 1.4351\n",
      "Baseline Loss: 3.4814 | Actual Loss: 1.2835\n",
      "Baseline Loss: 3.5335 | Actual Loss: 1.0160\n",
      "Baseline Loss: 3.6883 | Actual Loss: 0.9017\n",
      "Baseline Loss: 3.2753 | Actual Loss: 0.9366\n",
      "Baseline Loss: 3.4329 | Actual Loss: 0.7446\n",
      "Baseline Loss: 3.6507 | Actual Loss: 0.9495\n",
      "Baseline Loss: 3.5053 | Actual Loss: 1.1029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 62/1000 [00:19<04:53,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6194 | Actual Loss: 1.0938\n",
      "Baseline Loss: 3.4811 | Actual Loss: 2.6800\n",
      "Baseline Loss: 3.4098 | Actual Loss: 0.7970\n",
      "Baseline Loss: 3.6693 | Actual Loss: 0.6379\n",
      "Baseline Loss: 3.6040 | Actual Loss: 1.4250\n",
      "Baseline Loss: 3.2813 | Actual Loss: 2.2991\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.6919\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.8566\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.8355\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.5323\n",
      "Epoch 62/1000: Train Loss: 1.2292, Val Loss: 0.7291\n",
      "Baseline Loss: 3.3677 | Actual Loss: 1.7678\n",
      "Baseline Loss: 3.3071 | Actual Loss: 0.9051\n",
      "Baseline Loss: 3.6363 | Actual Loss: 1.7600\n",
      "Baseline Loss: 3.4174 | Actual Loss: 0.8794\n",
      "Baseline Loss: 3.4891 | Actual Loss: 0.9514\n",
      "Baseline Loss: 3.4463 | Actual Loss: 1.2035\n",
      "Baseline Loss: 3.4650 | Actual Loss: 1.0621\n",
      "Baseline Loss: 3.2303 | Actual Loss: 0.7479\n",
      "Baseline Loss: 3.6967 | Actual Loss: 0.6321\n",
      "Baseline Loss: 3.6317 | Actual Loss: 0.8851\n",
      "Baseline Loss: 3.5832 | Actual Loss: 0.7383\n",
      "Baseline Loss: 3.6544 | Actual Loss: 1.2347\n",
      "Baseline Loss: 3.7220 | Actual Loss: 1.2858\n",
      "Baseline Loss: 3.4929 | Actual Loss: 0.6853\n",
      "Baseline Loss: 3.6732 | Actual Loss: 0.9159\n",
      "Baseline Loss: 3.2333 | Actual Loss: 0.5622\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.7629\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.8188\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.6264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 63/1000 [00:19<05:05,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7994 | Actual Loss: 0.5488\n",
      "Epoch 63/1000: Train Loss: 1.0135, Val Loss: 0.6893\n",
      "Baseline Loss: 3.4801 | Actual Loss: 0.9007\n",
      "Baseline Loss: 3.7270 | Actual Loss: 2.0277\n",
      "Baseline Loss: 3.7259 | Actual Loss: 0.7438\n",
      "Baseline Loss: 3.4035 | Actual Loss: 1.0332\n",
      "Baseline Loss: 3.6359 | Actual Loss: 1.2345\n",
      "Baseline Loss: 3.4209 | Actual Loss: 0.7594\n",
      "Baseline Loss: 3.6106 | Actual Loss: 1.0296\n",
      "Baseline Loss: 3.4142 | Actual Loss: 0.5670\n",
      "Baseline Loss: 3.6369 | Actual Loss: 0.6168\n",
      "Baseline Loss: 3.4000 | Actual Loss: 1.2768\n",
      "Baseline Loss: 3.6132 | Actual Loss: 1.1000\n",
      "Baseline Loss: 3.1831 | Actual Loss: 0.8681\n",
      "Baseline Loss: 3.5085 | Actual Loss: 1.4070\n",
      "Baseline Loss: 3.5043 | Actual Loss: 0.5229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 64/1000 [00:20<05:10,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5625 | Actual Loss: 0.5448\n",
      "Baseline Loss: 3.3400 | Actual Loss: 1.2800\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.6097\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.6452\n",
      "Baseline Loss: 3.2785 | Actual Loss: 1.0148\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.6357\n",
      "Epoch 64/1000: Train Loss: 0.9945, Val Loss: 0.7264\n",
      "Baseline Loss: 3.4848 | Actual Loss: 1.2735\n",
      "Baseline Loss: 3.5583 | Actual Loss: 0.4313\n",
      "Baseline Loss: 3.6735 | Actual Loss: 2.2103\n",
      "Baseline Loss: 3.5414 | Actual Loss: 0.8637\n",
      "Baseline Loss: 3.5285 | Actual Loss: 0.6996\n",
      "Baseline Loss: 3.3274 | Actual Loss: 0.8494\n",
      "Baseline Loss: 3.6097 | Actual Loss: 0.8531\n",
      "Baseline Loss: 3.7027 | Actual Loss: 0.8619\n",
      "Baseline Loss: 3.6647 | Actual Loss: 0.8853\n",
      "Baseline Loss: 3.5009 | Actual Loss: 1.0518\n",
      "Baseline Loss: 3.5453 | Actual Loss: 1.1798\n",
      "Baseline Loss: 3.3476 | Actual Loss: 0.8648\n",
      "Baseline Loss: 3.5963 | Actual Loss: 0.7445\n",
      "Baseline Loss: 3.2393 | Actual Loss: 0.7836\n",
      "Baseline Loss: 3.3505 | Actual Loss: 0.9883\n",
      "Baseline Loss: 3.1114 | Actual Loss: 0.6160\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.6237\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.6993\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.9187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 65/1000 [00:20<04:55,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7994 | Actual Loss: 0.6223\n",
      "Epoch 65/1000: Train Loss: 0.9473, Val Loss: 0.7160\n",
      "Baseline Loss: 3.4663 | Actual Loss: 1.1166\n",
      "Baseline Loss: 3.5005 | Actual Loss: 1.0403\n",
      "Baseline Loss: 3.6449 | Actual Loss: 1.3509\n",
      "Baseline Loss: 3.4975 | Actual Loss: 0.6611\n",
      "Baseline Loss: 3.6642 | Actual Loss: 0.7537\n",
      "Baseline Loss: 3.5278 | Actual Loss: 0.8981\n",
      "Baseline Loss: 3.2883 | Actual Loss: 0.8010\n",
      "Baseline Loss: 3.4145 | Actual Loss: 0.4495\n",
      "Baseline Loss: 3.6973 | Actual Loss: 0.8258\n",
      "Baseline Loss: 3.5868 | Actual Loss: 0.7544\n",
      "Baseline Loss: 3.4804 | Actual Loss: 0.6544\n",
      "Baseline Loss: 3.5371 | Actual Loss: 1.1033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 66/1000 [00:20<05:04,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6588 | Actual Loss: 3.2611\n",
      "Baseline Loss: 3.4971 | Actual Loss: 1.1594\n",
      "Baseline Loss: 3.5740 | Actual Loss: 1.5667\n",
      "Baseline Loss: 3.3661 | Actual Loss: 0.7176\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.7229\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.6727\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.6636\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.5625\n",
      "Epoch 66/1000: Train Loss: 1.0696, Val Loss: 0.6554\n",
      "Baseline Loss: 3.5622 | Actual Loss: 0.8382\n",
      "Baseline Loss: 3.4281 | Actual Loss: 0.6768\n",
      "Baseline Loss: 3.5448 | Actual Loss: 1.4459\n",
      "Baseline Loss: 3.4358 | Actual Loss: 0.9871\n",
      "Baseline Loss: 3.6092 | Actual Loss: 0.4314\n",
      "Baseline Loss: 3.3674 | Actual Loss: 0.5807\n",
      "Baseline Loss: 3.5163 | Actual Loss: 1.9246\n",
      "Baseline Loss: 3.5788 | Actual Loss: 1.1441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 67/1000 [00:20<04:58,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7999 | Actual Loss: 0.2728\n",
      "Baseline Loss: 3.5204 | Actual Loss: 0.4807\n",
      "Baseline Loss: 3.5089 | Actual Loss: 0.8878\n",
      "Baseline Loss: 3.4112 | Actual Loss: 1.5577\n",
      "Baseline Loss: 3.4076 | Actual Loss: 0.9869\n",
      "Baseline Loss: 3.7631 | Actual Loss: 0.5945\n",
      "Baseline Loss: 3.5667 | Actual Loss: 1.1303\n",
      "Baseline Loss: 3.5507 | Actual Loss: 0.6806\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.5200\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.6246\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.8461\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.5230\n",
      "Epoch 67/1000: Train Loss: 0.9138, Val Loss: 0.6284\n",
      "New best validation loss: 0.6284\n",
      "Baseline Loss: 3.4063 | Actual Loss: 0.6053\n",
      "Baseline Loss: 3.4107 | Actual Loss: 1.1971\n",
      "Baseline Loss: 3.3245 | Actual Loss: 1.1190\n",
      "Baseline Loss: 3.5250 | Actual Loss: 0.9905\n",
      "Baseline Loss: 3.8048 | Actual Loss: 1.5701\n",
      "Baseline Loss: 3.6185 | Actual Loss: 0.9370\n",
      "Baseline Loss: 3.5792 | Actual Loss: 0.7607\n",
      "Baseline Loss: 3.5219 | Actual Loss: 1.2883\n",
      "Baseline Loss: 3.3780 | Actual Loss: 1.1235\n",
      "Baseline Loss: 3.4846 | Actual Loss: 0.9186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 68/1000 [00:21<05:08,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3375 | Actual Loss: 0.7867\n",
      "Baseline Loss: 3.5008 | Actual Loss: 0.8747\n",
      "Baseline Loss: 3.4697 | Actual Loss: 1.3404\n",
      "Baseline Loss: 3.8544 | Actual Loss: 2.3876\n",
      "Baseline Loss: 3.3548 | Actual Loss: 0.7573\n",
      "Baseline Loss: 3.1524 | Actual Loss: 1.4347\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.9306\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.6343\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.7804\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.5137\n",
      "Epoch 68/1000: Train Loss: 1.1307, Val Loss: 0.7147\n",
      "Baseline Loss: 3.5498 | Actual Loss: 1.4592\n",
      "Baseline Loss: 3.4548 | Actual Loss: 1.9893\n",
      "Baseline Loss: 3.5799 | Actual Loss: 0.9851\n",
      "Baseline Loss: 3.3677 | Actual Loss: 0.6247\n",
      "Baseline Loss: 3.6367 | Actual Loss: 1.2432\n",
      "Baseline Loss: 3.5455 | Actual Loss: 0.6479\n",
      "Baseline Loss: 3.2977 | Actual Loss: 1.1676\n",
      "Baseline Loss: 3.4028 | Actual Loss: 1.7087\n",
      "Baseline Loss: 3.4967 | Actual Loss: 0.4517\n",
      "Baseline Loss: 3.5701 | Actual Loss: 1.2375\n",
      "Baseline Loss: 3.4510 | Actual Loss: 0.8794\n",
      "Baseline Loss: 3.6544 | Actual Loss: 0.8479\n",
      "Baseline Loss: 3.6277 | Actual Loss: 0.6315\n",
      "Baseline Loss: 3.6778 | Actual Loss: 0.7527\n",
      "Baseline Loss: 3.4162 | Actual Loss: 0.4317\n",
      "Baseline Loss: 3.2572 | Actual Loss: 0.2278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 69/1000 [00:21<05:14,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6096 | Actual Loss: 0.7920\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.5986\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.6846\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.5058\n",
      "Epoch 69/1000: Train Loss: 0.9554, Val Loss: 0.6453\n",
      "Baseline Loss: 3.4625 | Actual Loss: 0.8004\n",
      "Baseline Loss: 3.4069 | Actual Loss: 1.0998\n",
      "Baseline Loss: 3.5960 | Actual Loss: 1.3359\n",
      "Baseline Loss: 3.4930 | Actual Loss: 2.2291\n",
      "Baseline Loss: 3.6785 | Actual Loss: 1.3569\n",
      "Baseline Loss: 3.4040 | Actual Loss: 0.5193\n",
      "Baseline Loss: 3.5562 | Actual Loss: 0.7421\n",
      "Baseline Loss: 3.3752 | Actual Loss: 0.8454\n",
      "Baseline Loss: 3.5287 | Actual Loss: 0.8740\n",
      "Baseline Loss: 3.4140 | Actual Loss: 0.5680\n",
      "Baseline Loss: 3.6594 | Actual Loss: 1.3966\n",
      "Baseline Loss: 3.5163 | Actual Loss: 0.7565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 70/1000 [00:21<04:55,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5658 | Actual Loss: 1.2244\n",
      "Baseline Loss: 3.3380 | Actual Loss: 0.9033\n",
      "Baseline Loss: 3.7520 | Actual Loss: 0.8481\n",
      "Baseline Loss: 3.1946 | Actual Loss: 0.6594\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.5606\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.7430\n",
      "Baseline Loss: 3.2785 | Actual Loss: 1.0564\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.6369\n",
      "Epoch 70/1000: Train Loss: 1.0100, Val Loss: 0.7492\n",
      "Baseline Loss: 3.4595 | Actual Loss: 0.6759\n",
      "Baseline Loss: 3.6416 | Actual Loss: 0.8272\n",
      "Baseline Loss: 3.4440 | Actual Loss: 0.9132\n",
      "Baseline Loss: 3.4474 | Actual Loss: 1.6134\n",
      "Baseline Loss: 3.6040 | Actual Loss: 1.0048\n",
      "Baseline Loss: 3.6007 | Actual Loss: 0.8504\n",
      "Baseline Loss: 3.3933 | Actual Loss: 1.0704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 71/1000 [00:22<05:05,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4657 | Actual Loss: 0.6947\n",
      "Baseline Loss: 3.6686 | Actual Loss: 0.6004\n",
      "Baseline Loss: 3.4858 | Actual Loss: 0.8947\n",
      "Baseline Loss: 3.4923 | Actual Loss: 1.5547\n",
      "Baseline Loss: 3.3309 | Actual Loss: 1.2140\n",
      "Baseline Loss: 3.3825 | Actual Loss: 0.8364\n",
      "Baseline Loss: 3.6231 | Actual Loss: 0.4015\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.8576\n",
      "Baseline Loss: 3.6175 | Actual Loss: 0.7657\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.5751\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.6274\n",
      "Baseline Loss: 3.2785 | Actual Loss: 1.0268\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.5108\n",
      "Epoch 71/1000: Train Loss: 0.9234, Val Loss: 0.6850\n",
      "Baseline Loss: 3.4056 | Actual Loss: 0.8751\n",
      "Baseline Loss: 3.4930 | Actual Loss: 0.6096\n",
      "Baseline Loss: 3.4252 | Actual Loss: 0.8972\n",
      "Baseline Loss: 3.6361 | Actual Loss: 1.3548\n",
      "Baseline Loss: 3.4179 | Actual Loss: 2.4918\n",
      "Baseline Loss: 3.5093 | Actual Loss: 0.7084\n",
      "Baseline Loss: 3.6004 | Actual Loss: 1.4842\n",
      "Baseline Loss: 3.2949 | Actual Loss: 0.7490\n",
      "Baseline Loss: 3.4398 | Actual Loss: 0.6496\n",
      "Baseline Loss: 3.6822 | Actual Loss: 0.5230\n",
      "Baseline Loss: 3.4625 | Actual Loss: 1.3881\n",
      "Baseline Loss: 3.6268 | Actual Loss: 0.8391\n",
      "Baseline Loss: 3.5749 | Actual Loss: 3.1877\n",
      "Baseline Loss: 3.5160 | Actual Loss: 1.1078\n",
      "Baseline Loss: 3.4814 | Actual Loss: 0.6287\n",
      "Baseline Loss: 3.1670 | Actual Loss: 0.7300\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.9576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 72/1000 [00:22<04:50,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5877 | Actual Loss: 0.7073\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.9407\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.5891\n",
      "Epoch 72/1000: Train Loss: 1.1390, Val Loss: 0.7987\n",
      "Baseline Loss: 3.7470 | Actual Loss: 3.0182\n",
      "Baseline Loss: 3.4471 | Actual Loss: 0.4440\n",
      "Baseline Loss: 3.3769 | Actual Loss: 0.8140\n",
      "Baseline Loss: 3.5365 | Actual Loss: 0.2543\n",
      "Baseline Loss: 3.7519 | Actual Loss: 1.0371\n",
      "Baseline Loss: 3.5017 | Actual Loss: 0.8952\n",
      "Baseline Loss: 3.6009 | Actual Loss: 1.0583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 73/1000 [00:22<05:03,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6274 | Actual Loss: 0.8417\n",
      "Baseline Loss: 3.5957 | Actual Loss: 0.8127\n",
      "Baseline Loss: 3.3918 | Actual Loss: 0.8790\n",
      "Baseline Loss: 3.3574 | Actual Loss: 0.6938\n",
      "Baseline Loss: 3.5009 | Actual Loss: 0.6485\n",
      "Baseline Loss: 3.5370 | Actual Loss: 0.7681\n",
      "Baseline Loss: 3.4109 | Actual Loss: 1.0768\n",
      "Baseline Loss: 3.5053 | Actual Loss: 1.0865\n",
      "Baseline Loss: 3.2342 | Actual Loss: 1.0652\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.8111\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.8250\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.7994\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.4559\n",
      "Epoch 73/1000: Train Loss: 0.9621, Val Loss: 0.7228\n",
      "Baseline Loss: 3.3151 | Actual Loss: 0.9894\n",
      "Baseline Loss: 3.3583 | Actual Loss: 0.8909\n",
      "Baseline Loss: 3.4860 | Actual Loss: 0.6139\n",
      "Baseline Loss: 3.5457 | Actual Loss: 0.7284\n",
      "Baseline Loss: 3.4399 | Actual Loss: 0.8529\n",
      "Baseline Loss: 3.7124 | Actual Loss: 0.8580\n",
      "Baseline Loss: 3.4393 | Actual Loss: 0.5884\n",
      "Baseline Loss: 3.4001 | Actual Loss: 0.6975\n",
      "Baseline Loss: 3.3080 | Actual Loss: 0.5248\n",
      "Baseline Loss: 3.5883 | Actual Loss: 0.8534\n",
      "Baseline Loss: 3.7269 | Actual Loss: 1.1345\n",
      "Baseline Loss: 3.6782 | Actual Loss: 1.0031\n",
      "Baseline Loss: 3.6144 | Actual Loss: 1.5794\n",
      "Baseline Loss: 3.6008 | Actual Loss: 1.1622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 74/1000 [00:23<05:02,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6412 | Actual Loss: 1.0192\n",
      "Baseline Loss: 3.2977 | Actual Loss: 1.0914\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.6957\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.7645\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.9310\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.6026\n",
      "Epoch 74/1000: Train Loss: 0.9117, Val Loss: 0.7485\n",
      "Baseline Loss: 3.6267 | Actual Loss: 0.9368\n",
      "Baseline Loss: 3.4976 | Actual Loss: 1.1243\n",
      "Baseline Loss: 3.4127 | Actual Loss: 0.9005\n",
      "Baseline Loss: 3.3476 | Actual Loss: 1.1652\n",
      "Baseline Loss: 3.6002 | Actual Loss: 0.9817\n",
      "Baseline Loss: 3.4544 | Actual Loss: 0.7426\n",
      "Baseline Loss: 3.5783 | Actual Loss: 0.7157\n",
      "Baseline Loss: 3.6000 | Actual Loss: 0.9445\n",
      "Baseline Loss: 3.3316 | Actual Loss: 0.8568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 75/1000 [00:23<04:44,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5751 | Actual Loss: 1.2364\n",
      "Baseline Loss: 3.6833 | Actual Loss: 1.1175\n",
      "Baseline Loss: 3.3140 | Actual Loss: 1.1283\n",
      "Baseline Loss: 3.6265 | Actual Loss: 0.5665\n",
      "Baseline Loss: 3.7177 | Actual Loss: 1.5387\n",
      "Baseline Loss: 3.5868 | Actual Loss: 1.7332\n",
      "Baseline Loss: 3.3751 | Actual Loss: 1.0573\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.6782\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.8492\n",
      "Baseline Loss: 3.2785 | Actual Loss: 1.0606\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.6753\n",
      "Epoch 75/1000: Train Loss: 1.0466, Val Loss: 0.8158\n",
      "Baseline Loss: 3.4782 | Actual Loss: 0.7923\n",
      "Baseline Loss: 3.6499 | Actual Loss: 0.6250\n",
      "Baseline Loss: 3.3408 | Actual Loss: 0.8751\n",
      "Baseline Loss: 3.5170 | Actual Loss: 0.8764\n",
      "Baseline Loss: 3.4971 | Actual Loss: 0.6423\n",
      "Baseline Loss: 3.5131 | Actual Loss: 0.8228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 76/1000 [00:23<04:56,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5134 | Actual Loss: 0.6322\n",
      "Baseline Loss: 3.4735 | Actual Loss: 0.9944\n",
      "Baseline Loss: 3.5289 | Actual Loss: 1.1252\n",
      "Baseline Loss: 3.3337 | Actual Loss: 0.8628\n",
      "Baseline Loss: 3.4893 | Actual Loss: 1.2473\n",
      "Baseline Loss: 3.6002 | Actual Loss: 0.6026\n",
      "Baseline Loss: 3.3773 | Actual Loss: 0.7828\n",
      "Baseline Loss: 3.6687 | Actual Loss: 1.3220\n",
      "Baseline Loss: 3.6010 | Actual Loss: 1.0803\n",
      "Baseline Loss: 3.1238 | Actual Loss: 1.1022\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.5538\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.5979\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.6311\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.5672\n",
      "Epoch 76/1000: Train Loss: 0.8991, Val Loss: 0.5875\n",
      "New best validation loss: 0.5875\n",
      "Baseline Loss: 3.7418 | Actual Loss: 0.8385\n",
      "Baseline Loss: 3.5706 | Actual Loss: 0.8787\n",
      "Baseline Loss: 3.6874 | Actual Loss: 0.9581\n",
      "Baseline Loss: 3.4554 | Actual Loss: 0.8443\n",
      "Baseline Loss: 3.4735 | Actual Loss: 0.7651\n",
      "Baseline Loss: 3.5625 | Actual Loss: 0.9607\n",
      "Baseline Loss: 3.5298 | Actual Loss: 1.3597\n",
      "Baseline Loss: 3.5830 | Actual Loss: 0.8688\n",
      "Baseline Loss: 3.3657 | Actual Loss: 0.8633\n",
      "Baseline Loss: 3.5079 | Actual Loss: 0.5142\n",
      "Baseline Loss: 3.5333 | Actual Loss: 0.8181\n",
      "Baseline Loss: 3.4665 | Actual Loss: 0.7783\n",
      "Baseline Loss: 3.4655 | Actual Loss: 0.4043\n",
      "Baseline Loss: 3.5742 | Actual Loss: 0.8001\n",
      "Baseline Loss: 3.5378 | Actual Loss: 1.1184\n",
      "Baseline Loss: 3.1883 | Actual Loss: 0.5915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 77/1000 [00:24<04:38,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6096 | Actual Loss: 0.8573\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.6663\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.5462\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.4185\n",
      "Epoch 77/1000: Train Loss: 0.8351, Val Loss: 0.6221\n",
      "Baseline Loss: 3.7524 | Actual Loss: 3.1332\n",
      "Baseline Loss: 3.5748 | Actual Loss: 0.5892\n",
      "Baseline Loss: 3.4617 | Actual Loss: 1.7482\n",
      "Baseline Loss: 3.4359 | Actual Loss: 3.1080\n",
      "Baseline Loss: 3.4322 | Actual Loss: 2.3212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 78/1000 [00:24<04:50,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6726 | Actual Loss: 0.5149\n",
      "Baseline Loss: 3.3825 | Actual Loss: 0.9231\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.9187\n",
      "Baseline Loss: 3.6502 | Actual Loss: 1.0935\n",
      "Baseline Loss: 3.7832 | Actual Loss: 1.1847\n",
      "Baseline Loss: 3.4322 | Actual Loss: 1.7602\n",
      "Baseline Loss: 3.5715 | Actual Loss: 0.9043\n",
      "Baseline Loss: 3.3082 | Actual Loss: 0.9809\n",
      "Baseline Loss: 3.4890 | Actual Loss: 0.7831\n",
      "Baseline Loss: 3.5044 | Actual Loss: 0.8643\n",
      "Baseline Loss: 3.5616 | Actual Loss: 0.8409\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.6995\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.7306\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.9278\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.6398\n",
      "Epoch 78/1000: Train Loss: 1.3543, Val Loss: 0.7494\n",
      "Baseline Loss: 3.4277 | Actual Loss: 0.8829\n",
      "Baseline Loss: 3.8545 | Actual Loss: 1.1739\n",
      "Baseline Loss: 3.3820 | Actual Loss: 0.6272\n",
      "Baseline Loss: 3.4848 | Actual Loss: 1.1561\n",
      "Baseline Loss: 3.4027 | Actual Loss: 0.7187\n",
      "Baseline Loss: 3.5402 | Actual Loss: 0.9272\n",
      "Baseline Loss: 3.7124 | Actual Loss: 0.9604\n",
      "Baseline Loss: 3.6007 | Actual Loss: 0.8880\n",
      "Baseline Loss: 3.2404 | Actual Loss: 0.8371\n",
      "Baseline Loss: 3.5694 | Actual Loss: 1.3504\n",
      "Baseline Loss: 3.5376 | Actual Loss: 0.9245\n",
      "Baseline Loss: 3.3850 | Actual Loss: 0.7673\n",
      "Baseline Loss: 3.2504 | Actual Loss: 0.8942\n",
      "Baseline Loss: 3.5833 | Actual Loss: 0.9235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 79/1000 [00:24<04:57,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.8547 | Actual Loss: 1.2932\n",
      "Baseline Loss: 3.2498 | Actual Loss: 0.5743\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.6494\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.6479\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.8039\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.5751\n",
      "Epoch 79/1000: Train Loss: 0.9312, Val Loss: 0.6690\n",
      "Baseline Loss: 3.3402 | Actual Loss: 0.5755\n",
      "Baseline Loss: 3.6092 | Actual Loss: 0.6473\n",
      "Baseline Loss: 3.4885 | Actual Loss: 0.4970\n",
      "Baseline Loss: 3.5885 | Actual Loss: 1.0301\n",
      "Baseline Loss: 3.4091 | Actual Loss: 0.9309\n",
      "Baseline Loss: 3.4545 | Actual Loss: 0.9545\n",
      "Baseline Loss: 3.3542 | Actual Loss: 0.9666\n",
      "Baseline Loss: 3.4131 | Actual Loss: 0.8297\n",
      "Baseline Loss: 3.5745 | Actual Loss: 0.6394\n",
      "Baseline Loss: 3.5580 | Actual Loss: 1.2491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 80/1000 [00:25<04:37,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4134 | Actual Loss: 1.3715\n",
      "Baseline Loss: 3.5284 | Actual Loss: 1.2487\n",
      "Baseline Loss: 3.3952 | Actual Loss: 1.3702\n",
      "Baseline Loss: 3.8212 | Actual Loss: 1.8931\n",
      "Baseline Loss: 3.5574 | Actual Loss: 1.2163\n",
      "Baseline Loss: 3.1747 | Actual Loss: 0.7678\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.7781\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.8724\n",
      "Baseline Loss: 3.2785 | Actual Loss: 1.0861\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.6493\n",
      "Epoch 80/1000: Train Loss: 1.0117, Val Loss: 0.8465\n",
      "Baseline Loss: 3.3819 | Actual Loss: 1.0675\n",
      "Baseline Loss: 3.4773 | Actual Loss: 1.1749\n",
      "Baseline Loss: 3.4666 | Actual Loss: 1.2665\n",
      "Baseline Loss: 3.5254 | Actual Loss: 1.0787\n",
      "Baseline Loss: 3.3241 | Actual Loss: 0.9575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 81/1000 [00:25<04:54,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4931 | Actual Loss: 0.7097\n",
      "Baseline Loss: 3.4025 | Actual Loss: 1.2076\n",
      "Baseline Loss: 3.8206 | Actual Loss: 1.0132\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.7921\n",
      "Baseline Loss: 3.4689 | Actual Loss: 0.5799\n",
      "Baseline Loss: 3.9564 | Actual Loss: 0.6408\n",
      "Baseline Loss: 3.4037 | Actual Loss: 1.4138\n",
      "Baseline Loss: 3.9072 | Actual Loss: 1.3185\n",
      "Baseline Loss: 3.4468 | Actual Loss: 1.2124\n",
      "Baseline Loss: 3.5834 | Actual Loss: 0.6626\n",
      "Baseline Loss: 3.3827 | Actual Loss: 1.2292\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.7898\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.6516\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.5726\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.6528\n",
      "Epoch 81/1000: Train Loss: 1.0203, Val Loss: 0.6667\n",
      "Baseline Loss: 3.4849 | Actual Loss: 1.1887\n",
      "Baseline Loss: 3.4434 | Actual Loss: 0.9313\n",
      "Baseline Loss: 3.4468 | Actual Loss: 1.2699\n",
      "Baseline Loss: 3.4393 | Actual Loss: 2.4761\n",
      "Baseline Loss: 3.4578 | Actual Loss: 1.0003\n",
      "Baseline Loss: 3.5293 | Actual Loss: 1.7550\n",
      "Baseline Loss: 3.4463 | Actual Loss: 0.7262\n",
      "Baseline Loss: 3.4592 | Actual Loss: 0.8258\n",
      "Baseline Loss: 3.5788 | Actual Loss: 0.9825\n",
      "Baseline Loss: 3.4283 | Actual Loss: 0.6110\n",
      "Baseline Loss: 3.5323 | Actual Loss: 1.3805\n",
      "Baseline Loss: 3.4965 | Actual Loss: 0.6483\n",
      "Baseline Loss: 3.6052 | Actual Loss: 1.2536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 82/1000 [00:25<04:55,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6682 | Actual Loss: 1.1380\n",
      "Baseline Loss: 3.6551 | Actual Loss: 0.9864\n",
      "Baseline Loss: 3.2650 | Actual Loss: 0.5935\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.7236\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.6168\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.4835\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.6001\n",
      "Epoch 82/1000: Train Loss: 1.1104, Val Loss: 0.6060\n",
      "Baseline Loss: 3.5365 | Actual Loss: 0.8732\n",
      "Baseline Loss: 3.5590 | Actual Loss: 0.9646\n",
      "Baseline Loss: 3.6365 | Actual Loss: 1.3590\n",
      "Baseline Loss: 3.7072 | Actual Loss: 1.2946\n",
      "Baseline Loss: 3.6186 | Actual Loss: 1.1897\n",
      "Baseline Loss: 3.5081 | Actual Loss: 0.4705\n",
      "Baseline Loss: 3.6367 | Actual Loss: 0.6807\n",
      "Baseline Loss: 3.7127 | Actual Loss: 0.6877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 83/1000 [00:26<04:36,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5833 | Actual Loss: 0.7061\n",
      "Baseline Loss: 3.4127 | Actual Loss: 0.9178\n",
      "Baseline Loss: 3.4555 | Actual Loss: 0.7534\n",
      "Baseline Loss: 3.2264 | Actual Loss: 0.6215\n",
      "Baseline Loss: 3.5365 | Actual Loss: 1.2082\n",
      "Baseline Loss: 3.6367 | Actual Loss: 0.6601\n",
      "Baseline Loss: 3.5010 | Actual Loss: 0.7232\n",
      "Baseline Loss: 3.1309 | Actual Loss: 1.0448\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.7392\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.6978\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.8777\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.6652\n",
      "Epoch 83/1000: Train Loss: 0.8847, Val Loss: 0.7450\n",
      "Baseline Loss: 3.6590 | Actual Loss: 0.9454\n",
      "Baseline Loss: 3.7160 | Actual Loss: 0.7079\n",
      "Baseline Loss: 3.5747 | Actual Loss: 0.9906\n",
      "Baseline Loss: 3.6731 | Actual Loss: 0.6875\n",
      "Baseline Loss: 3.5704 | Actual Loss: 0.7641\n",
      "Baseline Loss: 3.6590 | Actual Loss: 0.7144\n",
      "Baseline Loss: 3.2786 | Actual Loss: 1.3162\n",
      "Baseline Loss: 3.5018 | Actual Loss: 1.0449\n",
      "Baseline Loss: 3.5165 | Actual Loss: 0.9327\n",
      "Baseline Loss: 3.7732 | Actual Loss: 0.8629\n",
      "Baseline Loss: 3.3582 | Actual Loss: 0.8366\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.7438\n",
      "Baseline Loss: 3.2302 | Actual Loss: 0.6629\n",
      "Baseline Loss: 3.4241 | Actual Loss: 0.6211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 84/1000 [00:26<04:49,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3782 | Actual Loss: 0.8947\n",
      "Baseline Loss: 3.0988 | Actual Loss: 0.5372\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.6996\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.6874\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.7636\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.5253\n",
      "Epoch 84/1000: Train Loss: 0.8289, Val Loss: 0.6690\n",
      "Baseline Loss: 3.5292 | Actual Loss: 1.3753\n",
      "Baseline Loss: 3.6693 | Actual Loss: 1.1447\n",
      "Baseline Loss: 3.4435 | Actual Loss: 0.8222\n",
      "Baseline Loss: 3.6271 | Actual Loss: 0.9242\n",
      "Baseline Loss: 3.2983 | Actual Loss: 0.9207\n",
      "Baseline Loss: 3.5578 | Actual Loss: 0.7769\n",
      "Baseline Loss: 3.6925 | Actual Loss: 0.9136\n",
      "Baseline Loss: 3.4035 | Actual Loss: 0.7194\n",
      "Baseline Loss: 3.7221 | Actual Loss: 0.6774\n",
      "Baseline Loss: 3.2699 | Actual Loss: 0.9203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 85/1000 [00:26<04:29,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5414 | Actual Loss: 0.9424\n",
      "Baseline Loss: 3.7366 | Actual Loss: 0.9954\n",
      "Baseline Loss: 3.5830 | Actual Loss: 0.5995\n",
      "Baseline Loss: 3.5204 | Actual Loss: 0.9892\n",
      "Baseline Loss: 3.6270 | Actual Loss: 0.7821\n",
      "Baseline Loss: 3.5948 | Actual Loss: 0.4237\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.6686\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.6605\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.6018\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.4878\n",
      "Epoch 85/1000: Train Loss: 0.8704, Val Loss: 0.6047\n",
      "Baseline Loss: 3.8266 | Actual Loss: 1.1147\n",
      "Baseline Loss: 3.6462 | Actual Loss: 0.7643\n",
      "Baseline Loss: 3.6832 | Actual Loss: 0.6998\n",
      "Baseline Loss: 3.4390 | Actual Loss: 0.5780\n",
      "Baseline Loss: 3.6234 | Actual Loss: 0.6775\n",
      "Baseline Loss: 3.7072 | Actual Loss: 1.1569\n",
      "Baseline Loss: 3.4029 | Actual Loss: 1.0532\n",
      "Baseline Loss: 3.2639 | Actual Loss: 1.5983\n",
      "Baseline Loss: 3.4241 | Actual Loss: 0.9103\n",
      "Baseline Loss: 3.3401 | Actual Loss: 0.9191\n",
      "Baseline Loss: 3.4732 | Actual Loss: 0.8050\n",
      "Baseline Loss: 3.4653 | Actual Loss: 0.6364\n",
      "Baseline Loss: 3.4251 | Actual Loss: 0.6364\n",
      "Baseline Loss: 3.5179 | Actual Loss: 0.6447\n",
      "Baseline Loss: 3.4206 | Actual Loss: 1.2855\n",
      "Baseline Loss: 3.4792 | Actual Loss: 0.3561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▊         | 86/1000 [00:26<04:45,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6096 | Actual Loss: 0.6734\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.6697\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.5727\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.5497\n",
      "Epoch 86/1000: Train Loss: 0.8648, Val Loss: 0.6164\n",
      "Baseline Loss: 3.4662 | Actual Loss: 1.1941\n",
      "Baseline Loss: 3.4605 | Actual Loss: 0.8609\n",
      "Baseline Loss: 3.4893 | Actual Loss: 2.3090\n",
      "Baseline Loss: 3.4177 | Actual Loss: 0.7215\n",
      "Baseline Loss: 3.6236 | Actual Loss: 0.9429\n",
      "Baseline Loss: 3.4182 | Actual Loss: 0.6606\n",
      "Baseline Loss: 3.5748 | Actual Loss: 0.6583\n",
      "Baseline Loss: 3.7272 | Actual Loss: 1.4870\n",
      "Baseline Loss: 3.2939 | Actual Loss: 0.9453\n",
      "Baseline Loss: 3.6550 | Actual Loss: 0.6198\n",
      "Baseline Loss: 3.4816 | Actual Loss: 0.7357\n",
      "Baseline Loss: 3.5285 | Actual Loss: 0.5552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▊         | 87/1000 [00:27<04:54,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5489 | Actual Loss: 0.7560\n",
      "Baseline Loss: 3.8157 | Actual Loss: 0.4225\n",
      "Baseline Loss: 3.4500 | Actual Loss: 1.0850\n",
      "Baseline Loss: 3.7395 | Actual Loss: 1.3030\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.9256\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.6296\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.7360\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.5638\n",
      "Epoch 87/1000: Train Loss: 0.9535, Val Loss: 0.7137\n",
      "Baseline Loss: 3.3782 | Actual Loss: 0.9115\n",
      "Baseline Loss: 3.5453 | Actual Loss: 1.5579\n",
      "Baseline Loss: 3.7074 | Actual Loss: 1.2341\n",
      "Baseline Loss: 3.7169 | Actual Loss: 0.5865\n",
      "Baseline Loss: 3.6458 | Actual Loss: 0.7311\n",
      "Baseline Loss: 3.5039 | Actual Loss: 0.8873\n",
      "Baseline Loss: 3.4784 | Actual Loss: 0.8480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 88/1000 [00:27<04:41,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.2974 | Actual Loss: 0.9974\n",
      "Baseline Loss: 3.5371 | Actual Loss: 1.0011\n",
      "Baseline Loss: 3.3108 | Actual Loss: 0.8359\n",
      "Baseline Loss: 3.4767 | Actual Loss: 0.8583\n",
      "Baseline Loss: 3.7073 | Actual Loss: 1.4453\n",
      "Baseline Loss: 3.4145 | Actual Loss: 1.2928\n",
      "Baseline Loss: 3.5751 | Actual Loss: 1.0380\n",
      "Baseline Loss: 3.4362 | Actual Loss: 0.9037\n",
      "Baseline Loss: 3.1827 | Actual Loss: 0.2794\n",
      "Baseline Loss: 3.6096 | Actual Loss: 1.0821\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.6415\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.6365\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.6359\n",
      "Epoch 88/1000: Train Loss: 0.9630, Val Loss: 0.7490\n",
      "Baseline Loss: 3.5503 | Actual Loss: 0.7805\n",
      "Baseline Loss: 3.6058 | Actual Loss: 0.5557\n",
      "Baseline Loss: 3.5368 | Actual Loss: 1.1329\n",
      "Baseline Loss: 3.5036 | Actual Loss: 0.3479\n",
      "Baseline Loss: 3.7891 | Actual Loss: 1.0078\n",
      "Baseline Loss: 3.3459 | Actual Loss: 0.9046\n",
      "Baseline Loss: 3.4252 | Actual Loss: 1.3368\n",
      "Baseline Loss: 3.5710 | Actual Loss: 0.9884\n",
      "Baseline Loss: 3.4289 | Actual Loss: 0.8922\n",
      "Baseline Loss: 3.5624 | Actual Loss: 0.8608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 89/1000 [00:27<04:54,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5095 | Actual Loss: 0.8265\n",
      "Baseline Loss: 3.3383 | Actual Loss: 0.9607\n",
      "Baseline Loss: 3.5170 | Actual Loss: 0.9672\n",
      "Baseline Loss: 3.4228 | Actual Loss: 0.6318\n",
      "Baseline Loss: 3.6627 | Actual Loss: 0.7377\n",
      "Baseline Loss: 3.3307 | Actual Loss: 0.9571\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.6862\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.7528\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.7792\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.5572\n",
      "Epoch 89/1000: Train Loss: 0.8680, Val Loss: 0.6938\n",
      "Baseline Loss: 3.4506 | Actual Loss: 0.5832\n",
      "Baseline Loss: 3.4430 | Actual Loss: 0.5965\n",
      "Baseline Loss: 3.5219 | Actual Loss: 0.8272\n",
      "Baseline Loss: 3.6456 | Actual Loss: 1.6367\n",
      "Baseline Loss: 3.6142 | Actual Loss: 0.4574\n",
      "Baseline Loss: 3.4823 | Actual Loss: 0.7686\n",
      "Baseline Loss: 3.3889 | Actual Loss: 0.6211\n",
      "Baseline Loss: 3.5783 | Actual Loss: 0.8195\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.7034\n",
      "Baseline Loss: 3.6003 | Actual Loss: 1.3899\n",
      "Baseline Loss: 3.3605 | Actual Loss: 0.7895\n",
      "Baseline Loss: 3.5925 | Actual Loss: 1.1158\n",
      "Baseline Loss: 3.3751 | Actual Loss: 2.2886\n",
      "Baseline Loss: 3.3334 | Actual Loss: 1.2804\n",
      "Baseline Loss: 3.4463 | Actual Loss: 0.9392\n",
      "Baseline Loss: 3.1054 | Actual Loss: 0.5153\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.5355\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.7038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 90/1000 [00:28<04:58,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.2785 | Actual Loss: 0.7809\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.6590\n",
      "Epoch 90/1000: Train Loss: 0.9583, Val Loss: 0.6698\n",
      "Baseline Loss: 3.5880 | Actual Loss: 1.0696\n",
      "Baseline Loss: 3.4107 | Actual Loss: 1.0868\n",
      "Baseline Loss: 3.5171 | Actual Loss: 0.6185\n",
      "Baseline Loss: 3.3055 | Actual Loss: 0.9441\n",
      "Baseline Loss: 3.4769 | Actual Loss: 0.9123\n",
      "Baseline Loss: 3.6232 | Actual Loss: 1.0371\n",
      "Baseline Loss: 3.6326 | Actual Loss: 0.9979\n",
      "Baseline Loss: 3.4276 | Actual Loss: 0.8654\n",
      "Baseline Loss: 3.4175 | Actual Loss: 1.1994\n",
      "Baseline Loss: 3.5656 | Actual Loss: 0.8137\n",
      "Baseline Loss: 3.6550 | Actual Loss: 1.0929\n",
      "Baseline Loss: 3.6144 | Actual Loss: 0.6853\n",
      "Baseline Loss: 3.3746 | Actual Loss: 0.6212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 91/1000 [00:28<04:45,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6228 | Actual Loss: 0.4894\n",
      "Baseline Loss: 3.7072 | Actual Loss: 1.1824\n",
      "Baseline Loss: 3.6286 | Actual Loss: 1.1088\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.6981\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.9101\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.4662\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.4914\n",
      "Epoch 91/1000: Train Loss: 0.9203, Val Loss: 0.6415\n",
      "Baseline Loss: 3.6411 | Actual Loss: 0.4514\n",
      "Baseline Loss: 3.5328 | Actual Loss: 0.9166\n",
      "Baseline Loss: 3.6050 | Actual Loss: 0.8160\n",
      "Baseline Loss: 3.3448 | Actual Loss: 0.7347\n",
      "Baseline Loss: 3.7268 | Actual Loss: 0.7584\n",
      "Baseline Loss: 3.4894 | Actual Loss: 0.8574\n",
      "Baseline Loss: 3.3332 | Actual Loss: 0.9768\n",
      "Baseline Loss: 3.6789 | Actual Loss: 1.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 92/1000 [00:28<04:57,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6873 | Actual Loss: 0.7377\n",
      "Baseline Loss: 3.3991 | Actual Loss: 0.6403\n",
      "Baseline Loss: 3.5881 | Actual Loss: 1.0506\n",
      "Baseline Loss: 3.2968 | Actual Loss: 0.7013\n",
      "Baseline Loss: 3.5405 | Actual Loss: 0.9204\n",
      "Baseline Loss: 3.5055 | Actual Loss: 0.9547\n",
      "Baseline Loss: 3.4589 | Actual Loss: 1.1274\n",
      "Baseline Loss: 3.3922 | Actual Loss: 1.3067\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.4781\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.6417\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.6474\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.6255\n",
      "Epoch 92/1000: Train Loss: 0.8721, Val Loss: 0.5982\n",
      "Baseline Loss: 3.5082 | Actual Loss: 1.4679\n",
      "Baseline Loss: 3.6547 | Actual Loss: 0.6043\n",
      "Baseline Loss: 3.4816 | Actual Loss: 0.7238\n",
      "Baseline Loss: 3.4211 | Actual Loss: 0.9901\n",
      "Baseline Loss: 3.9317 | Actual Loss: 0.9068\n",
      "Baseline Loss: 3.6737 | Actual Loss: 0.9927\n",
      "Baseline Loss: 3.6146 | Actual Loss: 0.7397\n",
      "Baseline Loss: 3.5664 | Actual Loss: 0.7710\n",
      "Baseline Loss: 3.4100 | Actual Loss: 0.7956\n",
      "Baseline Loss: 3.5124 | Actual Loss: 1.0605\n",
      "Baseline Loss: 3.5492 | Actual Loss: 1.0374\n",
      "Baseline Loss: 3.3552 | Actual Loss: 0.5764\n",
      "Baseline Loss: 3.2481 | Actual Loss: 0.7225\n",
      "Baseline Loss: 3.4427 | Actual Loss: 0.9927\n",
      "Baseline Loss: 3.4659 | Actual Loss: 0.5369\n",
      "Baseline Loss: 3.2354 | Actual Loss: 1.8687\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.6970\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.7491\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.7222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 93/1000 [00:29<04:34,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7994 | Actual Loss: 0.6377\n",
      "Epoch 93/1000: Train Loss: 0.9242, Val Loss: 0.7015\n",
      "Baseline Loss: 3.5289 | Actual Loss: 0.8692\n",
      "Baseline Loss: 3.4512 | Actual Loss: 0.4102\n",
      "Baseline Loss: 3.5009 | Actual Loss: 1.3410\n",
      "Baseline Loss: 3.5835 | Actual Loss: 1.1053\n",
      "Baseline Loss: 3.5405 | Actual Loss: 0.5466\n",
      "Baseline Loss: 3.6276 | Actual Loss: 0.6631\n",
      "Baseline Loss: 3.5707 | Actual Loss: 0.8570\n",
      "Baseline Loss: 3.3048 | Actual Loss: 0.7807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 94/1000 [00:29<04:51,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3856 | Actual Loss: 0.4553\n",
      "Baseline Loss: 3.6095 | Actual Loss: 1.3107\n",
      "Baseline Loss: 3.6235 | Actual Loss: 1.2964\n",
      "Baseline Loss: 3.4891 | Actual Loss: 1.0217\n",
      "Baseline Loss: 3.6837 | Actual Loss: 1.6244\n",
      "Baseline Loss: 3.4143 | Actual Loss: 0.7587\n",
      "Baseline Loss: 3.5376 | Actual Loss: 0.9032\n",
      "Baseline Loss: 3.2980 | Actual Loss: 0.3372\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.5416\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.6979\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.8276\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.4993\n",
      "Epoch 94/1000: Train Loss: 0.8925, Val Loss: 0.6416\n",
      "Baseline Loss: 3.5285 | Actual Loss: 1.0046\n",
      "Baseline Loss: 3.4464 | Actual Loss: 0.7238\n",
      "Baseline Loss: 3.5736 | Actual Loss: 0.8106\n",
      "Baseline Loss: 3.4435 | Actual Loss: 1.7568\n",
      "Baseline Loss: 3.4064 | Actual Loss: 0.9883\n",
      "Baseline Loss: 3.4624 | Actual Loss: 0.9237\n",
      "Baseline Loss: 3.6642 | Actual Loss: 0.8464\n",
      "Baseline Loss: 3.4545 | Actual Loss: 0.8781\n",
      "Baseline Loss: 3.7177 | Actual Loss: 0.8438\n",
      "Baseline Loss: 3.5287 | Actual Loss: 0.9440\n",
      "Baseline Loss: 3.6101 | Actual Loss: 1.0227\n",
      "Baseline Loss: 3.5824 | Actual Loss: 0.5260\n",
      "Baseline Loss: 3.7073 | Actual Loss: 1.0426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 95/1000 [00:29<04:56,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5622 | Actual Loss: 0.4311\n",
      "Baseline Loss: 3.4654 | Actual Loss: 0.9219\n",
      "Baseline Loss: 3.3403 | Actual Loss: 0.4952\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.5589\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.6682\n",
      "Baseline Loss: 3.2785 | Actual Loss: 1.0626\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.6879\n",
      "Epoch 95/1000: Train Loss: 0.8850, Val Loss: 0.7444\n",
      "Baseline Loss: 3.5920 | Actual Loss: 0.8881\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.0867\n",
      "Baseline Loss: 3.4085 | Actual Loss: 0.9544\n",
      "Baseline Loss: 3.3472 | Actual Loss: 0.7452\n",
      "Baseline Loss: 3.7731 | Actual Loss: 1.3109\n",
      "Baseline Loss: 3.5448 | Actual Loss: 0.6046\n",
      "Baseline Loss: 3.5927 | Actual Loss: 0.8506\n",
      "Baseline Loss: 3.7023 | Actual Loss: 0.9810\n",
      "Baseline Loss: 3.6643 | Actual Loss: 1.1006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 96/1000 [00:30<04:36,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5289 | Actual Loss: 1.0100\n",
      "Baseline Loss: 3.6266 | Actual Loss: 0.7888\n",
      "Baseline Loss: 3.4581 | Actual Loss: 0.6864\n",
      "Baseline Loss: 3.5010 | Actual Loss: 0.4582\n",
      "Baseline Loss: 3.3480 | Actual Loss: 0.6957\n",
      "Baseline Loss: 3.4401 | Actual Loss: 0.4703\n",
      "Baseline Loss: 3.2108 | Actual Loss: 1.6520\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.8261\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.5965\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.5407\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.5963\n",
      "Epoch 96/1000: Train Loss: 0.8927, Val Loss: 0.6399\n",
      "Baseline Loss: 3.5081 | Actual Loss: 0.6889\n",
      "Baseline Loss: 3.3970 | Actual Loss: 0.8413\n",
      "Baseline Loss: 3.6318 | Actual Loss: 0.9461\n",
      "Baseline Loss: 3.7320 | Actual Loss: 1.0798\n",
      "Baseline Loss: 3.5618 | Actual Loss: 1.8707\n",
      "Baseline Loss: 3.3204 | Actual Loss: 1.0164\n",
      "Baseline Loss: 3.5075 | Actual Loss: 1.2532\n",
      "Baseline Loss: 3.3439 | Actual Loss: 0.5407\n",
      "Baseline Loss: 3.4470 | Actual Loss: 0.8758\n",
      "Baseline Loss: 3.8601 | Actual Loss: 0.8342\n",
      "Baseline Loss: 3.4575 | Actual Loss: 0.7145\n",
      "Baseline Loss: 3.5840 | Actual Loss: 0.8814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 97/1000 [00:30<04:51,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5965 | Actual Loss: 1.8291\n",
      "Baseline Loss: 3.4430 | Actual Loss: 0.6618\n",
      "Baseline Loss: 3.6135 | Actual Loss: 3.4454\n",
      "Baseline Loss: 3.1380 | Actual Loss: 2.6445\n",
      "Baseline Loss: 3.6096 | Actual Loss: 1.4264\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.6390\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.7933\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.7731\n",
      "Epoch 97/1000: Train Loss: 1.2578, Val Loss: 0.9079\n",
      "Baseline Loss: 3.5578 | Actual Loss: 0.5920\n",
      "Baseline Loss: 3.5830 | Actual Loss: 2.7529\n",
      "Baseline Loss: 3.6833 | Actual Loss: 1.3691\n",
      "Baseline Loss: 3.2204 | Actual Loss: 1.4657\n",
      "Baseline Loss: 3.5288 | Actual Loss: 0.8754\n",
      "Baseline Loss: 3.4510 | Actual Loss: 0.6646\n",
      "Baseline Loss: 3.6925 | Actual Loss: 0.7859\n",
      "Baseline Loss: 3.7272 | Actual Loss: 0.6022\n",
      "Baseline Loss: 3.4136 | Actual Loss: 0.9391\n",
      "Baseline Loss: 3.5745 | Actual Loss: 0.5810\n",
      "Baseline Loss: 3.3168 | Actual Loss: 0.9331\n",
      "Baseline Loss: 3.4068 | Actual Loss: 0.7357\n",
      "Baseline Loss: 3.5372 | Actual Loss: 0.6720\n",
      "Baseline Loss: 3.5408 | Actual Loss: 0.8586\n",
      "Baseline Loss: 3.5371 | Actual Loss: 0.9205\n",
      "Baseline Loss: 3.3150 | Actual Loss: 0.7378\n",
      "Baseline Loss: 3.6096 | Actual Loss: 1.2242\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.7089\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.7217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 98/1000 [00:30<04:55,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7994 | Actual Loss: 0.8979\n",
      "Epoch 98/1000: Train Loss: 0.9678, Val Loss: 0.8882\n",
      "Baseline Loss: 3.6596 | Actual Loss: 1.8220\n",
      "Baseline Loss: 3.3966 | Actual Loss: 0.6597\n",
      "Baseline Loss: 3.4772 | Actual Loss: 0.6249\n",
      "Baseline Loss: 3.5044 | Actual Loss: 0.5205\n",
      "Baseline Loss: 3.5538 | Actual Loss: 0.9251\n",
      "Baseline Loss: 3.5167 | Actual Loss: 0.4983\n",
      "Baseline Loss: 3.6598 | Actual Loss: 0.7328\n",
      "Baseline Loss: 3.4615 | Actual Loss: 1.5291\n",
      "Baseline Loss: 3.5446 | Actual Loss: 0.8904\n",
      "Baseline Loss: 3.3440 | Actual Loss: 0.7997\n",
      "Baseline Loss: 3.6010 | Actual Loss: 0.5817\n",
      "Baseline Loss: 3.5879 | Actual Loss: 0.7128\n",
      "Baseline Loss: 3.4037 | Actual Loss: 1.0622\n",
      "Baseline Loss: 3.5834 | Actual Loss: 0.8561\n",
      "Baseline Loss: 3.3997 | Actual Loss: 0.9810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 99/1000 [00:31<04:32,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.2817 | Actual Loss: 1.6031\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.6899\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.6728\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.9392\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.7897\n",
      "Epoch 99/1000: Train Loss: 0.9250, Val Loss: 0.7729\n",
      "Baseline Loss: 3.7075 | Actual Loss: 1.1573\n",
      "Baseline Loss: 3.4923 | Actual Loss: 0.6962\n",
      "Baseline Loss: 3.4771 | Actual Loss: 0.9838\n",
      "Baseline Loss: 3.4661 | Actual Loss: 0.6332\n",
      "Baseline Loss: 3.5208 | Actual Loss: 0.8845\n",
      "Baseline Loss: 3.4583 | Actual Loss: 0.5387\n",
      "Baseline Loss: 3.4319 | Actual Loss: 2.5147\n",
      "Baseline Loss: 3.4924 | Actual Loss: 1.2590\n",
      "Baseline Loss: 3.4432 | Actual Loss: 0.5271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 100/1000 [00:31<04:49,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4252 | Actual Loss: 0.9504\n",
      "Baseline Loss: 3.7479 | Actual Loss: 0.6879\n",
      "Baseline Loss: 3.5368 | Actual Loss: 0.6557\n",
      "Baseline Loss: 3.8773 | Actual Loss: 1.2087\n",
      "Baseline Loss: 3.2980 | Actual Loss: 0.3419\n",
      "Baseline Loss: 3.4463 | Actual Loss: 0.6441\n",
      "Baseline Loss: 3.6286 | Actual Loss: 0.7441\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.7739\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.6110\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.8153\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.7000\n",
      "Epoch 100/1000: Train Loss: 0.9017, Val Loss: 0.7250\n",
      "Baseline Loss: 3.6002 | Actual Loss: 1.0415\n",
      "Baseline Loss: 3.5674 | Actual Loss: 0.9442\n",
      "Baseline Loss: 3.4669 | Actual Loss: 0.8370\n",
      "Baseline Loss: 3.3182 | Actual Loss: 0.7893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 101/1000 [00:31<04:31,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5534 | Actual Loss: 0.9320\n",
      "Baseline Loss: 3.5488 | Actual Loss: 0.4840\n",
      "Baseline Loss: 3.6834 | Actual Loss: 0.9590\n",
      "Baseline Loss: 3.6546 | Actual Loss: 0.6221\n",
      "Baseline Loss: 3.5335 | Actual Loss: 0.5468\n",
      "Baseline Loss: 3.4615 | Actual Loss: 0.7585\n",
      "Baseline Loss: 3.4702 | Actual Loss: 0.7392\n",
      "Baseline Loss: 3.5335 | Actual Loss: 0.9666\n",
      "Baseline Loss: 3.3828 | Actual Loss: 0.8110\n",
      "Baseline Loss: 3.5583 | Actual Loss: 0.6256\n",
      "Baseline Loss: 3.6196 | Actual Loss: 0.3423\n",
      "Baseline Loss: 3.0091 | Actual Loss: 0.5422\n",
      "Baseline Loss: 3.6096 | Actual Loss: 1.4802\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.5600\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.5047\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.5657\n",
      "Epoch 101/1000: Train Loss: 0.7463, Val Loss: 0.7776\n",
      "Baseline Loss: 3.4804 | Actual Loss: 0.3294\n",
      "Baseline Loss: 3.7474 | Actual Loss: 0.6956\n",
      "Baseline Loss: 3.6598 | Actual Loss: 1.6518\n",
      "Baseline Loss: 3.5666 | Actual Loss: 0.6005\n",
      "Baseline Loss: 3.3209 | Actual Loss: 0.9921\n",
      "Baseline Loss: 3.3677 | Actual Loss: 0.6974\n",
      "Baseline Loss: 3.4583 | Actual Loss: 0.5207\n",
      "Baseline Loss: 3.5288 | Actual Loss: 0.9652\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.7372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 102/1000 [00:32<04:43,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.2790 | Actual Loss: 0.5447\n",
      "Baseline Loss: 3.4133 | Actual Loss: 0.7079\n",
      "Baseline Loss: 3.3958 | Actual Loss: 0.6535\n",
      "Baseline Loss: 3.7630 | Actual Loss: 0.4279\n",
      "Baseline Loss: 3.3611 | Actual Loss: 1.2809\n",
      "Baseline Loss: 3.5453 | Actual Loss: 1.1334\n",
      "Baseline Loss: 3.4399 | Actual Loss: 0.8202\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.6946\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.7256\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.8325\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.6777\n",
      "Epoch 102/1000: Train Loss: 0.7974, Val Loss: 0.7326\n",
      "Baseline Loss: 3.3436 | Actual Loss: 0.6174\n",
      "Baseline Loss: 3.4697 | Actual Loss: 0.7620\n",
      "Baseline Loss: 3.4499 | Actual Loss: 0.8241\n",
      "Baseline Loss: 3.5015 | Actual Loss: 0.8918\n",
      "Baseline Loss: 3.5372 | Actual Loss: 0.5938\n",
      "Baseline Loss: 3.4930 | Actual Loss: 1.2603\n",
      "Baseline Loss: 3.6231 | Actual Loss: 0.6467\n",
      "Baseline Loss: 3.4401 | Actual Loss: 0.7280\n",
      "Baseline Loss: 3.4071 | Actual Loss: 0.8779\n",
      "Baseline Loss: 3.3878 | Actual Loss: 0.6284\n",
      "Baseline Loss: 3.5371 | Actual Loss: 0.8640\n",
      "Baseline Loss: 3.6928 | Actual Loss: 0.3898\n",
      "Baseline Loss: 3.7015 | Actual Loss: 0.7139\n",
      "Baseline Loss: 3.3749 | Actual Loss: 0.8976\n",
      "Baseline Loss: 3.5337 | Actual Loss: 0.8139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 103/1000 [00:32<04:52,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.9410 | Actual Loss: 1.8078\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.6323\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.6448\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.8688\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.6170\n",
      "Epoch 103/1000: Train Loss: 0.8323, Val Loss: 0.6907\n",
      "Baseline Loss: 3.6312 | Actual Loss: 1.2970\n",
      "Baseline Loss: 3.5017 | Actual Loss: 0.9722\n",
      "Baseline Loss: 3.5250 | Actual Loss: 1.0799\n",
      "Baseline Loss: 3.5664 | Actual Loss: 0.9429\n",
      "Baseline Loss: 3.2978 | Actual Loss: 1.0296\n",
      "Baseline Loss: 3.6977 | Actual Loss: 0.4727\n",
      "Baseline Loss: 3.3916 | Actual Loss: 0.7802\n",
      "Baseline Loss: 3.6271 | Actual Loss: 0.7050\n",
      "Baseline Loss: 3.2941 | Actual Loss: 0.6994\n",
      "Baseline Loss: 3.4104 | Actual Loss: 0.4487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 104/1000 [00:32<04:33,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4140 | Actual Loss: 0.7541\n",
      "Baseline Loss: 3.5463 | Actual Loss: 0.6664\n",
      "Baseline Loss: 3.5039 | Actual Loss: 0.5512\n",
      "Baseline Loss: 3.6049 | Actual Loss: 0.8355\n",
      "Baseline Loss: 3.7832 | Actual Loss: 0.8921\n",
      "Baseline Loss: 3.7656 | Actual Loss: 0.3947\n",
      "Baseline Loss: 3.6096 | Actual Loss: 1.0920\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.6080\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.6975\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.6428\n",
      "Epoch 104/1000: Train Loss: 0.7826, Val Loss: 0.7601\n",
      "Baseline Loss: 3.6272 | Actual Loss: 0.6336\n",
      "Baseline Loss: 3.5462 | Actual Loss: 0.9115\n",
      "Baseline Loss: 3.5877 | Actual Loss: 1.6708\n",
      "Baseline Loss: 3.4971 | Actual Loss: 0.6215\n",
      "Baseline Loss: 3.4550 | Actual Loss: 0.6593\n",
      "Baseline Loss: 3.4967 | Actual Loss: 0.7790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 105/1000 [00:33<04:46,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4322 | Actual Loss: 0.8978\n",
      "Baseline Loss: 3.5957 | Actual Loss: 0.6821\n",
      "Baseline Loss: 3.2885 | Actual Loss: 1.3940\n",
      "Baseline Loss: 3.3985 | Actual Loss: 0.7010\n",
      "Baseline Loss: 3.3928 | Actual Loss: 0.8786\n",
      "Baseline Loss: 3.6010 | Actual Loss: 0.5251\n",
      "Baseline Loss: 3.5669 | Actual Loss: 0.8162\n",
      "Baseline Loss: 3.5204 | Actual Loss: 0.6756\n",
      "Baseline Loss: 3.9503 | Actual Loss: 1.1071\n",
      "Baseline Loss: 3.4491 | Actual Loss: 0.6327\n",
      "Baseline Loss: 3.6096 | Actual Loss: 1.1217\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.6039\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.7720\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.6631\n",
      "Epoch 105/1000: Train Loss: 0.8491, Val Loss: 0.7902\n",
      "Baseline Loss: 3.4020 | Actual Loss: 0.8659\n",
      "Baseline Loss: 3.6934 | Actual Loss: 0.8972\n",
      "Baseline Loss: 3.4290 | Actual Loss: 0.3885\n",
      "Baseline Loss: 3.3577 | Actual Loss: 1.5965\n",
      "Baseline Loss: 3.5364 | Actual Loss: 0.8296\n",
      "Baseline Loss: 3.7312 | Actual Loss: 0.8368\n",
      "Baseline Loss: 3.6095 | Actual Loss: 1.2942\n",
      "Baseline Loss: 3.5845 | Actual Loss: 0.7053\n",
      "Baseline Loss: 3.2925 | Actual Loss: 0.7660\n",
      "Baseline Loss: 3.5618 | Actual Loss: 0.8810\n",
      "Baseline Loss: 3.5281 | Actual Loss: 0.6239\n",
      "Baseline Loss: 3.5367 | Actual Loss: 0.4462\n",
      "Baseline Loss: 3.3660 | Actual Loss: 1.0266\n",
      "Baseline Loss: 3.4738 | Actual Loss: 0.6265\n",
      "Baseline Loss: 3.5494 | Actual Loss: 1.2060\n",
      "Baseline Loss: 3.3065 | Actual Loss: 0.8092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 106/1000 [00:33<04:48,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6096 | Actual Loss: 0.7753\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.5845\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.7061\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.5851\n",
      "Epoch 106/1000: Train Loss: 0.8625, Val Loss: 0.6627\n",
      "Baseline Loss: 3.3881 | Actual Loss: 0.4283\n",
      "Baseline Loss: 3.4421 | Actual Loss: 0.8496\n",
      "Baseline Loss: 3.4578 | Actual Loss: 0.7590\n",
      "Baseline Loss: 3.3607 | Actual Loss: 0.6506\n",
      "Baseline Loss: 3.5414 | Actual Loss: 0.6918\n",
      "Baseline Loss: 3.4064 | Actual Loss: 1.1726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 107/1000 [00:33<04:35,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6739 | Actual Loss: 1.4300\n",
      "Baseline Loss: 3.6140 | Actual Loss: 0.8240\n",
      "Baseline Loss: 3.6639 | Actual Loss: 0.6612\n",
      "Baseline Loss: 3.3675 | Actual Loss: 0.6679\n",
      "Baseline Loss: 3.4432 | Actual Loss: 0.4047\n",
      "Baseline Loss: 3.6235 | Actual Loss: 0.9226\n",
      "Baseline Loss: 3.7468 | Actual Loss: 1.0844\n",
      "Baseline Loss: 3.5011 | Actual Loss: 0.6034\n",
      "Baseline Loss: 3.4134 | Actual Loss: 0.8794\n",
      "Baseline Loss: 3.2504 | Actual Loss: 1.8000\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.8485\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.6149\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.7933\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.6221\n",
      "Epoch 107/1000: Train Loss: 0.8643, Val Loss: 0.7197\n",
      "Baseline Loss: 3.5367 | Actual Loss: 0.7494\n",
      "Baseline Loss: 3.4277 | Actual Loss: 0.7393\n",
      "Baseline Loss: 3.6596 | Actual Loss: 2.4831\n",
      "Baseline Loss: 3.6095 | Actual Loss: 0.6863\n",
      "Baseline Loss: 3.4620 | Actual Loss: 0.9400\n",
      "Baseline Loss: 3.4932 | Actual Loss: 0.8460\n",
      "Baseline Loss: 3.5377 | Actual Loss: 0.6406\n",
      "Baseline Loss: 3.6924 | Actual Loss: 0.6886\n",
      "Baseline Loss: 3.6319 | Actual Loss: 0.7984\n",
      "Baseline Loss: 3.4970 | Actual Loss: 0.7230\n",
      "Baseline Loss: 3.5875 | Actual Loss: 0.6018\n",
      "Baseline Loss: 3.2401 | Actual Loss: 0.8593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 108/1000 [00:33<04:43,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5008 | Actual Loss: 1.1625\n",
      "Baseline Loss: 3.4398 | Actual Loss: 0.6886\n",
      "Baseline Loss: 3.5540 | Actual Loss: 0.7745\n",
      "Baseline Loss: 3.1596 | Actual Loss: 0.5112\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.9534\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.6153\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.7988\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.6283\n",
      "Epoch 108/1000: Train Loss: 0.8683, Val Loss: 0.7490\n",
      "Baseline Loss: 3.6057 | Actual Loss: 1.3394\n",
      "Baseline Loss: 3.5793 | Actual Loss: 0.7057\n",
      "Baseline Loss: 3.3936 | Actual Loss: 0.7028\n",
      "Baseline Loss: 3.6052 | Actual Loss: 1.7014\n",
      "Baseline Loss: 3.5088 | Actual Loss: 0.6092\n",
      "Baseline Loss: 3.3924 | Actual Loss: 0.8798\n",
      "Baseline Loss: 3.5912 | Actual Loss: 0.5859\n",
      "Baseline Loss: 3.7021 | Actual Loss: 0.4011\n",
      "Baseline Loss: 3.3990 | Actual Loss: 0.7545\n",
      "Baseline Loss: 3.5960 | Actual Loss: 1.0772\n",
      "Baseline Loss: 3.5216 | Actual Loss: 0.9077\n",
      "Baseline Loss: 3.3656 | Actual Loss: 0.6084\n",
      "Baseline Loss: 3.4474 | Actual Loss: 0.9558\n",
      "Baseline Loss: 3.5410 | Actual Loss: 0.8950\n",
      "Baseline Loss: 3.6927 | Actual Loss: 0.4593\n",
      "Baseline Loss: 3.4399 | Actual Loss: 0.3836\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.6256\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.6752\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.7264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 109/1000 [00:34<04:45,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7994 | Actual Loss: 0.6424\n",
      "Epoch 109/1000: Train Loss: 0.8104, Val Loss: 0.6674\n",
      "Baseline Loss: 3.6406 | Actual Loss: 0.9135\n",
      "Baseline Loss: 3.4619 | Actual Loss: 0.6725\n",
      "Baseline Loss: 3.6009 | Actual Loss: 1.2391\n",
      "Baseline Loss: 3.3555 | Actual Loss: 0.7407\n",
      "Baseline Loss: 3.6190 | Actual Loss: 0.8213\n",
      "Baseline Loss: 3.5050 | Actual Loss: 0.9968\n",
      "Baseline Loss: 3.5537 | Actual Loss: 1.0819\n",
      "Baseline Loss: 3.5839 | Actual Loss: 0.3463\n",
      "Baseline Loss: 3.4975 | Actual Loss: 0.7482\n",
      "Baseline Loss: 3.3965 | Actual Loss: 0.7002\n",
      "Baseline Loss: 3.8835 | Actual Loss: 0.9656\n",
      "Baseline Loss: 3.3935 | Actual Loss: 0.5632\n",
      "Baseline Loss: 3.3715 | Actual Loss: 0.7248\n",
      "Baseline Loss: 3.5913 | Actual Loss: 0.6267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 110/1000 [00:34<04:33,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4520 | Actual Loss: 0.7679\n",
      "Baseline Loss: 2.9838 | Actual Loss: 0.3871\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.6967\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.6186\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.7238\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.6922\n",
      "Epoch 110/1000: Train Loss: 0.7685, Val Loss: 0.6828\n",
      "Baseline Loss: 3.4245 | Actual Loss: 0.6136\n",
      "Baseline Loss: 3.6918 | Actual Loss: 0.6740\n",
      "Baseline Loss: 3.5533 | Actual Loss: 1.8953\n",
      "Baseline Loss: 3.5415 | Actual Loss: 0.6824\n",
      "Baseline Loss: 3.8431 | Actual Loss: 0.7698\n",
      "Baseline Loss: 3.6453 | Actual Loss: 1.0057\n",
      "Baseline Loss: 3.5285 | Actual Loss: 0.4520\n",
      "Baseline Loss: 3.5296 | Actual Loss: 0.6093\n",
      "Baseline Loss: 3.4852 | Actual Loss: 0.8943\n",
      "Baseline Loss: 3.3417 | Actual Loss: 0.6637\n",
      "Baseline Loss: 3.3379 | Actual Loss: 0.7440\n",
      "Baseline Loss: 3.4863 | Actual Loss: 0.9728\n",
      "Baseline Loss: 3.5368 | Actual Loss: 0.6731\n",
      "Baseline Loss: 3.4852 | Actual Loss: 1.1326\n",
      "Baseline Loss: 3.5245 | Actual Loss: 2.6924\n",
      "Baseline Loss: 3.3571 | Actual Loss: 0.6975\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.5637\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.5640\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.6238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 111/1000 [00:34<04:42,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7994 | Actual Loss: 0.7488\n",
      "Epoch 111/1000: Train Loss: 0.9483, Val Loss: 0.6251\n",
      "Baseline Loss: 3.5289 | Actual Loss: 1.5005\n",
      "Baseline Loss: 3.4890 | Actual Loss: 0.3033\n",
      "Baseline Loss: 3.5704 | Actual Loss: 0.6649\n",
      "Baseline Loss: 3.5122 | Actual Loss: 0.6857\n",
      "Baseline Loss: 3.4464 | Actual Loss: 0.7482\n",
      "Baseline Loss: 3.6930 | Actual Loss: 1.4986\n",
      "Baseline Loss: 3.4507 | Actual Loss: 0.5499\n",
      "Baseline Loss: 3.5009 | Actual Loss: 0.6405\n",
      "Baseline Loss: 3.4067 | Actual Loss: 0.6269\n",
      "Baseline Loss: 3.6786 | Actual Loss: 1.8825\n",
      "Baseline Loss: 3.3642 | Actual Loss: 0.5911\n",
      "Baseline Loss: 3.4617 | Actual Loss: 0.4263\n",
      "Baseline Loss: 3.3433 | Actual Loss: 0.6275\n",
      "Baseline Loss: 3.6541 | Actual Loss: 0.4682\n",
      "Baseline Loss: 3.5055 | Actual Loss: 0.6966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 112/1000 [00:35<04:23,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7930 | Actual Loss: 0.9729\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.6010\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.5819\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.6405\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.7566\n",
      "Epoch 112/1000: Train Loss: 0.8052, Val Loss: 0.6450\n",
      "Baseline Loss: 3.4818 | Actual Loss: 1.0315\n",
      "Baseline Loss: 3.6004 | Actual Loss: 0.4362\n",
      "Baseline Loss: 3.4209 | Actual Loss: 1.3139\n",
      "Baseline Loss: 3.5215 | Actual Loss: 0.6226\n",
      "Baseline Loss: 3.7516 | Actual Loss: 0.7844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█▏        | 113/1000 [00:35<04:37,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.2353 | Actual Loss: 0.8616\n",
      "Baseline Loss: 3.5541 | Actual Loss: 0.4876\n",
      "Baseline Loss: 3.4800 | Actual Loss: 1.1949\n",
      "Baseline Loss: 3.6232 | Actual Loss: 0.7442\n",
      "Baseline Loss: 3.7421 | Actual Loss: 0.3816\n",
      "Baseline Loss: 3.4425 | Actual Loss: 0.6389\n",
      "Baseline Loss: 3.4617 | Actual Loss: 0.7592\n",
      "Baseline Loss: 3.3574 | Actual Loss: 0.6987\n",
      "Baseline Loss: 3.4508 | Actual Loss: 0.7720\n",
      "Baseline Loss: 3.5008 | Actual Loss: 0.5754\n",
      "Baseline Loss: 3.2653 | Actual Loss: 2.9384\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.5855\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.6515\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.7215\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.5980\n",
      "Epoch 113/1000: Train Loss: 0.8901, Val Loss: 0.6391\n",
      "Baseline Loss: 3.5168 | Actual Loss: 0.3331\n",
      "Baseline Loss: 3.3087 | Actual Loss: 0.9132\n",
      "Baseline Loss: 3.7993 | Actual Loss: 0.6151\n",
      "Baseline Loss: 3.4513 | Actual Loss: 0.6216\n",
      "Baseline Loss: 3.5833 | Actual Loss: 1.0502\n",
      "Baseline Loss: 3.4957 | Actual Loss: 0.5128\n",
      "Baseline Loss: 3.5796 | Actual Loss: 0.7312\n",
      "Baseline Loss: 3.5329 | Actual Loss: 0.8177\n",
      "Baseline Loss: 3.5663 | Actual Loss: 0.6701\n",
      "Baseline Loss: 3.3608 | Actual Loss: 1.4669\n",
      "Baseline Loss: 3.4848 | Actual Loss: 0.6488\n",
      "Baseline Loss: 3.7074 | Actual Loss: 1.1516\n",
      "Baseline Loss: 3.4469 | Actual Loss: 1.2127\n",
      "Baseline Loss: 3.3893 | Actual Loss: 0.6020\n",
      "Baseline Loss: 3.6271 | Actual Loss: 0.8083\n",
      "Baseline Loss: 3.1676 | Actual Loss: 1.4939\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.7193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█▏        | 114/1000 [00:35<04:42,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5877 | Actual Loss: 0.7123\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.7009\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.4600\n",
      "Epoch 114/1000: Train Loss: 0.8531, Val Loss: 0.6481\n",
      "Baseline Loss: 3.5081 | Actual Loss: 0.9211\n",
      "Baseline Loss: 3.4030 | Actual Loss: 1.6920\n",
      "Baseline Loss: 3.3965 | Actual Loss: 0.5521\n",
      "Baseline Loss: 3.5245 | Actual Loss: 1.0299\n",
      "Baseline Loss: 3.7679 | Actual Loss: 0.7554\n",
      "Baseline Loss: 3.3644 | Actual Loss: 1.0198\n",
      "Baseline Loss: 3.5132 | Actual Loss: 0.8403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 115/1000 [00:36<04:21,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3441 | Actual Loss: 0.7880\n",
      "Baseline Loss: 3.5207 | Actual Loss: 0.5666\n",
      "Baseline Loss: 3.5881 | Actual Loss: 1.4145\n",
      "Baseline Loss: 3.7728 | Actual Loss: 1.3375\n",
      "Baseline Loss: 3.6637 | Actual Loss: 1.1030\n",
      "Baseline Loss: 3.6141 | Actual Loss: 0.6885\n",
      "Baseline Loss: 3.2818 | Actual Loss: 0.8737\n",
      "Baseline Loss: 3.6587 | Actual Loss: 0.9848\n",
      "Baseline Loss: 3.7522 | Actual Loss: 0.4186\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.6846\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.7057\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.7850\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.5943\n",
      "Epoch 115/1000: Train Loss: 0.9366, Val Loss: 0.6924\n",
      "Baseline Loss: 3.7171 | Actual Loss: 0.7357\n",
      "Baseline Loss: 3.4106 | Actual Loss: 0.5837\n",
      "Baseline Loss: 3.5959 | Actual Loss: 1.0640\n",
      "Baseline Loss: 3.5919 | Actual Loss: 0.6650\n",
      "Baseline Loss: 3.5446 | Actual Loss: 1.0522\n",
      "Baseline Loss: 3.4177 | Actual Loss: 0.2854\n",
      "Baseline Loss: 3.6050 | Actual Loss: 0.7942\n",
      "Baseline Loss: 3.3090 | Actual Loss: 0.7004\n",
      "Baseline Loss: 3.5572 | Actual Loss: 0.9802\n",
      "Baseline Loss: 3.5623 | Actual Loss: 0.9734\n",
      "Baseline Loss: 3.5574 | Actual Loss: 0.6088\n",
      "Baseline Loss: 3.6450 | Actual Loss: 0.8561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 116/1000 [00:36<04:38,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3649 | Actual Loss: 0.4975\n",
      "Baseline Loss: 3.5965 | Actual Loss: 1.1916\n",
      "Baseline Loss: 3.5248 | Actual Loss: 0.9590\n",
      "Baseline Loss: 3.3217 | Actual Loss: 0.3270\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.7192\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.7149\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.7298\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.5771\n",
      "Epoch 116/1000: Train Loss: 0.7671, Val Loss: 0.6852\n",
      "Baseline Loss: 3.5929 | Actual Loss: 0.7464\n",
      "Baseline Loss: 3.4245 | Actual Loss: 1.3238\n",
      "Baseline Loss: 3.4971 | Actual Loss: 0.9055\n",
      "Baseline Loss: 3.5124 | Actual Loss: 1.2033\n",
      "Baseline Loss: 3.7990 | Actual Loss: 1.1394\n",
      "Baseline Loss: 3.5010 | Actual Loss: 1.4618\n",
      "Baseline Loss: 3.3335 | Actual Loss: 0.6817\n",
      "Baseline Loss: 3.5835 | Actual Loss: 0.7173\n",
      "Baseline Loss: 3.7664 | Actual Loss: 0.7864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 117/1000 [00:36<04:22,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5335 | Actual Loss: 0.9315\n",
      "Baseline Loss: 3.3894 | Actual Loss: 0.7515\n",
      "Baseline Loss: 3.5208 | Actual Loss: 0.9283\n",
      "Baseline Loss: 3.4971 | Actual Loss: 1.9993\n",
      "Baseline Loss: 3.4419 | Actual Loss: 0.5414\n",
      "Baseline Loss: 3.6050 | Actual Loss: 1.1595\n",
      "Baseline Loss: 3.0579 | Actual Loss: 0.4721\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.5929\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.6910\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.7544\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.7067\n",
      "Epoch 117/1000: Train Loss: 0.9843, Val Loss: 0.6863\n",
      "Baseline Loss: 3.6643 | Actual Loss: 1.0274\n",
      "Baseline Loss: 3.8156 | Actual Loss: 1.8472\n",
      "Baseline Loss: 3.3053 | Actual Loss: 1.2028\n",
      "Baseline Loss: 3.5620 | Actual Loss: 1.7881\n",
      "Baseline Loss: 3.6453 | Actual Loss: 0.7880\n",
      "Baseline Loss: 3.5372 | Actual Loss: 0.7350\n",
      "Baseline Loss: 3.7368 | Actual Loss: 0.2082\n",
      "Baseline Loss: 3.4182 | Actual Loss: 1.0089\n",
      "Baseline Loss: 3.3711 | Actual Loss: 0.7355\n",
      "Baseline Loss: 3.3924 | Actual Loss: 1.0937\n",
      "Baseline Loss: 3.4767 | Actual Loss: 0.5720\n",
      "Baseline Loss: 3.2907 | Actual Loss: 0.8882\n",
      "Baseline Loss: 3.6496 | Actual Loss: 2.2321\n",
      "Baseline Loss: 3.4630 | Actual Loss: 0.5261\n",
      "Baseline Loss: 3.3747 | Actual Loss: 0.7173\n",
      "Baseline Loss: 3.2813 | Actual Loss: 0.8241\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.6275\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.6294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 118/1000 [00:37<04:28,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.2785 | Actual Loss: 0.7707\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.6015\n",
      "Epoch 118/1000: Train Loss: 1.0122, Val Loss: 0.6573\n",
      "Baseline Loss: 3.4735 | Actual Loss: 1.1826\n",
      "Baseline Loss: 3.6270 | Actual Loss: 1.0184\n",
      "Baseline Loss: 3.5329 | Actual Loss: 1.3334\n",
      "Baseline Loss: 3.4481 | Actual Loss: 0.9648\n",
      "Baseline Loss: 3.5444 | Actual Loss: 0.5615\n",
      "Baseline Loss: 3.5798 | Actual Loss: 0.6616\n",
      "Baseline Loss: 3.7468 | Actual Loss: 0.7031\n",
      "Baseline Loss: 3.6443 | Actual Loss: 0.7030\n",
      "Baseline Loss: 3.4070 | Actual Loss: 0.5675\n",
      "Baseline Loss: 3.4398 | Actual Loss: 0.6312\n",
      "Baseline Loss: 3.6550 | Actual Loss: 1.1599\n",
      "Baseline Loss: 3.3478 | Actual Loss: 0.9468\n",
      "Baseline Loss: 3.5123 | Actual Loss: 0.4559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 119/1000 [00:37<04:42,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5419 | Actual Loss: 0.8491\n",
      "Baseline Loss: 3.5661 | Actual Loss: 0.8313\n",
      "Baseline Loss: 3.2810 | Actual Loss: 1.3272\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.4886\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.6355\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.7558\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.6033\n",
      "Epoch 119/1000: Train Loss: 0.8686, Val Loss: 0.6208\n",
      "Baseline Loss: 3.5578 | Actual Loss: 1.1773\n",
      "Baseline Loss: 3.4608 | Actual Loss: 1.2230\n",
      "Baseline Loss: 3.3478 | Actual Loss: 0.7480\n",
      "Baseline Loss: 3.7577 | Actual Loss: 0.8617\n",
      "Baseline Loss: 3.3517 | Actual Loss: 0.7660\n",
      "Baseline Loss: 3.3706 | Actual Loss: 0.6182\n",
      "Baseline Loss: 3.3273 | Actual Loss: 0.4877\n",
      "Baseline Loss: 3.2985 | Actual Loss: 0.9246\n",
      "Baseline Loss: 3.7417 | Actual Loss: 0.5788\n",
      "Baseline Loss: 3.3445 | Actual Loss: 0.5283\n",
      "Baseline Loss: 3.4288 | Actual Loss: 0.6008\n",
      "Baseline Loss: 3.5828 | Actual Loss: 1.2692\n",
      "Baseline Loss: 3.5620 | Actual Loss: 0.5905\n",
      "Baseline Loss: 3.7524 | Actual Loss: 0.9301\n",
      "Baseline Loss: 3.5008 | Actual Loss: 1.6642\n",
      "Baseline Loss: 3.5317 | Actual Loss: 0.5020\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.6370\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.6556\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.6646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 120/1000 [00:37<04:23,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7994 | Actual Loss: 0.6956\n",
      "Epoch 120/1000: Train Loss: 0.8419, Val Loss: 0.6632\n",
      "Baseline Loss: 3.6411 | Actual Loss: 1.0518\n",
      "Baseline Loss: 3.6365 | Actual Loss: 0.9272\n",
      "Baseline Loss: 3.5219 | Actual Loss: 1.2185\n",
      "Baseline Loss: 3.4622 | Actual Loss: 0.8601\n",
      "Baseline Loss: 3.4930 | Actual Loss: 0.5988\n",
      "Baseline Loss: 3.5787 | Actual Loss: 0.7671\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.7677\n",
      "Baseline Loss: 3.7272 | Actual Loss: 0.4629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 121/1000 [00:37<04:36,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3240 | Actual Loss: 0.6744\n",
      "Baseline Loss: 3.4432 | Actual Loss: 0.8071\n",
      "Baseline Loss: 3.5916 | Actual Loss: 0.7873\n",
      "Baseline Loss: 3.4766 | Actual Loss: 0.7815\n",
      "Baseline Loss: 3.3887 | Actual Loss: 0.8568\n",
      "Baseline Loss: 3.4286 | Actual Loss: 0.5962\n",
      "Baseline Loss: 3.6360 | Actual Loss: 0.5675\n",
      "Baseline Loss: 3.2260 | Actual Loss: 0.6424\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.8658\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.6865\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.8118\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.6483\n",
      "Epoch 121/1000: Train Loss: 0.7730, Val Loss: 0.7531\n",
      "Baseline Loss: 3.5742 | Actual Loss: 0.7731\n",
      "Baseline Loss: 3.4027 | Actual Loss: 0.7239\n",
      "Baseline Loss: 3.4655 | Actual Loss: 0.3118\n",
      "Baseline Loss: 3.4887 | Actual Loss: 0.6826\n",
      "Baseline Loss: 3.3276 | Actual Loss: 0.4680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 122/1000 [00:38<04:22,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.2879 | Actual Loss: 0.6971\n",
      "Baseline Loss: 3.7270 | Actual Loss: 0.3267\n",
      "Baseline Loss: 3.6093 | Actual Loss: 1.2206\n",
      "Baseline Loss: 3.5335 | Actual Loss: 1.3101\n",
      "Baseline Loss: 3.7069 | Actual Loss: 1.0223\n",
      "Baseline Loss: 3.6225 | Actual Loss: 0.9369\n",
      "Baseline Loss: 3.4778 | Actual Loss: 0.6167\n",
      "Baseline Loss: 3.4182 | Actual Loss: 0.8609\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.7487\n",
      "Baseline Loss: 3.5539 | Actual Loss: 2.4035\n",
      "Baseline Loss: 3.2813 | Actual Loss: 0.1793\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.9508\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.5646\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.6367\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.7045\n",
      "Epoch 122/1000: Train Loss: 0.8301, Val Loss: 0.7142\n",
      "Baseline Loss: 3.7627 | Actual Loss: 3.0519\n",
      "Baseline Loss: 3.3854 | Actual Loss: 0.9738\n",
      "Baseline Loss: 3.6414 | Actual Loss: 0.8362\n",
      "Baseline Loss: 3.3438 | Actual Loss: 0.7117\n",
      "Baseline Loss: 3.5664 | Actual Loss: 0.5270\n",
      "Baseline Loss: 3.2735 | Actual Loss: 0.8990\n",
      "Baseline Loss: 3.3891 | Actual Loss: 0.7446\n",
      "Baseline Loss: 3.4426 | Actual Loss: 0.8044\n",
      "Baseline Loss: 3.6131 | Actual Loss: 0.7275\n",
      "Baseline Loss: 3.8158 | Actual Loss: 1.0830\n",
      "Baseline Loss: 3.5005 | Actual Loss: 1.1464\n",
      "Baseline Loss: 3.4539 | Actual Loss: 0.4013\n",
      "Baseline Loss: 3.5827 | Actual Loss: 0.8525\n",
      "Baseline Loss: 3.6925 | Actual Loss: 0.5747\n",
      "Baseline Loss: 3.5523 | Actual Loss: 0.9490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 123/1000 [00:38<04:32,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3842 | Actual Loss: 0.5520\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.5153\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.6141\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.6814\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.7178\n",
      "Epoch 123/1000: Train Loss: 0.9272, Val Loss: 0.6322\n",
      "Baseline Loss: 3.3824 | Actual Loss: 0.8664\n",
      "Baseline Loss: 3.5171 | Actual Loss: 0.6535\n",
      "Baseline Loss: 3.4362 | Actual Loss: 0.9309\n",
      "Baseline Loss: 3.5083 | Actual Loss: 0.8939\n",
      "Baseline Loss: 3.2794 | Actual Loss: 0.9628\n",
      "Baseline Loss: 3.6826 | Actual Loss: 0.3019\n",
      "Baseline Loss: 3.4359 | Actual Loss: 0.7315\n",
      "Baseline Loss: 3.4325 | Actual Loss: 0.6091\n",
      "Baseline Loss: 3.6364 | Actual Loss: 0.4707\n",
      "Baseline Loss: 3.5410 | Actual Loss: 0.9848\n",
      "Baseline Loss: 3.6358 | Actual Loss: 0.6312\n",
      "Baseline Loss: 3.6497 | Actual Loss: 0.3880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 124/1000 [00:38<04:41,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4313 | Actual Loss: 0.8414\n",
      "Baseline Loss: 3.6591 | Actual Loss: 1.0075\n",
      "Baseline Loss: 3.5832 | Actual Loss: 1.1853\n",
      "Baseline Loss: 3.3845 | Actual Loss: 0.5835\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.5598\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.6383\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.9412\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.5884\n",
      "Epoch 124/1000: Train Loss: 0.7527, Val Loss: 0.6819\n",
      "Baseline Loss: 3.6546 | Actual Loss: 2.4143\n",
      "Baseline Loss: 3.7079 | Actual Loss: 0.6800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▎        | 125/1000 [00:39<04:20,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4881 | Actual Loss: 0.7176\n",
      "Baseline Loss: 3.5242 | Actual Loss: 0.3797\n",
      "Baseline Loss: 3.3784 | Actual Loss: 0.5752\n",
      "Baseline Loss: 3.6321 | Actual Loss: 1.0746\n",
      "Baseline Loss: 3.5165 | Actual Loss: 0.6063\n",
      "Baseline Loss: 3.3999 | Actual Loss: 1.0184\n",
      "Baseline Loss: 3.5913 | Actual Loss: 2.2098\n",
      "Baseline Loss: 3.3615 | Actual Loss: 0.8414\n",
      "Baseline Loss: 3.4614 | Actual Loss: 1.5079\n",
      "Baseline Loss: 3.4967 | Actual Loss: 0.8886\n",
      "Baseline Loss: 3.4354 | Actual Loss: 0.5659\n",
      "Baseline Loss: 3.4251 | Actual Loss: 1.0835\n",
      "Baseline Loss: 3.4434 | Actual Loss: 0.7259\n",
      "Baseline Loss: 3.7265 | Actual Loss: 0.8218\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.7467\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.6806\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.8216\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.6149\n",
      "Epoch 125/1000: Train Loss: 1.0069, Val Loss: 0.7160\n",
      "Baseline Loss: 3.5618 | Actual Loss: 0.5653\n",
      "Baseline Loss: 3.6049 | Actual Loss: 0.5544\n",
      "Baseline Loss: 3.3748 | Actual Loss: 0.6669\n",
      "Baseline Loss: 3.4811 | Actual Loss: 0.6292\n",
      "Baseline Loss: 3.4932 | Actual Loss: 0.6972\n",
      "Baseline Loss: 3.4725 | Actual Loss: 0.3510\n",
      "Baseline Loss: 3.3963 | Actual Loss: 0.9396\n",
      "Baseline Loss: 3.4738 | Actual Loss: 0.4884\n",
      "Baseline Loss: 3.3249 | Actual Loss: 0.6216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▎        | 125/1000 [00:39<04:36,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5701 | Actual Loss: 0.7192\n",
      "Baseline Loss: 3.4739 | Actual Loss: 0.7988\n",
      "Baseline Loss: 3.6507 | Actual Loss: 0.6408\n",
      "Baseline Loss: 3.4592 | Actual Loss: 0.4080\n",
      "Baseline Loss: 3.7170 | Actual Loss: 1.5326\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.8106\n",
      "Baseline Loss: 3.2719 | Actual Loss: 1.9172\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.6459\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.6187\n",
      "Baseline Loss: 3.2785 | Actual Loss: 0.7739\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.5611\n",
      "Epoch 126/1000: Train Loss: 0.7713, Val Loss: 0.6499\n",
      "\n",
      "Early stopping at epoch 126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5875116735696793"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.train_model(\n",
    "    data_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2080382a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training will be saved to: premodels_new_og/6/0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8753 | Actual Loss: 2.8253\n",
      "Baseline Loss: 2.8410 | Actual Loss: 2.7949\n",
      "Baseline Loss: 2.8826 | Actual Loss: 2.7880\n",
      "Baseline Loss: 2.8142 | Actual Loss: 2.6591\n",
      "Baseline Loss: 2.8904 | Actual Loss: 2.5981\n",
      "Baseline Loss: 2.8623 | Actual Loss: 2.5354\n",
      "Baseline Loss: 2.8330 | Actual Loss: 2.3881\n",
      "Baseline Loss: 2.7555 | Actual Loss: 2.1437\n",
      "Baseline Loss: 2.7994 | Actual Loss: 2.0234\n",
      "Baseline Loss: 2.7514 | Actual Loss: 2.0318\n",
      "Baseline Loss: 2.8606 | Actual Loss: 1.9462\n",
      "Baseline Loss: 2.8047 | Actual Loss: 1.8940\n",
      "Baseline Loss: 2.7910 | Actual Loss: 1.7683\n",
      "Baseline Loss: 2.7916 | Actual Loss: 1.6237\n",
      "Baseline Loss: 2.7596 | Actual Loss: 1.7015\n",
      "Baseline Loss: 2.5788 | Actual Loss: 1.4788\n",
      "Baseline Loss: 2.8321 | Actual Loss: 1.6722\n",
      "Baseline Loss: 2.8514 | Actual Loss: 1.7662\n",
      "Baseline Loss: 2.8204 | Actual Loss: 1.6988\n",
      "Baseline Loss: 2.7416 | Actual Loss: 1.5869\n",
      "Epoch 1/1000: Train Loss: 2.2000, Val Loss: 1.6810\n",
      "New best validation loss: 1.6810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 1/1000 [00:00<07:18,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8450 | Actual Loss: 1.5973\n",
      "Baseline Loss: 2.8009 | Actual Loss: 1.5981\n",
      "Baseline Loss: 2.8426 | Actual Loss: 1.7889\n",
      "Baseline Loss: 2.7531 | Actual Loss: 1.6013\n",
      "Baseline Loss: 2.8416 | Actual Loss: 1.5386\n",
      "Baseline Loss: 2.8887 | Actual Loss: 1.6594\n",
      "Baseline Loss: 2.8320 | Actual Loss: 1.6621\n",
      "Baseline Loss: 2.8453 | Actual Loss: 1.5282\n",
      "Baseline Loss: 2.8308 | Actual Loss: 1.6417\n",
      "Baseline Loss: 2.7865 | Actual Loss: 1.5011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 2/1000 [00:00<06:41,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9019 | Actual Loss: 1.4612\n",
      "Baseline Loss: 2.8850 | Actual Loss: 1.3581\n",
      "Baseline Loss: 2.8433 | Actual Loss: 1.4761\n",
      "Baseline Loss: 2.7708 | Actual Loss: 1.3125\n",
      "Baseline Loss: 2.8166 | Actual Loss: 1.5113\n",
      "Baseline Loss: 2.4000 | Actual Loss: 1.0143\n",
      "Baseline Loss: 2.8321 | Actual Loss: 1.4308\n",
      "Baseline Loss: 2.8514 | Actual Loss: 1.5185\n",
      "Baseline Loss: 2.8204 | Actual Loss: 1.4117\n",
      "Baseline Loss: 2.7416 | Actual Loss: 1.4857\n",
      "Epoch 2/1000: Train Loss: 1.5156, Val Loss: 1.4617\n",
      "New best validation loss: 1.4617\n",
      "Baseline Loss: 2.8770 | Actual Loss: 1.4077\n",
      "Baseline Loss: 2.8569 | Actual Loss: 1.3100\n",
      "Baseline Loss: 2.7658 | Actual Loss: 1.3856\n",
      "Baseline Loss: 2.9035 | Actual Loss: 1.4532\n",
      "Baseline Loss: 2.8656 | Actual Loss: 1.4646\n",
      "Baseline Loss: 2.8101 | Actual Loss: 1.1490\n",
      "Baseline Loss: 2.7952 | Actual Loss: 1.2668\n",
      "Baseline Loss: 2.8255 | Actual Loss: 1.3406\n",
      "Baseline Loss: 2.7814 | Actual Loss: 1.2474\n",
      "Baseline Loss: 2.8732 | Actual Loss: 1.5500\n",
      "Baseline Loss: 2.8349 | Actual Loss: 1.2033\n",
      "Baseline Loss: 2.8490 | Actual Loss: 1.1540\n",
      "Baseline Loss: 2.8113 | Actual Loss: 1.2769\n",
      "Baseline Loss: 2.8007 | Actual Loss: 1.3988\n",
      "Baseline Loss: 2.8519 | Actual Loss: 1.1993\n",
      "Baseline Loss: 2.4941 | Actual Loss: 0.8514\n",
      "Baseline Loss: 2.8321 | Actual Loss: 1.2569\n",
      "Baseline Loss: 2.8514 | Actual Loss: 1.2752\n",
      "Baseline Loss: 2.8204 | Actual Loss: 1.1268\n",
      "Baseline Loss: 2.7416 | Actual Loss: 1.2206\n",
      "Epoch 3/1000: Train Loss: 1.2912, Val Loss: 1.2199\n",
      "New best validation loss: 1.2199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 3/1000 [00:01<07:01,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7812 | Actual Loss: 1.1524\n",
      "Baseline Loss: 2.9567 | Actual Loss: 1.0608\n",
      "Baseline Loss: 2.9018 | Actual Loss: 1.1739\n",
      "Baseline Loss: 2.8440 | Actual Loss: 1.0424\n",
      "Baseline Loss: 2.7708 | Actual Loss: 1.1961\n",
      "Baseline Loss: 2.7926 | Actual Loss: 1.0539\n",
      "Baseline Loss: 2.8684 | Actual Loss: 1.0956\n",
      "Baseline Loss: 2.8000 | Actual Loss: 1.3070\n",
      "Baseline Loss: 2.9340 | Actual Loss: 1.2875\n",
      "Baseline Loss: 2.8367 | Actual Loss: 1.0333\n",
      "Baseline Loss: 2.7606 | Actual Loss: 0.8148\n",
      "Baseline Loss: 2.7970 | Actual Loss: 0.9050\n",
      "Baseline Loss: 2.9057 | Actual Loss: 0.9473\n",
      "Baseline Loss: 2.7952 | Actual Loss: 0.9357\n",
      "Baseline Loss: 2.7460 | Actual Loss: 0.9228\n",
      "Baseline Loss: 2.4898 | Actual Loss: 0.8633\n",
      "Baseline Loss: 2.8321 | Actual Loss: 1.0905\n",
      "Baseline Loss: 2.8514 | Actual Loss: 1.2756\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.8997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 4/1000 [00:01<07:10,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7416 | Actual Loss: 1.1144\n",
      "Epoch 4/1000: Train Loss: 1.0495, Val Loss: 1.0951\n",
      "New best validation loss: 1.0951\n",
      "Baseline Loss: 2.8510 | Actual Loss: 1.0105\n",
      "Baseline Loss: 2.8540 | Actual Loss: 1.1534\n",
      "Baseline Loss: 2.7935 | Actual Loss: 0.9421\n",
      "Baseline Loss: 2.8700 | Actual Loss: 1.0828\n",
      "Baseline Loss: 2.7738 | Actual Loss: 0.9285\n",
      "Baseline Loss: 2.8260 | Actual Loss: 1.0082\n",
      "Baseline Loss: 2.8356 | Actual Loss: 1.1430\n",
      "Baseline Loss: 2.8258 | Actual Loss: 0.9136\n",
      "Baseline Loss: 2.8130 | Actual Loss: 0.9256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 5/1000 [00:02<06:48,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8508 | Actual Loss: 0.9850\n",
      "Baseline Loss: 2.7990 | Actual Loss: 1.0493\n",
      "Baseline Loss: 2.8319 | Actual Loss: 0.9784\n",
      "Baseline Loss: 2.8318 | Actual Loss: 0.7797\n",
      "Baseline Loss: 2.8156 | Actual Loss: 0.8474\n",
      "Baseline Loss: 2.7757 | Actual Loss: 0.7337\n",
      "Baseline Loss: 2.6866 | Actual Loss: 0.7707\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.9875\n",
      "Baseline Loss: 2.8514 | Actual Loss: 1.2356\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.9538\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.9001\n",
      "Epoch 5/1000: Train Loss: 0.9532, Val Loss: 1.0192\n",
      "New best validation loss: 1.0192\n",
      "Baseline Loss: 2.8587 | Actual Loss: 1.0362\n",
      "Baseline Loss: 2.8321 | Actual Loss: 1.2495\n",
      "Baseline Loss: 2.8222 | Actual Loss: 0.9323\n",
      "Baseline Loss: 2.8014 | Actual Loss: 1.1609\n",
      "Baseline Loss: 2.8464 | Actual Loss: 1.1684\n",
      "Baseline Loss: 2.8256 | Actual Loss: 0.8809\n",
      "Baseline Loss: 2.7882 | Actual Loss: 0.9032\n",
      "Baseline Loss: 2.8356 | Actual Loss: 0.9115\n",
      "Baseline Loss: 2.8031 | Actual Loss: 0.7476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 6/1000 [00:02<07:00,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8279 | Actual Loss: 0.8090\n",
      "Baseline Loss: 2.8390 | Actual Loss: 0.8256\n",
      "Baseline Loss: 2.8462 | Actual Loss: 0.9925\n",
      "Baseline Loss: 2.8016 | Actual Loss: 0.6810\n",
      "Baseline Loss: 2.8788 | Actual Loss: 0.9478\n",
      "Baseline Loss: 2.7949 | Actual Loss: 0.8396\n",
      "Baseline Loss: 2.5080 | Actual Loss: 0.3535\n",
      "Baseline Loss: 2.8321 | Actual Loss: 1.0202\n",
      "Baseline Loss: 2.8514 | Actual Loss: 1.1177\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.8478\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.8265\n",
      "Epoch 6/1000: Train Loss: 0.9025, Val Loss: 0.9530\n",
      "New best validation loss: 0.9530\n",
      "Baseline Loss: 2.8205 | Actual Loss: 0.9329\n",
      "Baseline Loss: 2.8569 | Actual Loss: 1.0009\n",
      "Baseline Loss: 2.7977 | Actual Loss: 1.0268\n",
      "Baseline Loss: 2.9051 | Actual Loss: 1.0286\n",
      "Baseline Loss: 2.8567 | Actual Loss: 0.5989\n",
      "Baseline Loss: 2.8090 | Actual Loss: 0.8896\n",
      "Baseline Loss: 2.8734 | Actual Loss: 0.7923\n",
      "Baseline Loss: 2.7611 | Actual Loss: 0.9995\n",
      "Baseline Loss: 2.8048 | Actual Loss: 0.8279\n",
      "Baseline Loss: 2.7960 | Actual Loss: 1.0038\n",
      "Baseline Loss: 2.8249 | Actual Loss: 0.6851\n",
      "Baseline Loss: 2.8504 | Actual Loss: 1.0858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 7/1000 [00:02<06:39,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8396 | Actual Loss: 0.6790\n",
      "Baseline Loss: 2.8685 | Actual Loss: 1.0213\n",
      "Baseline Loss: 2.7978 | Actual Loss: 0.9467\n",
      "Baseline Loss: 2.6108 | Actual Loss: 0.8643\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.7496\n",
      "Baseline Loss: 2.8514 | Actual Loss: 1.0924\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.8264\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.7501\n",
      "Epoch 7/1000: Train Loss: 0.8990, Val Loss: 0.8546\n",
      "New best validation loss: 0.8546\n",
      "Baseline Loss: 2.8645 | Actual Loss: 0.7602\n",
      "Baseline Loss: 2.7661 | Actual Loss: 0.8043\n",
      "Baseline Loss: 2.7767 | Actual Loss: 0.9345\n",
      "Baseline Loss: 2.8551 | Actual Loss: 0.7208\n",
      "Baseline Loss: 2.8935 | Actual Loss: 0.7960\n",
      "Baseline Loss: 2.7913 | Actual Loss: 0.7286\n",
      "Baseline Loss: 2.8140 | Actual Loss: 0.6235\n",
      "Baseline Loss: 2.8618 | Actual Loss: 0.5342\n",
      "Baseline Loss: 2.8251 | Actual Loss: 0.6592\n",
      "Baseline Loss: 2.7982 | Actual Loss: 0.7065\n",
      "Baseline Loss: 2.8250 | Actual Loss: 0.7455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 8/1000 [00:03<06:52,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8858 | Actual Loss: 1.2817\n",
      "Baseline Loss: 2.7759 | Actual Loss: 0.8946\n",
      "Baseline Loss: 2.8343 | Actual Loss: 0.7859\n",
      "Baseline Loss: 2.8251 | Actual Loss: 0.9843\n",
      "Baseline Loss: 2.5800 | Actual Loss: 0.4424\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.6717\n",
      "Baseline Loss: 2.8514 | Actual Loss: 1.1099\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.6611\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.6993\n",
      "Epoch 8/1000: Train Loss: 0.7751, Val Loss: 0.7855\n",
      "New best validation loss: 0.7855\n",
      "Baseline Loss: 2.8630 | Actual Loss: 0.4598\n",
      "Baseline Loss: 2.8893 | Actual Loss: 0.8639\n",
      "Baseline Loss: 2.8553 | Actual Loss: 0.6192\n",
      "Baseline Loss: 2.8510 | Actual Loss: 0.8831\n",
      "Baseline Loss: 2.8387 | Actual Loss: 1.1036\n",
      "Baseline Loss: 2.8563 | Actual Loss: 0.6092\n",
      "Baseline Loss: 2.7536 | Actual Loss: 0.7459\n",
      "Baseline Loss: 2.8408 | Actual Loss: 0.6598\n",
      "Baseline Loss: 2.7818 | Actual Loss: 0.7810\n",
      "Baseline Loss: 2.8290 | Actual Loss: 0.8309\n",
      "Baseline Loss: 2.8030 | Actual Loss: 0.7353\n",
      "Baseline Loss: 2.8226 | Actual Loss: 0.8207\n",
      "Baseline Loss: 2.8358 | Actual Loss: 0.7374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 9/1000 [00:03<07:07,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9062 | Actual Loss: 1.0084\n",
      "Baseline Loss: 2.7874 | Actual Loss: 0.6957\n",
      "Baseline Loss: 2.4873 | Actual Loss: 0.3492\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.6310\n",
      "Baseline Loss: 2.8514 | Actual Loss: 1.0346\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.6175\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.5616\n",
      "Epoch 9/1000: Train Loss: 0.7439, Val Loss: 0.7112\n",
      "New best validation loss: 0.7112\n",
      "Baseline Loss: 2.8396 | Actual Loss: 0.7665\n",
      "Baseline Loss: 2.8784 | Actual Loss: 0.6005\n",
      "Baseline Loss: 2.8106 | Actual Loss: 0.5735\n",
      "Baseline Loss: 2.8439 | Actual Loss: 0.5333\n",
      "Baseline Loss: 2.8843 | Actual Loss: 0.6696\n",
      "Baseline Loss: 2.8220 | Actual Loss: 0.5965\n",
      "Baseline Loss: 2.8794 | Actual Loss: 0.6646\n",
      "Baseline Loss: 2.7699 | Actual Loss: 0.6722\n",
      "Baseline Loss: 2.8370 | Actual Loss: 0.7484\n",
      "Baseline Loss: 2.8614 | Actual Loss: 0.4298\n",
      "Baseline Loss: 2.7961 | Actual Loss: 0.6860\n",
      "Baseline Loss: 2.8339 | Actual Loss: 0.6651\n",
      "Baseline Loss: 2.8392 | Actual Loss: 0.9065\n",
      "Baseline Loss: 2.8043 | Actual Loss: 0.6632\n",
      "Baseline Loss: 2.7463 | Actual Loss: 0.6528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 10/1000 [00:04<06:47,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5014 | Actual Loss: 1.0080\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.6262\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.9034\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.5126\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.5624\n",
      "Epoch 10/1000: Train Loss: 0.6773, Val Loss: 0.6511\n",
      "New best validation loss: 0.6511\n",
      "Baseline Loss: 2.8088 | Actual Loss: 0.6934\n",
      "Baseline Loss: 2.8074 | Actual Loss: 0.7960\n",
      "Baseline Loss: 2.7821 | Actual Loss: 0.4874\n",
      "Baseline Loss: 2.8000 | Actual Loss: 0.7546\n",
      "Baseline Loss: 2.7843 | Actual Loss: 0.8550\n",
      "Baseline Loss: 2.8125 | Actual Loss: 0.5295\n",
      "Baseline Loss: 2.8323 | Actual Loss: 0.7063\n",
      "Baseline Loss: 2.9329 | Actual Loss: 0.5486\n",
      "Baseline Loss: 2.7938 | Actual Loss: 0.5179\n",
      "Baseline Loss: 2.7273 | Actual Loss: 0.8229\n",
      "Baseline Loss: 2.8883 | Actual Loss: 0.4897\n",
      "Baseline Loss: 2.7566 | Actual Loss: 0.4424\n",
      "Baseline Loss: 2.8340 | Actual Loss: 0.4580\n",
      "Baseline Loss: 2.8891 | Actual Loss: 0.4367\n",
      "Baseline Loss: 2.8015 | Actual Loss: 0.7947\n",
      "Baseline Loss: 2.7065 | Actual Loss: 0.3437\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.7418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 11/1000 [00:04<06:59,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8514 | Actual Loss: 1.0484\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.5849\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.8010\n",
      "Epoch 11/1000: Train Loss: 0.6048, Val Loss: 0.7940\n",
      "Baseline Loss: 2.7477 | Actual Loss: 0.5100\n",
      "Baseline Loss: 2.7670 | Actual Loss: 1.1733\n",
      "Baseline Loss: 2.8239 | Actual Loss: 0.7406\n",
      "Baseline Loss: 2.8139 | Actual Loss: 0.6206\n",
      "Baseline Loss: 2.9331 | Actual Loss: 0.6493\n",
      "Baseline Loss: 2.7825 | Actual Loss: 0.7724\n",
      "Baseline Loss: 2.7944 | Actual Loss: 0.7281\n",
      "Baseline Loss: 2.8429 | Actual Loss: 0.7366\n",
      "Baseline Loss: 2.8564 | Actual Loss: 0.8452\n",
      "Baseline Loss: 2.9234 | Actual Loss: 0.4994\n",
      "Baseline Loss: 2.9057 | Actual Loss: 0.6574\n",
      "Baseline Loss: 2.7987 | Actual Loss: 0.5683\n",
      "Baseline Loss: 2.8723 | Actual Loss: 0.6528\n",
      "Baseline Loss: 2.8014 | Actual Loss: 0.5895\n",
      "Baseline Loss: 2.7812 | Actual Loss: 0.4311\n",
      "Baseline Loss: 2.4521 | Actual Loss: 0.2645\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.6394\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.7761\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.5735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 12/1000 [00:05<07:08,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7416 | Actual Loss: 0.7072\n",
      "Epoch 12/1000: Train Loss: 0.6525, Val Loss: 0.6740\n",
      "Baseline Loss: 2.8482 | Actual Loss: 0.5705\n",
      "Baseline Loss: 2.8991 | Actual Loss: 0.7273\n",
      "Baseline Loss: 2.9120 | Actual Loss: 1.0135\n",
      "Baseline Loss: 2.7282 | Actual Loss: 0.7031\n",
      "Baseline Loss: 2.8922 | Actual Loss: 0.7193\n",
      "Baseline Loss: 2.8731 | Actual Loss: 0.8025\n",
      "Baseline Loss: 2.8489 | Actual Loss: 0.6244\n",
      "Baseline Loss: 2.7971 | Actual Loss: 0.6948\n",
      "Baseline Loss: 2.8982 | Actual Loss: 0.9088\n",
      "Baseline Loss: 2.8391 | Actual Loss: 0.7026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏         | 13/1000 [00:05<06:51,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8601 | Actual Loss: 0.6209\n",
      "Baseline Loss: 2.8211 | Actual Loss: 0.5418\n",
      "Baseline Loss: 2.7751 | Actual Loss: 0.7150\n",
      "Baseline Loss: 2.7657 | Actual Loss: 0.4871\n",
      "Baseline Loss: 2.7734 | Actual Loss: 0.5738\n",
      "Baseline Loss: 2.4938 | Actual Loss: 0.5040\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.5040\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.9891\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.4356\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.6148\n",
      "Epoch 13/1000: Train Loss: 0.6818, Val Loss: 0.6359\n",
      "New best validation loss: 0.6359\n",
      "Baseline Loss: 2.8394 | Actual Loss: 0.4284\n",
      "Baseline Loss: 2.7676 | Actual Loss: 0.6477\n",
      "Baseline Loss: 2.8047 | Actual Loss: 0.7623\n",
      "Baseline Loss: 2.8314 | Actual Loss: 0.8162\n",
      "Baseline Loss: 2.8396 | Actual Loss: 0.6241\n",
      "Baseline Loss: 2.8161 | Actual Loss: 0.5035\n",
      "Baseline Loss: 2.8882 | Actual Loss: 0.4040\n",
      "Baseline Loss: 2.7907 | Actual Loss: 0.6751\n",
      "Baseline Loss: 2.8665 | Actual Loss: 0.3153\n",
      "Baseline Loss: 2.8443 | Actual Loss: 0.6243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏         | 14/1000 [00:05<07:04,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7899 | Actual Loss: 0.4774\n",
      "Baseline Loss: 2.8705 | Actual Loss: 0.5073\n",
      "Baseline Loss: 2.8076 | Actual Loss: 0.4740\n",
      "Baseline Loss: 2.7978 | Actual Loss: 0.5455\n",
      "Baseline Loss: 2.8018 | Actual Loss: 0.5135\n",
      "Baseline Loss: 2.5791 | Actual Loss: 0.3302\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.4652\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.9371\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.5316\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.5404\n",
      "Epoch 14/1000: Train Loss: 0.5405, Val Loss: 0.6186\n",
      "New best validation loss: 0.6186\n",
      "Baseline Loss: 2.7420 | Actual Loss: 0.3773\n",
      "Baseline Loss: 2.7732 | Actual Loss: 0.7302\n",
      "Baseline Loss: 2.9269 | Actual Loss: 0.4040\n",
      "Baseline Loss: 2.8064 | Actual Loss: 0.6657\n",
      "Baseline Loss: 2.7759 | Actual Loss: 0.6130\n",
      "Baseline Loss: 2.9696 | Actual Loss: 0.3758\n",
      "Baseline Loss: 2.8440 | Actual Loss: 0.6209\n",
      "Baseline Loss: 2.8889 | Actual Loss: 0.7516\n",
      "Baseline Loss: 2.8543 | Actual Loss: 0.7057\n",
      "Baseline Loss: 2.8058 | Actual Loss: 0.5467\n",
      "Baseline Loss: 2.8157 | Actual Loss: 0.6122\n",
      "Baseline Loss: 2.8500 | Actual Loss: 0.3051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 15/1000 [00:06<06:49,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7750 | Actual Loss: 0.4237\n",
      "Baseline Loss: 2.7888 | Actual Loss: 0.5760\n",
      "Baseline Loss: 2.8260 | Actual Loss: 0.6056\n",
      "Baseline Loss: 2.5254 | Actual Loss: 0.5235\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.4089\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.9037\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.4614\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.4152\n",
      "Epoch 15/1000: Train Loss: 0.5523, Val Loss: 0.5473\n",
      "New best validation loss: 0.5473\n",
      "Baseline Loss: 2.8358 | Actual Loss: 0.4111\n",
      "Baseline Loss: 2.8440 | Actual Loss: 0.3833\n",
      "Baseline Loss: 2.8366 | Actual Loss: 0.4730\n",
      "Baseline Loss: 2.8210 | Actual Loss: 0.5270\n",
      "Baseline Loss: 2.7868 | Actual Loss: 0.4801\n",
      "Baseline Loss: 2.8803 | Actual Loss: 0.3651\n",
      "Baseline Loss: 2.8504 | Actual Loss: 0.4446\n",
      "Baseline Loss: 2.8314 | Actual Loss: 0.6793\n",
      "Baseline Loss: 2.8133 | Actual Loss: 0.5065\n",
      "Baseline Loss: 2.8500 | Actual Loss: 0.4493\n",
      "Baseline Loss: 2.8856 | Actual Loss: 0.6784\n",
      "Baseline Loss: 2.8149 | Actual Loss: 0.7858\n",
      "Baseline Loss: 2.7933 | Actual Loss: 0.4856\n",
      "Baseline Loss: 2.8071 | Actual Loss: 0.5624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 16/1000 [00:06<07:01,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8049 | Actual Loss: 0.6237\n",
      "Baseline Loss: 2.4314 | Actual Loss: 0.4886\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.4757\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.6743\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.5018\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.6904\n",
      "Epoch 16/1000: Train Loss: 0.5215, Val Loss: 0.5855\n",
      "Baseline Loss: 2.7848 | Actual Loss: 0.5217\n",
      "Baseline Loss: 2.8163 | Actual Loss: 0.6600\n",
      "Baseline Loss: 2.8659 | Actual Loss: 0.5325\n",
      "Baseline Loss: 2.8512 | Actual Loss: 0.4191\n",
      "Baseline Loss: 2.7843 | Actual Loss: 0.4411\n",
      "Baseline Loss: 2.8101 | Actual Loss: 0.6871\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.8555\n",
      "Baseline Loss: 2.8484 | Actual Loss: 1.1801\n",
      "Baseline Loss: 2.8060 | Actual Loss: 0.4937\n",
      "Baseline Loss: 2.7794 | Actual Loss: 0.3991\n",
      "Baseline Loss: 2.7969 | Actual Loss: 0.3458\n",
      "Baseline Loss: 2.7624 | Actual Loss: 0.5883\n",
      "Baseline Loss: 2.7816 | Actual Loss: 0.5484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 17/1000 [00:07<07:11,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9283 | Actual Loss: 0.7546\n",
      "Baseline Loss: 2.9059 | Actual Loss: 0.4986\n",
      "Baseline Loss: 2.5812 | Actual Loss: 0.5792\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.5452\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.8437\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.4279\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.4287\n",
      "Epoch 17/1000: Train Loss: 0.5940, Val Loss: 0.5614\n",
      "Baseline Loss: 2.8598 | Actual Loss: 0.4587\n",
      "Baseline Loss: 2.7720 | Actual Loss: 0.3934\n",
      "Baseline Loss: 2.8346 | Actual Loss: 0.3026\n",
      "Baseline Loss: 2.7988 | Actual Loss: 0.7816\n",
      "Baseline Loss: 2.8904 | Actual Loss: 0.7120\n",
      "Baseline Loss: 2.7955 | Actual Loss: 0.7105\n",
      "Baseline Loss: 2.7761 | Actual Loss: 0.4021\n",
      "Baseline Loss: 2.7979 | Actual Loss: 0.4226\n",
      "Baseline Loss: 2.8440 | Actual Loss: 0.5639\n",
      "Baseline Loss: 2.8446 | Actual Loss: 0.4147\n",
      "Baseline Loss: 2.8132 | Actual Loss: 0.4886\n",
      "Baseline Loss: 2.8368 | Actual Loss: 0.5219\n",
      "Baseline Loss: 2.8212 | Actual Loss: 0.5975\n",
      "Baseline Loss: 2.8760 | Actual Loss: 0.4488\n",
      "Baseline Loss: 2.8615 | Actual Loss: 0.6556\n",
      "Baseline Loss: 2.6324 | Actual Loss: 0.6948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 18/1000 [00:07<06:51,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8321 | Actual Loss: 0.4129\n",
      "Baseline Loss: 2.8514 | Actual Loss: 1.0893\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.4103\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.6588\n",
      "Epoch 18/1000: Train Loss: 0.5356, Val Loss: 0.6428\n",
      "Baseline Loss: 2.7433 | Actual Loss: 0.2116\n",
      "Baseline Loss: 2.8072 | Actual Loss: 0.6629\n",
      "Baseline Loss: 2.8513 | Actual Loss: 0.3725\n",
      "Baseline Loss: 2.9237 | Actual Loss: 0.7336\n",
      "Baseline Loss: 2.8555 | Actual Loss: 0.7347\n",
      "Baseline Loss: 2.8247 | Actual Loss: 0.5648\n",
      "Baseline Loss: 2.9014 | Actual Loss: 0.8412\n",
      "Baseline Loss: 2.8988 | Actual Loss: 0.4989\n",
      "Baseline Loss: 2.8194 | Actual Loss: 0.4873\n",
      "Baseline Loss: 2.7981 | Actual Loss: 0.4658\n",
      "Baseline Loss: 2.8358 | Actual Loss: 0.5276\n",
      "Baseline Loss: 2.7718 | Actual Loss: 0.4988\n",
      "Baseline Loss: 2.7722 | Actual Loss: 0.6465\n",
      "Baseline Loss: 2.8942 | Actual Loss: 0.6076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 19/1000 [00:08<07:02,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8450 | Actual Loss: 0.6176\n",
      "Baseline Loss: 2.5335 | Actual Loss: 0.4221\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.4965\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.9597\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.5045\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.5085\n",
      "Epoch 19/1000: Train Loss: 0.5559, Val Loss: 0.6173\n",
      "Baseline Loss: 2.8423 | Actual Loss: 0.6062\n",
      "Baseline Loss: 2.7811 | Actual Loss: 0.3910\n",
      "Baseline Loss: 2.8798 | Actual Loss: 0.4425\n",
      "Baseline Loss: 2.8192 | Actual Loss: 0.4278\n",
      "Baseline Loss: 2.8284 | Actual Loss: 0.6302\n",
      "Baseline Loss: 2.8169 | Actual Loss: 0.5375\n",
      "Baseline Loss: 2.7933 | Actual Loss: 0.6526\n",
      "Baseline Loss: 2.8019 | Actual Loss: 0.4407\n",
      "Baseline Loss: 2.8292 | Actual Loss: 0.3610\n",
      "Baseline Loss: 2.8290 | Actual Loss: 0.3687\n",
      "Baseline Loss: 2.8627 | Actual Loss: 0.3023\n",
      "Baseline Loss: 2.8182 | Actual Loss: 0.3838\n",
      "Baseline Loss: 2.8626 | Actual Loss: 0.4723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 20/1000 [00:08<07:11,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8275 | Actual Loss: 0.5199\n",
      "Baseline Loss: 2.7297 | Actual Loss: 0.4700\n",
      "Baseline Loss: 2.6227 | Actual Loss: 0.2593\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.5096\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.9358\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.4426\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.4128\n",
      "Epoch 20/1000: Train Loss: 0.4541, Val Loss: 0.5752\n",
      "Baseline Loss: 2.8313 | Actual Loss: 0.4606\n",
      "Baseline Loss: 2.7843 | Actual Loss: 0.2550\n",
      "Baseline Loss: 2.8416 | Actual Loss: 0.4366\n",
      "Baseline Loss: 2.8936 | Actual Loss: 0.3306\n",
      "Baseline Loss: 2.8602 | Actual Loss: 0.6867\n",
      "Baseline Loss: 2.8741 | Actual Loss: 0.5742\n",
      "Baseline Loss: 2.8021 | Actual Loss: 0.5023\n",
      "Baseline Loss: 2.8040 | Actual Loss: 0.6908\n",
      "Baseline Loss: 2.8198 | Actual Loss: 0.5759\n",
      "Baseline Loss: 2.8263 | Actual Loss: 0.2854\n",
      "Baseline Loss: 2.7720 | Actual Loss: 0.5910\n",
      "Baseline Loss: 2.8689 | Actual Loss: 0.7076\n",
      "Baseline Loss: 2.9081 | Actual Loss: 0.6064\n",
      "Baseline Loss: 2.7746 | Actual Loss: 0.4993\n",
      "Baseline Loss: 2.8611 | Actual Loss: 0.4033\n",
      "Baseline Loss: 2.5840 | Actual Loss: 0.2525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 21/1000 [00:08<06:55,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8321 | Actual Loss: 0.4408\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.8117\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3807\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.4023\n",
      "Epoch 21/1000: Train Loss: 0.4911, Val Loss: 0.5089\n",
      "New best validation loss: 0.5089\n",
      "Baseline Loss: 2.8739 | Actual Loss: 0.4250\n",
      "Baseline Loss: 2.7899 | Actual Loss: 0.5296\n",
      "Baseline Loss: 2.8102 | Actual Loss: 0.5549\n",
      "Baseline Loss: 2.8209 | Actual Loss: 0.4275\n",
      "Baseline Loss: 2.7784 | Actual Loss: 0.3031\n",
      "Baseline Loss: 2.8059 | Actual Loss: 0.6145\n",
      "Baseline Loss: 2.9169 | Actual Loss: 0.4008\n",
      "Baseline Loss: 2.8232 | Actual Loss: 0.4074\n",
      "Baseline Loss: 2.7865 | Actual Loss: 0.4216\n",
      "Baseline Loss: 2.7775 | Actual Loss: 0.5473\n",
      "Baseline Loss: 2.7946 | Actual Loss: 0.4343\n",
      "Baseline Loss: 2.8662 | Actual Loss: 0.7263\n",
      "Baseline Loss: 2.7985 | Actual Loss: 0.4157\n",
      "Baseline Loss: 2.8458 | Actual Loss: 0.6320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 22/1000 [00:09<07:06,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8848 | Actual Loss: 0.8766\n",
      "Baseline Loss: 2.6544 | Actual Loss: 1.1645\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.4655\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.9423\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.5004\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.4086\n",
      "Epoch 22/1000: Train Loss: 0.5551, Val Loss: 0.5792\n",
      "Baseline Loss: 2.8474 | Actual Loss: 0.5966\n",
      "Baseline Loss: 2.8087 | Actual Loss: 0.5046\n",
      "Baseline Loss: 2.7824 | Actual Loss: 0.4806\n",
      "Baseline Loss: 2.8411 | Actual Loss: 0.6330\n",
      "Baseline Loss: 2.8064 | Actual Loss: 0.2979\n",
      "Baseline Loss: 2.8109 | Actual Loss: 0.6177\n",
      "Baseline Loss: 2.8069 | Actual Loss: 0.4528\n",
      "Baseline Loss: 2.8464 | Actual Loss: 0.4992\n",
      "Baseline Loss: 2.8351 | Actual Loss: 0.4245\n",
      "Baseline Loss: 2.8545 | Actual Loss: 0.4710\n",
      "Baseline Loss: 2.8408 | Actual Loss: 0.2738\n",
      "Baseline Loss: 2.7589 | Actual Loss: 0.4973\n",
      "Baseline Loss: 2.7862 | Actual Loss: 0.4792\n",
      "Baseline Loss: 2.8707 | Actual Loss: 0.4032\n",
      "Baseline Loss: 2.9278 | Actual Loss: 0.5216\n",
      "Baseline Loss: 2.5030 | Actual Loss: 0.2117\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.4743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 23/1000 [00:09<07:07,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8514 | Actual Loss: 0.8912\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.4540\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.3469\n",
      "Epoch 23/1000: Train Loss: 0.4603, Val Loss: 0.5416\n",
      "Baseline Loss: 2.9061 | Actual Loss: 0.6148\n",
      "Baseline Loss: 2.7977 | Actual Loss: 0.4801\n",
      "Baseline Loss: 2.8971 | Actual Loss: 0.9758\n",
      "Baseline Loss: 2.7798 | Actual Loss: 0.4894\n",
      "Baseline Loss: 2.8166 | Actual Loss: 0.7696\n",
      "Baseline Loss: 2.7762 | Actual Loss: 0.4460\n",
      "Baseline Loss: 2.7983 | Actual Loss: 0.4588\n",
      "Baseline Loss: 2.8658 | Actual Loss: 0.4157\n",
      "Baseline Loss: 2.7818 | Actual Loss: 1.0004\n",
      "Baseline Loss: 2.7990 | Actual Loss: 0.4237\n",
      "Baseline Loss: 2.8217 | Actual Loss: 0.3826\n",
      "Baseline Loss: 2.7977 | Actual Loss: 0.4574\n",
      "Baseline Loss: 2.7770 | Actual Loss: 0.4803\n",
      "Baseline Loss: 2.8835 | Actual Loss: 0.2996\n",
      "Baseline Loss: 2.8428 | Actual Loss: 0.5390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 24/1000 [00:10<06:49,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5014 | Actual Loss: 0.2808\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.4684\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.9401\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3946\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.5469\n",
      "Epoch 24/1000: Train Loss: 0.5321, Val Loss: 0.5875\n",
      "Baseline Loss: 2.7520 | Actual Loss: 0.4618\n",
      "Baseline Loss: 2.8296 | Actual Loss: 0.3914\n",
      "Baseline Loss: 2.8398 | Actual Loss: 0.6755\n",
      "Baseline Loss: 2.8934 | Actual Loss: 0.5419\n",
      "Baseline Loss: 2.8144 | Actual Loss: 0.5571\n",
      "Baseline Loss: 2.9007 | Actual Loss: 0.4034\n",
      "Baseline Loss: 2.8861 | Actual Loss: 0.4001\n",
      "Baseline Loss: 2.8381 | Actual Loss: 0.5658\n",
      "Baseline Loss: 2.7934 | Actual Loss: 0.4965\n",
      "Baseline Loss: 2.7981 | Actual Loss: 0.2652\n",
      "Baseline Loss: 2.8546 | Actual Loss: 0.5124\n",
      "Baseline Loss: 2.8565 | Actual Loss: 0.7170\n",
      "Baseline Loss: 2.7623 | Actual Loss: 0.3967\n",
      "Baseline Loss: 2.8419 | Actual Loss: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▎         | 25/1000 [00:10<06:57,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8380 | Actual Loss: 0.6933\n",
      "Baseline Loss: 2.6054 | Actual Loss: 0.5545\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.4285\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.7943\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2968\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.3042\n",
      "Epoch 25/1000: Train Loss: 0.5046, Val Loss: 0.4559\n",
      "New best validation loss: 0.4559\n",
      "Baseline Loss: 2.8114 | Actual Loss: 0.5360\n",
      "Baseline Loss: 2.8531 | Actual Loss: 0.6051\n",
      "Baseline Loss: 2.7831 | Actual Loss: 0.4556\n",
      "Baseline Loss: 2.8380 | Actual Loss: 0.5831\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2859\n",
      "Baseline Loss: 2.8248 | Actual Loss: 0.3649\n",
      "Baseline Loss: 2.8056 | Actual Loss: 0.4857\n",
      "Baseline Loss: 2.7366 | Actual Loss: 0.4237\n",
      "Baseline Loss: 2.7922 | Actual Loss: 0.8512\n",
      "Baseline Loss: 2.8574 | Actual Loss: 0.5431\n",
      "Baseline Loss: 2.8710 | Actual Loss: 0.9024\n",
      "Baseline Loss: 2.8192 | Actual Loss: 0.4008\n",
      "Baseline Loss: 2.8198 | Actual Loss: 0.6643\n",
      "Baseline Loss: 2.8419 | Actual Loss: 0.4503\n",
      "Baseline Loss: 2.8163 | Actual Loss: 0.4993\n",
      "Baseline Loss: 2.6510 | Actual Loss: 0.2476\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.4094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 26/1000 [00:10<06:34,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8514 | Actual Loss: 0.5698\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.4890\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.4614\n",
      "Epoch 26/1000: Train Loss: 0.5187, Val Loss: 0.4824\n",
      "Baseline Loss: 2.8517 | Actual Loss: 0.7909\n",
      "Baseline Loss: 2.8023 | Actual Loss: 0.3388\n",
      "Baseline Loss: 2.8137 | Actual Loss: 1.0907\n",
      "Baseline Loss: 2.8650 | Actual Loss: 0.4218\n",
      "Baseline Loss: 2.8483 | Actual Loss: 0.3944\n",
      "Baseline Loss: 2.7869 | Actual Loss: 0.3050\n",
      "Baseline Loss: 2.8148 | Actual Loss: 0.4118\n",
      "Baseline Loss: 2.7851 | Actual Loss: 0.4202\n",
      "Baseline Loss: 2.8131 | Actual Loss: 0.5701\n",
      "Baseline Loss: 2.8863 | Actual Loss: 0.4196\n",
      "Baseline Loss: 2.8145 | Actual Loss: 0.3800\n",
      "Baseline Loss: 2.7958 | Actual Loss: 0.4593\n",
      "Baseline Loss: 2.8074 | Actual Loss: 0.4763\n",
      "Baseline Loss: 2.7949 | Actual Loss: 0.4521\n",
      "Baseline Loss: 2.8873 | Actual Loss: 0.3964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 27/1000 [00:11<06:51,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6348 | Actual Loss: 0.3467\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.4689\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.6231\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3620\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.3185\n",
      "Epoch 27/1000: Train Loss: 0.4796, Val Loss: 0.4431\n",
      "New best validation loss: 0.4431\n",
      "Baseline Loss: 2.8800 | Actual Loss: 0.3190\n",
      "Baseline Loss: 2.8916 | Actual Loss: 0.7938\n",
      "Baseline Loss: 2.7690 | Actual Loss: 0.3423\n",
      "Baseline Loss: 2.8283 | Actual Loss: 0.3925\n",
      "Baseline Loss: 2.8455 | Actual Loss: 0.5742\n",
      "Baseline Loss: 2.8192 | Actual Loss: 0.4991\n",
      "Baseline Loss: 2.8577 | Actual Loss: 0.5177\n",
      "Baseline Loss: 2.7952 | Actual Loss: 0.4686\n",
      "Baseline Loss: 2.8205 | Actual Loss: 0.5989\n",
      "Baseline Loss: 2.8336 | Actual Loss: 0.3119\n",
      "Baseline Loss: 2.8055 | Actual Loss: 0.3598\n",
      "Baseline Loss: 2.8307 | Actual Loss: 0.6155\n",
      "Baseline Loss: 2.7606 | Actual Loss: 0.3949\n",
      "Baseline Loss: 2.7648 | Actual Loss: 0.3248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 28/1000 [00:11<06:52,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8282 | Actual Loss: 0.3137\n",
      "Baseline Loss: 2.4383 | Actual Loss: 0.2784\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.4300\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.7848\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3732\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.3766\n",
      "Epoch 28/1000: Train Loss: 0.4441, Val Loss: 0.4911\n",
      "Baseline Loss: 2.8073 | Actual Loss: 0.3368\n",
      "Baseline Loss: 2.7858 | Actual Loss: 0.7361\n",
      "Baseline Loss: 2.8184 | Actual Loss: 0.3896\n",
      "Baseline Loss: 2.7752 | Actual Loss: 1.0747\n",
      "Baseline Loss: 2.7995 | Actual Loss: 0.4124\n",
      "Baseline Loss: 2.8429 | Actual Loss: 0.5961\n",
      "Baseline Loss: 2.8796 | Actual Loss: 0.2220\n",
      "Baseline Loss: 2.8222 | Actual Loss: 0.5234\n",
      "Baseline Loss: 2.8485 | Actual Loss: 0.3687\n",
      "Baseline Loss: 2.7855 | Actual Loss: 0.3187\n",
      "Baseline Loss: 2.8461 | Actual Loss: 0.6231\n",
      "Baseline Loss: 2.8094 | Actual Loss: 0.3956\n",
      "Baseline Loss: 2.8675 | Actual Loss: 0.4325\n",
      "Baseline Loss: 2.7664 | Actual Loss: 0.3205\n",
      "Baseline Loss: 2.8663 | Actual Loss: 0.6053\n",
      "Baseline Loss: 2.4849 | Actual Loss: 0.2501\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.4799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 29/1000 [00:12<06:34,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8514 | Actual Loss: 0.6984\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.5939\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.6444\n",
      "Epoch 29/1000: Train Loss: 0.4754, Val Loss: 0.6042\n",
      "Baseline Loss: 2.8148 | Actual Loss: 0.7056\n",
      "Baseline Loss: 2.7783 | Actual Loss: 0.3177\n",
      "Baseline Loss: 2.8137 | Actual Loss: 0.2723\n",
      "Baseline Loss: 2.8509 | Actual Loss: 0.2749\n",
      "Baseline Loss: 2.7970 | Actual Loss: 0.5054\n",
      "Baseline Loss: 2.8503 | Actual Loss: 0.3077\n",
      "Baseline Loss: 2.9172 | Actual Loss: 0.3501\n",
      "Baseline Loss: 2.8184 | Actual Loss: 0.2976\n",
      "Baseline Loss: 2.7782 | Actual Loss: 0.3206\n",
      "Baseline Loss: 2.7931 | Actual Loss: 0.3684\n",
      "Baseline Loss: 2.8455 | Actual Loss: 0.7340\n",
      "Baseline Loss: 2.8319 | Actual Loss: 0.4864\n",
      "Baseline Loss: 2.8751 | Actual Loss: 0.3550\n",
      "Baseline Loss: 2.8683 | Actual Loss: 0.4313\n",
      "Baseline Loss: 2.8886 | Actual Loss: 0.6450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 30/1000 [00:12<06:47,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5708 | Actual Loss: 0.3401\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.3978\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.6643\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.4235\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.7761\n",
      "Epoch 30/1000: Train Loss: 0.4195, Val Loss: 0.5654\n",
      "Baseline Loss: 2.7062 | Actual Loss: 0.4112\n",
      "Baseline Loss: 2.8415 | Actual Loss: 0.3050\n",
      "Baseline Loss: 2.8845 | Actual Loss: 0.6172\n",
      "Baseline Loss: 2.8337 | Actual Loss: 0.4842\n",
      "Baseline Loss: 2.8151 | Actual Loss: 0.6920\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.4123\n",
      "Baseline Loss: 2.7905 | Actual Loss: 0.5526\n",
      "Baseline Loss: 2.8709 | Actual Loss: 0.3901\n",
      "Baseline Loss: 2.9016 | Actual Loss: 0.4334\n",
      "Baseline Loss: 2.7863 | Actual Loss: 0.7032\n",
      "Baseline Loss: 2.8175 | Actual Loss: 0.3789\n",
      "Baseline Loss: 2.8476 | Actual Loss: 0.5116\n",
      "Baseline Loss: 2.8706 | Actual Loss: 0.2678\n",
      "Baseline Loss: 2.8153 | Actual Loss: 0.3159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 31/1000 [00:13<06:50,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7388 | Actual Loss: 0.5291\n",
      "Baseline Loss: 2.5918 | Actual Loss: 0.6956\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.4972\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.6140\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.4470\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.4615\n",
      "Epoch 31/1000: Train Loss: 0.4813, Val Loss: 0.5049\n",
      "Baseline Loss: 2.8379 | Actual Loss: 0.6932\n",
      "Baseline Loss: 2.8169 | Actual Loss: 0.4174\n",
      "Baseline Loss: 2.8432 | Actual Loss: 0.6577\n",
      "Baseline Loss: 2.8552 | Actual Loss: 0.4554\n",
      "Baseline Loss: 2.8827 | Actual Loss: 0.5673\n",
      "Baseline Loss: 2.8081 | Actual Loss: 0.3556\n",
      "Baseline Loss: 2.8969 | Actual Loss: 0.6881\n",
      "Baseline Loss: 2.8627 | Actual Loss: 0.5120\n",
      "Baseline Loss: 2.8665 | Actual Loss: 0.3338\n",
      "Baseline Loss: 2.7905 | Actual Loss: 0.4064\n",
      "Baseline Loss: 2.7670 | Actual Loss: 0.6466\n",
      "Baseline Loss: 2.7976 | Actual Loss: 0.5300\n",
      "Baseline Loss: 2.8069 | Actual Loss: 0.6722\n",
      "Baseline Loss: 2.8069 | Actual Loss: 0.1961\n",
      "Baseline Loss: 2.8766 | Actual Loss: 0.2619\n",
      "Baseline Loss: 2.5129 | Actual Loss: 0.3084\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.3963\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 32/1000 [00:13<06:34,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8204 | Actual Loss: 0.3870\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.4113\n",
      "Epoch 32/1000: Train Loss: 0.4814, Val Loss: 0.4289\n",
      "New best validation loss: 0.4289\n",
      "Baseline Loss: 2.7554 | Actual Loss: 0.3660\n",
      "Baseline Loss: 2.7995 | Actual Loss: 0.3192\n",
      "Baseline Loss: 2.8680 | Actual Loss: 0.1737\n",
      "Baseline Loss: 2.9504 | Actual Loss: 0.2798\n",
      "Baseline Loss: 2.7540 | Actual Loss: 0.2261\n",
      "Baseline Loss: 2.7776 | Actual Loss: 0.3539\n",
      "Baseline Loss: 2.8487 | Actual Loss: 0.5087\n",
      "Baseline Loss: 2.7976 | Actual Loss: 0.3167\n",
      "Baseline Loss: 2.8416 | Actual Loss: 0.2293\n",
      "Baseline Loss: 2.8081 | Actual Loss: 0.5359\n",
      "Baseline Loss: 2.8456 | Actual Loss: 0.8709\n",
      "Baseline Loss: 2.8045 | Actual Loss: 0.6873\n",
      "Baseline Loss: 2.7516 | Actual Loss: 0.3195\n",
      "Baseline Loss: 2.8450 | Actual Loss: 0.1787\n",
      "Baseline Loss: 2.7977 | Actual Loss: 0.6618\n",
      "Baseline Loss: 2.5806 | Actual Loss: 0.5038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 33/1000 [00:13<06:44,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8321 | Actual Loss: 0.3692\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.6132\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.4098\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.4828\n",
      "Epoch 33/1000: Train Loss: 0.4082, Val Loss: 0.4687\n",
      "Baseline Loss: 2.8305 | Actual Loss: 0.3565\n",
      "Baseline Loss: 2.8200 | Actual Loss: 0.4237\n",
      "Baseline Loss: 2.8153 | Actual Loss: 0.2618\n",
      "Baseline Loss: 2.8480 | Actual Loss: 0.5987\n",
      "Baseline Loss: 2.7942 | Actual Loss: 0.4308\n",
      "Baseline Loss: 2.8117 | Actual Loss: 0.4418\n",
      "Baseline Loss: 2.8301 | Actual Loss: 0.4242\n",
      "Baseline Loss: 2.7487 | Actual Loss: 0.4990\n",
      "Baseline Loss: 2.8131 | Actual Loss: 0.3481\n",
      "Baseline Loss: 2.7614 | Actual Loss: 0.4004\n",
      "Baseline Loss: 2.8164 | Actual Loss: 0.2092\n",
      "Baseline Loss: 2.8678 | Actual Loss: 0.3122\n",
      "Baseline Loss: 2.8524 | Actual Loss: 0.3044\n",
      "Baseline Loss: 2.8801 | Actual Loss: 0.4928\n",
      "Baseline Loss: 2.8669 | Actual Loss: 0.3262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 34/1000 [00:14<06:50,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.4804 | Actual Loss: 0.3495\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.4893\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.6447\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.4260\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.4629\n",
      "Epoch 34/1000: Train Loss: 0.3862, Val Loss: 0.5057\n",
      "Baseline Loss: 2.8876 | Actual Loss: 0.3875\n",
      "Baseline Loss: 2.8466 | Actual Loss: 0.4320\n",
      "Baseline Loss: 2.7841 | Actual Loss: 0.3828\n",
      "Baseline Loss: 2.8325 | Actual Loss: 0.4482\n",
      "Baseline Loss: 2.7926 | Actual Loss: 0.1729\n",
      "Baseline Loss: 2.8142 | Actual Loss: 0.5138\n",
      "Baseline Loss: 2.8130 | Actual Loss: 0.4547\n",
      "Baseline Loss: 2.8094 | Actual Loss: 0.4199\n",
      "Baseline Loss: 2.8071 | Actual Loss: 0.3969\n",
      "Baseline Loss: 2.8380 | Actual Loss: 0.4168\n",
      "Baseline Loss: 2.8587 | Actual Loss: 0.3374\n",
      "Baseline Loss: 2.8040 | Actual Loss: 0.4579\n",
      "Baseline Loss: 2.8554 | Actual Loss: 0.4064\n",
      "Baseline Loss: 2.8191 | Actual Loss: 0.3592\n",
      "Baseline Loss: 2.7965 | Actual Loss: 0.3432\n",
      "Baseline Loss: 2.4570 | Actual Loss: 0.5757\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.3592\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 35/1000 [00:14<06:36,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8204 | Actual Loss: 0.4247\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.5190\n",
      "Epoch 35/1000: Train Loss: 0.4066, Val Loss: 0.4481\n",
      "Baseline Loss: 2.7682 | Actual Loss: 0.2849\n",
      "Baseline Loss: 2.8248 | Actual Loss: 0.3712\n",
      "Baseline Loss: 2.8380 | Actual Loss: 0.3491\n",
      "Baseline Loss: 2.7433 | Actual Loss: 0.2840\n",
      "Baseline Loss: 2.8108 | Actual Loss: 0.2679\n",
      "Baseline Loss: 2.8662 | Actual Loss: 0.5720\n",
      "Baseline Loss: 2.8177 | Actual Loss: 0.3724\n",
      "Baseline Loss: 2.8263 | Actual Loss: 0.5279\n",
      "Baseline Loss: 2.7988 | Actual Loss: 0.3530\n",
      "Baseline Loss: 2.8611 | Actual Loss: 0.4204\n",
      "Baseline Loss: 2.8875 | Actual Loss: 0.3397\n",
      "Baseline Loss: 2.8004 | Actual Loss: 0.5091\n",
      "Baseline Loss: 2.9006 | Actual Loss: 0.4337\n",
      "Baseline Loss: 2.8253 | Actual Loss: 0.1738\n",
      "Baseline Loss: 2.8037 | Actual Loss: 0.3933\n",
      "Baseline Loss: 2.5874 | Actual Loss: 0.3200\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.4748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 36/1000 [00:15<06:47,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8514 | Actual Loss: 0.7934\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.4150\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.9710\n",
      "Epoch 36/1000: Train Loss: 0.3733, Val Loss: 0.6635\n",
      "Baseline Loss: 2.7765 | Actual Loss: 0.2563\n",
      "Baseline Loss: 2.8744 | Actual Loss: 0.5695\n",
      "Baseline Loss: 2.8624 | Actual Loss: 0.3138\n",
      "Baseline Loss: 2.8090 | Actual Loss: 0.3273\n",
      "Baseline Loss: 2.8370 | Actual Loss: 0.5029\n",
      "Baseline Loss: 2.8526 | Actual Loss: 0.2099\n",
      "Baseline Loss: 2.7701 | Actual Loss: 0.2491\n",
      "Baseline Loss: 2.9067 | Actual Loss: 0.6105\n",
      "Baseline Loss: 2.7746 | Actual Loss: 0.5304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 37/1000 [00:15<06:28,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7841 | Actual Loss: 1.0157\n",
      "Baseline Loss: 2.8235 | Actual Loss: 0.4008\n",
      "Baseline Loss: 2.8770 | Actual Loss: 0.5157\n",
      "Baseline Loss: 2.9091 | Actual Loss: 0.5901\n",
      "Baseline Loss: 2.7657 | Actual Loss: 0.4195\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.4633\n",
      "Baseline Loss: 2.5471 | Actual Loss: 0.2510\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.4233\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4536\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.5797\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.4620\n",
      "Epoch 37/1000: Train Loss: 0.4516, Val Loss: 0.4796\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.3958\n",
      "Baseline Loss: 2.8675 | Actual Loss: 0.4474\n",
      "Baseline Loss: 2.9028 | Actual Loss: 0.4116\n",
      "Baseline Loss: 2.8506 | Actual Loss: 0.4478\n",
      "Baseline Loss: 2.7969 | Actual Loss: 0.4816\n",
      "Baseline Loss: 2.8508 | Actual Loss: 0.3090\n",
      "Baseline Loss: 2.7757 | Actual Loss: 0.3177\n",
      "Baseline Loss: 2.8200 | Actual Loss: 0.3898\n",
      "Baseline Loss: 2.8109 | Actual Loss: 0.3534\n",
      "Baseline Loss: 2.8339 | Actual Loss: 0.5398\n",
      "Baseline Loss: 2.8036 | Actual Loss: 0.8018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 38/1000 [00:16<06:38,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7879 | Actual Loss: 0.2912\n",
      "Baseline Loss: 2.8570 | Actual Loss: 0.2472\n",
      "Baseline Loss: 2.8001 | Actual Loss: 0.3851\n",
      "Baseline Loss: 2.8355 | Actual Loss: 0.3973\n",
      "Baseline Loss: 2.4443 | Actual Loss: 0.3994\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.4513\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5973\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.5415\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.6167\n",
      "Epoch 38/1000: Train Loss: 0.4135, Val Loss: 0.5517\n",
      "Baseline Loss: 2.7795 | Actual Loss: 0.3206\n",
      "Baseline Loss: 2.8641 | Actual Loss: 0.5370\n",
      "Baseline Loss: 2.8445 | Actual Loss: 0.4211\n",
      "Baseline Loss: 2.8612 | Actual Loss: 0.3500\n",
      "Baseline Loss: 2.7829 | Actual Loss: 0.3971\n",
      "Baseline Loss: 2.7979 | Actual Loss: 0.3499\n",
      "Baseline Loss: 2.8490 | Actual Loss: 0.5219\n",
      "Baseline Loss: 2.8362 | Actual Loss: 0.3839\n",
      "Baseline Loss: 2.8831 | Actual Loss: 0.2808\n",
      "Baseline Loss: 2.8301 | Actual Loss: 0.3847\n",
      "Baseline Loss: 2.8817 | Actual Loss: 0.6950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 39/1000 [00:16<06:45,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7526 | Actual Loss: 0.2222\n",
      "Baseline Loss: 2.8441 | Actual Loss: 0.2525\n",
      "Baseline Loss: 2.8386 | Actual Loss: 0.4219\n",
      "Baseline Loss: 2.7980 | Actual Loss: 0.4695\n",
      "Baseline Loss: 2.5251 | Actual Loss: 0.1919\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.3334\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.7042\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.4156\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.3582\n",
      "Epoch 39/1000: Train Loss: 0.3875, Val Loss: 0.4528\n",
      "Baseline Loss: 2.7969 | Actual Loss: 0.5807\n",
      "Baseline Loss: 2.9081 | Actual Loss: 0.4332\n",
      "Baseline Loss: 2.7902 | Actual Loss: 0.4016\n",
      "Baseline Loss: 2.8339 | Actual Loss: 0.4472\n",
      "Baseline Loss: 2.8236 | Actual Loss: 0.3952\n",
      "Baseline Loss: 2.7991 | Actual Loss: 0.3607\n",
      "Baseline Loss: 2.8422 | Actual Loss: 0.4755\n",
      "Baseline Loss: 2.7765 | Actual Loss: 0.3879\n",
      "Baseline Loss: 2.8439 | Actual Loss: 0.6318\n",
      "Baseline Loss: 2.9674 | Actual Loss: 0.6062\n",
      "Baseline Loss: 2.8782 | Actual Loss: 0.4585\n",
      "Baseline Loss: 2.7685 | Actual Loss: 0.4798\n",
      "Baseline Loss: 2.8206 | Actual Loss: 0.5505\n",
      "Baseline Loss: 2.8188 | Actual Loss: 0.3291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 40/1000 [00:16<06:28,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8041 | Actual Loss: 0.4891\n",
      "Baseline Loss: 2.4137 | Actual Loss: 0.1931\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.4529\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5045\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.5412\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.3615\n",
      "Epoch 40/1000: Train Loss: 0.4513, Val Loss: 0.4650\n",
      "Baseline Loss: 2.8744 | Actual Loss: 0.4475\n",
      "Baseline Loss: 2.8601 | Actual Loss: 0.4905\n",
      "Baseline Loss: 2.8233 | Actual Loss: 0.4570\n",
      "Baseline Loss: 2.8443 | Actual Loss: 0.3523\n",
      "Baseline Loss: 2.7948 | Actual Loss: 0.4336\n",
      "Baseline Loss: 2.8307 | Actual Loss: 0.6631\n",
      "Baseline Loss: 2.8029 | Actual Loss: 0.6055\n",
      "Baseline Loss: 2.8144 | Actual Loss: 0.5810\n",
      "Baseline Loss: 2.7873 | Actual Loss: 0.3969\n",
      "Baseline Loss: 2.9211 | Actual Loss: 0.4939\n",
      "Baseline Loss: 2.8885 | Actual Loss: 0.4486\n",
      "Baseline Loss: 2.7913 | Actual Loss: 0.5559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 41/1000 [00:17<06:36,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7853 | Actual Loss: 0.4225\n",
      "Baseline Loss: 2.7942 | Actual Loss: 0.2872\n",
      "Baseline Loss: 2.7907 | Actual Loss: 0.4831\n",
      "Baseline Loss: 2.6815 | Actual Loss: 0.4384\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.4559\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.9179\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.4710\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.5882\n",
      "Epoch 41/1000: Train Loss: 0.4723, Val Loss: 0.6083\n",
      "Baseline Loss: 2.7869 | Actual Loss: 0.4705\n",
      "Baseline Loss: 2.8115 | Actual Loss: 0.5287\n",
      "Baseline Loss: 2.7920 | Actual Loss: 0.3615\n",
      "Baseline Loss: 2.8642 | Actual Loss: 0.4486\n",
      "Baseline Loss: 2.8360 | Actual Loss: 0.4428\n",
      "Baseline Loss: 2.8037 | Actual Loss: 0.5929\n",
      "Baseline Loss: 2.8164 | Actual Loss: 0.1667\n",
      "Baseline Loss: 2.9158 | Actual Loss: 0.3368\n",
      "Baseline Loss: 2.8788 | Actual Loss: 0.3647\n",
      "Baseline Loss: 2.7836 | Actual Loss: 0.3360\n",
      "Baseline Loss: 2.8445 | Actual Loss: 0.3485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 42/1000 [00:17<06:50,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8286 | Actual Loss: 0.3539\n",
      "Baseline Loss: 2.7588 | Actual Loss: 0.5854\n",
      "Baseline Loss: 2.8160 | Actual Loss: 0.4285\n",
      "Baseline Loss: 2.8500 | Actual Loss: 0.3377\n",
      "Baseline Loss: 2.5717 | Actual Loss: 0.4552\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.3248\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.8823\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3933\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2895\n",
      "Epoch 42/1000: Train Loss: 0.4099, Val Loss: 0.4725\n",
      "Baseline Loss: 2.7562 | Actual Loss: 0.3212\n",
      "Baseline Loss: 2.8506 | Actual Loss: 0.5467\n",
      "Baseline Loss: 2.8385 | Actual Loss: 0.5117\n",
      "Baseline Loss: 2.8441 | Actual Loss: 0.3465\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.1407\n",
      "Baseline Loss: 2.9259 | Actual Loss: 0.2383\n",
      "Baseline Loss: 2.8301 | Actual Loss: 0.2860\n",
      "Baseline Loss: 2.7933 | Actual Loss: 0.3967\n",
      "Baseline Loss: 2.7743 | Actual Loss: 0.2819\n",
      "Baseline Loss: 2.8247 | Actual Loss: 0.5809\n",
      "Baseline Loss: 2.8069 | Actual Loss: 0.2269\n",
      "Baseline Loss: 2.8182 | Actual Loss: 0.4027\n",
      "Baseline Loss: 2.7978 | Actual Loss: 0.5304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 43/1000 [00:18<06:27,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9304 | Actual Loss: 0.2730\n",
      "Baseline Loss: 2.8060 | Actual Loss: 0.5004\n",
      "Baseline Loss: 2.5198 | Actual Loss: 0.3199\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.3345\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.6628\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3163\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.4143\n",
      "Epoch 43/1000: Train Loss: 0.3690, Val Loss: 0.4320\n",
      "Baseline Loss: 2.8848 | Actual Loss: 0.5190\n",
      "Baseline Loss: 2.8145 | Actual Loss: 0.3946\n",
      "Baseline Loss: 2.7659 | Actual Loss: 0.3100\n",
      "Baseline Loss: 2.7954 | Actual Loss: 0.5937\n",
      "Baseline Loss: 2.8228 | Actual Loss: 0.5408\n",
      "Baseline Loss: 2.8750 | Actual Loss: 0.3915\n",
      "Baseline Loss: 2.7965 | Actual Loss: 0.2643\n",
      "Baseline Loss: 2.7758 | Actual Loss: 0.6787\n",
      "Baseline Loss: 2.7650 | Actual Loss: 0.3453\n",
      "Baseline Loss: 2.8425 | Actual Loss: 0.5508\n",
      "Baseline Loss: 2.8338 | Actual Loss: 0.2847\n",
      "Baseline Loss: 2.8870 | Actual Loss: 0.3518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 44/1000 [00:18<06:36,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8584 | Actual Loss: 0.4509\n",
      "Baseline Loss: 2.9228 | Actual Loss: 0.2878\n",
      "Baseline Loss: 2.8799 | Actual Loss: 0.4640\n",
      "Baseline Loss: 2.5595 | Actual Loss: 0.2169\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.3393\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.8174\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3858\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.4924\n",
      "Epoch 44/1000: Train Loss: 0.4153, Val Loss: 0.5087\n",
      "Baseline Loss: 2.8369 | Actual Loss: 0.2562\n",
      "Baseline Loss: 2.7500 | Actual Loss: 0.3361\n",
      "Baseline Loss: 2.8545 | Actual Loss: 0.3349\n",
      "Baseline Loss: 2.8767 | Actual Loss: 0.7474\n",
      "Baseline Loss: 2.9232 | Actual Loss: 0.3879\n",
      "Baseline Loss: 2.8290 | Actual Loss: 0.3395\n",
      "Baseline Loss: 2.8308 | Actual Loss: 0.4851\n",
      "Baseline Loss: 2.8654 | Actual Loss: 0.2603\n",
      "Baseline Loss: 2.7695 | Actual Loss: 0.4107\n",
      "Baseline Loss: 2.8422 | Actual Loss: 0.3468\n",
      "Baseline Loss: 2.8368 | Actual Loss: 0.3496\n",
      "Baseline Loss: 2.7920 | Actual Loss: 0.2827\n",
      "Baseline Loss: 2.8244 | Actual Loss: 0.3023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 45/1000 [00:18<06:40,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8172 | Actual Loss: 0.3712\n",
      "Baseline Loss: 2.8384 | Actual Loss: 0.3697\n",
      "Baseline Loss: 2.5117 | Actual Loss: 0.1061\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2785\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5812\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.4297\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.5394\n",
      "Epoch 45/1000: Train Loss: 0.3554, Val Loss: 0.4572\n",
      "Baseline Loss: 2.8276 | Actual Loss: 0.2151\n",
      "Baseline Loss: 2.8422 | Actual Loss: 0.1584\n",
      "Baseline Loss: 2.8539 | Actual Loss: 0.3624\n",
      "Baseline Loss: 2.8189 | Actual Loss: 0.1345\n",
      "Baseline Loss: 2.7925 | Actual Loss: 0.4077\n",
      "Baseline Loss: 2.8164 | Actual Loss: 0.2426\n",
      "Baseline Loss: 2.8509 | Actual Loss: 0.2953\n",
      "Baseline Loss: 2.8115 | Actual Loss: 0.4174\n",
      "Baseline Loss: 2.8786 | Actual Loss: 0.3688\n",
      "Baseline Loss: 2.8639 | Actual Loss: 0.3825\n",
      "Baseline Loss: 2.8110 | Actual Loss: 0.3941\n",
      "Baseline Loss: 2.8326 | Actual Loss: 0.4920\n",
      "Baseline Loss: 2.8128 | Actual Loss: 0.4390\n",
      "Baseline Loss: 2.8662 | Actual Loss: 0.1628\n",
      "Baseline Loss: 2.8596 | Actual Loss: 0.4551\n",
      "Baseline Loss: 2.4904 | Actual Loss: 0.3702\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 46/1000 [00:19<06:27,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8514 | Actual Loss: 0.6078\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3311\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.5970\n",
      "Epoch 46/1000: Train Loss: 0.3311, Val Loss: 0.4407\n",
      "Baseline Loss: 2.7912 | Actual Loss: 0.6856\n",
      "Baseline Loss: 2.8662 | Actual Loss: 0.5476\n",
      "Baseline Loss: 2.8696 | Actual Loss: 0.2254\n",
      "Baseline Loss: 2.8708 | Actual Loss: 0.4013\n",
      "Baseline Loss: 2.7642 | Actual Loss: 0.4057\n",
      "Baseline Loss: 2.8178 | Actual Loss: 0.2209\n",
      "Baseline Loss: 2.7639 | Actual Loss: 0.4714\n",
      "Baseline Loss: 2.8728 | Actual Loss: 0.4254\n",
      "Baseline Loss: 2.8309 | Actual Loss: 0.5362\n",
      "Baseline Loss: 2.8893 | Actual Loss: 0.2762\n",
      "Baseline Loss: 2.7940 | Actual Loss: 0.2570\n",
      "Baseline Loss: 2.7988 | Actual Loss: 0.2592\n",
      "Baseline Loss: 2.8134 | Actual Loss: 0.5465\n",
      "Baseline Loss: 2.8308 | Actual Loss: 0.5924\n",
      "Baseline Loss: 2.8079 | Actual Loss: 0.3279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 47/1000 [00:19<06:37,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6269 | Actual Loss: 0.6051\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.3582\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.6774\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.4733\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.3664\n",
      "Epoch 47/1000: Train Loss: 0.4240, Val Loss: 0.4688\n",
      "Baseline Loss: 2.8056 | Actual Loss: 0.3715\n",
      "Baseline Loss: 2.7985 | Actual Loss: 0.3218\n",
      "Baseline Loss: 2.8265 | Actual Loss: 0.5255\n",
      "Baseline Loss: 2.7577 | Actual Loss: 0.2723\n",
      "Baseline Loss: 2.8762 | Actual Loss: 0.3893\n",
      "Baseline Loss: 2.7678 | Actual Loss: 0.1459\n",
      "Baseline Loss: 2.9153 | Actual Loss: 0.1610\n",
      "Baseline Loss: 2.7675 | Actual Loss: 0.5552\n",
      "Baseline Loss: 2.8277 | Actual Loss: 0.4706\n",
      "Baseline Loss: 2.8818 | Actual Loss: 0.2501\n",
      "Baseline Loss: 2.8078 | Actual Loss: 0.3412\n",
      "Baseline Loss: 2.8150 | Actual Loss: 0.3968\n",
      "Baseline Loss: 2.8382 | Actual Loss: 0.5058\n",
      "Baseline Loss: 2.8229 | Actual Loss: 0.6588\n",
      "Baseline Loss: 2.7827 | Actual Loss: 0.4510\n",
      "Baseline Loss: 2.4947 | Actual Loss: 0.1288\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 48/1000 [00:20<06:47,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8514 | Actual Loss: 0.5756\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3684\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.5702\n",
      "Epoch 48/1000: Train Loss: 0.3716, Val Loss: 0.4519\n",
      "Baseline Loss: 2.8809 | Actual Loss: 0.4190\n",
      "Baseline Loss: 2.7517 | Actual Loss: 0.3677\n",
      "Baseline Loss: 2.7561 | Actual Loss: 0.2561\n",
      "Baseline Loss: 2.8312 | Actual Loss: 0.4235\n",
      "Baseline Loss: 2.8075 | Actual Loss: 0.4461\n",
      "Baseline Loss: 2.8409 | Actual Loss: 0.3365\n",
      "Baseline Loss: 2.8189 | Actual Loss: 0.4405\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3410\n",
      "Baseline Loss: 2.8486 | Actual Loss: 0.4590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 49/1000 [00:20<06:33,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7937 | Actual Loss: 0.3257\n",
      "Baseline Loss: 2.8264 | Actual Loss: 0.4330\n",
      "Baseline Loss: 2.8402 | Actual Loss: 0.4977\n",
      "Baseline Loss: 2.8242 | Actual Loss: 0.3498\n",
      "Baseline Loss: 2.8370 | Actual Loss: 0.3853\n",
      "Baseline Loss: 2.8172 | Actual Loss: 0.3083\n",
      "Baseline Loss: 2.6348 | Actual Loss: 0.2870\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2973\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.6516\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3877\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2160\n",
      "Epoch 49/1000: Train Loss: 0.3798, Val Loss: 0.3882\n",
      "New best validation loss: 0.3882\n",
      "Baseline Loss: 2.7821 | Actual Loss: 0.3234\n",
      "Baseline Loss: 2.7938 | Actual Loss: 0.3001\n",
      "Baseline Loss: 2.8190 | Actual Loss: 0.3747\n",
      "Baseline Loss: 2.8402 | Actual Loss: 0.2859\n",
      "Baseline Loss: 2.8378 | Actual Loss: 0.3759\n",
      "Baseline Loss: 2.8130 | Actual Loss: 0.3891\n",
      "Baseline Loss: 2.8428 | Actual Loss: 0.3884\n",
      "Baseline Loss: 2.8373 | Actual Loss: 0.1377\n",
      "Baseline Loss: 2.8600 | Actual Loss: 0.4076\n",
      "Baseline Loss: 2.8592 | Actual Loss: 0.3660\n",
      "Baseline Loss: 2.7860 | Actual Loss: 0.4037\n",
      "Baseline Loss: 2.7948 | Actual Loss: 0.2332\n",
      "Baseline Loss: 2.8573 | Actual Loss: 0.1645\n",
      "Baseline Loss: 2.8953 | Actual Loss: 0.2064\n",
      "Baseline Loss: 2.8274 | Actual Loss: 0.6108\n",
      "Baseline Loss: 2.5042 | Actual Loss: 0.4186\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 50/1000 [00:21<06:44,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8514 | Actual Loss: 1.1464\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.4816\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.7351\n",
      "Epoch 50/1000: Train Loss: 0.3366, Val Loss: 0.6594\n",
      "Baseline Loss: 2.8636 | Actual Loss: 0.8366\n",
      "Baseline Loss: 2.8340 | Actual Loss: 0.2751\n",
      "Baseline Loss: 2.9059 | Actual Loss: 0.1349\n",
      "Baseline Loss: 2.8059 | Actual Loss: 0.2741\n",
      "Baseline Loss: 2.7806 | Actual Loss: 0.5078\n",
      "Baseline Loss: 2.8232 | Actual Loss: 0.4079\n",
      "Baseline Loss: 2.7919 | Actual Loss: 0.3338\n",
      "Baseline Loss: 2.8109 | Actual Loss: 0.2330\n",
      "Baseline Loss: 2.8215 | Actual Loss: 0.6245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 51/1000 [00:21<06:28,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7927 | Actual Loss: 0.2509\n",
      "Baseline Loss: 2.8602 | Actual Loss: 0.3361\n",
      "Baseline Loss: 2.7625 | Actual Loss: 0.2329\n",
      "Baseline Loss: 2.7860 | Actual Loss: 0.3854\n",
      "Baseline Loss: 2.9063 | Actual Loss: 0.1396\n",
      "Baseline Loss: 2.8370 | Actual Loss: 0.4769\n",
      "Baseline Loss: 2.5251 | Actual Loss: 0.5567\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2959\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.7035\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.4187\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.3409\n",
      "Epoch 51/1000: Train Loss: 0.3754, Val Loss: 0.4397\n",
      "Baseline Loss: 2.8166 | Actual Loss: 0.3007\n",
      "Baseline Loss: 2.7822 | Actual Loss: 0.8186\n",
      "Baseline Loss: 2.9014 | Actual Loss: 0.2717\n",
      "Baseline Loss: 2.8862 | Actual Loss: 0.4357\n",
      "Baseline Loss: 2.7713 | Actual Loss: 0.4531\n",
      "Baseline Loss: 2.9367 | Actual Loss: 0.3226\n",
      "Baseline Loss: 2.7940 | Actual Loss: 0.3721\n",
      "Baseline Loss: 2.8117 | Actual Loss: 0.2939\n",
      "Baseline Loss: 2.8138 | Actual Loss: 0.2840\n",
      "Baseline Loss: 2.9269 | Actual Loss: 0.5671\n",
      "Baseline Loss: 2.8423 | Actual Loss: 0.3035\n",
      "Baseline Loss: 2.8145 | Actual Loss: 0.3439\n",
      "Baseline Loss: 2.8299 | Actual Loss: 0.1566\n",
      "Baseline Loss: 2.8176 | Actual Loss: 0.2924\n",
      "Baseline Loss: 2.7956 | Actual Loss: 0.2340\n",
      "Baseline Loss: 2.5114 | Actual Loss: 0.0904\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.4021\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.6086\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.4122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 52/1000 [00:21<06:39,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7416 | Actual Loss: 0.2561\n",
      "Epoch 52/1000: Train Loss: 0.3463, Val Loss: 0.4198\n",
      "Baseline Loss: 2.8868 | Actual Loss: 0.3195\n",
      "Baseline Loss: 2.8149 | Actual Loss: 0.4031\n",
      "Baseline Loss: 2.8718 | Actual Loss: 0.3981\n",
      "Baseline Loss: 2.7695 | Actual Loss: 0.3181\n",
      "Baseline Loss: 2.8033 | Actual Loss: 0.4183\n",
      "Baseline Loss: 2.9190 | Actual Loss: 0.4195\n",
      "Baseline Loss: 2.7525 | Actual Loss: 0.2777\n",
      "Baseline Loss: 2.7967 | Actual Loss: 0.2884\n",
      "Baseline Loss: 2.8294 | Actual Loss: 0.2150\n",
      "Baseline Loss: 2.8563 | Actual Loss: 0.2597\n",
      "Baseline Loss: 2.8768 | Actual Loss: 0.4103\n",
      "Baseline Loss: 2.8171 | Actual Loss: 0.4494\n",
      "Baseline Loss: 2.8036 | Actual Loss: 0.2654\n",
      "Baseline Loss: 2.8411 | Actual Loss: 0.2594\n",
      "Baseline Loss: 2.8012 | Actual Loss: 0.4505\n",
      "Baseline Loss: 2.5543 | Actual Loss: 0.2402\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.3518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 53/1000 [00:22<06:47,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8514 | Actual Loss: 0.6996\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3402\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.3587\n",
      "Epoch 53/1000: Train Loss: 0.3370, Val Loss: 0.4376\n",
      "Baseline Loss: 2.8471 | Actual Loss: 0.3365\n",
      "Baseline Loss: 2.8977 | Actual Loss: 0.2827\n",
      "Baseline Loss: 2.7828 | Actual Loss: 0.1623\n",
      "Baseline Loss: 2.8785 | Actual Loss: 0.3460\n",
      "Baseline Loss: 2.9045 | Actual Loss: 0.3055\n",
      "Baseline Loss: 2.7938 | Actual Loss: 0.3830\n",
      "Baseline Loss: 2.8010 | Actual Loss: 0.3377\n",
      "Baseline Loss: 2.7995 | Actual Loss: 0.1411\n",
      "Baseline Loss: 2.7789 | Actual Loss: 0.3496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 54/1000 [00:22<06:29,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8140 | Actual Loss: 0.2105\n",
      "Baseline Loss: 2.7652 | Actual Loss: 0.1732\n",
      "Baseline Loss: 2.7962 | Actual Loss: 0.5212\n",
      "Baseline Loss: 2.8367 | Actual Loss: 0.3053\n",
      "Baseline Loss: 2.8036 | Actual Loss: 0.4123\n",
      "Baseline Loss: 2.8722 | Actual Loss: 0.3159\n",
      "Baseline Loss: 2.4774 | Actual Loss: 0.7983\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.3352\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.6355\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.4157\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.3903\n",
      "Epoch 54/1000: Train Loss: 0.3363, Val Loss: 0.4442\n",
      "Baseline Loss: 2.8564 | Actual Loss: 0.2546\n",
      "Baseline Loss: 2.7999 | Actual Loss: 0.3605\n",
      "Baseline Loss: 2.7992 | Actual Loss: 0.3253\n",
      "Baseline Loss: 2.7835 | Actual Loss: 0.4051\n",
      "Baseline Loss: 2.8428 | Actual Loss: 0.3871\n",
      "Baseline Loss: 2.8363 | Actual Loss: 0.3733\n",
      "Baseline Loss: 2.7923 | Actual Loss: 0.3261\n",
      "Baseline Loss: 2.9086 | Actual Loss: 0.3825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 55/1000 [00:23<06:37,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8295 | Actual Loss: 0.4518\n",
      "Baseline Loss: 2.8662 | Actual Loss: 0.1269\n",
      "Baseline Loss: 2.8818 | Actual Loss: 0.5230\n",
      "Baseline Loss: 2.8327 | Actual Loss: 0.2565\n",
      "Baseline Loss: 2.8184 | Actual Loss: 0.2150\n",
      "Baseline Loss: 2.8071 | Actual Loss: 0.4061\n",
      "Baseline Loss: 2.8040 | Actual Loss: 0.3076\n",
      "Baseline Loss: 2.5195 | Actual Loss: 0.2111\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.3980\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5939\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3953\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.4513\n",
      "Epoch 55/1000: Train Loss: 0.3320, Val Loss: 0.4596\n",
      "Baseline Loss: 2.8075 | Actual Loss: 0.2949\n",
      "Baseline Loss: 2.8628 | Actual Loss: 0.4069\n",
      "Baseline Loss: 2.8356 | Actual Loss: 0.4531\n",
      "Baseline Loss: 2.8354 | Actual Loss: 0.2448\n",
      "Baseline Loss: 2.8245 | Actual Loss: 0.3299\n",
      "Baseline Loss: 2.7938 | Actual Loss: 0.3045\n",
      "Baseline Loss: 2.8555 | Actual Loss: 0.6080\n",
      "Baseline Loss: 2.8150 | Actual Loss: 0.3972\n",
      "Baseline Loss: 2.7827 | Actual Loss: 0.4021\n",
      "Baseline Loss: 2.8762 | Actual Loss: 0.2752\n",
      "Baseline Loss: 2.8005 | Actual Loss: 0.4040\n",
      "Baseline Loss: 2.8641 | Actual Loss: 0.2259\n",
      "Baseline Loss: 2.8736 | Actual Loss: 0.3740\n",
      "Baseline Loss: 2.9295 | Actual Loss: 0.4169\n",
      "Baseline Loss: 2.7976 | Actual Loss: 0.3601\n",
      "Baseline Loss: 2.5751 | Actual Loss: 0.1551\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2457\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.6715\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 56/1000 [00:23<06:42,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7416 | Actual Loss: 0.2761\n",
      "Epoch 56/1000: Train Loss: 0.3533, Val Loss: 0.3793\n",
      "New best validation loss: 0.3793\n",
      "Baseline Loss: 2.7971 | Actual Loss: 0.4676\n",
      "Baseline Loss: 2.9049 | Actual Loss: 0.3525\n",
      "Baseline Loss: 2.8265 | Actual Loss: 0.3767\n",
      "Baseline Loss: 2.7803 | Actual Loss: 0.2295\n",
      "Baseline Loss: 2.8207 | Actual Loss: 0.2318\n",
      "Baseline Loss: 2.8333 | Actual Loss: 0.3279\n",
      "Baseline Loss: 2.8435 | Actual Loss: 0.2187\n",
      "Baseline Loss: 2.7762 | Actual Loss: 0.3245\n",
      "Baseline Loss: 2.9521 | Actual Loss: 0.4692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 57/1000 [00:23<06:27,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7523 | Actual Loss: 0.1407\n",
      "Baseline Loss: 2.8400 | Actual Loss: 0.5461\n",
      "Baseline Loss: 2.8472 | Actual Loss: 0.2277\n",
      "Baseline Loss: 2.7824 | Actual Loss: 0.2280\n",
      "Baseline Loss: 2.8681 | Actual Loss: 0.2784\n",
      "Baseline Loss: 2.9002 | Actual Loss: 0.1586\n",
      "Baseline Loss: 2.4489 | Actual Loss: 0.1407\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2674\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.6420\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.4132\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.4328\n",
      "Epoch 57/1000: Train Loss: 0.2949, Val Loss: 0.4389\n",
      "Baseline Loss: 2.8101 | Actual Loss: 0.2128\n",
      "Baseline Loss: 2.8788 | Actual Loss: 0.2444\n",
      "Baseline Loss: 2.9163 | Actual Loss: 0.2073\n",
      "Baseline Loss: 2.8168 | Actual Loss: 0.3457\n",
      "Baseline Loss: 2.7926 | Actual Loss: 0.1918\n",
      "Baseline Loss: 2.8090 | Actual Loss: 0.3589\n",
      "Baseline Loss: 2.8624 | Actual Loss: 0.5573\n",
      "Baseline Loss: 2.8261 | Actual Loss: 0.5051\n",
      "Baseline Loss: 2.8783 | Actual Loss: 0.6175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 58/1000 [00:24<06:31,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7783 | Actual Loss: 0.2430\n",
      "Baseline Loss: 2.8480 | Actual Loss: 0.1163\n",
      "Baseline Loss: 2.8745 | Actual Loss: 0.3108\n",
      "Baseline Loss: 2.8089 | Actual Loss: 0.4207\n",
      "Baseline Loss: 2.8068 | Actual Loss: 0.2486\n",
      "Baseline Loss: 2.7854 | Actual Loss: 0.4880\n",
      "Baseline Loss: 2.5750 | Actual Loss: 0.2230\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2552\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.6390\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3633\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.3517\n",
      "Epoch 58/1000: Train Loss: 0.3307, Val Loss: 0.4023\n",
      "Baseline Loss: 2.9220 | Actual Loss: 0.2920\n",
      "Baseline Loss: 2.8047 | Actual Loss: 0.2420\n",
      "Baseline Loss: 2.8387 | Actual Loss: 0.3759\n",
      "Baseline Loss: 2.8811 | Actual Loss: 0.2655\n",
      "Baseline Loss: 2.8358 | Actual Loss: 0.5135\n",
      "Baseline Loss: 2.8993 | Actual Loss: 0.2327\n",
      "Baseline Loss: 2.8361 | Actual Loss: 0.4711\n",
      "Baseline Loss: 2.7927 | Actual Loss: 0.4735\n",
      "Baseline Loss: 2.8340 | Actual Loss: 0.2665\n",
      "Baseline Loss: 2.7790 | Actual Loss: 0.2270\n",
      "Baseline Loss: 2.8830 | Actual Loss: 0.2025\n",
      "Baseline Loss: 2.7899 | Actual Loss: 0.1770\n",
      "Baseline Loss: 2.9256 | Actual Loss: 0.1853\n",
      "Baseline Loss: 2.7999 | Actual Loss: 0.4456\n",
      "Baseline Loss: 2.7940 | Actual Loss: 0.3776\n",
      "Baseline Loss: 2.6348 | Actual Loss: 0.5455\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.3637\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.7404\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.4658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 59/1000 [00:24<06:41,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7416 | Actual Loss: 0.3706\n",
      "Epoch 59/1000: Train Loss: 0.3308, Val Loss: 0.4851\n",
      "Baseline Loss: 2.7852 | Actual Loss: 0.4942\n",
      "Baseline Loss: 2.7976 | Actual Loss: 0.2381\n",
      "Baseline Loss: 2.8035 | Actual Loss: 0.4670\n",
      "Baseline Loss: 2.8276 | Actual Loss: 0.7165\n",
      "Baseline Loss: 2.8658 | Actual Loss: 0.4882\n",
      "Baseline Loss: 2.8871 | Actual Loss: 0.4248\n",
      "Baseline Loss: 2.8253 | Actual Loss: 0.3429\n",
      "Baseline Loss: 2.8158 | Actual Loss: 0.2554\n",
      "Baseline Loss: 2.8098 | Actual Loss: 0.2877\n",
      "Baseline Loss: 2.7921 | Actual Loss: 0.2529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 60/1000 [00:25<06:27,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9140 | Actual Loss: 0.6111\n",
      "Baseline Loss: 2.8350 | Actual Loss: 0.3960\n",
      "Baseline Loss: 2.8508 | Actual Loss: 0.2773\n",
      "Baseline Loss: 2.7683 | Actual Loss: 0.3215\n",
      "Baseline Loss: 2.9220 | Actual Loss: 0.3448\n",
      "Baseline Loss: 2.4780 | Actual Loss: 0.1249\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.3316\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5112\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3547\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.3146\n",
      "Epoch 60/1000: Train Loss: 0.3777, Val Loss: 0.3780\n",
      "New best validation loss: 0.3780\n",
      "Baseline Loss: 2.7786 | Actual Loss: 0.5622\n",
      "Baseline Loss: 2.8510 | Actual Loss: 0.2589\n",
      "Baseline Loss: 2.8495 | Actual Loss: 0.3475\n",
      "Baseline Loss: 2.8146 | Actual Loss: 0.7323\n",
      "Baseline Loss: 2.8451 | Actual Loss: 0.4627\n",
      "Baseline Loss: 2.8248 | Actual Loss: 0.1920\n",
      "Baseline Loss: 2.8262 | Actual Loss: 0.2927\n",
      "Baseline Loss: 2.7331 | Actual Loss: 0.3924\n",
      "Baseline Loss: 2.7806 | Actual Loss: 0.1477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 61/1000 [00:25<06:36,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8282 | Actual Loss: 0.2753\n",
      "Baseline Loss: 2.8292 | Actual Loss: 0.7621\n",
      "Baseline Loss: 2.8470 | Actual Loss: 0.3765\n",
      "Baseline Loss: 2.7897 | Actual Loss: 0.4062\n",
      "Baseline Loss: 2.8700 | Actual Loss: 0.2170\n",
      "Baseline Loss: 2.9255 | Actual Loss: 0.3027\n",
      "Baseline Loss: 2.6099 | Actual Loss: 0.4727\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.4047\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.6767\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3726\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.3944\n",
      "Epoch 61/1000: Train Loss: 0.3875, Val Loss: 0.4621\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2716\n",
      "Baseline Loss: 2.8533 | Actual Loss: 0.5238\n",
      "Baseline Loss: 2.8036 | Actual Loss: 0.5290\n",
      "Baseline Loss: 2.8608 | Actual Loss: 0.2758\n",
      "Baseline Loss: 2.7961 | Actual Loss: 0.3111\n",
      "Baseline Loss: 2.8184 | Actual Loss: 0.2237\n",
      "Baseline Loss: 2.8185 | Actual Loss: 0.2569\n",
      "Baseline Loss: 2.8269 | Actual Loss: 0.4035\n",
      "Baseline Loss: 2.8555 | Actual Loss: 0.2356\n",
      "Baseline Loss: 2.8743 | Actual Loss: 0.3103\n",
      "Baseline Loss: 2.8108 | Actual Loss: 0.4873\n",
      "Baseline Loss: 2.8169 | Actual Loss: 0.3253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 62/1000 [00:26<06:39,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7956 | Actual Loss: 0.3983\n",
      "Baseline Loss: 2.8791 | Actual Loss: 0.3858\n",
      "Baseline Loss: 2.8405 | Actual Loss: 0.2521\n",
      "Baseline Loss: 2.4828 | Actual Loss: 0.4154\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2198\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5451\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3193\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.3392\n",
      "Epoch 62/1000: Train Loss: 0.3503, Val Loss: 0.3558\n",
      "New best validation loss: 0.3558\n",
      "Baseline Loss: 2.8065 | Actual Loss: 0.2169\n",
      "Baseline Loss: 2.8580 | Actual Loss: 0.5749\n",
      "Baseline Loss: 2.8672 | Actual Loss: 0.2200\n",
      "Baseline Loss: 2.7536 | Actual Loss: 0.2865\n",
      "Baseline Loss: 2.9063 | Actual Loss: 0.2242\n",
      "Baseline Loss: 2.7747 | Actual Loss: 0.4656\n",
      "Baseline Loss: 2.7696 | Actual Loss: 0.3722\n",
      "Baseline Loss: 2.8441 | Actual Loss: 0.2747\n",
      "Baseline Loss: 2.8270 | Actual Loss: 0.2890\n",
      "Baseline Loss: 2.8344 | Actual Loss: 0.3438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 63/1000 [00:26<06:23,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8450 | Actual Loss: 0.3040\n",
      "Baseline Loss: 2.7751 | Actual Loss: 0.3594\n",
      "Baseline Loss: 2.8015 | Actual Loss: 0.3689\n",
      "Baseline Loss: 2.8175 | Actual Loss: 0.3029\n",
      "Baseline Loss: 2.8449 | Actual Loss: 0.2192\n",
      "Baseline Loss: 2.5058 | Actual Loss: 0.1146\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2904\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5536\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2997\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.3869\n",
      "Epoch 63/1000: Train Loss: 0.3086, Val Loss: 0.3827\n",
      "Baseline Loss: 2.7557 | Actual Loss: 0.2531\n",
      "Baseline Loss: 2.8854 | Actual Loss: 0.2539\n",
      "Baseline Loss: 2.8605 | Actual Loss: 0.3291\n",
      "Baseline Loss: 2.7721 | Actual Loss: 0.1644\n",
      "Baseline Loss: 2.8055 | Actual Loss: 0.1715\n",
      "Baseline Loss: 2.8130 | Actual Loss: 0.1722\n",
      "Baseline Loss: 2.8883 | Actual Loss: 0.4200\n",
      "Baseline Loss: 2.8243 | Actual Loss: 0.4119\n",
      "Baseline Loss: 2.8150 | Actual Loss: 0.3139\n",
      "Baseline Loss: 2.8091 | Actual Loss: 0.7647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 64/1000 [00:26<06:31,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8148 | Actual Loss: 0.6260\n",
      "Baseline Loss: 2.8332 | Actual Loss: 0.5442\n",
      "Baseline Loss: 2.8339 | Actual Loss: 0.5640\n",
      "Baseline Loss: 2.8492 | Actual Loss: 0.5730\n",
      "Baseline Loss: 2.8480 | Actual Loss: 0.6191\n",
      "Baseline Loss: 2.5439 | Actual Loss: 0.3327\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.3726\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5830\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3506\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2327\n",
      "Epoch 64/1000: Train Loss: 0.4071, Val Loss: 0.3847\n",
      "Baseline Loss: 2.8612 | Actual Loss: 0.5017\n",
      "Baseline Loss: 2.8282 | Actual Loss: 0.2702\n",
      "Baseline Loss: 2.8678 | Actual Loss: 0.3679\n",
      "Baseline Loss: 2.8585 | Actual Loss: 0.3597\n",
      "Baseline Loss: 2.8441 | Actual Loss: 0.3270\n",
      "Baseline Loss: 2.8332 | Actual Loss: 0.3467\n",
      "Baseline Loss: 2.8195 | Actual Loss: 0.2877\n",
      "Baseline Loss: 2.8375 | Actual Loss: 0.4419\n",
      "Baseline Loss: 2.7873 | Actual Loss: 0.1777\n",
      "Baseline Loss: 2.7733 | Actual Loss: 0.3802\n",
      "Baseline Loss: 2.8330 | Actual Loss: 0.6662\n",
      "Baseline Loss: 2.8237 | Actual Loss: 0.2800\n",
      "Baseline Loss: 2.7987 | Actual Loss: 0.3645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 65/1000 [00:27<06:36,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8379 | Actual Loss: 0.4236\n",
      "Baseline Loss: 2.8225 | Actual Loss: 0.3303\n",
      "Baseline Loss: 2.6685 | Actual Loss: 0.3685\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.3579\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.6087\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.4268\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.4204\n",
      "Epoch 65/1000: Train Loss: 0.3684, Val Loss: 0.4535\n",
      "Baseline Loss: 2.8387 | Actual Loss: 0.2059\n",
      "Baseline Loss: 2.8224 | Actual Loss: 0.3741\n",
      "Baseline Loss: 2.7613 | Actual Loss: 0.2561\n",
      "Baseline Loss: 2.8551 | Actual Loss: 0.4082\n",
      "Baseline Loss: 2.7115 | Actual Loss: 0.3600\n",
      "Baseline Loss: 2.8165 | Actual Loss: 0.2728\n",
      "Baseline Loss: 2.8823 | Actual Loss: 0.2544\n",
      "Baseline Loss: 2.8000 | Actual Loss: 0.5528\n",
      "Baseline Loss: 2.7950 | Actual Loss: 0.3957\n",
      "Baseline Loss: 2.8901 | Actual Loss: 0.2950\n",
      "Baseline Loss: 2.8403 | Actual Loss: 0.2420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 66/1000 [00:27<06:24,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8486 | Actual Loss: 0.2869\n",
      "Baseline Loss: 2.8105 | Actual Loss: 0.3592\n",
      "Baseline Loss: 2.9391 | Actual Loss: 0.2525\n",
      "Baseline Loss: 2.7746 | Actual Loss: 0.2944\n",
      "Baseline Loss: 2.6735 | Actual Loss: 0.4873\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2176\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.6087\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3451\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2244\n",
      "Epoch 66/1000: Train Loss: 0.3311, Val Loss: 0.3489\n",
      "New best validation loss: 0.3489\n",
      "Baseline Loss: 2.9208 | Actual Loss: 0.2800\n",
      "Baseline Loss: 2.7638 | Actual Loss: 0.2046\n",
      "Baseline Loss: 2.8324 | Actual Loss: 0.1993\n",
      "Baseline Loss: 2.8691 | Actual Loss: 0.1645\n",
      "Baseline Loss: 2.8677 | Actual Loss: 0.4113\n",
      "Baseline Loss: 2.7546 | Actual Loss: 0.2585\n",
      "Baseline Loss: 2.8598 | Actual Loss: 0.3276\n",
      "Baseline Loss: 2.8274 | Actual Loss: 0.3083\n",
      "Baseline Loss: 2.8364 | Actual Loss: 0.2258\n",
      "Baseline Loss: 2.8662 | Actual Loss: 0.1362\n",
      "Baseline Loss: 2.8025 | Actual Loss: 0.2333\n",
      "Baseline Loss: 2.8224 | Actual Loss: 0.1995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 67/1000 [00:28<06:32,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8511 | Actual Loss: 0.2587\n",
      "Baseline Loss: 2.8016 | Actual Loss: 0.4132\n",
      "Baseline Loss: 2.9135 | Actual Loss: 0.2757\n",
      "Baseline Loss: 2.5484 | Actual Loss: 0.1517\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.3507\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.9730\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3917\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2698\n",
      "Epoch 67/1000: Train Loss: 0.2530, Val Loss: 0.4963\n",
      "Baseline Loss: 2.8349 | Actual Loss: 0.2388\n",
      "Baseline Loss: 2.7752 | Actual Loss: 0.2873\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.4083\n",
      "Baseline Loss: 2.7885 | Actual Loss: 0.3191\n",
      "Baseline Loss: 2.8701 | Actual Loss: 0.1643\n",
      "Baseline Loss: 2.9129 | Actual Loss: 0.3063\n",
      "Baseline Loss: 2.8035 | Actual Loss: 0.6786\n",
      "Baseline Loss: 2.8382 | Actual Loss: 0.2234\n",
      "Baseline Loss: 2.8814 | Actual Loss: 0.1781\n",
      "Baseline Loss: 2.8045 | Actual Loss: 0.2074\n",
      "Baseline Loss: 2.8125 | Actual Loss: 0.3108\n",
      "Baseline Loss: 2.8664 | Actual Loss: 0.3398\n",
      "Baseline Loss: 2.8472 | Actual Loss: 0.3491\n",
      "Baseline Loss: 2.8344 | Actual Loss: 0.4389\n",
      "Baseline Loss: 2.7413 | Actual Loss: 0.2358\n",
      "Baseline Loss: 2.6732 | Actual Loss: 0.1187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 68/1000 [00:28<06:12,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8321 | Actual Loss: 0.3442\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4992\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3553\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.3490\n",
      "Epoch 68/1000: Train Loss: 0.3003, Val Loss: 0.3869\n",
      "Baseline Loss: 2.8007 | Actual Loss: 0.3325\n",
      "Baseline Loss: 2.8594 | Actual Loss: 0.3668\n",
      "Baseline Loss: 2.8318 | Actual Loss: 0.3315\n",
      "Baseline Loss: 2.8131 | Actual Loss: 0.2143\n",
      "Baseline Loss: 2.8127 | Actual Loss: 0.1507\n",
      "Baseline Loss: 2.8030 | Actual Loss: 0.4394\n",
      "Baseline Loss: 2.8030 | Actual Loss: 0.3057\n",
      "Baseline Loss: 2.7572 | Actual Loss: 0.2447\n",
      "Baseline Loss: 2.7576 | Actual Loss: 0.1176\n",
      "Baseline Loss: 2.9092 | Actual Loss: 0.6566\n",
      "Baseline Loss: 2.8137 | Actual Loss: 0.1878\n",
      "Baseline Loss: 2.8335 | Actual Loss: 0.2173\n",
      "Baseline Loss: 2.8510 | Actual Loss: 0.2243\n",
      "Baseline Loss: 2.8829 | Actual Loss: 0.6394\n",
      "Baseline Loss: 2.9429 | Actual Loss: 0.8287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 69/1000 [00:28<06:26,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.3769 | Actual Loss: 0.1679\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2869\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.7004\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.4781\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.6111\n",
      "Epoch 69/1000: Train Loss: 0.3391, Val Loss: 0.5191\n",
      "Baseline Loss: 2.8415 | Actual Loss: 0.3798\n",
      "Baseline Loss: 2.7658 | Actual Loss: 0.2339\n",
      "Baseline Loss: 2.8020 | Actual Loss: 0.2408\n",
      "Baseline Loss: 2.8536 | Actual Loss: 0.2914\n",
      "Baseline Loss: 2.8829 | Actual Loss: 0.3843\n",
      "Baseline Loss: 2.9103 | Actual Loss: 0.1702\n",
      "Baseline Loss: 2.8530 | Actual Loss: 0.2923\n",
      "Baseline Loss: 2.8399 | Actual Loss: 0.3496\n",
      "Baseline Loss: 2.8235 | Actual Loss: 0.4348\n",
      "Baseline Loss: 2.8244 | Actual Loss: 0.3817\n",
      "Baseline Loss: 2.7959 | Actual Loss: 0.2438\n",
      "Baseline Loss: 2.7628 | Actual Loss: 0.2488\n",
      "Baseline Loss: 2.8644 | Actual Loss: 0.6385\n",
      "Baseline Loss: 2.7859 | Actual Loss: 0.5053\n",
      "Baseline Loss: 2.7845 | Actual Loss: 0.4191\n",
      "Baseline Loss: 2.6908 | Actual Loss: 0.6001\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.3348\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5824\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.5225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 70/1000 [00:29<06:33,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7416 | Actual Loss: 0.3709\n",
      "Epoch 70/1000: Train Loss: 0.3634, Val Loss: 0.4526\n",
      "Baseline Loss: 2.8478 | Actual Loss: 0.2361\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.2711\n",
      "Baseline Loss: 2.8001 | Actual Loss: 0.2507\n",
      "Baseline Loss: 2.7922 | Actual Loss: 0.3764\n",
      "Baseline Loss: 2.8127 | Actual Loss: 0.4675\n",
      "Baseline Loss: 2.7860 | Actual Loss: 0.2012\n",
      "Baseline Loss: 2.8738 | Actual Loss: 0.3664\n",
      "Baseline Loss: 2.7921 | Actual Loss: 0.5920\n",
      "Baseline Loss: 2.8397 | Actual Loss: 0.6027\n",
      "Baseline Loss: 2.7880 | Actual Loss: 0.3441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 71/1000 [00:29<06:12,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8747 | Actual Loss: 0.1971\n",
      "Baseline Loss: 2.8443 | Actual Loss: 0.4461\n",
      "Baseline Loss: 2.8492 | Actual Loss: 0.4658\n",
      "Baseline Loss: 2.8114 | Actual Loss: 0.2717\n",
      "Baseline Loss: 2.8274 | Actual Loss: 0.3047\n",
      "Baseline Loss: 2.6992 | Actual Loss: 0.2282\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.3023\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.7647\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3648\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.3922\n",
      "Epoch 71/1000: Train Loss: 0.3514, Val Loss: 0.4560\n",
      "Baseline Loss: 2.8391 | Actual Loss: 0.3277\n",
      "Baseline Loss: 2.8574 | Actual Loss: 0.4575\n",
      "Baseline Loss: 2.7899 | Actual Loss: 0.4096\n",
      "Baseline Loss: 2.8634 | Actual Loss: 0.2304\n",
      "Baseline Loss: 2.7268 | Actual Loss: 0.2766\n",
      "Baseline Loss: 2.8185 | Actual Loss: 0.2550\n",
      "Baseline Loss: 2.8108 | Actual Loss: 1.0259\n",
      "Baseline Loss: 2.8882 | Actual Loss: 0.3008\n",
      "Baseline Loss: 2.8105 | Actual Loss: 0.2480\n",
      "Baseline Loss: 2.8046 | Actual Loss: 0.3513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 72/1000 [00:30<06:26,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8652 | Actual Loss: 0.1828\n",
      "Baseline Loss: 2.8409 | Actual Loss: 0.2578\n",
      "Baseline Loss: 2.8131 | Actual Loss: 0.2015\n",
      "Baseline Loss: 2.7354 | Actual Loss: 0.3007\n",
      "Baseline Loss: 2.9432 | Actual Loss: 0.2295\n",
      "Baseline Loss: 2.5380 | Actual Loss: 0.3233\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2564\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5713\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3494\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2980\n",
      "Epoch 72/1000: Train Loss: 0.3362, Val Loss: 0.3688\n",
      "Baseline Loss: 2.8414 | Actual Loss: 0.2730\n",
      "Baseline Loss: 2.7908 | Actual Loss: 0.4554\n",
      "Baseline Loss: 2.7917 | Actual Loss: 0.2175\n",
      "Baseline Loss: 2.8753 | Actual Loss: 0.2884\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2918\n",
      "Baseline Loss: 2.7805 | Actual Loss: 0.3482\n",
      "Baseline Loss: 2.8412 | Actual Loss: 0.3170\n",
      "Baseline Loss: 2.7761 | Actual Loss: 0.4228\n",
      "Baseline Loss: 2.7858 | Actual Loss: 0.2888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 73/1000 [00:30<06:33,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8092 | Actual Loss: 0.1237\n",
      "Baseline Loss: 2.8826 | Actual Loss: 0.2764\n",
      "Baseline Loss: 2.8608 | Actual Loss: 0.2768\n",
      "Baseline Loss: 2.8471 | Actual Loss: 0.3036\n",
      "Baseline Loss: 2.7697 | Actual Loss: 0.2061\n",
      "Baseline Loss: 2.7937 | Actual Loss: 0.2945\n",
      "Baseline Loss: 2.6363 | Actual Loss: 0.1824\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2567\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5543\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2916\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.3540\n",
      "Epoch 73/1000: Train Loss: 0.2854, Val Loss: 0.3641\n",
      "Baseline Loss: 2.8423 | Actual Loss: 0.1571\n",
      "Baseline Loss: 2.8355 | Actual Loss: 0.3033\n",
      "Baseline Loss: 2.8645 | Actual Loss: 0.2740\n",
      "Baseline Loss: 2.8069 | Actual Loss: 0.2011\n",
      "Baseline Loss: 2.7589 | Actual Loss: 0.1985\n",
      "Baseline Loss: 2.9169 | Actual Loss: 0.3295\n",
      "Baseline Loss: 2.8323 | Actual Loss: 0.2695\n",
      "Baseline Loss: 2.7681 | Actual Loss: 0.2774\n",
      "Baseline Loss: 2.7819 | Actual Loss: 0.4462\n",
      "Baseline Loss: 2.8489 | Actual Loss: 0.4665\n",
      "Baseline Loss: 2.8907 | Actual Loss: 0.3961\n",
      "Baseline Loss: 2.8447 | Actual Loss: 0.2775\n",
      "Baseline Loss: 2.7837 | Actual Loss: 0.2909\n",
      "Baseline Loss: 2.8251 | Actual Loss: 0.2665\n",
      "Baseline Loss: 2.8862 | Actual Loss: 0.4183\n",
      "Baseline Loss: 2.5906 | Actual Loss: 0.1217\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2943\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.6107\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 74/1000 [00:31<06:38,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7416 | Actual Loss: 0.6561\n",
      "Epoch 74/1000: Train Loss: 0.2934, Val Loss: 0.4747\n",
      "Baseline Loss: 2.8084 | Actual Loss: 0.3352\n",
      "Baseline Loss: 2.8139 | Actual Loss: 0.1028\n",
      "Baseline Loss: 2.8813 | Actual Loss: 0.5000\n",
      "Baseline Loss: 2.8400 | Actual Loss: 0.2432\n",
      "Baseline Loss: 2.8605 | Actual Loss: 0.3252\n",
      "Baseline Loss: 2.9363 | Actual Loss: 0.2687\n",
      "Baseline Loss: 2.8133 | Actual Loss: 0.2210\n",
      "Baseline Loss: 2.8062 | Actual Loss: 0.1901\n",
      "Baseline Loss: 2.7274 | Actual Loss: 0.3842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 75/1000 [00:31<06:19,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8643 | Actual Loss: 0.2240\n",
      "Baseline Loss: 2.8123 | Actual Loss: 0.2839\n",
      "Baseline Loss: 2.7438 | Actual Loss: 0.3826\n",
      "Baseline Loss: 2.8131 | Actual Loss: 0.5002\n",
      "Baseline Loss: 2.8013 | Actual Loss: 0.2538\n",
      "Baseline Loss: 2.8402 | Actual Loss: 0.3346\n",
      "Baseline Loss: 2.5668 | Actual Loss: 0.4937\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.3035\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.7162\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3294\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2676\n",
      "Epoch 75/1000: Train Loss: 0.3152, Val Loss: 0.4042\n",
      "Baseline Loss: 2.7486 | Actual Loss: 0.2193\n",
      "Baseline Loss: 2.8254 | Actual Loss: 0.2445\n",
      "Baseline Loss: 2.7534 | Actual Loss: 0.5379\n",
      "Baseline Loss: 2.8474 | Actual Loss: 0.2400\n",
      "Baseline Loss: 2.8614 | Actual Loss: 0.2228\n",
      "Baseline Loss: 2.7781 | Actual Loss: 0.3261\n",
      "Baseline Loss: 2.7699 | Actual Loss: 0.3975\n",
      "Baseline Loss: 2.8540 | Actual Loss: 0.3214\n",
      "Baseline Loss: 2.8095 | Actual Loss: 0.3503\n",
      "Baseline Loss: 2.9867 | Actual Loss: 0.2656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 76/1000 [00:31<06:29,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8196 | Actual Loss: 0.2668\n",
      "Baseline Loss: 2.7690 | Actual Loss: 0.3017\n",
      "Baseline Loss: 2.9697 | Actual Loss: 0.2503\n",
      "Baseline Loss: 2.7876 | Actual Loss: 0.2809\n",
      "Baseline Loss: 2.8190 | Actual Loss: 0.2256\n",
      "Baseline Loss: 2.6321 | Actual Loss: 0.1132\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2439\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.6547\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2543\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.3395\n",
      "Epoch 76/1000: Train Loss: 0.2852, Val Loss: 0.3731\n",
      "Baseline Loss: 2.8645 | Actual Loss: 0.1733\n",
      "Baseline Loss: 2.8460 | Actual Loss: 0.3315\n",
      "Baseline Loss: 2.8436 | Actual Loss: 0.2074\n",
      "Baseline Loss: 2.8215 | Actual Loss: 0.2511\n",
      "Baseline Loss: 2.8491 | Actual Loss: 0.2871\n",
      "Baseline Loss: 2.9563 | Actual Loss: 0.2066\n",
      "Baseline Loss: 2.8022 | Actual Loss: 0.5543\n",
      "Baseline Loss: 2.8408 | Actual Loss: 0.2797\n",
      "Baseline Loss: 2.8415 | Actual Loss: 0.2017\n",
      "Baseline Loss: 2.8053 | Actual Loss: 0.2272\n",
      "Baseline Loss: 2.8245 | Actual Loss: 0.2491\n",
      "Baseline Loss: 2.8105 | Actual Loss: 0.1666\n",
      "Baseline Loss: 2.7997 | Actual Loss: 0.2318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 77/1000 [00:32<06:33,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8169 | Actual Loss: 0.3371\n",
      "Baseline Loss: 2.7500 | Actual Loss: 0.3297\n",
      "Baseline Loss: 2.4475 | Actual Loss: 0.1056\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.3663\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5369\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3031\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.4085\n",
      "Epoch 77/1000: Train Loss: 0.2587, Val Loss: 0.4037\n",
      "Baseline Loss: 2.8271 | Actual Loss: 0.3102\n",
      "Baseline Loss: 2.8816 | Actual Loss: 0.1329\n",
      "Baseline Loss: 2.8495 | Actual Loss: 0.2884\n",
      "Baseline Loss: 2.8007 | Actual Loss: 0.2258\n",
      "Baseline Loss: 2.8049 | Actual Loss: 0.2620\n",
      "Baseline Loss: 2.8472 | Actual Loss: 0.1899\n",
      "Baseline Loss: 2.7770 | Actual Loss: 0.4030\n",
      "Baseline Loss: 2.8535 | Actual Loss: 0.5273\n",
      "Baseline Loss: 2.7962 | Actual Loss: 0.3779\n",
      "Baseline Loss: 2.8338 | Actual Loss: 0.1509\n",
      "Baseline Loss: 2.8257 | Actual Loss: 0.1697\n",
      "Baseline Loss: 2.8669 | Actual Loss: 0.4058\n",
      "Baseline Loss: 2.7936 | Actual Loss: 0.3159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 78/1000 [00:32<06:14,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7868 | Actual Loss: 0.3455\n",
      "Baseline Loss: 2.8719 | Actual Loss: 0.4205\n",
      "Baseline Loss: 2.4996 | Actual Loss: 0.1078\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.3899\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.6078\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3195\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2717\n",
      "Epoch 78/1000: Train Loss: 0.2896, Val Loss: 0.3973\n",
      "Baseline Loss: 2.8728 | Actual Loss: 0.2539\n",
      "Baseline Loss: 2.8243 | Actual Loss: 0.3625\n",
      "Baseline Loss: 2.8075 | Actual Loss: 0.1921\n",
      "Baseline Loss: 2.7882 | Actual Loss: 0.4374\n",
      "Baseline Loss: 2.8375 | Actual Loss: 0.1456\n",
      "Baseline Loss: 2.7508 | Actual Loss: 0.3582\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.2574\n",
      "Baseline Loss: 2.8025 | Actual Loss: 0.1409\n",
      "Baseline Loss: 2.8796 | Actual Loss: 0.4681\n",
      "Baseline Loss: 2.8852 | Actual Loss: 0.2343\n",
      "Baseline Loss: 2.8235 | Actual Loss: 0.2783\n",
      "Baseline Loss: 2.8666 | Actual Loss: 0.4348\n",
      "Baseline Loss: 2.8478 | Actual Loss: 0.2992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 79/1000 [00:33<06:29,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7920 | Actual Loss: 0.3268\n",
      "Baseline Loss: 2.7920 | Actual Loss: 0.1687\n",
      "Baseline Loss: 2.4393 | Actual Loss: 0.2268\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.3223\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5598\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.4053\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2961\n",
      "Epoch 79/1000: Train Loss: 0.2866, Val Loss: 0.3959\n",
      "Baseline Loss: 2.8719 | Actual Loss: 0.3765\n",
      "Baseline Loss: 2.8506 | Actual Loss: 0.3310\n",
      "Baseline Loss: 2.8001 | Actual Loss: 0.1788\n",
      "Baseline Loss: 2.8512 | Actual Loss: 0.1711\n",
      "Baseline Loss: 2.8500 | Actual Loss: 0.4396\n",
      "Baseline Loss: 2.7607 | Actual Loss: 0.3029\n",
      "Baseline Loss: 2.8137 | Actual Loss: 0.1791\n",
      "Baseline Loss: 2.7952 | Actual Loss: 0.2076\n",
      "Baseline Loss: 2.7984 | Actual Loss: 0.3494\n",
      "Baseline Loss: 2.9118 | Actual Loss: 0.2276\n",
      "Baseline Loss: 2.8961 | Actual Loss: 0.1199\n",
      "Baseline Loss: 2.7511 | Actual Loss: 0.2059\n",
      "Baseline Loss: 2.8129 | Actual Loss: 0.4841\n",
      "Baseline Loss: 2.8346 | Actual Loss: 0.1880\n",
      "Baseline Loss: 2.8799 | Actual Loss: 0.3594\n",
      "Baseline Loss: 2.6647 | Actual Loss: 0.1778\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 80/1000 [00:33<06:14,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8514 | Actual Loss: 0.3860\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3813\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2610\n",
      "Epoch 80/1000: Train Loss: 0.2687, Val Loss: 0.3153\n",
      "New best validation loss: 0.3153\n",
      "Baseline Loss: 2.8327 | Actual Loss: 0.3372\n",
      "Baseline Loss: 2.8140 | Actual Loss: 0.2477\n",
      "Baseline Loss: 2.8236 | Actual Loss: 0.3409\n",
      "Baseline Loss: 2.8559 | Actual Loss: 0.2486\n",
      "Baseline Loss: 2.8444 | Actual Loss: 0.2297\n",
      "Baseline Loss: 2.8639 | Actual Loss: 0.3501\n",
      "Baseline Loss: 2.8152 | Actual Loss: 0.3606\n",
      "Baseline Loss: 2.8342 | Actual Loss: 0.2372\n",
      "Baseline Loss: 2.8683 | Actual Loss: 0.2851\n",
      "Baseline Loss: 2.8045 | Actual Loss: 0.2870\n",
      "Baseline Loss: 2.7685 | Actual Loss: 0.2196\n",
      "Baseline Loss: 2.8781 | Actual Loss: 0.5509\n",
      "Baseline Loss: 2.8165 | Actual Loss: 0.2549\n",
      "Baseline Loss: 2.7991 | Actual Loss: 0.1603\n",
      "Baseline Loss: 2.8695 | Actual Loss: 0.2114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 81/1000 [00:33<06:24,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5126 | Actual Loss: 0.3930\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.3113\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5958\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3218\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.3715\n",
      "Epoch 81/1000: Train Loss: 0.2946, Val Loss: 0.4001\n",
      "Baseline Loss: 2.8397 | Actual Loss: 0.2192\n",
      "Baseline Loss: 2.7896 | Actual Loss: 0.2090\n",
      "Baseline Loss: 2.8218 | Actual Loss: 0.2482\n",
      "Baseline Loss: 2.8288 | Actual Loss: 0.5047\n",
      "Baseline Loss: 2.7777 | Actual Loss: 0.2576\n",
      "Baseline Loss: 2.8432 | Actual Loss: 0.2681\n",
      "Baseline Loss: 2.8072 | Actual Loss: 0.3495\n",
      "Baseline Loss: 2.8299 | Actual Loss: 0.2546\n",
      "Baseline Loss: 2.8080 | Actual Loss: 0.1462\n",
      "Baseline Loss: 2.8492 | Actual Loss: 0.2716\n",
      "Baseline Loss: 2.8728 | Actual Loss: 0.2522\n",
      "Baseline Loss: 2.8312 | Actual Loss: 0.1008\n",
      "Baseline Loss: 2.8630 | Actual Loss: 0.1987\n",
      "Baseline Loss: 2.7873 | Actual Loss: 0.1722\n",
      "Baseline Loss: 2.8216 | Actual Loss: 0.1639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 82/1000 [00:34<06:32,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5729 | Actual Loss: 0.2880\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2713\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4613\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3561\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.3952\n",
      "Epoch 82/1000: Train Loss: 0.2440, Val Loss: 0.3710\n",
      "Baseline Loss: 2.8504 | Actual Loss: 0.2967\n",
      "Baseline Loss: 2.8349 | Actual Loss: 0.2707\n",
      "Baseline Loss: 2.8634 | Actual Loss: 0.2310\n",
      "Baseline Loss: 2.8687 | Actual Loss: 0.2043\n",
      "Baseline Loss: 2.7708 | Actual Loss: 0.3869\n",
      "Baseline Loss: 2.7911 | Actual Loss: 0.2470\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2506\n",
      "Baseline Loss: 2.8580 | Actual Loss: 0.2181\n",
      "Baseline Loss: 2.8843 | Actual Loss: 0.2675\n",
      "Baseline Loss: 2.8200 | Actual Loss: 0.2930\n",
      "Baseline Loss: 2.8461 | Actual Loss: 0.4198\n",
      "Baseline Loss: 2.8231 | Actual Loss: 0.1614\n",
      "Baseline Loss: 2.8630 | Actual Loss: 0.3116\n",
      "Baseline Loss: 2.7776 | Actual Loss: 0.6494\n",
      "Baseline Loss: 2.7819 | Actual Loss: 0.6059\n",
      "Baseline Loss: 2.5723 | Actual Loss: 0.1100\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2829\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.6607\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.4239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 83/1000 [00:34<06:13,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7416 | Actual Loss: 0.7145\n",
      "Epoch 83/1000: Train Loss: 0.3077, Val Loss: 0.5205\n",
      "Baseline Loss: 2.8576 | Actual Loss: 0.3825\n",
      "Baseline Loss: 2.8146 | Actual Loss: 0.4780\n",
      "Baseline Loss: 2.7823 | Actual Loss: 0.3306\n",
      "Baseline Loss: 2.8114 | Actual Loss: 0.2064\n",
      "Baseline Loss: 2.8755 | Actual Loss: 0.2747\n",
      "Baseline Loss: 2.7915 | Actual Loss: 0.2397\n",
      "Baseline Loss: 2.8466 | Actual Loss: 0.5647\n",
      "Baseline Loss: 2.9187 | Actual Loss: 0.4066\n",
      "Baseline Loss: 2.8185 | Actual Loss: 0.2251\n",
      "Baseline Loss: 2.8742 | Actual Loss: 0.2717\n",
      "Baseline Loss: 2.8329 | Actual Loss: 0.2385\n",
      "Baseline Loss: 2.8176 | Actual Loss: 0.2780\n",
      "Baseline Loss: 2.7612 | Actual Loss: 0.1998\n",
      "Baseline Loss: 2.8483 | Actual Loss: 0.2581\n",
      "Baseline Loss: 2.8600 | Actual Loss: 0.2030\n",
      "Baseline Loss: 2.5089 | Actual Loss: 0.0899\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2425\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5475\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.4180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 84/1000 [00:35<06:19,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7416 | Actual Loss: 0.3751\n",
      "Epoch 84/1000: Train Loss: 0.2905, Val Loss: 0.3958\n",
      "Baseline Loss: 2.8422 | Actual Loss: 0.8662\n",
      "Baseline Loss: 2.8198 | Actual Loss: 0.2671\n",
      "Baseline Loss: 2.8312 | Actual Loss: 0.2818\n",
      "Baseline Loss: 2.8577 | Actual Loss: 0.3072\n",
      "Baseline Loss: 2.7958 | Actual Loss: 0.3839\n",
      "Baseline Loss: 2.8429 | Actual Loss: 0.2080\n",
      "Baseline Loss: 2.7978 | Actual Loss: 0.5013\n",
      "Baseline Loss: 2.8785 | Actual Loss: 0.3394\n",
      "Baseline Loss: 2.9113 | Actual Loss: 0.3021\n",
      "Baseline Loss: 2.8034 | Actual Loss: 0.2526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 85/1000 [00:35<06:08,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7594 | Actual Loss: 0.1879\n",
      "Baseline Loss: 2.8361 | Actual Loss: 0.2941\n",
      "Baseline Loss: 2.8305 | Actual Loss: 0.2812\n",
      "Baseline Loss: 2.7609 | Actual Loss: 0.3389\n",
      "Baseline Loss: 2.8288 | Actual Loss: 0.5877\n",
      "Baseline Loss: 2.5341 | Actual Loss: 0.3746\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2536\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5075\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2323\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.4524\n",
      "Epoch 85/1000: Train Loss: 0.3609, Val Loss: 0.3614\n",
      "Baseline Loss: 2.8648 | Actual Loss: 0.3213\n",
      "Baseline Loss: 2.8704 | Actual Loss: 0.2014\n",
      "Baseline Loss: 2.7811 | Actual Loss: 0.2543\n",
      "Baseline Loss: 2.7885 | Actual Loss: 0.2375\n",
      "Baseline Loss: 2.9132 | Actual Loss: 0.2681\n",
      "Baseline Loss: 2.8241 | Actual Loss: 0.5344\n",
      "Baseline Loss: 2.8318 | Actual Loss: 0.2157\n",
      "Baseline Loss: 2.8154 | Actual Loss: 0.2704\n",
      "Baseline Loss: 2.8109 | Actual Loss: 0.3332\n",
      "Baseline Loss: 2.7732 | Actual Loss: 0.3452\n",
      "Baseline Loss: 2.8683 | Actual Loss: 0.2956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▊         | 86/1000 [00:36<06:24,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7680 | Actual Loss: 0.3771\n",
      "Baseline Loss: 2.8630 | Actual Loss: 0.2681\n",
      "Baseline Loss: 2.8531 | Actual Loss: 0.3368\n",
      "Baseline Loss: 2.7864 | Actual Loss: 0.1659\n",
      "Baseline Loss: 2.4501 | Actual Loss: 0.1826\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.3101\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5004\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3501\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.3978\n",
      "Epoch 86/1000: Train Loss: 0.2880, Val Loss: 0.3896\n",
      "Baseline Loss: 2.8167 | Actual Loss: 0.2562\n",
      "Baseline Loss: 2.8318 | Actual Loss: 0.2988\n",
      "Baseline Loss: 2.8320 | Actual Loss: 0.2771\n",
      "Baseline Loss: 2.9011 | Actual Loss: 0.1761\n",
      "Baseline Loss: 2.7459 | Actual Loss: 0.3393\n",
      "Baseline Loss: 2.8571 | Actual Loss: 0.2027\n",
      "Baseline Loss: 2.8954 | Actual Loss: 0.2904\n",
      "Baseline Loss: 2.8040 | Actual Loss: 0.2277\n",
      "Baseline Loss: 2.8363 | Actual Loss: 0.2222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▊         | 87/1000 [00:36<06:26,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8802 | Actual Loss: 0.3567\n",
      "Baseline Loss: 2.8040 | Actual Loss: 0.2294\n",
      "Baseline Loss: 2.8803 | Actual Loss: 0.2036\n",
      "Baseline Loss: 2.7727 | Actual Loss: 0.1865\n",
      "Baseline Loss: 2.8422 | Actual Loss: 0.2704\n",
      "Baseline Loss: 2.8489 | Actual Loss: 0.3003\n",
      "Baseline Loss: 2.4801 | Actual Loss: 0.2055\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.3146\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5596\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3233\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.3281\n",
      "Epoch 87/1000: Train Loss: 0.2527, Val Loss: 0.3814\n",
      "Baseline Loss: 2.8313 | Actual Loss: 0.3380\n",
      "Baseline Loss: 2.8392 | Actual Loss: 0.3227\n",
      "Baseline Loss: 2.8178 | Actual Loss: 0.1272\n",
      "Baseline Loss: 2.8367 | Actual Loss: 0.1561\n",
      "Baseline Loss: 2.7960 | Actual Loss: 0.4863\n",
      "Baseline Loss: 2.7949 | Actual Loss: 0.2398\n",
      "Baseline Loss: 2.8918 | Actual Loss: 0.2197\n",
      "Baseline Loss: 2.7921 | Actual Loss: 0.1172\n",
      "Baseline Loss: 2.7986 | Actual Loss: 0.2457\n",
      "Baseline Loss: 2.8954 | Actual Loss: 1.0292\n",
      "Baseline Loss: 2.8446 | Actual Loss: 0.2015\n",
      "Baseline Loss: 2.8200 | Actual Loss: 0.2970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 88/1000 [00:36<06:14,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8282 | Actual Loss: 0.1681\n",
      "Baseline Loss: 2.8148 | Actual Loss: 0.2722\n",
      "Baseline Loss: 2.8678 | Actual Loss: 0.3618\n",
      "Baseline Loss: 2.6673 | Actual Loss: 0.3737\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2019\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.3885\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2892\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.4569\n",
      "Epoch 88/1000: Train Loss: 0.3098, Val Loss: 0.3341\n",
      "Baseline Loss: 2.8019 | Actual Loss: 0.2868\n",
      "Baseline Loss: 2.9251 | Actual Loss: 0.3186\n",
      "Baseline Loss: 2.8102 | Actual Loss: 0.3108\n",
      "Baseline Loss: 2.8604 | Actual Loss: 0.3292\n",
      "Baseline Loss: 2.8637 | Actual Loss: 0.2003\n",
      "Baseline Loss: 2.8030 | Actual Loss: 0.4341\n",
      "Baseline Loss: 2.8786 | Actual Loss: 0.2201\n",
      "Baseline Loss: 2.8314 | Actual Loss: 0.3980\n",
      "Baseline Loss: 2.8629 | Actual Loss: 0.2555\n",
      "Baseline Loss: 2.8210 | Actual Loss: 0.1748\n",
      "Baseline Loss: 2.8299 | Actual Loss: 0.3102\n",
      "Baseline Loss: 2.8823 | Actual Loss: 0.2016\n",
      "Baseline Loss: 2.7625 | Actual Loss: 0.2033\n",
      "Baseline Loss: 2.7657 | Actual Loss: 0.2568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 89/1000 [00:37<06:18,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7718 | Actual Loss: 0.2449\n",
      "Baseline Loss: 2.6400 | Actual Loss: 0.2308\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2146\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.7927\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3933\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.4947\n",
      "Epoch 89/1000: Train Loss: 0.2735, Val Loss: 0.4738\n",
      "Baseline Loss: 2.8191 | Actual Loss: 0.2077\n",
      "Baseline Loss: 2.8614 | Actual Loss: 0.1300\n",
      "Baseline Loss: 2.9119 | Actual Loss: 0.3399\n",
      "Baseline Loss: 2.8055 | Actual Loss: 0.2829\n",
      "Baseline Loss: 2.9091 | Actual Loss: 0.1879\n",
      "Baseline Loss: 2.8074 | Actual Loss: 0.6262\n",
      "Baseline Loss: 2.8564 | Actual Loss: 0.4149\n",
      "Baseline Loss: 2.8090 | Actual Loss: 0.2400\n",
      "Baseline Loss: 2.7651 | Actual Loss: 0.2735\n",
      "Baseline Loss: 2.7869 | Actual Loss: 0.1577\n",
      "Baseline Loss: 2.7546 | Actual Loss: 0.1674\n",
      "Baseline Loss: 2.8094 | Actual Loss: 0.1666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 90/1000 [00:37<06:31,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8386 | Actual Loss: 0.3025\n",
      "Baseline Loss: 2.7571 | Actual Loss: 0.1835\n",
      "Baseline Loss: 2.9126 | Actual Loss: 0.3670\n",
      "Baseline Loss: 2.5968 | Actual Loss: 0.5477\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1794\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5003\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2909\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2704\n",
      "Epoch 90/1000: Train Loss: 0.2872, Val Loss: 0.3103\n",
      "New best validation loss: 0.3103\n",
      "Baseline Loss: 2.7393 | Actual Loss: 0.1262\n",
      "Baseline Loss: 2.8324 | Actual Loss: 0.1738\n",
      "Baseline Loss: 2.8379 | Actual Loss: 0.2528\n",
      "Baseline Loss: 2.9633 | Actual Loss: 0.2466\n",
      "Baseline Loss: 2.7724 | Actual Loss: 0.4151\n",
      "Baseline Loss: 2.8306 | Actual Loss: 0.3772\n",
      "Baseline Loss: 2.8958 | Actual Loss: 0.2450\n",
      "Baseline Loss: 2.8367 | Actual Loss: 0.2781\n",
      "Baseline Loss: 2.8483 | Actual Loss: 0.2786\n",
      "Baseline Loss: 2.7664 | Actual Loss: 0.1298\n",
      "Baseline Loss: 2.8143 | Actual Loss: 0.2276\n",
      "Baseline Loss: 2.8286 | Actual Loss: 0.2194\n",
      "Baseline Loss: 2.8648 | Actual Loss: 0.2538\n",
      "Baseline Loss: 2.9167 | Actual Loss: 0.3278\n",
      "Baseline Loss: 2.8287 | Actual Loss: 0.3071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 91/1000 [00:38<06:17,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6489 | Actual Loss: 0.1901\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2136\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5268\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3366\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2836\n",
      "Epoch 91/1000: Train Loss: 0.2531, Val Loss: 0.3402\n",
      "Baseline Loss: 2.7886 | Actual Loss: 0.1609\n",
      "Baseline Loss: 2.8043 | Actual Loss: 0.2689\n",
      "Baseline Loss: 2.8239 | Actual Loss: 0.1980\n",
      "Baseline Loss: 2.9146 | Actual Loss: 0.3768\n",
      "Baseline Loss: 2.8656 | Actual Loss: 0.3282\n",
      "Baseline Loss: 2.8508 | Actual Loss: 0.2363\n",
      "Baseline Loss: 2.8170 | Actual Loss: 0.2431\n",
      "Baseline Loss: 2.7771 | Actual Loss: 0.1762\n",
      "Baseline Loss: 2.7796 | Actual Loss: 0.2941\n",
      "Baseline Loss: 2.8276 | Actual Loss: 0.3452\n",
      "Baseline Loss: 2.7835 | Actual Loss: 0.2759\n",
      "Baseline Loss: 2.7846 | Actual Loss: 0.3845\n",
      "Baseline Loss: 2.7988 | Actual Loss: 0.2068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 92/1000 [00:38<06:31,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8212 | Actual Loss: 0.1929\n",
      "Baseline Loss: 2.8584 | Actual Loss: 0.2654\n",
      "Baseline Loss: 2.5102 | Actual Loss: 0.1974\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1792\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4140\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3657\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.1758\n",
      "Epoch 92/1000: Train Loss: 0.2594, Val Loss: 0.2837\n",
      "New best validation loss: 0.2837\n",
      "Baseline Loss: 2.7931 | Actual Loss: 0.2266\n",
      "Baseline Loss: 2.7739 | Actual Loss: 0.1300\n",
      "Baseline Loss: 2.8869 | Actual Loss: 0.1304\n",
      "Baseline Loss: 2.9231 | Actual Loss: 0.2269\n",
      "Baseline Loss: 2.8268 | Actual Loss: 0.2193\n",
      "Baseline Loss: 2.8908 | Actual Loss: 0.1683\n",
      "Baseline Loss: 2.7662 | Actual Loss: 0.1776\n",
      "Baseline Loss: 2.8455 | Actual Loss: 0.2977\n",
      "Baseline Loss: 2.7762 | Actual Loss: 0.1402\n",
      "Baseline Loss: 2.8174 | Actual Loss: 0.1312\n",
      "Baseline Loss: 2.7938 | Actual Loss: 0.3155\n",
      "Baseline Loss: 2.8340 | Actual Loss: 0.2621\n",
      "Baseline Loss: 2.8369 | Actual Loss: 0.1639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 93/1000 [00:39<06:34,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8089 | Actual Loss: 0.3930\n",
      "Baseline Loss: 2.8725 | Actual Loss: 0.2610\n",
      "Baseline Loss: 2.5760 | Actual Loss: 0.4960\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2702\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5211\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3089\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2641\n",
      "Epoch 93/1000: Train Loss: 0.2337, Val Loss: 0.3411\n",
      "Baseline Loss: 2.8109 | Actual Loss: 0.2882\n",
      "Baseline Loss: 2.8739 | Actual Loss: 0.2079\n",
      "Baseline Loss: 2.8774 | Actual Loss: 0.3681\n",
      "Baseline Loss: 2.8300 | Actual Loss: 0.1155\n",
      "Baseline Loss: 2.8288 | Actual Loss: 0.2873\n",
      "Baseline Loss: 2.8239 | Actual Loss: 0.2195\n",
      "Baseline Loss: 2.8182 | Actual Loss: 0.2228\n",
      "Baseline Loss: 2.7970 | Actual Loss: 0.2309\n",
      "Baseline Loss: 2.7320 | Actual Loss: 0.2256\n",
      "Baseline Loss: 2.8290 | Actual Loss: 0.2358\n",
      "Baseline Loss: 2.7965 | Actual Loss: 0.3390\n",
      "Baseline Loss: 2.8348 | Actual Loss: 0.1839\n",
      "Baseline Loss: 2.8084 | Actual Loss: 0.2632\n",
      "Baseline Loss: 2.8279 | Actual Loss: 0.1706\n",
      "Baseline Loss: 2.7871 | Actual Loss: 0.3193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 94/1000 [00:39<06:20,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.4852 | Actual Loss: 0.1253\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2163\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5866\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3464\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2764\n",
      "Epoch 94/1000: Train Loss: 0.2377, Val Loss: 0.3564\n",
      "Baseline Loss: 2.8171 | Actual Loss: 0.1126\n",
      "Baseline Loss: 2.8647 | Actual Loss: 0.1645\n",
      "Baseline Loss: 2.8231 | Actual Loss: 0.3465\n",
      "Baseline Loss: 2.8198 | Actual Loss: 0.3225\n",
      "Baseline Loss: 2.8009 | Actual Loss: 0.2639\n",
      "Baseline Loss: 2.8492 | Actual Loss: 0.1818\n",
      "Baseline Loss: 2.8065 | Actual Loss: 0.3617\n",
      "Baseline Loss: 2.7653 | Actual Loss: 0.2315\n",
      "Baseline Loss: 2.8057 | Actual Loss: 0.2479\n",
      "Baseline Loss: 2.8959 | Actual Loss: 0.1928\n",
      "Baseline Loss: 2.7832 | Actual Loss: 0.2384\n",
      "Baseline Loss: 2.8541 | Actual Loss: 0.1557\n",
      "Baseline Loss: 2.9051 | Actual Loss: 0.3266\n",
      "Baseline Loss: 2.8954 | Actual Loss: 0.2326\n",
      "Baseline Loss: 2.8213 | Actual Loss: 0.2292\n",
      "Baseline Loss: 2.4226 | Actual Loss: 0.2278\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 95/1000 [00:39<06:26,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8514 | Actual Loss: 0.5657\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.4474\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.3768\n",
      "Epoch 95/1000: Train Loss: 0.2397, Val Loss: 0.3944\n",
      "Baseline Loss: 2.8578 | Actual Loss: 0.1579\n",
      "Baseline Loss: 2.8839 | Actual Loss: 0.3319\n",
      "Baseline Loss: 2.8065 | Actual Loss: 0.2299\n",
      "Baseline Loss: 2.7732 | Actual Loss: 0.3271\n",
      "Baseline Loss: 2.8126 | Actual Loss: 0.2931\n",
      "Baseline Loss: 2.8501 | Actual Loss: 0.2753\n",
      "Baseline Loss: 2.8314 | Actual Loss: 0.2781\n",
      "Baseline Loss: 2.8044 | Actual Loss: 0.1583\n",
      "Baseline Loss: 2.7701 | Actual Loss: 0.2984\n",
      "Baseline Loss: 2.7858 | Actual Loss: 0.3154\n",
      "Baseline Loss: 2.8066 | Actual Loss: 0.2798\n",
      "Baseline Loss: 2.7974 | Actual Loss: 0.4980\n",
      "Baseline Loss: 2.8203 | Actual Loss: 0.2450\n",
      "Baseline Loss: 2.8090 | Actual Loss: 0.2689\n",
      "Baseline Loss: 2.7536 | Actual Loss: 0.3491\n",
      "Baseline Loss: 2.5631 | Actual Loss: 0.2344\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2137\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5330\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 96/1000 [00:40<06:27,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7416 | Actual Loss: 0.4257\n",
      "Epoch 96/1000: Train Loss: 0.2838, Val Loss: 0.3653\n",
      "Baseline Loss: 2.7323 | Actual Loss: 0.1346\n",
      "Baseline Loss: 2.7993 | Actual Loss: 0.2122\n",
      "Baseline Loss: 2.7507 | Actual Loss: 0.2855\n",
      "Baseline Loss: 2.8510 | Actual Loss: 0.1012\n",
      "Baseline Loss: 2.8780 | Actual Loss: 0.2869\n",
      "Baseline Loss: 2.8875 | Actual Loss: 0.2316\n",
      "Baseline Loss: 2.8758 | Actual Loss: 0.2497\n",
      "Baseline Loss: 2.8363 | Actual Loss: 0.2012\n",
      "Baseline Loss: 2.7382 | Actual Loss: 0.3674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 97/1000 [00:40<06:14,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7595 | Actual Loss: 0.2733\n",
      "Baseline Loss: 2.8251 | Actual Loss: 0.2970\n",
      "Baseline Loss: 2.7662 | Actual Loss: 0.1945\n",
      "Baseline Loss: 2.8050 | Actual Loss: 0.3290\n",
      "Baseline Loss: 2.9046 | Actual Loss: 0.2231\n",
      "Baseline Loss: 2.8190 | Actual Loss: 0.3528\n",
      "Baseline Loss: 2.6022 | Actual Loss: 0.1170\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2002\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4532\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.4260\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2412\n",
      "Epoch 97/1000: Train Loss: 0.2411, Val Loss: 0.3302\n",
      "Baseline Loss: 2.7530 | Actual Loss: 0.2455\n",
      "Baseline Loss: 2.8313 | Actual Loss: 0.2318\n",
      "Baseline Loss: 2.8014 | Actual Loss: 0.3950\n",
      "Baseline Loss: 2.8248 | Actual Loss: 0.3605\n",
      "Baseline Loss: 2.8068 | Actual Loss: 0.2684\n",
      "Baseline Loss: 2.8210 | Actual Loss: 0.1220\n",
      "Baseline Loss: 2.8130 | Actual Loss: 0.2314\n",
      "Baseline Loss: 2.7853 | Actual Loss: 0.2049\n",
      "Baseline Loss: 2.8320 | Actual Loss: 0.2159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 98/1000 [00:41<06:17,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8475 | Actual Loss: 0.1897\n",
      "Baseline Loss: 2.8540 | Actual Loss: 0.3445\n",
      "Baseline Loss: 2.8318 | Actual Loss: 0.1872\n",
      "Baseline Loss: 2.9530 | Actual Loss: 0.3257\n",
      "Baseline Loss: 2.8175 | Actual Loss: 0.2291\n",
      "Baseline Loss: 2.8356 | Actual Loss: 0.3608\n",
      "Baseline Loss: 2.6045 | Actual Loss: 0.0987\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2450\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.6312\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2716\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2440\n",
      "Epoch 98/1000: Train Loss: 0.2507, Val Loss: 0.3480\n",
      "Baseline Loss: 2.8826 | Actual Loss: 0.1321\n",
      "Baseline Loss: 2.8261 | Actual Loss: 0.2741\n",
      "Baseline Loss: 2.8605 | Actual Loss: 0.2496\n",
      "Baseline Loss: 2.8502 | Actual Loss: 0.4428\n",
      "Baseline Loss: 2.7721 | Actual Loss: 0.4007\n",
      "Baseline Loss: 2.8687 | Actual Loss: 0.3006\n",
      "Baseline Loss: 2.7923 | Actual Loss: 0.2411\n",
      "Baseline Loss: 2.7872 | Actual Loss: 0.3234\n",
      "Baseline Loss: 2.8129 | Actual Loss: 0.7779\n",
      "Baseline Loss: 2.8356 | Actual Loss: 0.3566\n",
      "Baseline Loss: 2.7822 | Actual Loss: 0.2807\n",
      "Baseline Loss: 2.7920 | Actual Loss: 0.1981\n",
      "Baseline Loss: 2.8343 | Actual Loss: 0.1181\n",
      "Baseline Loss: 2.8809 | Actual Loss: 0.3174\n",
      "Baseline Loss: 2.8911 | Actual Loss: 0.2138\n",
      "Baseline Loss: 2.6057 | Actual Loss: 0.2061\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1978\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5419\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 99/1000 [00:41<06:24,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7416 | Actual Loss: 0.3997\n",
      "Epoch 99/1000: Train Loss: 0.3021, Val Loss: 0.3725\n",
      "Baseline Loss: 2.8100 | Actual Loss: 0.2080\n",
      "Baseline Loss: 2.7919 | Actual Loss: 0.3075\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.2617\n",
      "Baseline Loss: 2.7662 | Actual Loss: 0.2301\n",
      "Baseline Loss: 2.8518 | Actual Loss: 0.3306\n",
      "Baseline Loss: 2.8319 | Actual Loss: 0.1077\n",
      "Baseline Loss: 2.8194 | Actual Loss: 0.1609\n",
      "Baseline Loss: 2.8530 | Actual Loss: 0.2516\n",
      "Baseline Loss: 2.8396 | Actual Loss: 0.3208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 100/1000 [00:41<06:07,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8887 | Actual Loss: 0.2831\n",
      "Baseline Loss: 2.8739 | Actual Loss: 0.2460\n",
      "Baseline Loss: 2.8081 | Actual Loss: 0.2938\n",
      "Baseline Loss: 2.8109 | Actual Loss: 0.2261\n",
      "Baseline Loss: 2.8028 | Actual Loss: 0.1624\n",
      "Baseline Loss: 2.7636 | Actual Loss: 0.2749\n",
      "Baseline Loss: 2.6669 | Actual Loss: 0.1956\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2158\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.7188\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2902\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.4755\n",
      "Epoch 100/1000: Train Loss: 0.2413, Val Loss: 0.4251\n",
      "Baseline Loss: 2.7885 | Actual Loss: 0.1620\n",
      "Baseline Loss: 2.7954 | Actual Loss: 0.2591\n",
      "Baseline Loss: 2.8131 | Actual Loss: 0.3617\n",
      "Baseline Loss: 2.8009 | Actual Loss: 0.5984\n",
      "Baseline Loss: 2.9131 | Actual Loss: 0.1886\n",
      "Baseline Loss: 2.8363 | Actual Loss: 0.3184\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2122\n",
      "Baseline Loss: 2.8368 | Actual Loss: 0.3605\n",
      "Baseline Loss: 2.7910 | Actual Loss: 0.1959\n",
      "Baseline Loss: 2.8142 | Actual Loss: 0.2848\n",
      "Baseline Loss: 2.7870 | Actual Loss: 0.2487\n",
      "Baseline Loss: 2.8222 | Actual Loss: 0.3556\n",
      "Baseline Loss: 2.7731 | Actual Loss: 0.2127\n",
      "Baseline Loss: 2.8032 | Actual Loss: 0.3519\n",
      "Baseline Loss: 2.8826 | Actual Loss: 0.2407\n",
      "Baseline Loss: 2.4925 | Actual Loss: 0.0498\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1956\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4624\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 101/1000 [00:42<06:19,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7416 | Actual Loss: 0.4468\n",
      "Epoch 101/1000: Train Loss: 0.2751, Val Loss: 0.3542\n",
      "Baseline Loss: 2.7971 | Actual Loss: 0.2257\n",
      "Baseline Loss: 2.8612 | Actual Loss: 0.2530\n",
      "Baseline Loss: 2.8826 | Actual Loss: 0.2452\n",
      "Baseline Loss: 2.8693 | Actual Loss: 0.1797\n",
      "Baseline Loss: 2.8053 | Actual Loss: 0.1858\n",
      "Baseline Loss: 2.9037 | Actual Loss: 0.3510\n",
      "Baseline Loss: 2.8600 | Actual Loss: 0.2795\n",
      "Baseline Loss: 2.7739 | Actual Loss: 0.1840\n",
      "Baseline Loss: 2.8007 | Actual Loss: 0.1358\n",
      "Baseline Loss: 2.8146 | Actual Loss: 0.2414\n",
      "Baseline Loss: 2.8766 | Actual Loss: 0.2705\n",
      "Baseline Loss: 2.7740 | Actual Loss: 0.1529\n",
      "Baseline Loss: 2.7932 | Actual Loss: 0.2594\n",
      "Baseline Loss: 2.8079 | Actual Loss: 0.2188\n",
      "Baseline Loss: 2.8121 | Actual Loss: 0.2612\n",
      "Baseline Loss: 2.5216 | Actual Loss: 0.1706\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2787\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.6094\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 102/1000 [00:42<06:23,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7416 | Actual Loss: 0.3406\n",
      "Epoch 102/1000: Train Loss: 0.2259, Val Loss: 0.4026\n",
      "Baseline Loss: 2.8358 | Actual Loss: 0.2897\n",
      "Baseline Loss: 2.7852 | Actual Loss: 0.2820\n",
      "Baseline Loss: 2.8220 | Actual Loss: 0.4052\n",
      "Baseline Loss: 2.8211 | Actual Loss: 0.1894\n",
      "Baseline Loss: 2.7821 | Actual Loss: 0.1943\n",
      "Baseline Loss: 2.8946 | Actual Loss: 0.1717\n",
      "Baseline Loss: 2.8290 | Actual Loss: 0.1735\n",
      "Baseline Loss: 2.8264 | Actual Loss: 0.1188\n",
      "Baseline Loss: 2.8116 | Actual Loss: 0.3151\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 103/1000 [00:43<06:08,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7617 | Actual Loss: 0.2795\n",
      "Baseline Loss: 2.8434 | Actual Loss: 0.2384\n",
      "Baseline Loss: 2.7944 | Actual Loss: 0.2825\n",
      "Baseline Loss: 2.7559 | Actual Loss: 0.2447\n",
      "Baseline Loss: 2.8026 | Actual Loss: 0.2632\n",
      "Baseline Loss: 2.6461 | Actual Loss: 0.4422\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1864\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5957\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2928\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.4198\n",
      "Epoch 103/1000: Train Loss: 0.2550, Val Loss: 0.3737\n",
      "Baseline Loss: 2.7764 | Actual Loss: 0.1992\n",
      "Baseline Loss: 2.7997 | Actual Loss: 0.3109\n",
      "Baseline Loss: 2.8621 | Actual Loss: 0.3156\n",
      "Baseline Loss: 2.8964 | Actual Loss: 0.1177\n",
      "Baseline Loss: 2.7797 | Actual Loss: 0.3056\n",
      "Baseline Loss: 2.7756 | Actual Loss: 0.2247\n",
      "Baseline Loss: 2.7722 | Actual Loss: 0.2812\n",
      "Baseline Loss: 2.7970 | Actual Loss: 0.3292\n",
      "Baseline Loss: 2.8020 | Actual Loss: 0.3128\n",
      "Baseline Loss: 2.8480 | Actual Loss: 0.2994\n",
      "Baseline Loss: 2.8586 | Actual Loss: 0.3938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 104/1000 [00:43<06:17,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8397 | Actual Loss: 0.3498\n",
      "Baseline Loss: 2.8524 | Actual Loss: 0.4348\n",
      "Baseline Loss: 2.8626 | Actual Loss: 0.2906\n",
      "Baseline Loss: 2.8379 | Actual Loss: 0.2356\n",
      "Baseline Loss: 2.5147 | Actual Loss: 0.1707\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2239\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.6824\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3364\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.1868\n",
      "Epoch 104/1000: Train Loss: 0.2857, Val Loss: 0.3573\n",
      "Baseline Loss: 2.7817 | Actual Loss: 0.2267\n",
      "Baseline Loss: 2.9120 | Actual Loss: 0.3199\n",
      "Baseline Loss: 2.8512 | Actual Loss: 0.2917\n",
      "Baseline Loss: 2.8071 | Actual Loss: 0.2532\n",
      "Baseline Loss: 2.7950 | Actual Loss: 0.3030\n",
      "Baseline Loss: 2.8275 | Actual Loss: 0.1376\n",
      "Baseline Loss: 2.7972 | Actual Loss: 0.1658\n",
      "Baseline Loss: 2.8267 | Actual Loss: 0.2162\n",
      "Baseline Loss: 2.8037 | Actual Loss: 0.2305\n",
      "Baseline Loss: 2.8929 | Actual Loss: 0.4787\n",
      "Baseline Loss: 2.8274 | Actual Loss: 0.2051\n",
      "Baseline Loss: 2.8536 | Actual Loss: 0.1770\n",
      "Baseline Loss: 2.8300 | Actual Loss: 0.2014\n",
      "Baseline Loss: 2.8419 | Actual Loss: 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 105/1000 [00:43<05:58,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8698 | Actual Loss: 0.4376\n",
      "Baseline Loss: 2.5607 | Actual Loss: 0.1415\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2310\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.3697\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.4054\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2089\n",
      "Epoch 105/1000: Train Loss: 0.2574, Val Loss: 0.3038\n",
      "Baseline Loss: 2.8698 | Actual Loss: 0.3693\n",
      "Baseline Loss: 2.7619 | Actual Loss: 0.1767\n",
      "Baseline Loss: 2.9388 | Actual Loss: 0.1223\n",
      "Baseline Loss: 2.8681 | Actual Loss: 0.2010\n",
      "Baseline Loss: 2.8077 | Actual Loss: 0.1953\n",
      "Baseline Loss: 2.8172 | Actual Loss: 0.2269\n",
      "Baseline Loss: 2.8001 | Actual Loss: 0.3718\n",
      "Baseline Loss: 2.7923 | Actual Loss: 0.2688\n",
      "Baseline Loss: 2.8220 | Actual Loss: 0.1455\n",
      "Baseline Loss: 2.8700 | Actual Loss: 0.1892\n",
      "Baseline Loss: 2.7637 | Actual Loss: 0.3533\n",
      "Baseline Loss: 2.8286 | Actual Loss: 0.0936\n",
      "Baseline Loss: 2.8075 | Actual Loss: 0.1300\n",
      "Baseline Loss: 2.7920 | Actual Loss: 0.2239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 106/1000 [00:44<06:15,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8086 | Actual Loss: 0.1847\n",
      "Baseline Loss: 2.5395 | Actual Loss: 0.2389\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2278\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.7636\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3091\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.4786\n",
      "Epoch 106/1000: Train Loss: 0.2182, Val Loss: 0.4448\n",
      "Baseline Loss: 2.7538 | Actual Loss: 0.1081\n",
      "Baseline Loss: 2.8393 | Actual Loss: 0.5162\n",
      "Baseline Loss: 2.8637 | Actual Loss: 0.2308\n",
      "Baseline Loss: 2.8066 | Actual Loss: 0.3335\n",
      "Baseline Loss: 2.8053 | Actual Loss: 0.1831\n",
      "Baseline Loss: 2.7943 | Actual Loss: 0.2664\n",
      "Baseline Loss: 2.8390 | Actual Loss: 0.1157\n",
      "Baseline Loss: 2.7994 | Actual Loss: 0.2728\n",
      "Baseline Loss: 2.7827 | Actual Loss: 0.3064\n",
      "Baseline Loss: 2.7743 | Actual Loss: 0.2203\n",
      "Baseline Loss: 2.8151 | Actual Loss: 0.1718\n",
      "Baseline Loss: 2.8832 | Actual Loss: 0.4144\n",
      "Baseline Loss: 2.8125 | Actual Loss: 0.1928\n",
      "Baseline Loss: 2.8081 | Actual Loss: 0.1767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 107/1000 [00:44<06:18,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9036 | Actual Loss: 0.1758\n",
      "Baseline Loss: 2.7401 | Actual Loss: 0.2456\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1772\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4126\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3073\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2672\n",
      "Epoch 107/1000: Train Loss: 0.2456, Val Loss: 0.2911\n",
      "Baseline Loss: 2.8781 | Actual Loss: 0.3269\n",
      "Baseline Loss: 2.8069 | Actual Loss: 0.3101\n",
      "Baseline Loss: 2.8296 | Actual Loss: 0.1868\n",
      "Baseline Loss: 2.7930 | Actual Loss: 0.4514\n",
      "Baseline Loss: 2.8231 | Actual Loss: 0.2399\n",
      "Baseline Loss: 2.8443 | Actual Loss: 0.1580\n",
      "Baseline Loss: 2.8524 | Actual Loss: 0.1608\n",
      "Baseline Loss: 2.7707 | Actual Loss: 0.1952\n",
      "Baseline Loss: 2.7927 | Actual Loss: 0.1521\n",
      "Baseline Loss: 2.8029 | Actual Loss: 0.2436\n",
      "Baseline Loss: 2.8391 | Actual Loss: 0.2073\n",
      "Baseline Loss: 2.8813 | Actual Loss: 0.1749\n",
      "Baseline Loss: 2.8543 | Actual Loss: 0.2356\n",
      "Baseline Loss: 2.8883 | Actual Loss: 0.2752\n",
      "Baseline Loss: 2.8381 | Actual Loss: 0.2379\n",
      "Baseline Loss: 2.6517 | Actual Loss: 1.2902\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1748\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 108/1000 [00:45<06:02,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8204 | Actual Loss: 0.3011\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.4068\n",
      "Epoch 108/1000: Train Loss: 0.3029, Val Loss: 0.3556\n",
      "Baseline Loss: 2.8557 | Actual Loss: 0.1876\n",
      "Baseline Loss: 2.8492 | Actual Loss: 0.2327\n",
      "Baseline Loss: 2.7955 | Actual Loss: 0.4143\n",
      "Baseline Loss: 2.8542 | Actual Loss: 0.2908\n",
      "Baseline Loss: 2.8525 | Actual Loss: 0.4256\n",
      "Baseline Loss: 2.8357 | Actual Loss: 0.2648\n",
      "Baseline Loss: 2.8292 | Actual Loss: 0.2135\n",
      "Baseline Loss: 2.8903 | Actual Loss: 0.1736\n",
      "Baseline Loss: 2.8089 | Actual Loss: 0.4082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 109/1000 [00:45<06:14,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8886 | Actual Loss: 0.3078\n",
      "Baseline Loss: 2.8159 | Actual Loss: 0.2239\n",
      "Baseline Loss: 2.7993 | Actual Loss: 0.2814\n",
      "Baseline Loss: 2.8427 | Actual Loss: 0.3669\n",
      "Baseline Loss: 2.7558 | Actual Loss: 0.1116\n",
      "Baseline Loss: 2.8191 | Actual Loss: 0.3007\n",
      "Baseline Loss: 2.5828 | Actual Loss: 0.1899\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1803\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4997\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2647\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.4161\n",
      "Epoch 109/1000: Train Loss: 0.2746, Val Loss: 0.3402\n",
      "Baseline Loss: 2.8356 | Actual Loss: 0.1998\n",
      "Baseline Loss: 2.8315 | Actual Loss: 0.3463\n",
      "Baseline Loss: 2.7996 | Actual Loss: 0.2009\n",
      "Baseline Loss: 2.8849 | Actual Loss: 0.2309\n",
      "Baseline Loss: 2.8163 | Actual Loss: 0.1025\n",
      "Baseline Loss: 2.7903 | Actual Loss: 0.4024\n",
      "Baseline Loss: 2.8485 | Actual Loss: 0.2534\n",
      "Baseline Loss: 2.7805 | Actual Loss: 0.1681\n",
      "Baseline Loss: 2.8639 | Actual Loss: 0.2261\n",
      "Baseline Loss: 2.8251 | Actual Loss: 0.4032\n",
      "Baseline Loss: 2.8427 | Actual Loss: 0.1921\n",
      "Baseline Loss: 2.7802 | Actual Loss: 0.1124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 110/1000 [00:46<06:18,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8623 | Actual Loss: 0.3682\n",
      "Baseline Loss: 2.8522 | Actual Loss: 0.1725\n",
      "Baseline Loss: 2.7842 | Actual Loss: 0.3101\n",
      "Baseline Loss: 2.5332 | Actual Loss: 0.0789\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1523\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4482\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2845\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2866\n",
      "Epoch 110/1000: Train Loss: 0.2355, Val Loss: 0.2929\n",
      "Baseline Loss: 2.8368 | Actual Loss: 0.1709\n",
      "Baseline Loss: 2.9036 | Actual Loss: 0.2780\n",
      "Baseline Loss: 2.8713 | Actual Loss: 0.1452\n",
      "Baseline Loss: 2.8218 | Actual Loss: 0.1515\n",
      "Baseline Loss: 2.8343 | Actual Loss: 0.2914\n",
      "Baseline Loss: 2.7958 | Actual Loss: 0.2248\n",
      "Baseline Loss: 2.7913 | Actual Loss: 0.1434\n",
      "Baseline Loss: 2.8113 | Actual Loss: 0.1470\n",
      "Baseline Loss: 2.8559 | Actual Loss: 0.1713\n",
      "Baseline Loss: 2.8346 | Actual Loss: 0.3259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 111/1000 [00:46<06:00,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8467 | Actual Loss: 0.1345\n",
      "Baseline Loss: 2.7855 | Actual Loss: 0.2162\n",
      "Baseline Loss: 2.8410 | Actual Loss: 0.2123\n",
      "Baseline Loss: 2.8172 | Actual Loss: 0.4383\n",
      "Baseline Loss: 2.7920 | Actual Loss: 0.2741\n",
      "Baseline Loss: 2.6622 | Actual Loss: 0.0638\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1678\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.6017\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3370\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.4300\n",
      "Epoch 111/1000: Train Loss: 0.2118, Val Loss: 0.3841\n",
      "Baseline Loss: 2.8574 | Actual Loss: 0.3722\n",
      "Baseline Loss: 2.8160 | Actual Loss: 0.1835\n",
      "Baseline Loss: 2.7751 | Actual Loss: 0.1200\n",
      "Baseline Loss: 2.8814 | Actual Loss: 0.1457\n",
      "Baseline Loss: 2.8007 | Actual Loss: 0.2510\n",
      "Baseline Loss: 2.8075 | Actual Loss: 0.1812\n",
      "Baseline Loss: 2.7890 | Actual Loss: 0.4827\n",
      "Baseline Loss: 2.9183 | Actual Loss: 0.3581\n",
      "Baseline Loss: 2.7740 | Actual Loss: 0.3922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 112/1000 [00:46<06:17,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8286 | Actual Loss: 1.1663\n",
      "Baseline Loss: 2.8942 | Actual Loss: 0.1688\n",
      "Baseline Loss: 2.8397 | Actual Loss: 0.3476\n",
      "Baseline Loss: 2.8951 | Actual Loss: 0.2926\n",
      "Baseline Loss: 2.8058 | Actual Loss: 0.5006\n",
      "Baseline Loss: 2.8073 | Actual Loss: 0.1400\n",
      "Baseline Loss: 2.5092 | Actual Loss: 0.0933\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1993\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4638\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3590\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.3176\n",
      "Epoch 112/1000: Train Loss: 0.3247, Val Loss: 0.3349\n",
      "Baseline Loss: 2.8605 | Actual Loss: 0.2526\n",
      "Baseline Loss: 2.8621 | Actual Loss: 0.1026\n",
      "Baseline Loss: 2.7684 | Actual Loss: 0.2205\n",
      "Baseline Loss: 2.8238 | Actual Loss: 0.3553\n",
      "Baseline Loss: 2.8547 | Actual Loss: 0.1982\n",
      "Baseline Loss: 2.8753 | Actual Loss: 0.1652\n",
      "Baseline Loss: 2.8086 | Actual Loss: 0.2752\n",
      "Baseline Loss: 2.7991 | Actual Loss: 0.3544\n",
      "Baseline Loss: 2.7843 | Actual Loss: 0.2799\n",
      "Baseline Loss: 2.8568 | Actual Loss: 0.2040\n",
      "Baseline Loss: 2.8558 | Actual Loss: 0.2875\n",
      "Baseline Loss: 2.8708 | Actual Loss: 0.3917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█▏        | 113/1000 [00:47<05:59,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7897 | Actual Loss: 0.1429\n",
      "Baseline Loss: 2.8243 | Actual Loss: 0.2405\n",
      "Baseline Loss: 2.8711 | Actual Loss: 0.2543\n",
      "Baseline Loss: 2.5763 | Actual Loss: 0.1875\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2219\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4617\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3936\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.3601\n",
      "Epoch 113/1000: Train Loss: 0.2445, Val Loss: 0.3593\n",
      "Baseline Loss: 2.8613 | Actual Loss: 0.2308\n",
      "Baseline Loss: 2.7746 | Actual Loss: 0.3007\n",
      "Baseline Loss: 2.8289 | Actual Loss: 0.2216\n",
      "Baseline Loss: 2.8433 | Actual Loss: 0.3784\n",
      "Baseline Loss: 2.7925 | Actual Loss: 0.2358\n",
      "Baseline Loss: 2.8013 | Actual Loss: 0.1461\n",
      "Baseline Loss: 2.8086 | Actual Loss: 0.1714\n",
      "Baseline Loss: 2.8057 | Actual Loss: 0.2170\n",
      "Baseline Loss: 2.8349 | Actual Loss: 0.3545\n",
      "Baseline Loss: 2.7875 | Actual Loss: 0.1482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█▏        | 114/1000 [00:47<06:10,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8192 | Actual Loss: 0.1608\n",
      "Baseline Loss: 2.8541 | Actual Loss: 0.1689\n",
      "Baseline Loss: 2.7962 | Actual Loss: 0.0835\n",
      "Baseline Loss: 2.8068 | Actual Loss: 0.2810\n",
      "Baseline Loss: 2.8467 | Actual Loss: 0.2416\n",
      "Baseline Loss: 2.6905 | Actual Loss: 0.1870\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2854\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4795\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3110\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.1605\n",
      "Epoch 114/1000: Train Loss: 0.2205, Val Loss: 0.3091\n",
      "Baseline Loss: 2.8279 | Actual Loss: 0.1534\n",
      "Baseline Loss: 2.8526 | Actual Loss: 0.2618\n",
      "Baseline Loss: 2.8287 | Actual Loss: 0.1308\n",
      "Baseline Loss: 2.7951 | Actual Loss: 0.3423\n",
      "Baseline Loss: 2.8692 | Actual Loss: 0.1810\n",
      "Baseline Loss: 2.8248 | Actual Loss: 0.3615\n",
      "Baseline Loss: 2.8585 | Actual Loss: 0.1427\n",
      "Baseline Loss: 2.9258 | Actual Loss: 0.2033\n",
      "Baseline Loss: 2.8710 | Actual Loss: 0.2288\n",
      "Baseline Loss: 2.8007 | Actual Loss: 0.3043\n",
      "Baseline Loss: 2.7597 | Actual Loss: 0.1972\n",
      "Baseline Loss: 2.7975 | Actual Loss: 0.1700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 115/1000 [00:48<06:18,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8116 | Actual Loss: 0.2410\n",
      "Baseline Loss: 2.7881 | Actual Loss: 0.2626\n",
      "Baseline Loss: 2.7892 | Actual Loss: 0.1689\n",
      "Baseline Loss: 2.5751 | Actual Loss: 0.1742\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1884\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4921\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2694\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2883\n",
      "Epoch 115/1000: Train Loss: 0.2202, Val Loss: 0.3095\n",
      "Baseline Loss: 2.8670 | Actual Loss: 0.2156\n",
      "Baseline Loss: 2.8626 | Actual Loss: 0.2215\n",
      "Baseline Loss: 2.7898 | Actual Loss: 0.1900\n",
      "Baseline Loss: 2.8073 | Actual Loss: 0.1287\n",
      "Baseline Loss: 2.8440 | Actual Loss: 0.0982\n",
      "Baseline Loss: 2.8844 | Actual Loss: 0.2393\n",
      "Baseline Loss: 2.7751 | Actual Loss: 0.1632\n",
      "Baseline Loss: 2.7729 | Actual Loss: 0.2452\n",
      "Baseline Loss: 2.7544 | Actual Loss: 0.1371\n",
      "Baseline Loss: 2.8439 | Actual Loss: 0.2225\n",
      "Baseline Loss: 2.8422 | Actual Loss: 0.2118\n",
      "Baseline Loss: 2.8445 | Actual Loss: 0.1495\n",
      "Baseline Loss: 2.8479 | Actual Loss: 0.2004\n",
      "Baseline Loss: 2.9315 | Actual Loss: 0.3738\n",
      "Baseline Loss: 2.7845 | Actual Loss: 0.2522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 116/1000 [00:48<06:01,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5868 | Actual Loss: 0.2587\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2136\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.7140\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3454\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.4359\n",
      "Epoch 116/1000: Train Loss: 0.2067, Val Loss: 0.4272\n",
      "Baseline Loss: 2.8290 | Actual Loss: 0.4793\n",
      "Baseline Loss: 2.8146 | Actual Loss: 0.2654\n",
      "Baseline Loss: 2.8665 | Actual Loss: 0.2413\n",
      "Baseline Loss: 2.7718 | Actual Loss: 0.2557\n",
      "Baseline Loss: 2.7444 | Actual Loss: 0.1525\n",
      "Baseline Loss: 2.8520 | Actual Loss: 0.1486\n",
      "Baseline Loss: 2.8726 | Actual Loss: 0.2371\n",
      "Baseline Loss: 2.8198 | Actual Loss: 0.2474\n",
      "Baseline Loss: 2.8006 | Actual Loss: 0.1414\n",
      "Baseline Loss: 2.8368 | Actual Loss: 0.1877\n",
      "Baseline Loss: 2.8940 | Actual Loss: 0.2512\n",
      "Baseline Loss: 2.8086 | Actual Loss: 0.2412\n",
      "Baseline Loss: 2.8007 | Actual Loss: 0.1539\n",
      "Baseline Loss: 2.8741 | Actual Loss: 0.2099\n",
      "Baseline Loss: 2.8073 | Actual Loss: 0.1322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 117/1000 [00:49<06:07,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6076 | Actual Loss: 0.2426\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2057\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.3432\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3333\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.3149\n",
      "Epoch 117/1000: Train Loss: 0.2242, Val Loss: 0.2993\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.1836\n",
      "Baseline Loss: 2.7759 | Actual Loss: 0.4471\n",
      "Baseline Loss: 2.8579 | Actual Loss: 0.1926\n",
      "Baseline Loss: 2.8504 | Actual Loss: 0.1677\n",
      "Baseline Loss: 2.7999 | Actual Loss: 0.3012\n",
      "Baseline Loss: 2.8288 | Actual Loss: 0.2266\n",
      "Baseline Loss: 2.7697 | Actual Loss: 0.1682\n",
      "Baseline Loss: 2.8452 | Actual Loss: 0.3917\n",
      "Baseline Loss: 2.7883 | Actual Loss: 0.2287\n",
      "Baseline Loss: 2.9283 | Actual Loss: 0.2398\n",
      "Baseline Loss: 2.8595 | Actual Loss: 0.1782\n",
      "Baseline Loss: 2.8314 | Actual Loss: 0.1311\n",
      "Baseline Loss: 2.8626 | Actual Loss: 0.2758\n",
      "Baseline Loss: 2.7991 | Actual Loss: 0.2020\n",
      "Baseline Loss: 2.7996 | Actual Loss: 0.2363\n",
      "Baseline Loss: 2.5640 | Actual Loss: 0.2563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 118/1000 [00:49<06:25,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8321 | Actual Loss: 0.1965\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5009\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2640\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.3223\n",
      "Epoch 118/1000: Train Loss: 0.2392, Val Loss: 0.3209\n",
      "Baseline Loss: 2.8446 | Actual Loss: 0.2695\n",
      "Baseline Loss: 2.8874 | Actual Loss: 0.1563\n",
      "Baseline Loss: 2.8210 | Actual Loss: 0.1816\n",
      "Baseline Loss: 2.8445 | Actual Loss: 0.2406\n",
      "Baseline Loss: 2.8209 | Actual Loss: 0.2195\n",
      "Baseline Loss: 2.8218 | Actual Loss: 0.2908\n",
      "Baseline Loss: 2.7528 | Actual Loss: 0.1101\n",
      "Baseline Loss: 2.8825 | Actual Loss: 0.1924\n",
      "Baseline Loss: 2.8248 | Actual Loss: 0.2041\n",
      "Baseline Loss: 2.8271 | Actual Loss: 0.1688\n",
      "Baseline Loss: 2.8895 | Actual Loss: 0.1201\n",
      "Baseline Loss: 2.8119 | Actual Loss: 0.2065\n",
      "Baseline Loss: 2.9477 | Actual Loss: 0.2073\n",
      "Baseline Loss: 2.7598 | Actual Loss: 0.1690\n",
      "Baseline Loss: 2.8188 | Actual Loss: 0.1465\n",
      "Baseline Loss: 2.5406 | Actual Loss: 0.0851\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2116\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 119/1000 [00:49<06:17,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8204 | Actual Loss: 0.2699\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2772\n",
      "Epoch 119/1000: Train Loss: 0.1855, Val Loss: 0.3306\n",
      "Baseline Loss: 2.8553 | Actual Loss: 0.1178\n",
      "Baseline Loss: 2.7439 | Actual Loss: 0.1110\n",
      "Baseline Loss: 2.8105 | Actual Loss: 0.2352\n",
      "Baseline Loss: 2.8122 | Actual Loss: 0.2895\n",
      "Baseline Loss: 2.8390 | Actual Loss: 0.1442\n",
      "Baseline Loss: 2.9034 | Actual Loss: 0.3138\n",
      "Baseline Loss: 2.8415 | Actual Loss: 0.1389\n",
      "Baseline Loss: 2.8879 | Actual Loss: 0.2196\n",
      "Baseline Loss: 2.8037 | Actual Loss: 0.2960\n",
      "Baseline Loss: 2.7866 | Actual Loss: 0.1562\n",
      "Baseline Loss: 2.8863 | Actual Loss: 0.2908\n",
      "Baseline Loss: 2.7771 | Actual Loss: 0.2394\n",
      "Baseline Loss: 2.7760 | Actual Loss: 0.2097\n",
      "Baseline Loss: 2.8622 | Actual Loss: 0.1777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 120/1000 [00:50<06:39,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9751 | Actual Loss: 0.1027\n",
      "Baseline Loss: 2.4873 | Actual Loss: 0.1132\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1413\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.3724\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2859\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2998\n",
      "Epoch 120/1000: Train Loss: 0.1972, Val Loss: 0.2749\n",
      "New best validation loss: 0.2749\n",
      "Baseline Loss: 2.8634 | Actual Loss: 0.1216\n",
      "Baseline Loss: 2.8308 | Actual Loss: 0.1977\n",
      "Baseline Loss: 2.8095 | Actual Loss: 0.1795\n",
      "Baseline Loss: 2.8022 | Actual Loss: 0.1192\n",
      "Baseline Loss: 2.8429 | Actual Loss: 0.2174\n",
      "Baseline Loss: 2.9388 | Actual Loss: 0.1536\n",
      "Baseline Loss: 2.8654 | Actual Loss: 0.1310\n",
      "Baseline Loss: 2.8077 | Actual Loss: 0.1811\n",
      "Baseline Loss: 2.8260 | Actual Loss: 0.2147\n",
      "Baseline Loss: 2.8651 | Actual Loss: 0.1492\n",
      "Baseline Loss: 2.7541 | Actual Loss: 0.1176\n",
      "Baseline Loss: 2.8254 | Actual Loss: 0.2419\n",
      "Baseline Loss: 2.8139 | Actual Loss: 0.2111\n",
      "Baseline Loss: 2.8356 | Actual Loss: 0.1110\n",
      "Baseline Loss: 2.8849 | Actual Loss: 0.3873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 121/1000 [00:50<06:46,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5565 | Actual Loss: 0.4986\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1626\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4422\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2934\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2805\n",
      "Epoch 121/1000: Train Loss: 0.2020, Val Loss: 0.2947\n",
      "Baseline Loss: 2.7836 | Actual Loss: 0.2451\n",
      "Baseline Loss: 2.8360 | Actual Loss: 0.2855\n",
      "Baseline Loss: 2.7977 | Actual Loss: 0.3407\n",
      "Baseline Loss: 2.8545 | Actual Loss: 0.2338\n",
      "Baseline Loss: 2.8223 | Actual Loss: 0.1711\n",
      "Baseline Loss: 2.8140 | Actual Loss: 0.1521\n",
      "Baseline Loss: 2.7776 | Actual Loss: 0.2073\n",
      "Baseline Loss: 2.8864 | Actual Loss: 0.1647\n",
      "Baseline Loss: 2.7881 | Actual Loss: 0.1113\n",
      "Baseline Loss: 2.8441 | Actual Loss: 0.2243\n",
      "Baseline Loss: 2.8924 | Actual Loss: 0.1437\n",
      "Baseline Loss: 2.8279 | Actual Loss: 0.1912\n",
      "Baseline Loss: 2.8073 | Actual Loss: 0.1191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 122/1000 [00:51<06:32,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8417 | Actual Loss: 0.2265\n",
      "Baseline Loss: 2.7959 | Actual Loss: 0.2247\n",
      "Baseline Loss: 2.4565 | Actual Loss: 0.1090\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2263\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5163\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3010\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2853\n",
      "Epoch 122/1000: Train Loss: 0.1969, Val Loss: 0.3322\n",
      "Baseline Loss: 2.8705 | Actual Loss: 0.1293\n",
      "Baseline Loss: 2.8435 | Actual Loss: 0.2182\n",
      "Baseline Loss: 2.7922 | Actual Loss: 0.2637\n",
      "Baseline Loss: 2.8063 | Actual Loss: 0.1544\n",
      "Baseline Loss: 2.8133 | Actual Loss: 0.1984\n",
      "Baseline Loss: 2.8225 | Actual Loss: 0.1708\n",
      "Baseline Loss: 2.8111 | Actual Loss: 0.2874\n",
      "Baseline Loss: 2.8643 | Actual Loss: 0.2071\n",
      "Baseline Loss: 2.8154 | Actual Loss: 0.3019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 123/1000 [00:51<06:42,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8046 | Actual Loss: 0.2550\n",
      "Baseline Loss: 2.7989 | Actual Loss: 0.1287\n",
      "Baseline Loss: 2.8556 | Actual Loss: 0.1434\n",
      "Baseline Loss: 2.8441 | Actual Loss: 0.1788\n",
      "Baseline Loss: 2.7972 | Actual Loss: 0.1147\n",
      "Baseline Loss: 2.7810 | Actual Loss: 0.1903\n",
      "Baseline Loss: 2.4813 | Actual Loss: 0.1100\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1640\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4058\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.4508\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.3232\n",
      "Epoch 123/1000: Train Loss: 0.1908, Val Loss: 0.3360\n",
      "Baseline Loss: 2.8010 | Actual Loss: 0.1084\n",
      "Baseline Loss: 2.7718 | Actual Loss: 0.1724\n",
      "Baseline Loss: 2.9423 | Actual Loss: 0.1753\n",
      "Baseline Loss: 2.7974 | Actual Loss: 0.5156\n",
      "Baseline Loss: 2.8170 | Actual Loss: 0.2166\n",
      "Baseline Loss: 2.7882 | Actual Loss: 0.1754\n",
      "Baseline Loss: 2.8787 | Actual Loss: 0.1890\n",
      "Baseline Loss: 2.7678 | Actual Loss: 0.1984\n",
      "Baseline Loss: 2.8101 | Actual Loss: 0.1824\n",
      "Baseline Loss: 2.8437 | Actual Loss: 0.1213\n",
      "Baseline Loss: 2.8290 | Actual Loss: 0.1564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 124/1000 [00:52<06:28,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8932 | Actual Loss: 0.1160\n",
      "Baseline Loss: 2.8125 | Actual Loss: 0.2677\n",
      "Baseline Loss: 2.7840 | Actual Loss: 0.1440\n",
      "Baseline Loss: 2.8832 | Actual Loss: 0.2032\n",
      "Baseline Loss: 2.6821 | Actual Loss: 0.2604\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1399\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.3656\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3387\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2655\n",
      "Epoch 124/1000: Train Loss: 0.2002, Val Loss: 0.2774\n",
      "Baseline Loss: 2.8212 | Actual Loss: 0.1784\n",
      "Baseline Loss: 2.8461 | Actual Loss: 0.2298\n",
      "Baseline Loss: 2.7898 | Actual Loss: 0.2095\n",
      "Baseline Loss: 2.8311 | Actual Loss: 0.1402\n",
      "Baseline Loss: 2.7877 | Actual Loss: 0.1398\n",
      "Baseline Loss: 2.7815 | Actual Loss: 0.3132\n",
      "Baseline Loss: 2.7821 | Actual Loss: 0.1922\n",
      "Baseline Loss: 2.8724 | Actual Loss: 0.2374\n",
      "Baseline Loss: 2.8450 | Actual Loss: 0.1777\n",
      "Baseline Loss: 2.8449 | Actual Loss: 0.1440\n",
      "Baseline Loss: 2.8846 | Actual Loss: 0.2120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▎        | 125/1000 [00:52<06:40,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8140 | Actual Loss: 0.2244\n",
      "Baseline Loss: 2.7806 | Actual Loss: 0.1651\n",
      "Baseline Loss: 2.8300 | Actual Loss: 0.2053\n",
      "Baseline Loss: 2.7769 | Actual Loss: 0.2074\n",
      "Baseline Loss: 2.4834 | Actual Loss: 0.1023\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1770\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4375\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2033\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.3168\n",
      "Epoch 125/1000: Train Loss: 0.1924, Val Loss: 0.2836\n",
      "Baseline Loss: 2.8519 | Actual Loss: 0.1848\n",
      "Baseline Loss: 2.8106 | Actual Loss: 0.1831\n",
      "Baseline Loss: 2.8583 | Actual Loss: 0.1709\n",
      "Baseline Loss: 2.8747 | Actual Loss: 0.2000\n",
      "Baseline Loss: 2.7929 | Actual Loss: 0.2060\n",
      "Baseline Loss: 2.8645 | Actual Loss: 0.1856\n",
      "Baseline Loss: 2.7725 | Actual Loss: 0.2069\n",
      "Baseline Loss: 2.8463 | Actual Loss: 0.1214\n",
      "Baseline Loss: 2.8643 | Actual Loss: 0.2964\n",
      "Baseline Loss: 2.8342 | Actual Loss: 0.1695\n",
      "Baseline Loss: 2.8457 | Actual Loss: 0.3348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 126/1000 [00:53<06:53,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7994 | Actual Loss: 0.1059\n",
      "Baseline Loss: 2.7706 | Actual Loss: 0.3111\n",
      "Baseline Loss: 2.8005 | Actual Loss: 0.2253\n",
      "Baseline Loss: 2.8089 | Actual Loss: 0.1386\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.1646\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1870\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4885\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2698\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2122\n",
      "Epoch 126/1000: Train Loss: 0.2003, Val Loss: 0.2894\n",
      "Baseline Loss: 2.8745 | Actual Loss: 0.1750\n",
      "Baseline Loss: 2.8123 | Actual Loss: 0.1833\n",
      "Baseline Loss: 2.7771 | Actual Loss: 0.1217\n",
      "Baseline Loss: 2.8476 | Actual Loss: 0.1710\n",
      "Baseline Loss: 2.8133 | Actual Loss: 0.1381\n",
      "Baseline Loss: 2.8263 | Actual Loss: 0.1795\n",
      "Baseline Loss: 2.8737 | Actual Loss: 0.1151\n",
      "Baseline Loss: 2.7819 | Actual Loss: 0.1835\n",
      "Baseline Loss: 2.8400 | Actual Loss: 0.1748\n",
      "Baseline Loss: 2.8430 | Actual Loss: 0.1533\n",
      "Baseline Loss: 2.8561 | Actual Loss: 0.2485\n",
      "Baseline Loss: 2.8953 | Actual Loss: 0.2855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 127/1000 [00:53<06:35,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8520 | Actual Loss: 0.5325\n",
      "Baseline Loss: 2.8286 | Actual Loss: 0.2020\n",
      "Baseline Loss: 2.7975 | Actual Loss: 0.1038\n",
      "Baseline Loss: 2.4753 | Actual Loss: 0.2303\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1944\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.7580\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3071\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.3256\n",
      "Epoch 127/1000: Train Loss: 0.1999, Val Loss: 0.3963\n",
      "Baseline Loss: 2.9405 | Actual Loss: 0.2478\n",
      "Baseline Loss: 2.8004 | Actual Loss: 0.2228\n",
      "Baseline Loss: 2.8146 | Actual Loss: 0.1643\n",
      "Baseline Loss: 2.8392 | Actual Loss: 0.1358\n",
      "Baseline Loss: 2.7978 | Actual Loss: 0.2297\n",
      "Baseline Loss: 2.8115 | Actual Loss: 0.0922\n",
      "Baseline Loss: 2.8490 | Actual Loss: 0.2322\n",
      "Baseline Loss: 2.8387 | Actual Loss: 0.2465\n",
      "Baseline Loss: 2.7871 | Actual Loss: 0.1624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 128/1000 [00:54<06:48,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8026 | Actual Loss: 0.1536\n",
      "Baseline Loss: 2.7554 | Actual Loss: 0.2279\n",
      "Baseline Loss: 2.8198 | Actual Loss: 0.1402\n",
      "Baseline Loss: 2.8548 | Actual Loss: 0.3586\n",
      "Baseline Loss: 2.8325 | Actual Loss: 0.2538\n",
      "Baseline Loss: 2.8311 | Actual Loss: 0.1450\n",
      "Baseline Loss: 2.4855 | Actual Loss: 0.0838\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1919\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.3513\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3437\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2883\n",
      "Epoch 128/1000: Train Loss: 0.1935, Val Loss: 0.2938\n",
      "Baseline Loss: 2.8713 | Actual Loss: 0.2283\n",
      "Baseline Loss: 2.8654 | Actual Loss: 0.1474\n",
      "Baseline Loss: 2.8788 | Actual Loss: 0.1583\n",
      "Baseline Loss: 2.8782 | Actual Loss: 0.2001\n",
      "Baseline Loss: 2.8184 | Actual Loss: 0.2606\n",
      "Baseline Loss: 2.8913 | Actual Loss: 0.1508\n",
      "Baseline Loss: 2.8583 | Actual Loss: 0.2034\n",
      "Baseline Loss: 2.7949 | Actual Loss: 0.3511\n",
      "Baseline Loss: 2.8404 | Actual Loss: 0.1372\n",
      "Baseline Loss: 2.8194 | Actual Loss: 0.3015\n",
      "Baseline Loss: 2.8754 | Actual Loss: 0.1535\n",
      "Baseline Loss: 2.8242 | Actual Loss: 0.1660\n",
      "Baseline Loss: 2.8805 | Actual Loss: 0.2087\n",
      "Baseline Loss: 2.8202 | Actual Loss: 0.1972\n",
      "Baseline Loss: 2.7770 | Actual Loss: 0.1576\n",
      "Baseline Loss: 2.5347 | Actual Loss: 0.0919\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1559\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4523\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 129/1000 [00:54<06:55,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7416 | Actual Loss: 0.2715\n",
      "Epoch 129/1000: Train Loss: 0.1946, Val Loss: 0.3184\n",
      "Baseline Loss: 2.8392 | Actual Loss: 0.1237\n",
      "Baseline Loss: 2.9125 | Actual Loss: 0.1238\n",
      "Baseline Loss: 2.7969 | Actual Loss: 0.1657\n",
      "Baseline Loss: 2.8326 | Actual Loss: 0.2048\n",
      "Baseline Loss: 2.7799 | Actual Loss: 0.2760\n",
      "Baseline Loss: 2.8404 | Actual Loss: 0.1732\n",
      "Baseline Loss: 2.8195 | Actual Loss: 0.1222\n",
      "Baseline Loss: 2.8409 | Actual Loss: 0.1708\n",
      "Baseline Loss: 2.8162 | Actual Loss: 0.1669\n",
      "Baseline Loss: 2.7750 | Actual Loss: 0.4079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 130/1000 [00:55<06:38,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8203 | Actual Loss: 0.2494\n",
      "Baseline Loss: 2.7781 | Actual Loss: 0.2021\n",
      "Baseline Loss: 2.8010 | Actual Loss: 0.1336\n",
      "Baseline Loss: 2.8563 | Actual Loss: 0.1244\n",
      "Baseline Loss: 2.8911 | Actual Loss: 0.1414\n",
      "Baseline Loss: 2.7949 | Actual Loss: 0.2437\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1831\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5466\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3440\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.3775\n",
      "Epoch 130/1000: Train Loss: 0.1893, Val Loss: 0.3628\n",
      "Baseline Loss: 2.8750 | Actual Loss: 0.3288\n",
      "Baseline Loss: 2.8056 | Actual Loss: 0.1498\n",
      "Baseline Loss: 2.8496 | Actual Loss: 0.2086\n",
      "Baseline Loss: 2.7794 | Actual Loss: 0.1773\n",
      "Baseline Loss: 2.8261 | Actual Loss: 0.2144\n",
      "Baseline Loss: 2.8740 | Actual Loss: 0.1620\n",
      "Baseline Loss: 2.8110 | Actual Loss: 0.3049\n",
      "Baseline Loss: 2.8102 | Actual Loss: 0.1638\n",
      "Baseline Loss: 2.9506 | Actual Loss: 0.1105\n",
      "Baseline Loss: 2.7670 | Actual Loss: 0.1245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 131/1000 [00:55<06:51,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7806 | Actual Loss: 0.3640\n",
      "Baseline Loss: 2.8701 | Actual Loss: 0.2288\n",
      "Baseline Loss: 2.8100 | Actual Loss: 0.1589\n",
      "Baseline Loss: 2.8601 | Actual Loss: 0.2362\n",
      "Baseline Loss: 2.7979 | Actual Loss: 0.1881\n",
      "Baseline Loss: 2.5418 | Actual Loss: 0.1101\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1662\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4563\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3297\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.3028\n",
      "Epoch 131/1000: Train Loss: 0.2019, Val Loss: 0.3137\n",
      "Baseline Loss: 2.7816 | Actual Loss: 0.0745\n",
      "Baseline Loss: 2.8076 | Actual Loss: 0.1625\n",
      "Baseline Loss: 2.8196 | Actual Loss: 0.2098\n",
      "Baseline Loss: 2.8996 | Actual Loss: 0.2461\n",
      "Baseline Loss: 2.7787 | Actual Loss: 0.2374\n",
      "Baseline Loss: 2.8999 | Actual Loss: 0.1473\n",
      "Baseline Loss: 2.7325 | Actual Loss: 0.1970\n",
      "Baseline Loss: 2.8360 | Actual Loss: 0.2331\n",
      "Baseline Loss: 2.8230 | Actual Loss: 0.2120\n",
      "Baseline Loss: 2.7967 | Actual Loss: 0.2040\n",
      "Baseline Loss: 2.7883 | Actual Loss: 0.2293\n",
      "Baseline Loss: 2.8162 | Actual Loss: 0.1859\n",
      "Baseline Loss: 2.7984 | Actual Loss: 0.1668\n",
      "Baseline Loss: 2.8256 | Actual Loss: 0.1608\n",
      "Baseline Loss: 2.8714 | Actual Loss: 0.3401\n",
      "Baseline Loss: 2.5556 | Actual Loss: 0.2006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 132/1000 [00:56<06:52,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8321 | Actual Loss: 0.1606\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5519\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3172\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.3209\n",
      "Epoch 132/1000: Train Loss: 0.2004, Val Loss: 0.3376\n",
      "Baseline Loss: 2.7672 | Actual Loss: 0.1034\n",
      "Baseline Loss: 2.8474 | Actual Loss: 0.2122\n",
      "Baseline Loss: 2.8414 | Actual Loss: 0.3663\n",
      "Baseline Loss: 2.8062 | Actual Loss: 0.1032\n",
      "Baseline Loss: 2.8144 | Actual Loss: 0.1693\n",
      "Baseline Loss: 2.7907 | Actual Loss: 0.1857\n",
      "Baseline Loss: 2.7876 | Actual Loss: 0.2001\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.2804\n",
      "Baseline Loss: 2.8340 | Actual Loss: 0.2417\n",
      "Baseline Loss: 2.8066 | Actual Loss: 0.3919\n",
      "Baseline Loss: 2.8205 | Actual Loss: 0.2177\n",
      "Baseline Loss: 2.8590 | Actual Loss: 0.1384\n",
      "Baseline Loss: 2.8787 | Actual Loss: 0.2061\n",
      "Baseline Loss: 2.7974 | Actual Loss: 0.1498\n",
      "Baseline Loss: 2.8718 | Actual Loss: 0.1344\n",
      "Baseline Loss: 2.6236 | Actual Loss: 0.1955\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 133/1000 [00:56<06:37,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8514 | Actual Loss: 0.4227\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3413\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.3066\n",
      "Epoch 133/1000: Train Loss: 0.2060, Val Loss: 0.3220\n",
      "Baseline Loss: 2.7859 | Actual Loss: 0.2188\n",
      "Baseline Loss: 2.8415 | Actual Loss: 0.0923\n",
      "Baseline Loss: 2.8355 | Actual Loss: 0.2945\n",
      "Baseline Loss: 2.8449 | Actual Loss: 0.1778\n",
      "Baseline Loss: 2.8140 | Actual Loss: 0.1002\n",
      "Baseline Loss: 2.8326 | Actual Loss: 0.1306\n",
      "Baseline Loss: 2.8234 | Actual Loss: 0.1403\n",
      "Baseline Loss: 2.7939 | Actual Loss: 0.1590\n",
      "Baseline Loss: 2.8624 | Actual Loss: 0.2059\n",
      "Baseline Loss: 2.7829 | Actual Loss: 0.0803\n",
      "Baseline Loss: 2.7908 | Actual Loss: 0.1487\n",
      "Baseline Loss: 2.7978 | Actual Loss: 0.1214\n",
      "Baseline Loss: 2.8417 | Actual Loss: 0.3101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 134/1000 [00:56<06:38,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7636 | Actual Loss: 0.1074\n",
      "Baseline Loss: 2.8270 | Actual Loss: 0.1184\n",
      "Baseline Loss: 2.7322 | Actual Loss: 0.1754\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1932\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4469\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3052\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2614\n",
      "Epoch 134/1000: Train Loss: 0.1613, Val Loss: 0.3017\n",
      "Baseline Loss: 2.8711 | Actual Loss: 0.1360\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.2366\n",
      "Baseline Loss: 2.7867 | Actual Loss: 0.1726\n",
      "Baseline Loss: 2.8752 | Actual Loss: 0.1828\n",
      "Baseline Loss: 2.8323 | Actual Loss: 0.1293\n",
      "Baseline Loss: 2.8326 | Actual Loss: 0.1394\n",
      "Baseline Loss: 2.8025 | Actual Loss: 0.2243\n",
      "Baseline Loss: 2.8174 | Actual Loss: 0.1841\n",
      "Baseline Loss: 2.8435 | Actual Loss: 0.1467\n",
      "Baseline Loss: 2.8642 | Actual Loss: 0.1157\n",
      "Baseline Loss: 2.7481 | Actual Loss: 0.1938\n",
      "Baseline Loss: 2.8879 | Actual Loss: 0.2779\n",
      "Baseline Loss: 2.8457 | Actual Loss: 0.2193\n",
      "Baseline Loss: 2.8445 | Actual Loss: 0.1258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▎        | 135/1000 [00:57<06:47,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7497 | Actual Loss: 0.1366\n",
      "Baseline Loss: 2.5344 | Actual Loss: 0.1366\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1865\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5045\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3230\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2206\n",
      "Epoch 135/1000: Train Loss: 0.1724, Val Loss: 0.3086\n",
      "Baseline Loss: 2.8309 | Actual Loss: 0.1211\n",
      "Baseline Loss: 2.8403 | Actual Loss: 0.1531\n",
      "Baseline Loss: 2.8127 | Actual Loss: 0.2258\n",
      "Baseline Loss: 2.8258 | Actual Loss: 0.2703\n",
      "Baseline Loss: 2.7568 | Actual Loss: 0.1365\n",
      "Baseline Loss: 2.8410 | Actual Loss: 0.1986\n",
      "Baseline Loss: 2.7981 | Actual Loss: 0.2319\n",
      "Baseline Loss: 2.8177 | Actual Loss: 0.1586\n",
      "Baseline Loss: 2.8422 | Actual Loss: 0.2424\n",
      "Baseline Loss: 2.8244 | Actual Loss: 0.1338\n",
      "Baseline Loss: 2.8241 | Actual Loss: 0.1787\n",
      "Baseline Loss: 2.8699 | Actual Loss: 0.1418\n",
      "Baseline Loss: 2.9065 | Actual Loss: 0.1676\n",
      "Baseline Loss: 2.8113 | Actual Loss: 0.3292\n",
      "Baseline Loss: 2.7657 | Actual Loss: 0.1574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▎        | 136/1000 [00:57<06:32,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5849 | Actual Loss: 0.1323\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1552\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5230\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2605\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.3342\n",
      "Epoch 136/1000: Train Loss: 0.1862, Val Loss: 0.3182\n",
      "Baseline Loss: 2.7896 | Actual Loss: 0.2139\n",
      "Baseline Loss: 2.8456 | Actual Loss: 0.2000\n",
      "Baseline Loss: 2.8871 | Actual Loss: 0.1789\n",
      "Baseline Loss: 2.8257 | Actual Loss: 0.1982\n",
      "Baseline Loss: 2.8265 | Actual Loss: 0.1411\n",
      "Baseline Loss: 2.7863 | Actual Loss: 0.1851\n",
      "Baseline Loss: 2.7657 | Actual Loss: 0.2872\n",
      "Baseline Loss: 2.7919 | Actual Loss: 0.1889\n",
      "Baseline Loss: 2.8726 | Actual Loss: 0.1057\n",
      "Baseline Loss: 2.8248 | Actual Loss: 0.1298\n",
      "Baseline Loss: 2.8670 | Actual Loss: 0.1739\n",
      "Baseline Loss: 2.8372 | Actual Loss: 0.1579\n",
      "Baseline Loss: 2.9084 | Actual Loss: 0.0874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▎        | 137/1000 [00:58<06:37,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8144 | Actual Loss: 0.2317\n",
      "Baseline Loss: 2.8899 | Actual Loss: 0.2054\n",
      "Baseline Loss: 2.6025 | Actual Loss: 0.2893\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1436\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4902\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3179\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2549\n",
      "Epoch 137/1000: Train Loss: 0.1859, Val Loss: 0.3016\n",
      "Baseline Loss: 2.7976 | Actual Loss: 0.2017\n",
      "Baseline Loss: 2.8366 | Actual Loss: 0.1299\n",
      "Baseline Loss: 2.7828 | Actual Loss: 0.1148\n",
      "Baseline Loss: 2.8212 | Actual Loss: 0.1285\n",
      "Baseline Loss: 2.8547 | Actual Loss: 0.2037\n",
      "Baseline Loss: 2.8230 | Actual Loss: 0.1336\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.1911\n",
      "Baseline Loss: 2.8196 | Actual Loss: 0.1905\n",
      "Baseline Loss: 2.7994 | Actual Loss: 0.2099\n",
      "Baseline Loss: 2.8590 | Actual Loss: 0.1390\n",
      "Baseline Loss: 2.8500 | Actual Loss: 0.2937\n",
      "Baseline Loss: 2.9012 | Actual Loss: 0.1094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 138/1000 [00:58<06:43,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8671 | Actual Loss: 0.1979\n",
      "Baseline Loss: 2.7942 | Actual Loss: 0.0895\n",
      "Baseline Loss: 2.8134 | Actual Loss: 0.2604\n",
      "Baseline Loss: 2.6159 | Actual Loss: 0.7863\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1751\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5910\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2111\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2947\n",
      "Epoch 138/1000: Train Loss: 0.2113, Val Loss: 0.3180\n",
      "Baseline Loss: 2.8239 | Actual Loss: 0.1657\n",
      "Baseline Loss: 2.8669 | Actual Loss: 0.2490\n",
      "Baseline Loss: 2.8214 | Actual Loss: 0.1816\n",
      "Baseline Loss: 2.8190 | Actual Loss: 0.1516\n",
      "Baseline Loss: 2.8136 | Actual Loss: 0.1841\n",
      "Baseline Loss: 2.8857 | Actual Loss: 0.1313\n",
      "Baseline Loss: 2.8695 | Actual Loss: 0.1910\n",
      "Baseline Loss: 2.8363 | Actual Loss: 0.2079\n",
      "Baseline Loss: 2.7869 | Actual Loss: 0.1355\n",
      "Baseline Loss: 2.8785 | Actual Loss: 0.1798\n",
      "Baseline Loss: 2.8269 | Actual Loss: 0.2782\n",
      "Baseline Loss: 2.7655 | Actual Loss: 0.1855\n",
      "Baseline Loss: 2.7858 | Actual Loss: 0.1961\n",
      "Baseline Loss: 2.8545 | Actual Loss: 0.1091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 139/1000 [00:59<06:26,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8023 | Actual Loss: 0.1763\n",
      "Baseline Loss: 2.6070 | Actual Loss: 0.0471\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1742\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5142\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3070\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.1863\n",
      "Epoch 139/1000: Train Loss: 0.1731, Val Loss: 0.2954\n",
      "Baseline Loss: 2.7151 | Actual Loss: 0.1684\n",
      "Baseline Loss: 2.8327 | Actual Loss: 0.2563\n",
      "Baseline Loss: 2.7899 | Actual Loss: 0.1606\n",
      "Baseline Loss: 2.8653 | Actual Loss: 0.1290\n",
      "Baseline Loss: 2.8463 | Actual Loss: 0.1497\n",
      "Baseline Loss: 2.8916 | Actual Loss: 0.3491\n",
      "Baseline Loss: 2.8452 | Actual Loss: 0.1321\n",
      "Baseline Loss: 2.8022 | Actual Loss: 0.2396\n",
      "Baseline Loss: 2.7917 | Actual Loss: 0.0903\n",
      "Baseline Loss: 2.8344 | Actual Loss: 0.2104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 140/1000 [00:59<06:39,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8891 | Actual Loss: 0.2294\n",
      "Baseline Loss: 2.7678 | Actual Loss: 0.3973\n",
      "Baseline Loss: 2.8236 | Actual Loss: 0.1811\n",
      "Baseline Loss: 2.8003 | Actual Loss: 0.1953\n",
      "Baseline Loss: 2.8793 | Actual Loss: 0.1546\n",
      "Baseline Loss: 2.6090 | Actual Loss: 0.3840\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1677\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4453\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3281\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2041\n",
      "Epoch 140/1000: Train Loss: 0.2142, Val Loss: 0.2863\n",
      "Baseline Loss: 2.8217 | Actual Loss: 0.2343\n",
      "Baseline Loss: 2.8182 | Actual Loss: 0.1504\n",
      "Baseline Loss: 2.8889 | Actual Loss: 0.1477\n",
      "Baseline Loss: 2.8700 | Actual Loss: 0.2174\n",
      "Baseline Loss: 2.7937 | Actual Loss: 0.1732\n",
      "Baseline Loss: 2.8539 | Actual Loss: 0.1954\n",
      "Baseline Loss: 2.7720 | Actual Loss: 0.1701\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.2716\n",
      "Baseline Loss: 2.9519 | Actual Loss: 0.2347\n",
      "Baseline Loss: 2.8444 | Actual Loss: 0.0874\n",
      "Baseline Loss: 2.7950 | Actual Loss: 0.1868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 141/1000 [01:00<06:45,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7976 | Actual Loss: 0.1600\n",
      "Baseline Loss: 2.8638 | Actual Loss: 0.2018\n",
      "Baseline Loss: 2.7788 | Actual Loss: 0.1768\n",
      "Baseline Loss: 2.7996 | Actual Loss: 0.2810\n",
      "Baseline Loss: 2.4962 | Actual Loss: 0.1070\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1475\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4750\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2199\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2637\n",
      "Epoch 141/1000: Train Loss: 0.1872, Val Loss: 0.2765\n",
      "Baseline Loss: 2.8325 | Actual Loss: 0.3893\n",
      "Baseline Loss: 2.8239 | Actual Loss: 0.1429\n",
      "Baseline Loss: 2.8410 | Actual Loss: 0.1799\n",
      "Baseline Loss: 2.8604 | Actual Loss: 0.2410\n",
      "Baseline Loss: 2.7490 | Actual Loss: 0.1310\n",
      "Baseline Loss: 2.8719 | Actual Loss: 0.1996\n",
      "Baseline Loss: 2.9154 | Actual Loss: 0.0946\n",
      "Baseline Loss: 2.7722 | Actual Loss: 0.2630\n",
      "Baseline Loss: 2.9144 | Actual Loss: 0.7548\n",
      "Baseline Loss: 2.7931 | Actual Loss: 0.0881\n",
      "Baseline Loss: 2.7515 | Actual Loss: 0.1860\n",
      "Baseline Loss: 2.8762 | Actual Loss: 0.2892\n",
      "Baseline Loss: 2.7951 | Actual Loss: 0.2426\n",
      "Baseline Loss: 2.8584 | Actual Loss: 0.2363\n",
      "Baseline Loss: 2.8798 | Actual Loss: 0.1342\n",
      "Baseline Loss: 2.5174 | Actual Loss: 0.0995\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2164\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 142/1000 [01:00<06:42,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8204 | Actual Loss: 0.2417\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2676\n",
      "Epoch 142/1000: Train Loss: 0.2295, Val Loss: 0.3114\n",
      "Baseline Loss: 2.8121 | Actual Loss: 0.2198\n",
      "Baseline Loss: 2.7913 | Actual Loss: 0.1622\n",
      "Baseline Loss: 2.8171 | Actual Loss: 0.1154\n",
      "Baseline Loss: 2.8387 | Actual Loss: 0.2024\n",
      "Baseline Loss: 2.8344 | Actual Loss: 0.1684\n",
      "Baseline Loss: 2.8298 | Actual Loss: 0.2058\n",
      "Baseline Loss: 2.8338 | Actual Loss: 0.1346\n",
      "Baseline Loss: 2.8206 | Actual Loss: 0.1242\n",
      "Baseline Loss: 2.8478 | Actual Loss: 0.1533\n",
      "Baseline Loss: 2.8606 | Actual Loss: 0.4422\n",
      "Baseline Loss: 2.8412 | Actual Loss: 0.2028\n",
      "Baseline Loss: 2.7848 | Actual Loss: 0.1220\n",
      "Baseline Loss: 2.7706 | Actual Loss: 0.1708\n",
      "Baseline Loss: 2.8877 | Actual Loss: 0.2330\n",
      "Baseline Loss: 2.8029 | Actual Loss: 0.3348\n",
      "Baseline Loss: 2.5729 | Actual Loss: 0.1844\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 143/1000 [01:01<06:34,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8514 | Actual Loss: 0.4721\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2326\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2495\n",
      "Epoch 143/1000: Train Loss: 0.1985, Val Loss: 0.2860\n",
      "Baseline Loss: 2.8275 | Actual Loss: 0.1242\n",
      "Baseline Loss: 2.8522 | Actual Loss: 0.1868\n",
      "Baseline Loss: 2.8607 | Actual Loss: 0.1854\n",
      "Baseline Loss: 2.7871 | Actual Loss: 0.1542\n",
      "Baseline Loss: 2.8263 | Actual Loss: 0.1438\n",
      "Baseline Loss: 2.8492 | Actual Loss: 0.3243\n",
      "Baseline Loss: 2.8800 | Actual Loss: 0.3169\n",
      "Baseline Loss: 2.7812 | Actual Loss: 0.1187\n",
      "Baseline Loss: 2.8392 | Actual Loss: 0.2769\n",
      "Baseline Loss: 2.7530 | Actual Loss: 0.2073\n",
      "Baseline Loss: 2.7273 | Actual Loss: 0.1181\n",
      "Baseline Loss: 2.8323 | Actual Loss: 0.3525\n",
      "Baseline Loss: 2.8777 | Actual Loss: 0.1616\n",
      "Baseline Loss: 2.7847 | Actual Loss: 0.0962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 144/1000 [01:01<06:38,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8231 | Actual Loss: 0.2388\n",
      "Baseline Loss: 2.5529 | Actual Loss: 0.0960\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1942\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5603\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3075\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2349\n",
      "Epoch 144/1000: Train Loss: 0.1939, Val Loss: 0.3242\n",
      "Baseline Loss: 2.8480 | Actual Loss: 0.1060\n",
      "Baseline Loss: 2.7767 | Actual Loss: 0.1894\n",
      "Baseline Loss: 2.9577 | Actual Loss: 0.3682\n",
      "Baseline Loss: 2.7772 | Actual Loss: 0.1234\n",
      "Baseline Loss: 2.9052 | Actual Loss: 0.2334\n",
      "Baseline Loss: 2.8294 | Actual Loss: 0.1598\n",
      "Baseline Loss: 2.7687 | Actual Loss: 0.2960\n",
      "Baseline Loss: 2.7451 | Actual Loss: 0.2722\n",
      "Baseline Loss: 2.8559 | Actual Loss: 0.1866\n",
      "Baseline Loss: 2.8340 | Actual Loss: 0.1850\n",
      "Baseline Loss: 2.8342 | Actual Loss: 0.1714\n",
      "Baseline Loss: 2.7832 | Actual Loss: 0.1504\n",
      "Baseline Loss: 2.8332 | Actual Loss: 0.1923\n",
      "Baseline Loss: 2.8315 | Actual Loss: 0.0818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 145/1000 [01:01<06:17,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8287 | Actual Loss: 0.0910\n",
      "Baseline Loss: 2.4879 | Actual Loss: 0.1551\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1500\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5923\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3073\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2668\n",
      "Epoch 145/1000: Train Loss: 0.1851, Val Loss: 0.3291\n",
      "Baseline Loss: 2.8042 | Actual Loss: 0.1610\n",
      "Baseline Loss: 2.7897 | Actual Loss: 0.0878\n",
      "Baseline Loss: 2.8460 | Actual Loss: 0.1342\n",
      "Baseline Loss: 2.8158 | Actual Loss: 0.2033\n",
      "Baseline Loss: 2.8571 | Actual Loss: 0.1272\n",
      "Baseline Loss: 2.8344 | Actual Loss: 0.1110\n",
      "Baseline Loss: 2.7765 | Actual Loss: 0.1797\n",
      "Baseline Loss: 2.8146 | Actual Loss: 0.1791\n",
      "Baseline Loss: 2.8096 | Actual Loss: 0.1389\n",
      "Baseline Loss: 2.8067 | Actual Loss: 0.1772\n",
      "Baseline Loss: 2.7805 | Actual Loss: 0.2817\n",
      "Baseline Loss: 2.8674 | Actual Loss: 0.2323\n",
      "Baseline Loss: 2.8236 | Actual Loss: 0.1626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 146/1000 [01:02<06:33,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8283 | Actual Loss: 0.1662\n",
      "Baseline Loss: 2.8318 | Actual Loss: 0.1960\n",
      "Baseline Loss: 2.4944 | Actual Loss: 0.0455\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1818\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4152\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3102\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2879\n",
      "Epoch 146/1000: Train Loss: 0.1615, Val Loss: 0.2988\n",
      "Baseline Loss: 2.7697 | Actual Loss: 0.1008\n",
      "Baseline Loss: 2.8247 | Actual Loss: 0.1403\n",
      "Baseline Loss: 2.8087 | Actual Loss: 0.2778\n",
      "Baseline Loss: 2.8107 | Actual Loss: 0.2221\n",
      "Baseline Loss: 2.8490 | Actual Loss: 0.1289\n",
      "Baseline Loss: 2.8422 | Actual Loss: 0.1452\n",
      "Baseline Loss: 2.8149 | Actual Loss: 0.2067\n",
      "Baseline Loss: 2.8356 | Actual Loss: 0.1749\n",
      "Baseline Loss: 2.8779 | Actual Loss: 0.2640\n",
      "Baseline Loss: 2.8479 | Actual Loss: 0.2162\n",
      "Baseline Loss: 2.8760 | Actual Loss: 0.0692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 147/1000 [01:02<06:38,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7939 | Actual Loss: 0.2280\n",
      "Baseline Loss: 2.8429 | Actual Loss: 0.2557\n",
      "Baseline Loss: 2.8394 | Actual Loss: 0.2586\n",
      "Baseline Loss: 2.8210 | Actual Loss: 0.1739\n",
      "Baseline Loss: 2.5102 | Actual Loss: 0.1039\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1345\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4599\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3230\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2836\n",
      "Epoch 147/1000: Train Loss: 0.1854, Val Loss: 0.3002\n",
      "Baseline Loss: 2.8426 | Actual Loss: 0.2173\n",
      "Baseline Loss: 2.9714 | Actual Loss: 0.1599\n",
      "Baseline Loss: 2.8127 | Actual Loss: 0.2512\n",
      "Baseline Loss: 2.8035 | Actual Loss: 0.0916\n",
      "Baseline Loss: 2.7505 | Actual Loss: 0.2322\n",
      "Baseline Loss: 2.8324 | Actual Loss: 0.1669\n",
      "Baseline Loss: 2.8220 | Actual Loss: 0.1019\n",
      "Baseline Loss: 2.8685 | Actual Loss: 0.2375\n",
      "Baseline Loss: 2.8158 | Actual Loss: 0.1068\n",
      "Baseline Loss: 2.7764 | Actual Loss: 0.2423\n",
      "Baseline Loss: 2.8586 | Actual Loss: 0.1714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 148/1000 [01:03<06:32,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8228 | Actual Loss: 0.1925\n",
      "Baseline Loss: 2.7732 | Actual Loss: 0.2048\n",
      "Baseline Loss: 2.7704 | Actual Loss: 0.1164\n",
      "Baseline Loss: 2.7645 | Actual Loss: 0.1665\n",
      "Baseline Loss: 2.5797 | Actual Loss: 0.1346\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1329\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4394\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.1873\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2637\n",
      "Epoch 148/1000: Train Loss: 0.1746, Val Loss: 0.2558\n",
      "New best validation loss: 0.2558\n",
      "Baseline Loss: 2.7657 | Actual Loss: 0.1318\n",
      "Baseline Loss: 2.8430 | Actual Loss: 0.3533\n",
      "Baseline Loss: 2.7838 | Actual Loss: 0.2424\n",
      "Baseline Loss: 2.8026 | Actual Loss: 0.2065\n",
      "Baseline Loss: 2.8288 | Actual Loss: 0.2696\n",
      "Baseline Loss: 2.8320 | Actual Loss: 0.1279\n",
      "Baseline Loss: 2.9211 | Actual Loss: 0.1102\n",
      "Baseline Loss: 2.8091 | Actual Loss: 0.1561\n",
      "Baseline Loss: 2.8441 | Actual Loss: 0.2036\n",
      "Baseline Loss: 2.8668 | Actual Loss: 0.1366\n",
      "Baseline Loss: 2.8583 | Actual Loss: 0.2020\n",
      "Baseline Loss: 2.8776 | Actual Loss: 0.1653\n",
      "Baseline Loss: 2.8189 | Actual Loss: 0.1837\n",
      "Baseline Loss: 2.8782 | Actual Loss: 0.1826\n",
      "Baseline Loss: 2.7374 | Actual Loss: 0.2016\n",
      "Baseline Loss: 2.5077 | Actual Loss: 0.0543\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1572\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.3536\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.1849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 149/1000 [01:03<06:46,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7416 | Actual Loss: 0.2699\n",
      "Epoch 149/1000: Train Loss: 0.1830, Val Loss: 0.2414\n",
      "New best validation loss: 0.2414\n",
      "Baseline Loss: 2.8171 | Actual Loss: 0.1585\n",
      "Baseline Loss: 2.7791 | Actual Loss: 0.5214\n",
      "Baseline Loss: 2.8109 | Actual Loss: 0.1453\n",
      "Baseline Loss: 2.8793 | Actual Loss: 0.1334\n",
      "Baseline Loss: 2.8317 | Actual Loss: 0.1860\n",
      "Baseline Loss: 2.8776 | Actual Loss: 0.1754\n",
      "Baseline Loss: 2.8640 | Actual Loss: 0.0907\n",
      "Baseline Loss: 2.8226 | Actual Loss: 0.2479\n",
      "Baseline Loss: 2.8267 | Actual Loss: 0.1447\n",
      "Baseline Loss: 2.8225 | Actual Loss: 0.1617\n",
      "Baseline Loss: 2.9025 | Actual Loss: 0.1740\n",
      "Baseline Loss: 2.8168 | Actual Loss: 0.1092\n",
      "Baseline Loss: 2.7728 | Actual Loss: 0.1552\n",
      "Baseline Loss: 2.8386 | Actual Loss: 0.1263\n",
      "Baseline Loss: 2.8037 | Actual Loss: 0.2113\n",
      "Baseline Loss: 2.4713 | Actual Loss: 0.1962\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1859\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4236\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 150/1000 [01:04<06:52,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7416 | Actual Loss: 0.2619\n",
      "Epoch 150/1000: Train Loss: 0.1836, Val Loss: 0.2883\n",
      "Baseline Loss: 2.7564 | Actual Loss: 0.2399\n",
      "Baseline Loss: 2.8513 | Actual Loss: 0.1069\n",
      "Baseline Loss: 2.7970 | Actual Loss: 0.4041\n",
      "Baseline Loss: 2.7407 | Actual Loss: 0.1460\n",
      "Baseline Loss: 2.9281 | Actual Loss: 0.2480\n",
      "Baseline Loss: 2.8062 | Actual Loss: 0.1247\n",
      "Baseline Loss: 2.8722 | Actual Loss: 0.2692\n",
      "Baseline Loss: 2.8304 | Actual Loss: 0.1534\n",
      "Baseline Loss: 2.8421 | Actual Loss: 0.1814\n",
      "Baseline Loss: 2.7585 | Actual Loss: 0.1206\n",
      "Baseline Loss: 2.8158 | Actual Loss: 0.3408\n",
      "Baseline Loss: 2.9222 | Actual Loss: 0.3381\n",
      "Baseline Loss: 2.8421 | Actual Loss: 0.1881\n",
      "Baseline Loss: 2.8553 | Actual Loss: 0.2952\n",
      "Baseline Loss: 2.8747 | Actual Loss: 0.1407\n",
      "Baseline Loss: 2.5785 | Actual Loss: 0.3622\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1566\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 151/1000 [01:04<07:01,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8204 | Actual Loss: 0.2279\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2071\n",
      "Epoch 151/1000: Train Loss: 0.2287, Val Loss: 0.2634\n",
      "Baseline Loss: 2.8502 | Actual Loss: 0.1222\n",
      "Baseline Loss: 2.7700 | Actual Loss: 0.1533\n",
      "Baseline Loss: 2.8640 | Actual Loss: 0.1794\n",
      "Baseline Loss: 2.8160 | Actual Loss: 0.1562\n",
      "Baseline Loss: 2.7695 | Actual Loss: 0.1110\n",
      "Baseline Loss: 2.7271 | Actual Loss: 0.0866\n",
      "Baseline Loss: 2.8480 | Actual Loss: 0.1469\n",
      "Baseline Loss: 2.8362 | Actual Loss: 0.1640\n",
      "Baseline Loss: 2.9136 | Actual Loss: 0.3237\n",
      "Baseline Loss: 2.8454 | Actual Loss: 0.2001\n",
      "Baseline Loss: 2.8152 | Actual Loss: 0.1953\n",
      "Baseline Loss: 2.8277 | Actual Loss: 0.2151\n",
      "Baseline Loss: 2.8121 | Actual Loss: 0.2234\n",
      "Baseline Loss: 2.8847 | Actual Loss: 0.2347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 152/1000 [01:05<06:43,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7788 | Actual Loss: 0.2299\n",
      "Baseline Loss: 2.3922 | Actual Loss: 0.1406\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1873\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5153\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2653\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2951\n",
      "Epoch 152/1000: Train Loss: 0.1801, Val Loss: 0.3157\n",
      "Baseline Loss: 2.8461 | Actual Loss: 0.1844\n",
      "Baseline Loss: 2.8402 | Actual Loss: 0.2469\n",
      "Baseline Loss: 2.8497 | Actual Loss: 0.1369\n",
      "Baseline Loss: 2.8536 | Actual Loss: 0.1628\n",
      "Baseline Loss: 2.9146 | Actual Loss: 0.1689\n",
      "Baseline Loss: 2.7812 | Actual Loss: 0.1665\n",
      "Baseline Loss: 2.7984 | Actual Loss: 0.1571\n",
      "Baseline Loss: 2.7039 | Actual Loss: 0.2083\n",
      "Baseline Loss: 2.7913 | Actual Loss: 0.1181\n",
      "Baseline Loss: 2.8441 | Actual Loss: 0.1247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 153/1000 [01:05<06:53,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.0071 | Actual Loss: 0.1006\n",
      "Baseline Loss: 2.7925 | Actual Loss: 0.0994\n",
      "Baseline Loss: 2.7892 | Actual Loss: 0.1224\n",
      "Baseline Loss: 2.7926 | Actual Loss: 0.1182\n",
      "Baseline Loss: 2.8541 | Actual Loss: 0.3407\n",
      "Baseline Loss: 2.5541 | Actual Loss: 0.2937\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1538\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4528\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2631\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.3271\n",
      "Epoch 153/1000: Train Loss: 0.1718, Val Loss: 0.2992\n",
      "Baseline Loss: 2.8770 | Actual Loss: 0.1514\n",
      "Baseline Loss: 2.7666 | Actual Loss: 0.3014\n",
      "Baseline Loss: 2.8283 | Actual Loss: 0.1831\n",
      "Baseline Loss: 2.8003 | Actual Loss: 0.2236\n",
      "Baseline Loss: 2.7976 | Actual Loss: 0.2353\n",
      "Baseline Loss: 2.8305 | Actual Loss: 0.1521\n",
      "Baseline Loss: 2.8622 | Actual Loss: 0.1807\n",
      "Baseline Loss: 2.8037 | Actual Loss: 0.0938\n",
      "Baseline Loss: 2.8452 | Actual Loss: 0.1892\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.2321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 154/1000 [01:06<06:40,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8294 | Actual Loss: 0.2099\n",
      "Baseline Loss: 2.7511 | Actual Loss: 0.3150\n",
      "Baseline Loss: 2.8487 | Actual Loss: 0.1012\n",
      "Baseline Loss: 2.8164 | Actual Loss: 0.1128\n",
      "Baseline Loss: 2.9363 | Actual Loss: 0.2293\n",
      "Baseline Loss: 2.5294 | Actual Loss: 0.1358\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1517\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5370\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2937\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2861\n",
      "Epoch 154/1000: Train Loss: 0.1904, Val Loss: 0.3171\n",
      "Baseline Loss: 2.8486 | Actual Loss: 0.2395\n",
      "Baseline Loss: 2.8360 | Actual Loss: 0.2450\n",
      "Baseline Loss: 2.8594 | Actual Loss: 0.1782\n",
      "Baseline Loss: 2.7629 | Actual Loss: 0.0816\n",
      "Baseline Loss: 2.7571 | Actual Loss: 0.1578\n",
      "Baseline Loss: 2.9142 | Actual Loss: 0.1624\n",
      "Baseline Loss: 2.8175 | Actual Loss: 0.1937\n",
      "Baseline Loss: 2.8269 | Actual Loss: 0.1494\n",
      "Baseline Loss: 2.8396 | Actual Loss: 0.1157\n",
      "Baseline Loss: 2.7729 | Actual Loss: 0.1991\n",
      "Baseline Loss: 2.8306 | Actual Loss: 0.1289\n",
      "Baseline Loss: 2.8614 | Actual Loss: 0.1457\n",
      "Baseline Loss: 2.8237 | Actual Loss: 0.2217\n",
      "Baseline Loss: 2.8361 | Actual Loss: 0.1090\n",
      "Baseline Loss: 2.8364 | Actual Loss: 0.2978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 155/1000 [01:06<06:52,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5541 | Actual Loss: 0.1862\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1623\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.3526\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2500\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2884\n",
      "Epoch 155/1000: Train Loss: 0.1757, Val Loss: 0.2633\n",
      "Baseline Loss: 2.8142 | Actual Loss: 0.1566\n",
      "Baseline Loss: 2.8299 | Actual Loss: 0.4015\n",
      "Baseline Loss: 2.9038 | Actual Loss: 0.2644\n",
      "Baseline Loss: 2.8009 | Actual Loss: 0.2074\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.1332\n",
      "Baseline Loss: 2.8410 | Actual Loss: 0.1491\n",
      "Baseline Loss: 2.8025 | Actual Loss: 0.1671\n",
      "Baseline Loss: 2.8158 | Actual Loss: 0.1247\n",
      "Baseline Loss: 2.9218 | Actual Loss: 0.2362\n",
      "Baseline Loss: 2.7846 | Actual Loss: 0.1204\n",
      "Baseline Loss: 2.8473 | Actual Loss: 0.1712\n",
      "Baseline Loss: 2.8533 | Actual Loss: 0.2069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 156/1000 [01:07<06:48,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7913 | Actual Loss: 0.2125\n",
      "Baseline Loss: 2.8184 | Actual Loss: 0.0852\n",
      "Baseline Loss: 2.8657 | Actual Loss: 0.1416\n",
      "Baseline Loss: 2.4040 | Actual Loss: 0.1365\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1696\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5318\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3325\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2442\n",
      "Epoch 156/1000: Train Loss: 0.1822, Val Loss: 0.3195\n",
      "Baseline Loss: 2.7869 | Actual Loss: 0.2636\n",
      "Baseline Loss: 2.9107 | Actual Loss: 0.1704\n",
      "Baseline Loss: 2.7841 | Actual Loss: 0.1327\n",
      "Baseline Loss: 2.8982 | Actual Loss: 0.1360\n",
      "Baseline Loss: 2.8315 | Actual Loss: 0.1077\n",
      "Baseline Loss: 2.8200 | Actual Loss: 0.2025\n",
      "Baseline Loss: 2.7976 | Actual Loss: 0.0975\n",
      "Baseline Loss: 2.8109 | Actual Loss: 0.2280\n",
      "Baseline Loss: 2.8666 | Actual Loss: 0.1817\n",
      "Baseline Loss: 2.8726 | Actual Loss: 0.1526\n",
      "Baseline Loss: 2.8245 | Actual Loss: 0.2247\n",
      "Baseline Loss: 2.8427 | Actual Loss: 0.2836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 157/1000 [01:07<06:40,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8059 | Actual Loss: 0.0840\n",
      "Baseline Loss: 2.8050 | Actual Loss: 0.1129\n",
      "Baseline Loss: 2.8041 | Actual Loss: 0.2957\n",
      "Baseline Loss: 2.6031 | Actual Loss: 0.0644\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2064\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4307\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2511\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.3116\n",
      "Epoch 157/1000: Train Loss: 0.1711, Val Loss: 0.2999\n",
      "Baseline Loss: 2.8154 | Actual Loss: 0.1493\n",
      "Baseline Loss: 2.8559 | Actual Loss: 0.2235\n",
      "Baseline Loss: 2.8764 | Actual Loss: 0.2951\n",
      "Baseline Loss: 2.8404 | Actual Loss: 0.1428\n",
      "Baseline Loss: 2.8217 | Actual Loss: 0.1269\n",
      "Baseline Loss: 2.8083 | Actual Loss: 0.2620\n",
      "Baseline Loss: 2.8523 | Actual Loss: 0.2851\n",
      "Baseline Loss: 2.8007 | Actual Loss: 0.1844\n",
      "Baseline Loss: 2.7807 | Actual Loss: 0.2898\n",
      "Baseline Loss: 2.8574 | Actual Loss: 0.1855\n",
      "Baseline Loss: 2.8183 | Actual Loss: 0.1293\n",
      "Baseline Loss: 2.8057 | Actual Loss: 0.3330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 158/1000 [01:08<06:49,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7830 | Actual Loss: 0.1453\n",
      "Baseline Loss: 2.8479 | Actual Loss: 0.0924\n",
      "Baseline Loss: 2.7949 | Actual Loss: 0.1835\n",
      "Baseline Loss: 2.5754 | Actual Loss: 0.0507\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2005\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.3767\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2421\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2749\n",
      "Epoch 158/1000: Train Loss: 0.1924, Val Loss: 0.2735\n",
      "Baseline Loss: 2.7733 | Actual Loss: 0.1571\n",
      "Baseline Loss: 2.8496 | Actual Loss: 0.1910\n",
      "Baseline Loss: 2.8136 | Actual Loss: 0.2064\n",
      "Baseline Loss: 2.8589 | Actual Loss: 0.2389\n",
      "Baseline Loss: 2.8162 | Actual Loss: 0.2884\n",
      "Baseline Loss: 2.8315 | Actual Loss: 0.1892\n",
      "Baseline Loss: 2.8506 | Actual Loss: 0.1727\n",
      "Baseline Loss: 2.8496 | Actual Loss: 0.1732\n",
      "Baseline Loss: 2.8020 | Actual Loss: 0.1126\n",
      "Baseline Loss: 2.7370 | Actual Loss: 0.1799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 159/1000 [01:08<06:45,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7985 | Actual Loss: 0.1327\n",
      "Baseline Loss: 2.8299 | Actual Loss: 0.2619\n",
      "Baseline Loss: 2.8926 | Actual Loss: 0.1595\n",
      "Baseline Loss: 2.8618 | Actual Loss: 0.1247\n",
      "Baseline Loss: 2.8375 | Actual Loss: 0.1615\n",
      "Baseline Loss: 2.6989 | Actual Loss: 0.1300\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1675\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4709\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3000\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2219\n",
      "Epoch 159/1000: Train Loss: 0.1800, Val Loss: 0.2901\n",
      "Baseline Loss: 2.8073 | Actual Loss: 0.2237\n",
      "Baseline Loss: 2.8454 | Actual Loss: 0.1817\n",
      "Baseline Loss: 2.7428 | Actual Loss: 0.2343\n",
      "Baseline Loss: 2.8533 | Actual Loss: 0.2186\n",
      "Baseline Loss: 2.8446 | Actual Loss: 0.2231\n",
      "Baseline Loss: 2.7928 | Actual Loss: 0.2468\n",
      "Baseline Loss: 2.8338 | Actual Loss: 0.1539\n",
      "Baseline Loss: 2.8765 | Actual Loss: 0.2325\n",
      "Baseline Loss: 2.7834 | Actual Loss: 0.1386\n",
      "Baseline Loss: 2.8551 | Actual Loss: 0.1272\n",
      "Baseline Loss: 2.8065 | Actual Loss: 0.2337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 160/1000 [01:09<06:34,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7526 | Actual Loss: 0.2463\n",
      "Baseline Loss: 2.8538 | Actual Loss: 0.1559\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2056\n",
      "Baseline Loss: 2.8055 | Actual Loss: 0.1357\n",
      "Baseline Loss: 2.4771 | Actual Loss: 0.0641\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1468\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4002\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2447\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.3275\n",
      "Epoch 160/1000: Train Loss: 0.1889, Val Loss: 0.2798\n",
      "Baseline Loss: 2.8028 | Actual Loss: 0.1871\n",
      "Baseline Loss: 2.8968 | Actual Loss: 0.1889\n",
      "Baseline Loss: 2.7881 | Actual Loss: 0.1695\n",
      "Baseline Loss: 2.7881 | Actual Loss: 0.1681\n",
      "Baseline Loss: 2.8732 | Actual Loss: 0.1467\n",
      "Baseline Loss: 2.8198 | Actual Loss: 0.1732\n",
      "Baseline Loss: 2.9053 | Actual Loss: 0.2828\n",
      "Baseline Loss: 2.7808 | Actual Loss: 0.0899\n",
      "Baseline Loss: 2.7851 | Actual Loss: 0.1625\n",
      "Baseline Loss: 2.7782 | Actual Loss: 0.1109\n",
      "Baseline Loss: 2.7743 | Actual Loss: 0.1352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 161/1000 [01:09<06:47,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8367 | Actual Loss: 0.1032\n",
      "Baseline Loss: 2.8358 | Actual Loss: 0.1050\n",
      "Baseline Loss: 2.7605 | Actual Loss: 0.1153\n",
      "Baseline Loss: 2.8459 | Actual Loss: 0.2117\n",
      "Baseline Loss: 2.5076 | Actual Loss: 0.0662\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2009\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4560\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3319\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2700\n",
      "Epoch 161/1000: Train Loss: 0.1510, Val Loss: 0.3147\n",
      "Baseline Loss: 2.8143 | Actual Loss: 0.2174\n",
      "Baseline Loss: 2.7412 | Actual Loss: 0.1480\n",
      "Baseline Loss: 2.8009 | Actual Loss: 0.1460\n",
      "Baseline Loss: 2.8198 | Actual Loss: 0.2346\n",
      "Baseline Loss: 2.8223 | Actual Loss: 0.1346\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.1990\n",
      "Baseline Loss: 2.8224 | Actual Loss: 0.2550\n",
      "Baseline Loss: 2.8500 | Actual Loss: 0.1155\n",
      "Baseline Loss: 2.8439 | Actual Loss: 0.1750\n",
      "Baseline Loss: 2.8208 | Actual Loss: 0.1812\n",
      "Baseline Loss: 2.7919 | Actual Loss: 0.3097\n",
      "Baseline Loss: 2.8265 | Actual Loss: 0.2311\n",
      "Baseline Loss: 2.8985 | Actual Loss: 0.2079\n",
      "Baseline Loss: 2.8839 | Actual Loss: 0.1544\n",
      "Baseline Loss: 2.8287 | Actual Loss: 0.1803\n",
      "Baseline Loss: 2.5445 | Actual Loss: 0.0771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 162/1000 [01:10<06:53,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8321 | Actual Loss: 0.2502\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4763\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2381\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2439\n",
      "Epoch 162/1000: Train Loss: 0.1854, Val Loss: 0.3021\n",
      "Baseline Loss: 2.8065 | Actual Loss: 0.2839\n",
      "Baseline Loss: 2.7961 | Actual Loss: 0.1293\n",
      "Baseline Loss: 2.9301 | Actual Loss: 0.2610\n",
      "Baseline Loss: 2.8251 | Actual Loss: 0.2415\n",
      "Baseline Loss: 2.7927 | Actual Loss: 0.1704\n",
      "Baseline Loss: 2.9228 | Actual Loss: 0.2690\n",
      "Baseline Loss: 2.8942 | Actual Loss: 0.6658\n",
      "Baseline Loss: 2.7849 | Actual Loss: 0.0807\n",
      "Baseline Loss: 2.8776 | Actual Loss: 0.1388\n",
      "Baseline Loss: 2.7990 | Actual Loss: 0.2343\n",
      "Baseline Loss: 2.8014 | Actual Loss: 0.2396\n",
      "Baseline Loss: 2.8860 | Actual Loss: 0.1484\n",
      "Baseline Loss: 2.8262 | Actual Loss: 0.1787\n",
      "Baseline Loss: 2.7996 | Actual Loss: 0.1225\n",
      "Baseline Loss: 2.7851 | Actual Loss: 0.1339\n",
      "Baseline Loss: 2.4660 | Actual Loss: 0.1407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▋        | 163/1000 [01:10<06:39,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8321 | Actual Loss: 0.1553\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4746\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2745\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.3358\n",
      "Epoch 163/1000: Train Loss: 0.2149, Val Loss: 0.3100\n",
      "Baseline Loss: 2.8346 | Actual Loss: 0.1775\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.2017\n",
      "Baseline Loss: 2.8979 | Actual Loss: 0.1094\n",
      "Baseline Loss: 2.8983 | Actual Loss: 0.2286\n",
      "Baseline Loss: 2.7842 | Actual Loss: 0.1766\n",
      "Baseline Loss: 2.7940 | Actual Loss: 0.1876\n",
      "Baseline Loss: 2.7625 | Actual Loss: 0.1930\n",
      "Baseline Loss: 2.8340 | Actual Loss: 0.1125\n",
      "Baseline Loss: 2.8547 | Actual Loss: 0.2425\n",
      "Baseline Loss: 2.8629 | Actual Loss: 0.2301\n",
      "Baseline Loss: 2.8390 | Actual Loss: 0.1615\n",
      "Baseline Loss: 2.8610 | Actual Loss: 0.2075\n",
      "Baseline Loss: 2.8116 | Actual Loss: 0.1933\n",
      "Baseline Loss: 2.8634 | Actual Loss: 0.1914\n",
      "Baseline Loss: 2.8214 | Actual Loss: 0.1098\n",
      "Baseline Loss: 2.4834 | Actual Loss: 0.0582\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▋        | 164/1000 [01:11<06:39,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8514 | Actual Loss: 0.4297\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3095\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2292\n",
      "Epoch 164/1000: Train Loss: 0.1738, Val Loss: 0.2783\n",
      "Baseline Loss: 2.8055 | Actual Loss: 0.1390\n",
      "Baseline Loss: 2.7939 | Actual Loss: 0.1202\n",
      "Baseline Loss: 2.8512 | Actual Loss: 0.2792\n",
      "Baseline Loss: 2.8445 | Actual Loss: 0.1654\n",
      "Baseline Loss: 2.8768 | Actual Loss: 0.4437\n",
      "Baseline Loss: 2.8704 | Actual Loss: 0.2046\n",
      "Baseline Loss: 2.8699 | Actual Loss: 0.1577\n",
      "Baseline Loss: 2.8433 | Actual Loss: 0.1960\n",
      "Baseline Loss: 2.8230 | Actual Loss: 0.2821\n",
      "Baseline Loss: 2.7993 | Actual Loss: 0.1749\n",
      "Baseline Loss: 2.8005 | Actual Loss: 0.2232\n",
      "Baseline Loss: 2.7434 | Actual Loss: 0.1856\n",
      "Baseline Loss: 2.8414 | Actual Loss: 0.1638\n",
      "Baseline Loss: 2.8943 | Actual Loss: 0.3303\n",
      "Baseline Loss: 2.8127 | Actual Loss: 0.4644\n",
      "Baseline Loss: 2.5292 | Actual Loss: 0.1491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▋        | 165/1000 [01:11<06:46,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8321 | Actual Loss: 0.1639\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5135\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2271\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2397\n",
      "Epoch 165/1000: Train Loss: 0.2300, Val Loss: 0.2860\n",
      "Baseline Loss: 2.7964 | Actual Loss: 0.1505\n",
      "Baseline Loss: 2.7844 | Actual Loss: 0.1700\n",
      "Baseline Loss: 2.7923 | Actual Loss: 0.1557\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1552\n",
      "Baseline Loss: 2.8058 | Actual Loss: 0.1771\n",
      "Baseline Loss: 2.9141 | Actual Loss: 0.2064\n",
      "Baseline Loss: 2.8348 | Actual Loss: 0.1748\n",
      "Baseline Loss: 2.8300 | Actual Loss: 0.1754\n",
      "Baseline Loss: 2.8060 | Actual Loss: 0.2110\n",
      "Baseline Loss: 2.7890 | Actual Loss: 0.2160\n",
      "Baseline Loss: 2.8343 | Actual Loss: 0.2061\n",
      "Baseline Loss: 2.8522 | Actual Loss: 0.1795\n",
      "Baseline Loss: 2.8458 | Actual Loss: 0.1012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 166/1000 [01:12<06:30,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7587 | Actual Loss: 0.1471\n",
      "Baseline Loss: 2.8392 | Actual Loss: 0.1945\n",
      "Baseline Loss: 2.4208 | Actual Loss: 0.1077\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1849\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4933\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3131\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2248\n",
      "Epoch 166/1000: Train Loss: 0.1705, Val Loss: 0.3040\n",
      "Baseline Loss: 2.8638 | Actual Loss: 0.0982\n",
      "Baseline Loss: 2.8685 | Actual Loss: 0.1475\n",
      "Baseline Loss: 2.9865 | Actual Loss: 0.3182\n",
      "Baseline Loss: 2.8175 | Actual Loss: 0.1120\n",
      "Baseline Loss: 2.7618 | Actual Loss: 0.2287\n",
      "Baseline Loss: 2.8248 | Actual Loss: 0.1842\n",
      "Baseline Loss: 2.7777 | Actual Loss: 0.2620\n",
      "Baseline Loss: 2.8031 | Actual Loss: 0.2269\n",
      "Baseline Loss: 2.8231 | Actual Loss: 0.2382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 167/1000 [01:12<06:27,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8429 | Actual Loss: 0.1747\n",
      "Baseline Loss: 2.7775 | Actual Loss: 0.1564\n",
      "Baseline Loss: 2.8384 | Actual Loss: 0.2165\n",
      "Baseline Loss: 2.8760 | Actual Loss: 0.2139\n",
      "Baseline Loss: 2.8063 | Actual Loss: 0.1532\n",
      "Baseline Loss: 2.7696 | Actual Loss: 0.0752\n",
      "Baseline Loss: 2.4916 | Actual Loss: 0.0669\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1466\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.7238\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3283\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2468\n",
      "Epoch 167/1000: Train Loss: 0.1795, Val Loss: 0.3614\n",
      "Baseline Loss: 2.8250 | Actual Loss: 0.2554\n",
      "Baseline Loss: 2.8608 | Actual Loss: 0.1893\n",
      "Baseline Loss: 2.8630 | Actual Loss: 0.1133\n",
      "Baseline Loss: 2.9075 | Actual Loss: 0.2263\n",
      "Baseline Loss: 2.8357 | Actual Loss: 0.1763\n",
      "Baseline Loss: 2.7977 | Actual Loss: 0.2022\n",
      "Baseline Loss: 2.8426 | Actual Loss: 0.1914\n",
      "Baseline Loss: 2.7765 | Actual Loss: 0.1617\n",
      "Baseline Loss: 2.8202 | Actual Loss: 0.1227\n",
      "Baseline Loss: 2.8195 | Actual Loss: 0.1896\n",
      "Baseline Loss: 2.8447 | Actual Loss: 0.2119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 168/1000 [01:12<06:20,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7968 | Actual Loss: 0.1026\n",
      "Baseline Loss: 2.8021 | Actual Loss: 0.2376\n",
      "Baseline Loss: 2.8102 | Actual Loss: 0.2424\n",
      "Baseline Loss: 2.8953 | Actual Loss: 0.3082\n",
      "Baseline Loss: 2.5055 | Actual Loss: 0.0354\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1925\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5562\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2373\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2756\n",
      "Epoch 168/1000: Train Loss: 0.1854, Val Loss: 0.3154\n",
      "Baseline Loss: 2.7874 | Actual Loss: 0.2173\n",
      "Baseline Loss: 2.8396 | Actual Loss: 0.1069\n",
      "Baseline Loss: 2.9120 | Actual Loss: 0.1526\n",
      "Baseline Loss: 2.7410 | Actual Loss: 0.1203\n",
      "Baseline Loss: 2.8480 | Actual Loss: 0.2191\n",
      "Baseline Loss: 2.8848 | Actual Loss: 0.2497\n",
      "Baseline Loss: 2.8148 | Actual Loss: 0.1407\n",
      "Baseline Loss: 2.8542 | Actual Loss: 0.1210\n",
      "Baseline Loss: 2.7899 | Actual Loss: 0.2034\n",
      "Baseline Loss: 2.8552 | Actual Loss: 0.1534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 169/1000 [01:13<06:31,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8249 | Actual Loss: 0.1649\n",
      "Baseline Loss: 2.8604 | Actual Loss: 0.1012\n",
      "Baseline Loss: 2.7709 | Actual Loss: 0.1171\n",
      "Baseline Loss: 2.8089 | Actual Loss: 0.2063\n",
      "Baseline Loss: 2.8155 | Actual Loss: 0.1663\n",
      "Baseline Loss: 2.6006 | Actual Loss: 0.0721\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1912\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.3878\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.1973\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2897\n",
      "Epoch 169/1000: Train Loss: 0.1570, Val Loss: 0.2665\n",
      "Baseline Loss: 2.7743 | Actual Loss: 0.2040\n",
      "Baseline Loss: 2.9187 | Actual Loss: 0.2633\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.1707\n",
      "Baseline Loss: 2.8425 | Actual Loss: 0.1303\n",
      "Baseline Loss: 2.8791 | Actual Loss: 0.4263\n",
      "Baseline Loss: 2.8164 | Actual Loss: 0.1984\n",
      "Baseline Loss: 2.7947 | Actual Loss: 0.0999\n",
      "Baseline Loss: 2.7988 | Actual Loss: 0.1145\n",
      "Baseline Loss: 2.8168 | Actual Loss: 0.1917\n",
      "Baseline Loss: 2.8058 | Actual Loss: 0.1079\n",
      "Baseline Loss: 2.8505 | Actual Loss: 0.1615\n",
      "Baseline Loss: 2.7623 | Actual Loss: 0.1182\n",
      "Baseline Loss: 2.7797 | Actual Loss: 0.1153\n",
      "Baseline Loss: 2.8123 | Actual Loss: 0.2611\n",
      "Baseline Loss: 2.8451 | Actual Loss: 0.1985\n",
      "Baseline Loss: 2.6607 | Actual Loss: 0.0924\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1476\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 170/1000 [01:13<06:37,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8204 | Actual Loss: 0.1896\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2370\n",
      "Epoch 170/1000: Train Loss: 0.1784, Val Loss: 0.2756\n",
      "Baseline Loss: 2.8551 | Actual Loss: 0.1721\n",
      "Baseline Loss: 2.8879 | Actual Loss: 0.2945\n",
      "Baseline Loss: 2.8050 | Actual Loss: 0.0962\n",
      "Baseline Loss: 2.8494 | Actual Loss: 0.3370\n",
      "Baseline Loss: 2.7787 | Actual Loss: 0.1463\n",
      "Baseline Loss: 2.8748 | Actual Loss: 0.1180\n",
      "Baseline Loss: 2.7871 | Actual Loss: 0.1419\n",
      "Baseline Loss: 2.7930 | Actual Loss: 0.1395\n",
      "Baseline Loss: 2.8290 | Actual Loss: 0.1990\n",
      "Baseline Loss: 2.8694 | Actual Loss: 0.0710\n",
      "Baseline Loss: 2.8557 | Actual Loss: 0.1118\n",
      "Baseline Loss: 2.8696 | Actual Loss: 0.1635\n",
      "Baseline Loss: 2.8217 | Actual Loss: 0.1340\n",
      "Baseline Loss: 2.8019 | Actual Loss: 0.1466\n",
      "Baseline Loss: 2.8004 | Actual Loss: 0.2702\n",
      "Baseline Loss: 2.6520 | Actual Loss: 0.5071\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1779\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 171/1000 [01:14<06:40,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8204 | Actual Loss: 0.2904\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.3212\n",
      "Epoch 171/1000: Train Loss: 0.1905, Val Loss: 0.3396\n",
      "Baseline Loss: 2.8776 | Actual Loss: 0.1497\n",
      "Baseline Loss: 2.7540 | Actual Loss: 0.1569\n",
      "Baseline Loss: 2.7772 | Actual Loss: 0.2477\n",
      "Baseline Loss: 2.9062 | Actual Loss: 0.1446\n",
      "Baseline Loss: 2.7946 | Actual Loss: 0.3094\n",
      "Baseline Loss: 2.8548 | Actual Loss: 0.1308\n",
      "Baseline Loss: 2.8938 | Actual Loss: 0.1779\n",
      "Baseline Loss: 2.8431 | Actual Loss: 0.1517\n",
      "Baseline Loss: 2.8082 | Actual Loss: 0.1184\n",
      "Baseline Loss: 2.8149 | Actual Loss: 0.1973\n",
      "Baseline Loss: 2.8342 | Actual Loss: 0.2152\n",
      "Baseline Loss: 2.8326 | Actual Loss: 0.2903\n",
      "Baseline Loss: 2.7819 | Actual Loss: 0.1674\n",
      "Baseline Loss: 2.8757 | Actual Loss: 0.4283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 172/1000 [01:14<06:24,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8457 | Actual Loss: 0.1680\n",
      "Baseline Loss: 2.4840 | Actual Loss: 0.2672\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1710\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4702\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3470\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2647\n",
      "Epoch 172/1000: Train Loss: 0.2076, Val Loss: 0.3132\n",
      "Baseline Loss: 2.8081 | Actual Loss: 0.2734\n",
      "Baseline Loss: 2.8323 | Actual Loss: 0.2003\n",
      "Baseline Loss: 2.8882 | Actual Loss: 0.1384\n",
      "Baseline Loss: 2.8373 | Actual Loss: 0.1606\n",
      "Baseline Loss: 2.8188 | Actual Loss: 0.0898\n",
      "Baseline Loss: 2.8105 | Actual Loss: 0.1058\n",
      "Baseline Loss: 2.8314 | Actual Loss: 0.1164\n",
      "Baseline Loss: 2.8122 | Actual Loss: 0.3158\n",
      "Baseline Loss: 2.7678 | Actual Loss: 0.0833\n",
      "Baseline Loss: 2.8854 | Actual Loss: 0.1342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 173/1000 [01:15<06:25,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7590 | Actual Loss: 0.1993\n",
      "Baseline Loss: 2.7599 | Actual Loss: 0.1727\n",
      "Baseline Loss: 2.8684 | Actual Loss: 0.1426\n",
      "Baseline Loss: 2.8411 | Actual Loss: 0.1981\n",
      "Baseline Loss: 2.9084 | Actual Loss: 0.1795\n",
      "Baseline Loss: 2.3937 | Actual Loss: 0.1721\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1750\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5382\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2619\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.3394\n",
      "Epoch 173/1000: Train Loss: 0.1676, Val Loss: 0.3286\n",
      "Baseline Loss: 2.7513 | Actual Loss: 0.1973\n",
      "Baseline Loss: 2.8119 | Actual Loss: 0.1452\n",
      "Baseline Loss: 2.8533 | Actual Loss: 0.2524\n",
      "Baseline Loss: 2.7803 | Actual Loss: 0.1429\n",
      "Baseline Loss: 2.8574 | Actual Loss: 0.0926\n",
      "Baseline Loss: 2.8000 | Actual Loss: 0.1255\n",
      "Baseline Loss: 2.8466 | Actual Loss: 0.2599\n",
      "Baseline Loss: 2.8387 | Actual Loss: 0.1959\n",
      "Baseline Loss: 2.7911 | Actual Loss: 0.1334\n",
      "Baseline Loss: 2.8479 | Actual Loss: 0.1591\n",
      "Baseline Loss: 2.8107 | Actual Loss: 0.1971\n",
      "Baseline Loss: 2.8338 | Actual Loss: 0.1280\n",
      "Baseline Loss: 2.7757 | Actual Loss: 0.1217\n",
      "Baseline Loss: 2.8138 | Actual Loss: 0.1552\n",
      "Baseline Loss: 2.8936 | Actual Loss: 0.0771\n",
      "Baseline Loss: 2.4509 | Actual Loss: 0.1106\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1458\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 174/1000 [01:15<06:34,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8204 | Actual Loss: 0.2526\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2913\n",
      "Epoch 174/1000: Train Loss: 0.1559, Val Loss: 0.3019\n",
      "Baseline Loss: 2.8171 | Actual Loss: 0.1359\n",
      "Baseline Loss: 2.9145 | Actual Loss: 0.2527\n",
      "Baseline Loss: 2.7856 | Actual Loss: 0.2044\n",
      "Baseline Loss: 2.8119 | Actual Loss: 0.1579\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.1556\n",
      "Baseline Loss: 2.9088 | Actual Loss: 0.2571\n",
      "Baseline Loss: 2.8693 | Actual Loss: 0.1882\n",
      "Baseline Loss: 2.8029 | Actual Loss: 0.1234\n",
      "Baseline Loss: 2.8219 | Actual Loss: 0.1243\n",
      "Baseline Loss: 2.8143 | Actual Loss: 0.1916\n",
      "Baseline Loss: 2.8435 | Actual Loss: 0.1175\n",
      "Baseline Loss: 2.8116 | Actual Loss: 0.2004\n",
      "Baseline Loss: 2.8129 | Actual Loss: 0.1063\n",
      "Baseline Loss: 2.8606 | Actual Loss: 0.0959\n",
      "Baseline Loss: 2.8138 | Actual Loss: 0.1453\n",
      "Baseline Loss: 2.4852 | Actual Loss: 0.1773\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1683\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.3582\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 175/1000 [01:16<06:15,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7416 | Actual Loss: 0.2403\n",
      "Epoch 175/1000: Train Loss: 0.1646, Val Loss: 0.2492\n",
      "Baseline Loss: 2.8195 | Actual Loss: 0.1078\n",
      "Baseline Loss: 2.8104 | Actual Loss: 0.2595\n",
      "Baseline Loss: 2.9282 | Actual Loss: 0.2070\n",
      "Baseline Loss: 2.7654 | Actual Loss: 0.2193\n",
      "Baseline Loss: 2.8531 | Actual Loss: 0.1031\n",
      "Baseline Loss: 2.8432 | Actual Loss: 0.2739\n",
      "Baseline Loss: 2.8663 | Actual Loss: 0.1370\n",
      "Baseline Loss: 2.8260 | Actual Loss: 0.1318\n",
      "Baseline Loss: 2.8607 | Actual Loss: 0.1945\n",
      "Baseline Loss: 2.9113 | Actual Loss: 0.2125\n",
      "Baseline Loss: 2.8224 | Actual Loss: 0.1194\n",
      "Baseline Loss: 2.7993 | Actual Loss: 0.0784\n",
      "Baseline Loss: 2.7410 | Actual Loss: 0.1402\n",
      "Baseline Loss: 2.8309 | Actual Loss: 0.2022\n",
      "Baseline Loss: 2.8275 | Actual Loss: 0.0858\n",
      "Baseline Loss: 2.4189 | Actual Loss: 0.1833\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1313\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 176/1000 [01:16<06:28,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8204 | Actual Loss: 0.2413\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2474\n",
      "Epoch 176/1000: Train Loss: 0.1660, Val Loss: 0.2772\n",
      "Baseline Loss: 2.8119 | Actual Loss: 0.1292\n",
      "Baseline Loss: 2.8534 | Actual Loss: 0.2024\n",
      "Baseline Loss: 2.8777 | Actual Loss: 0.1605\n",
      "Baseline Loss: 2.8340 | Actual Loss: 0.1074\n",
      "Baseline Loss: 2.8750 | Actual Loss: 0.1851\n",
      "Baseline Loss: 2.8466 | Actual Loss: 0.2153\n",
      "Baseline Loss: 2.7707 | Actual Loss: 0.1291\n",
      "Baseline Loss: 2.8308 | Actual Loss: 0.1699\n",
      "Baseline Loss: 2.7938 | Actual Loss: 0.2220\n",
      "Baseline Loss: 2.8415 | Actual Loss: 0.2342\n",
      "Baseline Loss: 2.8170 | Actual Loss: 0.2792\n",
      "Baseline Loss: 2.8263 | Actual Loss: 0.1453\n",
      "Baseline Loss: 2.8637 | Actual Loss: 0.2426\n",
      "Baseline Loss: 2.7997 | Actual Loss: 0.2788\n",
      "Baseline Loss: 2.8075 | Actual Loss: 0.2306\n",
      "Baseline Loss: 2.5937 | Actual Loss: 0.1015\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1683\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 177/1000 [01:17<06:15,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8204 | Actual Loss: 0.2729\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2614\n",
      "Epoch 177/1000: Train Loss: 0.1896, Val Loss: 0.3061\n",
      "Baseline Loss: 2.8113 | Actual Loss: 0.2563\n",
      "Baseline Loss: 2.8172 | Actual Loss: 0.2339\n",
      "Baseline Loss: 2.7985 | Actual Loss: 0.1440\n",
      "Baseline Loss: 2.7609 | Actual Loss: 0.2270\n",
      "Baseline Loss: 2.8483 | Actual Loss: 0.2401\n",
      "Baseline Loss: 2.8867 | Actual Loss: 0.1333\n",
      "Baseline Loss: 2.8052 | Actual Loss: 0.3296\n",
      "Baseline Loss: 2.7985 | Actual Loss: 0.0824\n",
      "Baseline Loss: 2.8627 | Actual Loss: 0.1491\n",
      "Baseline Loss: 2.8487 | Actual Loss: 0.2753\n",
      "Baseline Loss: 2.8136 | Actual Loss: 0.1044\n",
      "Baseline Loss: 2.9005 | Actual Loss: 0.1675\n",
      "Baseline Loss: 2.8572 | Actual Loss: 0.1877\n",
      "Baseline Loss: 2.8343 | Actual Loss: 0.1980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 178/1000 [01:17<06:27,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8330 | Actual Loss: 0.1668\n",
      "Baseline Loss: 2.5074 | Actual Loss: 0.0394\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1673\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4694\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2119\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2639\n",
      "Epoch 178/1000: Train Loss: 0.1834, Val Loss: 0.2781\n",
      "Baseline Loss: 2.8329 | Actual Loss: 0.2134\n",
      "Baseline Loss: 2.7725 | Actual Loss: 0.1698\n",
      "Baseline Loss: 2.8337 | Actual Loss: 0.1627\n",
      "Baseline Loss: 2.7939 | Actual Loss: 0.0955\n",
      "Baseline Loss: 2.9052 | Actual Loss: 0.2173\n",
      "Baseline Loss: 2.8313 | Actual Loss: 0.0933\n",
      "Baseline Loss: 2.8165 | Actual Loss: 0.0896\n",
      "Baseline Loss: 2.8693 | Actual Loss: 0.1885\n",
      "Baseline Loss: 2.8697 | Actual Loss: 0.2055\n",
      "Baseline Loss: 2.8314 | Actual Loss: 0.1955\n",
      "Baseline Loss: 2.8379 | Actual Loss: 0.2221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 179/1000 [01:18<06:26,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7958 | Actual Loss: 0.1732\n",
      "Baseline Loss: 2.8020 | Actual Loss: 0.1068\n",
      "Baseline Loss: 2.7837 | Actual Loss: 0.2499\n",
      "Baseline Loss: 2.8348 | Actual Loss: 0.1749\n",
      "Baseline Loss: 2.5026 | Actual Loss: 0.2562\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1662\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5657\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2119\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.3005\n",
      "Epoch 179/1000: Train Loss: 0.1759, Val Loss: 0.3111\n",
      "Baseline Loss: 2.7931 | Actual Loss: 0.1887\n",
      "Baseline Loss: 2.9141 | Actual Loss: 0.1960\n",
      "Baseline Loss: 2.8337 | Actual Loss: 0.0973\n",
      "Baseline Loss: 2.8548 | Actual Loss: 0.1459\n",
      "Baseline Loss: 2.7834 | Actual Loss: 0.1969\n",
      "Baseline Loss: 2.8108 | Actual Loss: 0.1177\n",
      "Baseline Loss: 2.7789 | Actual Loss: 0.1336\n",
      "Baseline Loss: 2.7697 | Actual Loss: 0.2966\n",
      "Baseline Loss: 2.8487 | Actual Loss: 0.3053\n",
      "Baseline Loss: 2.8892 | Actual Loss: 0.0792\n",
      "Baseline Loss: 2.7996 | Actual Loss: 0.1795\n",
      "Baseline Loss: 2.8144 | Actual Loss: 0.1264\n",
      "Baseline Loss: 2.7976 | Actual Loss: 0.0828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 180/1000 [01:18<06:14,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8236 | Actual Loss: 0.1809\n",
      "Baseline Loss: 2.8111 | Actual Loss: 0.1539\n",
      "Baseline Loss: 2.5344 | Actual Loss: 0.2742\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1969\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4767\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2449\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2528\n",
      "Epoch 180/1000: Train Loss: 0.1722, Val Loss: 0.2928\n",
      "Baseline Loss: 2.9256 | Actual Loss: 0.1915\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.1693\n",
      "Baseline Loss: 2.8014 | Actual Loss: 0.1288\n",
      "Baseline Loss: 2.8125 | Actual Loss: 0.2087\n",
      "Baseline Loss: 2.8697 | Actual Loss: 0.1542\n",
      "Baseline Loss: 2.8161 | Actual Loss: 0.2390\n",
      "Baseline Loss: 2.7788 | Actual Loss: 0.1717\n",
      "Baseline Loss: 2.8051 | Actual Loss: 0.2224\n",
      "Baseline Loss: 2.8256 | Actual Loss: 0.2442\n",
      "Baseline Loss: 2.8602 | Actual Loss: 0.1083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 181/1000 [01:19<06:22,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7671 | Actual Loss: 0.1847\n",
      "Baseline Loss: 2.8693 | Actual Loss: 0.0698\n",
      "Baseline Loss: 2.8023 | Actual Loss: 0.2294\n",
      "Baseline Loss: 2.8679 | Actual Loss: 0.1077\n",
      "Baseline Loss: 2.8645 | Actual Loss: 0.1393\n",
      "Baseline Loss: 2.4349 | Actual Loss: 0.0743\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1344\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4326\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2906\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.3139\n",
      "Epoch 181/1000: Train Loss: 0.1652, Val Loss: 0.2929\n",
      "Baseline Loss: 2.7609 | Actual Loss: 0.1931\n",
      "Baseline Loss: 2.7734 | Actual Loss: 0.0951\n",
      "Baseline Loss: 2.8708 | Actual Loss: 0.3760\n",
      "Baseline Loss: 2.8263 | Actual Loss: 0.2841\n",
      "Baseline Loss: 2.8196 | Actual Loss: 0.1366\n",
      "Baseline Loss: 2.7786 | Actual Loss: 0.1023\n",
      "Baseline Loss: 2.7880 | Actual Loss: 0.1524\n",
      "Baseline Loss: 2.8088 | Actual Loss: 0.1827\n",
      "Baseline Loss: 2.8666 | Actual Loss: 0.1109\n",
      "Baseline Loss: 2.8425 | Actual Loss: 0.1718\n",
      "Baseline Loss: 2.7587 | Actual Loss: 0.1874\n",
      "Baseline Loss: 2.8170 | Actual Loss: 0.1551\n",
      "Baseline Loss: 2.7915 | Actual Loss: 0.1906\n",
      "Baseline Loss: 2.8367 | Actual Loss: 0.1709\n",
      "Baseline Loss: 2.8172 | Actual Loss: 0.1266\n",
      "Baseline Loss: 2.6520 | Actual Loss: 0.0534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 182/1000 [01:19<06:29,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8321 | Actual Loss: 0.1602\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.3862\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3183\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.3154\n",
      "Epoch 182/1000: Train Loss: 0.1681, Val Loss: 0.2950\n",
      "Baseline Loss: 2.8340 | Actual Loss: 0.2188\n",
      "Baseline Loss: 2.7719 | Actual Loss: 0.2281\n",
      "Baseline Loss: 2.8142 | Actual Loss: 0.4176\n",
      "Baseline Loss: 2.8418 | Actual Loss: 0.1619\n",
      "Baseline Loss: 2.8605 | Actual Loss: 0.1236\n",
      "Baseline Loss: 2.8309 | Actual Loss: 0.1868\n",
      "Baseline Loss: 2.8072 | Actual Loss: 0.0787\n",
      "Baseline Loss: 2.8234 | Actual Loss: 0.2120\n",
      "Baseline Loss: 2.7582 | Actual Loss: 0.1371\n",
      "Baseline Loss: 2.8156 | Actual Loss: 0.1485\n",
      "Baseline Loss: 2.8086 | Actual Loss: 0.1731\n",
      "Baseline Loss: 2.8150 | Actual Loss: 0.1476\n",
      "Baseline Loss: 2.8108 | Actual Loss: 0.2942\n",
      "Baseline Loss: 2.8109 | Actual Loss: 0.3030\n",
      "Baseline Loss: 2.8618 | Actual Loss: 0.1623\n",
      "Baseline Loss: 2.4287 | Actual Loss: 0.1426\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 183/1000 [01:19<06:16,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8514 | Actual Loss: 0.4551\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2514\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2334\n",
      "Epoch 183/1000: Train Loss: 0.1960, Val Loss: 0.2773\n",
      "Baseline Loss: 2.7890 | Actual Loss: 0.2343\n",
      "Baseline Loss: 2.7700 | Actual Loss: 0.1021\n",
      "Baseline Loss: 2.8427 | Actual Loss: 0.1618\n",
      "Baseline Loss: 2.8302 | Actual Loss: 0.2412\n",
      "Baseline Loss: 2.8327 | Actual Loss: 0.1362\n",
      "Baseline Loss: 2.7944 | Actual Loss: 0.2903\n",
      "Baseline Loss: 2.8239 | Actual Loss: 0.2260\n",
      "Baseline Loss: 2.7934 | Actual Loss: 0.1932\n",
      "Baseline Loss: 2.7919 | Actual Loss: 0.1594\n",
      "Baseline Loss: 2.8502 | Actual Loss: 0.0757\n",
      "Baseline Loss: 2.8626 | Actual Loss: 0.1773\n",
      "Baseline Loss: 2.8686 | Actual Loss: 0.3018\n",
      "Baseline Loss: 2.8373 | Actual Loss: 0.2232\n",
      "Baseline Loss: 2.8001 | Actual Loss: 0.1227\n",
      "Baseline Loss: 2.8446 | Actual Loss: 0.2555\n",
      "Baseline Loss: 2.4239 | Actual Loss: 0.1348\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 184/1000 [01:20<06:23,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8514 | Actual Loss: 0.5623\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3235\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2633\n",
      "Epoch 184/1000: Train Loss: 0.1897, Val Loss: 0.3305\n",
      "Baseline Loss: 2.9152 | Actual Loss: 0.1103\n",
      "Baseline Loss: 2.8734 | Actual Loss: 0.1359\n",
      "Baseline Loss: 2.7911 | Actual Loss: 0.0760\n",
      "Baseline Loss: 2.8366 | Actual Loss: 0.5064\n",
      "Baseline Loss: 2.9290 | Actual Loss: 0.1735\n",
      "Baseline Loss: 2.7351 | Actual Loss: 0.1587\n",
      "Baseline Loss: 2.7625 | Actual Loss: 0.3710\n",
      "Baseline Loss: 2.7646 | Actual Loss: 0.2291\n",
      "Baseline Loss: 2.8332 | Actual Loss: 0.1891\n",
      "Baseline Loss: 2.8469 | Actual Loss: 0.1707\n",
      "Baseline Loss: 2.8129 | Actual Loss: 0.1806\n",
      "Baseline Loss: 2.7824 | Actual Loss: 0.0918\n",
      "Baseline Loss: 2.8262 | Actual Loss: 0.1883\n",
      "Baseline Loss: 2.7976 | Actual Loss: 0.1648\n",
      "Baseline Loss: 2.7460 | Actual Loss: 0.2120\n",
      "Baseline Loss: 2.6269 | Actual Loss: 0.0976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 185/1000 [01:20<06:33,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8321 | Actual Loss: 0.1953\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.3995\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2475\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2680\n",
      "Epoch 185/1000: Train Loss: 0.1910, Val Loss: 0.2776\n",
      "Baseline Loss: 2.8236 | Actual Loss: 0.1404\n",
      "Baseline Loss: 2.7958 | Actual Loss: 0.3514\n",
      "Baseline Loss: 2.7828 | Actual Loss: 0.1142\n",
      "Baseline Loss: 2.7848 | Actual Loss: 0.1478\n",
      "Baseline Loss: 2.8463 | Actual Loss: 0.2085\n",
      "Baseline Loss: 2.8542 | Actual Loss: 0.2634\n",
      "Baseline Loss: 2.7494 | Actual Loss: 0.1227\n",
      "Baseline Loss: 2.9134 | Actual Loss: 0.1576\n",
      "Baseline Loss: 2.8376 | Actual Loss: 0.1749\n",
      "Baseline Loss: 2.7928 | Actual Loss: 0.3261\n",
      "Baseline Loss: 2.8186 | Actual Loss: 0.1788\n",
      "Baseline Loss: 2.8525 | Actual Loss: 0.1903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▊        | 186/1000 [01:21<06:20,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8525 | Actual Loss: 0.0661\n",
      "Baseline Loss: 2.8337 | Actual Loss: 0.1688\n",
      "Baseline Loss: 2.8541 | Actual Loss: 0.1212\n",
      "Baseline Loss: 2.5427 | Actual Loss: 0.0762\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2004\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4749\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3003\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2508\n",
      "Epoch 186/1000: Train Loss: 0.1755, Val Loss: 0.3066\n",
      "Baseline Loss: 2.8016 | Actual Loss: 0.1519\n",
      "Baseline Loss: 2.8785 | Actual Loss: 0.3119\n",
      "Baseline Loss: 2.8595 | Actual Loss: 0.0996\n",
      "Baseline Loss: 2.7651 | Actual Loss: 0.1862\n",
      "Baseline Loss: 2.8055 | Actual Loss: 0.1188\n",
      "Baseline Loss: 2.8006 | Actual Loss: 0.1883\n",
      "Baseline Loss: 2.8138 | Actual Loss: 0.2799\n",
      "Baseline Loss: 2.7637 | Actual Loss: 0.2452\n",
      "Baseline Loss: 2.8077 | Actual Loss: 0.2301\n",
      "Baseline Loss: 2.7807 | Actual Loss: 0.0961\n",
      "Baseline Loss: 2.8290 | Actual Loss: 0.2470\n",
      "Baseline Loss: 2.8214 | Actual Loss: 0.0893\n",
      "Baseline Loss: 2.9043 | Actual Loss: 0.2100\n",
      "Baseline Loss: 2.9404 | Actual Loss: 0.2556\n",
      "Baseline Loss: 2.7795 | Actual Loss: 0.1774\n",
      "Baseline Loss: 2.5601 | Actual Loss: 0.2518\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1589\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5416\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▊        | 187/1000 [01:21<06:32,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7416 | Actual Loss: 0.3226\n",
      "Epoch 187/1000: Train Loss: 0.1962, Val Loss: 0.3277\n",
      "Baseline Loss: 2.8065 | Actual Loss: 0.1473\n",
      "Baseline Loss: 2.8198 | Actual Loss: 0.2516\n",
      "Baseline Loss: 2.8508 | Actual Loss: 0.1924\n",
      "Baseline Loss: 2.7854 | Actual Loss: 0.1621\n",
      "Baseline Loss: 2.7372 | Actual Loss: 0.2126\n",
      "Baseline Loss: 2.8063 | Actual Loss: 0.2093\n",
      "Baseline Loss: 2.8078 | Actual Loss: 0.1459\n",
      "Baseline Loss: 2.7926 | Actual Loss: 0.1473\n",
      "Baseline Loss: 2.8615 | Actual Loss: 0.2289\n",
      "Baseline Loss: 2.7934 | Actual Loss: 0.2190\n",
      "Baseline Loss: 2.7764 | Actual Loss: 0.1370\n",
      "Baseline Loss: 2.8001 | Actual Loss: 0.1968\n",
      "Baseline Loss: 2.8690 | Actual Loss: 0.1101\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.1194\n",
      "Baseline Loss: 2.8480 | Actual Loss: 0.1225\n",
      "Baseline Loss: 2.8057 | Actual Loss: 0.1532\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1610\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 188/1000 [01:22<06:21,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8204 | Actual Loss: 0.3171\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.3042\n",
      "Epoch 188/1000: Train Loss: 0.1722, Val Loss: 0.2991\n",
      "Baseline Loss: 2.8483 | Actual Loss: 0.1592\n",
      "Baseline Loss: 2.8416 | Actual Loss: 0.1796\n",
      "Baseline Loss: 2.7993 | Actual Loss: 0.1639\n",
      "Baseline Loss: 2.8481 | Actual Loss: 0.0933\n",
      "Baseline Loss: 2.8258 | Actual Loss: 0.2112\n",
      "Baseline Loss: 2.7699 | Actual Loss: 0.2245\n",
      "Baseline Loss: 2.8595 | Actual Loss: 0.1135\n",
      "Baseline Loss: 2.8739 | Actual Loss: 0.1948\n",
      "Baseline Loss: 2.8502 | Actual Loss: 0.1721\n",
      "Baseline Loss: 2.8157 | Actual Loss: 0.1227\n",
      "Baseline Loss: 2.8653 | Actual Loss: 0.1180\n",
      "Baseline Loss: 2.7495 | Actual Loss: 0.1515\n",
      "Baseline Loss: 2.8226 | Actual Loss: 0.2985\n",
      "Baseline Loss: 2.7920 | Actual Loss: 0.1391\n",
      "Baseline Loss: 2.8004 | Actual Loss: 0.4187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 189/1000 [01:22<06:25,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5516 | Actual Loss: 0.0935\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1529\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.7314\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3797\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2974\n",
      "Epoch 189/1000: Train Loss: 0.1784, Val Loss: 0.3904\n",
      "Baseline Loss: 2.8307 | Actual Loss: 0.2105\n",
      "Baseline Loss: 2.7613 | Actual Loss: 0.2318\n",
      "Baseline Loss: 2.8369 | Actual Loss: 0.1614\n",
      "Baseline Loss: 2.7213 | Actual Loss: 0.1817\n",
      "Baseline Loss: 2.7979 | Actual Loss: 0.1290\n",
      "Baseline Loss: 2.8910 | Actual Loss: 0.1880\n",
      "Baseline Loss: 2.8484 | Actual Loss: 0.1614\n",
      "Baseline Loss: 2.8307 | Actual Loss: 0.1195\n",
      "Baseline Loss: 2.9085 | Actual Loss: 0.2960\n",
      "Baseline Loss: 2.8081 | Actual Loss: 0.1126\n",
      "Baseline Loss: 2.7789 | Actual Loss: 0.2669\n",
      "Baseline Loss: 2.8520 | Actual Loss: 0.1461\n",
      "Baseline Loss: 2.8338 | Actual Loss: 0.1382\n",
      "Baseline Loss: 2.8901 | Actual Loss: 0.1884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 190/1000 [01:23<06:30,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7949 | Actual Loss: 0.1986\n",
      "Baseline Loss: 2.6171 | Actual Loss: 0.0527\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1875\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4911\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2483\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.3136\n",
      "Epoch 190/1000: Train Loss: 0.1739, Val Loss: 0.3101\n",
      "Baseline Loss: 2.9467 | Actual Loss: 0.2562\n",
      "Baseline Loss: 2.8592 | Actual Loss: 0.2297\n",
      "Baseline Loss: 2.8422 | Actual Loss: 0.1424\n",
      "Baseline Loss: 2.7549 | Actual Loss: 0.1389\n",
      "Baseline Loss: 2.8402 | Actual Loss: 0.1613\n",
      "Baseline Loss: 2.8725 | Actual Loss: 0.0805\n",
      "Baseline Loss: 2.7960 | Actual Loss: 0.2283\n",
      "Baseline Loss: 2.7913 | Actual Loss: 0.2121\n",
      "Baseline Loss: 2.7937 | Actual Loss: 0.0977\n",
      "Baseline Loss: 2.8178 | Actual Loss: 0.3261\n",
      "Baseline Loss: 2.8277 | Actual Loss: 0.1567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 191/1000 [01:23<06:19,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8656 | Actual Loss: 0.1837\n",
      "Baseline Loss: 2.8552 | Actual Loss: 0.0944\n",
      "Baseline Loss: 2.7652 | Actual Loss: 0.2005\n",
      "Baseline Loss: 2.7909 | Actual Loss: 0.1360\n",
      "Baseline Loss: 2.5268 | Actual Loss: 0.1539\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1532\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4581\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2877\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2453\n",
      "Epoch 191/1000: Train Loss: 0.1749, Val Loss: 0.2861\n",
      "Baseline Loss: 2.8227 | Actual Loss: 0.3130\n",
      "Baseline Loss: 2.7900 | Actual Loss: 0.3413\n",
      "Baseline Loss: 2.8956 | Actual Loss: 0.2647\n",
      "Baseline Loss: 2.8546 | Actual Loss: 0.1525\n",
      "Baseline Loss: 2.9072 | Actual Loss: 0.2876\n",
      "Baseline Loss: 2.8157 | Actual Loss: 0.0707\n",
      "Baseline Loss: 2.8140 | Actual Loss: 0.1448\n",
      "Baseline Loss: 2.7987 | Actual Loss: 0.1104\n",
      "Baseline Loss: 2.8543 | Actual Loss: 0.1558\n",
      "Baseline Loss: 2.8541 | Actual Loss: 0.1553\n",
      "Baseline Loss: 2.7882 | Actual Loss: 0.1464\n",
      "Baseline Loss: 2.7838 | Actual Loss: 0.1095\n",
      "Baseline Loss: 2.8145 | Actual Loss: 0.1511\n",
      "Baseline Loss: 2.7780 | Actual Loss: 0.1588\n",
      "Baseline Loss: 2.8012 | Actual Loss: 0.1559\n",
      "Baseline Loss: 2.5637 | Actual Loss: 0.1197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 192/1000 [01:24<06:33,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8321 | Actual Loss: 0.1887\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4629\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3380\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2729\n",
      "Epoch 192/1000: Train Loss: 0.1774, Val Loss: 0.3156\n",
      "Baseline Loss: 2.7640 | Actual Loss: 0.2686\n",
      "Baseline Loss: 2.7750 | Actual Loss: 0.4109\n",
      "Baseline Loss: 2.7944 | Actual Loss: 0.2304\n",
      "Baseline Loss: 2.8415 | Actual Loss: 0.1627\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.3400\n",
      "Baseline Loss: 2.8638 | Actual Loss: 0.4681\n",
      "Baseline Loss: 2.9020 | Actual Loss: 0.1961\n",
      "Baseline Loss: 2.8877 | Actual Loss: 0.1740\n",
      "Baseline Loss: 2.8457 | Actual Loss: 0.2793\n",
      "Baseline Loss: 2.9131 | Actual Loss: 0.2582\n",
      "Baseline Loss: 2.8263 | Actual Loss: 0.0926\n",
      "Baseline Loss: 2.7584 | Actual Loss: 0.3063\n",
      "Baseline Loss: 2.8043 | Actual Loss: 0.1808\n",
      "Baseline Loss: 2.7825 | Actual Loss: 0.1941\n",
      "Baseline Loss: 2.8805 | Actual Loss: 0.1424\n",
      "Baseline Loss: 2.6218 | Actual Loss: 0.1265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 193/1000 [01:24<06:12,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8321 | Actual Loss: 0.1602\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5900\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2819\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2588\n",
      "Epoch 193/1000: Train Loss: 0.2394, Val Loss: 0.3227\n",
      "Baseline Loss: 2.8309 | Actual Loss: 0.2527\n",
      "Baseline Loss: 2.8027 | Actual Loss: 0.1824\n",
      "Baseline Loss: 2.8832 | Actual Loss: 0.2045\n",
      "Baseline Loss: 2.8741 | Actual Loss: 0.1107\n",
      "Baseline Loss: 2.8181 | Actual Loss: 0.1516\n",
      "Baseline Loss: 2.9359 | Actual Loss: 0.2428\n",
      "Baseline Loss: 2.8335 | Actual Loss: 0.1530\n",
      "Baseline Loss: 2.8236 | Actual Loss: 0.2131\n",
      "Baseline Loss: 2.8176 | Actual Loss: 0.2229\n",
      "Baseline Loss: 2.8381 | Actual Loss: 0.0897\n",
      "Baseline Loss: 2.7662 | Actual Loss: 0.2899\n",
      "Baseline Loss: 2.8121 | Actual Loss: 0.1490\n",
      "Baseline Loss: 2.8329 | Actual Loss: 0.0541\n",
      "Baseline Loss: 2.7763 | Actual Loss: 0.2261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 194/1000 [01:25<06:21,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8231 | Actual Loss: 0.2357\n",
      "Baseline Loss: 2.5496 | Actual Loss: 0.2068\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1237\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.6417\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2374\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2830\n",
      "Epoch 194/1000: Train Loss: 0.1866, Val Loss: 0.3214\n",
      "Baseline Loss: 2.7943 | Actual Loss: 0.1882\n",
      "Baseline Loss: 2.8798 | Actual Loss: 0.2164\n",
      "Baseline Loss: 2.8663 | Actual Loss: 0.1855\n",
      "Baseline Loss: 2.8668 | Actual Loss: 0.1923\n",
      "Baseline Loss: 2.8247 | Actual Loss: 0.2031\n",
      "Baseline Loss: 2.7966 | Actual Loss: 0.1931\n",
      "Baseline Loss: 2.8577 | Actual Loss: 0.2084\n",
      "Baseline Loss: 2.8809 | Actual Loss: 0.1607\n",
      "Baseline Loss: 2.8368 | Actual Loss: 0.1160\n",
      "Baseline Loss: 2.8046 | Actual Loss: 0.3949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 195/1000 [01:25<06:32,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7858 | Actual Loss: 0.2011\n",
      "Baseline Loss: 2.8164 | Actual Loss: 0.1044\n",
      "Baseline Loss: 2.8391 | Actual Loss: 0.1614\n",
      "Baseline Loss: 2.8095 | Actual Loss: 0.1583\n",
      "Baseline Loss: 2.8089 | Actual Loss: 0.0744\n",
      "Baseline Loss: 2.5457 | Actual Loss: 0.0955\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1301\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4089\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2818\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2766\n",
      "Epoch 195/1000: Train Loss: 0.1784, Val Loss: 0.2744\n",
      "Baseline Loss: 2.8501 | Actual Loss: 0.2062\n",
      "Baseline Loss: 2.7942 | Actual Loss: 0.1523\n",
      "Baseline Loss: 2.8068 | Actual Loss: 0.1375\n",
      "Baseline Loss: 2.8281 | Actual Loss: 0.1580\n",
      "Baseline Loss: 2.8148 | Actual Loss: 0.1772\n",
      "Baseline Loss: 2.8030 | Actual Loss: 0.1196\n",
      "Baseline Loss: 2.8496 | Actual Loss: 0.1160\n",
      "Baseline Loss: 2.8464 | Actual Loss: 0.1551\n",
      "Baseline Loss: 2.9016 | Actual Loss: 0.1816\n",
      "Baseline Loss: 2.7871 | Actual Loss: 0.1703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 196/1000 [01:26<06:19,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8363 | Actual Loss: 0.1581\n",
      "Baseline Loss: 2.8378 | Actual Loss: 0.2686\n",
      "Baseline Loss: 2.7740 | Actual Loss: 0.3044\n",
      "Baseline Loss: 2.8335 | Actual Loss: 0.1575\n",
      "Baseline Loss: 2.8467 | Actual Loss: 0.1792\n",
      "Baseline Loss: 2.5671 | Actual Loss: 0.0306\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1639\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.5435\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2924\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.3159\n",
      "Epoch 196/1000: Train Loss: 0.1670, Val Loss: 0.3289\n",
      "Baseline Loss: 2.8309 | Actual Loss: 0.2452\n",
      "Baseline Loss: 2.7856 | Actual Loss: 0.1606\n",
      "Baseline Loss: 2.8208 | Actual Loss: 0.3669\n",
      "Baseline Loss: 2.7898 | Actual Loss: 0.1298\n",
      "Baseline Loss: 2.8376 | Actual Loss: 0.2334\n",
      "Baseline Loss: 2.7968 | Actual Loss: 0.1570\n",
      "Baseline Loss: 2.8893 | Actual Loss: 0.1379\n",
      "Baseline Loss: 2.8495 | Actual Loss: 0.1329\n",
      "Baseline Loss: 2.8238 | Actual Loss: 0.1784\n",
      "Baseline Loss: 2.8445 | Actual Loss: 0.2285\n",
      "Baseline Loss: 2.8432 | Actual Loss: 0.2298\n",
      "Baseline Loss: 2.8154 | Actual Loss: 0.1717\n",
      "Baseline Loss: 2.8000 | Actual Loss: 0.2077\n",
      "Baseline Loss: 2.7936 | Actual Loss: 0.2615\n",
      "Baseline Loss: 2.8446 | Actual Loss: 0.2007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 197/1000 [01:26<06:28,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5772 | Actual Loss: 0.0630\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1533\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4251\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3331\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2909\n",
      "Epoch 197/1000: Train Loss: 0.1941, Val Loss: 0.3006\n",
      "Baseline Loss: 2.8419 | Actual Loss: 0.2299\n",
      "Baseline Loss: 2.8275 | Actual Loss: 0.1744\n",
      "Baseline Loss: 2.9034 | Actual Loss: 0.2051\n",
      "Baseline Loss: 2.8058 | Actual Loss: 0.1389\n",
      "Baseline Loss: 2.8113 | Actual Loss: 0.2409\n",
      "Baseline Loss: 2.8375 | Actual Loss: 0.2226\n",
      "Baseline Loss: 2.7358 | Actual Loss: 0.1390\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.1001\n",
      "Baseline Loss: 2.8997 | Actual Loss: 0.1494\n",
      "Baseline Loss: 2.7917 | Actual Loss: 0.0853\n",
      "Baseline Loss: 2.7376 | Actual Loss: 0.0861\n",
      "Baseline Loss: 2.8067 | Actual Loss: 0.1187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 198/1000 [01:27<06:32,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8769 | Actual Loss: 1.0199\n",
      "Baseline Loss: 2.7942 | Actual Loss: 0.1122\n",
      "Baseline Loss: 2.8329 | Actual Loss: 0.1026\n",
      "Baseline Loss: 2.6594 | Actual Loss: 0.1433\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.2130\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4613\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3019\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2577\n",
      "Epoch 198/1000: Train Loss: 0.2043, Val Loss: 0.3085\n",
      "Baseline Loss: 2.8405 | Actual Loss: 0.3651\n",
      "Baseline Loss: 2.8044 | Actual Loss: 0.2086\n",
      "Baseline Loss: 2.8667 | Actual Loss: 0.1537\n",
      "Baseline Loss: 2.8742 | Actual Loss: 0.2860\n",
      "Baseline Loss: 2.8264 | Actual Loss: 0.2221\n",
      "Baseline Loss: 2.8387 | Actual Loss: 0.1257\n",
      "Baseline Loss: 2.8151 | Actual Loss: 0.1173\n",
      "Baseline Loss: 2.7976 | Actual Loss: 0.1318\n",
      "Baseline Loss: 2.7858 | Actual Loss: 0.1375\n",
      "Baseline Loss: 2.8476 | Actual Loss: 0.2145\n",
      "Baseline Loss: 2.8771 | Actual Loss: 0.1817\n",
      "Baseline Loss: 2.7417 | Actual Loss: 0.4417\n",
      "Baseline Loss: 2.8766 | Actual Loss: 0.1120\n",
      "Baseline Loss: 2.8314 | Actual Loss: 0.1417\n",
      "Baseline Loss: 2.8614 | Actual Loss: 0.1506\n",
      "Baseline Loss: 2.5711 | Actual Loss: 0.1063\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.1670\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4186\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.1925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 198/1000 [01:27<05:55,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7416 | Actual Loss: 0.3471\n",
      "Epoch 199/1000: Train Loss: 0.1935, Val Loss: 0.2813\n",
      "\n",
      "Early stopping at epoch 199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2414039522409439"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devices = [\"cuda\" if torch.cuda.is_available() else \"cpu\"]\n",
    "model4 = GNNModelWithNewLoss(\n",
    "        num_node_features=data_list[0].x.shape[1],\n",
    "        num_edge_features=data_list[0].edge_attr.shape[1],\n",
    "        num_global_features=0,\n",
    "        cov_num= 6,\n",
    "        hidden_dim=512,\n",
    "        dropout_rate=0.1,\n",
    "        property_index=0 ,\n",
    "        save_path= 'premodels_new_og/6/0' \n",
    "    ).to(devices[0])\n",
    "\n",
    "model4.train_model(\n",
    "    data_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea51dc95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training will be saved to: premodels_new_og/6/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6889 | Actual Loss: 2.6389\n",
      "Baseline Loss: 2.6833 | Actual Loss: 2.6203\n",
      "Baseline Loss: 2.6893 | Actual Loss: 2.5565\n",
      "Baseline Loss: 2.6581 | Actual Loss: 2.5377\n",
      "Baseline Loss: 2.6447 | Actual Loss: 2.4366\n",
      "Baseline Loss: 2.6380 | Actual Loss: 2.3702\n",
      "Baseline Loss: 2.6590 | Actual Loss: 2.4121\n",
      "Baseline Loss: 2.6675 | Actual Loss: 2.2729\n",
      "Baseline Loss: 2.6683 | Actual Loss: 2.1886\n",
      "Baseline Loss: 2.6885 | Actual Loss: 2.1612\n",
      "Baseline Loss: 2.6971 | Actual Loss: 2.1440\n",
      "Baseline Loss: 2.6953 | Actual Loss: 2.0283\n",
      "Baseline Loss: 2.6763 | Actual Loss: 1.9620\n",
      "Baseline Loss: 2.6656 | Actual Loss: 1.9330\n",
      "Baseline Loss: 2.6715 | Actual Loss: 2.1047\n",
      "Baseline Loss: 2.3053 | Actual Loss: 1.7543\n",
      "Baseline Loss: 2.6857 | Actual Loss: 1.8877\n",
      "Baseline Loss: 2.6990 | Actual Loss: 1.8621\n",
      "Baseline Loss: 2.6381 | Actual Loss: 1.7903\n",
      "Baseline Loss: 2.6194 | Actual Loss: 1.7319\n",
      "Epoch 1/1000: Train Loss: 2.2576, Val Loss: 1.8180\n",
      "New best validation loss: 1.8180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 1/1000 [00:00<07:27,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6602 | Actual Loss: 1.6694\n",
      "Baseline Loss: 2.6767 | Actual Loss: 1.7509\n",
      "Baseline Loss: 2.6927 | Actual Loss: 1.8507\n",
      "Baseline Loss: 2.6539 | Actual Loss: 1.6060\n",
      "Baseline Loss: 2.6926 | Actual Loss: 1.7824\n",
      "Baseline Loss: 2.6531 | Actual Loss: 1.8485\n",
      "Baseline Loss: 2.6620 | Actual Loss: 1.6460\n",
      "Baseline Loss: 2.6759 | Actual Loss: 1.7697\n",
      "Baseline Loss: 2.6832 | Actual Loss: 1.7426\n",
      "Baseline Loss: 2.6838 | Actual Loss: 1.6644\n",
      "Baseline Loss: 2.6595 | Actual Loss: 1.7429\n",
      "Baseline Loss: 2.6402 | Actual Loss: 1.7956\n",
      "Baseline Loss: 2.7008 | Actual Loss: 1.6844\n",
      "Baseline Loss: 2.7224 | Actual Loss: 1.8801\n",
      "Baseline Loss: 2.6612 | Actual Loss: 1.4655\n",
      "Baseline Loss: 2.2225 | Actual Loss: 1.4412\n",
      "Baseline Loss: 2.6857 | Actual Loss: 1.6459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 2/1000 [00:00<07:48,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6990 | Actual Loss: 1.7987\n",
      "Baseline Loss: 2.6381 | Actual Loss: 1.7227\n",
      "Baseline Loss: 2.6194 | Actual Loss: 1.5168\n",
      "Epoch 2/1000: Train Loss: 1.7088, Val Loss: 1.6710\n",
      "New best validation loss: 1.6710\n",
      "Baseline Loss: 2.6829 | Actual Loss: 1.6967\n",
      "Baseline Loss: 2.6662 | Actual Loss: 1.5971\n",
      "Baseline Loss: 2.6361 | Actual Loss: 1.6258\n",
      "Baseline Loss: 2.6587 | Actual Loss: 1.7623\n",
      "Baseline Loss: 2.6937 | Actual Loss: 1.6703\n",
      "Baseline Loss: 2.6727 | Actual Loss: 1.5913\n",
      "Baseline Loss: 2.6792 | Actual Loss: 1.5508\n",
      "Baseline Loss: 2.6407 | Actual Loss: 1.6794\n",
      "Baseline Loss: 2.6503 | Actual Loss: 1.6634\n",
      "Baseline Loss: 2.6669 | Actual Loss: 1.6693\n",
      "Baseline Loss: 2.6834 | Actual Loss: 1.3665\n",
      "Baseline Loss: 2.6688 | Actual Loss: 1.5095\n",
      "Baseline Loss: 2.7119 | Actual Loss: 1.8114\n",
      "Baseline Loss: 2.6557 | Actual Loss: 1.4753\n",
      "Baseline Loss: 2.6885 | Actual Loss: 1.6163\n",
      "Baseline Loss: 2.3734 | Actual Loss: 1.4066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 3/1000 [00:01<07:37,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6857 | Actual Loss: 1.6396\n",
      "Baseline Loss: 2.6990 | Actual Loss: 1.5877\n",
      "Baseline Loss: 2.6381 | Actual Loss: 1.4880\n",
      "Baseline Loss: 2.6194 | Actual Loss: 1.3742\n",
      "Epoch 3/1000: Train Loss: 1.6058, Val Loss: 1.5224\n",
      "New best validation loss: 1.5224\n",
      "Baseline Loss: 2.6693 | Actual Loss: 1.5708\n",
      "Baseline Loss: 2.7058 | Actual Loss: 1.7648\n",
      "Baseline Loss: 2.6438 | Actual Loss: 1.3519\n",
      "Baseline Loss: 2.6674 | Actual Loss: 1.5762\n",
      "Baseline Loss: 2.6947 | Actual Loss: 1.3976\n",
      "Baseline Loss: 2.6558 | Actual Loss: 1.2168\n",
      "Baseline Loss: 2.6796 | Actual Loss: 1.2420\n",
      "Baseline Loss: 2.6525 | Actual Loss: 1.4777\n",
      "Baseline Loss: 2.6447 | Actual Loss: 1.4898\n",
      "Baseline Loss: 2.7248 | Actual Loss: 1.4507\n",
      "Baseline Loss: 2.6661 | Actual Loss: 1.6459\n",
      "Baseline Loss: 2.6484 | Actual Loss: 1.4048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 4/1000 [00:01<08:01,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6775 | Actual Loss: 1.4774\n",
      "Baseline Loss: 2.6907 | Actual Loss: 1.5417\n",
      "Baseline Loss: 2.6954 | Actual Loss: 1.3491\n",
      "Baseline Loss: 2.3062 | Actual Loss: 0.9197\n",
      "Baseline Loss: 2.6857 | Actual Loss: 1.6014\n",
      "Baseline Loss: 2.6990 | Actual Loss: 1.5360\n",
      "Baseline Loss: 2.6381 | Actual Loss: 1.6022\n",
      "Baseline Loss: 2.6194 | Actual Loss: 1.4299\n",
      "Epoch 4/1000: Train Loss: 1.4298, Val Loss: 1.5424\n",
      "Baseline Loss: 2.6877 | Actual Loss: 1.2463\n",
      "Baseline Loss: 2.6679 | Actual Loss: 1.3175\n",
      "Baseline Loss: 2.7050 | Actual Loss: 1.2483\n",
      "Baseline Loss: 2.6552 | Actual Loss: 1.3561\n",
      "Baseline Loss: 2.6861 | Actual Loss: 1.3395\n",
      "Baseline Loss: 2.6416 | Actual Loss: 1.2506\n",
      "Baseline Loss: 2.6521 | Actual Loss: 1.6162\n",
      "Baseline Loss: 2.6855 | Actual Loss: 1.5040\n",
      "Baseline Loss: 2.6878 | Actual Loss: 1.3152\n",
      "Baseline Loss: 2.6888 | Actual Loss: 1.3182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 5/1000 [00:02<08:16,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6518 | Actual Loss: 1.2689\n",
      "Baseline Loss: 2.6592 | Actual Loss: 1.2445\n",
      "Baseline Loss: 2.6556 | Actual Loss: 0.9621\n",
      "Baseline Loss: 2.6667 | Actual Loss: 1.3712\n",
      "Baseline Loss: 2.6806 | Actual Loss: 1.1559\n",
      "Baseline Loss: 2.2750 | Actual Loss: 0.8317\n",
      "Baseline Loss: 2.6857 | Actual Loss: 1.1172\n",
      "Baseline Loss: 2.6990 | Actual Loss: 1.1037\n",
      "Baseline Loss: 2.6381 | Actual Loss: 1.2744\n",
      "Baseline Loss: 2.6194 | Actual Loss: 1.2618\n",
      "Epoch 5/1000: Train Loss: 1.2716, Val Loss: 1.1893\n",
      "New best validation loss: 1.1893\n",
      "Baseline Loss: 2.7388 | Actual Loss: 1.3361\n",
      "Baseline Loss: 2.7158 | Actual Loss: 1.3389\n",
      "Baseline Loss: 2.6276 | Actual Loss: 1.2430\n",
      "Baseline Loss: 2.6903 | Actual Loss: 1.2515\n",
      "Baseline Loss: 2.6634 | Actual Loss: 1.4428\n",
      "Baseline Loss: 2.6966 | Actual Loss: 1.1084\n",
      "Baseline Loss: 2.6810 | Actual Loss: 1.0738\n",
      "Baseline Loss: 2.6549 | Actual Loss: 0.9999\n",
      "Baseline Loss: 2.6641 | Actual Loss: 1.0400\n",
      "Baseline Loss: 2.6654 | Actual Loss: 1.1551\n",
      "Baseline Loss: 2.6717 | Actual Loss: 1.2091\n",
      "Baseline Loss: 2.6876 | Actual Loss: 1.0107\n",
      "Baseline Loss: 2.6654 | Actual Loss: 0.8435\n",
      "Baseline Loss: 2.6381 | Actual Loss: 1.0300\n",
      "Baseline Loss: 2.6826 | Actual Loss: 1.1090\n",
      "Baseline Loss: 2.2629 | Actual Loss: 0.6879\n",
      "Baseline Loss: 2.6857 | Actual Loss: 1.0323\n",
      "Baseline Loss: 2.6990 | Actual Loss: 1.0339\n",
      "Baseline Loss: 2.6381 | Actual Loss: 1.1859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 6/1000 [00:02<07:59,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6194 | Actual Loss: 1.2397\n",
      "Epoch 6/1000: Train Loss: 1.1175, Val Loss: 1.1230\n",
      "New best validation loss: 1.1230\n",
      "Baseline Loss: 2.7037 | Actual Loss: 1.1996\n",
      "Baseline Loss: 2.6821 | Actual Loss: 1.0014\n",
      "Baseline Loss: 2.6733 | Actual Loss: 0.9395\n",
      "Baseline Loss: 2.6763 | Actual Loss: 1.0956\n",
      "Baseline Loss: 2.6832 | Actual Loss: 0.9963\n",
      "Baseline Loss: 2.6401 | Actual Loss: 1.1159\n",
      "Baseline Loss: 2.6699 | Actual Loss: 1.1000\n",
      "Baseline Loss: 2.6918 | Actual Loss: 1.0282\n",
      "Baseline Loss: 2.6751 | Actual Loss: 0.7678\n",
      "Baseline Loss: 2.6970 | Actual Loss: 0.8680\n",
      "Baseline Loss: 2.6693 | Actual Loss: 0.9009\n",
      "Baseline Loss: 2.6554 | Actual Loss: 0.9518\n",
      "Baseline Loss: 2.6769 | Actual Loss: 0.7590\n",
      "Baseline Loss: 2.7011 | Actual Loss: 0.9189\n",
      "Baseline Loss: 2.6577 | Actual Loss: 0.8030\n",
      "Baseline Loss: 2.2375 | Actual Loss: 0.5586\n",
      "Baseline Loss: 2.6857 | Actual Loss: 1.0118\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.8370\n",
      "Baseline Loss: 2.6381 | Actual Loss: 1.2137\n",
      "Baseline Loss: 2.6194 | Actual Loss: 1.0409\n",
      "Epoch 7/1000: Train Loss: 0.9378, Val Loss: 1.0258\n",
      "New best validation loss: 1.0258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 7/1000 [00:03<07:59,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6832 | Actual Loss: 0.7934\n",
      "Baseline Loss: 2.6887 | Actual Loss: 0.9731\n",
      "Baseline Loss: 2.6560 | Actual Loss: 0.9664\n",
      "Baseline Loss: 2.6766 | Actual Loss: 0.9723\n",
      "Baseline Loss: 2.7044 | Actual Loss: 0.8420\n",
      "Baseline Loss: 2.6739 | Actual Loss: 1.0163\n",
      "Baseline Loss: 2.6897 | Actual Loss: 1.2024\n",
      "Baseline Loss: 2.6544 | Actual Loss: 0.9062\n",
      "Baseline Loss: 2.7113 | Actual Loss: 1.3817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 8/1000 [00:03<07:38,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6511 | Actual Loss: 0.8917\n",
      "Baseline Loss: 2.6500 | Actual Loss: 0.8819\n",
      "Baseline Loss: 2.6596 | Actual Loss: 0.6918\n",
      "Baseline Loss: 2.6737 | Actual Loss: 0.9725\n",
      "Baseline Loss: 2.6967 | Actual Loss: 1.0605\n",
      "Baseline Loss: 2.6801 | Actual Loss: 0.9416\n",
      "Baseline Loss: 2.2821 | Actual Loss: 0.6402\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.9630\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.8949\n",
      "Baseline Loss: 2.6381 | Actual Loss: 1.0270\n",
      "Baseline Loss: 2.6194 | Actual Loss: 1.0085\n",
      "Epoch 8/1000: Train Loss: 0.9459, Val Loss: 0.9734\n",
      "New best validation loss: 0.9734\n",
      "Baseline Loss: 2.6557 | Actual Loss: 0.9215\n",
      "Baseline Loss: 2.6353 | Actual Loss: 0.7311\n",
      "Baseline Loss: 2.7001 | Actual Loss: 0.7913\n",
      "Baseline Loss: 2.6709 | Actual Loss: 0.6642\n",
      "Baseline Loss: 2.6985 | Actual Loss: 0.7223\n",
      "Baseline Loss: 2.6619 | Actual Loss: 0.9909\n",
      "Baseline Loss: 2.7197 | Actual Loss: 1.0166\n",
      "Baseline Loss: 2.6920 | Actual Loss: 0.8173\n",
      "Baseline Loss: 2.6855 | Actual Loss: 0.8676\n",
      "Baseline Loss: 2.6731 | Actual Loss: 0.9329\n",
      "Baseline Loss: 2.6517 | Actual Loss: 0.7868\n",
      "Baseline Loss: 2.6856 | Actual Loss: 0.6990\n",
      "Baseline Loss: 2.6531 | Actual Loss: 1.1356\n",
      "Baseline Loss: 2.6799 | Actual Loss: 0.8590\n",
      "Baseline Loss: 2.6762 | Actual Loss: 1.0064\n",
      "Baseline Loss: 2.2478 | Actual Loss: 0.9735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 9/1000 [00:04<07:50,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6857 | Actual Loss: 1.1405\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.9591\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.9442\n",
      "Baseline Loss: 2.6194 | Actual Loss: 1.1023\n",
      "Epoch 9/1000: Train Loss: 0.8697, Val Loss: 1.0365\n",
      "Baseline Loss: 2.7146 | Actual Loss: 0.9216\n",
      "Baseline Loss: 2.6299 | Actual Loss: 0.7286\n",
      "Baseline Loss: 2.6608 | Actual Loss: 0.8520\n",
      "Baseline Loss: 2.6715 | Actual Loss: 1.0289\n",
      "Baseline Loss: 2.6814 | Actual Loss: 0.7884\n",
      "Baseline Loss: 2.6886 | Actual Loss: 0.6880\n",
      "Baseline Loss: 2.7388 | Actual Loss: 0.7267\n",
      "Baseline Loss: 2.6695 | Actual Loss: 0.9323\n",
      "Baseline Loss: 2.6779 | Actual Loss: 0.8698\n",
      "Baseline Loss: 2.6397 | Actual Loss: 0.8322\n",
      "Baseline Loss: 2.6959 | Actual Loss: 0.9694\n",
      "Baseline Loss: 2.6545 | Actual Loss: 0.7638\n",
      "Baseline Loss: 2.6890 | Actual Loss: 0.8996\n",
      "Baseline Loss: 2.6659 | Actual Loss: 1.1686\n",
      "Baseline Loss: 2.6405 | Actual Loss: 1.0453\n",
      "Baseline Loss: 2.2744 | Actual Loss: 0.5531\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.7872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 10/1000 [00:04<07:58,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6990 | Actual Loss: 1.0395\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.8558\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.9244\n",
      "Epoch 10/1000: Train Loss: 0.8605, Val Loss: 0.9017\n",
      "New best validation loss: 0.9017\n",
      "Baseline Loss: 2.6787 | Actual Loss: 0.9025\n",
      "Baseline Loss: 2.6781 | Actual Loss: 0.8060\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.7987\n",
      "Baseline Loss: 2.6773 | Actual Loss: 1.0102\n",
      "Baseline Loss: 2.6909 | Actual Loss: 0.8354\n",
      "Baseline Loss: 2.7336 | Actual Loss: 0.6984\n",
      "Baseline Loss: 2.7014 | Actual Loss: 0.8873\n",
      "Baseline Loss: 2.6845 | Actual Loss: 1.1519\n",
      "Baseline Loss: 2.6749 | Actual Loss: 0.7423\n",
      "Baseline Loss: 2.6658 | Actual Loss: 0.9205\n",
      "Baseline Loss: 2.6580 | Actual Loss: 1.1201\n",
      "Baseline Loss: 2.6485 | Actual Loss: 0.8927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 11/1000 [00:05<07:38,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6522 | Actual Loss: 0.8797\n",
      "Baseline Loss: 2.6609 | Actual Loss: 0.7751\n",
      "Baseline Loss: 2.6901 | Actual Loss: 0.8092\n",
      "Baseline Loss: 2.3325 | Actual Loss: 0.7337\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.9693\n",
      "Baseline Loss: 2.6990 | Actual Loss: 1.0901\n",
      "Baseline Loss: 2.6381 | Actual Loss: 1.1114\n",
      "Baseline Loss: 2.6194 | Actual Loss: 1.0745\n",
      "Epoch 11/1000: Train Loss: 0.8727, Val Loss: 1.0613\n",
      "Baseline Loss: 2.6780 | Actual Loss: 1.1161\n",
      "Baseline Loss: 2.6672 | Actual Loss: 1.0416\n",
      "Baseline Loss: 2.6813 | Actual Loss: 0.8370\n",
      "Baseline Loss: 2.6634 | Actual Loss: 0.9828\n",
      "Baseline Loss: 2.7008 | Actual Loss: 0.8002\n",
      "Baseline Loss: 2.6811 | Actual Loss: 0.7044\n",
      "Baseline Loss: 2.6470 | Actual Loss: 0.8561\n",
      "Baseline Loss: 2.6994 | Actual Loss: 0.8883\n",
      "Baseline Loss: 2.6588 | Actual Loss: 0.7933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 12/1000 [00:05<07:49,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6708 | Actual Loss: 0.5927\n",
      "Baseline Loss: 2.6777 | Actual Loss: 0.8408\n",
      "Baseline Loss: 2.6578 | Actual Loss: 0.8980\n",
      "Baseline Loss: 2.6726 | Actual Loss: 0.9167\n",
      "Baseline Loss: 2.6784 | Actual Loss: 0.9099\n",
      "Baseline Loss: 2.6779 | Actual Loss: 0.9538\n",
      "Baseline Loss: 2.2187 | Actual Loss: 0.5396\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.8474\n",
      "Baseline Loss: 2.6990 | Actual Loss: 1.0693\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.8975\n",
      "Baseline Loss: 2.6194 | Actual Loss: 1.0215\n",
      "Epoch 12/1000: Train Loss: 0.8545, Val Loss: 0.9589\n",
      "Baseline Loss: 2.7009 | Actual Loss: 0.7944\n",
      "Baseline Loss: 2.6447 | Actual Loss: 0.6980\n",
      "Baseline Loss: 2.6432 | Actual Loss: 0.5723\n",
      "Baseline Loss: 2.6520 | Actual Loss: 0.7213\n",
      "Baseline Loss: 2.6941 | Actual Loss: 0.7810\n",
      "Baseline Loss: 2.6928 | Actual Loss: 0.7207\n",
      "Baseline Loss: 2.7222 | Actual Loss: 0.6882\n",
      "Baseline Loss: 2.6982 | Actual Loss: 0.9065\n",
      "Baseline Loss: 2.7225 | Actual Loss: 0.9127\n",
      "Baseline Loss: 2.6629 | Actual Loss: 0.8119\n",
      "Baseline Loss: 2.6668 | Actual Loss: 0.7691\n",
      "Baseline Loss: 2.6698 | Actual Loss: 0.7208\n",
      "Baseline Loss: 2.6561 | Actual Loss: 0.9246\n",
      "Baseline Loss: 2.6707 | Actual Loss: 0.5055\n",
      "Baseline Loss: 2.6807 | Actual Loss: 0.4588\n",
      "Baseline Loss: 2.2756 | Actual Loss: 0.5946\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.7169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏         | 13/1000 [00:06<07:56,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6990 | Actual Loss: 0.8280\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.7848\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.7772\n",
      "Epoch 13/1000: Train Loss: 0.7238, Val Loss: 0.7767\n",
      "New best validation loss: 0.7767\n",
      "Baseline Loss: 2.6807 | Actual Loss: 1.0562\n",
      "Baseline Loss: 2.6802 | Actual Loss: 0.7949\n",
      "Baseline Loss: 2.6737 | Actual Loss: 0.5945\n",
      "Baseline Loss: 2.6442 | Actual Loss: 0.5640\n",
      "Baseline Loss: 2.6688 | Actual Loss: 0.7140\n",
      "Baseline Loss: 2.6756 | Actual Loss: 0.5526\n",
      "Baseline Loss: 2.6687 | Actual Loss: 0.5931\n",
      "Baseline Loss: 2.6551 | Actual Loss: 0.7306\n",
      "Baseline Loss: 2.6787 | Actual Loss: 0.6779\n",
      "Baseline Loss: 2.7164 | Actual Loss: 0.6360\n",
      "Baseline Loss: 2.6734 | Actual Loss: 0.8236\n",
      "Baseline Loss: 2.6401 | Actual Loss: 0.8168\n",
      "Baseline Loss: 2.6941 | Actual Loss: 0.8244\n",
      "Baseline Loss: 2.6504 | Actual Loss: 0.5373\n",
      "Baseline Loss: 2.6656 | Actual Loss: 0.8130\n",
      "Baseline Loss: 2.3880 | Actual Loss: 0.5408\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.7248\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.8026\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.7499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏         | 14/1000 [00:06<07:29,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6194 | Actual Loss: 0.8733\n",
      "Epoch 14/1000: Train Loss: 0.7044, Val Loss: 0.7876\n",
      "Baseline Loss: 2.6606 | Actual Loss: 0.7195\n",
      "Baseline Loss: 2.6625 | Actual Loss: 0.8962\n",
      "Baseline Loss: 2.7020 | Actual Loss: 0.5729\n",
      "Baseline Loss: 2.6672 | Actual Loss: 0.7971\n",
      "Baseline Loss: 2.6781 | Actual Loss: 0.7317\n",
      "Baseline Loss: 2.6687 | Actual Loss: 0.6988\n",
      "Baseline Loss: 2.6697 | Actual Loss: 0.5255\n",
      "Baseline Loss: 2.6791 | Actual Loss: 0.6195\n",
      "Baseline Loss: 2.6850 | Actual Loss: 0.5785\n",
      "Baseline Loss: 2.6478 | Actual Loss: 0.5468\n",
      "Baseline Loss: 2.6748 | Actual Loss: 0.6258\n",
      "Baseline Loss: 2.7161 | Actual Loss: 0.5571\n",
      "Baseline Loss: 2.6996 | Actual Loss: 0.5566\n",
      "Baseline Loss: 2.6488 | Actual Loss: 0.5580\n",
      "Baseline Loss: 2.6930 | Actual Loss: 0.7309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 15/1000 [00:07<07:40,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2622 | Actual Loss: 0.6171\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.7187\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.8581\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.7444\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.8290\n",
      "Epoch 15/1000: Train Loss: 0.6457, Val Loss: 0.7875\n",
      "Baseline Loss: 2.6611 | Actual Loss: 0.7941\n",
      "Baseline Loss: 2.6905 | Actual Loss: 0.8016\n",
      "Baseline Loss: 2.6653 | Actual Loss: 0.6926\n",
      "Baseline Loss: 2.6809 | Actual Loss: 0.4975\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5329\n",
      "Baseline Loss: 2.6850 | Actual Loss: 0.8451\n",
      "Baseline Loss: 2.6660 | Actual Loss: 0.6231\n",
      "Baseline Loss: 2.6359 | Actual Loss: 0.6102\n",
      "Baseline Loss: 2.7079 | Actual Loss: 0.5770\n",
      "Baseline Loss: 2.6637 | Actual Loss: 0.4719\n",
      "Baseline Loss: 2.6851 | Actual Loss: 0.7055\n",
      "Baseline Loss: 2.6315 | Actual Loss: 0.8375\n",
      "Baseline Loss: 2.6820 | Actual Loss: 0.6121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 16/1000 [00:07<07:42,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6931 | Actual Loss: 0.6277\n",
      "Baseline Loss: 2.6555 | Actual Loss: 0.6535\n",
      "Baseline Loss: 2.2698 | Actual Loss: 0.4916\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.9404\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.8444\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.6752\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.7321\n",
      "Epoch 16/1000: Train Loss: 0.6484, Val Loss: 0.7980\n",
      "Baseline Loss: 2.6863 | Actual Loss: 0.6541\n",
      "Baseline Loss: 2.6797 | Actual Loss: 0.4979\n",
      "Baseline Loss: 2.6597 | Actual Loss: 0.6843\n",
      "Baseline Loss: 2.6830 | Actual Loss: 0.5748\n",
      "Baseline Loss: 2.6855 | Actual Loss: 0.6575\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.8877\n",
      "Baseline Loss: 2.6954 | Actual Loss: 0.6796\n",
      "Baseline Loss: 2.6891 | Actual Loss: 0.6632\n",
      "Baseline Loss: 2.6559 | Actual Loss: 0.7444\n",
      "Baseline Loss: 2.7154 | Actual Loss: 0.6275\n",
      "Baseline Loss: 2.6546 | Actual Loss: 0.5467\n",
      "Baseline Loss: 2.6641 | Actual Loss: 0.6542\n",
      "Baseline Loss: 2.6713 | Actual Loss: 0.6825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 17/1000 [00:08<07:35,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6919 | Actual Loss: 0.5769\n",
      "Baseline Loss: 2.6440 | Actual Loss: 0.7192\n",
      "Baseline Loss: 2.2119 | Actual Loss: 0.2849\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.8210\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.7516\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.6830\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.7260\n",
      "Epoch 17/1000: Train Loss: 0.6334, Val Loss: 0.7454\n",
      "New best validation loss: 0.7454\n",
      "Baseline Loss: 2.6695 | Actual Loss: 0.6508\n",
      "Baseline Loss: 2.6516 | Actual Loss: 0.9326\n",
      "Baseline Loss: 2.6616 | Actual Loss: 0.4528\n",
      "Baseline Loss: 2.6982 | Actual Loss: 0.5999\n",
      "Baseline Loss: 2.6966 | Actual Loss: 0.6269\n",
      "Baseline Loss: 2.6707 | Actual Loss: 0.6333\n",
      "Baseline Loss: 2.6576 | Actual Loss: 0.7958\n",
      "Baseline Loss: 2.6862 | Actual Loss: 0.6715\n",
      "Baseline Loss: 2.7027 | Actual Loss: 0.4949\n",
      "Baseline Loss: 2.6694 | Actual Loss: 0.3571\n",
      "Baseline Loss: 2.6771 | Actual Loss: 0.6886\n",
      "Baseline Loss: 2.6455 | Actual Loss: 0.4355\n",
      "Baseline Loss: 2.6586 | Actual Loss: 0.8195\n",
      "Baseline Loss: 2.6775 | Actual Loss: 0.8069\n",
      "Baseline Loss: 2.6786 | Actual Loss: 0.5925\n",
      "Baseline Loss: 2.2690 | Actual Loss: 0.4041\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.6768\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.7036\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.6742\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.7854\n",
      "Epoch 18/1000: Train Loss: 0.6227, Val Loss: 0.7100\n",
      "New best validation loss: 0.7100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 18/1000 [00:08<07:49,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6456 | Actual Loss: 0.6238\n",
      "Baseline Loss: 2.6562 | Actual Loss: 0.8740\n",
      "Baseline Loss: 2.6955 | Actual Loss: 0.5093\n",
      "Baseline Loss: 2.6733 | Actual Loss: 0.6693\n",
      "Baseline Loss: 2.6552 | Actual Loss: 0.9011\n",
      "Baseline Loss: 2.7038 | Actual Loss: 0.3341\n",
      "Baseline Loss: 2.7096 | Actual Loss: 0.4830\n",
      "Baseline Loss: 2.6774 | Actual Loss: 0.7285\n",
      "Baseline Loss: 2.7120 | Actual Loss: 0.3949\n",
      "Baseline Loss: 2.6633 | Actual Loss: 0.8027\n",
      "Baseline Loss: 2.6664 | Actual Loss: 0.7713\n",
      "Baseline Loss: 2.6587 | Actual Loss: 0.5729\n",
      "Baseline Loss: 2.6591 | Actual Loss: 0.5130\n",
      "Baseline Loss: 2.7226 | Actual Loss: 0.7327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 19/1000 [00:09<08:01,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6768 | Actual Loss: 0.5281\n",
      "Baseline Loss: 2.2283 | Actual Loss: 0.5211\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.6638\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.7269\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.6972\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.7057\n",
      "Epoch 19/1000: Train Loss: 0.6225, Val Loss: 0.6984\n",
      "New best validation loss: 0.6984\n",
      "Baseline Loss: 2.6718 | Actual Loss: 0.5380\n",
      "Baseline Loss: 2.6611 | Actual Loss: 0.7861\n",
      "Baseline Loss: 2.7031 | Actual Loss: 0.7715\n",
      "Baseline Loss: 2.6993 | Actual Loss: 0.6011\n",
      "Baseline Loss: 2.6479 | Actual Loss: 0.5008\n",
      "Baseline Loss: 2.6186 | Actual Loss: 0.6094\n",
      "Baseline Loss: 2.6445 | Actual Loss: 0.4947\n",
      "Baseline Loss: 2.7145 | Actual Loss: 0.4995\n",
      "Baseline Loss: 2.6707 | Actual Loss: 0.6088\n",
      "Baseline Loss: 2.7128 | Actual Loss: 0.5938\n",
      "Baseline Loss: 2.6868 | Actual Loss: 0.5490\n",
      "Baseline Loss: 2.6932 | Actual Loss: 0.6804\n",
      "Baseline Loss: 2.6612 | Actual Loss: 0.3446\n",
      "Baseline Loss: 2.6598 | Actual Loss: 0.6791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 20/1000 [00:09<07:45,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6571 | Actual Loss: 0.4779\n",
      "Baseline Loss: 2.2425 | Actual Loss: 0.3201\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.7209\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.9207\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.6064\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.8117\n",
      "Epoch 20/1000: Train Loss: 0.5659, Val Loss: 0.7649\n",
      "Baseline Loss: 2.6980 | Actual Loss: 0.6124\n",
      "Baseline Loss: 2.7424 | Actual Loss: 0.4292\n",
      "Baseline Loss: 2.6829 | Actual Loss: 0.8701\n",
      "Baseline Loss: 2.6859 | Actual Loss: 0.5576\n",
      "Baseline Loss: 2.6792 | Actual Loss: 0.4624\n",
      "Baseline Loss: 2.6761 | Actual Loss: 0.6335\n",
      "Baseline Loss: 2.6696 | Actual Loss: 0.4998\n",
      "Baseline Loss: 2.6851 | Actual Loss: 0.8401\n",
      "Baseline Loss: 2.6794 | Actual Loss: 0.4609\n",
      "Baseline Loss: 2.6658 | Actual Loss: 0.4771\n",
      "Baseline Loss: 2.6548 | Actual Loss: 0.4390\n",
      "Baseline Loss: 2.6637 | Actual Loss: 0.6485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 21/1000 [00:10<08:00,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6439 | Actual Loss: 0.7060\n",
      "Baseline Loss: 2.6987 | Actual Loss: 0.2886\n",
      "Baseline Loss: 2.6493 | Actual Loss: 0.5923\n",
      "Baseline Loss: 2.2443 | Actual Loss: 0.1932\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.6676\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.7336\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.7181\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.8122\n",
      "Epoch 21/1000: Train Loss: 0.5444, Val Loss: 0.7329\n",
      "Baseline Loss: 2.6610 | Actual Loss: 0.7016\n",
      "Baseline Loss: 2.6634 | Actual Loss: 0.6506\n",
      "Baseline Loss: 2.6570 | Actual Loss: 0.6981\n",
      "Baseline Loss: 2.6359 | Actual Loss: 0.5848\n",
      "Baseline Loss: 2.6768 | Actual Loss: 0.4423\n",
      "Baseline Loss: 2.7025 | Actual Loss: 0.4182\n",
      "Baseline Loss: 2.7127 | Actual Loss: 0.3861\n",
      "Baseline Loss: 2.6629 | Actual Loss: 0.5883\n",
      "Baseline Loss: 2.6874 | Actual Loss: 0.7818\n",
      "Baseline Loss: 2.6714 | Actual Loss: 0.6506\n",
      "Baseline Loss: 2.6790 | Actual Loss: 0.4751\n",
      "Baseline Loss: 2.6443 | Actual Loss: 0.6211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 22/1000 [00:10<08:05,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6529 | Actual Loss: 0.5124\n",
      "Baseline Loss: 2.6481 | Actual Loss: 0.4815\n",
      "Baseline Loss: 2.6997 | Actual Loss: 0.4723\n",
      "Baseline Loss: 2.2806 | Actual Loss: 0.5024\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5954\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.7194\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.6810\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.8103\n",
      "Epoch 22/1000: Train Loss: 0.5604, Val Loss: 0.7015\n",
      "Baseline Loss: 2.7007 | Actual Loss: 0.5665\n",
      "Baseline Loss: 2.6673 | Actual Loss: 0.6162\n",
      "Baseline Loss: 2.6633 | Actual Loss: 0.4915\n",
      "Baseline Loss: 2.6879 | Actual Loss: 0.5008\n",
      "Baseline Loss: 2.6893 | Actual Loss: 1.1965\n",
      "Baseline Loss: 2.6454 | Actual Loss: 0.4055\n",
      "Baseline Loss: 2.6540 | Actual Loss: 0.3599\n",
      "Baseline Loss: 2.6977 | Actual Loss: 0.3442\n",
      "Baseline Loss: 2.6408 | Actual Loss: 0.3992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 23/1000 [00:10<07:45,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6861 | Actual Loss: 0.4376\n",
      "Baseline Loss: 2.6687 | Actual Loss: 0.6199\n",
      "Baseline Loss: 2.6622 | Actual Loss: 0.4882\n",
      "Baseline Loss: 2.6923 | Actual Loss: 0.6155\n",
      "Baseline Loss: 2.6983 | Actual Loss: 0.6268\n",
      "Baseline Loss: 2.7078 | Actual Loss: 0.7461\n",
      "Baseline Loss: 2.3156 | Actual Loss: 0.5017\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.7782\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.8427\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.8101\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.9418\n",
      "Epoch 23/1000: Train Loss: 0.5573, Val Loss: 0.8432\n",
      "Baseline Loss: 2.7082 | Actual Loss: 0.5313\n",
      "Baseline Loss: 2.6721 | Actual Loss: 0.6737\n",
      "Baseline Loss: 2.6843 | Actual Loss: 0.6077\n",
      "Baseline Loss: 2.6845 | Actual Loss: 0.3561\n",
      "Baseline Loss: 2.6654 | Actual Loss: 0.7382\n",
      "Baseline Loss: 2.6891 | Actual Loss: 0.4989\n",
      "Baseline Loss: 2.6603 | Actual Loss: 0.5252\n",
      "Baseline Loss: 2.6563 | Actual Loss: 0.5940\n",
      "Baseline Loss: 2.6810 | Actual Loss: 0.4565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 24/1000 [00:11<07:50,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6622 | Actual Loss: 0.8795\n",
      "Baseline Loss: 2.6672 | Actual Loss: 0.5013\n",
      "Baseline Loss: 2.6961 | Actual Loss: 0.7473\n",
      "Baseline Loss: 2.6035 | Actual Loss: 0.7294\n",
      "Baseline Loss: 2.6897 | Actual Loss: 0.7935\n",
      "Baseline Loss: 2.6879 | Actual Loss: 0.4452\n",
      "Baseline Loss: 2.1939 | Actual Loss: 0.3658\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.7041\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.7970\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.6676\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.8206\n",
      "Epoch 24/1000: Train Loss: 0.5902, Val Loss: 0.7473\n",
      "Baseline Loss: 2.6790 | Actual Loss: 0.8617\n",
      "Baseline Loss: 2.7018 | Actual Loss: 0.4935\n",
      "Baseline Loss: 2.6616 | Actual Loss: 0.6382\n",
      "Baseline Loss: 2.6356 | Actual Loss: 0.7266\n",
      "Baseline Loss: 2.6487 | Actual Loss: 0.6080\n",
      "Baseline Loss: 2.6577 | Actual Loss: 0.5889\n",
      "Baseline Loss: 2.6829 | Actual Loss: 0.4105\n",
      "Baseline Loss: 2.6624 | Actual Loss: 0.6033\n",
      "Baseline Loss: 2.6912 | Actual Loss: 0.4262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▎         | 25/1000 [00:11<07:37,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7078 | Actual Loss: 0.6849\n",
      "Baseline Loss: 2.6595 | Actual Loss: 0.4516\n",
      "Baseline Loss: 2.6766 | Actual Loss: 0.3652\n",
      "Baseline Loss: 2.6806 | Actual Loss: 0.6068\n",
      "Baseline Loss: 2.6820 | Actual Loss: 0.5310\n",
      "Baseline Loss: 2.6595 | Actual Loss: 0.9576\n",
      "Baseline Loss: 2.2910 | Actual Loss: 0.2925\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.6731\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.8169\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.5656\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.7648\n",
      "Epoch 25/1000: Train Loss: 0.5779, Val Loss: 0.7051\n",
      "Baseline Loss: 2.6560 | Actual Loss: 0.6647\n",
      "Baseline Loss: 2.7008 | Actual Loss: 0.4656\n",
      "Baseline Loss: 2.6347 | Actual Loss: 0.4720\n",
      "Baseline Loss: 2.6683 | Actual Loss: 0.6739\n",
      "Baseline Loss: 2.6563 | Actual Loss: 0.5204\n",
      "Baseline Loss: 2.6956 | Actual Loss: 0.5953\n",
      "Baseline Loss: 2.6747 | Actual Loss: 0.5430\n",
      "Baseline Loss: 2.6763 | Actual Loss: 0.5277\n",
      "Baseline Loss: 2.7109 | Actual Loss: 0.4548\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.6845\n",
      "Baseline Loss: 2.6730 | Actual Loss: 0.4463\n",
      "Baseline Loss: 2.6550 | Actual Loss: 0.3613\n",
      "Baseline Loss: 2.6954 | Actual Loss: 0.5750\n",
      "Baseline Loss: 2.6628 | Actual Loss: 0.6267\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5952\n",
      "Baseline Loss: 2.2467 | Actual Loss: 0.2527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 26/1000 [00:12<07:41,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6857 | Actual Loss: 0.7698\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.7342\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.5869\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.6720\n",
      "Epoch 26/1000: Train Loss: 0.5287, Val Loss: 0.6907\n",
      "New best validation loss: 0.6907\n",
      "Baseline Loss: 2.6892 | Actual Loss: 0.2763\n",
      "Baseline Loss: 2.6852 | Actual Loss: 0.9356\n",
      "Baseline Loss: 2.6142 | Actual Loss: 0.5704\n",
      "Baseline Loss: 2.6787 | Actual Loss: 0.3920\n",
      "Baseline Loss: 2.6725 | Actual Loss: 0.4648\n",
      "Baseline Loss: 2.6607 | Actual Loss: 0.3456\n",
      "Baseline Loss: 2.6727 | Actual Loss: 0.3668\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.7572\n",
      "Baseline Loss: 2.6904 | Actual Loss: 0.5267\n",
      "Baseline Loss: 2.6669 | Actual Loss: 0.5989\n",
      "Baseline Loss: 2.6737 | Actual Loss: 0.4416\n",
      "Baseline Loss: 2.6431 | Actual Loss: 0.5595\n",
      "Baseline Loss: 2.6676 | Actual Loss: 0.5116\n",
      "Baseline Loss: 2.6407 | Actual Loss: 0.2877\n",
      "Baseline Loss: 2.6872 | Actual Loss: 0.4776\n",
      "Baseline Loss: 2.2939 | Actual Loss: 0.4382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 27/1000 [00:12<07:23,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6857 | Actual Loss: 0.6602\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.6059\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.6605\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.7977\n",
      "Epoch 27/1000: Train Loss: 0.4969, Val Loss: 0.6811\n",
      "New best validation loss: 0.6811\n",
      "Baseline Loss: 2.6761 | Actual Loss: 0.3949\n",
      "Baseline Loss: 2.7140 | Actual Loss: 0.4162\n",
      "Baseline Loss: 2.6683 | Actual Loss: 0.6695\n",
      "Baseline Loss: 2.6642 | Actual Loss: 0.5243\n",
      "Baseline Loss: 2.6609 | Actual Loss: 0.4628\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.7319\n",
      "Baseline Loss: 2.6382 | Actual Loss: 0.3565\n",
      "Baseline Loss: 2.6215 | Actual Loss: 0.5801\n",
      "Baseline Loss: 2.6824 | Actual Loss: 0.8747\n",
      "Baseline Loss: 2.6963 | Actual Loss: 0.3553\n",
      "Baseline Loss: 2.6827 | Actual Loss: 0.8696\n",
      "Baseline Loss: 2.6595 | Actual Loss: 0.4234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 28/1000 [00:13<07:40,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6762 | Actual Loss: 0.4155\n",
      "Baseline Loss: 2.6272 | Actual Loss: 0.6559\n",
      "Baseline Loss: 2.6552 | Actual Loss: 0.6910\n",
      "Baseline Loss: 2.2708 | Actual Loss: 0.3589\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.6863\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.8367\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.5920\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.7298\n",
      "Epoch 28/1000: Train Loss: 0.5488, Val Loss: 0.7112\n",
      "Baseline Loss: 2.6824 | Actual Loss: 0.5315\n",
      "Baseline Loss: 2.6810 | Actual Loss: 0.4348\n",
      "Baseline Loss: 2.6674 | Actual Loss: 0.3511\n",
      "Baseline Loss: 2.6740 | Actual Loss: 0.4762\n",
      "Baseline Loss: 2.7131 | Actual Loss: 0.5064\n",
      "Baseline Loss: 2.6558 | Actual Loss: 0.5808\n",
      "Baseline Loss: 2.6341 | Actual Loss: 0.2824\n",
      "Baseline Loss: 2.6918 | Actual Loss: 0.5042\n",
      "Baseline Loss: 2.6669 | Actual Loss: 0.5954\n",
      "Baseline Loss: 2.6783 | Actual Loss: 0.7900\n",
      "Baseline Loss: 2.6636 | Actual Loss: 0.4213\n",
      "Baseline Loss: 2.6864 | Actual Loss: 0.3223\n",
      "Baseline Loss: 2.6641 | Actual Loss: 0.4852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 29/1000 [00:13<07:46,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6457 | Actual Loss: 0.5741\n",
      "Baseline Loss: 2.6888 | Actual Loss: 0.5045\n",
      "Baseline Loss: 2.2681 | Actual Loss: 0.3819\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.6308\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.6863\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.6313\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.6877\n",
      "Epoch 29/1000: Train Loss: 0.4839, Val Loss: 0.6590\n",
      "New best validation loss: 0.6590\n",
      "Baseline Loss: 2.7120 | Actual Loss: 0.3821\n",
      "Baseline Loss: 2.6681 | Actual Loss: 0.6643\n",
      "Baseline Loss: 2.6702 | Actual Loss: 0.3644\n",
      "Baseline Loss: 2.6687 | Actual Loss: 0.5376\n",
      "Baseline Loss: 2.6773 | Actual Loss: 0.5338\n",
      "Baseline Loss: 2.6782 | Actual Loss: 0.6577\n",
      "Baseline Loss: 2.7302 | Actual Loss: 0.4717\n",
      "Baseline Loss: 2.6527 | Actual Loss: 0.2858\n",
      "Baseline Loss: 2.6662 | Actual Loss: 0.6953\n",
      "Baseline Loss: 2.6711 | Actual Loss: 0.4176\n",
      "Baseline Loss: 2.6911 | Actual Loss: 0.5134\n",
      "Baseline Loss: 2.6468 | Actual Loss: 0.3645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 30/1000 [00:14<07:27,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6963 | Actual Loss: 0.3057\n",
      "Baseline Loss: 2.6400 | Actual Loss: 0.5531\n",
      "Baseline Loss: 2.6277 | Actual Loss: 0.6596\n",
      "Baseline Loss: 2.2759 | Actual Loss: 0.2954\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.8098\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.5521\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.4576\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.5652\n",
      "Epoch 30/1000: Train Loss: 0.4814, Val Loss: 0.5962\n",
      "New best validation loss: 0.5962\n",
      "Baseline Loss: 2.6932 | Actual Loss: 0.4831\n",
      "Baseline Loss: 2.6798 | Actual Loss: 0.2938\n",
      "Baseline Loss: 2.6774 | Actual Loss: 0.4312\n",
      "Baseline Loss: 2.6485 | Actual Loss: 0.5929\n",
      "Baseline Loss: 2.6698 | Actual Loss: 0.4623\n",
      "Baseline Loss: 2.6753 | Actual Loss: 0.5937\n",
      "Baseline Loss: 2.6845 | Actual Loss: 0.3239\n",
      "Baseline Loss: 2.6626 | Actual Loss: 0.4783\n",
      "Baseline Loss: 2.6570 | Actual Loss: 0.5631\n",
      "Baseline Loss: 2.7223 | Actual Loss: 0.4998\n",
      "Baseline Loss: 2.6865 | Actual Loss: 0.4060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 31/1000 [00:14<07:38,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6512 | Actual Loss: 0.5375\n",
      "Baseline Loss: 2.6512 | Actual Loss: 0.4438\n",
      "Baseline Loss: 2.6646 | Actual Loss: 0.2585\n",
      "Baseline Loss: 2.6625 | Actual Loss: 0.7650\n",
      "Baseline Loss: 2.3388 | Actual Loss: 0.4616\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.6744\n",
      "Baseline Loss: 2.6990 | Actual Loss: 1.0196\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.4582\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.5716\n",
      "Epoch 31/1000: Train Loss: 0.4747, Val Loss: 0.6809\n",
      "Baseline Loss: 2.6614 | Actual Loss: 0.4901\n",
      "Baseline Loss: 2.6599 | Actual Loss: 0.3307\n",
      "Baseline Loss: 2.6833 | Actual Loss: 0.4717\n",
      "Baseline Loss: 2.6444 | Actual Loss: 0.4571\n",
      "Baseline Loss: 2.6335 | Actual Loss: 0.4963\n",
      "Baseline Loss: 2.6996 | Actual Loss: 0.4608\n",
      "Baseline Loss: 2.6812 | Actual Loss: 0.4104\n",
      "Baseline Loss: 2.6649 | Actual Loss: 0.4871\n",
      "Baseline Loss: 2.6805 | Actual Loss: 0.4261\n",
      "Baseline Loss: 2.6887 | Actual Loss: 0.4272\n",
      "Baseline Loss: 2.6709 | Actual Loss: 0.4912\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.6168\n",
      "Baseline Loss: 2.6872 | Actual Loss: 0.5970\n",
      "Baseline Loss: 2.6675 | Actual Loss: 0.1952\n",
      "Baseline Loss: 2.7202 | Actual Loss: 0.4217\n",
      "Baseline Loss: 2.2933 | Actual Loss: 0.2282\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.7211\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.5844\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.5230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 32/1000 [00:15<07:38,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6194 | Actual Loss: 0.6118\n",
      "Epoch 32/1000: Train Loss: 0.4380, Val Loss: 0.6101\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2779\n",
      "Baseline Loss: 2.6937 | Actual Loss: 0.5566\n",
      "Baseline Loss: 2.6542 | Actual Loss: 0.3853\n",
      "Baseline Loss: 2.6871 | Actual Loss: 0.2377\n",
      "Baseline Loss: 2.6783 | Actual Loss: 0.6085\n",
      "Baseline Loss: 2.6705 | Actual Loss: 0.3749\n",
      "Baseline Loss: 2.6490 | Actual Loss: 0.3965\n",
      "Baseline Loss: 2.7020 | Actual Loss: 0.5098\n",
      "Baseline Loss: 2.7011 | Actual Loss: 0.4544\n",
      "Baseline Loss: 2.7396 | Actual Loss: 0.3206\n",
      "Baseline Loss: 2.6689 | Actual Loss: 0.5685\n",
      "Baseline Loss: 2.6812 | Actual Loss: 0.4638\n",
      "Baseline Loss: 2.6495 | Actual Loss: 0.3935\n",
      "Baseline Loss: 2.6379 | Actual Loss: 0.6647\n",
      "Baseline Loss: 2.6945 | Actual Loss: 0.4001\n",
      "Baseline Loss: 2.1963 | Actual Loss: 0.3134\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5895\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.6563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 33/1000 [00:15<07:54,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6381 | Actual Loss: 0.5279\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4853\n",
      "Epoch 33/1000: Train Loss: 0.4329, Val Loss: 0.5647\n",
      "New best validation loss: 0.5647\n",
      "Baseline Loss: 2.6412 | Actual Loss: 0.5508\n",
      "Baseline Loss: 2.6902 | Actual Loss: 0.6288\n",
      "Baseline Loss: 2.6705 | Actual Loss: 0.4633\n",
      "Baseline Loss: 2.6374 | Actual Loss: 0.4998\n",
      "Baseline Loss: 2.6761 | Actual Loss: 0.3970\n",
      "Baseline Loss: 2.6545 | Actual Loss: 0.5950\n",
      "Baseline Loss: 2.6695 | Actual Loss: 0.4098\n",
      "Baseline Loss: 2.6998 | Actual Loss: 0.5210\n",
      "Baseline Loss: 2.6701 | Actual Loss: 0.3632\n",
      "Baseline Loss: 2.6666 | Actual Loss: 0.2695\n",
      "Baseline Loss: 2.7038 | Actual Loss: 0.4185\n",
      "Baseline Loss: 2.6573 | Actual Loss: 0.4818\n",
      "Baseline Loss: 2.6576 | Actual Loss: 0.4319\n",
      "Baseline Loss: 2.6784 | Actual Loss: 0.3300\n",
      "Baseline Loss: 2.6430 | Actual Loss: 0.4061\n",
      "Baseline Loss: 2.3119 | Actual Loss: 0.5325\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.6806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 34/1000 [00:16<07:37,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6990 | Actual Loss: 0.6613\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.4623\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4974\n",
      "Epoch 34/1000: Train Loss: 0.4562, Val Loss: 0.5754\n",
      "Baseline Loss: 2.6464 | Actual Loss: 0.3196\n",
      "Baseline Loss: 2.7207 | Actual Loss: 0.3405\n",
      "Baseline Loss: 2.7012 | Actual Loss: 0.4928\n",
      "Baseline Loss: 2.6491 | Actual Loss: 0.3025\n",
      "Baseline Loss: 2.6798 | Actual Loss: 0.4687\n",
      "Baseline Loss: 2.6654 | Actual Loss: 0.5840\n",
      "Baseline Loss: 2.6552 | Actual Loss: 0.5412\n",
      "Baseline Loss: 2.6710 | Actual Loss: 0.5137\n",
      "Baseline Loss: 2.6676 | Actual Loss: 0.6855\n",
      "Baseline Loss: 2.6669 | Actual Loss: 0.4440\n",
      "Baseline Loss: 2.6656 | Actual Loss: 0.3973\n",
      "Baseline Loss: 2.6964 | Actual Loss: 0.3248\n",
      "Baseline Loss: 2.6621 | Actual Loss: 0.5041\n",
      "Baseline Loss: 2.6981 | Actual Loss: 0.7067\n",
      "Baseline Loss: 2.6699 | Actual Loss: 0.5796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 35/1000 [00:16<07:37,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2770 | Actual Loss: 0.2651\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.6434\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.6712\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.4587\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.5290\n",
      "Epoch 35/1000: Train Loss: 0.4669, Val Loss: 0.5756\n",
      "Baseline Loss: 2.6708 | Actual Loss: 0.3986\n",
      "Baseline Loss: 2.6713 | Actual Loss: 0.4131\n",
      "Baseline Loss: 2.6911 | Actual Loss: 0.4866\n",
      "Baseline Loss: 2.6958 | Actual Loss: 0.2776\n",
      "Baseline Loss: 2.6574 | Actual Loss: 0.5850\n",
      "Baseline Loss: 2.6681 | Actual Loss: 0.4346\n",
      "Baseline Loss: 2.6845 | Actual Loss: 0.3395\n",
      "Baseline Loss: 2.6943 | Actual Loss: 0.6064\n",
      "Baseline Loss: 2.7007 | Actual Loss: 0.4603\n",
      "Baseline Loss: 2.6596 | Actual Loss: 0.8011\n",
      "Baseline Loss: 2.6987 | Actual Loss: 0.4977\n",
      "Baseline Loss: 2.6614 | Actual Loss: 0.4046\n",
      "Baseline Loss: 2.6620 | Actual Loss: 0.5904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 36/1000 [00:17<07:49,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6487 | Actual Loss: 0.4161\n",
      "Baseline Loss: 2.7034 | Actual Loss: 0.3910\n",
      "Baseline Loss: 2.2948 | Actual Loss: 0.2039\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5721\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.5936\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.4255\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.6331\n",
      "Epoch 36/1000: Train Loss: 0.4567, Val Loss: 0.5561\n",
      "New best validation loss: 0.5561\n",
      "Baseline Loss: 2.6918 | Actual Loss: 0.3990\n",
      "Baseline Loss: 2.6738 | Actual Loss: 0.7474\n",
      "Baseline Loss: 2.7078 | Actual Loss: 0.6716\n",
      "Baseline Loss: 2.7009 | Actual Loss: 0.3748\n",
      "Baseline Loss: 2.6610 | Actual Loss: 0.4223\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3338\n",
      "Baseline Loss: 2.6612 | Actual Loss: 0.4614\n",
      "Baseline Loss: 2.6551 | Actual Loss: 0.2703\n",
      "Baseline Loss: 2.6850 | Actual Loss: 0.2280\n",
      "Baseline Loss: 2.6422 | Actual Loss: 0.4653\n",
      "Baseline Loss: 2.6805 | Actual Loss: 0.5927\n",
      "Baseline Loss: 2.6698 | Actual Loss: 0.6149\n",
      "Baseline Loss: 2.7263 | Actual Loss: 0.4149\n",
      "Baseline Loss: 2.6249 | Actual Loss: 0.5433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 37/1000 [00:17<07:28,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6658 | Actual Loss: 0.5102\n",
      "Baseline Loss: 2.2990 | Actual Loss: 0.2747\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.6682\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.7153\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.5109\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.5684\n",
      "Epoch 37/1000: Train Loss: 0.4578, Val Loss: 0.6157\n",
      "Baseline Loss: 2.6597 | Actual Loss: 0.4757\n",
      "Baseline Loss: 2.6516 | Actual Loss: 0.3634\n",
      "Baseline Loss: 2.6549 | Actual Loss: 0.6108\n",
      "Baseline Loss: 2.6882 | Actual Loss: 0.3357\n",
      "Baseline Loss: 2.6368 | Actual Loss: 0.5216\n",
      "Baseline Loss: 2.6241 | Actual Loss: 0.3868\n",
      "Baseline Loss: 2.7168 | Actual Loss: 0.4037\n",
      "Baseline Loss: 2.6979 | Actual Loss: 0.4475\n",
      "Baseline Loss: 2.6815 | Actual Loss: 0.3159\n",
      "Baseline Loss: 2.6311 | Actual Loss: 0.4838\n",
      "Baseline Loss: 2.6603 | Actual Loss: 0.4844\n",
      "Baseline Loss: 2.7228 | Actual Loss: 0.6529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 38/1000 [00:18<07:32,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6766 | Actual Loss: 0.7224\n",
      "Baseline Loss: 2.6581 | Actual Loss: 0.7331\n",
      "Baseline Loss: 2.6991 | Actual Loss: 0.5057\n",
      "Baseline Loss: 2.2692 | Actual Loss: 0.3734\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.6228\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.5600\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.4417\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.5818\n",
      "Epoch 38/1000: Train Loss: 0.4886, Val Loss: 0.5516\n",
      "New best validation loss: 0.5516\n",
      "Baseline Loss: 2.6602 | Actual Loss: 0.5423\n",
      "Baseline Loss: 2.6668 | Actual Loss: 0.5615\n",
      "Baseline Loss: 2.6806 | Actual Loss: 0.3009\n",
      "Baseline Loss: 2.6863 | Actual Loss: 0.5512\n",
      "Baseline Loss: 2.6608 | Actual Loss: 0.5011\n",
      "Baseline Loss: 2.6709 | Actual Loss: 0.3250\n",
      "Baseline Loss: 2.7050 | Actual Loss: 0.3864\n",
      "Baseline Loss: 2.6698 | Actual Loss: 0.4167\n",
      "Baseline Loss: 2.6531 | Actual Loss: 0.3982\n",
      "Baseline Loss: 2.6580 | Actual Loss: 0.4028\n",
      "Baseline Loss: 2.6663 | Actual Loss: 0.3778\n",
      "Baseline Loss: 2.7133 | Actual Loss: 0.3766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 39/1000 [00:18<07:48,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6709 | Actual Loss: 0.3518\n",
      "Baseline Loss: 2.6809 | Actual Loss: 0.5618\n",
      "Baseline Loss: 2.7139 | Actual Loss: 0.4972\n",
      "Baseline Loss: 2.2666 | Actual Loss: 0.5852\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.6741\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.6687\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.4791\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4551\n",
      "Epoch 39/1000: Train Loss: 0.4460, Val Loss: 0.5693\n",
      "Baseline Loss: 2.6689 | Actual Loss: 0.4480\n",
      "Baseline Loss: 2.7053 | Actual Loss: 0.3398\n",
      "Baseline Loss: 2.6750 | Actual Loss: 0.3271\n",
      "Baseline Loss: 2.6878 | Actual Loss: 0.3796\n",
      "Baseline Loss: 2.6220 | Actual Loss: 0.2699\n",
      "Baseline Loss: 2.6750 | Actual Loss: 0.3634\n",
      "Baseline Loss: 2.6466 | Actual Loss: 0.3706\n",
      "Baseline Loss: 2.6696 | Actual Loss: 0.3350\n",
      "Baseline Loss: 2.6521 | Actual Loss: 0.2860\n",
      "Baseline Loss: 2.6562 | Actual Loss: 0.4168\n",
      "Baseline Loss: 2.6793 | Actual Loss: 0.5486\n",
      "Baseline Loss: 2.6874 | Actual Loss: 0.3852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 40/1000 [00:18<07:21,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6753 | Actual Loss: 0.5311\n",
      "Baseline Loss: 2.6905 | Actual Loss: 0.3974\n",
      "Baseline Loss: 2.6895 | Actual Loss: 0.3379\n",
      "Baseline Loss: 2.2936 | Actual Loss: 0.2242\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.6166\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.5950\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.4519\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.5509\n",
      "Epoch 40/1000: Train Loss: 0.3726, Val Loss: 0.5536\n",
      "Baseline Loss: 2.7285 | Actual Loss: 0.4985\n",
      "Baseline Loss: 2.6556 | Actual Loss: 0.2049\n",
      "Baseline Loss: 2.7081 | Actual Loss: 0.4054\n",
      "Baseline Loss: 2.6631 | Actual Loss: 0.2919\n",
      "Baseline Loss: 2.6648 | Actual Loss: 0.5937\n",
      "Baseline Loss: 2.6626 | Actual Loss: 0.4349\n",
      "Baseline Loss: 2.6432 | Actual Loss: 0.2975\n",
      "Baseline Loss: 2.6750 | Actual Loss: 0.2975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 41/1000 [00:19<07:26,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6629 | Actual Loss: 0.3905\n",
      "Baseline Loss: 2.6642 | Actual Loss: 0.3716\n",
      "Baseline Loss: 2.6826 | Actual Loss: 0.4390\n",
      "Baseline Loss: 2.6797 | Actual Loss: 0.7681\n",
      "Baseline Loss: 2.6935 | Actual Loss: 0.5417\n",
      "Baseline Loss: 2.6687 | Actual Loss: 0.4339\n",
      "Baseline Loss: 2.6496 | Actual Loss: 0.5208\n",
      "Baseline Loss: 2.3126 | Actual Loss: 0.3661\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.6946\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.5467\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3657\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4240\n",
      "Epoch 41/1000: Train Loss: 0.4285, Val Loss: 0.5077\n",
      "New best validation loss: 0.5077\n",
      "Baseline Loss: 2.6767 | Actual Loss: 0.3288\n",
      "Baseline Loss: 2.6498 | Actual Loss: 0.3936\n",
      "Baseline Loss: 2.6848 | Actual Loss: 0.4134\n",
      "Baseline Loss: 2.6707 | Actual Loss: 0.2378\n",
      "Baseline Loss: 2.6698 | Actual Loss: 0.3466\n",
      "Baseline Loss: 2.6860 | Actual Loss: 0.4214\n",
      "Baseline Loss: 2.6378 | Actual Loss: 0.5926\n",
      "Baseline Loss: 2.6897 | Actual Loss: 0.2896\n",
      "Baseline Loss: 2.6643 | Actual Loss: 0.3609\n",
      "Baseline Loss: 2.7162 | Actual Loss: 0.3565\n",
      "Baseline Loss: 2.6789 | Actual Loss: 0.5114\n",
      "Baseline Loss: 2.6911 | Actual Loss: 0.4811\n",
      "Baseline Loss: 2.6999 | Actual Loss: 0.4346\n",
      "Baseline Loss: 2.6645 | Actual Loss: 0.4679\n",
      "Baseline Loss: 2.6765 | Actual Loss: 0.2406\n",
      "Baseline Loss: 2.2771 | Actual Loss: 0.4803\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5652\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.5784\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.5015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 42/1000 [00:19<07:41,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6194 | Actual Loss: 0.5437\n",
      "Epoch 42/1000: Train Loss: 0.3973, Val Loss: 0.5472\n",
      "Baseline Loss: 2.6790 | Actual Loss: 0.4718\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.2702\n",
      "Baseline Loss: 2.6912 | Actual Loss: 0.2381\n",
      "Baseline Loss: 2.6361 | Actual Loss: 0.4148\n",
      "Baseline Loss: 2.6834 | Actual Loss: 0.4370\n",
      "Baseline Loss: 2.6680 | Actual Loss: 0.5159\n",
      "Baseline Loss: 2.6569 | Actual Loss: 0.2456\n",
      "Baseline Loss: 2.6771 | Actual Loss: 0.2640\n",
      "Baseline Loss: 2.6824 | Actual Loss: 0.3624\n",
      "Baseline Loss: 2.7060 | Actual Loss: 0.5097\n",
      "Baseline Loss: 2.6490 | Actual Loss: 0.6830\n",
      "Baseline Loss: 2.6815 | Actual Loss: 0.3859\n",
      "Baseline Loss: 2.6645 | Actual Loss: 0.3622\n",
      "Baseline Loss: 2.6994 | Actual Loss: 0.3711\n",
      "Baseline Loss: 2.7106 | Actual Loss: 0.3689\n",
      "Baseline Loss: 2.2159 | Actual Loss: 0.0491\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5050\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.6232\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3646\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4550\n",
      "Epoch 43/1000: Train Loss: 0.3719, Val Loss: 0.4870\n",
      "New best validation loss: 0.4870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 43/1000 [00:20<07:21,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6691 | Actual Loss: 0.4188\n",
      "Baseline Loss: 2.7006 | Actual Loss: 0.4050\n",
      "Baseline Loss: 2.6679 | Actual Loss: 0.5406\n",
      "Baseline Loss: 2.6715 | Actual Loss: 0.4344\n",
      "Baseline Loss: 2.6609 | Actual Loss: 0.4025\n",
      "Baseline Loss: 2.7633 | Actual Loss: 0.4871\n",
      "Baseline Loss: 2.6817 | Actual Loss: 0.3303\n",
      "Baseline Loss: 2.6329 | Actual Loss: 0.5425\n",
      "Baseline Loss: 2.6616 | Actual Loss: 0.3654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 44/1000 [00:20<07:28,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6554 | Actual Loss: 0.1663\n",
      "Baseline Loss: 2.6808 | Actual Loss: 0.4561\n",
      "Baseline Loss: 2.6666 | Actual Loss: 0.5121\n",
      "Baseline Loss: 2.6891 | Actual Loss: 0.3870\n",
      "Baseline Loss: 2.6627 | Actual Loss: 0.4362\n",
      "Baseline Loss: 2.6851 | Actual Loss: 0.8503\n",
      "Baseline Loss: 2.2693 | Actual Loss: 0.6008\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5014\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.6782\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.4511\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4952\n",
      "Epoch 44/1000: Train Loss: 0.4585, Val Loss: 0.5315\n",
      "Baseline Loss: 2.7161 | Actual Loss: 0.4845\n",
      "Baseline Loss: 2.6467 | Actual Loss: 0.5788\n",
      "Baseline Loss: 2.7071 | Actual Loss: 0.3407\n",
      "Baseline Loss: 2.6996 | Actual Loss: 0.3780\n",
      "Baseline Loss: 2.6486 | Actual Loss: 0.5056\n",
      "Baseline Loss: 2.6511 | Actual Loss: 0.3344\n",
      "Baseline Loss: 2.6502 | Actual Loss: 0.2672\n",
      "Baseline Loss: 2.6609 | Actual Loss: 0.3416\n",
      "Baseline Loss: 2.6909 | Actual Loss: 0.3344\n",
      "Baseline Loss: 2.6331 | Actual Loss: 0.5737\n",
      "Baseline Loss: 2.6530 | Actual Loss: 0.5503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 45/1000 [00:21<07:13,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6532 | Actual Loss: 0.4408\n",
      "Baseline Loss: 2.6794 | Actual Loss: 0.4154\n",
      "Baseline Loss: 2.6827 | Actual Loss: 0.3158\n",
      "Baseline Loss: 2.6452 | Actual Loss: 0.4068\n",
      "Baseline Loss: 2.3059 | Actual Loss: 0.2005\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.6150\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.6834\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.6067\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4838\n",
      "Epoch 45/1000: Train Loss: 0.4043, Val Loss: 0.5972\n",
      "Baseline Loss: 2.6778 | Actual Loss: 0.4624\n",
      "Baseline Loss: 2.6835 | Actual Loss: 0.4405\n",
      "Baseline Loss: 2.6226 | Actual Loss: 0.6860\n",
      "Baseline Loss: 2.6404 | Actual Loss: 0.3945\n",
      "Baseline Loss: 2.7394 | Actual Loss: 0.2863\n",
      "Baseline Loss: 2.6941 | Actual Loss: 0.4419\n",
      "Baseline Loss: 2.6781 | Actual Loss: 0.4544\n",
      "Baseline Loss: 2.6493 | Actual Loss: 0.2656\n",
      "Baseline Loss: 2.6542 | Actual Loss: 0.3752\n",
      "Baseline Loss: 2.6699 | Actual Loss: 0.3490\n",
      "Baseline Loss: 2.6526 | Actual Loss: 0.4000\n",
      "Baseline Loss: 2.7045 | Actual Loss: 0.6793\n",
      "Baseline Loss: 2.6585 | Actual Loss: 0.2875\n",
      "Baseline Loss: 2.6563 | Actual Loss: 0.5242\n",
      "Baseline Loss: 2.6994 | Actual Loss: 0.3550\n",
      "Baseline Loss: 2.2870 | Actual Loss: 0.2850\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.6111\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.6173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 46/1000 [00:21<07:19,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6381 | Actual Loss: 0.4846\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4734\n",
      "Epoch 46/1000: Train Loss: 0.4179, Val Loss: 0.5466\n",
      "Baseline Loss: 2.6618 | Actual Loss: 0.2771\n",
      "Baseline Loss: 2.7059 | Actual Loss: 0.3448\n",
      "Baseline Loss: 2.6630 | Actual Loss: 0.3565\n",
      "Baseline Loss: 2.7277 | Actual Loss: 0.4080\n",
      "Baseline Loss: 2.6727 | Actual Loss: 0.3952\n",
      "Baseline Loss: 2.6928 | Actual Loss: 0.7068\n",
      "Baseline Loss: 2.6568 | Actual Loss: 0.5717\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4369\n",
      "Baseline Loss: 2.6837 | Actual Loss: 0.3330\n",
      "Baseline Loss: 2.6540 | Actual Loss: 0.4650\n",
      "Baseline Loss: 2.6559 | Actual Loss: 0.4224\n",
      "Baseline Loss: 2.6707 | Actual Loss: 0.4622\n",
      "Baseline Loss: 2.6517 | Actual Loss: 0.4045\n",
      "Baseline Loss: 2.6842 | Actual Loss: 0.4700\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.3136\n",
      "Baseline Loss: 2.2221 | Actual Loss: 0.3013\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.8253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 47/1000 [00:22<07:14,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6990 | Actual Loss: 0.6221\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.4654\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.5965\n",
      "Epoch 47/1000: Train Loss: 0.4168, Val Loss: 0.6273\n",
      "Baseline Loss: 2.6995 | Actual Loss: 0.3914\n",
      "Baseline Loss: 2.6815 | Actual Loss: 0.2484\n",
      "Baseline Loss: 2.6490 | Actual Loss: 0.2357\n",
      "Baseline Loss: 2.6463 | Actual Loss: 0.3357\n",
      "Baseline Loss: 2.6598 | Actual Loss: 0.3150\n",
      "Baseline Loss: 2.7031 | Actual Loss: 0.5041\n",
      "Baseline Loss: 2.6414 | Actual Loss: 0.3477\n",
      "Baseline Loss: 2.6565 | Actual Loss: 0.5803\n",
      "Baseline Loss: 2.6923 | Actual Loss: 0.6005\n",
      "Baseline Loss: 2.6676 | Actual Loss: 0.6045\n",
      "Baseline Loss: 2.6695 | Actual Loss: 0.6749\n",
      "Baseline Loss: 2.7284 | Actual Loss: 0.4939\n",
      "Baseline Loss: 2.7171 | Actual Loss: 0.4215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 48/1000 [00:22<07:36,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6556 | Actual Loss: 0.3336\n",
      "Baseline Loss: 2.6636 | Actual Loss: 0.2823\n",
      "Baseline Loss: 2.3047 | Actual Loss: 0.2386\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5780\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.5402\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.4097\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4145\n",
      "Epoch 48/1000: Train Loss: 0.4130, Val Loss: 0.4856\n",
      "New best validation loss: 0.4856\n",
      "Baseline Loss: 2.6410 | Actual Loss: 0.3022\n",
      "Baseline Loss: 2.6598 | Actual Loss: 0.3198\n",
      "Baseline Loss: 2.7024 | Actual Loss: 0.4048\n",
      "Baseline Loss: 2.6643 | Actual Loss: 0.2843\n",
      "Baseline Loss: 2.6450 | Actual Loss: 0.4317\n",
      "Baseline Loss: 2.6683 | Actual Loss: 0.7150\n",
      "Baseline Loss: 2.6589 | Actual Loss: 0.2838\n",
      "Baseline Loss: 2.6942 | Actual Loss: 0.3314\n",
      "Baseline Loss: 2.6992 | Actual Loss: 0.4447\n",
      "Baseline Loss: 2.7066 | Actual Loss: 0.3353\n",
      "Baseline Loss: 2.6835 | Actual Loss: 0.4785\n",
      "Baseline Loss: 2.6626 | Actual Loss: 0.2953\n",
      "Baseline Loss: 2.6880 | Actual Loss: 0.1994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 49/1000 [00:23<07:35,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6548 | Actual Loss: 0.2666\n",
      "Baseline Loss: 2.6771 | Actual Loss: 0.4003\n",
      "Baseline Loss: 2.2634 | Actual Loss: 0.1820\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.6282\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.6018\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3773\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4777\n",
      "Epoch 49/1000: Train Loss: 0.3547, Val Loss: 0.5212\n",
      "Baseline Loss: 2.6357 | Actual Loss: 0.4470\n",
      "Baseline Loss: 2.6748 | Actual Loss: 0.3616\n",
      "Baseline Loss: 2.7072 | Actual Loss: 0.3261\n",
      "Baseline Loss: 2.6509 | Actual Loss: 0.3150\n",
      "Baseline Loss: 2.6356 | Actual Loss: 0.4420\n",
      "Baseline Loss: 2.6796 | Actual Loss: 0.6189\n",
      "Baseline Loss: 2.6646 | Actual Loss: 0.3102\n",
      "Baseline Loss: 2.6417 | Actual Loss: 0.3408\n",
      "Baseline Loss: 2.6899 | Actual Loss: 0.5568\n",
      "Baseline Loss: 2.6525 | Actual Loss: 0.3640\n",
      "Baseline Loss: 2.6739 | Actual Loss: 0.4077\n",
      "Baseline Loss: 2.6553 | Actual Loss: 0.4612\n",
      "Baseline Loss: 2.6774 | Actual Loss: 0.4054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 50/1000 [00:23<07:17,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6695 | Actual Loss: 0.2614\n",
      "Baseline Loss: 2.7051 | Actual Loss: 0.2658\n",
      "Baseline Loss: 2.3301 | Actual Loss: 0.2665\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.6190\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.5835\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3355\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.5845\n",
      "Epoch 50/1000: Train Loss: 0.3844, Val Loss: 0.5306\n",
      "Baseline Loss: 2.6798 | Actual Loss: 0.3234\n",
      "Baseline Loss: 2.6883 | Actual Loss: 0.4347\n",
      "Baseline Loss: 2.6810 | Actual Loss: 0.2110\n",
      "Baseline Loss: 2.6888 | Actual Loss: 0.4897\n",
      "Baseline Loss: 2.7011 | Actual Loss: 0.4517\n",
      "Baseline Loss: 2.6645 | Actual Loss: 0.4101\n",
      "Baseline Loss: 2.6706 | Actual Loss: 0.3439\n",
      "Baseline Loss: 2.6630 | Actual Loss: 0.3033\n",
      "Baseline Loss: 2.6706 | Actual Loss: 0.2310\n",
      "Baseline Loss: 2.6590 | Actual Loss: 0.3056\n",
      "Baseline Loss: 2.6911 | Actual Loss: 0.4423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 51/1000 [00:24<07:31,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7071 | Actual Loss: 0.3249\n",
      "Baseline Loss: 2.6811 | Actual Loss: 0.6171\n",
      "Baseline Loss: 2.6824 | Actual Loss: 0.3669\n",
      "Baseline Loss: 2.6610 | Actual Loss: 0.4522\n",
      "Baseline Loss: 2.1966 | Actual Loss: 0.2635\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5614\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.6010\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.4827\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.5253\n",
      "Epoch 51/1000: Train Loss: 0.3732, Val Loss: 0.5426\n",
      "Baseline Loss: 2.6679 | Actual Loss: 0.2388\n",
      "Baseline Loss: 2.6951 | Actual Loss: 0.5410\n",
      "Baseline Loss: 2.6750 | Actual Loss: 0.4803\n",
      "Baseline Loss: 2.6845 | Actual Loss: 0.5105\n",
      "Baseline Loss: 2.6926 | Actual Loss: 0.4252\n",
      "Baseline Loss: 2.6745 | Actual Loss: 0.3485\n",
      "Baseline Loss: 2.6930 | Actual Loss: 0.3705\n",
      "Baseline Loss: 2.6953 | Actual Loss: 0.3330\n",
      "Baseline Loss: 2.6610 | Actual Loss: 0.3683\n",
      "Baseline Loss: 2.6787 | Actual Loss: 0.1605\n",
      "Baseline Loss: 2.6560 | Actual Loss: 0.3782\n",
      "Baseline Loss: 2.6406 | Actual Loss: 0.5198\n",
      "Baseline Loss: 2.7161 | Actual Loss: 0.3500\n",
      "Baseline Loss: 2.6523 | Actual Loss: 0.3414\n",
      "Baseline Loss: 2.6504 | Actual Loss: 0.5059\n",
      "Baseline Loss: 2.1712 | Actual Loss: 0.3992\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.6028\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.6043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 52/1000 [00:24<07:29,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6381 | Actual Loss: 0.4671\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4744\n",
      "Epoch 52/1000: Train Loss: 0.3919, Val Loss: 0.5372\n",
      "Baseline Loss: 2.6908 | Actual Loss: 0.3686\n",
      "Baseline Loss: 2.6555 | Actual Loss: 0.4135\n",
      "Baseline Loss: 2.6576 | Actual Loss: 0.3263\n",
      "Baseline Loss: 2.6425 | Actual Loss: 0.4074\n",
      "Baseline Loss: 2.6704 | Actual Loss: 0.4674\n",
      "Baseline Loss: 2.6343 | Actual Loss: 0.3775\n",
      "Baseline Loss: 2.6919 | Actual Loss: 0.4772\n",
      "Baseline Loss: 2.7166 | Actual Loss: 0.3824\n",
      "Baseline Loss: 2.6695 | Actual Loss: 0.3807\n",
      "Baseline Loss: 2.7503 | Actual Loss: 0.5848\n",
      "Baseline Loss: 2.6753 | Actual Loss: 0.2760\n",
      "Baseline Loss: 2.6658 | Actual Loss: 0.3885\n",
      "Baseline Loss: 2.6937 | Actual Loss: 0.2566\n",
      "Baseline Loss: 2.6686 | Actual Loss: 0.3890\n",
      "Baseline Loss: 2.6429 | Actual Loss: 0.3619\n",
      "Baseline Loss: 2.2806 | Actual Loss: 0.0713\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.6507\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.6299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 53/1000 [00:25<07:38,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6381 | Actual Loss: 0.4650\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4830\n",
      "Epoch 53/1000: Train Loss: 0.3706, Val Loss: 0.5571\n",
      "Baseline Loss: 2.6504 | Actual Loss: 0.2680\n",
      "Baseline Loss: 2.7248 | Actual Loss: 0.3280\n",
      "Baseline Loss: 2.6712 | Actual Loss: 0.3777\n",
      "Baseline Loss: 2.7008 | Actual Loss: 0.3523\n",
      "Baseline Loss: 2.6685 | Actual Loss: 0.3747\n",
      "Baseline Loss: 2.7108 | Actual Loss: 0.3763\n",
      "Baseline Loss: 2.6513 | Actual Loss: 0.3437\n",
      "Baseline Loss: 2.6665 | Actual Loss: 0.3454\n",
      "Baseline Loss: 2.6741 | Actual Loss: 0.3307\n",
      "Baseline Loss: 2.6441 | Actual Loss: 0.2400\n",
      "Baseline Loss: 2.6380 | Actual Loss: 0.4873\n",
      "Baseline Loss: 2.6882 | Actual Loss: 0.1723\n",
      "Baseline Loss: 2.7066 | Actual Loss: 0.4673\n",
      "Baseline Loss: 2.6501 | Actual Loss: 0.5423\n",
      "Baseline Loss: 2.6576 | Actual Loss: 0.1772\n",
      "Baseline Loss: 2.2762 | Actual Loss: 0.4044\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.6649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 54/1000 [00:25<07:24,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6990 | Actual Loss: 0.7657\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.5189\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.5902\n",
      "Epoch 54/1000: Train Loss: 0.3492, Val Loss: 0.6349\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4103\n",
      "Baseline Loss: 2.6678 | Actual Loss: 0.4850\n",
      "Baseline Loss: 2.7108 | Actual Loss: 0.3769\n",
      "Baseline Loss: 2.6842 | Actual Loss: 0.4725\n",
      "Baseline Loss: 2.6541 | Actual Loss: 0.4456\n",
      "Baseline Loss: 2.6306 | Actual Loss: 0.2452\n",
      "Baseline Loss: 2.6563 | Actual Loss: 0.3092\n",
      "Baseline Loss: 2.6915 | Actual Loss: 0.2397\n",
      "Baseline Loss: 2.6741 | Actual Loss: 0.5189\n",
      "Baseline Loss: 2.7116 | Actual Loss: 0.3658\n",
      "Baseline Loss: 2.6842 | Actual Loss: 0.3206\n",
      "Baseline Loss: 2.6771 | Actual Loss: 0.2574\n",
      "Baseline Loss: 2.6544 | Actual Loss: 0.4833\n",
      "Baseline Loss: 2.6708 | Actual Loss: 0.2659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 55/1000 [00:26<07:25,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6927 | Actual Loss: 0.3809\n",
      "Baseline Loss: 2.3014 | Actual Loss: 0.1286\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5865\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.5737\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.4284\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.5310\n",
      "Epoch 55/1000: Train Loss: 0.3566, Val Loss: 0.5299\n",
      "Baseline Loss: 2.6560 | Actual Loss: 0.3610\n",
      "Baseline Loss: 2.6793 | Actual Loss: 0.2918\n",
      "Baseline Loss: 2.6970 | Actual Loss: 0.3482\n",
      "Baseline Loss: 2.6301 | Actual Loss: 0.3510\n",
      "Baseline Loss: 2.6350 | Actual Loss: 0.4381\n",
      "Baseline Loss: 2.6826 | Actual Loss: 0.3474\n",
      "Baseline Loss: 2.6717 | Actual Loss: 0.3100\n",
      "Baseline Loss: 2.6988 | Actual Loss: 0.2435\n",
      "Baseline Loss: 2.6399 | Actual Loss: 0.4039\n",
      "Baseline Loss: 2.6808 | Actual Loss: 0.6083\n",
      "Baseline Loss: 2.7360 | Actual Loss: 0.6191\n",
      "Baseline Loss: 2.6736 | Actual Loss: 0.3898\n",
      "Baseline Loss: 2.6587 | Actual Loss: 0.3705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 56/1000 [00:26<07:30,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6644 | Actual Loss: 0.4221\n",
      "Baseline Loss: 2.6783 | Actual Loss: 0.4236\n",
      "Baseline Loss: 2.2505 | Actual Loss: 0.3975\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5375\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.6095\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3900\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.5157\n",
      "Epoch 56/1000: Train Loss: 0.3954, Val Loss: 0.5132\n",
      "Baseline Loss: 2.6641 | Actual Loss: 0.4789\n",
      "Baseline Loss: 2.6204 | Actual Loss: 0.2723\n",
      "Baseline Loss: 2.7083 | Actual Loss: 0.4018\n",
      "Baseline Loss: 2.6551 | Actual Loss: 0.4537\n",
      "Baseline Loss: 2.6742 | Actual Loss: 0.4781\n",
      "Baseline Loss: 2.6518 | Actual Loss: 0.4879\n",
      "Baseline Loss: 2.6748 | Actual Loss: 0.3609\n",
      "Baseline Loss: 2.7313 | Actual Loss: 0.2775\n",
      "Baseline Loss: 2.6740 | Actual Loss: 0.2736\n",
      "Baseline Loss: 2.6805 | Actual Loss: 0.4005\n",
      "Baseline Loss: 2.6592 | Actual Loss: 0.2937\n",
      "Baseline Loss: 2.6732 | Actual Loss: 0.2781\n",
      "Baseline Loss: 2.6864 | Actual Loss: 0.4484\n",
      "Baseline Loss: 2.6889 | Actual Loss: 0.3156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 57/1000 [00:26<07:13,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7166 | Actual Loss: 0.4640\n",
      "Baseline Loss: 2.2510 | Actual Loss: 0.2049\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.7018\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.5020\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.5008\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4692\n",
      "Epoch 57/1000: Train Loss: 0.3681, Val Loss: 0.5434\n",
      "Baseline Loss: 2.6629 | Actual Loss: 0.3248\n",
      "Baseline Loss: 2.6985 | Actual Loss: 0.2183\n",
      "Baseline Loss: 2.6942 | Actual Loss: 0.3117\n",
      "Baseline Loss: 2.7204 | Actual Loss: 0.4206\n",
      "Baseline Loss: 2.6721 | Actual Loss: 0.2593\n",
      "Baseline Loss: 2.7444 | Actual Loss: 0.2368\n",
      "Baseline Loss: 2.6807 | Actual Loss: 0.3249\n",
      "Baseline Loss: 2.6656 | Actual Loss: 0.2799\n",
      "Baseline Loss: 2.6822 | Actual Loss: 0.1938\n",
      "Baseline Loss: 2.6470 | Actual Loss: 0.4038\n",
      "Baseline Loss: 2.6838 | Actual Loss: 0.4227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 58/1000 [00:27<07:24,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6332 | Actual Loss: 0.3316\n",
      "Baseline Loss: 2.6782 | Actual Loss: 0.4768\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3837\n",
      "Baseline Loss: 2.6664 | Actual Loss: 0.5430\n",
      "Baseline Loss: 2.2791 | Actual Loss: 0.2258\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.6833\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.6018\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.4436\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4814\n",
      "Epoch 58/1000: Train Loss: 0.3348, Val Loss: 0.5525\n",
      "Baseline Loss: 2.6524 | Actual Loss: 0.2834\n",
      "Baseline Loss: 2.6533 | Actual Loss: 0.4649\n",
      "Baseline Loss: 2.6553 | Actual Loss: 0.3960\n",
      "Baseline Loss: 2.6631 | Actual Loss: 0.2615\n",
      "Baseline Loss: 2.7033 | Actual Loss: 0.3660\n",
      "Baseline Loss: 2.6665 | Actual Loss: 0.5200\n",
      "Baseline Loss: 2.6586 | Actual Loss: 0.3293\n",
      "Baseline Loss: 2.6498 | Actual Loss: 0.2892\n",
      "Baseline Loss: 2.6464 | Actual Loss: 0.5057\n",
      "Baseline Loss: 2.6669 | Actual Loss: 0.4152\n",
      "Baseline Loss: 2.6725 | Actual Loss: 0.4658\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.4631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 59/1000 [00:27<07:25,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6607 | Actual Loss: 0.3177\n",
      "Baseline Loss: 2.7077 | Actual Loss: 0.2534\n",
      "Baseline Loss: 2.7435 | Actual Loss: 0.5997\n",
      "Baseline Loss: 2.2563 | Actual Loss: 0.1807\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5706\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.6281\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3619\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4732\n",
      "Epoch 59/1000: Train Loss: 0.3820, Val Loss: 0.5085\n",
      "Baseline Loss: 2.6775 | Actual Loss: 0.2765\n",
      "Baseline Loss: 2.6737 | Actual Loss: 0.2540\n",
      "Baseline Loss: 2.6586 | Actual Loss: 0.2907\n",
      "Baseline Loss: 2.7179 | Actual Loss: 0.2456\n",
      "Baseline Loss: 2.7162 | Actual Loss: 0.3089\n",
      "Baseline Loss: 2.6648 | Actual Loss: 0.3675\n",
      "Baseline Loss: 2.6362 | Actual Loss: 0.3991\n",
      "Baseline Loss: 2.7096 | Actual Loss: 0.3257\n",
      "Baseline Loss: 2.6555 | Actual Loss: 0.3779\n",
      "Baseline Loss: 2.6843 | Actual Loss: 0.1940\n",
      "Baseline Loss: 2.6407 | Actual Loss: 0.5721\n",
      "Baseline Loss: 2.6858 | Actual Loss: 0.3619\n",
      "Baseline Loss: 2.6433 | Actual Loss: 0.4847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 60/1000 [00:28<07:09,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6597 | Actual Loss: 0.3426\n",
      "Baseline Loss: 2.6673 | Actual Loss: 0.3370\n",
      "Baseline Loss: 2.3580 | Actual Loss: 0.2699\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5497\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.5810\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.4137\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.5260\n",
      "Epoch 60/1000: Train Loss: 0.3380, Val Loss: 0.5176\n",
      "Baseline Loss: 2.6555 | Actual Loss: 0.2608\n",
      "Baseline Loss: 2.6935 | Actual Loss: 0.3846\n",
      "Baseline Loss: 2.6782 | Actual Loss: 0.2761\n",
      "Baseline Loss: 2.6785 | Actual Loss: 0.3791\n",
      "Baseline Loss: 2.6875 | Actual Loss: 0.3071\n",
      "Baseline Loss: 2.6770 | Actual Loss: 0.4888\n",
      "Baseline Loss: 2.7267 | Actual Loss: 0.3529\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3580\n",
      "Baseline Loss: 2.6354 | Actual Loss: 0.3377\n",
      "Baseline Loss: 2.6850 | Actual Loss: 0.3821\n",
      "Baseline Loss: 2.6536 | Actual Loss: 0.5273\n",
      "Baseline Loss: 2.6750 | Actual Loss: 0.4870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 61/1000 [00:28<07:23,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6754 | Actual Loss: 0.3540\n",
      "Baseline Loss: 2.6730 | Actual Loss: 0.3935\n",
      "Baseline Loss: 2.6494 | Actual Loss: 0.3192\n",
      "Baseline Loss: 2.3071 | Actual Loss: 0.0971\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5597\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.4939\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.4342\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4503\n",
      "Epoch 61/1000: Train Loss: 0.3566, Val Loss: 0.4845\n",
      "New best validation loss: 0.4845\n",
      "Baseline Loss: 2.6696 | Actual Loss: 0.2409\n",
      "Baseline Loss: 2.6511 | Actual Loss: 0.3380\n",
      "Baseline Loss: 2.6350 | Actual Loss: 0.3846\n",
      "Baseline Loss: 2.7045 | Actual Loss: 0.2489\n",
      "Baseline Loss: 2.6688 | Actual Loss: 0.3059\n",
      "Baseline Loss: 2.7006 | Actual Loss: 0.4124\n",
      "Baseline Loss: 2.7014 | Actual Loss: 0.4723\n",
      "Baseline Loss: 2.6676 | Actual Loss: 0.2746\n",
      "Baseline Loss: 2.6500 | Actual Loss: 0.4684\n",
      "Baseline Loss: 2.6565 | Actual Loss: 0.2922\n",
      "Baseline Loss: 2.6392 | Actual Loss: 0.2566\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.1917\n",
      "Baseline Loss: 2.6701 | Actual Loss: 0.4904\n",
      "Baseline Loss: 2.6614 | Actual Loss: 0.4936\n",
      "Baseline Loss: 2.6994 | Actual Loss: 0.4779\n",
      "Baseline Loss: 2.2541 | Actual Loss: 0.1464\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.6546\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.6198\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 62/1000 [00:29<07:28,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6194 | Actual Loss: 0.4316\n",
      "Epoch 62/1000: Train Loss: 0.3434, Val Loss: 0.5131\n",
      "Baseline Loss: 2.6878 | Actual Loss: 0.3134\n",
      "Baseline Loss: 2.6579 | Actual Loss: 0.2546\n",
      "Baseline Loss: 2.7152 | Actual Loss: 0.3390\n",
      "Baseline Loss: 2.6821 | Actual Loss: 0.5721\n",
      "Baseline Loss: 2.7088 | Actual Loss: 0.3061\n",
      "Baseline Loss: 2.6960 | Actual Loss: 0.2576\n",
      "Baseline Loss: 2.6944 | Actual Loss: 0.2488\n",
      "Baseline Loss: 2.6842 | Actual Loss: 0.3325\n",
      "Baseline Loss: 2.6863 | Actual Loss: 0.3473\n",
      "Baseline Loss: 2.6923 | Actual Loss: 0.3564\n",
      "Baseline Loss: 2.6482 | Actual Loss: 0.3784\n",
      "Baseline Loss: 2.6375 | Actual Loss: 0.3888\n",
      "Baseline Loss: 2.6829 | Actual Loss: 0.3814\n",
      "Baseline Loss: 2.6906 | Actual Loss: 0.4007\n",
      "Baseline Loss: 2.6437 | Actual Loss: 0.1843\n",
      "Baseline Loss: 2.2710 | Actual Loss: 0.0807\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4832\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.5389\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3489\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3789\n",
      "Epoch 63/1000: Train Loss: 0.3214, Val Loss: 0.4375\n",
      "New best validation loss: 0.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 63/1000 [00:29<07:08,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6683 | Actual Loss: 0.3090\n",
      "Baseline Loss: 2.7338 | Actual Loss: 0.2416\n",
      "Baseline Loss: 2.6643 | Actual Loss: 0.2151\n",
      "Baseline Loss: 2.7045 | Actual Loss: 0.3048\n",
      "Baseline Loss: 2.6822 | Actual Loss: 0.3917\n",
      "Baseline Loss: 2.6616 | Actual Loss: 0.2952\n",
      "Baseline Loss: 2.6921 | Actual Loss: 0.2815\n",
      "Baseline Loss: 2.6675 | Actual Loss: 0.3455\n",
      "Baseline Loss: 2.6487 | Actual Loss: 0.4147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 64/1000 [00:30<07:20,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7025 | Actual Loss: 0.4668\n",
      "Baseline Loss: 2.6648 | Actual Loss: 0.3522\n",
      "Baseline Loss: 2.6851 | Actual Loss: 0.2627\n",
      "Baseline Loss: 2.6343 | Actual Loss: 0.2787\n",
      "Baseline Loss: 2.6455 | Actual Loss: 0.3425\n",
      "Baseline Loss: 2.6822 | Actual Loss: 0.2903\n",
      "Baseline Loss: 2.2942 | Actual Loss: 0.2974\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5068\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.5403\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.5401\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4878\n",
      "Epoch 64/1000: Train Loss: 0.3181, Val Loss: 0.5187\n",
      "Baseline Loss: 2.6942 | Actual Loss: 0.4174\n",
      "Baseline Loss: 2.6388 | Actual Loss: 0.4911\n",
      "Baseline Loss: 2.6553 | Actual Loss: 0.2636\n",
      "Baseline Loss: 2.6588 | Actual Loss: 0.2618\n",
      "Baseline Loss: 2.6527 | Actual Loss: 0.2820\n",
      "Baseline Loss: 2.6935 | Actual Loss: 0.4748\n",
      "Baseline Loss: 2.6833 | Actual Loss: 0.3822\n",
      "Baseline Loss: 2.6443 | Actual Loss: 0.2086\n",
      "Baseline Loss: 2.6952 | Actual Loss: 0.2572\n",
      "Baseline Loss: 2.6955 | Actual Loss: 0.5850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 65/1000 [00:30<07:04,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6563 | Actual Loss: 0.2652\n",
      "Baseline Loss: 2.6778 | Actual Loss: 0.2540\n",
      "Baseline Loss: 2.6998 | Actual Loss: 0.3295\n",
      "Baseline Loss: 2.6790 | Actual Loss: 0.2637\n",
      "Baseline Loss: 2.6714 | Actual Loss: 0.3008\n",
      "Baseline Loss: 2.3014 | Actual Loss: 0.3170\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.6029\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.5213\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.4090\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3596\n",
      "Epoch 65/1000: Train Loss: 0.3346, Val Loss: 0.4732\n",
      "Baseline Loss: 2.6739 | Actual Loss: 0.4110\n",
      "Baseline Loss: 2.6369 | Actual Loss: 0.2824\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3418\n",
      "Baseline Loss: 2.6847 | Actual Loss: 0.1275\n",
      "Baseline Loss: 2.7066 | Actual Loss: 0.2787\n",
      "Baseline Loss: 2.7218 | Actual Loss: 0.2931\n",
      "Baseline Loss: 2.6416 | Actual Loss: 0.3766\n",
      "Baseline Loss: 2.6811 | Actual Loss: 0.3820\n",
      "Baseline Loss: 2.6688 | Actual Loss: 0.3797\n",
      "Baseline Loss: 2.7110 | Actual Loss: 0.2720\n",
      "Baseline Loss: 2.6616 | Actual Loss: 0.2926\n",
      "Baseline Loss: 2.6701 | Actual Loss: 0.2710\n",
      "Baseline Loss: 2.6368 | Actual Loss: 0.3895\n",
      "Baseline Loss: 2.6800 | Actual Loss: 0.5513\n",
      "Baseline Loss: 2.6860 | Actual Loss: 1.4258\n",
      "Baseline Loss: 2.2563 | Actual Loss: 0.1688\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.6792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 66/1000 [00:31<07:15,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6990 | Actual Loss: 0.4609\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3041\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4321\n",
      "Epoch 66/1000: Train Loss: 0.3902, Val Loss: 0.4690\n",
      "Baseline Loss: 2.6815 | Actual Loss: 0.4320\n",
      "Baseline Loss: 2.7157 | Actual Loss: 0.1678\n",
      "Baseline Loss: 2.6761 | Actual Loss: 0.3523\n",
      "Baseline Loss: 2.6762 | Actual Loss: 0.4022\n",
      "Baseline Loss: 2.6496 | Actual Loss: 0.3282\n",
      "Baseline Loss: 2.6468 | Actual Loss: 0.2515\n",
      "Baseline Loss: 2.6401 | Actual Loss: 0.4508\n",
      "Baseline Loss: 2.6928 | Actual Loss: 0.2913\n",
      "Baseline Loss: 2.6766 | Actual Loss: 0.2741\n",
      "Baseline Loss: 2.6808 | Actual Loss: 0.4077\n",
      "Baseline Loss: 2.6728 | Actual Loss: 0.3161\n",
      "Baseline Loss: 2.7164 | Actual Loss: 0.2133\n",
      "Baseline Loss: 2.6889 | Actual Loss: 0.4475\n",
      "Baseline Loss: 2.6838 | Actual Loss: 0.2245\n",
      "Baseline Loss: 2.6718 | Actual Loss: 0.2847\n",
      "Baseline Loss: 2.2634 | Actual Loss: 0.1245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 67/1000 [00:31<07:06,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6857 | Actual Loss: 0.7737\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.5110\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3833\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4954\n",
      "Epoch 67/1000: Train Loss: 0.3105, Val Loss: 0.5409\n",
      "Baseline Loss: 2.6997 | Actual Loss: 0.3805\n",
      "Baseline Loss: 2.6370 | Actual Loss: 0.4312\n",
      "Baseline Loss: 2.6725 | Actual Loss: 0.3210\n",
      "Baseline Loss: 2.6816 | Actual Loss: 0.4461\n",
      "Baseline Loss: 2.6811 | Actual Loss: 0.3817\n",
      "Baseline Loss: 2.6702 | Actual Loss: 0.4614\n",
      "Baseline Loss: 2.6823 | Actual Loss: 0.1993\n",
      "Baseline Loss: 2.6900 | Actual Loss: 0.4332\n",
      "Baseline Loss: 2.6583 | Actual Loss: 0.2841\n",
      "Baseline Loss: 2.6533 | Actual Loss: 0.2343\n",
      "Baseline Loss: 2.6582 | Actual Loss: 0.4810\n",
      "Baseline Loss: 2.6412 | Actual Loss: 0.2424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 68/1000 [00:32<07:25,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6998 | Actual Loss: 0.2760\n",
      "Baseline Loss: 2.6756 | Actual Loss: 0.3900\n",
      "Baseline Loss: 2.6676 | Actual Loss: 0.2277\n",
      "Baseline Loss: 2.2582 | Actual Loss: 0.1843\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.6385\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.5179\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.4113\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3913\n",
      "Epoch 68/1000: Train Loss: 0.3359, Val Loss: 0.4897\n",
      "Baseline Loss: 2.6598 | Actual Loss: 0.3983\n",
      "Baseline Loss: 2.6923 | Actual Loss: 0.4350\n",
      "Baseline Loss: 2.6931 | Actual Loss: 0.5204\n",
      "Baseline Loss: 2.6490 | Actual Loss: 0.5523\n",
      "Baseline Loss: 2.6579 | Actual Loss: 0.3206\n",
      "Baseline Loss: 2.6793 | Actual Loss: 0.2265\n",
      "Baseline Loss: 2.6652 | Actual Loss: 0.2802\n",
      "Baseline Loss: 2.6676 | Actual Loss: 0.1774\n",
      "Baseline Loss: 2.6792 | Actual Loss: 0.4854\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.3047\n",
      "Baseline Loss: 2.6575 | Actual Loss: 0.3795\n",
      "Baseline Loss: 2.6469 | Actual Loss: 0.3372\n",
      "Baseline Loss: 2.6724 | Actual Loss: 0.3850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 69/1000 [00:32<07:24,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6468 | Actual Loss: 0.3121\n",
      "Baseline Loss: 2.7061 | Actual Loss: 0.2982\n",
      "Baseline Loss: 2.2415 | Actual Loss: 0.1858\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.6119\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.4921\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3447\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4032\n",
      "Epoch 69/1000: Train Loss: 0.3499, Val Loss: 0.4630\n",
      "Baseline Loss: 2.6988 | Actual Loss: 0.4535\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.2996\n",
      "Baseline Loss: 2.6681 | Actual Loss: 0.3271\n",
      "Baseline Loss: 2.6869 | Actual Loss: 0.3244\n",
      "Baseline Loss: 2.6283 | Actual Loss: 0.2562\n",
      "Baseline Loss: 2.6721 | Actual Loss: 0.2821\n",
      "Baseline Loss: 2.6793 | Actual Loss: 0.3198\n",
      "Baseline Loss: 2.6958 | Actual Loss: 0.4465\n",
      "Baseline Loss: 2.6745 | Actual Loss: 0.4046\n",
      "Baseline Loss: 2.6497 | Actual Loss: 0.3412\n",
      "Baseline Loss: 2.6806 | Actual Loss: 0.3612\n",
      "Baseline Loss: 2.6789 | Actual Loss: 0.1979\n",
      "Baseline Loss: 2.6988 | Actual Loss: 0.1644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 70/1000 [00:33<07:12,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7103 | Actual Loss: 0.3517\n",
      "Baseline Loss: 2.6543 | Actual Loss: 0.3584\n",
      "Baseline Loss: 2.2449 | Actual Loss: 0.1457\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.6531\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.5237\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3153\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4268\n",
      "Epoch 70/1000: Train Loss: 0.3146, Val Loss: 0.4797\n",
      "Baseline Loss: 2.6726 | Actual Loss: 0.5560\n",
      "Baseline Loss: 2.6762 | Actual Loss: 0.3083\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.2415\n",
      "Baseline Loss: 2.6485 | Actual Loss: 0.2853\n",
      "Baseline Loss: 2.6962 | Actual Loss: 0.2222\n",
      "Baseline Loss: 2.6680 | Actual Loss: 0.2679\n",
      "Baseline Loss: 2.6696 | Actual Loss: 0.2722\n",
      "Baseline Loss: 2.7071 | Actual Loss: 0.2779\n",
      "Baseline Loss: 2.6717 | Actual Loss: 0.2963\n",
      "Baseline Loss: 2.7067 | Actual Loss: 0.2392\n",
      "Baseline Loss: 2.6516 | Actual Loss: 0.2330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 71/1000 [00:33<07:23,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6730 | Actual Loss: 0.3383\n",
      "Baseline Loss: 2.6411 | Actual Loss: 0.3367\n",
      "Baseline Loss: 2.6799 | Actual Loss: 0.3036\n",
      "Baseline Loss: 2.6692 | Actual Loss: 0.3351\n",
      "Baseline Loss: 2.1726 | Actual Loss: 0.2901\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5958\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.5539\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.4050\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4923\n",
      "Epoch 71/1000: Train Loss: 0.3002, Val Loss: 0.5117\n",
      "Baseline Loss: 2.6549 | Actual Loss: 0.3169\n",
      "Baseline Loss: 2.6525 | Actual Loss: 0.4022\n",
      "Baseline Loss: 2.6885 | Actual Loss: 0.4515\n",
      "Baseline Loss: 2.6582 | Actual Loss: 0.4235\n",
      "Baseline Loss: 2.6250 | Actual Loss: 0.3243\n",
      "Baseline Loss: 2.6848 | Actual Loss: 0.3397\n",
      "Baseline Loss: 2.6917 | Actual Loss: 0.3543\n",
      "Baseline Loss: 2.6892 | Actual Loss: 0.5165\n",
      "Baseline Loss: 2.6563 | Actual Loss: 0.5137\n",
      "Baseline Loss: 2.7097 | Actual Loss: 0.3901\n",
      "Baseline Loss: 2.6707 | Actual Loss: 0.1967\n",
      "Baseline Loss: 2.6778 | Actual Loss: 0.7173\n",
      "Baseline Loss: 2.6730 | Actual Loss: 0.4600\n",
      "Baseline Loss: 2.6602 | Actual Loss: 0.6049\n",
      "Baseline Loss: 2.6894 | Actual Loss: 0.4226\n",
      "Baseline Loss: 2.2600 | Actual Loss: 0.1953\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4456\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.5670\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.4174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 72/1000 [00:34<07:22,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6194 | Actual Loss: 0.4026\n",
      "Epoch 72/1000: Train Loss: 0.4143, Val Loss: 0.4581\n",
      "Baseline Loss: 2.6456 | Actual Loss: 0.4542\n",
      "Baseline Loss: 2.6846 | Actual Loss: 0.3827\n",
      "Baseline Loss: 2.6544 | Actual Loss: 0.3448\n",
      "Baseline Loss: 2.6559 | Actual Loss: 0.2870\n",
      "Baseline Loss: 2.7030 | Actual Loss: 0.3529\n",
      "Baseline Loss: 2.6259 | Actual Loss: 0.4072\n",
      "Baseline Loss: 2.7007 | Actual Loss: 0.2198\n",
      "Baseline Loss: 2.6619 | Actual Loss: 0.3229\n",
      "Baseline Loss: 2.7335 | Actual Loss: 0.2749\n",
      "Baseline Loss: 2.6981 | Actual Loss: 0.4038\n",
      "Baseline Loss: 2.7114 | Actual Loss: 0.3979\n",
      "Baseline Loss: 2.6629 | Actual Loss: 0.3207\n",
      "Baseline Loss: 2.6302 | Actual Loss: 0.3062\n",
      "Baseline Loss: 2.6883 | Actual Loss: 0.3486\n",
      "Baseline Loss: 2.6572 | Actual Loss: 0.3557\n",
      "Baseline Loss: 2.2850 | Actual Loss: 0.1878\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4134\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.5001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 73/1000 [00:34<07:34,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6381 | Actual Loss: 0.3466\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3941\n",
      "Epoch 73/1000: Train Loss: 0.3354, Val Loss: 0.4135\n",
      "New best validation loss: 0.4135\n",
      "Baseline Loss: 2.6750 | Actual Loss: 0.3227\n",
      "Baseline Loss: 2.6631 | Actual Loss: 0.3105\n",
      "Baseline Loss: 2.6693 | Actual Loss: 0.2348\n",
      "Baseline Loss: 2.6750 | Actual Loss: 0.4968\n",
      "Baseline Loss: 2.6662 | Actual Loss: 0.5008\n",
      "Baseline Loss: 2.6723 | Actual Loss: 0.2460\n",
      "Baseline Loss: 2.7291 | Actual Loss: 0.3913\n",
      "Baseline Loss: 2.6705 | Actual Loss: 0.1522\n",
      "Baseline Loss: 2.6843 | Actual Loss: 0.3304\n",
      "Baseline Loss: 2.7056 | Actual Loss: 0.6189\n",
      "Baseline Loss: 2.7131 | Actual Loss: 0.1850\n",
      "Baseline Loss: 2.6626 | Actual Loss: 0.3733\n",
      "Baseline Loss: 2.6876 | Actual Loss: 0.2655\n",
      "Baseline Loss: 2.6829 | Actual Loss: 0.3434\n",
      "Baseline Loss: 2.6285 | Actual Loss: 0.6236\n",
      "Baseline Loss: 2.2581 | Actual Loss: 0.1349\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5491\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.5354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 74/1000 [00:34<07:11,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6381 | Actual Loss: 0.4577\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4100\n",
      "Epoch 74/1000: Train Loss: 0.3456, Val Loss: 0.4880\n",
      "Baseline Loss: 2.6707 | Actual Loss: 0.3781\n",
      "Baseline Loss: 2.6431 | Actual Loss: 0.3488\n",
      "Baseline Loss: 2.7173 | Actual Loss: 0.3118\n",
      "Baseline Loss: 2.6523 | Actual Loss: 0.2906\n",
      "Baseline Loss: 2.6635 | Actual Loss: 0.4689\n",
      "Baseline Loss: 2.6440 | Actual Loss: 0.3907\n",
      "Baseline Loss: 2.6841 | Actual Loss: 0.3185\n",
      "Baseline Loss: 2.6679 | Actual Loss: 0.2868\n",
      "Baseline Loss: 2.7095 | Actual Loss: 0.3709\n",
      "Baseline Loss: 2.6938 | Actual Loss: 0.4388\n",
      "Baseline Loss: 2.6823 | Actual Loss: 0.6153\n",
      "Baseline Loss: 2.6592 | Actual Loss: 0.4557\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.3014\n",
      "Baseline Loss: 2.6487 | Actual Loss: 0.4571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 75/1000 [00:35<07:14,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7046 | Actual Loss: 0.3475\n",
      "Baseline Loss: 2.2426 | Actual Loss: 0.1883\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4968\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.4557\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3582\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4843\n",
      "Epoch 75/1000: Train Loss: 0.3731, Val Loss: 0.4487\n",
      "Baseline Loss: 2.6620 | Actual Loss: 0.5219\n",
      "Baseline Loss: 2.6637 | Actual Loss: 0.2589\n",
      "Baseline Loss: 2.6995 | Actual Loss: 0.2955\n",
      "Baseline Loss: 2.6685 | Actual Loss: 0.3124\n",
      "Baseline Loss: 2.7298 | Actual Loss: 0.7141\n",
      "Baseline Loss: 2.6562 | Actual Loss: 0.2612\n",
      "Baseline Loss: 2.6885 | Actual Loss: 0.2039\n",
      "Baseline Loss: 2.6609 | Actual Loss: 0.2078\n",
      "Baseline Loss: 2.6762 | Actual Loss: 0.3500\n",
      "Baseline Loss: 2.6368 | Actual Loss: 0.4116\n",
      "Baseline Loss: 2.6706 | Actual Loss: 0.3032\n",
      "Baseline Loss: 2.6693 | Actual Loss: 0.3959\n",
      "Baseline Loss: 2.6973 | Actual Loss: 0.4338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 76/1000 [00:35<07:35,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6838 | Actual Loss: 0.3576\n",
      "Baseline Loss: 2.6549 | Actual Loss: 0.3878\n",
      "Baseline Loss: 2.2585 | Actual Loss: 0.1367\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.6376\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.4496\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3402\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3594\n",
      "Epoch 76/1000: Train Loss: 0.3470, Val Loss: 0.4467\n",
      "Baseline Loss: 2.6745 | Actual Loss: 0.2546\n",
      "Baseline Loss: 2.6693 | Actual Loss: 0.3207\n",
      "Baseline Loss: 2.6966 | Actual Loss: 0.4491\n",
      "Baseline Loss: 2.7157 | Actual Loss: 0.2456\n",
      "Baseline Loss: 2.6705 | Actual Loss: 0.3478\n",
      "Baseline Loss: 2.6574 | Actual Loss: 0.2970\n",
      "Baseline Loss: 2.7296 | Actual Loss: 0.3742\n",
      "Baseline Loss: 2.6636 | Actual Loss: 0.1825\n",
      "Baseline Loss: 2.6827 | Actual Loss: 0.3131\n",
      "Baseline Loss: 2.6705 | Actual Loss: 0.2212\n",
      "Baseline Loss: 2.6407 | Actual Loss: 0.3968\n",
      "Baseline Loss: 2.6533 | Actual Loss: 0.3974\n",
      "Baseline Loss: 2.6785 | Actual Loss: 0.3614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 77/1000 [00:36<07:09,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6904 | Actual Loss: 0.3172\n",
      "Baseline Loss: 2.6401 | Actual Loss: 0.2720\n",
      "Baseline Loss: 2.2434 | Actual Loss: 0.0558\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5818\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.4886\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.4349\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3907\n",
      "Epoch 77/1000: Train Loss: 0.3004, Val Loss: 0.4740\n",
      "Baseline Loss: 2.6824 | Actual Loss: 0.1808\n",
      "Baseline Loss: 2.6595 | Actual Loss: 0.4569\n",
      "Baseline Loss: 2.6842 | Actual Loss: 0.2705\n",
      "Baseline Loss: 2.6979 | Actual Loss: 0.2745\n",
      "Baseline Loss: 2.6552 | Actual Loss: 0.2910\n",
      "Baseline Loss: 2.6774 | Actual Loss: 0.4355\n",
      "Baseline Loss: 2.6478 | Actual Loss: 0.2935\n",
      "Baseline Loss: 2.6804 | Actual Loss: 0.2841\n",
      "Baseline Loss: 2.6797 | Actual Loss: 0.2534\n",
      "Baseline Loss: 2.6819 | Actual Loss: 0.2703\n",
      "Baseline Loss: 2.6966 | Actual Loss: 0.2283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 78/1000 [00:36<07:14,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6639 | Actual Loss: 0.3119\n",
      "Baseline Loss: 2.6528 | Actual Loss: 0.8693\n",
      "Baseline Loss: 2.6772 | Actual Loss: 0.3508\n",
      "Baseline Loss: 2.6991 | Actual Loss: 0.3813\n",
      "Baseline Loss: 2.2936 | Actual Loss: 0.3437\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5862\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.4735\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2995\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4186\n",
      "Epoch 78/1000: Train Loss: 0.3435, Val Loss: 0.4445\n",
      "Baseline Loss: 2.6913 | Actual Loss: 0.5020\n",
      "Baseline Loss: 2.6664 | Actual Loss: 0.3111\n",
      "Baseline Loss: 2.7043 | Actual Loss: 0.2477\n",
      "Baseline Loss: 2.6766 | Actual Loss: 0.2602\n",
      "Baseline Loss: 2.6520 | Actual Loss: 0.2461\n",
      "Baseline Loss: 2.6517 | Actual Loss: 0.2892\n",
      "Baseline Loss: 2.6495 | Actual Loss: 0.3954\n",
      "Baseline Loss: 2.6586 | Actual Loss: 0.3850\n",
      "Baseline Loss: 2.7076 | Actual Loss: 0.5259\n",
      "Baseline Loss: 2.6718 | Actual Loss: 0.2293\n",
      "Baseline Loss: 2.6886 | Actual Loss: 0.1928\n",
      "Baseline Loss: 2.6675 | Actual Loss: 0.2689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 79/1000 [00:37<07:26,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6494 | Actual Loss: 0.4752\n",
      "Baseline Loss: 2.6736 | Actual Loss: 0.2854\n",
      "Baseline Loss: 2.6892 | Actual Loss: 0.3468\n",
      "Baseline Loss: 2.2666 | Actual Loss: 0.3697\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.6421\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.4740\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3280\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3750\n",
      "Epoch 79/1000: Train Loss: 0.3332, Val Loss: 0.4548\n",
      "Baseline Loss: 2.6558 | Actual Loss: 0.2380\n",
      "Baseline Loss: 2.6863 | Actual Loss: 0.3341\n",
      "Baseline Loss: 2.6876 | Actual Loss: 0.3620\n",
      "Baseline Loss: 2.6597 | Actual Loss: 0.1691\n",
      "Baseline Loss: 2.6550 | Actual Loss: 0.1312\n",
      "Baseline Loss: 2.6952 | Actual Loss: 0.2113\n",
      "Baseline Loss: 2.6883 | Actual Loss: 0.2756\n",
      "Baseline Loss: 2.6401 | Actual Loss: 0.3558\n",
      "Baseline Loss: 2.6665 | Actual Loss: 0.3512\n",
      "Baseline Loss: 2.6741 | Actual Loss: 0.3740\n",
      "Baseline Loss: 2.6227 | Actual Loss: 0.3643\n",
      "Baseline Loss: 2.6906 | Actual Loss: 0.2562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 80/1000 [00:37<07:01,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6684 | Actual Loss: 0.3195\n",
      "Baseline Loss: 2.7132 | Actual Loss: 0.4692\n",
      "Baseline Loss: 2.6561 | Actual Loss: 0.3420\n",
      "Baseline Loss: 2.3153 | Actual Loss: 0.2566\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.6033\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.4561\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3580\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4643\n",
      "Epoch 80/1000: Train Loss: 0.3006, Val Loss: 0.4704\n",
      "Baseline Loss: 2.6659 | Actual Loss: 0.2690\n",
      "Baseline Loss: 2.7208 | Actual Loss: 0.2835\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.3254\n",
      "Baseline Loss: 2.7007 | Actual Loss: 0.2863\n",
      "Baseline Loss: 2.6589 | Actual Loss: 0.1731\n",
      "Baseline Loss: 2.6665 | Actual Loss: 0.4364\n",
      "Baseline Loss: 2.7007 | Actual Loss: 0.4226\n",
      "Baseline Loss: 2.6604 | Actual Loss: 0.2869\n",
      "Baseline Loss: 2.6864 | Actual Loss: 0.2830\n",
      "Baseline Loss: 2.6564 | Actual Loss: 0.4359\n",
      "Baseline Loss: 2.6539 | Actual Loss: 0.4658\n",
      "Baseline Loss: 2.6525 | Actual Loss: 0.3325\n",
      "Baseline Loss: 2.7237 | Actual Loss: 0.2747\n",
      "Baseline Loss: 2.6533 | Actual Loss: 0.3933\n",
      "Baseline Loss: 2.6937 | Actual Loss: 0.4614\n",
      "Baseline Loss: 2.2391 | Actual Loss: 0.2573\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4324\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.5736\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.4722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 81/1000 [00:38<07:18,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6194 | Actual Loss: 0.4677\n",
      "Epoch 81/1000: Train Loss: 0.3367, Val Loss: 0.4865\n",
      "Baseline Loss: 2.6612 | Actual Loss: 0.3060\n",
      "Baseline Loss: 2.7009 | Actual Loss: 0.4200\n",
      "Baseline Loss: 2.6556 | Actual Loss: 0.2444\n",
      "Baseline Loss: 2.6852 | Actual Loss: 0.3439\n",
      "Baseline Loss: 2.6503 | Actual Loss: 0.3129\n",
      "Baseline Loss: 2.6871 | Actual Loss: 0.2133\n",
      "Baseline Loss: 2.6631 | Actual Loss: 0.4029\n",
      "Baseline Loss: 2.6664 | Actual Loss: 0.4837\n",
      "Baseline Loss: 2.6665 | Actual Loss: 0.3486\n",
      "Baseline Loss: 2.7217 | Actual Loss: 0.2634\n",
      "Baseline Loss: 2.6420 | Actual Loss: 0.2333\n",
      "Baseline Loss: 2.6720 | Actual Loss: 0.2805\n",
      "Baseline Loss: 2.6964 | Actual Loss: 0.1541\n",
      "Baseline Loss: 2.7064 | Actual Loss: 0.3771\n",
      "Baseline Loss: 2.6652 | Actual Loss: 0.2417\n",
      "Baseline Loss: 2.2318 | Actual Loss: 0.2013\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.6189\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.4614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 82/1000 [00:38<07:16,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6381 | Actual Loss: 0.3421\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3588\n",
      "Epoch 82/1000: Train Loss: 0.3017, Val Loss: 0.4453\n",
      "Baseline Loss: 2.6844 | Actual Loss: 0.4436\n",
      "Baseline Loss: 2.6318 | Actual Loss: 0.2363\n",
      "Baseline Loss: 2.6531 | Actual Loss: 0.2524\n",
      "Baseline Loss: 2.6784 | Actual Loss: 0.4827\n",
      "Baseline Loss: 2.6593 | Actual Loss: 0.5564\n",
      "Baseline Loss: 2.7044 | Actual Loss: 0.2676\n",
      "Baseline Loss: 2.6633 | Actual Loss: 0.3171\n",
      "Baseline Loss: 2.6931 | Actual Loss: 0.3251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 83/1000 [00:39<06:52,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7022 | Actual Loss: 0.5005\n",
      "Baseline Loss: 2.6649 | Actual Loss: 0.2965\n",
      "Baseline Loss: 2.6916 | Actual Loss: 0.3336\n",
      "Baseline Loss: 2.6654 | Actual Loss: 0.2324\n",
      "Baseline Loss: 2.6982 | Actual Loss: 0.4582\n",
      "Baseline Loss: 2.6510 | Actual Loss: 0.2599\n",
      "Baseline Loss: 2.6818 | Actual Loss: 0.3158\n",
      "Baseline Loss: 2.2435 | Actual Loss: 0.1162\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5303\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3826\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.4058\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4449\n",
      "Epoch 83/1000: Train Loss: 0.3371, Val Loss: 0.4409\n",
      "Baseline Loss: 2.7186 | Actual Loss: 0.2787\n",
      "Baseline Loss: 2.6535 | Actual Loss: 0.3403\n",
      "Baseline Loss: 2.6588 | Actual Loss: 0.1668\n",
      "Baseline Loss: 2.6310 | Actual Loss: 0.4400\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.3385\n",
      "Baseline Loss: 2.6622 | Actual Loss: 0.3719\n",
      "Baseline Loss: 2.7083 | Actual Loss: 0.2859\n",
      "Baseline Loss: 2.6408 | Actual Loss: 0.3576\n",
      "Baseline Loss: 2.6841 | Actual Loss: 0.2340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 84/1000 [00:39<07:05,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6809 | Actual Loss: 0.3174\n",
      "Baseline Loss: 2.6884 | Actual Loss: 0.3564\n",
      "Baseline Loss: 2.6531 | Actual Loss: 0.3999\n",
      "Baseline Loss: 2.6442 | Actual Loss: 0.4634\n",
      "Baseline Loss: 2.6512 | Actual Loss: 0.2455\n",
      "Baseline Loss: 2.6942 | Actual Loss: 0.2914\n",
      "Baseline Loss: 2.2731 | Actual Loss: 0.1975\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4904\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.4344\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.4072\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4225\n",
      "Epoch 84/1000: Train Loss: 0.3178, Val Loss: 0.4386\n",
      "Baseline Loss: 2.6724 | Actual Loss: 0.2621\n",
      "Baseline Loss: 2.6744 | Actual Loss: 0.3234\n",
      "Baseline Loss: 2.6643 | Actual Loss: 0.2425\n",
      "Baseline Loss: 2.6380 | Actual Loss: 0.3865\n",
      "Baseline Loss: 2.6651 | Actual Loss: 0.2100\n",
      "Baseline Loss: 2.6767 | Actual Loss: 0.2591\n",
      "Baseline Loss: 2.7128 | Actual Loss: 0.1643\n",
      "Baseline Loss: 2.6702 | Actual Loss: 0.5149\n",
      "Baseline Loss: 2.6672 | Actual Loss: 0.4739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 85/1000 [00:40<06:50,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6620 | Actual Loss: 0.2947\n",
      "Baseline Loss: 2.6709 | Actual Loss: 0.1695\n",
      "Baseline Loss: 2.6607 | Actual Loss: 0.2785\n",
      "Baseline Loss: 2.7108 | Actual Loss: 0.1967\n",
      "Baseline Loss: 2.6513 | Actual Loss: 0.4969\n",
      "Baseline Loss: 2.6987 | Actual Loss: 0.4097\n",
      "Baseline Loss: 2.3086 | Actual Loss: 0.1492\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5414\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3471\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3481\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3771\n",
      "Epoch 85/1000: Train Loss: 0.3020, Val Loss: 0.4034\n",
      "New best validation loss: 0.4034\n",
      "Baseline Loss: 2.6715 | Actual Loss: 0.3815\n",
      "Baseline Loss: 2.6582 | Actual Loss: 0.1685\n",
      "Baseline Loss: 2.6591 | Actual Loss: 0.2601\n",
      "Baseline Loss: 2.6552 | Actual Loss: 0.4984\n",
      "Baseline Loss: 2.6735 | Actual Loss: 0.1633\n",
      "Baseline Loss: 2.6692 | Actual Loss: 0.2227\n",
      "Baseline Loss: 2.6607 | Actual Loss: 0.2660\n",
      "Baseline Loss: 2.7390 | Actual Loss: 0.3476\n",
      "Baseline Loss: 2.7081 | Actual Loss: 0.1841\n",
      "Baseline Loss: 2.6388 | Actual Loss: 0.3402\n",
      "Baseline Loss: 2.6631 | Actual Loss: 0.2193\n",
      "Baseline Loss: 2.6686 | Actual Loss: 0.3553\n",
      "Baseline Loss: 2.6423 | Actual Loss: 0.3147\n",
      "Baseline Loss: 2.6595 | Actual Loss: 0.2512\n",
      "Baseline Loss: 2.6893 | Actual Loss: 0.4740\n",
      "Baseline Loss: 2.2731 | Actual Loss: 0.2178\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5211\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.5907\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▊         | 86/1000 [00:40<06:55,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6194 | Actual Loss: 0.4301\n",
      "Epoch 86/1000: Train Loss: 0.2915, Val Loss: 0.4850\n",
      "Baseline Loss: 2.6933 | Actual Loss: 1.4616\n",
      "Baseline Loss: 2.6696 | Actual Loss: 0.2159\n",
      "Baseline Loss: 2.6625 | Actual Loss: 0.2104\n",
      "Baseline Loss: 2.6619 | Actual Loss: 0.2571\n",
      "Baseline Loss: 2.6688 | Actual Loss: 0.3782\n",
      "Baseline Loss: 2.6587 | Actual Loss: 0.3548\n",
      "Baseline Loss: 2.6697 | Actual Loss: 0.2594\n",
      "Baseline Loss: 2.6689 | Actual Loss: 0.3125\n",
      "Baseline Loss: 2.6811 | Actual Loss: 0.2543\n",
      "Baseline Loss: 2.6279 | Actual Loss: 0.1725\n",
      "Baseline Loss: 2.6594 | Actual Loss: 0.2195\n",
      "Baseline Loss: 2.6958 | Actual Loss: 0.3194\n",
      "Baseline Loss: 2.6945 | Actual Loss: 0.2016\n",
      "Baseline Loss: 2.6742 | Actual Loss: 0.4459\n",
      "Baseline Loss: 2.7086 | Actual Loss: 0.4061\n",
      "Baseline Loss: 2.2477 | Actual Loss: 0.0938\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5415\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.4527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▊         | 87/1000 [00:40<06:50,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6381 | Actual Loss: 0.4872\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3960\n",
      "Epoch 87/1000: Train Loss: 0.3477, Val Loss: 0.4693\n",
      "Baseline Loss: 2.6743 | Actual Loss: 0.1325\n",
      "Baseline Loss: 2.6476 | Actual Loss: 0.2969\n",
      "Baseline Loss: 2.6725 | Actual Loss: 0.3919\n",
      "Baseline Loss: 2.6633 | Actual Loss: 0.3486\n",
      "Baseline Loss: 2.6820 | Actual Loss: 0.2423\n",
      "Baseline Loss: 2.6672 | Actual Loss: 0.4072\n",
      "Baseline Loss: 2.6835 | Actual Loss: 0.3762\n",
      "Baseline Loss: 2.7430 | Actual Loss: 0.2318\n",
      "Baseline Loss: 2.7109 | Actual Loss: 0.3675\n",
      "Baseline Loss: 2.7072 | Actual Loss: 0.3118\n",
      "Baseline Loss: 2.6707 | Actual Loss: 0.2391\n",
      "Baseline Loss: 2.6702 | Actual Loss: 0.3003\n",
      "Baseline Loss: 2.6863 | Actual Loss: 0.2427\n",
      "Baseline Loss: 2.6658 | Actual Loss: 0.2083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 88/1000 [00:41<07:00,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6583 | Actual Loss: 0.3171\n",
      "Baseline Loss: 2.2874 | Actual Loss: 0.3047\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5707\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.5038\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3474\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3918\n",
      "Epoch 88/1000: Train Loss: 0.2949, Val Loss: 0.4534\n",
      "Baseline Loss: 2.7132 | Actual Loss: 0.2947\n",
      "Baseline Loss: 2.6633 | Actual Loss: 0.2353\n",
      "Baseline Loss: 2.6718 | Actual Loss: 0.3901\n",
      "Baseline Loss: 2.6870 | Actual Loss: 0.3131\n",
      "Baseline Loss: 2.6660 | Actual Loss: 0.2777\n",
      "Baseline Loss: 2.7084 | Actual Loss: 0.4516\n",
      "Baseline Loss: 2.6603 | Actual Loss: 0.2466\n",
      "Baseline Loss: 2.6871 | Actual Loss: 0.1271\n",
      "Baseline Loss: 2.6295 | Actual Loss: 0.3924\n",
      "Baseline Loss: 2.6872 | Actual Loss: 0.2570\n",
      "Baseline Loss: 2.6965 | Actual Loss: 0.2860\n",
      "Baseline Loss: 2.7070 | Actual Loss: 0.3489\n",
      "Baseline Loss: 2.6858 | Actual Loss: 0.4079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 89/1000 [00:41<07:13,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7133 | Actual Loss: 0.3604\n",
      "Baseline Loss: 2.6333 | Actual Loss: 0.3184\n",
      "Baseline Loss: 2.2456 | Actual Loss: 0.2431\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4597\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.4361\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2585\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4485\n",
      "Epoch 89/1000: Train Loss: 0.3094, Val Loss: 0.4007\n",
      "New best validation loss: 0.4007\n",
      "Baseline Loss: 2.6869 | Actual Loss: 0.2448\n",
      "Baseline Loss: 2.6582 | Actual Loss: 0.3494\n",
      "Baseline Loss: 2.6603 | Actual Loss: 0.2111\n",
      "Baseline Loss: 2.6751 | Actual Loss: 0.5185\n",
      "Baseline Loss: 2.6776 | Actual Loss: 0.8382\n",
      "Baseline Loss: 2.6668 | Actual Loss: 0.1989\n",
      "Baseline Loss: 2.6725 | Actual Loss: 0.1828\n",
      "Baseline Loss: 2.6661 | Actual Loss: 0.2084\n",
      "Baseline Loss: 2.6952 | Actual Loss: 0.1786\n",
      "Baseline Loss: 2.6879 | Actual Loss: 0.3526\n",
      "Baseline Loss: 2.7237 | Actual Loss: 0.2760\n",
      "Baseline Loss: 2.6717 | Actual Loss: 0.2278\n",
      "Baseline Loss: 2.6202 | Actual Loss: 0.2991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 90/1000 [00:42<07:03,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6424 | Actual Loss: 0.2060\n",
      "Baseline Loss: 2.6805 | Actual Loss: 0.2646\n",
      "Baseline Loss: 2.2417 | Actual Loss: 0.2372\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5409\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.5268\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.5555\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.5937\n",
      "Epoch 90/1000: Train Loss: 0.2996, Val Loss: 0.5542\n",
      "Baseline Loss: 2.6872 | Actual Loss: 0.2505\n",
      "Baseline Loss: 2.6879 | Actual Loss: 0.3859\n",
      "Baseline Loss: 2.6305 | Actual Loss: 0.5609\n",
      "Baseline Loss: 2.6635 | Actual Loss: 0.3145\n",
      "Baseline Loss: 2.6866 | Actual Loss: 0.2638\n",
      "Baseline Loss: 2.6741 | Actual Loss: 0.2994\n",
      "Baseline Loss: 2.6905 | Actual Loss: 0.1931\n",
      "Baseline Loss: 2.6264 | Actual Loss: 0.3234\n",
      "Baseline Loss: 2.6596 | Actual Loss: 0.2712\n",
      "Baseline Loss: 2.6934 | Actual Loss: 0.3539\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.3934\n",
      "Baseline Loss: 2.7248 | Actual Loss: 0.2863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 91/1000 [00:42<07:09,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6642 | Actual Loss: 0.2310\n",
      "Baseline Loss: 2.6491 | Actual Loss: 0.2883\n",
      "Baseline Loss: 2.6718 | Actual Loss: 0.2836\n",
      "Baseline Loss: 2.3038 | Actual Loss: 0.0992\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4914\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.5169\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3468\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.5401\n",
      "Epoch 91/1000: Train Loss: 0.2999, Val Loss: 0.4738\n",
      "Baseline Loss: 2.6815 | Actual Loss: 0.3170\n",
      "Baseline Loss: 2.6986 | Actual Loss: 0.4856\n",
      "Baseline Loss: 2.6479 | Actual Loss: 0.5384\n",
      "Baseline Loss: 2.6947 | Actual Loss: 0.2712\n",
      "Baseline Loss: 2.7070 | Actual Loss: 0.1674\n",
      "Baseline Loss: 2.6743 | Actual Loss: 0.1952\n",
      "Baseline Loss: 2.7111 | Actual Loss: 0.3749\n",
      "Baseline Loss: 2.6451 | Actual Loss: 0.1669\n",
      "Baseline Loss: 2.6508 | Actual Loss: 0.3658\n",
      "Baseline Loss: 2.6713 | Actual Loss: 0.3937\n",
      "Baseline Loss: 2.6654 | Actual Loss: 0.3785\n",
      "Baseline Loss: 2.6311 | Actual Loss: 0.2391\n",
      "Baseline Loss: 2.7171 | Actual Loss: 0.2258\n",
      "Baseline Loss: 2.6967 | Actual Loss: 0.4623\n",
      "Baseline Loss: 2.6467 | Actual Loss: 0.4153\n",
      "Baseline Loss: 2.2379 | Actual Loss: 0.3116\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5501\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.4451\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 92/1000 [00:43<07:19,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6194 | Actual Loss: 0.4017\n",
      "Epoch 92/1000: Train Loss: 0.3318, Val Loss: 0.4445\n",
      "Baseline Loss: 2.7005 | Actual Loss: 0.2689\n",
      "Baseline Loss: 2.6520 | Actual Loss: 0.2876\n",
      "Baseline Loss: 2.6843 | Actual Loss: 0.3961\n",
      "Baseline Loss: 2.6646 | Actual Loss: 0.4388\n",
      "Baseline Loss: 2.6682 | Actual Loss: 0.2735\n",
      "Baseline Loss: 2.6890 | Actual Loss: 0.1950\n",
      "Baseline Loss: 2.6711 | Actual Loss: 0.2548\n",
      "Baseline Loss: 2.6684 | Actual Loss: 0.2101\n",
      "Baseline Loss: 2.6724 | Actual Loss: 0.2957\n",
      "Baseline Loss: 2.6673 | Actual Loss: 0.2008\n",
      "Baseline Loss: 2.6928 | Actual Loss: 0.2914\n",
      "Baseline Loss: 2.6455 | Actual Loss: 0.2282\n",
      "Baseline Loss: 2.7176 | Actual Loss: 0.1769\n",
      "Baseline Loss: 2.7064 | Actual Loss: 0.4394\n",
      "Baseline Loss: 2.6584 | Actual Loss: 0.3274\n",
      "Baseline Loss: 2.2779 | Actual Loss: 0.3092\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 93/1000 [00:43<07:28,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6990 | Actual Loss: 0.4908\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3414\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4606\n",
      "Epoch 93/1000: Train Loss: 0.2871, Val Loss: 0.4279\n",
      "Baseline Loss: 2.6815 | Actual Loss: 0.2398\n",
      "Baseline Loss: 2.6786 | Actual Loss: 0.1814\n",
      "Baseline Loss: 2.6536 | Actual Loss: 0.1316\n",
      "Baseline Loss: 2.6557 | Actual Loss: 0.2412\n",
      "Baseline Loss: 2.6573 | Actual Loss: 0.4176\n",
      "Baseline Loss: 2.6555 | Actual Loss: 0.2160\n",
      "Baseline Loss: 2.6647 | Actual Loss: 0.3576\n",
      "Baseline Loss: 2.6887 | Actual Loss: 0.3515\n",
      "Baseline Loss: 2.6426 | Actual Loss: 0.2824\n",
      "Baseline Loss: 2.6479 | Actual Loss: 0.2855\n",
      "Baseline Loss: 2.6898 | Actual Loss: 0.3664\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.3271\n",
      "Baseline Loss: 2.6875 | Actual Loss: 0.3964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 94/1000 [00:44<07:02,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6668 | Actual Loss: 0.2242\n",
      "Baseline Loss: 2.6762 | Actual Loss: 0.2623\n",
      "Baseline Loss: 2.2981 | Actual Loss: 0.2849\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4664\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.4752\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.4562\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3272\n",
      "Epoch 94/1000: Train Loss: 0.2854, Val Loss: 0.4312\n",
      "Baseline Loss: 2.6764 | Actual Loss: 0.2264\n",
      "Baseline Loss: 2.6727 | Actual Loss: 0.4423\n",
      "Baseline Loss: 2.6677 | Actual Loss: 0.6466\n",
      "Baseline Loss: 2.7007 | Actual Loss: 0.1210\n",
      "Baseline Loss: 2.6646 | Actual Loss: 0.4392\n",
      "Baseline Loss: 2.6567 | Actual Loss: 0.5176\n",
      "Baseline Loss: 2.6571 | Actual Loss: 0.3066\n",
      "Baseline Loss: 2.6767 | Actual Loss: 0.1394\n",
      "Baseline Loss: 2.6880 | Actual Loss: 0.3507\n",
      "Baseline Loss: 2.6613 | Actual Loss: 0.2727\n",
      "Baseline Loss: 2.6659 | Actual Loss: 0.1747\n",
      "Baseline Loss: 2.6827 | Actual Loss: 0.3070\n",
      "Baseline Loss: 2.6660 | Actual Loss: 0.3058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 95/1000 [00:44<07:12,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6749 | Actual Loss: 0.3818\n",
      "Baseline Loss: 2.6909 | Actual Loss: 0.2422\n",
      "Baseline Loss: 2.2705 | Actual Loss: 0.3686\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4489\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.4755\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3662\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4536\n",
      "Epoch 95/1000: Train Loss: 0.3277, Val Loss: 0.4360\n",
      "Baseline Loss: 2.6970 | Actual Loss: 0.3851\n",
      "Baseline Loss: 2.7035 | Actual Loss: 0.1957\n",
      "Baseline Loss: 2.6715 | Actual Loss: 0.2912\n",
      "Baseline Loss: 2.6195 | Actual Loss: 0.2501\n",
      "Baseline Loss: 2.7201 | Actual Loss: 0.3338\n",
      "Baseline Loss: 2.6565 | Actual Loss: 0.1926\n",
      "Baseline Loss: 2.6739 | Actual Loss: 0.3734\n",
      "Baseline Loss: 2.6769 | Actual Loss: 0.3501\n",
      "Baseline Loss: 2.6722 | Actual Loss: 0.1995\n",
      "Baseline Loss: 2.6757 | Actual Loss: 0.2308\n",
      "Baseline Loss: 2.6658 | Actual Loss: 0.2222\n",
      "Baseline Loss: 2.6774 | Actual Loss: 0.2406\n",
      "Baseline Loss: 2.7095 | Actual Loss: 0.2315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 96/1000 [00:45<07:21,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6744 | Actual Loss: 0.2148\n",
      "Baseline Loss: 2.6707 | Actual Loss: 0.2236\n",
      "Baseline Loss: 2.2722 | Actual Loss: 0.3379\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.3922\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.4584\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3970\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.5622\n",
      "Epoch 96/1000: Train Loss: 0.2671, Val Loss: 0.4525\n",
      "Baseline Loss: 2.6966 | Actual Loss: 0.2803\n",
      "Baseline Loss: 2.7061 | Actual Loss: 0.4533\n",
      "Baseline Loss: 2.6741 | Actual Loss: 0.2733\n",
      "Baseline Loss: 2.6817 | Actual Loss: 0.3509\n",
      "Baseline Loss: 2.6327 | Actual Loss: 0.6058\n",
      "Baseline Loss: 2.6875 | Actual Loss: 0.2329\n",
      "Baseline Loss: 2.6697 | Actual Loss: 0.2388\n",
      "Baseline Loss: 2.6386 | Actual Loss: 0.1904\n",
      "Baseline Loss: 2.7120 | Actual Loss: 0.3062\n",
      "Baseline Loss: 2.6777 | Actual Loss: 0.5433\n",
      "Baseline Loss: 2.6579 | Actual Loss: 0.2647\n",
      "Baseline Loss: 2.6560 | Actual Loss: 0.3658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 97/1000 [00:45<06:55,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6833 | Actual Loss: 0.3742\n",
      "Baseline Loss: 2.6713 | Actual Loss: 0.2472\n",
      "Baseline Loss: 2.6682 | Actual Loss: 0.4227\n",
      "Baseline Loss: 2.2637 | Actual Loss: 0.2666\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5360\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.5073\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.4489\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.5270\n",
      "Epoch 97/1000: Train Loss: 0.3385, Val Loss: 0.5048\n",
      "Baseline Loss: 2.6564 | Actual Loss: 0.4020\n",
      "Baseline Loss: 2.7264 | Actual Loss: 0.3538\n",
      "Baseline Loss: 2.6489 | Actual Loss: 0.2648\n",
      "Baseline Loss: 2.6536 | Actual Loss: 0.4894\n",
      "Baseline Loss: 2.6751 | Actual Loss: 0.3144\n",
      "Baseline Loss: 2.6994 | Actual Loss: 0.3601\n",
      "Baseline Loss: 2.6621 | Actual Loss: 0.3471\n",
      "Baseline Loss: 2.6529 | Actual Loss: 0.2697\n",
      "Baseline Loss: 2.6576 | Actual Loss: 0.1996\n",
      "Baseline Loss: 2.6777 | Actual Loss: 0.4207\n",
      "Baseline Loss: 2.7014 | Actual Loss: 0.3902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 98/1000 [00:46<07:07,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6971 | Actual Loss: 0.2669\n",
      "Baseline Loss: 2.6705 | Actual Loss: 0.3346\n",
      "Baseline Loss: 2.6376 | Actual Loss: 0.4450\n",
      "Baseline Loss: 2.6888 | Actual Loss: 0.3014\n",
      "Baseline Loss: 2.2383 | Actual Loss: 0.2459\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4106\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.5600\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3411\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2829\n",
      "Epoch 98/1000: Train Loss: 0.3378, Val Loss: 0.3987\n",
      "New best validation loss: 0.3987\n",
      "Baseline Loss: 2.6599 | Actual Loss: 0.4347\n",
      "Baseline Loss: 2.6664 | Actual Loss: 0.2803\n",
      "Baseline Loss: 2.6692 | Actual Loss: 0.3003\n",
      "Baseline Loss: 2.6386 | Actual Loss: 0.3383\n",
      "Baseline Loss: 2.6526 | Actual Loss: 0.3093\n",
      "Baseline Loss: 2.6662 | Actual Loss: 0.3340\n",
      "Baseline Loss: 2.6868 | Actual Loss: 0.4369\n",
      "Baseline Loss: 2.7143 | Actual Loss: 0.2814\n",
      "Baseline Loss: 2.6819 | Actual Loss: 0.3640\n",
      "Baseline Loss: 2.6568 | Actual Loss: 0.4330\n",
      "Baseline Loss: 2.7162 | Actual Loss: 0.3270\n",
      "Baseline Loss: 2.6980 | Actual Loss: 0.3118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 99/1000 [00:46<07:13,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6411 | Actual Loss: 0.2734\n",
      "Baseline Loss: 2.6791 | Actual Loss: 0.3050\n",
      "Baseline Loss: 2.6420 | Actual Loss: 0.4287\n",
      "Baseline Loss: 2.2692 | Actual Loss: 0.0584\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4553\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3985\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3912\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3603\n",
      "Epoch 99/1000: Train Loss: 0.3260, Val Loss: 0.4013\n",
      "Baseline Loss: 2.7173 | Actual Loss: 0.2759\n",
      "Baseline Loss: 2.6604 | Actual Loss: 0.2927\n",
      "Baseline Loss: 2.6590 | Actual Loss: 0.3632\n",
      "Baseline Loss: 2.6584 | Actual Loss: 0.2778\n",
      "Baseline Loss: 2.6707 | Actual Loss: 0.2129\n",
      "Baseline Loss: 2.6698 | Actual Loss: 0.2882\n",
      "Baseline Loss: 2.7110 | Actual Loss: 0.3343\n",
      "Baseline Loss: 2.6613 | Actual Loss: 0.2451\n",
      "Baseline Loss: 2.6359 | Actual Loss: 0.3187\n",
      "Baseline Loss: 2.7002 | Actual Loss: 0.2018\n",
      "Baseline Loss: 2.6516 | Actual Loss: 0.2189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 100/1000 [00:47<06:56,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6807 | Actual Loss: 0.1194\n",
      "Baseline Loss: 2.7199 | Actual Loss: 0.3309\n",
      "Baseline Loss: 2.6693 | Actual Loss: 0.2630\n",
      "Baseline Loss: 2.6962 | Actual Loss: 0.3944\n",
      "Baseline Loss: 2.2355 | Actual Loss: 0.0981\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.6574\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.4779\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2742\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4208\n",
      "Epoch 100/1000: Train Loss: 0.2647, Val Loss: 0.4576\n",
      "Baseline Loss: 2.7008 | Actual Loss: 0.4543\n",
      "Baseline Loss: 2.6456 | Actual Loss: 0.4226\n",
      "Baseline Loss: 2.6646 | Actual Loss: 0.4185\n",
      "Baseline Loss: 2.7126 | Actual Loss: 0.3573\n",
      "Baseline Loss: 2.6708 | Actual Loss: 0.2941\n",
      "Baseline Loss: 2.7386 | Actual Loss: 0.2358\n",
      "Baseline Loss: 2.6815 | Actual Loss: 0.5205\n",
      "Baseline Loss: 2.6610 | Actual Loss: 0.2743\n",
      "Baseline Loss: 2.6657 | Actual Loss: 0.2935\n",
      "Baseline Loss: 2.6486 | Actual Loss: 0.2584\n",
      "Baseline Loss: 2.6919 | Actual Loss: 0.1399\n",
      "Baseline Loss: 2.6464 | Actual Loss: 0.3328\n",
      "Baseline Loss: 2.6473 | Actual Loss: 0.1993\n",
      "Baseline Loss: 2.6814 | Actual Loss: 0.2449\n",
      "Baseline Loss: 2.7052 | Actual Loss: 0.3452\n",
      "Baseline Loss: 2.2376 | Actual Loss: 0.1354\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.3746\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.4752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 101/1000 [00:47<07:06,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6381 | Actual Loss: 0.3310\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3758\n",
      "Epoch 101/1000: Train Loss: 0.3079, Val Loss: 0.3891\n",
      "New best validation loss: 0.3891\n",
      "Baseline Loss: 2.6690 | Actual Loss: 0.3630\n",
      "Baseline Loss: 2.6955 | Actual Loss: 0.2139\n",
      "Baseline Loss: 2.6498 | Actual Loss: 0.3842\n",
      "Baseline Loss: 2.6835 | Actual Loss: 0.2452\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.3971\n",
      "Baseline Loss: 2.6981 | Actual Loss: 0.2666\n",
      "Baseline Loss: 2.6427 | Actual Loss: 0.2131\n",
      "Baseline Loss: 2.6993 | Actual Loss: 0.2989\n",
      "Baseline Loss: 2.6366 | Actual Loss: 0.3826\n",
      "Baseline Loss: 2.7601 | Actual Loss: 0.1476\n",
      "Baseline Loss: 2.6263 | Actual Loss: 0.3289\n",
      "Baseline Loss: 2.7081 | Actual Loss: 0.1426\n",
      "Baseline Loss: 2.6426 | Actual Loss: 0.2198\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.3088\n",
      "Baseline Loss: 2.6978 | Actual Loss: 0.3222\n",
      "Baseline Loss: 2.2498 | Actual Loss: 0.1670\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.7308\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.4141\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 102/1000 [00:48<07:05,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6194 | Actual Loss: 0.3802\n",
      "Epoch 102/1000: Train Loss: 0.2751, Val Loss: 0.4643\n",
      "Baseline Loss: 2.6775 | Actual Loss: 0.3012\n",
      "Baseline Loss: 2.7029 | Actual Loss: 0.2778\n",
      "Baseline Loss: 2.6670 | Actual Loss: 0.3205\n",
      "Baseline Loss: 2.6661 | Actual Loss: 0.2533\n",
      "Baseline Loss: 2.6687 | Actual Loss: 0.2124\n",
      "Baseline Loss: 2.6789 | Actual Loss: 0.2472\n",
      "Baseline Loss: 2.6425 | Actual Loss: 0.3561\n",
      "Baseline Loss: 2.6877 | Actual Loss: 0.2621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 103/1000 [00:48<06:49,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6649 | Actual Loss: 0.1907\n",
      "Baseline Loss: 2.6811 | Actual Loss: 0.3232\n",
      "Baseline Loss: 2.6546 | Actual Loss: 0.3521\n",
      "Baseline Loss: 2.6917 | Actual Loss: 0.2547\n",
      "Baseline Loss: 2.6688 | Actual Loss: 0.3032\n",
      "Baseline Loss: 2.6302 | Actual Loss: 0.3839\n",
      "Baseline Loss: 2.6565 | Actual Loss: 0.2734\n",
      "Baseline Loss: 2.2963 | Actual Loss: 0.2787\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5229\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3796\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3741\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3226\n",
      "Epoch 103/1000: Train Loss: 0.2869, Val Loss: 0.3998\n",
      "Baseline Loss: 2.6991 | Actual Loss: 0.2916\n",
      "Baseline Loss: 2.6798 | Actual Loss: 0.3259\n",
      "Baseline Loss: 2.6525 | Actual Loss: 0.1969\n",
      "Baseline Loss: 2.6673 | Actual Loss: 0.2388\n",
      "Baseline Loss: 2.6521 | Actual Loss: 0.2676\n",
      "Baseline Loss: 2.6503 | Actual Loss: 0.3555\n",
      "Baseline Loss: 2.6588 | Actual Loss: 0.5604\n",
      "Baseline Loss: 2.6662 | Actual Loss: 0.2608\n",
      "Baseline Loss: 2.7122 | Actual Loss: 0.1507\n",
      "Baseline Loss: 2.7019 | Actual Loss: 0.2863\n",
      "Baseline Loss: 2.6388 | Actual Loss: 0.4832\n",
      "Baseline Loss: 2.6880 | Actual Loss: 0.2647\n",
      "Baseline Loss: 2.7290 | Actual Loss: 0.2531\n",
      "Baseline Loss: 2.7072 | Actual Loss: 0.3300\n",
      "Baseline Loss: 2.6923 | Actual Loss: 0.3796\n",
      "Baseline Loss: 2.2190 | Actual Loss: 0.1723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 104/1000 [00:49<06:57,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6857 | Actual Loss: 0.5184\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.4748\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.4179\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4224\n",
      "Epoch 104/1000: Train Loss: 0.3011, Val Loss: 0.4584\n",
      "Baseline Loss: 2.6935 | Actual Loss: 0.3460\n",
      "Baseline Loss: 2.6683 | Actual Loss: 0.3004\n",
      "Baseline Loss: 2.6192 | Actual Loss: 0.2601\n",
      "Baseline Loss: 2.6635 | Actual Loss: 0.3409\n",
      "Baseline Loss: 2.6288 | Actual Loss: 0.3103\n",
      "Baseline Loss: 2.6748 | Actual Loss: 0.4851\n",
      "Baseline Loss: 2.6490 | Actual Loss: 0.1937\n",
      "Baseline Loss: 2.6704 | Actual Loss: 0.3040\n",
      "Baseline Loss: 2.7005 | Actual Loss: 0.2418\n",
      "Baseline Loss: 2.6735 | Actual Loss: 0.2380\n",
      "Baseline Loss: 2.6879 | Actual Loss: 0.3186\n",
      "Baseline Loss: 2.6871 | Actual Loss: 0.3303\n",
      "Baseline Loss: 2.7067 | Actual Loss: 0.4693\n",
      "Baseline Loss: 2.6793 | Actual Loss: 0.3941\n",
      "Baseline Loss: 2.6949 | Actual Loss: 0.2323\n",
      "Baseline Loss: 2.2282 | Actual Loss: 0.6521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 105/1000 [00:49<06:40,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6857 | Actual Loss: 0.4610\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.5738\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3063\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3754\n",
      "Epoch 105/1000: Train Loss: 0.3386, Val Loss: 0.4291\n",
      "Baseline Loss: 2.6652 | Actual Loss: 0.2638\n",
      "Baseline Loss: 2.6749 | Actual Loss: 0.2003\n",
      "Baseline Loss: 2.6469 | Actual Loss: 0.3163\n",
      "Baseline Loss: 2.6920 | Actual Loss: 0.2728\n",
      "Baseline Loss: 2.6805 | Actual Loss: 0.2286\n",
      "Baseline Loss: 2.6863 | Actual Loss: 0.2414\n",
      "Baseline Loss: 2.6841 | Actual Loss: 0.3833\n",
      "Baseline Loss: 2.7170 | Actual Loss: 0.3023\n",
      "Baseline Loss: 2.6485 | Actual Loss: 0.2695\n",
      "Baseline Loss: 2.6863 | Actual Loss: 0.2212\n",
      "Baseline Loss: 2.6632 | Actual Loss: 0.2995\n",
      "Baseline Loss: 2.6696 | Actual Loss: 0.2571\n",
      "Baseline Loss: 2.6777 | Actual Loss: 0.2337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 106/1000 [00:49<06:45,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6502 | Actual Loss: 0.2252\n",
      "Baseline Loss: 2.6647 | Actual Loss: 0.3333\n",
      "Baseline Loss: 2.2815 | Actual Loss: 0.1472\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5413\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.5000\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3507\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4034\n",
      "Epoch 106/1000: Train Loss: 0.2622, Val Loss: 0.4488\n",
      "Baseline Loss: 2.6388 | Actual Loss: 0.2041\n",
      "Baseline Loss: 2.6532 | Actual Loss: 0.4163\n",
      "Baseline Loss: 2.6780 | Actual Loss: 0.2986\n",
      "Baseline Loss: 2.6626 | Actual Loss: 0.2664\n",
      "Baseline Loss: 2.6980 | Actual Loss: 0.1507\n",
      "Baseline Loss: 2.6681 | Actual Loss: 0.5098\n",
      "Baseline Loss: 2.6691 | Actual Loss: 0.2728\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3325\n",
      "Baseline Loss: 2.6631 | Actual Loss: 0.3115\n",
      "Baseline Loss: 2.6791 | Actual Loss: 0.2968\n",
      "Baseline Loss: 2.7177 | Actual Loss: 0.2656\n",
      "Baseline Loss: 2.6379 | Actual Loss: 0.2961\n",
      "Baseline Loss: 2.6792 | Actual Loss: 0.1968\n",
      "Baseline Loss: 2.6711 | Actual Loss: 0.4337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 107/1000 [00:50<06:41,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6692 | Actual Loss: 0.3587\n",
      "Baseline Loss: 2.3083 | Actual Loss: 0.0908\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5036\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.6141\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2528\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4325\n",
      "Epoch 107/1000: Train Loss: 0.2938, Val Loss: 0.4508\n",
      "Baseline Loss: 2.6717 | Actual Loss: 0.1806\n",
      "Baseline Loss: 2.6631 | Actual Loss: 0.2854\n",
      "Baseline Loss: 2.6451 | Actual Loss: 0.2734\n",
      "Baseline Loss: 2.7248 | Actual Loss: 0.3424\n",
      "Baseline Loss: 2.6480 | Actual Loss: 0.2190\n",
      "Baseline Loss: 2.6795 | Actual Loss: 0.1729\n",
      "Baseline Loss: 2.6981 | Actual Loss: 0.1886\n",
      "Baseline Loss: 2.6865 | Actual Loss: 0.2576\n",
      "Baseline Loss: 2.6579 | Actual Loss: 0.3706\n",
      "Baseline Loss: 2.6340 | Actual Loss: 0.3648\n",
      "Baseline Loss: 2.6923 | Actual Loss: 0.5363\n",
      "Baseline Loss: 2.6704 | Actual Loss: 0.2934\n",
      "Baseline Loss: 2.6931 | Actual Loss: 0.3251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 108/1000 [00:50<06:48,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6626 | Actual Loss: 0.4441\n",
      "Baseline Loss: 2.6757 | Actual Loss: 0.2273\n",
      "Baseline Loss: 2.3583 | Actual Loss: 0.2359\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5342\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3228\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.4243\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3428\n",
      "Epoch 108/1000: Train Loss: 0.2948, Val Loss: 0.4060\n",
      "Baseline Loss: 2.6372 | Actual Loss: 0.2871\n",
      "Baseline Loss: 2.6736 | Actual Loss: 0.4244\n",
      "Baseline Loss: 2.6468 | Actual Loss: 0.3420\n",
      "Baseline Loss: 2.6573 | Actual Loss: 0.1819\n",
      "Baseline Loss: 2.6954 | Actual Loss: 0.2989\n",
      "Baseline Loss: 2.6692 | Actual Loss: 0.2292\n",
      "Baseline Loss: 2.6714 | Actual Loss: 0.2893\n",
      "Baseline Loss: 2.6766 | Actual Loss: 0.2626\n",
      "Baseline Loss: 2.6461 | Actual Loss: 0.2350\n",
      "Baseline Loss: 2.6696 | Actual Loss: 0.6485\n",
      "Baseline Loss: 2.6541 | Actual Loss: 0.2713\n",
      "Baseline Loss: 2.7073 | Actual Loss: 0.2110\n",
      "Baseline Loss: 2.6825 | Actual Loss: 0.2780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 109/1000 [00:51<07:04,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7061 | Actual Loss: 0.2040\n",
      "Baseline Loss: 2.6725 | Actual Loss: 0.3851\n",
      "Baseline Loss: 2.3536 | Actual Loss: 0.1617\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5583\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.4275\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2377\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3361\n",
      "Epoch 109/1000: Train Loss: 0.2944, Val Loss: 0.3899\n",
      "Baseline Loss: 2.6533 | Actual Loss: 0.3160\n",
      "Baseline Loss: 2.6937 | Actual Loss: 0.3094\n",
      "Baseline Loss: 2.7176 | Actual Loss: 0.3696\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.2178\n",
      "Baseline Loss: 2.6307 | Actual Loss: 0.2965\n",
      "Baseline Loss: 2.6588 | Actual Loss: 0.1920\n",
      "Baseline Loss: 2.6933 | Actual Loss: 0.1768\n",
      "Baseline Loss: 2.6891 | Actual Loss: 0.2439\n",
      "Baseline Loss: 2.6525 | Actual Loss: 0.4071\n",
      "Baseline Loss: 2.6648 | Actual Loss: 0.4516\n",
      "Baseline Loss: 2.6551 | Actual Loss: 0.1635\n",
      "Baseline Loss: 2.6903 | Actual Loss: 0.3565\n",
      "Baseline Loss: 2.6687 | Actual Loss: 0.2925\n",
      "Baseline Loss: 2.6968 | Actual Loss: 0.3427\n",
      "Baseline Loss: 2.6854 | Actual Loss: 0.2996\n",
      "Baseline Loss: 2.2386 | Actual Loss: 0.1958\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4754\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3346\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 110/1000 [00:51<06:56,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6194 | Actual Loss: 0.4157\n",
      "Epoch 110/1000: Train Loss: 0.2894, Val Loss: 0.3763\n",
      "New best validation loss: 0.3763\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2514\n",
      "Baseline Loss: 2.6503 | Actual Loss: 0.2412\n",
      "Baseline Loss: 2.7001 | Actual Loss: 0.2644\n",
      "Baseline Loss: 2.6801 | Actual Loss: 0.2204\n",
      "Baseline Loss: 2.6739 | Actual Loss: 0.2978\n",
      "Baseline Loss: 2.6736 | Actual Loss: 0.2495\n",
      "Baseline Loss: 2.6240 | Actual Loss: 0.3282\n",
      "Baseline Loss: 2.6551 | Actual Loss: 0.2056\n",
      "Baseline Loss: 2.6732 | Actual Loss: 0.1913\n",
      "Baseline Loss: 2.6834 | Actual Loss: 0.3664\n",
      "Baseline Loss: 2.6290 | Actual Loss: 0.2131\n",
      "Baseline Loss: 2.6818 | Actual Loss: 0.2328\n",
      "Baseline Loss: 2.6728 | Actual Loss: 0.2910\n",
      "Baseline Loss: 2.6897 | Actual Loss: 0.1521\n",
      "Baseline Loss: 2.7369 | Actual Loss: 0.2226\n",
      "Baseline Loss: 2.3330 | Actual Loss: 0.3023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 111/1000 [00:52<07:10,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6857 | Actual Loss: 0.5352\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3563\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3133\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3563\n",
      "Epoch 111/1000: Train Loss: 0.2519, Val Loss: 0.3903\n",
      "Baseline Loss: 2.6603 | Actual Loss: 0.3817\n",
      "Baseline Loss: 2.6558 | Actual Loss: 0.3046\n",
      "Baseline Loss: 2.6660 | Actual Loss: 0.3175\n",
      "Baseline Loss: 2.6747 | Actual Loss: 0.3343\n",
      "Baseline Loss: 2.6972 | Actual Loss: 0.2149\n",
      "Baseline Loss: 2.6507 | Actual Loss: 0.2853\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2332\n",
      "Baseline Loss: 2.6450 | Actual Loss: 0.5488\n",
      "Baseline Loss: 2.6652 | Actual Loss: 0.2328\n",
      "Baseline Loss: 2.6972 | Actual Loss: 0.2856\n",
      "Baseline Loss: 2.6821 | Actual Loss: 0.2633\n",
      "Baseline Loss: 2.6642 | Actual Loss: 0.2974\n",
      "Baseline Loss: 2.7046 | Actual Loss: 0.2423\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.2419\n",
      "Baseline Loss: 2.6962 | Actual Loss: 0.2895\n",
      "Baseline Loss: 2.3105 | Actual Loss: 0.2377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 112/1000 [00:52<07:18,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6857 | Actual Loss: 0.4987\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3385\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2720\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3761\n",
      "Epoch 112/1000: Train Loss: 0.2944, Val Loss: 0.3713\n",
      "New best validation loss: 0.3713\n",
      "Baseline Loss: 2.6512 | Actual Loss: 0.3424\n",
      "Baseline Loss: 2.6749 | Actual Loss: 0.3429\n",
      "Baseline Loss: 2.6550 | Actual Loss: 0.2270\n",
      "Baseline Loss: 2.6776 | Actual Loss: 0.3507\n",
      "Baseline Loss: 2.7347 | Actual Loss: 0.3304\n",
      "Baseline Loss: 2.6985 | Actual Loss: 0.2127\n",
      "Baseline Loss: 2.6518 | Actual Loss: 0.2127\n",
      "Baseline Loss: 2.6455 | Actual Loss: 0.2064\n",
      "Baseline Loss: 2.6431 | Actual Loss: 0.2949\n",
      "Baseline Loss: 2.6761 | Actual Loss: 0.1926\n",
      "Baseline Loss: 2.7088 | Actual Loss: 0.2159\n",
      "Baseline Loss: 2.6449 | Actual Loss: 0.2724\n",
      "Baseline Loss: 2.6884 | Actual Loss: 0.1898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█▏        | 113/1000 [00:53<06:56,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6449 | Actual Loss: 0.2328\n",
      "Baseline Loss: 2.6854 | Actual Loss: 0.2976\n",
      "Baseline Loss: 2.2877 | Actual Loss: 0.1261\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4380\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.4328\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3511\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4231\n",
      "Epoch 113/1000: Train Loss: 0.2530, Val Loss: 0.4112\n",
      "Baseline Loss: 2.6526 | Actual Loss: 0.2141\n",
      "Baseline Loss: 2.6520 | Actual Loss: 0.1679\n",
      "Baseline Loss: 2.6608 | Actual Loss: 0.2903\n",
      "Baseline Loss: 2.6565 | Actual Loss: 0.2643\n",
      "Baseline Loss: 2.6627 | Actual Loss: 0.3263\n",
      "Baseline Loss: 2.6886 | Actual Loss: 0.2442\n",
      "Baseline Loss: 2.6906 | Actual Loss: 0.2526\n",
      "Baseline Loss: 2.7203 | Actual Loss: 0.3215\n",
      "Baseline Loss: 2.6632 | Actual Loss: 0.2010\n",
      "Baseline Loss: 2.6565 | Actual Loss: 0.2080\n",
      "Baseline Loss: 2.6571 | Actual Loss: 0.2169\n",
      "Baseline Loss: 2.6705 | Actual Loss: 0.1388\n",
      "Baseline Loss: 2.7078 | Actual Loss: 0.2448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█▏        | 114/1000 [00:53<06:57,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7001 | Actual Loss: 0.1666\n",
      "Baseline Loss: 2.6847 | Actual Loss: 0.1505\n",
      "Baseline Loss: 2.2693 | Actual Loss: 0.1421\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.3911\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3715\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3657\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4623\n",
      "Epoch 114/1000: Train Loss: 0.2219, Val Loss: 0.3976\n",
      "Baseline Loss: 2.6395 | Actual Loss: 0.2825\n",
      "Baseline Loss: 2.6665 | Actual Loss: 0.3689\n",
      "Baseline Loss: 2.6637 | Actual Loss: 0.2207\n",
      "Baseline Loss: 2.6811 | Actual Loss: 0.1928\n",
      "Baseline Loss: 2.6456 | Actual Loss: 0.2549\n",
      "Baseline Loss: 2.6906 | Actual Loss: 0.1374\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2938\n",
      "Baseline Loss: 2.6810 | Actual Loss: 0.3222\n",
      "Baseline Loss: 2.6612 | Actual Loss: 0.2814\n",
      "Baseline Loss: 2.6939 | Actual Loss: 0.5090\n",
      "Baseline Loss: 2.6669 | Actual Loss: 0.2235\n",
      "Baseline Loss: 2.6362 | Actual Loss: 0.2374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 115/1000 [00:54<07:17,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6568 | Actual Loss: 0.2091\n",
      "Baseline Loss: 2.6824 | Actual Loss: 0.1221\n",
      "Baseline Loss: 2.6421 | Actual Loss: 0.3096\n",
      "Baseline Loss: 2.3008 | Actual Loss: 0.1410\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4362\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3299\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.4639\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4086\n",
      "Epoch 115/1000: Train Loss: 0.2567, Val Loss: 0.4096\n",
      "Baseline Loss: 2.7072 | Actual Loss: 0.3101\n",
      "Baseline Loss: 2.6759 | Actual Loss: 0.1372\n",
      "Baseline Loss: 2.6516 | Actual Loss: 0.2670\n",
      "Baseline Loss: 2.6408 | Actual Loss: 0.2132\n",
      "Baseline Loss: 2.6551 | Actual Loss: 0.3088\n",
      "Baseline Loss: 2.6784 | Actual Loss: 0.2934\n",
      "Baseline Loss: 2.6691 | Actual Loss: 0.3541\n",
      "Baseline Loss: 2.6860 | Actual Loss: 0.3089\n",
      "Baseline Loss: 2.6858 | Actual Loss: 0.3625\n",
      "Baseline Loss: 2.6679 | Actual Loss: 0.4512\n",
      "Baseline Loss: 2.6727 | Actual Loss: 0.3884\n",
      "Baseline Loss: 2.6505 | Actual Loss: 0.3643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 116/1000 [00:54<06:51,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6668 | Actual Loss: 0.1628\n",
      "Baseline Loss: 2.6668 | Actual Loss: 0.2967\n",
      "Baseline Loss: 2.7164 | Actual Loss: 0.2325\n",
      "Baseline Loss: 2.2856 | Actual Loss: 0.1832\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4300\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.4484\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3499\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3517\n",
      "Epoch 116/1000: Train Loss: 0.2896, Val Loss: 0.3950\n",
      "Baseline Loss: 2.6797 | Actual Loss: 0.1634\n",
      "Baseline Loss: 2.6444 | Actual Loss: 0.2199\n",
      "Baseline Loss: 2.6541 | Actual Loss: 0.2726\n",
      "Baseline Loss: 2.6604 | Actual Loss: 0.2340\n",
      "Baseline Loss: 2.6884 | Actual Loss: 0.2447\n",
      "Baseline Loss: 2.6576 | Actual Loss: 0.2371\n",
      "Baseline Loss: 2.6541 | Actual Loss: 0.1725\n",
      "Baseline Loss: 2.6865 | Actual Loss: 0.2502\n",
      "Baseline Loss: 2.6905 | Actual Loss: 0.3450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 117/1000 [00:55<07:01,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7141 | Actual Loss: 0.3279\n",
      "Baseline Loss: 2.6714 | Actual Loss: 0.7342\n",
      "Baseline Loss: 2.6862 | Actual Loss: 0.3464\n",
      "Baseline Loss: 2.6404 | Actual Loss: 0.2478\n",
      "Baseline Loss: 2.7022 | Actual Loss: 0.2565\n",
      "Baseline Loss: 2.7092 | Actual Loss: 0.2808\n",
      "Baseline Loss: 2.2960 | Actual Loss: 0.1953\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4658\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3170\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3234\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3416\n",
      "Epoch 117/1000: Train Loss: 0.2830, Val Loss: 0.3619\n",
      "New best validation loss: 0.3619\n",
      "Baseline Loss: 2.7112 | Actual Loss: 0.1986\n",
      "Baseline Loss: 2.6638 | Actual Loss: 0.2254\n",
      "Baseline Loss: 2.6771 | Actual Loss: 0.3928\n",
      "Baseline Loss: 2.6582 | Actual Loss: 0.2483\n",
      "Baseline Loss: 2.6476 | Actual Loss: 0.2223\n",
      "Baseline Loss: 2.6642 | Actual Loss: 0.5130\n",
      "Baseline Loss: 2.6973 | Actual Loss: 0.1725\n",
      "Baseline Loss: 2.6772 | Actual Loss: 0.3120\n",
      "Baseline Loss: 2.6806 | Actual Loss: 0.3803\n",
      "Baseline Loss: 2.6911 | Actual Loss: 0.1451\n",
      "Baseline Loss: 2.6937 | Actual Loss: 0.4643\n",
      "Baseline Loss: 2.6912 | Actual Loss: 0.1364\n",
      "Baseline Loss: 2.6763 | Actual Loss: 0.2415\n",
      "Baseline Loss: 2.6760 | Actual Loss: 0.4126\n",
      "Baseline Loss: 2.6856 | Actual Loss: 0.2121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 118/1000 [00:55<07:17,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2901 | Actual Loss: 0.2138\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.3710\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3686\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3053\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2394\n",
      "Epoch 118/1000: Train Loss: 0.2807, Val Loss: 0.3211\n",
      "New best validation loss: 0.3211\n",
      "Baseline Loss: 2.7377 | Actual Loss: 0.2835\n",
      "Baseline Loss: 2.6667 | Actual Loss: 0.1579\n",
      "Baseline Loss: 2.7081 | Actual Loss: 0.3389\n",
      "Baseline Loss: 2.7136 | Actual Loss: 0.2983\n",
      "Baseline Loss: 2.6733 | Actual Loss: 0.4030\n",
      "Baseline Loss: 2.6401 | Actual Loss: 0.2867\n",
      "Baseline Loss: 2.6673 | Actual Loss: 0.2915\n",
      "Baseline Loss: 2.6323 | Actual Loss: 0.3772\n",
      "Baseline Loss: 2.6567 | Actual Loss: 0.2340\n",
      "Baseline Loss: 2.6404 | Actual Loss: 0.1963\n",
      "Baseline Loss: 2.6745 | Actual Loss: 0.2667\n",
      "Baseline Loss: 2.6951 | Actual Loss: 0.3211\n",
      "Baseline Loss: 2.6627 | Actual Loss: 0.3338\n",
      "Baseline Loss: 2.6912 | Actual Loss: 0.2757\n",
      "Baseline Loss: 2.6610 | Actual Loss: 0.2739\n",
      "Baseline Loss: 2.2541 | Actual Loss: 0.3841\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 119/1000 [00:56<06:48,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6990 | Actual Loss: 0.4072\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2913\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3587\n",
      "Epoch 119/1000: Train Loss: 0.2952, Val Loss: 0.4025\n",
      "Baseline Loss: 2.7060 | Actual Loss: 0.1171\n",
      "Baseline Loss: 2.6708 | Actual Loss: 0.2263\n",
      "Baseline Loss: 2.6760 | Actual Loss: 0.1548\n",
      "Baseline Loss: 2.6748 | Actual Loss: 0.1945\n",
      "Baseline Loss: 2.6689 | Actual Loss: 0.2931\n",
      "Baseline Loss: 2.6799 | Actual Loss: 0.2758\n",
      "Baseline Loss: 2.6954 | Actual Loss: 0.4321\n",
      "Baseline Loss: 2.6277 | Actual Loss: 0.3175\n",
      "Baseline Loss: 2.6790 | Actual Loss: 0.2783\n",
      "Baseline Loss: 2.6595 | Actual Loss: 0.2391\n",
      "Baseline Loss: 2.6730 | Actual Loss: 0.1391\n",
      "Baseline Loss: 2.7044 | Actual Loss: 0.3206\n",
      "Baseline Loss: 2.7117 | Actual Loss: 0.2661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 120/1000 [00:56<07:06,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6602 | Actual Loss: 0.1424\n",
      "Baseline Loss: 2.6550 | Actual Loss: 0.2469\n",
      "Baseline Loss: 2.3113 | Actual Loss: 0.1660\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5239\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.4247\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2971\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3843\n",
      "Epoch 120/1000: Train Loss: 0.2381, Val Loss: 0.4075\n",
      "Baseline Loss: 2.6589 | Actual Loss: 0.3802\n",
      "Baseline Loss: 2.6552 | Actual Loss: 0.2968\n",
      "Baseline Loss: 2.6728 | Actual Loss: 0.2634\n",
      "Baseline Loss: 2.6398 | Actual Loss: 0.2324\n",
      "Baseline Loss: 2.7013 | Actual Loss: 0.2580\n",
      "Baseline Loss: 2.6863 | Actual Loss: 0.2099\n",
      "Baseline Loss: 2.6974 | Actual Loss: 0.2521\n",
      "Baseline Loss: 2.6859 | Actual Loss: 0.3950\n",
      "Baseline Loss: 2.6989 | Actual Loss: 0.4716\n",
      "Baseline Loss: 2.6414 | Actual Loss: 0.1710\n",
      "Baseline Loss: 2.6565 | Actual Loss: 0.3923\n",
      "Baseline Loss: 2.6672 | Actual Loss: 0.3464\n",
      "Baseline Loss: 2.7098 | Actual Loss: 0.2395\n",
      "Baseline Loss: 2.6493 | Actual Loss: 0.1689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 121/1000 [00:57<07:02,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7052 | Actual Loss: 0.1961\n",
      "Baseline Loss: 2.2811 | Actual Loss: 0.1727\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4653\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.4631\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2506\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3253\n",
      "Epoch 121/1000: Train Loss: 0.2779, Val Loss: 0.3761\n",
      "Baseline Loss: 2.6844 | Actual Loss: 0.2128\n",
      "Baseline Loss: 2.6388 | Actual Loss: 0.1977\n",
      "Baseline Loss: 2.6910 | Actual Loss: 0.3369\n",
      "Baseline Loss: 2.6989 | Actual Loss: 0.2163\n",
      "Baseline Loss: 2.6476 | Actual Loss: 0.2895\n",
      "Baseline Loss: 2.6619 | Actual Loss: 0.1537\n",
      "Baseline Loss: 2.6986 | Actual Loss: 0.2536\n",
      "Baseline Loss: 2.7179 | Actual Loss: 0.1321\n",
      "Baseline Loss: 2.6818 | Actual Loss: 0.1762\n",
      "Baseline Loss: 2.6775 | Actual Loss: 0.2222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 122/1000 [00:57<06:35,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6556 | Actual Loss: 0.3126\n",
      "Baseline Loss: 2.6574 | Actual Loss: 0.2577\n",
      "Baseline Loss: 2.6679 | Actual Loss: 0.2727\n",
      "Baseline Loss: 2.6392 | Actual Loss: 0.1458\n",
      "Baseline Loss: 2.6475 | Actual Loss: 0.1844\n",
      "Baseline Loss: 2.3202 | Actual Loss: 0.1490\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5707\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3468\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2875\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4413\n",
      "Epoch 122/1000: Train Loss: 0.2196, Val Loss: 0.4116\n",
      "Baseline Loss: 2.6269 | Actual Loss: 0.2541\n",
      "Baseline Loss: 2.6991 | Actual Loss: 0.3001\n",
      "Baseline Loss: 2.6516 | Actual Loss: 0.3285\n",
      "Baseline Loss: 2.6842 | Actual Loss: 0.2464\n",
      "Baseline Loss: 2.6775 | Actual Loss: 0.1622\n",
      "Baseline Loss: 2.6921 | Actual Loss: 0.2965\n",
      "Baseline Loss: 2.6702 | Actual Loss: 0.3169\n",
      "Baseline Loss: 2.6497 | Actual Loss: 0.1500\n",
      "Baseline Loss: 2.7064 | Actual Loss: 0.2996\n",
      "Baseline Loss: 2.6689 | Actual Loss: 0.2125\n",
      "Baseline Loss: 2.6937 | Actual Loss: 0.4287\n",
      "Baseline Loss: 2.6960 | Actual Loss: 0.2788\n",
      "Baseline Loss: 2.6727 | Actual Loss: 0.4068\n",
      "Baseline Loss: 2.6795 | Actual Loss: 0.2498\n",
      "Baseline Loss: 2.6973 | Actual Loss: 0.2338\n",
      "Baseline Loss: 2.2560 | Actual Loss: 0.2269\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.7733\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 123/1000 [00:58<07:01,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6381 | Actual Loss: 0.3314\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3475\n",
      "Epoch 123/1000: Train Loss: 0.2745, Val Loss: 0.4395\n",
      "Baseline Loss: 2.6757 | Actual Loss: 0.2832\n",
      "Baseline Loss: 2.6933 | Actual Loss: 0.2687\n",
      "Baseline Loss: 2.6926 | Actual Loss: 0.1489\n",
      "Baseline Loss: 2.6948 | Actual Loss: 0.3793\n",
      "Baseline Loss: 2.6321 | Actual Loss: 0.3446\n",
      "Baseline Loss: 2.6661 | Actual Loss: 0.2360\n",
      "Baseline Loss: 2.6928 | Actual Loss: 0.1461\n",
      "Baseline Loss: 2.6516 | Actual Loss: 0.2308\n",
      "Baseline Loss: 2.7037 | Actual Loss: 0.2065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 124/1000 [00:58<06:38,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6707 | Actual Loss: 0.3431\n",
      "Baseline Loss: 2.6647 | Actual Loss: 0.3629\n",
      "Baseline Loss: 2.6402 | Actual Loss: 0.2189\n",
      "Baseline Loss: 2.6553 | Actual Loss: 0.1986\n",
      "Baseline Loss: 2.6953 | Actual Loss: 0.2173\n",
      "Baseline Loss: 2.6859 | Actual Loss: 0.1753\n",
      "Baseline Loss: 2.3467 | Actual Loss: 0.2002\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5139\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.4159\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2534\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4813\n",
      "Epoch 124/1000: Train Loss: 0.2475, Val Loss: 0.4161\n",
      "Baseline Loss: 2.6883 | Actual Loss: 0.3348\n",
      "Baseline Loss: 2.6953 | Actual Loss: 0.2479\n",
      "Baseline Loss: 2.6764 | Actual Loss: 0.3068\n",
      "Baseline Loss: 2.6619 | Actual Loss: 0.1539\n",
      "Baseline Loss: 2.6712 | Actual Loss: 0.1772\n",
      "Baseline Loss: 2.6691 | Actual Loss: 0.2110\n",
      "Baseline Loss: 2.6733 | Actual Loss: 0.2284\n",
      "Baseline Loss: 2.6871 | Actual Loss: 0.1523\n",
      "Baseline Loss: 2.6860 | Actual Loss: 0.2253\n",
      "Baseline Loss: 2.7187 | Actual Loss: 0.2365\n",
      "Baseline Loss: 2.6673 | Actual Loss: 0.1789\n",
      "Baseline Loss: 2.6611 | Actual Loss: 0.2302\n",
      "Baseline Loss: 2.6848 | Actual Loss: 0.2380\n",
      "Baseline Loss: 2.6729 | Actual Loss: 0.1408\n",
      "Baseline Loss: 2.6859 | Actual Loss: 0.2070\n",
      "Baseline Loss: 2.2474 | Actual Loss: 0.1061\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4399\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.4039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▎        | 125/1000 [00:58<06:52,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6381 | Actual Loss: 0.3077\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3700\n",
      "Epoch 125/1000: Train Loss: 0.2110, Val Loss: 0.3804\n",
      "Baseline Loss: 2.6601 | Actual Loss: 0.2837\n",
      "Baseline Loss: 2.7121 | Actual Loss: 0.2742\n",
      "Baseline Loss: 2.6362 | Actual Loss: 0.3304\n",
      "Baseline Loss: 2.6815 | Actual Loss: 0.1697\n",
      "Baseline Loss: 2.6964 | Actual Loss: 0.2596\n",
      "Baseline Loss: 2.6991 | Actual Loss: 0.2025\n",
      "Baseline Loss: 2.6721 | Actual Loss: 0.2802\n",
      "Baseline Loss: 2.6613 | Actual Loss: 0.2151\n",
      "Baseline Loss: 2.6296 | Actual Loss: 0.2391\n",
      "Baseline Loss: 2.6724 | Actual Loss: 0.2892\n",
      "Baseline Loss: 2.7007 | Actual Loss: 0.3383\n",
      "Baseline Loss: 2.6402 | Actual Loss: 0.2407\n",
      "Baseline Loss: 2.6592 | Actual Loss: 0.2682\n",
      "Baseline Loss: 2.6472 | Actual Loss: 0.3172\n",
      "Baseline Loss: 2.6632 | Actual Loss: 0.2146\n",
      "Baseline Loss: 2.2684 | Actual Loss: 0.0823\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 126/1000 [00:59<06:43,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6990 | Actual Loss: 0.3951\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3275\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3665\n",
      "Epoch 126/1000: Train Loss: 0.2503, Val Loss: 0.4206\n",
      "Baseline Loss: 2.6713 | Actual Loss: 0.2816\n",
      "Baseline Loss: 2.6864 | Actual Loss: 0.2556\n",
      "Baseline Loss: 2.6532 | Actual Loss: 0.1973\n",
      "Baseline Loss: 2.6622 | Actual Loss: 0.1865\n",
      "Baseline Loss: 2.6626 | Actual Loss: 0.2291\n",
      "Baseline Loss: 2.6344 | Actual Loss: 0.2847\n",
      "Baseline Loss: 2.7107 | Actual Loss: 0.1477\n",
      "Baseline Loss: 2.7199 | Actual Loss: 0.3298\n",
      "Baseline Loss: 2.6939 | Actual Loss: 0.2253\n",
      "Baseline Loss: 2.7038 | Actual Loss: 0.1723\n",
      "Baseline Loss: 2.6452 | Actual Loss: 0.1351\n",
      "Baseline Loss: 2.6714 | Actual Loss: 0.1590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 127/1000 [00:59<06:59,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6836 | Actual Loss: 0.3726\n",
      "Baseline Loss: 2.6453 | Actual Loss: 0.4003\n",
      "Baseline Loss: 2.6305 | Actual Loss: 0.2563\n",
      "Baseline Loss: 2.3083 | Actual Loss: 0.1002\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4758\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.4159\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2550\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4524\n",
      "Epoch 127/1000: Train Loss: 0.2333, Val Loss: 0.3998\n",
      "Baseline Loss: 2.6987 | Actual Loss: 0.2774\n",
      "Baseline Loss: 2.6554 | Actual Loss: 0.2461\n",
      "Baseline Loss: 2.7102 | Actual Loss: 0.2965\n",
      "Baseline Loss: 2.7083 | Actual Loss: 0.4101\n",
      "Baseline Loss: 2.6443 | Actual Loss: 0.2852\n",
      "Baseline Loss: 2.6528 | Actual Loss: 0.4663\n",
      "Baseline Loss: 2.6962 | Actual Loss: 0.1789\n",
      "Baseline Loss: 2.6721 | Actual Loss: 0.3407\n",
      "Baseline Loss: 2.7104 | Actual Loss: 0.2275\n",
      "Baseline Loss: 2.6557 | Actual Loss: 0.3975\n",
      "Baseline Loss: 2.6527 | Actual Loss: 0.2822\n",
      "Baseline Loss: 2.6528 | Actual Loss: 0.2029\n",
      "Baseline Loss: 2.6616 | Actual Loss: 0.2759\n",
      "Baseline Loss: 2.6880 | Actual Loss: 0.2142\n",
      "Baseline Loss: 2.6572 | Actual Loss: 0.4126\n",
      "Baseline Loss: 2.3422 | Actual Loss: 0.1669\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 128/1000 [01:00<07:09,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6990 | Actual Loss: 0.3865\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3544\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4257\n",
      "Epoch 128/1000: Train Loss: 0.2926, Val Loss: 0.4284\n",
      "Baseline Loss: 2.7026 | Actual Loss: 0.2565\n",
      "Baseline Loss: 2.6890 | Actual Loss: 0.3755\n",
      "Baseline Loss: 2.6891 | Actual Loss: 0.2027\n",
      "Baseline Loss: 2.6770 | Actual Loss: 0.2743\n",
      "Baseline Loss: 2.7115 | Actual Loss: 0.1935\n",
      "Baseline Loss: 2.6638 | Actual Loss: 0.1934\n",
      "Baseline Loss: 2.6680 | Actual Loss: 0.3166\n",
      "Baseline Loss: 2.6556 | Actual Loss: 0.2478\n",
      "Baseline Loss: 2.6412 | Actual Loss: 0.3827\n",
      "Baseline Loss: 2.6352 | Actual Loss: 0.1997\n",
      "Baseline Loss: 2.6899 | Actual Loss: 0.1445\n",
      "Baseline Loss: 2.6807 | Actual Loss: 0.2357\n",
      "Baseline Loss: 2.6629 | Actual Loss: 0.4736\n",
      "Baseline Loss: 2.6668 | Actual Loss: 0.3806\n",
      "Baseline Loss: 2.6414 | Actual Loss: 0.2358\n",
      "Baseline Loss: 2.3008 | Actual Loss: 0.1510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 129/1000 [01:00<06:47,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6857 | Actual Loss: 0.3257\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3302\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3303\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3499\n",
      "Epoch 129/1000: Train Loss: 0.2665, Val Loss: 0.3341\n",
      "Baseline Loss: 2.6896 | Actual Loss: 0.1339\n",
      "Baseline Loss: 2.6392 | Actual Loss: 0.1772\n",
      "Baseline Loss: 2.6625 | Actual Loss: 0.2713\n",
      "Baseline Loss: 2.6749 | Actual Loss: 0.2087\n",
      "Baseline Loss: 2.6823 | Actual Loss: 0.2404\n",
      "Baseline Loss: 2.6560 | Actual Loss: 0.2038\n",
      "Baseline Loss: 2.7204 | Actual Loss: 0.2578\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.2137\n",
      "Baseline Loss: 2.6586 | Actual Loss: 0.2563\n",
      "Baseline Loss: 2.6279 | Actual Loss: 0.2565\n",
      "Baseline Loss: 2.6676 | Actual Loss: 0.3249\n",
      "Baseline Loss: 2.6691 | Actual Loss: 0.5047\n",
      "Baseline Loss: 2.6938 | Actual Loss: 0.3644\n",
      "Baseline Loss: 2.6607 | Actual Loss: 0.2759\n",
      "Baseline Loss: 2.6859 | Actual Loss: 0.2002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 130/1000 [01:01<06:53,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2957 | Actual Loss: 0.1743\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.6162\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3291\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3796\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3905\n",
      "Epoch 130/1000: Train Loss: 0.2540, Val Loss: 0.4288\n",
      "Baseline Loss: 2.6873 | Actual Loss: 0.3048\n",
      "Baseline Loss: 2.6438 | Actual Loss: 0.3779\n",
      "Baseline Loss: 2.6850 | Actual Loss: 0.1398\n",
      "Baseline Loss: 2.6527 | Actual Loss: 0.2103\n",
      "Baseline Loss: 2.6935 | Actual Loss: 0.3031\n",
      "Baseline Loss: 2.6557 | Actual Loss: 0.4151\n",
      "Baseline Loss: 2.6799 | Actual Loss: 0.3380\n",
      "Baseline Loss: 2.6494 | Actual Loss: 0.1980\n",
      "Baseline Loss: 2.6832 | Actual Loss: 0.3141\n",
      "Baseline Loss: 2.6584 | Actual Loss: 0.1956\n",
      "Baseline Loss: 2.6293 | Actual Loss: 0.2312\n",
      "Baseline Loss: 2.7067 | Actual Loss: 0.2620\n",
      "Baseline Loss: 2.7139 | Actual Loss: 0.1812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 131/1000 [01:01<07:01,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6522 | Actual Loss: 0.4407\n",
      "Baseline Loss: 2.7507 | Actual Loss: 0.2887\n",
      "Baseline Loss: 2.2960 | Actual Loss: 0.1429\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4256\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.4123\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.4276\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3925\n",
      "Epoch 131/1000: Train Loss: 0.2715, Val Loss: 0.4145\n",
      "Baseline Loss: 2.6750 | Actual Loss: 0.2870\n",
      "Baseline Loss: 2.6756 | Actual Loss: 0.4048\n",
      "Baseline Loss: 2.6796 | Actual Loss: 0.2190\n",
      "Baseline Loss: 2.6771 | Actual Loss: 0.3413\n",
      "Baseline Loss: 2.7094 | Actual Loss: 0.2077\n",
      "Baseline Loss: 2.7107 | Actual Loss: 0.4399\n",
      "Baseline Loss: 2.6737 | Actual Loss: 0.3302\n",
      "Baseline Loss: 2.6843 | Actual Loss: 0.2632\n",
      "Baseline Loss: 2.6425 | Actual Loss: 0.3558\n",
      "Baseline Loss: 2.6711 | Actual Loss: 0.2458\n",
      "Baseline Loss: 2.6900 | Actual Loss: 0.3290\n",
      "Baseline Loss: 2.6222 | Actual Loss: 0.2622\n",
      "Baseline Loss: 2.6534 | Actual Loss: 0.1625\n",
      "Baseline Loss: 2.6765 | Actual Loss: 0.1704\n",
      "Baseline Loss: 2.6728 | Actual Loss: 0.2156\n",
      "Baseline Loss: 2.2767 | Actual Loss: 0.1281\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4395\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3735\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 132/1000 [01:02<07:08,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6194 | Actual Loss: 0.3661\n",
      "Epoch 132/1000: Train Loss: 0.2727, Val Loss: 0.3801\n",
      "Baseline Loss: 2.6879 | Actual Loss: 0.5208\n",
      "Baseline Loss: 2.6614 | Actual Loss: 0.3078\n",
      "Baseline Loss: 2.6933 | Actual Loss: 0.1951\n",
      "Baseline Loss: 2.6352 | Actual Loss: 0.2058\n",
      "Baseline Loss: 2.6680 | Actual Loss: 0.1926\n",
      "Baseline Loss: 2.6757 | Actual Loss: 0.2679\n",
      "Baseline Loss: 2.7200 | Actual Loss: 0.2996\n",
      "Baseline Loss: 2.6452 | Actual Loss: 0.1422\n",
      "Baseline Loss: 2.6902 | Actual Loss: 0.1719\n",
      "Baseline Loss: 2.6265 | Actual Loss: 0.1900\n",
      "Baseline Loss: 2.6733 | Actual Loss: 0.1923\n",
      "Baseline Loss: 2.6989 | Actual Loss: 0.1426\n",
      "Baseline Loss: 2.7001 | Actual Loss: 0.2596\n",
      "Baseline Loss: 2.6799 | Actual Loss: 0.2212\n",
      "Baseline Loss: 2.6666 | Actual Loss: 0.1262\n",
      "Baseline Loss: 2.2426 | Actual Loss: 0.2409\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4143\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.4201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 133/1000 [01:02<06:53,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6381 | Actual Loss: 0.3793\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3144\n",
      "Epoch 133/1000: Train Loss: 0.2298, Val Loss: 0.3820\n",
      "Baseline Loss: 2.7034 | Actual Loss: 0.1999\n",
      "Baseline Loss: 2.6799 | Actual Loss: 0.3866\n",
      "Baseline Loss: 2.6824 | Actual Loss: 0.1603\n",
      "Baseline Loss: 2.6707 | Actual Loss: 0.1977\n",
      "Baseline Loss: 2.6709 | Actual Loss: 0.2448\n",
      "Baseline Loss: 2.6527 | Actual Loss: 0.2048\n",
      "Baseline Loss: 2.6784 | Actual Loss: 0.2183\n",
      "Baseline Loss: 2.6844 | Actual Loss: 0.2377\n",
      "Baseline Loss: 2.6762 | Actual Loss: 0.2115\n",
      "Baseline Loss: 2.6935 | Actual Loss: 0.3823\n",
      "Baseline Loss: 2.6607 | Actual Loss: 0.1908\n",
      "Baseline Loss: 2.6768 | Actual Loss: 0.2609\n",
      "Baseline Loss: 2.6845 | Actual Loss: 0.2494\n",
      "Baseline Loss: 2.6602 | Actual Loss: 0.2919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 134/1000 [01:03<06:59,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6631 | Actual Loss: 0.2133\n",
      "Baseline Loss: 2.2888 | Actual Loss: 0.1214\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5756\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.2840\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3339\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2610\n",
      "Epoch 134/1000: Train Loss: 0.2357, Val Loss: 0.3636\n",
      "Baseline Loss: 2.7073 | Actual Loss: 0.1928\n",
      "Baseline Loss: 2.6543 | Actual Loss: 0.1682\n",
      "Baseline Loss: 2.6564 | Actual Loss: 0.2981\n",
      "Baseline Loss: 2.6353 | Actual Loss: 0.3047\n",
      "Baseline Loss: 2.6574 | Actual Loss: 0.1668\n",
      "Baseline Loss: 2.6906 | Actual Loss: 0.2834\n",
      "Baseline Loss: 2.6625 | Actual Loss: 0.1873\n",
      "Baseline Loss: 2.6649 | Actual Loss: 0.2745\n",
      "Baseline Loss: 2.7269 | Actual Loss: 0.2352\n",
      "Baseline Loss: 2.6892 | Actual Loss: 0.3044\n",
      "Baseline Loss: 2.6736 | Actual Loss: 0.1356\n",
      "Baseline Loss: 2.6470 | Actual Loss: 0.2290\n",
      "Baseline Loss: 2.6895 | Actual Loss: 0.3623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▎        | 135/1000 [01:03<07:06,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6478 | Actual Loss: 0.2727\n",
      "Baseline Loss: 2.6590 | Actual Loss: 0.2118\n",
      "Baseline Loss: 2.3129 | Actual Loss: 0.0748\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.3848\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3779\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2911\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3132\n",
      "Epoch 135/1000: Train Loss: 0.2313, Val Loss: 0.3417\n",
      "Baseline Loss: 2.6762 | Actual Loss: 0.4363\n",
      "Baseline Loss: 2.6744 | Actual Loss: 0.1400\n",
      "Baseline Loss: 2.6858 | Actual Loss: 0.2516\n",
      "Baseline Loss: 2.6576 | Actual Loss: 0.4010\n",
      "Baseline Loss: 2.6808 | Actual Loss: 0.2592\n",
      "Baseline Loss: 2.6427 | Actual Loss: 0.3766\n",
      "Baseline Loss: 2.7603 | Actual Loss: 0.2612\n",
      "Baseline Loss: 2.6509 | Actual Loss: 0.3022\n",
      "Baseline Loss: 2.6588 | Actual Loss: 0.4453\n",
      "Baseline Loss: 2.6689 | Actual Loss: 0.2032\n",
      "Baseline Loss: 2.6669 | Actual Loss: 0.2829\n",
      "Baseline Loss: 2.7231 | Actual Loss: 0.2944\n",
      "Baseline Loss: 2.6866 | Actual Loss: 0.2426\n",
      "Baseline Loss: 2.7257 | Actual Loss: 0.2175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▎        | 136/1000 [01:04<06:41,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6618 | Actual Loss: 0.3195\n",
      "Baseline Loss: 2.2209 | Actual Loss: 0.0915\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5468\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.4247\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3132\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3953\n",
      "Epoch 136/1000: Train Loss: 0.2828, Val Loss: 0.4200\n",
      "Baseline Loss: 2.6805 | Actual Loss: 0.2159\n",
      "Baseline Loss: 2.6866 | Actual Loss: 0.2378\n",
      "Baseline Loss: 2.6108 | Actual Loss: 0.3800\n",
      "Baseline Loss: 2.6571 | Actual Loss: 0.2646\n",
      "Baseline Loss: 2.7219 | Actual Loss: 0.2390\n",
      "Baseline Loss: 2.6968 | Actual Loss: 0.2209\n",
      "Baseline Loss: 2.6689 | Actual Loss: 0.1660\n",
      "Baseline Loss: 2.6791 | Actual Loss: 0.2448\n",
      "Baseline Loss: 2.6704 | Actual Loss: 0.2454\n",
      "Baseline Loss: 2.6854 | Actual Loss: 0.3255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▎        | 137/1000 [01:04<06:48,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7008 | Actual Loss: 0.1615\n",
      "Baseline Loss: 2.6495 | Actual Loss: 0.1579\n",
      "Baseline Loss: 2.7228 | Actual Loss: 0.3216\n",
      "Baseline Loss: 2.6492 | Actual Loss: 0.2420\n",
      "Baseline Loss: 2.6731 | Actual Loss: 0.2179\n",
      "Baseline Loss: 2.2800 | Actual Loss: 0.1233\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5101\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.4258\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2896\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3372\n",
      "Epoch 137/1000: Train Loss: 0.2353, Val Loss: 0.3907\n",
      "Baseline Loss: 2.6665 | Actual Loss: 0.2240\n",
      "Baseline Loss: 2.6690 | Actual Loss: 0.1931\n",
      "Baseline Loss: 2.6450 | Actual Loss: 0.2241\n",
      "Baseline Loss: 2.6946 | Actual Loss: 0.1060\n",
      "Baseline Loss: 2.6935 | Actual Loss: 0.2058\n",
      "Baseline Loss: 2.6625 | Actual Loss: 0.3166\n",
      "Baseline Loss: 2.6307 | Actual Loss: 0.2982\n",
      "Baseline Loss: 2.6778 | Actual Loss: 0.3547\n",
      "Baseline Loss: 2.6811 | Actual Loss: 0.1678\n",
      "Baseline Loss: 2.6618 | Actual Loss: 0.2340\n",
      "Baseline Loss: 2.6900 | Actual Loss: 0.3779\n",
      "Baseline Loss: 2.6500 | Actual Loss: 0.3086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 138/1000 [01:05<07:00,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7313 | Actual Loss: 0.3097\n",
      "Baseline Loss: 2.6633 | Actual Loss: 0.2625\n",
      "Baseline Loss: 2.6406 | Actual Loss: 0.1713\n",
      "Baseline Loss: 2.2354 | Actual Loss: 0.1905\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.3240\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.4490\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2186\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2852\n",
      "Epoch 138/1000: Train Loss: 0.2465, Val Loss: 0.3192\n",
      "New best validation loss: 0.3192\n",
      "Baseline Loss: 2.6621 | Actual Loss: 0.4327\n",
      "Baseline Loss: 2.6586 | Actual Loss: 0.2219\n",
      "Baseline Loss: 2.6895 | Actual Loss: 0.2552\n",
      "Baseline Loss: 2.7033 | Actual Loss: 0.0891\n",
      "Baseline Loss: 2.6443 | Actual Loss: 0.3239\n",
      "Baseline Loss: 2.7021 | Actual Loss: 0.2373\n",
      "Baseline Loss: 2.6631 | Actual Loss: 0.4087\n",
      "Baseline Loss: 2.7043 | Actual Loss: 0.2685\n",
      "Baseline Loss: 2.6637 | Actual Loss: 0.1460\n",
      "Baseline Loss: 2.6397 | Actual Loss: 0.2045\n",
      "Baseline Loss: 2.6835 | Actual Loss: 0.2123\n",
      "Baseline Loss: 2.6476 | Actual Loss: 0.1862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 139/1000 [01:05<06:40,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6588 | Actual Loss: 0.2791\n",
      "Baseline Loss: 2.7271 | Actual Loss: 0.2676\n",
      "Baseline Loss: 2.6754 | Actual Loss: 0.1771\n",
      "Baseline Loss: 2.2909 | Actual Loss: 0.2189\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5212\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3468\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3565\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3609\n",
      "Epoch 139/1000: Train Loss: 0.2456, Val Loss: 0.3964\n",
      "Baseline Loss: 2.6475 | Actual Loss: 0.2246\n",
      "Baseline Loss: 2.6568 | Actual Loss: 0.3172\n",
      "Baseline Loss: 2.7037 | Actual Loss: 0.1825\n",
      "Baseline Loss: 2.6472 | Actual Loss: 0.2646\n",
      "Baseline Loss: 2.7182 | Actual Loss: 0.2429\n",
      "Baseline Loss: 2.6995 | Actual Loss: 0.2889\n",
      "Baseline Loss: 2.6355 | Actual Loss: 0.3287\n",
      "Baseline Loss: 2.7058 | Actual Loss: 0.3829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 140/1000 [01:06<06:44,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6608 | Actual Loss: 0.2710\n",
      "Baseline Loss: 2.6462 | Actual Loss: 0.2006\n",
      "Baseline Loss: 2.6898 | Actual Loss: 0.3125\n",
      "Baseline Loss: 2.6761 | Actual Loss: 0.1891\n",
      "Baseline Loss: 2.6818 | Actual Loss: 0.1884\n",
      "Baseline Loss: 2.6496 | Actual Loss: 0.1982\n",
      "Baseline Loss: 2.6586 | Actual Loss: 0.4979\n",
      "Baseline Loss: 2.2900 | Actual Loss: 0.3832\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4579\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.5904\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2650\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2562\n",
      "Epoch 140/1000: Train Loss: 0.2796, Val Loss: 0.3924\n",
      "Baseline Loss: 2.6340 | Actual Loss: 0.2108\n",
      "Baseline Loss: 2.6998 | Actual Loss: 0.2088\n",
      "Baseline Loss: 2.6833 | Actual Loss: 0.2159\n",
      "Baseline Loss: 2.6672 | Actual Loss: 0.2695\n",
      "Baseline Loss: 2.6904 | Actual Loss: 0.2793\n",
      "Baseline Loss: 2.6654 | Actual Loss: 0.1429\n",
      "Baseline Loss: 2.7024 | Actual Loss: 0.1476\n",
      "Baseline Loss: 2.6986 | Actual Loss: 0.2738\n",
      "Baseline Loss: 2.7006 | Actual Loss: 0.2125\n",
      "Baseline Loss: 2.6955 | Actual Loss: 0.2436\n",
      "Baseline Loss: 2.6698 | Actual Loss: 0.3718\n",
      "Baseline Loss: 2.6398 | Actual Loss: 0.3101\n",
      "Baseline Loss: 2.6759 | Actual Loss: 0.2577\n",
      "Baseline Loss: 2.6583 | Actual Loss: 0.2132\n",
      "Baseline Loss: 2.6736 | Actual Loss: 0.2480\n",
      "Baseline Loss: 2.2706 | Actual Loss: 0.0771\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4072\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 141/1000 [01:06<06:51,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6381 | Actual Loss: 0.3014\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4772\n",
      "Epoch 141/1000: Train Loss: 0.2302, Val Loss: 0.3864\n",
      "Baseline Loss: 2.6546 | Actual Loss: 0.2339\n",
      "Baseline Loss: 2.6330 | Actual Loss: 0.2742\n",
      "Baseline Loss: 2.6664 | Actual Loss: 0.3305\n",
      "Baseline Loss: 2.6901 | Actual Loss: 0.2055\n",
      "Baseline Loss: 2.6876 | Actual Loss: 0.3128\n",
      "Baseline Loss: 2.6481 | Actual Loss: 0.1338\n",
      "Baseline Loss: 2.6960 | Actual Loss: 0.2230\n",
      "Baseline Loss: 2.6433 | Actual Loss: 0.2503\n",
      "Baseline Loss: 2.6709 | Actual Loss: 0.1797\n",
      "Baseline Loss: 2.6979 | Actual Loss: 0.1321\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2513\n",
      "Baseline Loss: 2.6463 | Actual Loss: 0.1783\n",
      "Baseline Loss: 2.6807 | Actual Loss: 0.2888\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.2231\n",
      "Baseline Loss: 2.7092 | Actual Loss: 0.4022\n",
      "Baseline Loss: 2.2724 | Actual Loss: 0.2016\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4924\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.4480\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 142/1000 [01:07<06:31,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6194 | Actual Loss: 0.4245\n",
      "Epoch 142/1000: Train Loss: 0.2388, Val Loss: 0.4100\n",
      "Baseline Loss: 2.6838 | Actual Loss: 0.2489\n",
      "Baseline Loss: 2.6335 | Actual Loss: 0.1970\n",
      "Baseline Loss: 2.6922 | Actual Loss: 0.3768\n",
      "Baseline Loss: 2.6676 | Actual Loss: 0.2026\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.1678\n",
      "Baseline Loss: 2.6800 | Actual Loss: 0.3086\n",
      "Baseline Loss: 2.6905 | Actual Loss: 0.1895\n",
      "Baseline Loss: 2.6867 | Actual Loss: 0.1589\n",
      "Baseline Loss: 2.6516 | Actual Loss: 0.2302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 143/1000 [01:07<06:36,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6793 | Actual Loss: 0.3332\n",
      "Baseline Loss: 2.7345 | Actual Loss: 0.2861\n",
      "Baseline Loss: 2.6545 | Actual Loss: 0.2614\n",
      "Baseline Loss: 2.6558 | Actual Loss: 0.2985\n",
      "Baseline Loss: 2.6858 | Actual Loss: 0.1585\n",
      "Baseline Loss: 2.6603 | Actual Loss: 0.1628\n",
      "Baseline Loss: 2.2462 | Actual Loss: 0.2546\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4918\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.4748\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3402\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3243\n",
      "Epoch 143/1000: Train Loss: 0.2397, Val Loss: 0.4078\n",
      "Baseline Loss: 2.6872 | Actual Loss: 0.2820\n",
      "Baseline Loss: 2.6680 | Actual Loss: 0.1773\n",
      "Baseline Loss: 2.6554 | Actual Loss: 0.2655\n",
      "Baseline Loss: 2.7082 | Actual Loss: 0.1159\n",
      "Baseline Loss: 2.6730 | Actual Loss: 0.2471\n",
      "Baseline Loss: 2.6321 | Actual Loss: 0.2381\n",
      "Baseline Loss: 2.7269 | Actual Loss: 0.1146\n",
      "Baseline Loss: 2.6933 | Actual Loss: 0.2313\n",
      "Baseline Loss: 2.6935 | Actual Loss: 0.2681\n",
      "Baseline Loss: 2.6563 | Actual Loss: 0.1849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 144/1000 [01:07<06:30,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6752 | Actual Loss: 0.2806\n",
      "Baseline Loss: 2.6527 | Actual Loss: 0.2167\n",
      "Baseline Loss: 2.7038 | Actual Loss: 0.2837\n",
      "Baseline Loss: 2.6603 | Actual Loss: 0.4160\n",
      "Baseline Loss: 2.6618 | Actual Loss: 0.1375\n",
      "Baseline Loss: 2.2742 | Actual Loss: 0.1830\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5976\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.4385\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3252\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4316\n",
      "Epoch 144/1000: Train Loss: 0.2277, Val Loss: 0.4482\n",
      "Baseline Loss: 2.6725 | Actual Loss: 0.1691\n",
      "Baseline Loss: 2.6694 | Actual Loss: 0.4218\n",
      "Baseline Loss: 2.6931 | Actual Loss: 0.1532\n",
      "Baseline Loss: 2.6653 | Actual Loss: 0.1398\n",
      "Baseline Loss: 2.6904 | Actual Loss: 0.2158\n",
      "Baseline Loss: 2.6598 | Actual Loss: 0.3062\n",
      "Baseline Loss: 2.6693 | Actual Loss: 0.3313\n",
      "Baseline Loss: 2.6699 | Actual Loss: 0.1531\n",
      "Baseline Loss: 2.6885 | Actual Loss: 0.2352\n",
      "Baseline Loss: 2.6989 | Actual Loss: 0.2732\n",
      "Baseline Loss: 2.6866 | Actual Loss: 0.1561\n",
      "Baseline Loss: 2.6824 | Actual Loss: 0.1777\n",
      "Baseline Loss: 2.6369 | Actual Loss: 0.1316\n",
      "Baseline Loss: 2.6485 | Actual Loss: 0.2390\n",
      "Baseline Loss: 2.6501 | Actual Loss: 0.2939\n",
      "Baseline Loss: 2.2691 | Actual Loss: 0.1185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 145/1000 [01:08<06:45,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6857 | Actual Loss: 0.4237\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3489\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.4120\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4749\n",
      "Epoch 145/1000: Train Loss: 0.2197, Val Loss: 0.4149\n",
      "Baseline Loss: 2.6767 | Actual Loss: 0.1768\n",
      "Baseline Loss: 2.6498 | Actual Loss: 0.3024\n",
      "Baseline Loss: 2.6563 | Actual Loss: 0.3198\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.3301\n",
      "Baseline Loss: 2.6494 | Actual Loss: 0.2603\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.1602\n",
      "Baseline Loss: 2.6808 | Actual Loss: 0.4069\n",
      "Baseline Loss: 2.6638 | Actual Loss: 0.1625\n",
      "Baseline Loss: 2.7239 | Actual Loss: 0.2890\n",
      "Baseline Loss: 2.6632 | Actual Loss: 0.1956\n",
      "Baseline Loss: 2.6791 | Actual Loss: 0.2750\n",
      "Baseline Loss: 2.6715 | Actual Loss: 0.2471\n",
      "Baseline Loss: 2.6492 | Actual Loss: 0.3078\n",
      "Baseline Loss: 2.6915 | Actual Loss: 0.2877\n",
      "Baseline Loss: 2.6967 | Actual Loss: 0.2253\n",
      "Baseline Loss: 2.3098 | Actual Loss: 0.0900\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4523\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 146/1000 [01:08<06:20,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6381 | Actual Loss: 0.3068\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3510\n",
      "Epoch 146/1000: Train Loss: 0.2523, Val Loss: 0.3716\n",
      "Baseline Loss: 2.6822 | Actual Loss: 0.3395\n",
      "Baseline Loss: 2.7373 | Actual Loss: 0.3598\n",
      "Baseline Loss: 2.7171 | Actual Loss: 0.3684\n",
      "Baseline Loss: 2.6761 | Actual Loss: 0.2644\n",
      "Baseline Loss: 2.6658 | Actual Loss: 0.2543\n",
      "Baseline Loss: 2.6825 | Actual Loss: 0.2787\n",
      "Baseline Loss: 2.6948 | Actual Loss: 0.2101\n",
      "Baseline Loss: 2.6838 | Actual Loss: 0.1972\n",
      "Baseline Loss: 2.6805 | Actual Loss: 0.4413\n",
      "Baseline Loss: 2.6197 | Actual Loss: 0.3465\n",
      "Baseline Loss: 2.6380 | Actual Loss: 0.4022\n",
      "Baseline Loss: 2.6659 | Actual Loss: 0.3244\n",
      "Baseline Loss: 2.6712 | Actual Loss: 0.2353\n",
      "Baseline Loss: 2.6800 | Actual Loss: 0.1478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 147/1000 [01:09<06:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6598 | Actual Loss: 0.5262\n",
      "Baseline Loss: 2.3071 | Actual Loss: 0.0866\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4074\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.4436\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3042\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3674\n",
      "Epoch 147/1000: Train Loss: 0.2989, Val Loss: 0.3807\n",
      "Baseline Loss: 2.6518 | Actual Loss: 0.3697\n",
      "Baseline Loss: 2.7227 | Actual Loss: 0.2274\n",
      "Baseline Loss: 2.6772 | Actual Loss: 0.3468\n",
      "Baseline Loss: 2.7123 | Actual Loss: 0.2686\n",
      "Baseline Loss: 2.6692 | Actual Loss: 0.1692\n",
      "Baseline Loss: 2.6557 | Actual Loss: 0.1784\n",
      "Baseline Loss: 2.6903 | Actual Loss: 0.3650\n",
      "Baseline Loss: 2.6694 | Actual Loss: 0.2742\n",
      "Baseline Loss: 2.6652 | Actual Loss: 0.3913\n",
      "Baseline Loss: 2.6619 | Actual Loss: 0.2725\n",
      "Baseline Loss: 2.6701 | Actual Loss: 0.2067\n",
      "Baseline Loss: 2.6655 | Actual Loss: 0.1767\n",
      "Baseline Loss: 2.6635 | Actual Loss: 0.1385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 148/1000 [01:09<06:43,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6558 | Actual Loss: 0.1600\n",
      "Baseline Loss: 2.6646 | Actual Loss: 0.2471\n",
      "Baseline Loss: 2.2283 | Actual Loss: 0.1260\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5709\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.4361\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2477\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3821\n",
      "Epoch 148/1000: Train Loss: 0.2449, Val Loss: 0.4092\n",
      "Baseline Loss: 2.6842 | Actual Loss: 0.3226\n",
      "Baseline Loss: 2.7028 | Actual Loss: 0.3754\n",
      "Baseline Loss: 2.7175 | Actual Loss: 0.2829\n",
      "Baseline Loss: 2.6741 | Actual Loss: 0.2605\n",
      "Baseline Loss: 2.6716 | Actual Loss: 0.1605\n",
      "Baseline Loss: 2.6735 | Actual Loss: 0.1722\n",
      "Baseline Loss: 2.7120 | Actual Loss: 0.1501\n",
      "Baseline Loss: 2.6624 | Actual Loss: 0.4382\n",
      "Baseline Loss: 2.7251 | Actual Loss: 0.2708\n",
      "Baseline Loss: 2.6706 | Actual Loss: 0.3649\n",
      "Baseline Loss: 2.6766 | Actual Loss: 0.4618\n",
      "Baseline Loss: 2.6443 | Actual Loss: 0.2718\n",
      "Baseline Loss: 2.6478 | Actual Loss: 0.1335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 149/1000 [01:10<06:26,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6857 | Actual Loss: 0.2935\n",
      "Baseline Loss: 2.6875 | Actual Loss: 0.3094\n",
      "Baseline Loss: 2.2026 | Actual Loss: 0.2449\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.3377\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3457\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3010\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4809\n",
      "Epoch 149/1000: Train Loss: 0.2821, Val Loss: 0.3663\n",
      "Baseline Loss: 2.6593 | Actual Loss: 0.1332\n",
      "Baseline Loss: 2.7424 | Actual Loss: 0.1135\n",
      "Baseline Loss: 2.6509 | Actual Loss: 0.1210\n",
      "Baseline Loss: 2.6964 | Actual Loss: 0.1542\n",
      "Baseline Loss: 2.6749 | Actual Loss: 0.2810\n",
      "Baseline Loss: 2.6621 | Actual Loss: 0.2783\n",
      "Baseline Loss: 2.6596 | Actual Loss: 0.1502\n",
      "Baseline Loss: 2.6463 | Actual Loss: 0.2599\n",
      "Baseline Loss: 2.6612 | Actual Loss: 0.1537\n",
      "Baseline Loss: 2.6731 | Actual Loss: 0.2492\n",
      "Baseline Loss: 2.6723 | Actual Loss: 0.1953\n",
      "Baseline Loss: 2.6942 | Actual Loss: 0.2115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 150/1000 [01:10<06:39,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6571 | Actual Loss: 0.2485\n",
      "Baseline Loss: 2.6516 | Actual Loss: 0.2337\n",
      "Baseline Loss: 2.6952 | Actual Loss: 0.1896\n",
      "Baseline Loss: 2.2169 | Actual Loss: 0.0734\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5637\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3852\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3068\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4581\n",
      "Epoch 150/1000: Train Loss: 0.1904, Val Loss: 0.4285\n",
      "Baseline Loss: 2.6463 | Actual Loss: 0.1808\n",
      "Baseline Loss: 2.6693 | Actual Loss: 0.2811\n",
      "Baseline Loss: 2.6955 | Actual Loss: 0.2476\n",
      "Baseline Loss: 2.6871 | Actual Loss: 0.2289\n",
      "Baseline Loss: 2.6650 | Actual Loss: 0.3212\n",
      "Baseline Loss: 2.6603 | Actual Loss: 0.2011\n",
      "Baseline Loss: 2.6594 | Actual Loss: 0.1701\n",
      "Baseline Loss: 2.6672 | Actual Loss: 0.2440\n",
      "Baseline Loss: 2.6780 | Actual Loss: 0.2810\n",
      "Baseline Loss: 2.6803 | Actual Loss: 0.4223\n",
      "Baseline Loss: 2.6855 | Actual Loss: 0.2773\n",
      "Baseline Loss: 2.6905 | Actual Loss: 0.1928\n",
      "Baseline Loss: 2.6780 | Actual Loss: 0.2987\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.2979\n",
      "Baseline Loss: 2.6923 | Actual Loss: 0.3013\n",
      "Baseline Loss: 2.2681 | Actual Loss: 0.1459\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4624\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.4127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 151/1000 [01:11<06:49,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6381 | Actual Loss: 0.4049\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3088\n",
      "Epoch 151/1000: Train Loss: 0.2558, Val Loss: 0.3972\n",
      "Baseline Loss: 2.7340 | Actual Loss: 0.5580\n",
      "Baseline Loss: 2.6749 | Actual Loss: 0.2668\n",
      "Baseline Loss: 2.6041 | Actual Loss: 0.2099\n",
      "Baseline Loss: 2.6864 | Actual Loss: 0.2365\n",
      "Baseline Loss: 2.6767 | Actual Loss: 0.1834\n",
      "Baseline Loss: 2.6940 | Actual Loss: 0.1895\n",
      "Baseline Loss: 2.6684 | Actual Loss: 0.2374\n",
      "Baseline Loss: 2.6733 | Actual Loss: 0.1716\n",
      "Baseline Loss: 2.6756 | Actual Loss: 0.2244\n",
      "Baseline Loss: 2.6490 | Actual Loss: 0.1096\n",
      "Baseline Loss: 2.6903 | Actual Loss: 0.2489\n",
      "Baseline Loss: 2.6732 | Actual Loss: 0.1954\n",
      "Baseline Loss: 2.6563 | Actual Loss: 0.2010\n",
      "Baseline Loss: 2.6801 | Actual Loss: 0.2441\n",
      "Baseline Loss: 2.6331 | Actual Loss: 0.2049\n",
      "Baseline Loss: 2.2520 | Actual Loss: 0.1246\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.6127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 152/1000 [01:11<06:59,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6990 | Actual Loss: 0.4686\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2879\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3708\n",
      "Epoch 152/1000: Train Loss: 0.2254, Val Loss: 0.4350\n",
      "Baseline Loss: 2.6274 | Actual Loss: 0.1505\n",
      "Baseline Loss: 2.7205 | Actual Loss: 0.1768\n",
      "Baseline Loss: 2.6634 | Actual Loss: 0.2081\n",
      "Baseline Loss: 2.6891 | Actual Loss: 0.2602\n",
      "Baseline Loss: 2.6555 | Actual Loss: 0.3446\n",
      "Baseline Loss: 2.6432 | Actual Loss: 0.2834\n",
      "Baseline Loss: 2.6366 | Actual Loss: 0.2017\n",
      "Baseline Loss: 2.6823 | Actual Loss: 0.2734\n",
      "Baseline Loss: 2.6756 | Actual Loss: 0.3118\n",
      "Baseline Loss: 2.6336 | Actual Loss: 0.1585\n",
      "Baseline Loss: 2.6938 | Actual Loss: 0.2298\n",
      "Baseline Loss: 2.6748 | Actual Loss: 0.0690\n",
      "Baseline Loss: 2.6923 | Actual Loss: 0.1814\n",
      "Baseline Loss: 2.6452 | Actual Loss: 0.6687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 153/1000 [01:12<06:40,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7035 | Actual Loss: 0.1914\n",
      "Baseline Loss: 2.2889 | Actual Loss: 0.1877\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.6177\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.5151\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3142\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4006\n",
      "Epoch 153/1000: Train Loss: 0.2436, Val Loss: 0.4619\n",
      "Baseline Loss: 2.6781 | Actual Loss: 0.3347\n",
      "Baseline Loss: 2.6365 | Actual Loss: 0.1917\n",
      "Baseline Loss: 2.6797 | Actual Loss: 0.4753\n",
      "Baseline Loss: 2.6722 | Actual Loss: 0.1030\n",
      "Baseline Loss: 2.6778 | Actual Loss: 0.2688\n",
      "Baseline Loss: 2.6481 | Actual Loss: 0.3083\n",
      "Baseline Loss: 2.7194 | Actual Loss: 0.2959\n",
      "Baseline Loss: 2.6981 | Actual Loss: 0.3372\n",
      "Baseline Loss: 2.6667 | Actual Loss: 0.2816\n",
      "Baseline Loss: 2.6604 | Actual Loss: 0.2601\n",
      "Baseline Loss: 2.6811 | Actual Loss: 0.2645\n",
      "Baseline Loss: 2.6713 | Actual Loss: 0.3116\n",
      "Baseline Loss: 2.6916 | Actual Loss: 0.3043\n",
      "Baseline Loss: 2.6576 | Actual Loss: 0.1987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 154/1000 [01:12<06:48,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6730 | Actual Loss: 0.1944\n",
      "Baseline Loss: 2.2511 | Actual Loss: 0.0473\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5151\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.4466\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2954\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4230\n",
      "Epoch 154/1000: Train Loss: 0.2611, Val Loss: 0.4200\n",
      "Baseline Loss: 2.6772 | Actual Loss: 0.2405\n",
      "Baseline Loss: 2.6752 | Actual Loss: 0.2831\n",
      "Baseline Loss: 2.6827 | Actual Loss: 0.1969\n",
      "Baseline Loss: 2.6317 | Actual Loss: 0.2422\n",
      "Baseline Loss: 2.6601 | Actual Loss: 0.1499\n",
      "Baseline Loss: 2.7107 | Actual Loss: 0.1445\n",
      "Baseline Loss: 2.6704 | Actual Loss: 0.2703\n",
      "Baseline Loss: 2.6897 | Actual Loss: 0.2143\n",
      "Baseline Loss: 2.6417 | Actual Loss: 0.3329\n",
      "Baseline Loss: 2.7083 | Actual Loss: 0.1472\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.1744\n",
      "Baseline Loss: 2.6727 | Actual Loss: 0.3451\n",
      "Baseline Loss: 2.6717 | Actual Loss: 0.2042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 155/1000 [01:13<06:54,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6913 | Actual Loss: 0.3457\n",
      "Baseline Loss: 2.6417 | Actual Loss: 0.3942\n",
      "Baseline Loss: 2.2429 | Actual Loss: 0.0756\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4575\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.4356\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2938\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3262\n",
      "Epoch 155/1000: Train Loss: 0.2351, Val Loss: 0.3783\n",
      "Baseline Loss: 2.6737 | Actual Loss: 0.1967\n",
      "Baseline Loss: 2.6683 | Actual Loss: 0.1742\n",
      "Baseline Loss: 2.6834 | Actual Loss: 0.1716\n",
      "Baseline Loss: 2.6623 | Actual Loss: 0.1955\n",
      "Baseline Loss: 2.6737 | Actual Loss: 0.4658\n",
      "Baseline Loss: 2.6910 | Actual Loss: 0.1160\n",
      "Baseline Loss: 2.6530 | Actual Loss: 0.2380\n",
      "Baseline Loss: 2.6886 | Actual Loss: 0.2161\n",
      "Baseline Loss: 2.6353 | Actual Loss: 0.3597\n",
      "Baseline Loss: 2.6784 | Actual Loss: 0.1867\n",
      "Baseline Loss: 2.6662 | Actual Loss: 0.2275\n",
      "Baseline Loss: 2.6671 | Actual Loss: 0.1709\n",
      "Baseline Loss: 2.6321 | Actual Loss: 0.2275\n",
      "Baseline Loss: 2.7098 | Actual Loss: 0.2521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 156/1000 [01:13<06:33,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6603 | Actual Loss: 0.1438\n",
      "Baseline Loss: 2.2590 | Actual Loss: 0.2011\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.3602\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.4261\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2666\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.5067\n",
      "Epoch 156/1000: Train Loss: 0.2215, Val Loss: 0.3899\n",
      "Baseline Loss: 2.6759 | Actual Loss: 0.2927\n",
      "Baseline Loss: 2.7417 | Actual Loss: 0.2172\n",
      "Baseline Loss: 2.6728 | Actual Loss: 0.2979\n",
      "Baseline Loss: 2.6404 | Actual Loss: 0.3053\n",
      "Baseline Loss: 2.6604 | Actual Loss: 0.3092\n",
      "Baseline Loss: 2.6454 | Actual Loss: 0.1264\n",
      "Baseline Loss: 2.7205 | Actual Loss: 0.1439\n",
      "Baseline Loss: 2.6749 | Actual Loss: 0.2475\n",
      "Baseline Loss: 2.7037 | Actual Loss: 0.1398\n",
      "Baseline Loss: 2.6601 | Actual Loss: 0.4349\n",
      "Baseline Loss: 2.6830 | Actual Loss: 0.1818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 157/1000 [01:14<06:46,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6709 | Actual Loss: 0.2560\n",
      "Baseline Loss: 2.6237 | Actual Loss: 0.2201\n",
      "Baseline Loss: 2.7076 | Actual Loss: 0.3180\n",
      "Baseline Loss: 2.6728 | Actual Loss: 0.3437\n",
      "Baseline Loss: 2.2809 | Actual Loss: 0.1662\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4372\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3327\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2930\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3994\n",
      "Epoch 157/1000: Train Loss: 0.2500, Val Loss: 0.3656\n",
      "Baseline Loss: 2.6982 | Actual Loss: 0.5239\n",
      "Baseline Loss: 2.6589 | Actual Loss: 0.3080\n",
      "Baseline Loss: 2.7076 | Actual Loss: 0.3307\n",
      "Baseline Loss: 2.7410 | Actual Loss: 0.2620\n",
      "Baseline Loss: 2.6772 | Actual Loss: 0.2500\n",
      "Baseline Loss: 2.6946 | Actual Loss: 0.2707\n",
      "Baseline Loss: 2.6067 | Actual Loss: 0.2098\n",
      "Baseline Loss: 2.6789 | Actual Loss: 0.1285\n",
      "Baseline Loss: 2.6992 | Actual Loss: 0.2427\n",
      "Baseline Loss: 2.6386 | Actual Loss: 0.2372\n",
      "Baseline Loss: 2.7032 | Actual Loss: 0.3545\n",
      "Baseline Loss: 2.6926 | Actual Loss: 0.1620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 158/1000 [01:14<06:47,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6791 | Actual Loss: 0.2588\n",
      "Baseline Loss: 2.6417 | Actual Loss: 0.1834\n",
      "Baseline Loss: 2.6340 | Actual Loss: 0.1646\n",
      "Baseline Loss: 2.2276 | Actual Loss: 0.1801\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4730\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.5058\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3548\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3037\n",
      "Epoch 158/1000: Train Loss: 0.2542, Val Loss: 0.4093\n",
      "Baseline Loss: 2.6956 | Actual Loss: 0.1179\n",
      "Baseline Loss: 2.6841 | Actual Loss: 0.2412\n",
      "Baseline Loss: 2.6623 | Actual Loss: 0.2189\n",
      "Baseline Loss: 2.6893 | Actual Loss: 0.2855\n",
      "Baseline Loss: 2.6923 | Actual Loss: 0.1926\n",
      "Baseline Loss: 2.6524 | Actual Loss: 0.1241\n",
      "Baseline Loss: 2.6605 | Actual Loss: 0.1690\n",
      "Baseline Loss: 2.7122 | Actual Loss: 0.3110\n",
      "Baseline Loss: 2.6790 | Actual Loss: 0.3008\n",
      "Baseline Loss: 2.6884 | Actual Loss: 0.2801\n",
      "Baseline Loss: 2.6965 | Actual Loss: 0.3774\n",
      "Baseline Loss: 2.6653 | Actual Loss: 0.1923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 159/1000 [01:15<06:28,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7072 | Actual Loss: 0.2445\n",
      "Baseline Loss: 2.6715 | Actual Loss: 0.2292\n",
      "Baseline Loss: 2.6419 | Actual Loss: 0.2604\n",
      "Baseline Loss: 2.2699 | Actual Loss: 0.0839\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4384\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3819\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2110\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4059\n",
      "Epoch 159/1000: Train Loss: 0.2268, Val Loss: 0.3593\n",
      "Baseline Loss: 2.7107 | Actual Loss: 0.1400\n",
      "Baseline Loss: 2.6888 | Actual Loss: 0.2177\n",
      "Baseline Loss: 2.6588 | Actual Loss: 0.1976\n",
      "Baseline Loss: 2.6793 | Actual Loss: 0.2519\n",
      "Baseline Loss: 2.6688 | Actual Loss: 0.3577\n",
      "Baseline Loss: 2.6736 | Actual Loss: 0.2929\n",
      "Baseline Loss: 2.6286 | Actual Loss: 0.2573\n",
      "Baseline Loss: 2.7151 | Actual Loss: 0.2724\n",
      "Baseline Loss: 2.6444 | Actual Loss: 0.6710\n",
      "Baseline Loss: 2.6676 | Actual Loss: 0.1797\n",
      "Baseline Loss: 2.6863 | Actual Loss: 0.2158\n",
      "Baseline Loss: 2.6874 | Actual Loss: 0.2025\n",
      "Baseline Loss: 2.6844 | Actual Loss: 0.3286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 160/1000 [01:15<06:39,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6300 | Actual Loss: 0.2878\n",
      "Baseline Loss: 2.6918 | Actual Loss: 0.3201\n",
      "Baseline Loss: 2.2963 | Actual Loss: 0.2425\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4631\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3851\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2494\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3613\n",
      "Epoch 160/1000: Train Loss: 0.2772, Val Loss: 0.3647\n",
      "Baseline Loss: 2.6335 | Actual Loss: 0.4265\n",
      "Baseline Loss: 2.6577 | Actual Loss: 0.2365\n",
      "Baseline Loss: 2.6829 | Actual Loss: 0.1931\n",
      "Baseline Loss: 2.6908 | Actual Loss: 0.1974\n",
      "Baseline Loss: 2.6369 | Actual Loss: 0.2339\n",
      "Baseline Loss: 2.6498 | Actual Loss: 0.2774\n",
      "Baseline Loss: 2.6748 | Actual Loss: 0.2868\n",
      "Baseline Loss: 2.7025 | Actual Loss: 0.2836\n",
      "Baseline Loss: 2.7122 | Actual Loss: 0.1165\n",
      "Baseline Loss: 2.6863 | Actual Loss: 0.2053\n",
      "Baseline Loss: 2.6562 | Actual Loss: 0.2887\n",
      "Baseline Loss: 2.6846 | Actual Loss: 0.0865\n",
      "Baseline Loss: 2.6703 | Actual Loss: 0.2433\n",
      "Baseline Loss: 2.6372 | Actual Loss: 0.1508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 161/1000 [01:16<06:46,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6328 | Actual Loss: 0.2302\n",
      "Baseline Loss: 2.2832 | Actual Loss: 0.1574\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4208\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3078\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3521\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4084\n",
      "Epoch 161/1000: Train Loss: 0.2259, Val Loss: 0.3723\n",
      "Baseline Loss: 2.6664 | Actual Loss: 0.1797\n",
      "Baseline Loss: 2.6704 | Actual Loss: 0.2763\n",
      "Baseline Loss: 2.6896 | Actual Loss: 0.2434\n",
      "Baseline Loss: 2.6591 | Actual Loss: 0.2439\n",
      "Baseline Loss: 2.6960 | Actual Loss: 0.0959\n",
      "Baseline Loss: 2.7111 | Actual Loss: 0.2331\n",
      "Baseline Loss: 2.6584 | Actual Loss: 0.2629\n",
      "Baseline Loss: 2.6504 | Actual Loss: 0.2783\n",
      "Baseline Loss: 2.6793 | Actual Loss: 0.1712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 162/1000 [01:16<06:33,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6676 | Actual Loss: 0.2082\n",
      "Baseline Loss: 2.6588 | Actual Loss: 0.2185\n",
      "Baseline Loss: 2.6958 | Actual Loss: 0.3330\n",
      "Baseline Loss: 2.7056 | Actual Loss: 0.2102\n",
      "Baseline Loss: 2.6244 | Actual Loss: 0.3155\n",
      "Baseline Loss: 2.6838 | Actual Loss: 0.2382\n",
      "Baseline Loss: 2.2739 | Actual Loss: 0.0942\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5396\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3003\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2159\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2535\n",
      "Epoch 162/1000: Train Loss: 0.2251, Val Loss: 0.3273\n",
      "Baseline Loss: 2.7017 | Actual Loss: 0.3620\n",
      "Baseline Loss: 2.6836 | Actual Loss: 0.2395\n",
      "Baseline Loss: 2.6715 | Actual Loss: 0.3061\n",
      "Baseline Loss: 2.6790 | Actual Loss: 0.2803\n",
      "Baseline Loss: 2.6386 | Actual Loss: 0.2208\n",
      "Baseline Loss: 2.6728 | Actual Loss: 0.2239\n",
      "Baseline Loss: 2.6544 | Actual Loss: 0.2920\n",
      "Baseline Loss: 2.6761 | Actual Loss: 0.1775\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.2044\n",
      "Baseline Loss: 2.6592 | Actual Loss: 0.1856\n",
      "Baseline Loss: 2.6648 | Actual Loss: 0.1683\n",
      "Baseline Loss: 2.6932 | Actual Loss: 0.2800\n",
      "Baseline Loss: 2.6833 | Actual Loss: 0.3306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▋        | 163/1000 [01:17<06:49,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6728 | Actual Loss: 0.2950\n",
      "Baseline Loss: 2.7041 | Actual Loss: 0.1951\n",
      "Baseline Loss: 2.2391 | Actual Loss: 0.0631\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4894\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3882\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2668\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2831\n",
      "Epoch 163/1000: Train Loss: 0.2390, Val Loss: 0.3569\n",
      "Baseline Loss: 2.6583 | Actual Loss: 0.2163\n",
      "Baseline Loss: 2.6469 | Actual Loss: 0.1940\n",
      "Baseline Loss: 2.7011 | Actual Loss: 0.2226\n",
      "Baseline Loss: 2.6331 | Actual Loss: 0.1541\n",
      "Baseline Loss: 2.6514 | Actual Loss: 0.1441\n",
      "Baseline Loss: 2.6765 | Actual Loss: 0.2585\n",
      "Baseline Loss: 2.6835 | Actual Loss: 0.2251\n",
      "Baseline Loss: 2.6552 | Actual Loss: 0.2121\n",
      "Baseline Loss: 2.7104 | Actual Loss: 0.1812\n",
      "Baseline Loss: 2.7002 | Actual Loss: 0.2947\n",
      "Baseline Loss: 2.6823 | Actual Loss: 0.2127\n",
      "Baseline Loss: 2.7034 | Actual Loss: 0.2132\n",
      "Baseline Loss: 2.6816 | Actual Loss: 0.1523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▋        | 164/1000 [01:17<06:39,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6983 | Actual Loss: 0.3538\n",
      "Baseline Loss: 2.6660 | Actual Loss: 0.1393\n",
      "Baseline Loss: 2.2859 | Actual Loss: 0.1164\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5878\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.4306\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3416\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3807\n",
      "Epoch 164/1000: Train Loss: 0.2057, Val Loss: 0.4352\n",
      "Baseline Loss: 2.7063 | Actual Loss: 0.2005\n",
      "Baseline Loss: 2.6922 | Actual Loss: 0.2567\n",
      "Baseline Loss: 2.6654 | Actual Loss: 0.2159\n",
      "Baseline Loss: 2.6900 | Actual Loss: 0.3072\n",
      "Baseline Loss: 2.6627 | Actual Loss: 0.1545\n",
      "Baseline Loss: 2.6783 | Actual Loss: 0.2683\n",
      "Baseline Loss: 2.6436 | Actual Loss: 0.2931\n",
      "Baseline Loss: 2.6574 | Actual Loss: 0.1473\n",
      "Baseline Loss: 2.7002 | Actual Loss: 0.3203\n",
      "Baseline Loss: 2.6754 | Actual Loss: 0.1695\n",
      "Baseline Loss: 2.6516 | Actual Loss: 0.2522\n",
      "Baseline Loss: 2.6631 | Actual Loss: 0.1279\n",
      "Baseline Loss: 2.6631 | Actual Loss: 0.2733\n",
      "Baseline Loss: 2.6812 | Actual Loss: 0.2965\n",
      "Baseline Loss: 2.7186 | Actual Loss: 0.2310\n",
      "Baseline Loss: 2.3038 | Actual Loss: 0.0465\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5592\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▋        | 165/1000 [01:18<06:49,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6381 | Actual Loss: 0.3557\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4057\n",
      "Epoch 165/1000: Train Loss: 0.2225, Val Loss: 0.4140\n",
      "Baseline Loss: 2.6724 | Actual Loss: 0.2698\n",
      "Baseline Loss: 2.6750 | Actual Loss: 0.2507\n",
      "Baseline Loss: 2.6746 | Actual Loss: 0.1977\n",
      "Baseline Loss: 2.6749 | Actual Loss: 0.1136\n",
      "Baseline Loss: 2.6579 | Actual Loss: 0.2366\n",
      "Baseline Loss: 2.6553 | Actual Loss: 0.2923\n",
      "Baseline Loss: 2.6711 | Actual Loss: 0.1532\n",
      "Baseline Loss: 2.6850 | Actual Loss: 0.1809\n",
      "Baseline Loss: 2.6598 | Actual Loss: 0.2754\n",
      "Baseline Loss: 2.6430 | Actual Loss: 0.1304\n",
      "Baseline Loss: 2.6955 | Actual Loss: 0.3181\n",
      "Baseline Loss: 2.6809 | Actual Loss: 0.2268\n",
      "Baseline Loss: 2.6549 | Actual Loss: 0.2369\n",
      "Baseline Loss: 2.6868 | Actual Loss: 0.1852\n",
      "Baseline Loss: 2.6821 | Actual Loss: 0.1870\n",
      "Baseline Loss: 2.2377 | Actual Loss: 0.1042\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 166/1000 [01:18<06:33,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6990 | Actual Loss: 0.4020\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3423\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3275\n",
      "Epoch 166/1000: Train Loss: 0.2099, Val Loss: 0.3822\n",
      "Baseline Loss: 2.6767 | Actual Loss: 0.1810\n",
      "Baseline Loss: 2.6620 | Actual Loss: 0.2197\n",
      "Baseline Loss: 2.6636 | Actual Loss: 0.2893\n",
      "Baseline Loss: 2.6709 | Actual Loss: 0.1314\n",
      "Baseline Loss: 2.6614 | Actual Loss: 0.3518\n",
      "Baseline Loss: 2.6620 | Actual Loss: 0.1946\n",
      "Baseline Loss: 2.6676 | Actual Loss: 0.1706\n",
      "Baseline Loss: 2.6571 | Actual Loss: 0.1616\n",
      "Baseline Loss: 2.6768 | Actual Loss: 0.1516\n",
      "Baseline Loss: 2.7223 | Actual Loss: 0.1720\n",
      "Baseline Loss: 2.6647 | Actual Loss: 0.1916\n",
      "Baseline Loss: 2.6686 | Actual Loss: 0.0895\n",
      "Baseline Loss: 2.6654 | Actual Loss: 0.1729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 167/1000 [01:18<06:48,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7022 | Actual Loss: 0.2295\n",
      "Baseline Loss: 2.6457 | Actual Loss: 0.1467\n",
      "Baseline Loss: 2.3171 | Actual Loss: 0.0762\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5589\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3750\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2244\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2967\n",
      "Epoch 167/1000: Train Loss: 0.1831, Val Loss: 0.3637\n",
      "Baseline Loss: 2.7064 | Actual Loss: 0.2784\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.1086\n",
      "Baseline Loss: 2.6834 | Actual Loss: 0.1730\n",
      "Baseline Loss: 2.6461 | Actual Loss: 0.1408\n",
      "Baseline Loss: 2.6780 | Actual Loss: 0.2495\n",
      "Baseline Loss: 2.6646 | Actual Loss: 0.1551\n",
      "Baseline Loss: 2.6889 | Actual Loss: 0.2044\n",
      "Baseline Loss: 2.6748 | Actual Loss: 0.2339\n",
      "Baseline Loss: 2.6646 | Actual Loss: 0.1629\n",
      "Baseline Loss: 2.6672 | Actual Loss: 0.2129\n",
      "Baseline Loss: 2.6418 | Actual Loss: 0.2461\n",
      "Baseline Loss: 2.6719 | Actual Loss: 0.2550\n",
      "Baseline Loss: 2.6801 | Actual Loss: 0.2035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 168/1000 [01:19<06:46,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6690 | Actual Loss: 0.2121\n",
      "Baseline Loss: 2.7052 | Actual Loss: 0.1888\n",
      "Baseline Loss: 2.3344 | Actual Loss: 0.2801\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4689\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3813\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3736\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3307\n",
      "Epoch 168/1000: Train Loss: 0.2066, Val Loss: 0.3886\n",
      "Baseline Loss: 2.7231 | Actual Loss: 0.2027\n",
      "Baseline Loss: 2.6979 | Actual Loss: 0.0582\n",
      "Baseline Loss: 2.6621 | Actual Loss: 0.1932\n",
      "Baseline Loss: 2.6503 | Actual Loss: 0.2219\n",
      "Baseline Loss: 2.6832 | Actual Loss: 0.1928\n",
      "Baseline Loss: 2.6533 | Actual Loss: 0.0920\n",
      "Baseline Loss: 2.6498 | Actual Loss: 0.2500\n",
      "Baseline Loss: 2.6678 | Actual Loss: 0.2057\n",
      "Baseline Loss: 2.6880 | Actual Loss: 0.1317\n",
      "Baseline Loss: 2.7216 | Actual Loss: 0.2297\n",
      "Baseline Loss: 2.6739 | Actual Loss: 0.1125\n",
      "Baseline Loss: 2.6399 | Actual Loss: 0.1441\n",
      "Baseline Loss: 2.6425 | Actual Loss: 0.1534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 169/1000 [01:19<06:30,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6773 | Actual Loss: 0.2202\n",
      "Baseline Loss: 2.6851 | Actual Loss: 0.1637\n",
      "Baseline Loss: 2.2728 | Actual Loss: 0.1212\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5002\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3525\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3925\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3128\n",
      "Epoch 169/1000: Train Loss: 0.1683, Val Loss: 0.3895\n",
      "Baseline Loss: 2.6941 | Actual Loss: 0.2803\n",
      "Baseline Loss: 2.6582 | Actual Loss: 0.1830\n",
      "Baseline Loss: 2.6917 | Actual Loss: 0.1648\n",
      "Baseline Loss: 2.6604 | Actual Loss: 0.2262\n",
      "Baseline Loss: 2.6429 | Actual Loss: 0.2340\n",
      "Baseline Loss: 2.6981 | Actual Loss: 0.2241\n",
      "Baseline Loss: 2.6627 | Actual Loss: 0.1703\n",
      "Baseline Loss: 2.6924 | Actual Loss: 0.2467\n",
      "Baseline Loss: 2.6547 | Actual Loss: 0.1133\n",
      "Baseline Loss: 2.6557 | Actual Loss: 0.2509\n",
      "Baseline Loss: 2.6291 | Actual Loss: 0.1883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 170/1000 [01:20<06:41,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6926 | Actual Loss: 0.2537\n",
      "Baseline Loss: 2.6521 | Actual Loss: 0.1532\n",
      "Baseline Loss: 2.6624 | Actual Loss: 0.1758\n",
      "Baseline Loss: 2.6685 | Actual Loss: 0.1586\n",
      "Baseline Loss: 2.3394 | Actual Loss: 0.0698\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4435\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3817\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3267\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3158\n",
      "Epoch 170/1000: Train Loss: 0.1933, Val Loss: 0.3669\n",
      "Baseline Loss: 2.6314 | Actual Loss: 0.2117\n",
      "Baseline Loss: 2.6738 | Actual Loss: 0.1353\n",
      "Baseline Loss: 2.6429 | Actual Loss: 0.4308\n",
      "Baseline Loss: 2.6820 | Actual Loss: 0.1768\n",
      "Baseline Loss: 2.6449 | Actual Loss: 0.1728\n",
      "Baseline Loss: 2.6562 | Actual Loss: 0.1816\n",
      "Baseline Loss: 2.6743 | Actual Loss: 0.1192\n",
      "Baseline Loss: 2.6824 | Actual Loss: 0.2244\n",
      "Baseline Loss: 2.6934 | Actual Loss: 0.1424\n",
      "Baseline Loss: 2.6752 | Actual Loss: 0.1760\n",
      "Baseline Loss: 2.6971 | Actual Loss: 0.1553\n",
      "Baseline Loss: 2.6656 | Actual Loss: 0.1450\n",
      "Baseline Loss: 2.6602 | Actual Loss: 0.3894\n",
      "Baseline Loss: 2.6931 | Actual Loss: 0.1166\n",
      "Baseline Loss: 2.6870 | Actual Loss: 0.1508\n",
      "Baseline Loss: 2.3086 | Actual Loss: 0.1324\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 171/1000 [01:20<06:47,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6990 | Actual Loss: 0.4007\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2400\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3417\n",
      "Epoch 171/1000: Train Loss: 0.1913, Val Loss: 0.3609\n",
      "Baseline Loss: 2.6372 | Actual Loss: 0.1792\n",
      "Baseline Loss: 2.6721 | Actual Loss: 0.2353\n",
      "Baseline Loss: 2.7061 | Actual Loss: 0.1540\n",
      "Baseline Loss: 2.6360 | Actual Loss: 0.1418\n",
      "Baseline Loss: 2.6692 | Actual Loss: 0.3563\n",
      "Baseline Loss: 2.6973 | Actual Loss: 0.1110\n",
      "Baseline Loss: 2.6681 | Actual Loss: 0.1948\n",
      "Baseline Loss: 2.7442 | Actual Loss: 0.2496\n",
      "Baseline Loss: 2.6752 | Actual Loss: 0.1593\n",
      "Baseline Loss: 2.6522 | Actual Loss: 0.1761\n",
      "Baseline Loss: 2.6356 | Actual Loss: 0.1741\n",
      "Baseline Loss: 2.6804 | Actual Loss: 0.1589\n",
      "Baseline Loss: 2.6651 | Actual Loss: 0.2201\n",
      "Baseline Loss: 2.6615 | Actual Loss: 0.1457\n",
      "Baseline Loss: 2.6790 | Actual Loss: 0.2540\n",
      "Baseline Loss: 2.2954 | Actual Loss: 0.1672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 172/1000 [01:21<06:56,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6857 | Actual Loss: 0.4250\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3416\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2625\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3572\n",
      "Epoch 172/1000: Train Loss: 0.1923, Val Loss: 0.3466\n",
      "Baseline Loss: 2.6739 | Actual Loss: 0.1216\n",
      "Baseline Loss: 2.6553 | Actual Loss: 0.1624\n",
      "Baseline Loss: 2.7114 | Actual Loss: 0.1778\n",
      "Baseline Loss: 2.6756 | Actual Loss: 0.2995\n",
      "Baseline Loss: 2.6622 | Actual Loss: 0.2249\n",
      "Baseline Loss: 2.7100 | Actual Loss: 0.2646\n",
      "Baseline Loss: 2.6354 | Actual Loss: 0.1699\n",
      "Baseline Loss: 2.6368 | Actual Loss: 0.1484\n",
      "Baseline Loss: 2.6646 | Actual Loss: 0.3574\n",
      "Baseline Loss: 2.6616 | Actual Loss: 0.2617\n",
      "Baseline Loss: 2.6444 | Actual Loss: 0.2025\n",
      "Baseline Loss: 2.7337 | Actual Loss: 0.1840\n",
      "Baseline Loss: 2.6735 | Actual Loss: 0.2940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 173/1000 [01:21<06:32,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6966 | Actual Loss: 0.2205\n",
      "Baseline Loss: 2.6704 | Actual Loss: 0.3112\n",
      "Baseline Loss: 2.2672 | Actual Loss: 0.2017\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4197\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3131\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2897\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3382\n",
      "Epoch 173/1000: Train Loss: 0.2251, Val Loss: 0.3402\n",
      "Baseline Loss: 2.6923 | Actual Loss: 0.0991\n",
      "Baseline Loss: 2.6616 | Actual Loss: 0.1948\n",
      "Baseline Loss: 2.6850 | Actual Loss: 0.1435\n",
      "Baseline Loss: 2.6112 | Actual Loss: 0.2120\n",
      "Baseline Loss: 2.6871 | Actual Loss: 0.2647\n",
      "Baseline Loss: 2.6871 | Actual Loss: 0.1736\n",
      "Baseline Loss: 2.6971 | Actual Loss: 0.1468\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.1604\n",
      "Baseline Loss: 2.6401 | Actual Loss: 0.2209\n",
      "Baseline Loss: 2.6692 | Actual Loss: 0.1638\n",
      "Baseline Loss: 2.6940 | Actual Loss: 0.1952\n",
      "Baseline Loss: 2.6949 | Actual Loss: 0.2075\n",
      "Baseline Loss: 2.7117 | Actual Loss: 0.2943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 174/1000 [01:22<06:36,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6775 | Actual Loss: 0.1631\n",
      "Baseline Loss: 2.6938 | Actual Loss: 0.1684\n",
      "Baseline Loss: 2.1865 | Actual Loss: 0.1361\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4535\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3192\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2614\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4092\n",
      "Epoch 174/1000: Train Loss: 0.1840, Val Loss: 0.3608\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.1560\n",
      "Baseline Loss: 2.6684 | Actual Loss: 0.2590\n",
      "Baseline Loss: 2.6768 | Actual Loss: 0.3389\n",
      "Baseline Loss: 2.6561 | Actual Loss: 0.1705\n",
      "Baseline Loss: 2.6571 | Actual Loss: 0.1960\n",
      "Baseline Loss: 2.6699 | Actual Loss: 0.2446\n",
      "Baseline Loss: 2.6812 | Actual Loss: 0.2086\n",
      "Baseline Loss: 2.6643 | Actual Loss: 0.4844\n",
      "Baseline Loss: 2.6462 | Actual Loss: 0.2679\n",
      "Baseline Loss: 2.6658 | Actual Loss: 0.2472\n",
      "Baseline Loss: 2.6865 | Actual Loss: 0.4301\n",
      "Baseline Loss: 2.6707 | Actual Loss: 0.3053\n",
      "Baseline Loss: 2.6781 | Actual Loss: 0.2318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 175/1000 [01:22<06:42,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6491 | Actual Loss: 0.1453\n",
      "Baseline Loss: 2.7272 | Actual Loss: 0.1049\n",
      "Baseline Loss: 2.3020 | Actual Loss: 0.1089\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4408\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3433\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3004\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2788\n",
      "Epoch 175/1000: Train Loss: 0.2437, Val Loss: 0.3408\n",
      "Baseline Loss: 2.6813 | Actual Loss: 0.1362\n",
      "Baseline Loss: 2.6568 | Actual Loss: 0.2246\n",
      "Baseline Loss: 2.6633 | Actual Loss: 0.2276\n",
      "Baseline Loss: 2.6448 | Actual Loss: 0.1818\n",
      "Baseline Loss: 2.6749 | Actual Loss: 0.1964\n",
      "Baseline Loss: 2.6701 | Actual Loss: 0.2310\n",
      "Baseline Loss: 2.6898 | Actual Loss: 0.2929\n",
      "Baseline Loss: 2.6967 | Actual Loss: 0.2667\n",
      "Baseline Loss: 2.6984 | Actual Loss: 0.2753\n",
      "Baseline Loss: 2.6284 | Actual Loss: 0.2018\n",
      "Baseline Loss: 2.6594 | Actual Loss: 0.2196\n",
      "Baseline Loss: 2.7102 | Actual Loss: 0.1708\n",
      "Baseline Loss: 2.6553 | Actual Loss: 0.1227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 176/1000 [01:23<06:21,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6620 | Actual Loss: 0.1472\n",
      "Baseline Loss: 2.7208 | Actual Loss: 0.1392\n",
      "Baseline Loss: 2.2273 | Actual Loss: 0.0834\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4557\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3365\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2775\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3057\n",
      "Epoch 176/1000: Train Loss: 0.1948, Val Loss: 0.3438\n",
      "Baseline Loss: 2.6601 | Actual Loss: 0.1158\n",
      "Baseline Loss: 2.6756 | Actual Loss: 0.2216\n",
      "Baseline Loss: 2.6579 | Actual Loss: 0.1840\n",
      "Baseline Loss: 2.6666 | Actual Loss: 0.1822\n",
      "Baseline Loss: 2.6903 | Actual Loss: 0.0991\n",
      "Baseline Loss: 2.7058 | Actual Loss: 0.2356\n",
      "Baseline Loss: 2.7007 | Actual Loss: 0.1577\n",
      "Baseline Loss: 2.6067 | Actual Loss: 0.1709\n",
      "Baseline Loss: 2.6670 | Actual Loss: 0.2158\n",
      "Baseline Loss: 2.6763 | Actual Loss: 0.2170\n",
      "Baseline Loss: 2.6940 | Actual Loss: 0.2407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 177/1000 [01:23<06:32,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7013 | Actual Loss: 0.2178\n",
      "Baseline Loss: 2.6675 | Actual Loss: 0.2981\n",
      "Baseline Loss: 2.6408 | Actual Loss: 0.2058\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.2253\n",
      "Baseline Loss: 2.3080 | Actual Loss: 0.0891\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4377\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3508\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2407\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2601\n",
      "Epoch 177/1000: Train Loss: 0.1923, Val Loss: 0.3223\n",
      "Baseline Loss: 2.6632 | Actual Loss: 0.1679\n",
      "Baseline Loss: 2.6790 | Actual Loss: 0.2168\n",
      "Baseline Loss: 2.6600 | Actual Loss: 0.1448\n",
      "Baseline Loss: 2.6856 | Actual Loss: 0.2960\n",
      "Baseline Loss: 2.6362 | Actual Loss: 0.1959\n",
      "Baseline Loss: 2.7006 | Actual Loss: 0.1753\n",
      "Baseline Loss: 2.6788 | Actual Loss: 0.1685\n",
      "Baseline Loss: 2.6673 | Actual Loss: 0.2635\n",
      "Baseline Loss: 2.6618 | Actual Loss: 0.1678\n",
      "Baseline Loss: 2.6588 | Actual Loss: 0.1460\n",
      "Baseline Loss: 2.7009 | Actual Loss: 0.2310\n",
      "Baseline Loss: 2.6555 | Actual Loss: 0.2233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 178/1000 [01:24<06:37,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6945 | Actual Loss: 0.2888\n",
      "Baseline Loss: 2.7009 | Actual Loss: 0.2263\n",
      "Baseline Loss: 2.6419 | Actual Loss: 0.2737\n",
      "Baseline Loss: 2.3276 | Actual Loss: 0.1350\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4781\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3444\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2927\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3454\n",
      "Epoch 178/1000: Train Loss: 0.2075, Val Loss: 0.3652\n",
      "Baseline Loss: 2.6735 | Actual Loss: 0.2351\n",
      "Baseline Loss: 2.6647 | Actual Loss: 0.1246\n",
      "Baseline Loss: 2.6809 | Actual Loss: 0.3244\n",
      "Baseline Loss: 2.6744 | Actual Loss: 0.1724\n",
      "Baseline Loss: 2.6939 | Actual Loss: 0.2032\n",
      "Baseline Loss: 2.7100 | Actual Loss: 0.1572\n",
      "Baseline Loss: 2.6730 | Actual Loss: 0.1202\n",
      "Baseline Loss: 2.7041 | Actual Loss: 0.1767\n",
      "Baseline Loss: 2.6874 | Actual Loss: 0.1739\n",
      "Baseline Loss: 2.6437 | Actual Loss: 0.1611\n",
      "Baseline Loss: 2.6176 | Actual Loss: 0.1756\n",
      "Baseline Loss: 2.6586 | Actual Loss: 0.2038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 179/1000 [01:24<06:15,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6691 | Actual Loss: 0.1550\n",
      "Baseline Loss: 2.6362 | Actual Loss: 0.3268\n",
      "Baseline Loss: 2.7534 | Actual Loss: 0.2808\n",
      "Baseline Loss: 2.3280 | Actual Loss: 0.1855\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4605\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3300\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2331\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3286\n",
      "Epoch 179/1000: Train Loss: 0.1985, Val Loss: 0.3381\n",
      "Baseline Loss: 2.7071 | Actual Loss: 0.1792\n",
      "Baseline Loss: 2.6707 | Actual Loss: 0.1943\n",
      "Baseline Loss: 2.7051 | Actual Loss: 0.1983\n",
      "Baseline Loss: 2.6765 | Actual Loss: 0.1905\n",
      "Baseline Loss: 2.6642 | Actual Loss: 0.1951\n",
      "Baseline Loss: 2.6879 | Actual Loss: 0.1611\n",
      "Baseline Loss: 2.7358 | Actual Loss: 0.1646\n",
      "Baseline Loss: 2.6324 | Actual Loss: 0.2895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 180/1000 [01:25<06:24,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6588 | Actual Loss: 0.1707\n",
      "Baseline Loss: 2.6883 | Actual Loss: 0.1312\n",
      "Baseline Loss: 2.6741 | Actual Loss: 0.2106\n",
      "Baseline Loss: 2.6972 | Actual Loss: 0.1420\n",
      "Baseline Loss: 2.7030 | Actual Loss: 0.2261\n",
      "Baseline Loss: 2.6593 | Actual Loss: 0.1755\n",
      "Baseline Loss: 2.6335 | Actual Loss: 0.1527\n",
      "Baseline Loss: 2.2678 | Actual Loss: 0.0720\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5822\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.4544\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3523\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2684\n",
      "Epoch 180/1000: Train Loss: 0.1783, Val Loss: 0.4143\n",
      "Baseline Loss: 2.6720 | Actual Loss: 0.1989\n",
      "Baseline Loss: 2.6837 | Actual Loss: 0.1790\n",
      "Baseline Loss: 2.7151 | Actual Loss: 0.2678\n",
      "Baseline Loss: 2.6781 | Actual Loss: 0.2368\n",
      "Baseline Loss: 2.6361 | Actual Loss: 0.1436\n",
      "Baseline Loss: 2.6227 | Actual Loss: 0.1290\n",
      "Baseline Loss: 2.6810 | Actual Loss: 0.2453\n",
      "Baseline Loss: 2.6848 | Actual Loss: 0.1237\n",
      "Baseline Loss: 2.6624 | Actual Loss: 0.2617\n",
      "Baseline Loss: 2.7101 | Actual Loss: 0.2008\n",
      "Baseline Loss: 2.6581 | Actual Loss: 0.1657\n",
      "Baseline Loss: 2.6580 | Actual Loss: 0.1639\n",
      "Baseline Loss: 2.6658 | Actual Loss: 0.1689\n",
      "Baseline Loss: 2.6877 | Actual Loss: 0.1398\n",
      "Baseline Loss: 2.6662 | Actual Loss: 0.2594\n",
      "Baseline Loss: 2.2292 | Actual Loss: 0.1111\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.3849\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 181/1000 [01:25<06:31,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6381 | Actual Loss: 0.3282\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2956\n",
      "Epoch 181/1000: Train Loss: 0.1872, Val Loss: 0.3503\n",
      "Baseline Loss: 2.6590 | Actual Loss: 0.2309\n",
      "Baseline Loss: 2.6888 | Actual Loss: 0.1479\n",
      "Baseline Loss: 2.6807 | Actual Loss: 0.2127\n",
      "Baseline Loss: 2.6211 | Actual Loss: 0.1434\n",
      "Baseline Loss: 2.7085 | Actual Loss: 0.2076\n",
      "Baseline Loss: 2.6668 | Actual Loss: 0.2282\n",
      "Baseline Loss: 2.7041 | Actual Loss: 0.1137\n",
      "Baseline Loss: 2.6307 | Actual Loss: 0.1551\n",
      "Baseline Loss: 2.6731 | Actual Loss: 0.1956\n",
      "Baseline Loss: 2.6353 | Actual Loss: 0.1051\n",
      "Baseline Loss: 2.6674 | Actual Loss: 0.1637\n",
      "Baseline Loss: 2.6696 | Actual Loss: 0.2165\n",
      "Baseline Loss: 2.6349 | Actual Loss: 0.3070\n",
      "Baseline Loss: 2.7109 | Actual Loss: 0.4603\n",
      "Baseline Loss: 2.7130 | Actual Loss: 0.2202\n",
      "Baseline Loss: 2.3023 | Actual Loss: 0.1231\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5560\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.2820\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 182/1000 [01:26<06:11,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6194 | Actual Loss: 0.3144\n",
      "Epoch 182/1000: Train Loss: 0.2019, Val Loss: 0.3516\n",
      "Baseline Loss: 2.6627 | Actual Loss: 0.2667\n",
      "Baseline Loss: 2.6731 | Actual Loss: 0.1299\n",
      "Baseline Loss: 2.6650 | Actual Loss: 0.1508\n",
      "Baseline Loss: 2.6844 | Actual Loss: 0.1566\n",
      "Baseline Loss: 2.7014 | Actual Loss: 0.1164\n",
      "Baseline Loss: 2.6850 | Actual Loss: 0.2195\n",
      "Baseline Loss: 2.6592 | Actual Loss: 0.1126\n",
      "Baseline Loss: 2.6691 | Actual Loss: 0.1227\n",
      "Baseline Loss: 2.6533 | Actual Loss: 0.2485\n",
      "Baseline Loss: 2.6653 | Actual Loss: 0.1467\n",
      "Baseline Loss: 2.6960 | Actual Loss: 0.2078\n",
      "Baseline Loss: 2.7179 | Actual Loss: 0.2400\n",
      "Baseline Loss: 2.6773 | Actual Loss: 0.2008\n",
      "Baseline Loss: 2.6826 | Actual Loss: 0.1620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 183/1000 [01:26<06:17,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6496 | Actual Loss: 0.1856\n",
      "Baseline Loss: 2.2871 | Actual Loss: 0.2916\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4891\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3930\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2402\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2617\n",
      "Epoch 183/1000: Train Loss: 0.1849, Val Loss: 0.3460\n",
      "Baseline Loss: 2.7159 | Actual Loss: 0.1482\n",
      "Baseline Loss: 2.6632 | Actual Loss: 0.2207\n",
      "Baseline Loss: 2.6688 | Actual Loss: 0.2885\n",
      "Baseline Loss: 2.7072 | Actual Loss: 0.1790\n",
      "Baseline Loss: 2.6620 | Actual Loss: 0.2173\n",
      "Baseline Loss: 2.6759 | Actual Loss: 0.2263\n",
      "Baseline Loss: 2.6726 | Actual Loss: 0.2522\n",
      "Baseline Loss: 2.7061 | Actual Loss: 0.7263\n",
      "Baseline Loss: 2.6455 | Actual Loss: 0.1572\n",
      "Baseline Loss: 2.6582 | Actual Loss: 0.1592\n",
      "Baseline Loss: 2.7047 | Actual Loss: 0.2269\n",
      "Baseline Loss: 2.6365 | Actual Loss: 0.2693\n",
      "Baseline Loss: 2.6560 | Actual Loss: 0.1667\n",
      "Baseline Loss: 2.6859 | Actual Loss: 0.1468\n",
      "Baseline Loss: 2.7206 | Actual Loss: 0.2219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 184/1000 [01:26<06:12,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2829 | Actual Loss: 0.2236\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.3828\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3450\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2543\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2851\n",
      "Epoch 184/1000: Train Loss: 0.2394, Val Loss: 0.3168\n",
      "New best validation loss: 0.3168\n",
      "Baseline Loss: 2.6860 | Actual Loss: 0.2091\n",
      "Baseline Loss: 2.6919 | Actual Loss: 0.2483\n",
      "Baseline Loss: 2.6865 | Actual Loss: 0.2090\n",
      "Baseline Loss: 2.6656 | Actual Loss: 0.1796\n",
      "Baseline Loss: 2.6871 | Actual Loss: 0.2448\n",
      "Baseline Loss: 2.6882 | Actual Loss: 0.1406\n",
      "Baseline Loss: 2.6955 | Actual Loss: 0.2179\n",
      "Baseline Loss: 2.6612 | Actual Loss: 0.1420\n",
      "Baseline Loss: 2.6679 | Actual Loss: 0.2884\n",
      "Baseline Loss: 2.6592 | Actual Loss: 0.1140\n",
      "Baseline Loss: 2.6444 | Actual Loss: 0.1041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 185/1000 [01:27<06:26,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6614 | Actual Loss: 0.2474\n",
      "Baseline Loss: 2.6714 | Actual Loss: 0.2177\n",
      "Baseline Loss: 2.6233 | Actual Loss: 0.1221\n",
      "Baseline Loss: 2.6555 | Actual Loss: 0.1604\n",
      "Baseline Loss: 2.3014 | Actual Loss: 0.3230\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4427\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3595\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2949\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3184\n",
      "Epoch 185/1000: Train Loss: 0.1980, Val Loss: 0.3539\n",
      "Baseline Loss: 2.7166 | Actual Loss: 0.0951\n",
      "Baseline Loss: 2.6839 | Actual Loss: 0.1548\n",
      "Baseline Loss: 2.6771 | Actual Loss: 0.1831\n",
      "Baseline Loss: 2.6445 | Actual Loss: 0.2243\n",
      "Baseline Loss: 2.6809 | Actual Loss: 0.2361\n",
      "Baseline Loss: 2.6855 | Actual Loss: 0.1170\n",
      "Baseline Loss: 2.6535 | Actual Loss: 0.1279\n",
      "Baseline Loss: 2.6945 | Actual Loss: 0.1720\n",
      "Baseline Loss: 2.6797 | Actual Loss: 0.1643\n",
      "Baseline Loss: 2.6538 | Actual Loss: 0.1263\n",
      "Baseline Loss: 2.6741 | Actual Loss: 0.2265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▊        | 186/1000 [01:27<06:17,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6505 | Actual Loss: 0.1576\n",
      "Baseline Loss: 2.6819 | Actual Loss: 0.2536\n",
      "Baseline Loss: 2.6933 | Actual Loss: 0.2772\n",
      "Baseline Loss: 2.6715 | Actual Loss: 0.2542\n",
      "Baseline Loss: 2.2413 | Actual Loss: 0.0891\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4630\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3240\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2807\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2986\n",
      "Epoch 186/1000: Train Loss: 0.1787, Val Loss: 0.3416\n",
      "Baseline Loss: 2.6736 | Actual Loss: 0.1173\n",
      "Baseline Loss: 2.6752 | Actual Loss: 0.2160\n",
      "Baseline Loss: 2.7038 | Actual Loss: 0.2935\n",
      "Baseline Loss: 2.7022 | Actual Loss: 0.2177\n",
      "Baseline Loss: 2.6366 | Actual Loss: 0.2289\n",
      "Baseline Loss: 2.6595 | Actual Loss: 0.1333\n",
      "Baseline Loss: 2.6808 | Actual Loss: 0.1421\n",
      "Baseline Loss: 2.6539 | Actual Loss: 0.2443\n",
      "Baseline Loss: 2.6804 | Actual Loss: 0.1546\n",
      "Baseline Loss: 2.6531 | Actual Loss: 0.1506\n",
      "Baseline Loss: 2.6746 | Actual Loss: 0.2190\n",
      "Baseline Loss: 2.6652 | Actual Loss: 0.3142\n",
      "Baseline Loss: 2.6801 | Actual Loss: 0.1300\n",
      "Baseline Loss: 2.6650 | Actual Loss: 0.1572\n",
      "Baseline Loss: 2.6777 | Actual Loss: 0.1408\n",
      "Baseline Loss: 2.2749 | Actual Loss: 0.2100\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4198\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3462\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▊        | 187/1000 [01:28<06:32,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6194 | Actual Loss: 0.3033\n",
      "Epoch 187/1000: Train Loss: 0.1919, Val Loss: 0.3360\n",
      "Baseline Loss: 2.6957 | Actual Loss: 0.2591\n",
      "Baseline Loss: 2.6624 | Actual Loss: 0.2657\n",
      "Baseline Loss: 2.6756 | Actual Loss: 0.1737\n",
      "Baseline Loss: 2.6643 | Actual Loss: 0.2157\n",
      "Baseline Loss: 2.7004 | Actual Loss: 0.1992\n",
      "Baseline Loss: 2.6830 | Actual Loss: 0.2106\n",
      "Baseline Loss: 2.6445 | Actual Loss: 0.1336\n",
      "Baseline Loss: 2.6740 | Actual Loss: 0.1175\n",
      "Baseline Loss: 2.6969 | Actual Loss: 0.2447\n",
      "Baseline Loss: 2.6946 | Actual Loss: 0.2396\n",
      "Baseline Loss: 2.6466 | Actual Loss: 0.1866\n",
      "Baseline Loss: 2.6462 | Actual Loss: 0.3005\n",
      "Baseline Loss: 2.6717 | Actual Loss: 0.1801\n",
      "Baseline Loss: 2.6734 | Actual Loss: 0.1565\n",
      "Baseline Loss: 2.6913 | Actual Loss: 0.0982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 188/1000 [01:28<06:31,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2406 | Actual Loss: 0.0520\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4160\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3613\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2709\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2664\n",
      "Epoch 188/1000: Train Loss: 0.1896, Val Loss: 0.3287\n",
      "Baseline Loss: 2.7014 | Actual Loss: 0.1457\n",
      "Baseline Loss: 2.6743 | Actual Loss: 0.1686\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.1164\n",
      "Baseline Loss: 2.6710 | Actual Loss: 0.2312\n",
      "Baseline Loss: 2.6451 | Actual Loss: 0.2161\n",
      "Baseline Loss: 2.6904 | Actual Loss: 0.1738\n",
      "Baseline Loss: 2.6544 | Actual Loss: 0.3768\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.1722\n",
      "Baseline Loss: 2.6484 | Actual Loss: 0.1832\n",
      "Baseline Loss: 2.6488 | Actual Loss: 0.3683\n",
      "Baseline Loss: 2.6890 | Actual Loss: 0.1988\n",
      "Baseline Loss: 2.6494 | Actual Loss: 0.2087\n",
      "Baseline Loss: 2.7008 | Actual Loss: 0.2347\n",
      "Baseline Loss: 2.7102 | Actual Loss: 0.1580\n",
      "Baseline Loss: 2.6774 | Actual Loss: 0.1195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 189/1000 [01:29<06:19,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2474 | Actual Loss: 0.0681\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4864\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3589\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2370\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2956\n",
      "Epoch 189/1000: Train Loss: 0.1963, Val Loss: 0.3445\n",
      "Baseline Loss: 2.6693 | Actual Loss: 0.1249\n",
      "Baseline Loss: 2.6863 | Actual Loss: 0.1441\n",
      "Baseline Loss: 2.7005 | Actual Loss: 0.1808\n",
      "Baseline Loss: 2.6941 | Actual Loss: 0.1078\n",
      "Baseline Loss: 2.6504 | Actual Loss: 0.2213\n",
      "Baseline Loss: 2.6664 | Actual Loss: 0.2386\n",
      "Baseline Loss: 2.6539 | Actual Loss: 0.1616\n",
      "Baseline Loss: 2.6996 | Actual Loss: 0.2491\n",
      "Baseline Loss: 2.6658 | Actual Loss: 0.1337\n",
      "Baseline Loss: 2.6819 | Actual Loss: 0.2034\n",
      "Baseline Loss: 2.6632 | Actual Loss: 0.2015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 190/1000 [01:29<06:28,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6780 | Actual Loss: 0.1393\n",
      "Baseline Loss: 2.6959 | Actual Loss: 0.1813\n",
      "Baseline Loss: 2.6687 | Actual Loss: 0.1939\n",
      "Baseline Loss: 2.6591 | Actual Loss: 0.2077\n",
      "Baseline Loss: 2.2874 | Actual Loss: 0.0751\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4262\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3351\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2715\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3317\n",
      "Epoch 190/1000: Train Loss: 0.1727, Val Loss: 0.3411\n",
      "Baseline Loss: 2.6819 | Actual Loss: 0.1694\n",
      "Baseline Loss: 2.6460 | Actual Loss: 0.1411\n",
      "Baseline Loss: 2.6672 | Actual Loss: 0.1143\n",
      "Baseline Loss: 2.6656 | Actual Loss: 0.2297\n",
      "Baseline Loss: 2.6443 | Actual Loss: 0.4184\n",
      "Baseline Loss: 2.6742 | Actual Loss: 0.3025\n",
      "Baseline Loss: 2.6795 | Actual Loss: 0.2974\n",
      "Baseline Loss: 2.6560 | Actual Loss: 0.1568\n",
      "Baseline Loss: 2.6732 | Actual Loss: 0.2598\n",
      "Baseline Loss: 2.7063 | Actual Loss: 0.1464\n",
      "Baseline Loss: 2.6792 | Actual Loss: 0.1718\n",
      "Baseline Loss: 2.7079 | Actual Loss: 0.1459\n",
      "Baseline Loss: 2.7095 | Actual Loss: 0.2058\n",
      "Baseline Loss: 2.6622 | Actual Loss: 0.1133\n",
      "Baseline Loss: 2.6905 | Actual Loss: 0.1808\n",
      "Baseline Loss: 2.2924 | Actual Loss: 0.1173\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 191/1000 [01:30<06:36,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6990 | Actual Loss: 0.3872\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3227\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3356\n",
      "Epoch 191/1000: Train Loss: 0.1982, Val Loss: 0.3807\n",
      "Baseline Loss: 2.6572 | Actual Loss: 0.2517\n",
      "Baseline Loss: 2.6540 | Actual Loss: 0.2472\n",
      "Baseline Loss: 2.6959 | Actual Loss: 0.1584\n",
      "Baseline Loss: 2.6795 | Actual Loss: 0.3055\n",
      "Baseline Loss: 2.6323 | Actual Loss: 0.2116\n",
      "Baseline Loss: 2.7134 | Actual Loss: 0.2668\n",
      "Baseline Loss: 2.6728 | Actual Loss: 0.1628\n",
      "Baseline Loss: 2.6592 | Actual Loss: 0.1290\n",
      "Baseline Loss: 2.6500 | Actual Loss: 0.1453\n",
      "Baseline Loss: 2.6865 | Actual Loss: 0.1681\n",
      "Baseline Loss: 2.7164 | Actual Loss: 0.2583\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.2724\n",
      "Baseline Loss: 2.6727 | Actual Loss: 0.2187\n",
      "Baseline Loss: 2.6646 | Actual Loss: 0.1650\n",
      "Baseline Loss: 2.6354 | Actual Loss: 0.2445\n",
      "Baseline Loss: 2.2618 | Actual Loss: 0.1373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 192/1000 [01:30<06:42,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6857 | Actual Loss: 0.3726\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3687\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2821\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2664\n",
      "Epoch 192/1000: Train Loss: 0.2089, Val Loss: 0.3224\n",
      "Baseline Loss: 2.6523 | Actual Loss: 0.2247\n",
      "Baseline Loss: 2.7203 | Actual Loss: 0.1410\n",
      "Baseline Loss: 2.6854 | Actual Loss: 0.1479\n",
      "Baseline Loss: 2.6720 | Actual Loss: 0.1443\n",
      "Baseline Loss: 2.6632 | Actual Loss: 0.2478\n",
      "Baseline Loss: 2.6199 | Actual Loss: 0.1815\n",
      "Baseline Loss: 2.6494 | Actual Loss: 0.2222\n",
      "Baseline Loss: 2.6524 | Actual Loss: 0.0981\n",
      "Baseline Loss: 2.6450 | Actual Loss: 0.1676\n",
      "Baseline Loss: 2.6786 | Actual Loss: 0.1860\n",
      "Baseline Loss: 2.6791 | Actual Loss: 0.2307\n",
      "Baseline Loss: 2.6980 | Actual Loss: 0.1254\n",
      "Baseline Loss: 2.6885 | Actual Loss: 0.2078\n",
      "Baseline Loss: 2.6909 | Actual Loss: 0.1464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 193/1000 [01:31<06:16,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6834 | Actual Loss: 0.1689\n",
      "Baseline Loss: 2.2459 | Actual Loss: 0.1964\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5004\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3157\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2897\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2996\n",
      "Epoch 193/1000: Train Loss: 0.1773, Val Loss: 0.3514\n",
      "Baseline Loss: 2.6492 | Actual Loss: 0.2502\n",
      "Baseline Loss: 2.6794 | Actual Loss: 0.1962\n",
      "Baseline Loss: 2.6508 | Actual Loss: 0.2562\n",
      "Baseline Loss: 2.7052 | Actual Loss: 0.1923\n",
      "Baseline Loss: 2.6602 | Actual Loss: 0.1781\n",
      "Baseline Loss: 2.7047 | Actual Loss: 0.2431\n",
      "Baseline Loss: 2.7436 | Actual Loss: 0.1214\n",
      "Baseline Loss: 2.6915 | Actual Loss: 0.2279\n",
      "Baseline Loss: 2.6726 | Actual Loss: 0.1823\n",
      "Baseline Loss: 2.6808 | Actual Loss: 0.1096\n",
      "Baseline Loss: 2.6336 | Actual Loss: 0.2094\n",
      "Baseline Loss: 2.6897 | Actual Loss: 0.1173\n",
      "Baseline Loss: 2.6739 | Actual Loss: 0.1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 194/1000 [01:31<06:25,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6354 | Actual Loss: 0.1668\n",
      "Baseline Loss: 2.6929 | Actual Loss: 0.2510\n",
      "Baseline Loss: 2.2485 | Actual Loss: 0.0660\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.3825\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3914\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2999\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2989\n",
      "Epoch 194/1000: Train Loss: 0.1824, Val Loss: 0.3432\n",
      "Baseline Loss: 2.7168 | Actual Loss: 0.2063\n",
      "Baseline Loss: 2.6788 | Actual Loss: 0.3428\n",
      "Baseline Loss: 2.6553 | Actual Loss: 0.1313\n",
      "Baseline Loss: 2.6850 | Actual Loss: 0.1240\n",
      "Baseline Loss: 2.6727 | Actual Loss: 0.1395\n",
      "Baseline Loss: 2.6624 | Actual Loss: 0.5810\n",
      "Baseline Loss: 2.6543 | Actual Loss: 0.1340\n",
      "Baseline Loss: 2.7000 | Actual Loss: 0.1570\n",
      "Baseline Loss: 2.6376 | Actual Loss: 0.2235\n",
      "Baseline Loss: 2.6845 | Actual Loss: 0.2699\n",
      "Baseline Loss: 2.6391 | Actual Loss: 0.2490\n",
      "Baseline Loss: 2.6865 | Actual Loss: 0.1838\n",
      "Baseline Loss: 2.6369 | Actual Loss: 0.2126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 195/1000 [01:32<06:27,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6866 | Actual Loss: 0.1959\n",
      "Baseline Loss: 2.7391 | Actual Loss: 0.1799\n",
      "Baseline Loss: 2.3026 | Actual Loss: 0.1217\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5535\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.2502\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3032\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3511\n",
      "Epoch 195/1000: Train Loss: 0.2158, Val Loss: 0.3645\n",
      "Baseline Loss: 2.6503 | Actual Loss: 0.1280\n",
      "Baseline Loss: 2.6492 | Actual Loss: 0.2251\n",
      "Baseline Loss: 2.7186 | Actual Loss: 0.4589\n",
      "Baseline Loss: 2.6739 | Actual Loss: 0.3054\n",
      "Baseline Loss: 2.7043 | Actual Loss: 0.2254\n",
      "Baseline Loss: 2.6736 | Actual Loss: 0.2204\n",
      "Baseline Loss: 2.7103 | Actual Loss: 0.2476\n",
      "Baseline Loss: 2.6721 | Actual Loss: 0.0856\n",
      "Baseline Loss: 2.6768 | Actual Loss: 0.1409\n",
      "Baseline Loss: 2.6826 | Actual Loss: 0.2547\n",
      "Baseline Loss: 2.6885 | Actual Loss: 0.1856\n",
      "Baseline Loss: 2.6924 | Actual Loss: 0.1774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 196/1000 [01:32<06:07,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6627 | Actual Loss: 0.2273\n",
      "Baseline Loss: 2.6464 | Actual Loss: 0.2611\n",
      "Baseline Loss: 2.6316 | Actual Loss: 0.2340\n",
      "Baseline Loss: 2.3606 | Actual Loss: 0.1250\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5262\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3676\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2340\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2344\n",
      "Epoch 196/1000: Train Loss: 0.2189, Val Loss: 0.3405\n",
      "Baseline Loss: 2.7035 | Actual Loss: 0.2097\n",
      "Baseline Loss: 2.6473 | Actual Loss: 0.2729\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.1330\n",
      "Baseline Loss: 2.6712 | Actual Loss: 0.2221\n",
      "Baseline Loss: 2.6720 | Actual Loss: 0.1145\n",
      "Baseline Loss: 2.6513 | Actual Loss: 0.2145\n",
      "Baseline Loss: 2.6738 | Actual Loss: 0.2268\n",
      "Baseline Loss: 2.6620 | Actual Loss: 0.1299\n",
      "Baseline Loss: 2.6871 | Actual Loss: 0.1757\n",
      "Baseline Loss: 2.6702 | Actual Loss: 0.2836\n",
      "Baseline Loss: 2.6685 | Actual Loss: 0.1712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 197/1000 [01:33<06:17,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6517 | Actual Loss: 0.1931\n",
      "Baseline Loss: 2.7053 | Actual Loss: 0.2470\n",
      "Baseline Loss: 2.6743 | Actual Loss: 0.1854\n",
      "Baseline Loss: 2.6562 | Actual Loss: 0.2560\n",
      "Baseline Loss: 2.2554 | Actual Loss: 0.0618\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4454\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3435\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2706\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3277\n",
      "Epoch 197/1000: Train Loss: 0.1936, Val Loss: 0.3468\n",
      "Baseline Loss: 2.6714 | Actual Loss: 0.1038\n",
      "Baseline Loss: 2.6625 | Actual Loss: 0.2286\n",
      "Baseline Loss: 2.6670 | Actual Loss: 0.2443\n",
      "Baseline Loss: 2.6787 | Actual Loss: 0.0663\n",
      "Baseline Loss: 2.6646 | Actual Loss: 0.0969\n",
      "Baseline Loss: 2.7248 | Actual Loss: 0.1453\n",
      "Baseline Loss: 2.6635 | Actual Loss: 0.1676\n",
      "Baseline Loss: 2.6634 | Actual Loss: 0.2052\n",
      "Baseline Loss: 2.6730 | Actual Loss: 0.1077\n",
      "Baseline Loss: 2.6999 | Actual Loss: 0.1760\n",
      "Baseline Loss: 2.6485 | Actual Loss: 0.1516\n",
      "Baseline Loss: 2.6480 | Actual Loss: 0.2834\n",
      "Baseline Loss: 2.6977 | Actual Loss: 0.2159\n",
      "Baseline Loss: 2.6870 | Actual Loss: 0.1950\n",
      "Baseline Loss: 2.6710 | Actual Loss: 0.1987\n",
      "Baseline Loss: 2.2643 | Actual Loss: 0.1583\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4665\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 198/1000 [01:33<06:26,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6381 | Actual Loss: 0.3752\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2894\n",
      "Epoch 198/1000: Train Loss: 0.1715, Val Loss: 0.3592\n",
      "Baseline Loss: 2.6921 | Actual Loss: 0.1227\n",
      "Baseline Loss: 2.6848 | Actual Loss: 0.1826\n",
      "Baseline Loss: 2.6473 | Actual Loss: 0.1344\n",
      "Baseline Loss: 2.6374 | Actual Loss: 0.1927\n",
      "Baseline Loss: 2.6734 | Actual Loss: 0.2922\n",
      "Baseline Loss: 2.6535 | Actual Loss: 0.2455\n",
      "Baseline Loss: 2.6454 | Actual Loss: 0.2080\n",
      "Baseline Loss: 2.6935 | Actual Loss: 0.1524\n",
      "Baseline Loss: 2.6800 | Actual Loss: 0.2787\n",
      "Baseline Loss: 2.6723 | Actual Loss: 0.2553\n",
      "Baseline Loss: 2.6746 | Actual Loss: 0.1410\n",
      "Baseline Loss: 2.6485 | Actual Loss: 0.2549\n",
      "Baseline Loss: 2.6485 | Actual Loss: 0.1307\n",
      "Baseline Loss: 2.7005 | Actual Loss: 0.2098\n",
      "Baseline Loss: 2.7101 | Actual Loss: 0.5225\n",
      "Baseline Loss: 2.2782 | Actual Loss: 0.0921\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 199/1000 [01:34<06:11,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6990 | Actual Loss: 0.3137\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3294\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2534\n",
      "Epoch 199/1000: Train Loss: 0.2135, Val Loss: 0.3363\n",
      "Baseline Loss: 2.6798 | Actual Loss: 0.0837\n",
      "Baseline Loss: 2.6534 | Actual Loss: 0.2507\n",
      "Baseline Loss: 2.6872 | Actual Loss: 0.1162\n",
      "Baseline Loss: 2.6716 | Actual Loss: 0.0873\n",
      "Baseline Loss: 2.7162 | Actual Loss: 0.2878\n",
      "Baseline Loss: 2.6458 | Actual Loss: 0.1741\n",
      "Baseline Loss: 2.7337 | Actual Loss: 0.2344\n",
      "Baseline Loss: 2.6727 | Actual Loss: 0.1807\n",
      "Baseline Loss: 2.6565 | Actual Loss: 0.2079\n",
      "Baseline Loss: 2.6851 | Actual Loss: 0.1808\n",
      "Baseline Loss: 2.6432 | Actual Loss: 0.1931\n",
      "Baseline Loss: 2.6639 | Actual Loss: 0.1794\n",
      "Baseline Loss: 2.6796 | Actual Loss: 0.1425\n",
      "Baseline Loss: 2.6570 | Actual Loss: 0.1813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 200/1000 [01:34<06:15,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6419 | Actual Loss: 0.1658\n",
      "Baseline Loss: 2.3217 | Actual Loss: 0.0464\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4965\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.4347\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3411\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3156\n",
      "Epoch 200/1000: Train Loss: 0.1695, Val Loss: 0.3970\n",
      "Baseline Loss: 2.7256 | Actual Loss: 0.2522\n",
      "Baseline Loss: 2.6729 | Actual Loss: 0.1452\n",
      "Baseline Loss: 2.6362 | Actual Loss: 0.1861\n",
      "Baseline Loss: 2.6300 | Actual Loss: 0.1360\n",
      "Baseline Loss: 2.6753 | Actual Loss: 0.1679\n",
      "Baseline Loss: 2.6783 | Actual Loss: 0.1717\n",
      "Baseline Loss: 2.6724 | Actual Loss: 0.2494\n",
      "Baseline Loss: 2.6451 | Actual Loss: 0.2087\n",
      "Baseline Loss: 2.6878 | Actual Loss: 0.2506\n",
      "Baseline Loss: 2.6784 | Actual Loss: 0.1651\n",
      "Baseline Loss: 2.6515 | Actual Loss: 0.1875\n",
      "Baseline Loss: 2.6789 | Actual Loss: 0.0907\n",
      "Baseline Loss: 2.6818 | Actual Loss: 0.1291\n",
      "Baseline Loss: 2.6672 | Actual Loss: 0.3040\n",
      "Baseline Loss: 2.6878 | Actual Loss: 0.1528\n",
      "Baseline Loss: 2.2777 | Actual Loss: 0.0509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 201/1000 [01:35<06:21,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6857 | Actual Loss: 0.5031\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3058\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3167\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3068\n",
      "Epoch 201/1000: Train Loss: 0.1780, Val Loss: 0.3581\n",
      "Baseline Loss: 2.6869 | Actual Loss: 0.1638\n",
      "Baseline Loss: 2.6658 | Actual Loss: 0.1238\n",
      "Baseline Loss: 2.6995 | Actual Loss: 0.2595\n",
      "Baseline Loss: 2.6695 | Actual Loss: 0.1665\n",
      "Baseline Loss: 2.6986 | Actual Loss: 0.1787\n",
      "Baseline Loss: 2.6463 | Actual Loss: 0.2136\n",
      "Baseline Loss: 2.6665 | Actual Loss: 0.1447\n",
      "Baseline Loss: 2.6775 | Actual Loss: 0.1074\n",
      "Baseline Loss: 2.6742 | Actual Loss: 0.1490\n",
      "Baseline Loss: 2.6685 | Actual Loss: 0.1986\n",
      "Baseline Loss: 2.6548 | Actual Loss: 0.1318\n",
      "Baseline Loss: 2.7363 | Actual Loss: 0.1341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 202/1000 [01:35<06:02,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6443 | Actual Loss: 0.2884\n",
      "Baseline Loss: 2.6824 | Actual Loss: 0.1073\n",
      "Baseline Loss: 2.6627 | Actual Loss: 0.1465\n",
      "Baseline Loss: 2.2549 | Actual Loss: 0.1457\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4592\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3360\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3037\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3031\n",
      "Epoch 202/1000: Train Loss: 0.1662, Val Loss: 0.3505\n",
      "Baseline Loss: 2.6790 | Actual Loss: 0.1706\n",
      "Baseline Loss: 2.6559 | Actual Loss: 0.1619\n",
      "Baseline Loss: 2.7189 | Actual Loss: 0.1098\n",
      "Baseline Loss: 2.6637 | Actual Loss: 0.2902\n",
      "Baseline Loss: 2.6577 | Actual Loss: 0.2495\n",
      "Baseline Loss: 2.7050 | Actual Loss: 0.2313\n",
      "Baseline Loss: 2.6656 | Actual Loss: 0.2130\n",
      "Baseline Loss: 2.6643 | Actual Loss: 0.1956\n",
      "Baseline Loss: 2.6895 | Actual Loss: 0.1300\n",
      "Baseline Loss: 2.6934 | Actual Loss: 0.1985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 203/1000 [01:36<06:12,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6231 | Actual Loss: 0.2460\n",
      "Baseline Loss: 2.6973 | Actual Loss: 0.2222\n",
      "Baseline Loss: 2.6567 | Actual Loss: 0.0933\n",
      "Baseline Loss: 2.6787 | Actual Loss: 0.1394\n",
      "Baseline Loss: 2.6736 | Actual Loss: 0.3345\n",
      "Baseline Loss: 2.3005 | Actual Loss: 0.1125\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5295\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3636\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2739\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3211\n",
      "Epoch 203/1000: Train Loss: 0.1936, Val Loss: 0.3720\n",
      "Baseline Loss: 2.6506 | Actual Loss: 0.1841\n",
      "Baseline Loss: 2.6894 | Actual Loss: 0.3813\n",
      "Baseline Loss: 2.7028 | Actual Loss: 0.0846\n",
      "Baseline Loss: 2.6595 | Actual Loss: 0.1552\n",
      "Baseline Loss: 2.6568 | Actual Loss: 0.1286\n",
      "Baseline Loss: 2.6596 | Actual Loss: 0.1910\n",
      "Baseline Loss: 2.7487 | Actual Loss: 0.4029\n",
      "Baseline Loss: 2.6719 | Actual Loss: 0.1793\n",
      "Baseline Loss: 2.6303 | Actual Loss: 0.1545\n",
      "Baseline Loss: 2.7229 | Actual Loss: 0.0718\n",
      "Baseline Loss: 2.6614 | Actual Loss: 0.2129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 204/1000 [01:36<06:00,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6430 | Actual Loss: 0.0852\n",
      "Baseline Loss: 2.6660 | Actual Loss: 0.2197\n",
      "Baseline Loss: 2.7120 | Actual Loss: 0.0992\n",
      "Baseline Loss: 2.6843 | Actual Loss: 0.1863\n",
      "Baseline Loss: 2.2053 | Actual Loss: 0.1744\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4579\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.4226\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2310\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2766\n",
      "Epoch 204/1000: Train Loss: 0.1819, Val Loss: 0.3470\n",
      "Baseline Loss: 2.6983 | Actual Loss: 0.1594\n",
      "Baseline Loss: 2.6619 | Actual Loss: 0.2322\n",
      "Baseline Loss: 2.7554 | Actual Loss: 0.2311\n",
      "Baseline Loss: 2.6906 | Actual Loss: 0.1795\n",
      "Baseline Loss: 2.6508 | Actual Loss: 0.1787\n",
      "Baseline Loss: 2.6645 | Actual Loss: 0.3063\n",
      "Baseline Loss: 2.6833 | Actual Loss: 0.3724\n",
      "Baseline Loss: 2.6411 | Actual Loss: 0.2193\n",
      "Baseline Loss: 2.6779 | Actual Loss: 0.3234\n",
      "Baseline Loss: 2.6399 | Actual Loss: 0.1828\n",
      "Baseline Loss: 2.7014 | Actual Loss: 0.1764\n",
      "Baseline Loss: 2.6635 | Actual Loss: 0.1711\n",
      "Baseline Loss: 2.6426 | Actual Loss: 0.1159\n",
      "Baseline Loss: 2.6783 | Actual Loss: 0.1979\n",
      "Baseline Loss: 2.6664 | Actual Loss: 0.2823\n",
      "Baseline Loss: 2.2551 | Actual Loss: 0.1117\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4497\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3394\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 205/1000 [01:36<06:02,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6194 | Actual Loss: 0.3168\n",
      "Epoch 205/1000: Train Loss: 0.2150, Val Loss: 0.3444\n",
      "Baseline Loss: 2.6416 | Actual Loss: 0.1666\n",
      "Baseline Loss: 2.6725 | Actual Loss: 0.2197\n",
      "Baseline Loss: 2.6511 | Actual Loss: 0.1806\n",
      "Baseline Loss: 2.7086 | Actual Loss: 0.1824\n",
      "Baseline Loss: 2.6462 | Actual Loss: 0.2131\n",
      "Baseline Loss: 2.6519 | Actual Loss: 0.1475\n",
      "Baseline Loss: 2.6568 | Actual Loss: 0.1968\n",
      "Baseline Loss: 2.6793 | Actual Loss: 0.1569\n",
      "Baseline Loss: 2.7233 | Actual Loss: 0.2387\n",
      "Baseline Loss: 2.6773 | Actual Loss: 0.1929\n",
      "Baseline Loss: 2.6854 | Actual Loss: 0.2590\n",
      "Baseline Loss: 2.6601 | Actual Loss: 0.2341\n",
      "Baseline Loss: 2.6662 | Actual Loss: 0.2758\n",
      "Baseline Loss: 2.6797 | Actual Loss: 0.1768\n",
      "Baseline Loss: 2.6460 | Actual Loss: 0.1585\n",
      "Baseline Loss: 2.2966 | Actual Loss: 0.1425\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4277\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 206/1000 [01:37<05:57,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6381 | Actual Loss: 0.2891\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3223\n",
      "Epoch 206/1000: Train Loss: 0.1964, Val Loss: 0.3446\n",
      "Baseline Loss: 2.7104 | Actual Loss: 0.1103\n",
      "Baseline Loss: 2.6962 | Actual Loss: 0.2935\n",
      "Baseline Loss: 2.6646 | Actual Loss: 0.2282\n",
      "Baseline Loss: 2.6450 | Actual Loss: 0.3323\n",
      "Baseline Loss: 2.6891 | Actual Loss: 0.1910\n",
      "Baseline Loss: 2.7311 | Actual Loss: 0.1831\n",
      "Baseline Loss: 2.6701 | Actual Loss: 0.1174\n",
      "Baseline Loss: 2.6420 | Actual Loss: 0.3595\n",
      "Baseline Loss: 2.6385 | Actual Loss: 0.1534\n",
      "Baseline Loss: 2.6539 | Actual Loss: 0.1586\n",
      "Baseline Loss: 2.6709 | Actual Loss: 0.3053\n",
      "Baseline Loss: 2.6711 | Actual Loss: 0.2138\n",
      "Baseline Loss: 2.6618 | Actual Loss: 0.2095\n",
      "Baseline Loss: 2.6819 | Actual Loss: 0.1566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 207/1000 [01:37<06:10,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6392 | Actual Loss: 0.2389\n",
      "Baseline Loss: 2.3053 | Actual Loss: 0.1594\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4495\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3689\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2153\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3057\n",
      "Epoch 207/1000: Train Loss: 0.2132, Val Loss: 0.3348\n",
      "Baseline Loss: 2.6737 | Actual Loss: 0.3396\n",
      "Baseline Loss: 2.6331 | Actual Loss: 0.1875\n",
      "Baseline Loss: 2.6838 | Actual Loss: 0.3357\n",
      "Baseline Loss: 2.7000 | Actual Loss: 0.1726\n",
      "Baseline Loss: 2.6720 | Actual Loss: 0.0945\n",
      "Baseline Loss: 2.7032 | Actual Loss: 0.1523\n",
      "Baseline Loss: 2.6499 | Actual Loss: 0.2081\n",
      "Baseline Loss: 2.7008 | Actual Loss: 0.1499\n",
      "Baseline Loss: 2.6687 | Actual Loss: 0.1656\n",
      "Baseline Loss: 2.6540 | Actual Loss: 0.1244\n",
      "Baseline Loss: 2.7171 | Actual Loss: 0.0842\n",
      "Baseline Loss: 2.6910 | Actual Loss: 0.3224\n",
      "Baseline Loss: 2.6518 | Actual Loss: 0.2398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 208/1000 [01:38<06:14,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6760 | Actual Loss: 0.1602\n",
      "Baseline Loss: 2.6674 | Actual Loss: 0.2111\n",
      "Baseline Loss: 2.2933 | Actual Loss: 0.3995\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.3955\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3759\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2414\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3986\n",
      "Epoch 208/1000: Train Loss: 0.2092, Val Loss: 0.3528\n",
      "Baseline Loss: 2.6587 | Actual Loss: 0.2252\n",
      "Baseline Loss: 2.6655 | Actual Loss: 0.1804\n",
      "Baseline Loss: 2.6654 | Actual Loss: 0.1342\n",
      "Baseline Loss: 2.6614 | Actual Loss: 0.2423\n",
      "Baseline Loss: 2.7035 | Actual Loss: 0.0906\n",
      "Baseline Loss: 2.6551 | Actual Loss: 0.2172\n",
      "Baseline Loss: 2.6774 | Actual Loss: 0.1643\n",
      "Baseline Loss: 2.6820 | Actual Loss: 0.1244\n",
      "Baseline Loss: 2.6568 | Actual Loss: 0.1191\n",
      "Baseline Loss: 2.6413 | Actual Loss: 0.1224\n",
      "Baseline Loss: 2.6551 | Actual Loss: 0.1742\n",
      "Baseline Loss: 2.6715 | Actual Loss: 0.3502\n",
      "Baseline Loss: 2.6815 | Actual Loss: 0.1933\n",
      "Baseline Loss: 2.6551 | Actual Loss: 0.2153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 209/1000 [01:38<06:05,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6934 | Actual Loss: 0.2732\n",
      "Baseline Loss: 2.2446 | Actual Loss: 0.2105\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4619\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3729\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2687\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3755\n",
      "Epoch 209/1000: Train Loss: 0.1898, Val Loss: 0.3698\n",
      "Baseline Loss: 2.6387 | Actual Loss: 0.2643\n",
      "Baseline Loss: 2.6693 | Actual Loss: 0.1526\n",
      "Baseline Loss: 2.6705 | Actual Loss: 0.2520\n",
      "Baseline Loss: 2.6753 | Actual Loss: 0.2124\n",
      "Baseline Loss: 2.6451 | Actual Loss: 0.1248\n",
      "Baseline Loss: 2.6795 | Actual Loss: 0.2886\n",
      "Baseline Loss: 2.6627 | Actual Loss: 0.2052\n",
      "Baseline Loss: 2.6539 | Actual Loss: 0.1409\n",
      "Baseline Loss: 2.7268 | Actual Loss: 0.1497\n",
      "Baseline Loss: 2.6414 | Actual Loss: 0.2449\n",
      "Baseline Loss: 2.6577 | Actual Loss: 0.2427\n",
      "Baseline Loss: 2.6704 | Actual Loss: 0.1617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 210/1000 [01:39<06:10,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6760 | Actual Loss: 0.1376\n",
      "Baseline Loss: 2.6500 | Actual Loss: 0.2181\n",
      "Baseline Loss: 2.6631 | Actual Loss: 0.1584\n",
      "Baseline Loss: 2.2921 | Actual Loss: 0.0657\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.3428\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3150\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3269\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3516\n",
      "Epoch 210/1000: Train Loss: 0.1887, Val Loss: 0.3341\n",
      "Baseline Loss: 2.6795 | Actual Loss: 0.2176\n",
      "Baseline Loss: 2.6650 | Actual Loss: 0.1839\n",
      "Baseline Loss: 2.6577 | Actual Loss: 0.1682\n",
      "Baseline Loss: 2.6360 | Actual Loss: 0.2133\n",
      "Baseline Loss: 2.6977 | Actual Loss: 0.1295\n",
      "Baseline Loss: 2.6703 | Actual Loss: 0.2104\n",
      "Baseline Loss: 2.6867 | Actual Loss: 0.2346\n",
      "Baseline Loss: 2.6740 | Actual Loss: 0.1901\n",
      "Baseline Loss: 2.6701 | Actual Loss: 0.2463\n",
      "Baseline Loss: 2.6441 | Actual Loss: 0.1678\n",
      "Baseline Loss: 2.6892 | Actual Loss: 0.1831\n",
      "Baseline Loss: 2.6795 | Actual Loss: 0.1338\n",
      "Baseline Loss: 2.6768 | Actual Loss: 0.2039\n",
      "Baseline Loss: 2.6518 | Actual Loss: 0.2935\n",
      "Baseline Loss: 2.6620 | Actual Loss: 0.1364\n",
      "Baseline Loss: 2.3582 | Actual Loss: 0.1335\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4107\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.2870\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 211/1000 [01:39<06:23,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6194 | Actual Loss: 0.2635\n",
      "Epoch 211/1000: Train Loss: 0.1904, Val Loss: 0.3041\n",
      "New best validation loss: 0.3041\n",
      "Baseline Loss: 2.6728 | Actual Loss: 0.2025\n",
      "Baseline Loss: 2.7592 | Actual Loss: 0.1483\n",
      "Baseline Loss: 2.6396 | Actual Loss: 0.1202\n",
      "Baseline Loss: 2.6721 | Actual Loss: 0.4188\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.1531\n",
      "Baseline Loss: 2.6771 | Actual Loss: 0.1088\n",
      "Baseline Loss: 2.6672 | Actual Loss: 0.3448\n",
      "Baseline Loss: 2.6637 | Actual Loss: 0.1764\n",
      "Baseline Loss: 2.6757 | Actual Loss: 0.1272\n",
      "Baseline Loss: 2.6774 | Actual Loss: 0.1114\n",
      "Baseline Loss: 2.6689 | Actual Loss: 0.2917\n",
      "Baseline Loss: 2.6628 | Actual Loss: 0.2094\n",
      "Baseline Loss: 2.6941 | Actual Loss: 0.1618\n",
      "Baseline Loss: 2.7104 | Actual Loss: 0.3433\n",
      "Baseline Loss: 2.6589 | Actual Loss: 0.2147\n",
      "Baseline Loss: 2.2038 | Actual Loss: 0.1519\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5589\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 212/1000 [01:40<06:24,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6381 | Actual Loss: 0.3330\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2869\n",
      "Epoch 212/1000: Train Loss: 0.2053, Val Loss: 0.3745\n",
      "Baseline Loss: 2.6573 | Actual Loss: 0.1375\n",
      "Baseline Loss: 2.6590 | Actual Loss: 0.1720\n",
      "Baseline Loss: 2.6213 | Actual Loss: 0.3448\n",
      "Baseline Loss: 2.7045 | Actual Loss: 0.1390\n",
      "Baseline Loss: 2.7141 | Actual Loss: 0.1355\n",
      "Baseline Loss: 2.6505 | Actual Loss: 0.1181\n",
      "Baseline Loss: 2.6475 | Actual Loss: 0.3257\n",
      "Baseline Loss: 2.6969 | Actual Loss: 0.1803\n",
      "Baseline Loss: 2.6699 | Actual Loss: 0.0841\n",
      "Baseline Loss: 2.6547 | Actual Loss: 0.2561\n",
      "Baseline Loss: 2.7151 | Actual Loss: 0.1862\n",
      "Baseline Loss: 2.6808 | Actual Loss: 0.2279\n",
      "Baseline Loss: 2.7420 | Actual Loss: 0.1942\n",
      "Baseline Loss: 2.6469 | Actual Loss: 0.1421\n",
      "Baseline Loss: 2.7008 | Actual Loss: 0.1865\n",
      "Baseline Loss: 2.2569 | Actual Loss: 0.1030\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██▏       | 213/1000 [01:40<06:07,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6990 | Actual Loss: 0.2612\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2749\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2946\n",
      "Epoch 213/1000: Train Loss: 0.1833, Val Loss: 0.3435\n",
      "Baseline Loss: 2.6520 | Actual Loss: 0.1361\n",
      "Baseline Loss: 2.6899 | Actual Loss: 0.2156\n",
      "Baseline Loss: 2.6530 | Actual Loss: 0.1512\n",
      "Baseline Loss: 2.6962 | Actual Loss: 0.2766\n",
      "Baseline Loss: 2.7026 | Actual Loss: 0.1946\n",
      "Baseline Loss: 2.6733 | Actual Loss: 0.1847\n",
      "Baseline Loss: 2.7179 | Actual Loss: 0.2421\n",
      "Baseline Loss: 2.6521 | Actual Loss: 0.1888\n",
      "Baseline Loss: 2.6720 | Actual Loss: 0.1363\n",
      "Baseline Loss: 2.6921 | Actual Loss: 0.3132\n",
      "Baseline Loss: 2.6590 | Actual Loss: 0.1287\n",
      "Baseline Loss: 2.6718 | Actual Loss: 0.2590\n",
      "Baseline Loss: 2.6257 | Actual Loss: 0.1751\n",
      "Baseline Loss: 2.6973 | Actual Loss: 0.1320\n",
      "Baseline Loss: 2.7214 | Actual Loss: 0.1636\n",
      "Baseline Loss: 2.2432 | Actual Loss: 0.0906\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██▏       | 214/1000 [01:41<06:12,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6990 | Actual Loss: 0.2792\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2314\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3728\n",
      "Epoch 214/1000: Train Loss: 0.1868, Val Loss: 0.3598\n",
      "Baseline Loss: 2.6806 | Actual Loss: 0.1625\n",
      "Baseline Loss: 2.6478 | Actual Loss: 0.1633\n",
      "Baseline Loss: 2.6850 | Actual Loss: 0.1525\n",
      "Baseline Loss: 2.6859 | Actual Loss: 0.2341\n",
      "Baseline Loss: 2.6862 | Actual Loss: 0.1102\n",
      "Baseline Loss: 2.6575 | Actual Loss: 0.1645\n",
      "Baseline Loss: 2.6529 | Actual Loss: 0.2905\n",
      "Baseline Loss: 2.6702 | Actual Loss: 0.1681\n",
      "Baseline Loss: 2.6730 | Actual Loss: 0.1231\n",
      "Baseline Loss: 2.6868 | Actual Loss: 0.1747\n",
      "Baseline Loss: 2.6463 | Actual Loss: 0.1138\n",
      "Baseline Loss: 2.6551 | Actual Loss: 0.1803\n",
      "Baseline Loss: 2.6385 | Actual Loss: 0.1973\n",
      "Baseline Loss: 2.7090 | Actual Loss: 0.1742\n",
      "Baseline Loss: 2.6491 | Actual Loss: 0.4688\n",
      "Baseline Loss: 2.2382 | Actual Loss: 0.1313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 215/1000 [01:41<06:19,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6857 | Actual Loss: 0.4433\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3739\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2280\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2930\n",
      "Epoch 215/1000: Train Loss: 0.1881, Val Loss: 0.3345\n",
      "Baseline Loss: 2.7033 | Actual Loss: 0.1476\n",
      "Baseline Loss: 2.6886 | Actual Loss: 0.2243\n",
      "Baseline Loss: 2.6647 | Actual Loss: 0.2209\n",
      "Baseline Loss: 2.6535 | Actual Loss: 0.1208\n",
      "Baseline Loss: 2.6982 | Actual Loss: 0.2506\n",
      "Baseline Loss: 2.6834 | Actual Loss: 0.2883\n",
      "Baseline Loss: 2.6538 | Actual Loss: 0.1930\n",
      "Baseline Loss: 2.6593 | Actual Loss: 0.2126\n",
      "Baseline Loss: 2.7164 | Actual Loss: 0.2468\n",
      "Baseline Loss: 2.7207 | Actual Loss: 0.2730\n",
      "Baseline Loss: 2.6301 | Actual Loss: 0.2170\n",
      "Baseline Loss: 2.6630 | Actual Loss: 0.1577\n",
      "Baseline Loss: 2.6778 | Actual Loss: 0.1420\n",
      "Baseline Loss: 2.6436 | Actual Loss: 0.1397\n",
      "Baseline Loss: 2.6542 | Actual Loss: 0.1081\n",
      "Baseline Loss: 2.3041 | Actual Loss: 0.1842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 216/1000 [01:42<06:05,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6857 | Actual Loss: 0.4277\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3597\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2630\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2174\n",
      "Epoch 216/1000: Train Loss: 0.1954, Val Loss: 0.3170\n",
      "Baseline Loss: 2.6851 | Actual Loss: 0.1468\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.2845\n",
      "Baseline Loss: 2.6854 | Actual Loss: 0.1803\n",
      "Baseline Loss: 2.7141 | Actual Loss: 0.1630\n",
      "Baseline Loss: 2.6590 | Actual Loss: 0.2089\n",
      "Baseline Loss: 2.7732 | Actual Loss: 0.2423\n",
      "Baseline Loss: 2.6507 | Actual Loss: 0.1959\n",
      "Baseline Loss: 2.6628 | Actual Loss: 0.2378\n",
      "Baseline Loss: 2.6405 | Actual Loss: 0.2037\n",
      "Baseline Loss: 2.6942 | Actual Loss: 0.2047\n",
      "Baseline Loss: 2.6552 | Actual Loss: 0.1911\n",
      "Baseline Loss: 2.6584 | Actual Loss: 0.1265\n",
      "Baseline Loss: 2.6594 | Actual Loss: 0.1330\n",
      "Baseline Loss: 2.6828 | Actual Loss: 0.2092\n",
      "Baseline Loss: 2.6485 | Actual Loss: 0.1656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 217/1000 [01:42<06:12,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2098 | Actual Loss: 0.2736\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4338\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.4784\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2970\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3249\n",
      "Epoch 217/1000: Train Loss: 0.1979, Val Loss: 0.3835\n",
      "Baseline Loss: 2.6540 | Actual Loss: 0.1486\n",
      "Baseline Loss: 2.6486 | Actual Loss: 0.1354\n",
      "Baseline Loss: 2.6842 | Actual Loss: 0.1632\n",
      "Baseline Loss: 2.6419 | Actual Loss: 0.1539\n",
      "Baseline Loss: 2.6601 | Actual Loss: 0.2039\n",
      "Baseline Loss: 2.6972 | Actual Loss: 0.2477\n",
      "Baseline Loss: 2.6774 | Actual Loss: 0.2124\n",
      "Baseline Loss: 2.6734 | Actual Loss: 0.2448\n",
      "Baseline Loss: 2.7057 | Actual Loss: 0.1044\n",
      "Baseline Loss: 2.6473 | Actual Loss: 0.1825\n",
      "Baseline Loss: 2.6268 | Actual Loss: 0.1555\n",
      "Baseline Loss: 2.7010 | Actual Loss: 0.1162\n",
      "Baseline Loss: 2.6728 | Actual Loss: 0.2680\n",
      "Baseline Loss: 2.6860 | Actual Loss: 0.1178\n",
      "Baseline Loss: 2.6477 | Actual Loss: 0.2330\n",
      "Baseline Loss: 2.3150 | Actual Loss: 0.0831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 218/1000 [01:43<06:14,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6857 | Actual Loss: 0.4267\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.2897\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2870\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3158\n",
      "Epoch 218/1000: Train Loss: 0.1731, Val Loss: 0.3298\n",
      "Baseline Loss: 2.7121 | Actual Loss: 0.1674\n",
      "Baseline Loss: 2.7040 | Actual Loss: 0.1852\n",
      "Baseline Loss: 2.6480 | Actual Loss: 0.2110\n",
      "Baseline Loss: 2.6862 | Actual Loss: 0.0999\n",
      "Baseline Loss: 2.6962 | Actual Loss: 0.1273\n",
      "Baseline Loss: 2.6937 | Actual Loss: 0.4412\n",
      "Baseline Loss: 2.6551 | Actual Loss: 0.1151\n",
      "Baseline Loss: 2.6468 | Actual Loss: 0.3843\n",
      "Baseline Loss: 2.6703 | Actual Loss: 0.2187\n",
      "Baseline Loss: 2.6902 | Actual Loss: 0.3244\n",
      "Baseline Loss: 2.6512 | Actual Loss: 0.1435\n",
      "Baseline Loss: 2.7165 | Actual Loss: 0.1540\n",
      "Baseline Loss: 2.6488 | Actual Loss: 0.2426\n",
      "Baseline Loss: 2.6568 | Actual Loss: 0.2245\n",
      "Baseline Loss: 2.6442 | Actual Loss: 0.1379\n",
      "Baseline Loss: 2.2492 | Actual Loss: 0.1637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 219/1000 [01:43<05:56,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6857 | Actual Loss: 0.4372\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3637\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3353\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2834\n",
      "Epoch 219/1000: Train Loss: 0.2088, Val Loss: 0.3549\n",
      "Baseline Loss: 2.6671 | Actual Loss: 0.4789\n",
      "Baseline Loss: 2.7247 | Actual Loss: 0.2236\n",
      "Baseline Loss: 2.6713 | Actual Loss: 0.3728\n",
      "Baseline Loss: 2.6988 | Actual Loss: 0.1629\n",
      "Baseline Loss: 2.6426 | Actual Loss: 0.1917\n",
      "Baseline Loss: 2.6557 | Actual Loss: 0.3458\n",
      "Baseline Loss: 2.6703 | Actual Loss: 0.1192\n",
      "Baseline Loss: 2.7001 | Actual Loss: 0.1268\n",
      "Baseline Loss: 2.6580 | Actual Loss: 0.1470\n",
      "Baseline Loss: 2.6658 | Actual Loss: 0.1537\n",
      "Baseline Loss: 2.6972 | Actual Loss: 0.2289\n",
      "Baseline Loss: 2.6401 | Actual Loss: 0.2151\n",
      "Baseline Loss: 2.6505 | Actual Loss: 0.1201\n",
      "Baseline Loss: 2.6835 | Actual Loss: 0.1859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 220/1000 [01:43<05:54,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6668 | Actual Loss: 0.1764\n",
      "Baseline Loss: 2.2969 | Actual Loss: 0.1747\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5082\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3822\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2321\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2947\n",
      "Epoch 220/1000: Train Loss: 0.2140, Val Loss: 0.3543\n",
      "Baseline Loss: 2.7078 | Actual Loss: 0.1358\n",
      "Baseline Loss: 2.6637 | Actual Loss: 0.2249\n",
      "Baseline Loss: 2.6788 | Actual Loss: 0.1530\n",
      "Baseline Loss: 2.6728 | Actual Loss: 0.1922\n",
      "Baseline Loss: 2.7145 | Actual Loss: 0.1959\n",
      "Baseline Loss: 2.6757 | Actual Loss: 0.2461\n",
      "Baseline Loss: 2.6815 | Actual Loss: 0.2504\n",
      "Baseline Loss: 2.6642 | Actual Loss: 0.2104\n",
      "Baseline Loss: 2.6534 | Actual Loss: 0.1764\n",
      "Baseline Loss: 2.6407 | Actual Loss: 0.1900\n",
      "Baseline Loss: 2.6488 | Actual Loss: 0.3540\n",
      "Baseline Loss: 2.7168 | Actual Loss: 0.1982\n",
      "Baseline Loss: 2.6905 | Actual Loss: 0.2753\n",
      "Baseline Loss: 2.6575 | Actual Loss: 0.2389\n",
      "Baseline Loss: 2.6935 | Actual Loss: 0.2301\n",
      "Baseline Loss: 2.2087 | Actual Loss: 0.1508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 221/1000 [01:44<05:38,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6857 | Actual Loss: 0.5219\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.4257\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3202\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3872\n",
      "Epoch 221/1000: Train Loss: 0.2139, Val Loss: 0.4138\n",
      "Baseline Loss: 2.6852 | Actual Loss: 0.2331\n",
      "Baseline Loss: 2.6269 | Actual Loss: 0.2122\n",
      "Baseline Loss: 2.6656 | Actual Loss: 0.1621\n",
      "Baseline Loss: 2.6624 | Actual Loss: 0.1340\n",
      "Baseline Loss: 2.6495 | Actual Loss: 0.1846\n",
      "Baseline Loss: 2.7228 | Actual Loss: 0.1526\n",
      "Baseline Loss: 2.6785 | Actual Loss: 0.1474\n",
      "Baseline Loss: 2.6491 | Actual Loss: 0.2200\n",
      "Baseline Loss: 2.6966 | Actual Loss: 0.1936\n",
      "Baseline Loss: 2.6419 | Actual Loss: 0.1180\n",
      "Baseline Loss: 2.7109 | Actual Loss: 0.2925\n",
      "Baseline Loss: 2.6649 | Actual Loss: 0.1383\n",
      "Baseline Loss: 2.7155 | Actual Loss: 0.1243\n",
      "Baseline Loss: 2.7032 | Actual Loss: 0.1601\n",
      "Baseline Loss: 2.6316 | Actual Loss: 0.1363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 222/1000 [01:44<06:00,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2960 | Actual Loss: 0.0399\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4349\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3946\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2904\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2542\n",
      "Epoch 222/1000: Train Loss: 0.1656, Val Loss: 0.3435\n",
      "Baseline Loss: 2.6643 | Actual Loss: 0.1938\n",
      "Baseline Loss: 2.6793 | Actual Loss: 0.0867\n",
      "Baseline Loss: 2.6308 | Actual Loss: 0.1416\n",
      "Baseline Loss: 2.6658 | Actual Loss: 0.2999\n",
      "Baseline Loss: 2.7134 | Actual Loss: 0.2622\n",
      "Baseline Loss: 2.6746 | Actual Loss: 0.2835\n",
      "Baseline Loss: 2.7089 | Actual Loss: 0.1150\n",
      "Baseline Loss: 2.6601 | Actual Loss: 0.2346\n",
      "Baseline Loss: 2.6743 | Actual Loss: 0.1440\n",
      "Baseline Loss: 2.6598 | Actual Loss: 0.2617\n",
      "Baseline Loss: 2.6765 | Actual Loss: 0.0852\n",
      "Baseline Loss: 2.7043 | Actual Loss: 0.1720\n",
      "Baseline Loss: 2.6726 | Actual Loss: 0.2148\n",
      "Baseline Loss: 2.7009 | Actual Loss: 0.4324\n",
      "Baseline Loss: 2.6425 | Actual Loss: 0.3042\n",
      "Baseline Loss: 2.2868 | Actual Loss: 0.0821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 223/1000 [01:45<05:44,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6857 | Actual Loss: 0.4207\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.2185\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2850\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3009\n",
      "Epoch 223/1000: Train Loss: 0.2071, Val Loss: 0.3063\n",
      "Baseline Loss: 2.6579 | Actual Loss: 0.1488\n",
      "Baseline Loss: 2.6273 | Actual Loss: 0.1693\n",
      "Baseline Loss: 2.6518 | Actual Loss: 0.2256\n",
      "Baseline Loss: 2.6399 | Actual Loss: 0.1332\n",
      "Baseline Loss: 2.6931 | Actual Loss: 0.2485\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.1654\n",
      "Baseline Loss: 2.6671 | Actual Loss: 0.1540\n",
      "Baseline Loss: 2.6933 | Actual Loss: 0.3875\n",
      "Baseline Loss: 2.6767 | Actual Loss: 0.2063\n",
      "Baseline Loss: 2.6754 | Actual Loss: 0.1810\n",
      "Baseline Loss: 2.6784 | Actual Loss: 0.2261\n",
      "Baseline Loss: 2.6551 | Actual Loss: 0.1974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 224/1000 [01:45<05:55,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6669 | Actual Loss: 0.1960\n",
      "Baseline Loss: 2.7043 | Actual Loss: 0.2136\n",
      "Baseline Loss: 2.6842 | Actual Loss: 0.1374\n",
      "Baseline Loss: 2.2812 | Actual Loss: 0.1279\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.3906\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3040\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2526\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2531\n",
      "Epoch 224/1000: Train Loss: 0.1949, Val Loss: 0.3001\n",
      "New best validation loss: 0.3001\n",
      "Baseline Loss: 2.6865 | Actual Loss: 0.2335\n",
      "Baseline Loss: 2.7406 | Actual Loss: 0.1371\n",
      "Baseline Loss: 2.6818 | Actual Loss: 0.1937\n",
      "Baseline Loss: 2.7031 | Actual Loss: 0.2347\n",
      "Baseline Loss: 2.6683 | Actual Loss: 0.3024\n",
      "Baseline Loss: 2.6383 | Actual Loss: 0.1598\n",
      "Baseline Loss: 2.6308 | Actual Loss: 0.2408\n",
      "Baseline Loss: 2.6837 | Actual Loss: 0.1214\n",
      "Baseline Loss: 2.6848 | Actual Loss: 0.2936\n",
      "Baseline Loss: 2.6841 | Actual Loss: 0.2624\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.2704\n",
      "Baseline Loss: 2.6787 | Actual Loss: 0.3385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▎       | 225/1000 [01:46<06:07,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6987 | Actual Loss: 0.1913\n",
      "Baseline Loss: 2.6782 | Actual Loss: 0.2037\n",
      "Baseline Loss: 2.6772 | Actual Loss: 0.1646\n",
      "Baseline Loss: 2.2370 | Actual Loss: 0.2569\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5892\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.2975\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2948\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2699\n",
      "Epoch 225/1000: Train Loss: 0.2253, Val Loss: 0.3629\n",
      "Baseline Loss: 2.6579 | Actual Loss: 0.2617\n",
      "Baseline Loss: 2.6713 | Actual Loss: 0.1216\n",
      "Baseline Loss: 2.6814 | Actual Loss: 0.2098\n",
      "Baseline Loss: 2.7137 | Actual Loss: 0.0588\n",
      "Baseline Loss: 2.6697 | Actual Loss: 0.0775\n",
      "Baseline Loss: 2.6401 | Actual Loss: 0.1466\n",
      "Baseline Loss: 2.6338 | Actual Loss: 0.1403\n",
      "Baseline Loss: 2.6894 | Actual Loss: 0.2733\n",
      "Baseline Loss: 2.7083 | Actual Loss: 0.1945\n",
      "Baseline Loss: 2.6940 | Actual Loss: 0.0872\n",
      "Baseline Loss: 2.6380 | Actual Loss: 0.1562\n",
      "Baseline Loss: 2.6713 | Actual Loss: 0.0897\n",
      "Baseline Loss: 2.6952 | Actual Loss: 0.2139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 226/1000 [01:46<05:49,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6591 | Actual Loss: 0.0813\n",
      "Baseline Loss: 2.6898 | Actual Loss: 0.1964\n",
      "Baseline Loss: 2.3298 | Actual Loss: 0.2812\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4904\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3487\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2597\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2542\n",
      "Epoch 226/1000: Train Loss: 0.1619, Val Loss: 0.3383\n",
      "Baseline Loss: 2.6310 | Actual Loss: 0.1374\n",
      "Baseline Loss: 2.6812 | Actual Loss: 0.3544\n",
      "Baseline Loss: 2.6989 | Actual Loss: 0.0672\n",
      "Baseline Loss: 2.7170 | Actual Loss: 0.2351\n",
      "Baseline Loss: 2.6622 | Actual Loss: 0.1292\n",
      "Baseline Loss: 2.6863 | Actual Loss: 0.1286\n",
      "Baseline Loss: 2.6744 | Actual Loss: 0.2574\n",
      "Baseline Loss: 2.6869 | Actual Loss: 0.2575\n",
      "Baseline Loss: 2.6595 | Actual Loss: 0.3444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 227/1000 [01:47<05:59,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6553 | Actual Loss: 0.1907\n",
      "Baseline Loss: 2.6581 | Actual Loss: 0.1563\n",
      "Baseline Loss: 2.6633 | Actual Loss: 0.1650\n",
      "Baseline Loss: 2.6455 | Actual Loss: 0.1702\n",
      "Baseline Loss: 2.6884 | Actual Loss: 0.1749\n",
      "Baseline Loss: 2.6618 | Actual Loss: 0.2039\n",
      "Baseline Loss: 2.2560 | Actual Loss: 0.0344\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5287\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.2852\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3158\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2971\n",
      "Epoch 227/1000: Train Loss: 0.1879, Val Loss: 0.3567\n",
      "Baseline Loss: 2.7152 | Actual Loss: 0.2091\n",
      "Baseline Loss: 2.6567 | Actual Loss: 0.1730\n",
      "Baseline Loss: 2.7167 | Actual Loss: 0.0887\n",
      "Baseline Loss: 2.6492 | Actual Loss: 0.1835\n",
      "Baseline Loss: 2.6556 | Actual Loss: 0.1434\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.2235\n",
      "Baseline Loss: 2.6696 | Actual Loss: 0.1227\n",
      "Baseline Loss: 2.7114 | Actual Loss: 0.1587\n",
      "Baseline Loss: 2.6733 | Actual Loss: 0.1241\n",
      "Baseline Loss: 2.6798 | Actual Loss: 0.2200\n",
      "Baseline Loss: 2.7008 | Actual Loss: 0.5277\n",
      "Baseline Loss: 2.6582 | Actual Loss: 0.2938\n",
      "Baseline Loss: 2.6656 | Actual Loss: 0.1263\n",
      "Baseline Loss: 2.6365 | Actual Loss: 0.1278\n",
      "Baseline Loss: 2.6986 | Actual Loss: 0.1771\n",
      "Baseline Loss: 2.2374 | Actual Loss: 0.0616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 228/1000 [01:47<06:05,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6857 | Actual Loss: 0.4571\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.2579\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2491\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2689\n",
      "Epoch 228/1000: Train Loss: 0.1851, Val Loss: 0.3082\n",
      "Baseline Loss: 2.6521 | Actual Loss: 0.1849\n",
      "Baseline Loss: 2.6420 | Actual Loss: 0.1837\n",
      "Baseline Loss: 2.6849 | Actual Loss: 0.1994\n",
      "Baseline Loss: 2.6581 | Actual Loss: 0.2055\n",
      "Baseline Loss: 2.6808 | Actual Loss: 0.1308\n",
      "Baseline Loss: 2.6676 | Actual Loss: 0.1901\n",
      "Baseline Loss: 2.6616 | Actual Loss: 0.1511\n",
      "Baseline Loss: 2.7484 | Actual Loss: 0.1429\n",
      "Baseline Loss: 2.6743 | Actual Loss: 0.1277\n",
      "Baseline Loss: 2.6820 | Actual Loss: 0.1941\n",
      "Baseline Loss: 2.7194 | Actual Loss: 0.2194\n",
      "Baseline Loss: 2.6961 | Actual Loss: 0.2223\n",
      "Baseline Loss: 2.6546 | Actual Loss: 0.1029\n",
      "Baseline Loss: 2.6730 | Actual Loss: 0.2223\n",
      "Baseline Loss: 2.6621 | Actual Loss: 0.1356\n",
      "Baseline Loss: 2.2363 | Actual Loss: 0.1055\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4754\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.2956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 229/1000 [01:48<05:45,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6381 | Actual Loss: 0.2225\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2906\n",
      "Epoch 229/1000: Train Loss: 0.1699, Val Loss: 0.3210\n",
      "Baseline Loss: 2.6752 | Actual Loss: 0.2371\n",
      "Baseline Loss: 2.6517 | Actual Loss: 0.1290\n",
      "Baseline Loss: 2.6985 | Actual Loss: 0.1145\n",
      "Baseline Loss: 2.6763 | Actual Loss: 0.2699\n",
      "Baseline Loss: 2.6830 | Actual Loss: 0.1807\n",
      "Baseline Loss: 2.6628 | Actual Loss: 0.1650\n",
      "Baseline Loss: 2.6967 | Actual Loss: 0.1270\n",
      "Baseline Loss: 2.6885 | Actual Loss: 0.1869\n",
      "Baseline Loss: 2.6888 | Actual Loss: 0.1451\n",
      "Baseline Loss: 2.6892 | Actual Loss: 0.2293\n",
      "Baseline Loss: 2.6512 | Actual Loss: 0.2351\n",
      "Baseline Loss: 2.6599 | Actual Loss: 0.1856\n",
      "Baseline Loss: 2.6558 | Actual Loss: 0.1530\n",
      "Baseline Loss: 2.6609 | Actual Loss: 0.1860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 230/1000 [01:48<06:01,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6589 | Actual Loss: 0.1834\n",
      "Baseline Loss: 2.2853 | Actual Loss: 0.1425\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4489\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3992\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2992\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2739\n",
      "Epoch 230/1000: Train Loss: 0.1794, Val Loss: 0.3553\n",
      "Baseline Loss: 2.6859 | Actual Loss: 0.2012\n",
      "Baseline Loss: 2.6374 | Actual Loss: 0.2102\n",
      "Baseline Loss: 2.6482 | Actual Loss: 0.2260\n",
      "Baseline Loss: 2.6673 | Actual Loss: 0.1682\n",
      "Baseline Loss: 2.6563 | Actual Loss: 0.1773\n",
      "Baseline Loss: 2.6737 | Actual Loss: 0.2073\n",
      "Baseline Loss: 2.7103 | Actual Loss: 0.2590\n",
      "Baseline Loss: 2.6915 | Actual Loss: 0.1584\n",
      "Baseline Loss: 2.6696 | Actual Loss: 0.1675\n",
      "Baseline Loss: 2.7096 | Actual Loss: 0.1236\n",
      "Baseline Loss: 2.6926 | Actual Loss: 0.2878\n",
      "Baseline Loss: 2.6461 | Actual Loss: 0.1615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 231/1000 [01:49<06:05,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7192 | Actual Loss: 0.1576\n",
      "Baseline Loss: 2.6522 | Actual Loss: 0.1634\n",
      "Baseline Loss: 2.6847 | Actual Loss: 0.2454\n",
      "Baseline Loss: 2.2160 | Actual Loss: 0.2328\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4523\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3720\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2896\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3896\n",
      "Epoch 231/1000: Train Loss: 0.1967, Val Loss: 0.3759\n",
      "Baseline Loss: 2.6801 | Actual Loss: 0.2396\n",
      "Baseline Loss: 2.6601 | Actual Loss: 0.2070\n",
      "Baseline Loss: 2.6730 | Actual Loss: 0.1480\n",
      "Baseline Loss: 2.6945 | Actual Loss: 0.1683\n",
      "Baseline Loss: 2.6845 | Actual Loss: 0.1383\n",
      "Baseline Loss: 2.6574 | Actual Loss: 0.2365\n",
      "Baseline Loss: 2.6718 | Actual Loss: 0.1652\n",
      "Baseline Loss: 2.6393 | Actual Loss: 0.2141\n",
      "Baseline Loss: 2.6624 | Actual Loss: 0.2264\n",
      "Baseline Loss: 2.6461 | Actual Loss: 0.1648\n",
      "Baseline Loss: 2.6813 | Actual Loss: 0.1946\n",
      "Baseline Loss: 2.7078 | Actual Loss: 0.1364\n",
      "Baseline Loss: 2.6812 | Actual Loss: 0.1666\n",
      "Baseline Loss: 2.6714 | Actual Loss: 0.1630\n",
      "Baseline Loss: 2.6724 | Actual Loss: 0.1356\n",
      "Baseline Loss: 2.2371 | Actual Loss: 0.1444\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4914\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3358\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 232/1000 [01:49<06:04,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6194 | Actual Loss: 0.3193\n",
      "Epoch 232/1000: Train Loss: 0.1781, Val Loss: 0.3593\n",
      "Baseline Loss: 2.7240 | Actual Loss: 0.2542\n",
      "Baseline Loss: 2.6341 | Actual Loss: 0.1710\n",
      "Baseline Loss: 2.6411 | Actual Loss: 0.1255\n",
      "Baseline Loss: 2.7085 | Actual Loss: 0.2011\n",
      "Baseline Loss: 2.6777 | Actual Loss: 0.2788\n",
      "Baseline Loss: 2.7175 | Actual Loss: 0.2018\n",
      "Baseline Loss: 2.6744 | Actual Loss: 0.1365\n",
      "Baseline Loss: 2.6573 | Actual Loss: 0.1995\n",
      "Baseline Loss: 2.6720 | Actual Loss: 0.2063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 233/1000 [01:49<05:49,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6482 | Actual Loss: 0.1923\n",
      "Baseline Loss: 2.6790 | Actual Loss: 0.2915\n",
      "Baseline Loss: 2.6549 | Actual Loss: 0.1499\n",
      "Baseline Loss: 2.6855 | Actual Loss: 0.2641\n",
      "Baseline Loss: 2.6690 | Actual Loss: 0.2139\n",
      "Baseline Loss: 2.6567 | Actual Loss: 0.1965\n",
      "Baseline Loss: 2.3344 | Actual Loss: 0.2080\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4901\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3845\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2791\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3037\n",
      "Epoch 233/1000: Train Loss: 0.2057, Val Loss: 0.3644\n",
      "Baseline Loss: 2.6658 | Actual Loss: 0.1336\n",
      "Baseline Loss: 2.6942 | Actual Loss: 0.2108\n",
      "Baseline Loss: 2.6831 | Actual Loss: 0.1281\n",
      "Baseline Loss: 2.6669 | Actual Loss: 0.1492\n",
      "Baseline Loss: 2.6967 | Actual Loss: 0.1537\n",
      "Baseline Loss: 2.6241 | Actual Loss: 0.2652\n",
      "Baseline Loss: 2.7144 | Actual Loss: 0.2184\n",
      "Baseline Loss: 2.6531 | Actual Loss: 0.1234\n",
      "Baseline Loss: 2.6797 | Actual Loss: 0.1292\n",
      "Baseline Loss: 2.7185 | Actual Loss: 0.1444\n",
      "Baseline Loss: 2.6968 | Actual Loss: 0.3200\n",
      "Baseline Loss: 2.6635 | Actual Loss: 0.1975\n",
      "Baseline Loss: 2.6910 | Actual Loss: 0.2094\n",
      "Baseline Loss: 2.6596 | Actual Loss: 0.1940\n",
      "Baseline Loss: 2.6674 | Actual Loss: 0.1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 234/1000 [01:50<06:02,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.3153 | Actual Loss: 0.2413\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5114\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3541\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2436\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2866\n",
      "Epoch 234/1000: Train Loss: 0.1839, Val Loss: 0.3490\n",
      "Baseline Loss: 2.6997 | Actual Loss: 0.2826\n",
      "Baseline Loss: 2.6588 | Actual Loss: 0.2046\n",
      "Baseline Loss: 2.6741 | Actual Loss: 0.1570\n",
      "Baseline Loss: 2.6492 | Actual Loss: 0.2155\n",
      "Baseline Loss: 2.6561 | Actual Loss: 0.1942\n",
      "Baseline Loss: 2.6940 | Actual Loss: 0.1023\n",
      "Baseline Loss: 2.6489 | Actual Loss: 0.1751\n",
      "Baseline Loss: 2.6481 | Actual Loss: 0.2270\n",
      "Baseline Loss: 2.7034 | Actual Loss: 0.1334\n",
      "Baseline Loss: 2.7127 | Actual Loss: 0.1952\n",
      "Baseline Loss: 2.6699 | Actual Loss: 0.4000\n",
      "Baseline Loss: 2.6873 | Actual Loss: 0.2824\n",
      "Baseline Loss: 2.6705 | Actual Loss: 0.2888\n",
      "Baseline Loss: 2.6626 | Actual Loss: 0.1903\n",
      "Baseline Loss: 2.6757 | Actual Loss: 0.2375\n",
      "Baseline Loss: 2.2699 | Actual Loss: 0.1223\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██▎       | 235/1000 [01:50<06:03,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6990 | Actual Loss: 0.3997\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2103\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2739\n",
      "Epoch 235/1000: Train Loss: 0.2130, Val Loss: 0.3473\n",
      "Baseline Loss: 2.6936 | Actual Loss: 0.1786\n",
      "Baseline Loss: 2.6819 | Actual Loss: 0.1290\n",
      "Baseline Loss: 2.6917 | Actual Loss: 0.1590\n",
      "Baseline Loss: 2.6402 | Actual Loss: 0.1789\n",
      "Baseline Loss: 2.6717 | Actual Loss: 0.1674\n",
      "Baseline Loss: 2.6595 | Actual Loss: 0.1923\n",
      "Baseline Loss: 2.7026 | Actual Loss: 0.2506\n",
      "Baseline Loss: 2.6463 | Actual Loss: 0.1137\n",
      "Baseline Loss: 2.6980 | Actual Loss: 0.1722\n",
      "Baseline Loss: 2.6891 | Actual Loss: 0.4649\n",
      "Baseline Loss: 2.6654 | Actual Loss: 0.2136\n",
      "Baseline Loss: 2.6481 | Actual Loss: 0.3383\n",
      "Baseline Loss: 2.6367 | Actual Loss: 0.1131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██▎       | 236/1000 [01:51<05:54,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6331 | Actual Loss: 0.1623\n",
      "Baseline Loss: 2.7142 | Actual Loss: 0.1531\n",
      "Baseline Loss: 2.3398 | Actual Loss: 0.1034\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4747\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3398\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3475\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2863\n",
      "Epoch 236/1000: Train Loss: 0.1932, Val Loss: 0.3621\n",
      "Baseline Loss: 2.6864 | Actual Loss: 0.1197\n",
      "Baseline Loss: 2.6695 | Actual Loss: 0.1294\n",
      "Baseline Loss: 2.6564 | Actual Loss: 0.2112\n",
      "Baseline Loss: 2.6539 | Actual Loss: 0.1695\n",
      "Baseline Loss: 2.6490 | Actual Loss: 0.1899\n",
      "Baseline Loss: 2.6703 | Actual Loss: 0.1587\n",
      "Baseline Loss: 2.6646 | Actual Loss: 0.1354\n",
      "Baseline Loss: 2.6892 | Actual Loss: 0.2054\n",
      "Baseline Loss: 2.6789 | Actual Loss: 0.1766\n",
      "Baseline Loss: 2.6481 | Actual Loss: 0.1636\n",
      "Baseline Loss: 2.6893 | Actual Loss: 0.0876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██▎       | 237/1000 [01:51<05:56,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6748 | Actual Loss: 0.1744\n",
      "Baseline Loss: 2.6997 | Actual Loss: 0.2099\n",
      "Baseline Loss: 2.6655 | Actual Loss: 0.1214\n",
      "Baseline Loss: 2.6921 | Actual Loss: 0.1917\n",
      "Baseline Loss: 2.2981 | Actual Loss: 0.0987\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4968\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.2984\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3054\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2999\n",
      "Epoch 237/1000: Train Loss: 0.1589, Val Loss: 0.3501\n",
      "Baseline Loss: 2.6919 | Actual Loss: 0.1591\n",
      "Baseline Loss: 2.6540 | Actual Loss: 0.2188\n",
      "Baseline Loss: 2.6599 | Actual Loss: 0.1805\n",
      "Baseline Loss: 2.6779 | Actual Loss: 0.2104\n",
      "Baseline Loss: 2.6833 | Actual Loss: 0.1740\n",
      "Baseline Loss: 2.6456 | Actual Loss: 0.1912\n",
      "Baseline Loss: 2.7052 | Actual Loss: 0.1826\n",
      "Baseline Loss: 2.6562 | Actual Loss: 0.2747\n",
      "Baseline Loss: 2.6679 | Actual Loss: 0.2030\n",
      "Baseline Loss: 2.6612 | Actual Loss: 0.1911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██▍       | 238/1000 [01:52<05:39,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6863 | Actual Loss: 0.2401\n",
      "Baseline Loss: 2.6757 | Actual Loss: 0.1676\n",
      "Baseline Loss: 2.6943 | Actual Loss: 0.1014\n",
      "Baseline Loss: 2.6797 | Actual Loss: 0.1698\n",
      "Baseline Loss: 2.6876 | Actual Loss: 0.1332\n",
      "Baseline Loss: 2.2898 | Actual Loss: 0.1494\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4690\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3407\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2209\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3033\n",
      "Epoch 238/1000: Train Loss: 0.1842, Val Loss: 0.3335\n",
      "Baseline Loss: 2.6826 | Actual Loss: 0.1856\n",
      "Baseline Loss: 2.6692 | Actual Loss: 0.1862\n",
      "Baseline Loss: 2.6919 | Actual Loss: 0.1261\n",
      "Baseline Loss: 2.6730 | Actual Loss: 0.2634\n",
      "Baseline Loss: 2.6859 | Actual Loss: 0.1716\n",
      "Baseline Loss: 2.6872 | Actual Loss: 0.1294\n",
      "Baseline Loss: 2.6809 | Actual Loss: 0.1324\n",
      "Baseline Loss: 2.6744 | Actual Loss: 0.1587\n",
      "Baseline Loss: 2.6892 | Actual Loss: 0.1903\n",
      "Baseline Loss: 2.6652 | Actual Loss: 0.2452\n",
      "Baseline Loss: 2.6695 | Actual Loss: 0.2976\n",
      "Baseline Loss: 2.6383 | Actual Loss: 0.2696\n",
      "Baseline Loss: 2.6847 | Actual Loss: 0.2182\n",
      "Baseline Loss: 2.6830 | Actual Loss: 0.2911\n",
      "Baseline Loss: 2.6784 | Actual Loss: 0.2007\n",
      "Baseline Loss: 2.2605 | Actual Loss: 0.2093\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██▍       | 239/1000 [01:52<05:58,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6990 | Actual Loss: 0.2358\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2941\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2771\n",
      "Epoch 239/1000: Train Loss: 0.2047, Val Loss: 0.3289\n",
      "Baseline Loss: 2.6622 | Actual Loss: 0.1877\n",
      "Baseline Loss: 2.6976 | Actual Loss: 0.2766\n",
      "Baseline Loss: 2.6567 | Actual Loss: 0.1449\n",
      "Baseline Loss: 2.6631 | Actual Loss: 0.0851\n",
      "Baseline Loss: 2.6575 | Actual Loss: 0.1378\n",
      "Baseline Loss: 2.6705 | Actual Loss: 0.1530\n",
      "Baseline Loss: 2.6546 | Actual Loss: 0.2167\n",
      "Baseline Loss: 2.6913 | Actual Loss: 0.1034\n",
      "Baseline Loss: 2.6947 | Actual Loss: 0.1781\n",
      "Baseline Loss: 2.6969 | Actual Loss: 0.1538\n",
      "Baseline Loss: 2.6556 | Actual Loss: 0.2738\n",
      "Baseline Loss: 2.6557 | Actual Loss: 0.1511\n",
      "Baseline Loss: 2.6718 | Actual Loss: 0.1244\n",
      "Baseline Loss: 2.6748 | Actual Loss: 0.1756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██▍       | 240/1000 [01:53<05:58,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6933 | Actual Loss: 0.2564\n",
      "Baseline Loss: 2.2611 | Actual Loss: 0.2454\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5482\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3239\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2103\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3301\n",
      "Epoch 240/1000: Train Loss: 0.1790, Val Loss: 0.3531\n",
      "Baseline Loss: 2.7338 | Actual Loss: 0.2613\n",
      "Baseline Loss: 2.6993 | Actual Loss: 0.1589\n",
      "Baseline Loss: 2.7232 | Actual Loss: 0.1038\n",
      "Baseline Loss: 2.6693 | Actual Loss: 0.1793\n",
      "Baseline Loss: 2.6533 | Actual Loss: 0.0734\n",
      "Baseline Loss: 2.7069 | Actual Loss: 0.2098\n",
      "Baseline Loss: 2.6851 | Actual Loss: 0.2738\n",
      "Baseline Loss: 2.6796 | Actual Loss: 0.1634\n",
      "Baseline Loss: 2.6576 | Actual Loss: 0.1382\n",
      "Baseline Loss: 2.6901 | Actual Loss: 0.1850\n",
      "Baseline Loss: 2.6496 | Actual Loss: 0.1320\n",
      "Baseline Loss: 2.6891 | Actual Loss: 0.1295\n",
      "Baseline Loss: 2.6740 | Actual Loss: 0.1992\n",
      "Baseline Loss: 2.6714 | Actual Loss: 0.2288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██▍       | 241/1000 [01:53<05:41,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6636 | Actual Loss: 0.2986\n",
      "Baseline Loss: 2.2578 | Actual Loss: 0.0879\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4682\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3194\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2891\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2888\n",
      "Epoch 241/1000: Train Loss: 0.1764, Val Loss: 0.3414\n",
      "Baseline Loss: 2.6954 | Actual Loss: 0.2146\n",
      "Baseline Loss: 2.6716 | Actual Loss: 0.1541\n",
      "Baseline Loss: 2.6678 | Actual Loss: 0.0929\n",
      "Baseline Loss: 2.6513 | Actual Loss: 0.2206\n",
      "Baseline Loss: 2.6919 | Actual Loss: 0.2083\n",
      "Baseline Loss: 2.6715 | Actual Loss: 0.1755\n",
      "Baseline Loss: 2.6701 | Actual Loss: 0.1658\n",
      "Baseline Loss: 2.6860 | Actual Loss: 0.1267\n",
      "Baseline Loss: 2.6547 | Actual Loss: 0.1292\n",
      "Baseline Loss: 2.6621 | Actual Loss: 0.1640\n",
      "Baseline Loss: 2.6732 | Actual Loss: 0.2113\n",
      "Baseline Loss: 2.6547 | Actual Loss: 0.2569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██▍       | 242/1000 [01:54<05:55,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6574 | Actual Loss: 0.1838\n",
      "Baseline Loss: 2.6657 | Actual Loss: 0.1465\n",
      "Baseline Loss: 2.6724 | Actual Loss: 0.1990\n",
      "Baseline Loss: 2.3056 | Actual Loss: 0.1280\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.3977\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.2648\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2895\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3343\n",
      "Epoch 242/1000: Train Loss: 0.1736, Val Loss: 0.3216\n",
      "Baseline Loss: 2.6756 | Actual Loss: 0.2025\n",
      "Baseline Loss: 2.6614 | Actual Loss: 0.2583\n",
      "Baseline Loss: 2.6562 | Actual Loss: 0.2084\n",
      "Baseline Loss: 2.6823 | Actual Loss: 0.2168\n",
      "Baseline Loss: 2.6574 | Actual Loss: 0.2249\n",
      "Baseline Loss: 2.7067 | Actual Loss: 0.3029\n",
      "Baseline Loss: 2.6599 | Actual Loss: 0.1503\n",
      "Baseline Loss: 2.6814 | Actual Loss: 0.2121\n",
      "Baseline Loss: 2.6567 | Actual Loss: 0.1707\n",
      "Baseline Loss: 2.6956 | Actual Loss: 0.2735\n",
      "Baseline Loss: 2.6546 | Actual Loss: 0.1813\n",
      "Baseline Loss: 2.6531 | Actual Loss: 0.2371\n",
      "Baseline Loss: 2.6788 | Actual Loss: 0.1275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██▍       | 243/1000 [01:54<05:38,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6530 | Actual Loss: 0.1929\n",
      "Baseline Loss: 2.6662 | Actual Loss: 0.2002\n",
      "Baseline Loss: 2.2637 | Actual Loss: 0.0862\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4065\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3478\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2696\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2679\n",
      "Epoch 243/1000: Train Loss: 0.2029, Val Loss: 0.3229\n",
      "Baseline Loss: 2.6717 | Actual Loss: 0.3009\n",
      "Baseline Loss: 2.6707 | Actual Loss: 0.1069\n",
      "Baseline Loss: 2.6562 | Actual Loss: 0.2679\n",
      "Baseline Loss: 2.6834 | Actual Loss: 0.1354\n",
      "Baseline Loss: 2.6970 | Actual Loss: 0.2150\n",
      "Baseline Loss: 2.6805 | Actual Loss: 0.1715\n",
      "Baseline Loss: 2.6775 | Actual Loss: 0.2154\n",
      "Baseline Loss: 2.6429 | Actual Loss: 0.1355\n",
      "Baseline Loss: 2.6839 | Actual Loss: 0.1464\n",
      "Baseline Loss: 2.6995 | Actual Loss: 0.1523\n",
      "Baseline Loss: 2.6899 | Actual Loss: 0.1478\n",
      "Baseline Loss: 2.7175 | Actual Loss: 0.1917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██▍       | 244/1000 [01:55<05:50,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6367 | Actual Loss: 0.1573\n",
      "Baseline Loss: 2.6481 | Actual Loss: 0.1773\n",
      "Baseline Loss: 2.7063 | Actual Loss: 0.1502\n",
      "Baseline Loss: 2.2208 | Actual Loss: 0.1613\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4807\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3655\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3348\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2890\n",
      "Epoch 244/1000: Train Loss: 0.1770, Val Loss: 0.3675\n",
      "Baseline Loss: 2.6595 | Actual Loss: 0.1437\n",
      "Baseline Loss: 2.6843 | Actual Loss: 0.2565\n",
      "Baseline Loss: 2.6329 | Actual Loss: 0.2124\n",
      "Baseline Loss: 2.7488 | Actual Loss: 0.1065\n",
      "Baseline Loss: 2.6459 | Actual Loss: 0.1872\n",
      "Baseline Loss: 2.6601 | Actual Loss: 0.1356\n",
      "Baseline Loss: 2.6482 | Actual Loss: 0.2487\n",
      "Baseline Loss: 2.6523 | Actual Loss: 0.2457\n",
      "Baseline Loss: 2.6504 | Actual Loss: 0.1771\n",
      "Baseline Loss: 2.6689 | Actual Loss: 0.1456\n",
      "Baseline Loss: 2.6960 | Actual Loss: 0.2183\n",
      "Baseline Loss: 2.6372 | Actual Loss: 0.1960\n",
      "Baseline Loss: 2.6855 | Actual Loss: 0.1722\n",
      "Baseline Loss: 2.7133 | Actual Loss: 0.1888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██▍       | 245/1000 [01:55<05:56,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6818 | Actual Loss: 0.1959\n",
      "Baseline Loss: 2.2724 | Actual Loss: 0.0604\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4455\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3004\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2992\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3448\n",
      "Epoch 245/1000: Train Loss: 0.1807, Val Loss: 0.3475\n",
      "Baseline Loss: 2.6609 | Actual Loss: 0.1302\n",
      "Baseline Loss: 2.7121 | Actual Loss: 0.0909\n",
      "Baseline Loss: 2.6427 | Actual Loss: 0.2939\n",
      "Baseline Loss: 2.6832 | Actual Loss: 0.2016\n",
      "Baseline Loss: 2.6956 | Actual Loss: 0.1758\n",
      "Baseline Loss: 2.6464 | Actual Loss: 0.1838\n",
      "Baseline Loss: 2.7135 | Actual Loss: 0.1809\n",
      "Baseline Loss: 2.6450 | Actual Loss: 0.2279\n",
      "Baseline Loss: 2.6725 | Actual Loss: 0.1127\n",
      "Baseline Loss: 2.6612 | Actual Loss: 0.0924\n",
      "Baseline Loss: 2.6514 | Actual Loss: 0.2200\n",
      "Baseline Loss: 2.6579 | Actual Loss: 0.1411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▍       | 246/1000 [01:55<05:39,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6762 | Actual Loss: 0.1979\n",
      "Baseline Loss: 2.6668 | Actual Loss: 0.1689\n",
      "Baseline Loss: 2.6872 | Actual Loss: 0.1538\n",
      "Baseline Loss: 2.2493 | Actual Loss: 0.1318\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4445\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3198\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2157\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2484\n",
      "Epoch 246/1000: Train Loss: 0.1690, Val Loss: 0.3071\n",
      "Baseline Loss: 2.6652 | Actual Loss: 0.1234\n",
      "Baseline Loss: 2.7033 | Actual Loss: 0.1291\n",
      "Baseline Loss: 2.6928 | Actual Loss: 0.1238\n",
      "Baseline Loss: 2.6635 | Actual Loss: 0.1454\n",
      "Baseline Loss: 2.6470 | Actual Loss: 0.3641\n",
      "Baseline Loss: 2.6391 | Actual Loss: 0.1336\n",
      "Baseline Loss: 2.6765 | Actual Loss: 0.2208\n",
      "Baseline Loss: 2.6951 | Actual Loss: 0.1897\n",
      "Baseline Loss: 2.6750 | Actual Loss: 0.2086\n",
      "Baseline Loss: 2.6515 | Actual Loss: 0.2005\n",
      "Baseline Loss: 2.6823 | Actual Loss: 0.1480\n",
      "Baseline Loss: 2.6864 | Actual Loss: 0.1488\n",
      "Baseline Loss: 2.6731 | Actual Loss: 0.1908\n",
      "Baseline Loss: 2.6804 | Actual Loss: 0.2092\n",
      "Baseline Loss: 2.6698 | Actual Loss: 0.2914\n",
      "Baseline Loss: 2.2714 | Actual Loss: 0.1058\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▍       | 247/1000 [01:56<05:48,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6990 | Actual Loss: 0.3087\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2369\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3254\n",
      "Epoch 247/1000: Train Loss: 0.1833, Val Loss: 0.3563\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.0914\n",
      "Baseline Loss: 2.6870 | Actual Loss: 0.3260\n",
      "Baseline Loss: 2.6905 | Actual Loss: 0.3493\n",
      "Baseline Loss: 2.7001 | Actual Loss: 0.1737\n",
      "Baseline Loss: 2.6799 | Actual Loss: 0.3314\n",
      "Baseline Loss: 2.6580 | Actual Loss: 0.2043\n",
      "Baseline Loss: 2.6550 | Actual Loss: 0.3102\n",
      "Baseline Loss: 2.6713 | Actual Loss: 0.2111\n",
      "Baseline Loss: 2.6376 | Actual Loss: 0.1469\n",
      "Baseline Loss: 2.6310 | Actual Loss: 0.2091\n",
      "Baseline Loss: 2.6567 | Actual Loss: 0.1403\n",
      "Baseline Loss: 2.6877 | Actual Loss: 0.1617\n",
      "Baseline Loss: 2.7027 | Actual Loss: 0.0945\n",
      "Baseline Loss: 2.6763 | Actual Loss: 0.1118\n",
      "Baseline Loss: 2.6796 | Actual Loss: 0.1090\n",
      "Baseline Loss: 2.2727 | Actual Loss: 0.0797\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▍       | 248/1000 [01:56<05:53,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6990 | Actual Loss: 0.4359\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2658\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3951\n",
      "Epoch 248/1000: Train Loss: 0.1907, Val Loss: 0.3819\n",
      "Baseline Loss: 2.6628 | Actual Loss: 0.0868\n",
      "Baseline Loss: 2.6484 | Actual Loss: 0.1710\n",
      "Baseline Loss: 2.6972 | Actual Loss: 0.2088\n",
      "Baseline Loss: 2.6698 | Actual Loss: 0.1852\n",
      "Baseline Loss: 2.7280 | Actual Loss: 0.2714\n",
      "Baseline Loss: 2.6917 | Actual Loss: 0.2969\n",
      "Baseline Loss: 2.6254 | Actual Loss: 0.2734\n",
      "Baseline Loss: 2.6506 | Actual Loss: 0.1583\n",
      "Baseline Loss: 2.6382 | Actual Loss: 0.1836\n",
      "Baseline Loss: 2.7374 | Actual Loss: 0.2847\n",
      "Baseline Loss: 2.6780 | Actual Loss: 0.1504\n",
      "Baseline Loss: 2.6388 | Actual Loss: 0.2060\n",
      "Baseline Loss: 2.7070 | Actual Loss: 0.1846\n",
      "Baseline Loss: 2.6632 | Actual Loss: 0.1664\n",
      "Baseline Loss: 2.6688 | Actual Loss: 0.2265\n",
      "Baseline Loss: 2.2794 | Actual Loss: 0.1192\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4589\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▍       | 249/1000 [01:57<05:35,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6381 | Actual Loss: 0.2933\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2760\n",
      "Epoch 249/1000: Train Loss: 0.1983, Val Loss: 0.3392\n",
      "Baseline Loss: 2.6580 | Actual Loss: 0.2267\n",
      "Baseline Loss: 2.6383 | Actual Loss: 0.2263\n",
      "Baseline Loss: 2.6592 | Actual Loss: 0.1085\n",
      "Baseline Loss: 2.6614 | Actual Loss: 0.2350\n",
      "Baseline Loss: 2.6762 | Actual Loss: 0.1181\n",
      "Baseline Loss: 2.6569 | Actual Loss: 0.1380\n",
      "Baseline Loss: 2.7240 | Actual Loss: 0.2118\n",
      "Baseline Loss: 2.6541 | Actual Loss: 0.1364\n",
      "Baseline Loss: 2.6578 | Actual Loss: 0.1444\n",
      "Baseline Loss: 2.6714 | Actual Loss: 0.2170\n",
      "Baseline Loss: 2.6932 | Actual Loss: 0.1322\n",
      "Baseline Loss: 2.6763 | Actual Loss: 0.2204\n",
      "Baseline Loss: 2.6926 | Actual Loss: 0.2827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▌       | 250/1000 [01:57<05:54,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6985 | Actual Loss: 0.2076\n",
      "Baseline Loss: 2.6793 | Actual Loss: 0.4307\n",
      "Baseline Loss: 2.2751 | Actual Loss: 0.1746\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4923\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3101\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2976\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2883\n",
      "Epoch 250/1000: Train Loss: 0.2007, Val Loss: 0.3471\n",
      "Baseline Loss: 2.6866 | Actual Loss: 0.2029\n",
      "Baseline Loss: 2.6438 | Actual Loss: 0.2068\n",
      "Baseline Loss: 2.7039 | Actual Loss: 0.3277\n",
      "Baseline Loss: 2.7043 | Actual Loss: 0.1487\n",
      "Baseline Loss: 2.6728 | Actual Loss: 0.4673\n",
      "Baseline Loss: 2.6828 | Actual Loss: 0.1931\n",
      "Baseline Loss: 2.6547 | Actual Loss: 0.1369\n",
      "Baseline Loss: 2.6455 | Actual Loss: 0.1643\n",
      "Baseline Loss: 2.6948 | Actual Loss: 0.1114\n",
      "Baseline Loss: 2.6460 | Actual Loss: 0.1896\n",
      "Baseline Loss: 2.6888 | Actual Loss: 0.2265\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.1351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▌       | 251/1000 [01:58<05:54,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6669 | Actual Loss: 0.1816\n",
      "Baseline Loss: 2.6699 | Actual Loss: 0.1440\n",
      "Baseline Loss: 2.7035 | Actual Loss: 0.1887\n",
      "Baseline Loss: 2.2850 | Actual Loss: 0.0962\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4851\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.2809\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3091\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2624\n",
      "Epoch 251/1000: Train Loss: 0.1951, Val Loss: 0.3344\n",
      "Baseline Loss: 2.7071 | Actual Loss: 0.1531\n",
      "Baseline Loss: 2.7031 | Actual Loss: 0.2132\n",
      "Baseline Loss: 2.6571 | Actual Loss: 0.2520\n",
      "Baseline Loss: 2.6378 | Actual Loss: 0.1911\n",
      "Baseline Loss: 2.6460 | Actual Loss: 0.1656\n",
      "Baseline Loss: 2.6487 | Actual Loss: 0.1823\n",
      "Baseline Loss: 2.6629 | Actual Loss: 0.2152\n",
      "Baseline Loss: 2.6730 | Actual Loss: 0.1783\n",
      "Baseline Loss: 2.7145 | Actual Loss: 0.3055\n",
      "Baseline Loss: 2.6331 | Actual Loss: 0.1425\n",
      "Baseline Loss: 2.6611 | Actual Loss: 0.1823\n",
      "Baseline Loss: 2.6512 | Actual Loss: 0.2343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▌       | 252/1000 [01:58<05:38,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6869 | Actual Loss: 0.1758\n",
      "Baseline Loss: 2.6925 | Actual Loss: 0.2363\n",
      "Baseline Loss: 2.7421 | Actual Loss: 0.1085\n",
      "Baseline Loss: 2.2924 | Actual Loss: 0.1741\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5694\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3211\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2793\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2346\n",
      "Epoch 252/1000: Train Loss: 0.1944, Val Loss: 0.3511\n",
      "Baseline Loss: 2.7142 | Actual Loss: 0.2767\n",
      "Baseline Loss: 2.6309 | Actual Loss: 0.1378\n",
      "Baseline Loss: 2.6871 | Actual Loss: 0.2513\n",
      "Baseline Loss: 2.6529 | Actual Loss: 0.1324\n",
      "Baseline Loss: 2.6976 | Actual Loss: 0.2278\n",
      "Baseline Loss: 2.6604 | Actual Loss: 0.1717\n",
      "Baseline Loss: 2.6564 | Actual Loss: 0.1811\n",
      "Baseline Loss: 2.6672 | Actual Loss: 0.1224\n",
      "Baseline Loss: 2.6503 | Actual Loss: 0.2046\n",
      "Baseline Loss: 2.7277 | Actual Loss: 0.2516\n",
      "Baseline Loss: 2.6671 | Actual Loss: 0.2860\n",
      "Baseline Loss: 2.6595 | Actual Loss: 0.3090\n",
      "Baseline Loss: 2.6683 | Actual Loss: 0.1827\n",
      "Baseline Loss: 2.7246 | Actual Loss: 0.3119\n",
      "Baseline Loss: 2.6503 | Actual Loss: 0.0979\n",
      "Baseline Loss: 2.2372 | Actual Loss: 0.1428\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4498\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3135\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▌       | 253/1000 [01:59<05:53,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6194 | Actual Loss: 0.2605\n",
      "Epoch 253/1000: Train Loss: 0.2055, Val Loss: 0.3131\n",
      "Baseline Loss: 2.6723 | Actual Loss: 0.1289\n",
      "Baseline Loss: 2.6592 | Actual Loss: 0.1398\n",
      "Baseline Loss: 2.6798 | Actual Loss: 0.1842\n",
      "Baseline Loss: 2.6448 | Actual Loss: 0.1849\n",
      "Baseline Loss: 2.6523 | Actual Loss: 0.1661\n",
      "Baseline Loss: 2.6659 | Actual Loss: 0.3515\n",
      "Baseline Loss: 2.6672 | Actual Loss: 0.1851\n",
      "Baseline Loss: 2.6886 | Actual Loss: 0.1783\n",
      "Baseline Loss: 2.6690 | Actual Loss: 0.2826\n",
      "Baseline Loss: 2.6973 | Actual Loss: 0.1538\n",
      "Baseline Loss: 2.6638 | Actual Loss: 0.1910\n",
      "Baseline Loss: 2.6176 | Actual Loss: 0.1583\n",
      "Baseline Loss: 2.7032 | Actual Loss: 0.1723\n",
      "Baseline Loss: 2.6856 | Actual Loss: 0.1675\n",
      "Baseline Loss: 2.6754 | Actual Loss: 0.1863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▌       | 254/1000 [01:59<05:52,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.3273 | Actual Loss: 0.1254\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.3810\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3458\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3320\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3123\n",
      "Epoch 254/1000: Train Loss: 0.1847, Val Loss: 0.3428\n",
      "Baseline Loss: 2.6574 | Actual Loss: 0.1693\n",
      "Baseline Loss: 2.6408 | Actual Loss: 0.1829\n",
      "Baseline Loss: 2.6652 | Actual Loss: 0.1025\n",
      "Baseline Loss: 2.7168 | Actual Loss: 0.2297\n",
      "Baseline Loss: 2.6811 | Actual Loss: 0.2491\n",
      "Baseline Loss: 2.6423 | Actual Loss: 0.0898\n",
      "Baseline Loss: 2.6693 | Actual Loss: 0.1731\n",
      "Baseline Loss: 2.7394 | Actual Loss: 0.3251\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.1525\n",
      "Baseline Loss: 2.6653 | Actual Loss: 0.0830\n",
      "Baseline Loss: 2.6742 | Actual Loss: 0.1280\n",
      "Baseline Loss: 2.6906 | Actual Loss: 0.1831\n",
      "Baseline Loss: 2.6667 | Actual Loss: 0.1704\n",
      "Baseline Loss: 2.6414 | Actual Loss: 0.2965\n",
      "Baseline Loss: 2.6163 | Actual Loss: 0.1239\n",
      "Baseline Loss: 2.2602 | Actual Loss: 0.0961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▌       | 255/1000 [02:00<05:35,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6857 | Actual Loss: 0.4310\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.2855\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3323\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3260\n",
      "Epoch 255/1000: Train Loss: 0.1722, Val Loss: 0.3437\n",
      "Baseline Loss: 2.7024 | Actual Loss: 0.1802\n",
      "Baseline Loss: 2.6910 | Actual Loss: 0.5152\n",
      "Baseline Loss: 2.6558 | Actual Loss: 0.1534\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.1689\n",
      "Baseline Loss: 2.6601 | Actual Loss: 0.1626\n",
      "Baseline Loss: 2.6806 | Actual Loss: 0.2773\n",
      "Baseline Loss: 2.6709 | Actual Loss: 0.1725\n",
      "Baseline Loss: 2.7013 | Actual Loss: 0.2619\n",
      "Baseline Loss: 2.6580 | Actual Loss: 0.1382\n",
      "Baseline Loss: 2.6980 | Actual Loss: 0.2393\n",
      "Baseline Loss: 2.6581 | Actual Loss: 0.1265\n",
      "Baseline Loss: 2.7262 | Actual Loss: 0.1215\n",
      "Baseline Loss: 2.6817 | Actual Loss: 0.3266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▌       | 256/1000 [02:00<05:48,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6688 | Actual Loss: 0.1615\n",
      "Baseline Loss: 2.6553 | Actual Loss: 0.2890\n",
      "Baseline Loss: 2.2868 | Actual Loss: 0.5721\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4939\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3237\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2489\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3026\n",
      "Epoch 256/1000: Train Loss: 0.2417, Val Loss: 0.3423\n",
      "Baseline Loss: 2.7341 | Actual Loss: 0.1738\n",
      "Baseline Loss: 2.6816 | Actual Loss: 0.1533\n",
      "Baseline Loss: 2.6689 | Actual Loss: 0.1730\n",
      "Baseline Loss: 2.6520 | Actual Loss: 0.1556\n",
      "Baseline Loss: 2.6387 | Actual Loss: 0.2315\n",
      "Baseline Loss: 2.6418 | Actual Loss: 0.1875\n",
      "Baseline Loss: 2.6782 | Actual Loss: 0.2631\n",
      "Baseline Loss: 2.6968 | Actual Loss: 0.1520\n",
      "Baseline Loss: 2.6625 | Actual Loss: 0.2294\n",
      "Baseline Loss: 2.7058 | Actual Loss: 0.1531\n",
      "Baseline Loss: 2.6723 | Actual Loss: 0.2904\n",
      "Baseline Loss: 2.6575 | Actual Loss: 0.0971\n",
      "Baseline Loss: 2.7115 | Actual Loss: 0.1649\n",
      "Baseline Loss: 2.6733 | Actual Loss: 0.1391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▌       | 257/1000 [02:01<05:50,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6688 | Actual Loss: 0.1688\n",
      "Baseline Loss: 2.3068 | Actual Loss: 1.4452\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4585\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3290\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3172\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3157\n",
      "Epoch 257/1000: Train Loss: 0.2611, Val Loss: 0.3551\n",
      "Baseline Loss: 2.6562 | Actual Loss: 0.2195\n",
      "Baseline Loss: 2.6997 | Actual Loss: 0.3050\n",
      "Baseline Loss: 2.6523 | Actual Loss: 0.1814\n",
      "Baseline Loss: 2.6614 | Actual Loss: 0.1352\n",
      "Baseline Loss: 2.6631 | Actual Loss: 0.1874\n",
      "Baseline Loss: 2.6824 | Actual Loss: 0.1824\n",
      "Baseline Loss: 2.6797 | Actual Loss: 0.1787\n",
      "Baseline Loss: 2.7183 | Actual Loss: 0.1524\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.1524\n",
      "Baseline Loss: 2.6697 | Actual Loss: 0.2269\n",
      "Baseline Loss: 2.7109 | Actual Loss: 0.1468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▌       | 258/1000 [02:01<05:38,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6802 | Actual Loss: 0.1207\n",
      "Baseline Loss: 2.6630 | Actual Loss: 0.1727\n",
      "Baseline Loss: 2.6442 | Actual Loss: 0.2161\n",
      "Baseline Loss: 2.6487 | Actual Loss: 0.2150\n",
      "Baseline Loss: 2.3376 | Actual Loss: 0.0949\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4226\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3055\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2668\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2608\n",
      "Epoch 258/1000: Train Loss: 0.1805, Val Loss: 0.3139\n",
      "Baseline Loss: 2.6476 | Actual Loss: 0.1202\n",
      "Baseline Loss: 2.6571 | Actual Loss: 0.2236\n",
      "Baseline Loss: 2.6530 | Actual Loss: 0.1907\n",
      "Baseline Loss: 2.7269 | Actual Loss: 0.1686\n",
      "Baseline Loss: 2.6935 | Actual Loss: 0.2229\n",
      "Baseline Loss: 2.6885 | Actual Loss: 0.1394\n",
      "Baseline Loss: 2.7034 | Actual Loss: 0.2268\n",
      "Baseline Loss: 2.6736 | Actual Loss: 0.1767\n",
      "Baseline Loss: 2.7131 | Actual Loss: 0.1994\n",
      "Baseline Loss: 2.6546 | Actual Loss: 0.2586\n",
      "Baseline Loss: 2.6634 | Actual Loss: 0.1441\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.2253\n",
      "Baseline Loss: 2.6632 | Actual Loss: 0.1064\n",
      "Baseline Loss: 2.6673 | Actual Loss: 0.1838\n",
      "Baseline Loss: 2.6659 | Actual Loss: 0.1170\n",
      "Baseline Loss: 2.2289 | Actual Loss: 0.1284\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4724\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.2750\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▌       | 259/1000 [02:02<05:47,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6194 | Actual Loss: 0.3188\n",
      "Epoch 259/1000: Train Loss: 0.1770, Val Loss: 0.3484\n",
      "Baseline Loss: 2.6517 | Actual Loss: 0.2154\n",
      "Baseline Loss: 2.7209 | Actual Loss: 0.3284\n",
      "Baseline Loss: 2.6479 | Actual Loss: 0.1289\n",
      "Baseline Loss: 2.7064 | Actual Loss: 0.1597\n",
      "Baseline Loss: 2.6611 | Actual Loss: 0.2102\n",
      "Baseline Loss: 2.7200 | Actual Loss: 0.2866\n",
      "Baseline Loss: 2.7168 | Actual Loss: 0.2284\n",
      "Baseline Loss: 2.7103 | Actual Loss: 0.1024\n",
      "Baseline Loss: 2.6497 | Actual Loss: 0.2018\n",
      "Baseline Loss: 2.6557 | Actual Loss: 0.1621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▌       | 260/1000 [02:02<05:32,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6789 | Actual Loss: 0.1297\n",
      "Baseline Loss: 2.6723 | Actual Loss: 0.1388\n",
      "Baseline Loss: 2.6825 | Actual Loss: 0.1468\n",
      "Baseline Loss: 2.6533 | Actual Loss: 0.1612\n",
      "Baseline Loss: 2.6299 | Actual Loss: 0.3433\n",
      "Baseline Loss: 2.2624 | Actual Loss: 0.0858\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5418\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.2530\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2463\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3105\n",
      "Epoch 260/1000: Train Loss: 0.1893, Val Loss: 0.3379\n",
      "Baseline Loss: 2.6832 | Actual Loss: 0.1730\n",
      "Baseline Loss: 2.7198 | Actual Loss: 0.1751\n",
      "Baseline Loss: 2.6695 | Actual Loss: 0.0925\n",
      "Baseline Loss: 2.6585 | Actual Loss: 0.1026\n",
      "Baseline Loss: 2.6834 | Actual Loss: 0.2241\n",
      "Baseline Loss: 2.6791 | Actual Loss: 0.2827\n",
      "Baseline Loss: 2.6451 | Actual Loss: 0.1411\n",
      "Baseline Loss: 2.6765 | Actual Loss: 0.2644\n",
      "Baseline Loss: 2.6491 | Actual Loss: 0.6249\n",
      "Baseline Loss: 2.6915 | Actual Loss: 0.1792\n",
      "Baseline Loss: 2.7022 | Actual Loss: 0.1979\n",
      "Baseline Loss: 2.6479 | Actual Loss: 0.2026\n",
      "Baseline Loss: 2.6481 | Actual Loss: 0.1940\n",
      "Baseline Loss: 2.6675 | Actual Loss: 0.1410\n",
      "Baseline Loss: 2.6659 | Actual Loss: 0.1720\n",
      "Baseline Loss: 2.2724 | Actual Loss: 0.1602\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▌       | 261/1000 [02:02<05:41,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6990 | Actual Loss: 0.3917\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3389\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3064\n",
      "Epoch 261/1000: Train Loss: 0.2080, Val Loss: 0.3732\n",
      "Baseline Loss: 2.6985 | Actual Loss: 0.1920\n",
      "Baseline Loss: 2.6924 | Actual Loss: 0.1864\n",
      "Baseline Loss: 2.6708 | Actual Loss: 0.2571\n",
      "Baseline Loss: 2.6872 | Actual Loss: 0.1712\n",
      "Baseline Loss: 2.6692 | Actual Loss: 0.1268\n",
      "Baseline Loss: 2.6800 | Actual Loss: 0.3007\n",
      "Baseline Loss: 2.6811 | Actual Loss: 0.1736\n",
      "Baseline Loss: 2.7288 | Actual Loss: 0.2431\n",
      "Baseline Loss: 2.6185 | Actual Loss: 0.1906\n",
      "Baseline Loss: 2.6544 | Actual Loss: 0.1387\n",
      "Baseline Loss: 2.6689 | Actual Loss: 0.1761\n",
      "Baseline Loss: 2.7081 | Actual Loss: 0.1686\n",
      "Baseline Loss: 2.6408 | Actual Loss: 0.1855\n",
      "Baseline Loss: 2.6778 | Actual Loss: 0.1638\n",
      "Baseline Loss: 2.6988 | Actual Loss: 0.1339\n",
      "Baseline Loss: 2.2713 | Actual Loss: 0.2139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▌       | 262/1000 [02:03<05:35,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6857 | Actual Loss: 0.4701\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3136\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2366\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2750\n",
      "Epoch 262/1000: Train Loss: 0.1889, Val Loss: 0.3238\n",
      "Baseline Loss: 2.6619 | Actual Loss: 0.1590\n",
      "Baseline Loss: 2.7116 | Actual Loss: 0.1936\n",
      "Baseline Loss: 2.6670 | Actual Loss: 0.0707\n",
      "Baseline Loss: 2.6605 | Actual Loss: 0.1492\n",
      "Baseline Loss: 2.6824 | Actual Loss: 0.1356\n",
      "Baseline Loss: 2.6826 | Actual Loss: 0.1836\n",
      "Baseline Loss: 2.6784 | Actual Loss: 0.3099\n",
      "Baseline Loss: 2.7311 | Actual Loss: 0.1975\n",
      "Baseline Loss: 2.6549 | Actual Loss: 0.2668\n",
      "Baseline Loss: 2.6855 | Actual Loss: 0.1963\n",
      "Baseline Loss: 2.6560 | Actual Loss: 0.1897\n",
      "Baseline Loss: 2.6738 | Actual Loss: 0.3217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▋       | 263/1000 [02:03<05:51,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6703 | Actual Loss: 0.3736\n",
      "Baseline Loss: 2.6394 | Actual Loss: 0.1957\n",
      "Baseline Loss: 2.6475 | Actual Loss: 0.1699\n",
      "Baseline Loss: 2.2617 | Actual Loss: 0.1731\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4518\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3192\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3248\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2116\n",
      "Epoch 263/1000: Train Loss: 0.2054, Val Loss: 0.3268\n",
      "Baseline Loss: 2.6491 | Actual Loss: 0.2091\n",
      "Baseline Loss: 2.6576 | Actual Loss: 0.2440\n",
      "Baseline Loss: 2.6740 | Actual Loss: 0.1525\n",
      "Baseline Loss: 2.6639 | Actual Loss: 0.2292\n",
      "Baseline Loss: 2.6939 | Actual Loss: 0.2482\n",
      "Baseline Loss: 2.6868 | Actual Loss: 0.2409\n",
      "Baseline Loss: 2.6529 | Actual Loss: 0.2460\n",
      "Baseline Loss: 2.6937 | Actual Loss: 0.1464\n",
      "Baseline Loss: 2.6703 | Actual Loss: 0.1821\n",
      "Baseline Loss: 2.6680 | Actual Loss: 0.2494\n",
      "Baseline Loss: 2.6737 | Actual Loss: 0.1588\n",
      "Baseline Loss: 2.6774 | Actual Loss: 0.1661\n",
      "Baseline Loss: 2.6896 | Actual Loss: 0.1773\n",
      "Baseline Loss: 2.6980 | Actual Loss: 0.0877\n",
      "Baseline Loss: 2.6796 | Actual Loss: 0.1541\n",
      "Baseline Loss: 2.2613 | Actual Loss: 0.0649\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5206\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▋       | 264/1000 [02:04<05:58,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6381 | Actual Loss: 0.1929\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4192\n",
      "Epoch 264/1000: Train Loss: 0.1848, Val Loss: 0.3587\n",
      "Baseline Loss: 2.6563 | Actual Loss: 0.1715\n",
      "Baseline Loss: 2.7051 | Actual Loss: 0.0942\n",
      "Baseline Loss: 2.6847 | Actual Loss: 0.1774\n",
      "Baseline Loss: 2.6521 | Actual Loss: 0.1394\n",
      "Baseline Loss: 2.6619 | Actual Loss: 0.1466\n",
      "Baseline Loss: 2.6787 | Actual Loss: 0.1891\n",
      "Baseline Loss: 2.6851 | Actual Loss: 0.3089\n",
      "Baseline Loss: 2.6785 | Actual Loss: 0.2244\n",
      "Baseline Loss: 2.6985 | Actual Loss: 0.2537\n",
      "Baseline Loss: 2.6472 | Actual Loss: 0.1915\n",
      "Baseline Loss: 2.6784 | Actual Loss: 0.1379\n",
      "Baseline Loss: 2.6635 | Actual Loss: 0.2966\n",
      "Baseline Loss: 2.7211 | Actual Loss: 0.2191\n",
      "Baseline Loss: 2.6514 | Actual Loss: 0.2024\n",
      "Baseline Loss: 2.6829 | Actual Loss: 0.1563\n",
      "Baseline Loss: 2.1937 | Actual Loss: 0.2876\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▋       | 265/1000 [02:04<05:46,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6990 | Actual Loss: 0.3466\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2428\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3314\n",
      "Epoch 265/1000: Train Loss: 0.1998, Val Loss: 0.3334\n",
      "Baseline Loss: 2.6879 | Actual Loss: 0.1417\n",
      "Baseline Loss: 2.6749 | Actual Loss: 0.1593\n",
      "Baseline Loss: 2.6797 | Actual Loss: 0.1400\n",
      "Baseline Loss: 2.6639 | Actual Loss: 0.2185\n",
      "Baseline Loss: 2.6918 | Actual Loss: 0.1100\n",
      "Baseline Loss: 2.7028 | Actual Loss: 0.1744\n",
      "Baseline Loss: 2.7018 | Actual Loss: 0.0964\n",
      "Baseline Loss: 2.6663 | Actual Loss: 0.1585\n",
      "Baseline Loss: 2.6615 | Actual Loss: 0.2526\n",
      "Baseline Loss: 2.6614 | Actual Loss: 0.1868\n",
      "Baseline Loss: 2.6305 | Actual Loss: 0.1040\n",
      "Baseline Loss: 2.6819 | Actual Loss: 0.1569\n",
      "Baseline Loss: 2.6318 | Actual Loss: 0.1163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  27%|██▋       | 266/1000 [02:05<05:56,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6552 | Actual Loss: 0.2330\n",
      "Baseline Loss: 2.6813 | Actual Loss: 0.2294\n",
      "Baseline Loss: 2.2464 | Actual Loss: 0.0844\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4540\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.2563\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2638\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3034\n",
      "Epoch 266/1000: Train Loss: 0.1601, Val Loss: 0.3193\n",
      "Baseline Loss: 2.6848 | Actual Loss: 0.1317\n",
      "Baseline Loss: 2.6534 | Actual Loss: 0.2703\n",
      "Baseline Loss: 2.6808 | Actual Loss: 0.3499\n",
      "Baseline Loss: 2.6578 | Actual Loss: 0.1963\n",
      "Baseline Loss: 2.6444 | Actual Loss: 0.1637\n",
      "Baseline Loss: 2.7008 | Actual Loss: 0.1869\n",
      "Baseline Loss: 2.6590 | Actual Loss: 0.2626\n",
      "Baseline Loss: 2.6529 | Actual Loss: 0.1262\n",
      "Baseline Loss: 2.7037 | Actual Loss: 0.2361\n",
      "Baseline Loss: 2.6734 | Actual Loss: 0.3746\n",
      "Baseline Loss: 2.6760 | Actual Loss: 0.2544\n",
      "Baseline Loss: 2.6968 | Actual Loss: 0.1517\n",
      "Baseline Loss: 2.7019 | Actual Loss: 0.1159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  27%|██▋       | 267/1000 [02:05<06:03,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6779 | Actual Loss: 0.1391\n",
      "Baseline Loss: 2.6824 | Actual Loss: 0.1988\n",
      "Baseline Loss: 2.2780 | Actual Loss: 0.1553\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4286\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3296\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2831\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3055\n",
      "Epoch 267/1000: Train Loss: 0.2071, Val Loss: 0.3367\n",
      "Baseline Loss: 2.6538 | Actual Loss: 0.1730\n",
      "Baseline Loss: 2.6414 | Actual Loss: 0.2698\n",
      "Baseline Loss: 2.6462 | Actual Loss: 0.2966\n",
      "Baseline Loss: 2.7151 | Actual Loss: 0.1328\n",
      "Baseline Loss: 2.6728 | Actual Loss: 0.3696\n",
      "Baseline Loss: 2.6747 | Actual Loss: 0.3231\n",
      "Baseline Loss: 2.6996 | Actual Loss: 0.2612\n",
      "Baseline Loss: 2.6565 | Actual Loss: 0.1479\n",
      "Baseline Loss: 2.7094 | Actual Loss: 0.1880\n",
      "Baseline Loss: 2.6462 | Actual Loss: 0.1176\n",
      "Baseline Loss: 2.6757 | Actual Loss: 0.2104\n",
      "Baseline Loss: 2.7150 | Actual Loss: 0.1456\n",
      "Baseline Loss: 2.6543 | Actual Loss: 0.1538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  27%|██▋       | 268/1000 [02:06<06:07,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7076 | Actual Loss: 0.1516\n",
      "Baseline Loss: 2.6514 | Actual Loss: 0.2061\n",
      "Baseline Loss: 2.2638 | Actual Loss: 0.0961\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4191\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3393\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2787\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.4085\n",
      "Epoch 268/1000: Train Loss: 0.2027, Val Loss: 0.3614\n",
      "Baseline Loss: 2.6829 | Actual Loss: 0.2568\n",
      "Baseline Loss: 2.6752 | Actual Loss: 0.1633\n",
      "Baseline Loss: 2.6730 | Actual Loss: 0.2065\n",
      "Baseline Loss: 2.6450 | Actual Loss: 0.2150\n",
      "Baseline Loss: 2.6869 | Actual Loss: 0.2297\n",
      "Baseline Loss: 2.6565 | Actual Loss: 0.1396\n",
      "Baseline Loss: 2.6939 | Actual Loss: 0.3404\n",
      "Baseline Loss: 2.6862 | Actual Loss: 0.1705\n",
      "Baseline Loss: 2.6471 | Actual Loss: 0.0899\n",
      "Baseline Loss: 2.6701 | Actual Loss: 0.1170\n",
      "Baseline Loss: 2.7228 | Actual Loss: 0.2089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  27%|██▋       | 269/1000 [02:06<05:48,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6706 | Actual Loss: 0.1841\n",
      "Baseline Loss: 2.6833 | Actual Loss: 0.1730\n",
      "Baseline Loss: 2.6966 | Actual Loss: 0.1246\n",
      "Baseline Loss: 2.6659 | Actual Loss: 0.2216\n",
      "Baseline Loss: 2.2687 | Actual Loss: 0.0804\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4393\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.2975\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3157\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2470\n",
      "Epoch 269/1000: Train Loss: 0.1826, Val Loss: 0.3249\n",
      "Baseline Loss: 2.7162 | Actual Loss: 0.2858\n",
      "Baseline Loss: 2.6740 | Actual Loss: 0.2018\n",
      "Baseline Loss: 2.6717 | Actual Loss: 0.1497\n",
      "Baseline Loss: 2.6722 | Actual Loss: 0.0933\n",
      "Baseline Loss: 2.6741 | Actual Loss: 0.2892\n",
      "Baseline Loss: 2.6604 | Actual Loss: 0.1962\n",
      "Baseline Loss: 2.6426 | Actual Loss: 0.2525\n",
      "Baseline Loss: 2.6974 | Actual Loss: 0.2464\n",
      "Baseline Loss: 2.7050 | Actual Loss: 0.1603\n",
      "Baseline Loss: 2.6809 | Actual Loss: 0.1621\n",
      "Baseline Loss: 2.6793 | Actual Loss: 0.1594\n",
      "Baseline Loss: 2.6784 | Actual Loss: 0.3269\n",
      "Baseline Loss: 2.6515 | Actual Loss: 0.1741\n",
      "Baseline Loss: 2.6485 | Actual Loss: 0.3195\n",
      "Baseline Loss: 2.7198 | Actual Loss: 0.1310\n",
      "Baseline Loss: 2.2261 | Actual Loss: 0.0838\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4500\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  27%|██▋       | 270/1000 [02:07<05:49,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6381 | Actual Loss: 0.2617\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3225\n",
      "Epoch 270/1000: Train Loss: 0.2020, Val Loss: 0.3551\n",
      "Baseline Loss: 2.6639 | Actual Loss: 0.1558\n",
      "Baseline Loss: 2.6661 | Actual Loss: 0.1349\n",
      "Baseline Loss: 2.6750 | Actual Loss: 0.1850\n",
      "Baseline Loss: 2.6631 | Actual Loss: 0.1353\n",
      "Baseline Loss: 2.6498 | Actual Loss: 0.2607\n",
      "Baseline Loss: 2.6725 | Actual Loss: 0.1067\n",
      "Baseline Loss: 2.6958 | Actual Loss: 0.1767\n",
      "Baseline Loss: 2.6460 | Actual Loss: 0.1854\n",
      "Baseline Loss: 2.6411 | Actual Loss: 0.1525\n",
      "Baseline Loss: 2.7095 | Actual Loss: 0.1463\n",
      "Baseline Loss: 2.6687 | Actual Loss: 0.1500\n",
      "Baseline Loss: 2.6564 | Actual Loss: 0.2214\n",
      "Baseline Loss: 2.7000 | Actual Loss: 0.1417\n",
      "Baseline Loss: 2.7000 | Actual Loss: 0.2125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  27%|██▋       | 271/1000 [02:07<05:53,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6526 | Actual Loss: 0.1848\n",
      "Baseline Loss: 2.2666 | Actual Loss: 0.1867\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5743\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.2761\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3174\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2675\n",
      "Epoch 271/1000: Train Loss: 0.1710, Val Loss: 0.3588\n",
      "Baseline Loss: 2.6688 | Actual Loss: 0.1537\n",
      "Baseline Loss: 2.7052 | Actual Loss: 0.2484\n",
      "Baseline Loss: 2.6706 | Actual Loss: 0.1981\n",
      "Baseline Loss: 2.6546 | Actual Loss: 0.1377\n",
      "Baseline Loss: 2.6674 | Actual Loss: 0.1471\n",
      "Baseline Loss: 2.6762 | Actual Loss: 0.1859\n",
      "Baseline Loss: 2.6484 | Actual Loss: 0.5813\n",
      "Baseline Loss: 2.6771 | Actual Loss: 0.1408\n",
      "Baseline Loss: 2.6528 | Actual Loss: 0.1586\n",
      "Baseline Loss: 2.6899 | Actual Loss: 0.1358\n",
      "Baseline Loss: 2.6540 | Actual Loss: 0.1941\n",
      "Baseline Loss: 2.6754 | Actual Loss: 0.0988\n",
      "Baseline Loss: 2.6935 | Actual Loss: 0.2058\n",
      "Baseline Loss: 2.6914 | Actual Loss: 0.2119\n",
      "Baseline Loss: 2.6449 | Actual Loss: 0.0716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  27%|██▋       | 272/1000 [02:08<05:36,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2623 | Actual Loss: 0.3208\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.5078\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3174\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3709\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2653\n",
      "Epoch 272/1000: Train Loss: 0.1994, Val Loss: 0.3654\n",
      "Baseline Loss: 2.7229 | Actual Loss: 0.1971\n",
      "Baseline Loss: 2.6986 | Actual Loss: 0.1226\n",
      "Baseline Loss: 2.6608 | Actual Loss: 0.1288\n",
      "Baseline Loss: 2.6555 | Actual Loss: 0.1506\n",
      "Baseline Loss: 2.6813 | Actual Loss: 0.2686\n",
      "Baseline Loss: 2.6623 | Actual Loss: 0.1459\n",
      "Baseline Loss: 2.7119 | Actual Loss: 0.1761\n",
      "Baseline Loss: 2.6694 | Actual Loss: 0.1265\n",
      "Baseline Loss: 2.6765 | Actual Loss: 0.1869\n",
      "Baseline Loss: 2.6408 | Actual Loss: 0.2558\n",
      "Baseline Loss: 2.6705 | Actual Loss: 0.1279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  27%|██▋       | 273/1000 [02:08<05:48,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6868 | Actual Loss: 0.2606\n",
      "Baseline Loss: 2.6673 | Actual Loss: 0.2344\n",
      "Baseline Loss: 2.6766 | Actual Loss: 0.2013\n",
      "Baseline Loss: 2.6433 | Actual Loss: 0.1830\n",
      "Baseline Loss: 2.2126 | Actual Loss: 0.0659\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4025\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3987\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2885\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.3938\n",
      "Epoch 273/1000: Train Loss: 0.1770, Val Loss: 0.3709\n",
      "Baseline Loss: 2.6977 | Actual Loss: 0.1809\n",
      "Baseline Loss: 2.6843 | Actual Loss: 0.2395\n",
      "Baseline Loss: 2.6599 | Actual Loss: 0.1254\n",
      "Baseline Loss: 2.7116 | Actual Loss: 0.1638\n",
      "Baseline Loss: 2.6897 | Actual Loss: 0.1846\n",
      "Baseline Loss: 2.7140 | Actual Loss: 0.2676\n",
      "Baseline Loss: 2.6418 | Actual Loss: 0.1062\n",
      "Baseline Loss: 2.6560 | Actual Loss: 0.1352\n",
      "Baseline Loss: 2.6866 | Actual Loss: 0.1000\n",
      "Baseline Loss: 2.7355 | Actual Loss: 0.2378\n",
      "Baseline Loss: 2.6711 | Actual Loss: 0.1164\n",
      "Baseline Loss: 2.6666 | Actual Loss: 0.1873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  27%|██▋       | 273/1000 [02:09<05:44,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6555 | Actual Loss: 0.3103\n",
      "Baseline Loss: 2.6595 | Actual Loss: 0.1902\n",
      "Baseline Loss: 2.6486 | Actual Loss: 0.1473\n",
      "Baseline Loss: 2.3068 | Actual Loss: 0.1518\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4933\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.3189\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3149\n",
      "Baseline Loss: 2.6194 | Actual Loss: 0.2614\n",
      "Epoch 274/1000: Train Loss: 0.1778, Val Loss: 0.3471\n",
      "\n",
      "Early stopping at epoch 274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.30008406192064285"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devices = [\"cuda\" if torch.cuda.is_available() else \"cpu\"]\n",
    "model5 = GNNModelWithNewLoss(\n",
    "        num_node_features=data_list[0].x.shape[1],\n",
    "        num_edge_features=data_list[0].edge_attr.shape[1],\n",
    "        num_global_features=0,\n",
    "        cov_num= 6,\n",
    "        hidden_dim=512,\n",
    "        dropout_rate=0.1,\n",
    "        property_index= 1,\n",
    "        save_path= 'premodels_new_og/6/1' \n",
    "    ).to(devices[0])\n",
    "\n",
    "model5.train_model(\n",
    "    data_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "971916e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training will be saved to: premodels_new_og/6/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3492 | Actual Loss: 3.2911\n",
      "Baseline Loss: 3.4283 | Actual Loss: 3.4281\n",
      "Baseline Loss: 3.4104 | Actual Loss: 3.4245\n",
      "Baseline Loss: 3.5878 | Actual Loss: 3.5980\n",
      "Baseline Loss: 3.5927 | Actual Loss: 3.5306\n",
      "Baseline Loss: 3.4222 | Actual Loss: 3.4115\n",
      "Baseline Loss: 3.7172 | Actual Loss: 3.7402\n",
      "Baseline Loss: 3.4242 | Actual Loss: 3.3470\n",
      "Baseline Loss: 3.7224 | Actual Loss: 3.4889\n",
      "Baseline Loss: 3.3479 | Actual Loss: 3.2558\n",
      "Baseline Loss: 3.6827 | Actual Loss: 3.4736\n",
      "Baseline Loss: 3.5329 | Actual Loss: 3.3391\n",
      "Baseline Loss: 3.3281 | Actual Loss: 3.1274\n",
      "Baseline Loss: 3.4631 | Actual Loss: 3.2332\n",
      "Baseline Loss: 3.5041 | Actual Loss: 3.2496\n",
      "Baseline Loss: 3.5201 | Actual Loss: 3.1177\n",
      "Baseline Loss: 3.7429 | Actual Loss: 3.4257\n",
      "Baseline Loss: 3.6229 | Actual Loss: 3.3890\n",
      "Baseline Loss: 3.5384 | Actual Loss: 3.2256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 1/1000 [00:00<06:57,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4730 | Actual Loss: 3.3214\n",
      "Epoch 1/1000: Train Loss: 3.3785, Val Loss: 3.3404\n",
      "New best validation loss: 3.3404\n",
      "Baseline Loss: 3.4029 | Actual Loss: 3.0122\n",
      "Baseline Loss: 3.3925 | Actual Loss: 3.1285\n",
      "Baseline Loss: 3.4370 | Actual Loss: 3.3824\n",
      "Baseline Loss: 3.5461 | Actual Loss: 3.2929\n",
      "Baseline Loss: 3.4967 | Actual Loss: 3.2825\n",
      "Baseline Loss: 3.2934 | Actual Loss: 2.8937\n",
      "Baseline Loss: 3.5089 | Actual Loss: 3.1419\n",
      "Baseline Loss: 3.3285 | Actual Loss: 2.8766\n",
      "Baseline Loss: 3.6458 | Actual Loss: 2.9382\n",
      "Baseline Loss: 3.7839 | Actual Loss: 2.9472\n",
      "Baseline Loss: 3.5254 | Actual Loss: 2.8173\n",
      "Baseline Loss: 3.6453 | Actual Loss: 3.0567\n",
      "Baseline Loss: 3.6875 | Actual Loss: 2.8766\n",
      "Baseline Loss: 3.7073 | Actual Loss: 2.9580\n",
      "Baseline Loss: 3.4543 | Actual Loss: 2.7900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 2/1000 [00:00<07:34,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4393 | Actual Loss: 2.7318\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.6599\n",
      "Baseline Loss: 3.6229 | Actual Loss: 2.6048\n",
      "Baseline Loss: 3.5384 | Actual Loss: 2.6234\n",
      "Baseline Loss: 3.4730 | Actual Loss: 2.8145\n",
      "Epoch 2/1000: Train Loss: 3.0079, Val Loss: 2.6757\n",
      "New best validation loss: 2.6757\n",
      "Baseline Loss: 3.3988 | Actual Loss: 2.8957\n",
      "Baseline Loss: 3.4314 | Actual Loss: 2.7055\n",
      "Baseline Loss: 3.5875 | Actual Loss: 2.5887\n",
      "Baseline Loss: 3.5256 | Actual Loss: 2.4561\n",
      "Baseline Loss: 3.5704 | Actual Loss: 2.3513\n",
      "Baseline Loss: 3.3243 | Actual Loss: 1.9967\n",
      "Baseline Loss: 3.4286 | Actual Loss: 2.6911\n",
      "Baseline Loss: 3.5500 | Actual Loss: 2.1679\n",
      "Baseline Loss: 3.5917 | Actual Loss: 2.2500\n",
      "Baseline Loss: 3.4661 | Actual Loss: 2.0960\n",
      "Baseline Loss: 3.6179 | Actual Loss: 1.7000\n",
      "Baseline Loss: 3.5410 | Actual Loss: 1.9401\n",
      "Baseline Loss: 3.4542 | Actual Loss: 2.1398\n",
      "Baseline Loss: 3.5781 | Actual Loss: 2.0710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 3/1000 [00:01<08:08,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4882 | Actual Loss: 1.7400\n",
      "Baseline Loss: 3.0702 | Actual Loss: 1.6380\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.0806\n",
      "Baseline Loss: 3.6229 | Actual Loss: 2.1023\n",
      "Baseline Loss: 3.5384 | Actual Loss: 2.2479\n",
      "Baseline Loss: 3.4730 | Actual Loss: 2.2239\n",
      "Epoch 3/1000: Train Loss: 2.2142, Val Loss: 2.1637\n",
      "New best validation loss: 2.1637\n",
      "Baseline Loss: 3.4029 | Actual Loss: 1.8172\n",
      "Baseline Loss: 3.4437 | Actual Loss: 2.0731\n",
      "Baseline Loss: 3.4846 | Actual Loss: 1.7137\n",
      "Baseline Loss: 3.6140 | Actual Loss: 1.6390\n",
      "Baseline Loss: 3.3690 | Actual Loss: 2.2306\n",
      "Baseline Loss: 3.4929 | Actual Loss: 2.6241\n",
      "Baseline Loss: 3.5290 | Actual Loss: 1.3940\n",
      "Baseline Loss: 3.3413 | Actual Loss: 1.7806\n",
      "Baseline Loss: 3.3959 | Actual Loss: 1.4725\n",
      "Baseline Loss: 3.6096 | Actual Loss: 2.1766\n",
      "Baseline Loss: 3.4661 | Actual Loss: 1.7710\n",
      "Baseline Loss: 3.5091 | Actual Loss: 1.3016\n",
      "Baseline Loss: 3.6883 | Actual Loss: 1.5349\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.7305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 4/1000 [00:01<07:30,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5746 | Actual Loss: 1.8931\n",
      "Baseline Loss: 2.9040 | Actual Loss: 1.1784\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.6608\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.5805\n",
      "Baseline Loss: 3.5384 | Actual Loss: 1.5658\n",
      "Baseline Loss: 3.4730 | Actual Loss: 1.7301\n",
      "Epoch 4/1000: Train Loss: 1.7707, Val Loss: 1.6343\n",
      "New best validation loss: 1.6343\n",
      "Baseline Loss: 3.4688 | Actual Loss: 1.0518\n",
      "Baseline Loss: 3.5328 | Actual Loss: 1.4612\n",
      "Baseline Loss: 3.4854 | Actual Loss: 1.9021\n",
      "Baseline Loss: 3.4969 | Actual Loss: 1.9072\n",
      "Baseline Loss: 3.4887 | Actual Loss: 1.9018\n",
      "Baseline Loss: 3.4358 | Actual Loss: 1.4099\n",
      "Baseline Loss: 3.5213 | Actual Loss: 1.8876\n",
      "Baseline Loss: 3.4651 | Actual Loss: 1.4062\n",
      "Baseline Loss: 3.4970 | Actual Loss: 1.8130\n",
      "Baseline Loss: 3.5967 | Actual Loss: 1.3636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 5/1000 [00:02<07:41,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3346 | Actual Loss: 1.5292\n",
      "Baseline Loss: 3.3677 | Actual Loss: 1.7463\n",
      "Baseline Loss: 3.6051 | Actual Loss: 1.9094\n",
      "Baseline Loss: 3.8721 | Actual Loss: 1.3611\n",
      "Baseline Loss: 3.4247 | Actual Loss: 1.9235\n",
      "Baseline Loss: 3.4402 | Actual Loss: 1.2132\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.5582\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.7546\n",
      "Baseline Loss: 3.5384 | Actual Loss: 1.8440\n",
      "Baseline Loss: 3.4730 | Actual Loss: 1.7091\n",
      "Epoch 5/1000: Train Loss: 1.6117, Val Loss: 1.7165\n",
      "Baseline Loss: 3.4358 | Actual Loss: 1.4497\n",
      "Baseline Loss: 3.3751 | Actual Loss: 1.7283\n",
      "Baseline Loss: 3.6878 | Actual Loss: 1.4149\n",
      "Baseline Loss: 3.3585 | Actual Loss: 1.3577\n",
      "Baseline Loss: 3.4035 | Actual Loss: 1.4374\n",
      "Baseline Loss: 3.3435 | Actual Loss: 2.2801\n",
      "Baseline Loss: 3.4106 | Actual Loss: 1.8202\n",
      "Baseline Loss: 3.4888 | Actual Loss: 2.0152\n",
      "Baseline Loss: 3.4398 | Actual Loss: 1.5569\n",
      "Baseline Loss: 3.4062 | Actual Loss: 1.1163\n",
      "Baseline Loss: 3.5792 | Actual Loss: 1.3441\n",
      "Baseline Loss: 3.7273 | Actual Loss: 1.3219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 6/1000 [00:02<07:28,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6045 | Actual Loss: 1.3405\n",
      "Baseline Loss: 3.4706 | Actual Loss: 1.5899\n",
      "Baseline Loss: 3.9197 | Actual Loss: 1.3513\n",
      "Baseline Loss: 3.2415 | Actual Loss: 0.8475\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.6063\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.3512\n",
      "Baseline Loss: 3.5384 | Actual Loss: 1.2844\n",
      "Baseline Loss: 3.4730 | Actual Loss: 1.6892\n",
      "Epoch 6/1000: Train Loss: 1.4982, Val Loss: 1.4828\n",
      "New best validation loss: 1.4828\n",
      "Baseline Loss: 3.4972 | Actual Loss: 1.8099\n",
      "Baseline Loss: 3.7367 | Actual Loss: 1.8030\n",
      "Baseline Loss: 3.5359 | Actual Loss: 1.2612\n",
      "Baseline Loss: 3.5365 | Actual Loss: 1.2373\n",
      "Baseline Loss: 3.4358 | Actual Loss: 1.2378\n",
      "Baseline Loss: 3.6224 | Actual Loss: 0.8811\n",
      "Baseline Loss: 3.4541 | Actual Loss: 1.5919\n",
      "Baseline Loss: 3.5216 | Actual Loss: 1.3305\n",
      "Baseline Loss: 3.6969 | Actual Loss: 1.7381\n",
      "Baseline Loss: 3.4101 | Actual Loss: 1.1499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 7/1000 [00:03<07:37,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4777 | Actual Loss: 1.6639\n",
      "Baseline Loss: 3.5247 | Actual Loss: 1.0781\n",
      "Baseline Loss: 3.3605 | Actual Loss: 1.2346\n",
      "Baseline Loss: 3.4649 | Actual Loss: 1.4850\n",
      "Baseline Loss: 3.4541 | Actual Loss: 0.7397\n",
      "Baseline Loss: 3.2498 | Actual Loss: 0.6706\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.6949\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.3554\n",
      "Baseline Loss: 3.5384 | Actual Loss: 1.1020\n",
      "Baseline Loss: 3.4730 | Actual Loss: 1.3579\n",
      "Epoch 7/1000: Train Loss: 1.3070, Val Loss: 1.3776\n",
      "New best validation loss: 1.3776\n",
      "Baseline Loss: 3.5092 | Actual Loss: 1.5471\n",
      "Baseline Loss: 3.5487 | Actual Loss: 1.2514\n",
      "Baseline Loss: 3.5966 | Actual Loss: 1.0321\n",
      "Baseline Loss: 3.5212 | Actual Loss: 1.4618\n",
      "Baseline Loss: 3.6093 | Actual Loss: 0.8721\n",
      "Baseline Loss: 3.5748 | Actual Loss: 0.9844\n",
      "Baseline Loss: 3.4029 | Actual Loss: 1.5061\n",
      "Baseline Loss: 3.6409 | Actual Loss: 0.9903\n",
      "Baseline Loss: 3.4134 | Actual Loss: 1.2623\n",
      "Baseline Loss: 3.4398 | Actual Loss: 0.7217\n",
      "Baseline Loss: 3.4616 | Actual Loss: 1.7823\n",
      "Baseline Loss: 3.3857 | Actual Loss: 2.0257\n",
      "Baseline Loss: 3.4352 | Actual Loss: 1.7714\n",
      "Baseline Loss: 3.5965 | Actual Loss: 1.2390\n",
      "Baseline Loss: 3.4229 | Actual Loss: 1.1703\n",
      "Baseline Loss: 3.3571 | Actual Loss: 1.0952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 8/1000 [00:03<07:56,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7429 | Actual Loss: 1.2377\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.4721\n",
      "Baseline Loss: 3.5384 | Actual Loss: 1.2703\n",
      "Baseline Loss: 3.4730 | Actual Loss: 1.2535\n",
      "Epoch 8/1000: Train Loss: 1.2946, Val Loss: 1.3084\n",
      "New best validation loss: 1.3084\n",
      "Baseline Loss: 3.4112 | Actual Loss: 1.6202\n",
      "Baseline Loss: 3.4209 | Actual Loss: 0.9335\n",
      "Baseline Loss: 3.5044 | Actual Loss: 1.3169\n",
      "Baseline Loss: 3.3862 | Actual Loss: 1.7237\n",
      "Baseline Loss: 3.5549 | Actual Loss: 1.0745\n",
      "Baseline Loss: 3.3780 | Actual Loss: 1.3109\n",
      "Baseline Loss: 3.5203 | Actual Loss: 1.3836\n",
      "Baseline Loss: 3.3648 | Actual Loss: 1.1831\n",
      "Baseline Loss: 3.3046 | Actual Loss: 1.3595\n",
      "Baseline Loss: 3.5177 | Actual Loss: 0.9047\n",
      "Baseline Loss: 3.5749 | Actual Loss: 0.9701\n",
      "Baseline Loss: 3.5453 | Actual Loss: 2.0254\n",
      "Baseline Loss: 3.5751 | Actual Loss: 1.4629\n",
      "Baseline Loss: 3.5135 | Actual Loss: 1.0793\n",
      "Baseline Loss: 3.6090 | Actual Loss: 1.2287\n",
      "Baseline Loss: 3.4210 | Actual Loss: 0.5525\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.1070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 9/1000 [00:04<07:39,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6229 | Actual Loss: 1.2194\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.9495\n",
      "Baseline Loss: 3.4730 | Actual Loss: 1.8343\n",
      "Epoch 9/1000: Train Loss: 1.2581, Val Loss: 1.2775\n",
      "New best validation loss: 1.2775\n",
      "Baseline Loss: 3.4252 | Actual Loss: 1.2179\n",
      "Baseline Loss: 3.5658 | Actual Loss: 1.0887\n",
      "Baseline Loss: 3.4429 | Actual Loss: 1.3818\n",
      "Baseline Loss: 3.5969 | Actual Loss: 1.3975\n",
      "Baseline Loss: 3.4033 | Actual Loss: 1.3618\n",
      "Baseline Loss: 3.4699 | Actual Loss: 1.1503\n",
      "Baseline Loss: 3.5619 | Actual Loss: 1.3179\n",
      "Baseline Loss: 3.3924 | Actual Loss: 1.2551\n",
      "Baseline Loss: 3.7121 | Actual Loss: 1.5249\n",
      "Baseline Loss: 3.4654 | Actual Loss: 1.0550\n",
      "Baseline Loss: 3.5085 | Actual Loss: 1.1165\n",
      "Baseline Loss: 3.4329 | Actual Loss: 1.2508\n",
      "Baseline Loss: 3.4665 | Actual Loss: 1.1509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 10/1000 [00:04<07:43,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4146 | Actual Loss: 1.5520\n",
      "Baseline Loss: 3.8102 | Actual Loss: 1.5293\n",
      "Baseline Loss: 3.6527 | Actual Loss: 1.4170\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.5402\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.2685\n",
      "Baseline Loss: 3.5384 | Actual Loss: 1.2281\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.9395\n",
      "Epoch 10/1000: Train Loss: 1.2980, Val Loss: 1.2441\n",
      "New best validation loss: 1.2441\n",
      "Baseline Loss: 3.3372 | Actual Loss: 1.0647\n",
      "Baseline Loss: 3.5244 | Actual Loss: 1.1970\n",
      "Baseline Loss: 3.6688 | Actual Loss: 1.0758\n",
      "Baseline Loss: 3.5878 | Actual Loss: 1.9332\n",
      "Baseline Loss: 3.5996 | Actual Loss: 0.9139\n",
      "Baseline Loss: 3.4393 | Actual Loss: 1.0147\n",
      "Baseline Loss: 3.4782 | Actual Loss: 1.6009\n",
      "Baseline Loss: 3.4626 | Actual Loss: 1.3958\n",
      "Baseline Loss: 3.4545 | Actual Loss: 0.8026\n",
      "Baseline Loss: 3.5125 | Actual Loss: 1.4451\n",
      "Baseline Loss: 3.4070 | Actual Loss: 1.1878\n",
      "Baseline Loss: 3.9016 | Actual Loss: 1.8287\n",
      "Baseline Loss: 3.3649 | Actual Loss: 1.9924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 11/1000 [00:05<07:53,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3817 | Actual Loss: 1.7194\n",
      "Baseline Loss: 3.5371 | Actual Loss: 0.8546\n",
      "Baseline Loss: 3.2257 | Actual Loss: 1.0491\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.2429\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.4747\n",
      "Baseline Loss: 3.5384 | Actual Loss: 1.1721\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.9445\n",
      "Epoch 11/1000: Train Loss: 1.3172, Val Loss: 1.2085\n",
      "New best validation loss: 1.2085\n",
      "Baseline Loss: 3.4617 | Actual Loss: 1.2934\n",
      "Baseline Loss: 3.6875 | Actual Loss: 0.9958\n",
      "Baseline Loss: 3.6051 | Actual Loss: 1.2954\n",
      "Baseline Loss: 3.4242 | Actual Loss: 1.1296\n",
      "Baseline Loss: 3.4730 | Actual Loss: 1.6203\n",
      "Baseline Loss: 3.3950 | Actual Loss: 1.2216\n",
      "Baseline Loss: 3.4289 | Actual Loss: 1.1743\n",
      "Baseline Loss: 3.2762 | Actual Loss: 1.4824\n",
      "Baseline Loss: 3.4282 | Actual Loss: 0.7774\n",
      "Baseline Loss: 3.5200 | Actual Loss: 1.1105\n",
      "Baseline Loss: 3.5456 | Actual Loss: 0.9188\n",
      "Baseline Loss: 3.5543 | Actual Loss: 0.8584\n",
      "Baseline Loss: 3.5923 | Actual Loss: 1.0062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 12/1000 [00:05<07:37,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7023 | Actual Loss: 1.2859\n",
      "Baseline Loss: 3.3413 | Actual Loss: 1.6718\n",
      "Baseline Loss: 3.5399 | Actual Loss: 1.7700\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.0248\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.4760\n",
      "Baseline Loss: 3.5384 | Actual Loss: 1.4732\n",
      "Baseline Loss: 3.4730 | Actual Loss: 1.2169\n",
      "Epoch 12/1000: Train Loss: 1.2257, Val Loss: 1.2978\n",
      "Baseline Loss: 3.4665 | Actual Loss: 1.3009\n",
      "Baseline Loss: 3.2142 | Actual Loss: 1.2793\n",
      "Baseline Loss: 3.4287 | Actual Loss: 1.2274\n",
      "Baseline Loss: 3.4243 | Actual Loss: 1.2301\n",
      "Baseline Loss: 3.5589 | Actual Loss: 0.9202\n",
      "Baseline Loss: 3.4811 | Actual Loss: 0.9728\n",
      "Baseline Loss: 3.4689 | Actual Loss: 1.0941\n",
      "Baseline Loss: 3.7219 | Actual Loss: 0.9579\n",
      "Baseline Loss: 3.8319 | Actual Loss: 1.5194\n",
      "Baseline Loss: 3.4039 | Actual Loss: 0.9306\n",
      "Baseline Loss: 3.5376 | Actual Loss: 0.9283\n",
      "Baseline Loss: 3.3742 | Actual Loss: 1.3290\n",
      "Baseline Loss: 3.4742 | Actual Loss: 2.3130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏         | 13/1000 [00:06<07:44,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6270 | Actual Loss: 1.0494\n",
      "Baseline Loss: 3.4462 | Actual Loss: 1.9603\n",
      "Baseline Loss: 3.2977 | Actual Loss: 2.3176\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.0144\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.8598\n",
      "Baseline Loss: 3.5384 | Actual Loss: 1.2816\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.8232\n",
      "Epoch 13/1000: Train Loss: 1.3331, Val Loss: 1.2448\n",
      "Baseline Loss: 3.2392 | Actual Loss: 1.2068\n",
      "Baseline Loss: 3.5082 | Actual Loss: 1.0437\n",
      "Baseline Loss: 3.3723 | Actual Loss: 1.1219\n",
      "Baseline Loss: 3.6132 | Actual Loss: 1.0451\n",
      "Baseline Loss: 3.5008 | Actual Loss: 1.0593\n",
      "Baseline Loss: 3.4930 | Actual Loss: 1.4395\n",
      "Baseline Loss: 3.6637 | Actual Loss: 0.6577\n",
      "Baseline Loss: 3.3085 | Actual Loss: 0.9533\n",
      "Baseline Loss: 3.4245 | Actual Loss: 1.0612\n",
      "Baseline Loss: 3.3372 | Actual Loss: 1.4433\n",
      "Baseline Loss: 3.4036 | Actual Loss: 1.2298\n",
      "Baseline Loss: 3.5656 | Actual Loss: 0.6207\n",
      "Baseline Loss: 3.4574 | Actual Loss: 1.1227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏         | 14/1000 [00:06<07:50,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.8051 | Actual Loss: 1.2489\n",
      "Baseline Loss: 3.5541 | Actual Loss: 1.0493\n",
      "Baseline Loss: 3.6172 | Actual Loss: 1.1981\n",
      "Baseline Loss: 3.7429 | Actual Loss: 0.9130\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.8200\n",
      "Baseline Loss: 3.5384 | Actual Loss: 1.0226\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.8935\n",
      "Epoch 14/1000: Train Loss: 1.0938, Val Loss: 1.1623\n",
      "New best validation loss: 1.1623\n",
      "Baseline Loss: 3.4362 | Actual Loss: 1.0690\n",
      "Baseline Loss: 3.4705 | Actual Loss: 1.7217\n",
      "Baseline Loss: 3.5128 | Actual Loss: 0.8607\n",
      "Baseline Loss: 3.6831 | Actual Loss: 1.0487\n",
      "Baseline Loss: 3.3235 | Actual Loss: 1.4552\n",
      "Baseline Loss: 3.5832 | Actual Loss: 0.9742\n",
      "Baseline Loss: 3.5532 | Actual Loss: 1.8794\n",
      "Baseline Loss: 3.5622 | Actual Loss: 1.1220\n",
      "Baseline Loss: 3.3459 | Actual Loss: 1.0862\n",
      "Baseline Loss: 3.3346 | Actual Loss: 1.4275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 15/1000 [00:06<07:35,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6406 | Actual Loss: 1.0214\n",
      "Baseline Loss: 3.5618 | Actual Loss: 0.8477\n",
      "Baseline Loss: 3.4321 | Actual Loss: 1.0278\n",
      "Baseline Loss: 3.5874 | Actual Loss: 1.2572\n",
      "Baseline Loss: 3.4352 | Actual Loss: 1.2593\n",
      "Baseline Loss: 3.4789 | Actual Loss: 1.2077\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.6381\n",
      "Baseline Loss: 3.6229 | Actual Loss: 3.2586\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.7569\n",
      "Baseline Loss: 3.4730 | Actual Loss: 2.0583\n",
      "Epoch 15/1000: Train Loss: 1.2041, Val Loss: 2.1780\n",
      "Baseline Loss: 3.6545 | Actual Loss: 1.8330\n",
      "Baseline Loss: 3.6880 | Actual Loss: 3.0014\n",
      "Baseline Loss: 3.5667 | Actual Loss: 1.3270\n",
      "Baseline Loss: 3.3549 | Actual Loss: 0.9363\n",
      "Baseline Loss: 3.4114 | Actual Loss: 1.5180\n",
      "Baseline Loss: 3.2576 | Actual Loss: 1.1788\n",
      "Baseline Loss: 3.3718 | Actual Loss: 1.3093\n",
      "Baseline Loss: 3.7267 | Actual Loss: 1.0811\n",
      "Baseline Loss: 3.4437 | Actual Loss: 0.8562\n",
      "Baseline Loss: 3.4581 | Actual Loss: 0.9880\n",
      "Baseline Loss: 3.4613 | Actual Loss: 1.2183\n",
      "Baseline Loss: 3.4069 | Actual Loss: 0.7416\n",
      "Baseline Loss: 3.7473 | Actual Loss: 2.8321\n",
      "Baseline Loss: 3.5085 | Actual Loss: 2.5239\n",
      "Baseline Loss: 3.5787 | Actual Loss: 0.9430\n",
      "Baseline Loss: 3.1606 | Actual Loss: 1.1289\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.0541\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.5958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 16/1000 [00:07<07:48,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5384 | Actual Loss: 1.1152\n",
      "Baseline Loss: 3.4730 | Actual Loss: 1.0028\n",
      "Epoch 16/1000: Train Loss: 1.4635, Val Loss: 1.1920\n",
      "Baseline Loss: 3.4100 | Actual Loss: 1.2281\n",
      "Baseline Loss: 3.4620 | Actual Loss: 1.1758\n",
      "Baseline Loss: 3.6407 | Actual Loss: 1.0968\n",
      "Baseline Loss: 3.5377 | Actual Loss: 1.0325\n",
      "Baseline Loss: 3.2089 | Actual Loss: 1.1543\n",
      "Baseline Loss: 3.8374 | Actual Loss: 0.7903\n",
      "Baseline Loss: 3.5368 | Actual Loss: 1.0886\n",
      "Baseline Loss: 3.3335 | Actual Loss: 1.2547\n",
      "Baseline Loss: 3.5661 | Actual Loss: 0.7787\n",
      "Baseline Loss: 3.6280 | Actual Loss: 1.0465\n",
      "Baseline Loss: 3.5125 | Actual Loss: 0.9832\n",
      "Baseline Loss: 3.7472 | Actual Loss: 1.6903\n",
      "Baseline Loss: 3.3237 | Actual Loss: 1.2072\n",
      "Baseline Loss: 3.3380 | Actual Loss: 1.6172\n",
      "Baseline Loss: 3.5173 | Actual Loss: 0.9975\n",
      "Baseline Loss: 3.4405 | Actual Loss: 1.1386\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.0537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 17/1000 [00:07<07:33,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6229 | Actual Loss: 1.3056\n",
      "Baseline Loss: 3.5384 | Actual Loss: 1.2791\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.7875\n",
      "Epoch 17/1000: Train Loss: 1.1425, Val Loss: 1.1065\n",
      "New best validation loss: 1.1065\n",
      "Baseline Loss: 3.5250 | Actual Loss: 0.9529\n",
      "Baseline Loss: 3.5844 | Actual Loss: 1.0851\n",
      "Baseline Loss: 3.4242 | Actual Loss: 0.9050\n",
      "Baseline Loss: 3.4057 | Actual Loss: 0.8306\n",
      "Baseline Loss: 3.4064 | Actual Loss: 1.0727\n",
      "Baseline Loss: 3.4971 | Actual Loss: 1.6787\n",
      "Baseline Loss: 3.4928 | Actual Loss: 1.4622\n",
      "Baseline Loss: 3.4321 | Actual Loss: 1.1791\n",
      "Baseline Loss: 3.5130 | Actual Loss: 1.1805\n",
      "Baseline Loss: 3.6132 | Actual Loss: 0.8498\n",
      "Baseline Loss: 3.4730 | Actual Loss: 1.0443\n",
      "Baseline Loss: 3.7164 | Actual Loss: 1.3815\n",
      "Baseline Loss: 3.5879 | Actual Loss: 1.4714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 18/1000 [00:08<07:45,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3961 | Actual Loss: 1.2332\n",
      "Baseline Loss: 3.5587 | Actual Loss: 0.9897\n",
      "Baseline Loss: 3.2823 | Actual Loss: 0.4586\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.2120\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.7474\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.9091\n",
      "Baseline Loss: 3.4730 | Actual Loss: 1.2589\n",
      "Epoch 18/1000: Train Loss: 1.1109, Val Loss: 1.2818\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.6719\n",
      "Baseline Loss: 3.6225 | Actual Loss: 1.2921\n",
      "Baseline Loss: 3.4437 | Actual Loss: 0.9123\n",
      "Baseline Loss: 3.6545 | Actual Loss: 1.4673\n",
      "Baseline Loss: 3.8100 | Actual Loss: 0.9066\n",
      "Baseline Loss: 3.4004 | Actual Loss: 1.1509\n",
      "Baseline Loss: 3.4779 | Actual Loss: 0.5623\n",
      "Baseline Loss: 3.4408 | Actual Loss: 0.5220\n",
      "Baseline Loss: 3.5966 | Actual Loss: 1.1031\n",
      "Baseline Loss: 3.3015 | Actual Loss: 1.1056\n",
      "Baseline Loss: 3.5959 | Actual Loss: 0.8810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 19/1000 [00:08<07:51,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.2219 | Actual Loss: 1.3618\n",
      "Baseline Loss: 3.4590 | Actual Loss: 1.3804\n",
      "Baseline Loss: 3.4212 | Actual Loss: 1.4489\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.3561\n",
      "Baseline Loss: 3.7268 | Actual Loss: 1.4394\n",
      "Baseline Loss: 3.7429 | Actual Loss: 0.8802\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.4463\n",
      "Baseline Loss: 3.5384 | Actual Loss: 1.5451\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.8657\n",
      "Epoch 19/1000: Train Loss: 1.0976, Val Loss: 1.1843\n",
      "Baseline Loss: 3.2550 | Actual Loss: 1.2741\n",
      "Baseline Loss: 3.4140 | Actual Loss: 1.1882\n",
      "Baseline Loss: 3.5126 | Actual Loss: 1.0127\n",
      "Baseline Loss: 3.3265 | Actual Loss: 1.2336\n",
      "Baseline Loss: 3.5327 | Actual Loss: 1.4136\n",
      "Baseline Loss: 3.5373 | Actual Loss: 1.0977\n",
      "Baseline Loss: 3.5086 | Actual Loss: 1.0841\n",
      "Baseline Loss: 3.4923 | Actual Loss: 1.1069\n",
      "Baseline Loss: 3.7522 | Actual Loss: 0.9084\n",
      "Baseline Loss: 3.3571 | Actual Loss: 0.8933\n",
      "Baseline Loss: 3.4212 | Actual Loss: 0.8826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 20/1000 [00:09<07:39,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5540 | Actual Loss: 0.9491\n",
      "Baseline Loss: 3.7020 | Actual Loss: 0.3953\n",
      "Baseline Loss: 3.5209 | Actual Loss: 1.0320\n",
      "Baseline Loss: 3.5012 | Actual Loss: 2.7639\n",
      "Baseline Loss: 3.4586 | Actual Loss: 1.7249\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.0938\n",
      "Baseline Loss: 3.6229 | Actual Loss: 2.3377\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.8407\n",
      "Baseline Loss: 3.4730 | Actual Loss: 2.1425\n",
      "Epoch 20/1000: Train Loss: 1.1850, Val Loss: 1.8537\n",
      "Baseline Loss: 3.5364 | Actual Loss: 1.1520\n",
      "Baseline Loss: 3.5167 | Actual Loss: 1.2091\n",
      "Baseline Loss: 3.4029 | Actual Loss: 0.9575\n",
      "Baseline Loss: 3.3189 | Actual Loss: 0.7359\n",
      "Baseline Loss: 3.7221 | Actual Loss: 1.6337\n",
      "Baseline Loss: 3.3409 | Actual Loss: 1.1765\n",
      "Baseline Loss: 3.5087 | Actual Loss: 0.9145\n",
      "Baseline Loss: 3.4769 | Actual Loss: 1.0260\n",
      "Baseline Loss: 3.7422 | Actual Loss: 1.0592\n",
      "Baseline Loss: 3.7171 | Actual Loss: 1.5572\n",
      "Baseline Loss: 3.5498 | Actual Loss: 0.8332\n",
      "Baseline Loss: 3.6052 | Actual Loss: 0.6989\n",
      "Baseline Loss: 3.6547 | Actual Loss: 0.6835\n",
      "Baseline Loss: 3.3104 | Actual Loss: 0.9246\n",
      "Baseline Loss: 3.4778 | Actual Loss: 1.2274\n",
      "Baseline Loss: 3.3322 | Actual Loss: 0.8436\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.3194\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.5350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 21/1000 [00:09<07:47,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5384 | Actual Loss: 0.8458\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.6827\n",
      "Epoch 21/1000: Train Loss: 1.0396, Val Loss: 1.0957\n",
      "New best validation loss: 1.0957\n",
      "Baseline Loss: 3.5624 | Actual Loss: 1.0591\n",
      "Baseline Loss: 3.3813 | Actual Loss: 1.2105\n",
      "Baseline Loss: 3.4584 | Actual Loss: 0.9493\n",
      "Baseline Loss: 3.2671 | Actual Loss: 0.6687\n",
      "Baseline Loss: 4.0079 | Actual Loss: 0.8242\n",
      "Baseline Loss: 3.4024 | Actual Loss: 1.2047\n",
      "Baseline Loss: 3.3674 | Actual Loss: 1.4146\n",
      "Baseline Loss: 3.7126 | Actual Loss: 0.8858\n",
      "Baseline Loss: 3.8956 | Actual Loss: 1.3603\n",
      "Baseline Loss: 3.4735 | Actual Loss: 1.1984\n",
      "Baseline Loss: 3.3297 | Actual Loss: 0.6651\n",
      "Baseline Loss: 3.2153 | Actual Loss: 1.3333\n",
      "Baseline Loss: 3.3311 | Actual Loss: 0.6564\n",
      "Baseline Loss: 3.9010 | Actual Loss: 0.9081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 22/1000 [00:10<07:51,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5495 | Actual Loss: 1.0233\n",
      "Baseline Loss: 3.5619 | Actual Loss: 1.4361\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.8568\n",
      "Baseline Loss: 3.6229 | Actual Loss: 2.3233\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.7496\n",
      "Baseline Loss: 3.4730 | Actual Loss: 1.0830\n",
      "Epoch 22/1000: Train Loss: 1.0499, Val Loss: 1.5032\n",
      "Baseline Loss: 3.5493 | Actual Loss: 1.2603\n",
      "Baseline Loss: 3.5012 | Actual Loss: 1.1210\n",
      "Baseline Loss: 3.4063 | Actual Loss: 0.7836\n",
      "Baseline Loss: 3.6039 | Actual Loss: 1.3594\n",
      "Baseline Loss: 3.8047 | Actual Loss: 0.6802\n",
      "Baseline Loss: 3.5743 | Actual Loss: 0.8119\n",
      "Baseline Loss: 3.3368 | Actual Loss: 1.0837\n",
      "Baseline Loss: 3.4040 | Actual Loss: 1.1268\n",
      "Baseline Loss: 3.4657 | Actual Loss: 1.5276\n",
      "Baseline Loss: 3.4744 | Actual Loss: 0.9654\n",
      "Baseline Loss: 3.4855 | Actual Loss: 0.6161\n",
      "Baseline Loss: 3.4583 | Actual Loss: 0.9771\n",
      "Baseline Loss: 3.3743 | Actual Loss: 0.7968\n",
      "Baseline Loss: 3.6639 | Actual Loss: 1.1070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 23/1000 [00:10<07:25,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3156 | Actual Loss: 1.2890\n",
      "Baseline Loss: 3.3479 | Actual Loss: 1.9961\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.2581\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.2726\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.9979\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.7228\n",
      "Epoch 23/1000: Train Loss: 1.0939, Val Loss: 1.0628\n",
      "New best validation loss: 1.0628\n",
      "Baseline Loss: 3.6137 | Actual Loss: 0.8040\n",
      "Baseline Loss: 3.4713 | Actual Loss: 1.0582\n",
      "Baseline Loss: 3.6644 | Actual Loss: 1.0585\n",
      "Baseline Loss: 3.7070 | Actual Loss: 1.4843\n",
      "Baseline Loss: 3.3774 | Actual Loss: 0.8917\n",
      "Baseline Loss: 3.4929 | Actual Loss: 0.7692\n",
      "Baseline Loss: 3.2509 | Actual Loss: 1.7222\n",
      "Baseline Loss: 3.4074 | Actual Loss: 0.6027\n",
      "Baseline Loss: 3.2948 | Actual Loss: 1.0929\n",
      "Baseline Loss: 3.5208 | Actual Loss: 1.1250\n",
      "Baseline Loss: 3.3578 | Actual Loss: 0.4522\n",
      "Baseline Loss: 3.5242 | Actual Loss: 1.1978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 24/1000 [00:11<07:41,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.2948 | Actual Loss: 0.8231\n",
      "Baseline Loss: 3.5285 | Actual Loss: 0.5527\n",
      "Baseline Loss: 3.5875 | Actual Loss: 1.0371\n",
      "Baseline Loss: 3.5091 | Actual Loss: 0.9915\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.2801\n",
      "Baseline Loss: 3.6229 | Actual Loss: 2.4765\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.7034\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.7579\n",
      "Epoch 24/1000: Train Loss: 0.9789, Val Loss: 1.5545\n",
      "Baseline Loss: 3.3506 | Actual Loss: 0.8527\n",
      "Baseline Loss: 3.5583 | Actual Loss: 0.4528\n",
      "Baseline Loss: 3.7526 | Actual Loss: 1.5784\n",
      "Baseline Loss: 3.3850 | Actual Loss: 0.8605\n",
      "Baseline Loss: 3.4739 | Actual Loss: 1.1546\n",
      "Baseline Loss: 3.5132 | Actual Loss: 1.2783\n",
      "Baseline Loss: 3.5379 | Actual Loss: 1.3003\n",
      "Baseline Loss: 3.7728 | Actual Loss: 1.5150\n",
      "Baseline Loss: 3.7221 | Actual Loss: 1.0284\n",
      "Baseline Loss: 3.4547 | Actual Loss: 0.7505\n",
      "Baseline Loss: 3.6598 | Actual Loss: 0.4170\n",
      "Baseline Loss: 3.5919 | Actual Loss: 1.0045\n",
      "Baseline Loss: 3.6327 | Actual Loss: 1.0963\n",
      "Baseline Loss: 3.2449 | Actual Loss: 0.9938\n",
      "Baseline Loss: 3.5416 | Actual Loss: 1.1116\n",
      "Baseline Loss: 3.3482 | Actual Loss: 0.9151\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.4895\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.2266\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.7999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▎         | 25/1000 [00:11<07:49,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4730 | Actual Loss: 1.3484\n",
      "Epoch 25/1000: Train Loss: 1.0194, Val Loss: 1.2161\n",
      "Baseline Loss: 3.4965 | Actual Loss: 0.9219\n",
      "Baseline Loss: 3.3111 | Actual Loss: 0.7617\n",
      "Baseline Loss: 3.6933 | Actual Loss: 0.8933\n",
      "Baseline Loss: 3.4891 | Actual Loss: 1.5021\n",
      "Baseline Loss: 3.7471 | Actual Loss: 0.8020\n",
      "Baseline Loss: 3.3852 | Actual Loss: 1.3216\n",
      "Baseline Loss: 3.7070 | Actual Loss: 0.6544\n",
      "Baseline Loss: 3.5574 | Actual Loss: 0.3197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 26/1000 [00:12<07:24,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.2530 | Actual Loss: 1.1101\n",
      "Baseline Loss: 3.4317 | Actual Loss: 0.4414\n",
      "Baseline Loss: 3.6284 | Actual Loss: 1.1823\n",
      "Baseline Loss: 3.4363 | Actual Loss: 1.3290\n",
      "Baseline Loss: 3.4212 | Actual Loss: 1.0135\n",
      "Baseline Loss: 3.6359 | Actual Loss: 1.0405\n",
      "Baseline Loss: 3.5326 | Actual Loss: 1.0163\n",
      "Baseline Loss: 3.6645 | Actual Loss: 4.7883\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.5597\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.3604\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.9055\n",
      "Baseline Loss: 3.4730 | Actual Loss: 1.0263\n",
      "Epoch 26/1000: Train Loss: 1.1936, Val Loss: 1.2130\n",
      "Baseline Loss: 3.3436 | Actual Loss: 1.2804\n",
      "Baseline Loss: 3.3239 | Actual Loss: 1.0377\n",
      "Baseline Loss: 3.4888 | Actual Loss: 1.3180\n",
      "Baseline Loss: 3.4106 | Actual Loss: 1.3258\n",
      "Baseline Loss: 3.4960 | Actual Loss: 1.0551\n",
      "Baseline Loss: 3.5452 | Actual Loss: 0.9989\n",
      "Baseline Loss: 3.6220 | Actual Loss: 0.7287\n",
      "Baseline Loss: 3.4633 | Actual Loss: 1.1782\n",
      "Baseline Loss: 3.3995 | Actual Loss: 1.2514\n",
      "Baseline Loss: 3.4008 | Actual Loss: 0.8149\n",
      "Baseline Loss: 3.4282 | Actual Loss: 0.6062\n",
      "Baseline Loss: 3.6144 | Actual Loss: 1.0304\n",
      "Baseline Loss: 3.5014 | Actual Loss: 1.7206\n",
      "Baseline Loss: 3.6184 | Actual Loss: 1.1550\n",
      "Baseline Loss: 3.5578 | Actual Loss: 0.5505\n",
      "Baseline Loss: 3.7268 | Actual Loss: 2.1172\n",
      "Baseline Loss: 3.7429 | Actual Loss: 0.8903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 27/1000 [00:12<07:42,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6229 | Actual Loss: 1.3403\n",
      "Baseline Loss: 3.5384 | Actual Loss: 1.1344\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.8783\n",
      "Epoch 27/1000: Train Loss: 1.1356, Val Loss: 1.0608\n",
      "New best validation loss: 1.0608\n",
      "Baseline Loss: 3.6454 | Actual Loss: 0.8440\n",
      "Baseline Loss: 3.2819 | Actual Loss: 1.1729\n",
      "Baseline Loss: 3.7273 | Actual Loss: 1.1572\n",
      "Baseline Loss: 3.4434 | Actual Loss: 0.9728\n",
      "Baseline Loss: 3.3856 | Actual Loss: 0.9665\n",
      "Baseline Loss: 3.5617 | Actual Loss: 1.3823\n",
      "Baseline Loss: 3.4620 | Actual Loss: 0.6256\n",
      "Baseline Loss: 3.4887 | Actual Loss: 0.7527\n",
      "Baseline Loss: 3.4211 | Actual Loss: 0.6992\n",
      "Baseline Loss: 3.4480 | Actual Loss: 0.9058\n",
      "Baseline Loss: 3.3504 | Actual Loss: 0.9390\n",
      "Baseline Loss: 3.3573 | Actual Loss: 1.8513\n",
      "Baseline Loss: 3.4931 | Actual Loss: 2.8542\n",
      "Baseline Loss: 3.7891 | Actual Loss: 2.1995\n",
      "Baseline Loss: 3.6274 | Actual Loss: 1.2685\n",
      "Baseline Loss: 3.2204 | Actual Loss: 0.7667\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.7592\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.6297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 28/1000 [00:13<07:40,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5384 | Actual Loss: 0.6016\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.9172\n",
      "Epoch 28/1000: Train Loss: 1.2099, Val Loss: 1.2269\n",
      "Baseline Loss: 3.5656 | Actual Loss: 1.3956\n",
      "Baseline Loss: 3.5709 | Actual Loss: 0.5079\n",
      "Baseline Loss: 3.6092 | Actual Loss: 1.3408\n",
      "Baseline Loss: 3.4253 | Actual Loss: 0.8837\n",
      "Baseline Loss: 3.4205 | Actual Loss: 1.1837\n",
      "Baseline Loss: 3.3070 | Actual Loss: 1.4128\n",
      "Baseline Loss: 3.3745 | Actual Loss: 1.1701\n",
      "Baseline Loss: 3.6188 | Actual Loss: 1.0027\n",
      "Baseline Loss: 3.5124 | Actual Loss: 0.7729\n",
      "Baseline Loss: 3.7521 | Actual Loss: 1.1601\n",
      "Baseline Loss: 3.4810 | Actual Loss: 0.9309\n",
      "Baseline Loss: 3.4143 | Actual Loss: 0.5004\n",
      "Baseline Loss: 3.7373 | Actual Loss: 1.3671\n",
      "Baseline Loss: 3.3961 | Actual Loss: 1.0492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 29/1000 [00:13<07:28,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5415 | Actual Loss: 0.7994\n",
      "Baseline Loss: 3.2646 | Actual Loss: 1.1823\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.2432\n",
      "Baseline Loss: 3.6229 | Actual Loss: 2.6593\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.5541\n",
      "Baseline Loss: 3.4730 | Actual Loss: 1.0428\n",
      "Epoch 29/1000: Train Loss: 1.0412, Val Loss: 1.6249\n",
      "Baseline Loss: 3.5668 | Actual Loss: 0.5275\n",
      "Baseline Loss: 3.3508 | Actual Loss: 0.7636\n",
      "Baseline Loss: 3.4965 | Actual Loss: 0.7344\n",
      "Baseline Loss: 3.5413 | Actual Loss: 0.7242\n",
      "Baseline Loss: 3.5328 | Actual Loss: 0.9875\n",
      "Baseline Loss: 3.4686 | Actual Loss: 0.9667\n",
      "Baseline Loss: 3.5021 | Actual Loss: 1.7910\n",
      "Baseline Loss: 3.6136 | Actual Loss: 0.8177\n",
      "Baseline Loss: 3.7423 | Actual Loss: 0.8592\n",
      "Baseline Loss: 3.6007 | Actual Loss: 0.6684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 30/1000 [00:14<07:35,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3819 | Actual Loss: 1.3729\n",
      "Baseline Loss: 3.2586 | Actual Loss: 0.8387\n",
      "Baseline Loss: 3.6287 | Actual Loss: 1.6118\n",
      "Baseline Loss: 3.4039 | Actual Loss: 1.9292\n",
      "Baseline Loss: 3.6051 | Actual Loss: 0.7838\n",
      "Baseline Loss: 3.1302 | Actual Loss: 0.7015\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.1361\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.5744\n",
      "Baseline Loss: 3.5384 | Actual Loss: 1.3652\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.7210\n",
      "Epoch 30/1000: Train Loss: 1.0049, Val Loss: 1.1992\n",
      "Baseline Loss: 3.4507 | Actual Loss: 0.9133\n",
      "Baseline Loss: 3.4371 | Actual Loss: 1.1700\n",
      "Baseline Loss: 3.4432 | Actual Loss: 1.0011\n",
      "Baseline Loss: 3.5000 | Actual Loss: 1.0302\n",
      "Baseline Loss: 3.6827 | Actual Loss: 1.0868\n",
      "Baseline Loss: 3.6405 | Actual Loss: 0.8550\n",
      "Baseline Loss: 3.5009 | Actual Loss: 1.3289\n",
      "Baseline Loss: 3.4360 | Actual Loss: 2.6907\n",
      "Baseline Loss: 3.4847 | Actual Loss: 0.6603\n",
      "Baseline Loss: 3.5875 | Actual Loss: 0.9237\n",
      "Baseline Loss: 3.5015 | Actual Loss: 1.1748\n",
      "Baseline Loss: 3.4809 | Actual Loss: 0.8436\n",
      "Baseline Loss: 3.5250 | Actual Loss: 1.1936\n",
      "Baseline Loss: 3.4697 | Actual Loss: 0.9330\n",
      "Baseline Loss: 3.4655 | Actual Loss: 0.7753\n",
      "Baseline Loss: 3.2980 | Actual Loss: 1.8027\n",
      "Baseline Loss: 3.7429 | Actual Loss: 0.9151\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.5320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 31/1000 [00:14<07:37,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5384 | Actual Loss: 1.1872\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.6462\n",
      "Epoch 31/1000: Train Loss: 1.1489, Val Loss: 1.0701\n",
      "Baseline Loss: 3.6276 | Actual Loss: 0.8812\n",
      "Baseline Loss: 3.5961 | Actual Loss: 0.7509\n",
      "Baseline Loss: 3.3934 | Actual Loss: 0.6026\n",
      "Baseline Loss: 3.4931 | Actual Loss: 1.2432\n",
      "Baseline Loss: 3.4100 | Actual Loss: 0.9278\n",
      "Baseline Loss: 3.5878 | Actual Loss: 0.9107\n",
      "Baseline Loss: 3.5965 | Actual Loss: 0.9747\n",
      "Baseline Loss: 3.4353 | Actual Loss: 0.8161\n",
      "Baseline Loss: 3.5747 | Actual Loss: 1.2121\n",
      "Baseline Loss: 3.7943 | Actual Loss: 1.3755\n",
      "Baseline Loss: 3.3046 | Actual Loss: 0.9484\n",
      "Baseline Loss: 3.3172 | Actual Loss: 0.9694\n",
      "Baseline Loss: 3.4620 | Actual Loss: 0.7810\n",
      "Baseline Loss: 3.3201 | Actual Loss: 0.8991\n",
      "Baseline Loss: 3.7941 | Actual Loss: 1.4991\n",
      "Baseline Loss: 3.0075 | Actual Loss: 1.0760\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.0944\n",
      "Baseline Loss: 3.6229 | Actual Loss: 2.2328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 32/1000 [00:14<07:16,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5384 | Actual Loss: 0.8147\n",
      "Baseline Loss: 3.4730 | Actual Loss: 1.3210\n",
      "Epoch 32/1000: Train Loss: 0.9917, Val Loss: 1.6157\n",
      "Baseline Loss: 3.5327 | Actual Loss: 1.2166\n",
      "Baseline Loss: 3.5580 | Actual Loss: 1.1363\n",
      "Baseline Loss: 3.4545 | Actual Loss: 0.8383\n",
      "Baseline Loss: 3.4855 | Actual Loss: 0.9001\n",
      "Baseline Loss: 3.4960 | Actual Loss: 2.2059\n",
      "Baseline Loss: 3.5965 | Actual Loss: 0.8991\n",
      "Baseline Loss: 3.4180 | Actual Loss: 0.6580\n",
      "Baseline Loss: 3.4325 | Actual Loss: 0.8538\n",
      "Baseline Loss: 3.5624 | Actual Loss: 0.9560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 33/1000 [00:15<07:27,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4390 | Actual Loss: 0.9254\n",
      "Baseline Loss: 3.4544 | Actual Loss: 1.4806\n",
      "Baseline Loss: 3.6885 | Actual Loss: 0.7794\n",
      "Baseline Loss: 3.7366 | Actual Loss: 0.6701\n",
      "Baseline Loss: 3.3036 | Actual Loss: 0.6861\n",
      "Baseline Loss: 3.4967 | Actual Loss: 0.6483\n",
      "Baseline Loss: 3.2817 | Actual Loss: 0.5538\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.3913\n",
      "Baseline Loss: 3.6229 | Actual Loss: 2.7422\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6227\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.9747\n",
      "Epoch 33/1000: Train Loss: 0.9630, Val Loss: 1.6827\n",
      "Baseline Loss: 3.3583 | Actual Loss: 2.4708\n",
      "Baseline Loss: 3.8212 | Actual Loss: 1.4452\n",
      "Baseline Loss: 3.4616 | Actual Loss: 0.7415\n",
      "Baseline Loss: 3.7118 | Actual Loss: 1.9598\n",
      "Baseline Loss: 3.5410 | Actual Loss: 1.7729\n",
      "Baseline Loss: 3.3811 | Actual Loss: 1.1276\n",
      "Baseline Loss: 3.3338 | Actual Loss: 1.0140\n",
      "Baseline Loss: 3.4067 | Actual Loss: 0.4813\n",
      "Baseline Loss: 3.4068 | Actual Loss: 1.0925\n",
      "Baseline Loss: 3.5287 | Actual Loss: 1.4975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 34/1000 [00:15<07:11,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4502 | Actual Loss: 1.4143\n",
      "Baseline Loss: 3.3340 | Actual Loss: 0.8923\n",
      "Baseline Loss: 3.6102 | Actual Loss: 0.7397\n",
      "Baseline Loss: 3.2691 | Actual Loss: 0.9306\n",
      "Baseline Loss: 3.5613 | Actual Loss: 1.0804\n",
      "Baseline Loss: 3.8791 | Actual Loss: 1.5400\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.0359\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.3936\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6964\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.6449\n",
      "Epoch 34/1000: Train Loss: 1.2625, Val Loss: 0.9427\n",
      "New best validation loss: 0.9427\n",
      "Baseline Loss: 3.4479 | Actual Loss: 1.1309\n",
      "Baseline Loss: 3.6919 | Actual Loss: 1.2489\n",
      "Baseline Loss: 3.5015 | Actual Loss: 0.9742\n",
      "Baseline Loss: 3.3477 | Actual Loss: 0.6051\n",
      "Baseline Loss: 3.4624 | Actual Loss: 1.3410\n",
      "Baseline Loss: 3.3501 | Actual Loss: 1.3093\n",
      "Baseline Loss: 3.6093 | Actual Loss: 1.1837\n",
      "Baseline Loss: 3.6552 | Actual Loss: 0.7884\n",
      "Baseline Loss: 3.3848 | Actual Loss: 0.9833\n",
      "Baseline Loss: 3.7625 | Actual Loss: 0.9735\n",
      "Baseline Loss: 3.4031 | Actual Loss: 1.2641\n",
      "Baseline Loss: 3.5875 | Actual Loss: 0.7590\n",
      "Baseline Loss: 3.5751 | Actual Loss: 0.8308\n",
      "Baseline Loss: 3.3306 | Actual Loss: 0.8083\n",
      "Baseline Loss: 3.4810 | Actual Loss: 0.7478\n",
      "Baseline Loss: 3.4589 | Actual Loss: 2.0497\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.0877\n",
      "Baseline Loss: 3.6229 | Actual Loss: 2.4612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 35/1000 [00:16<07:16,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5384 | Actual Loss: 0.7873\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.8269\n",
      "Epoch 35/1000: Train Loss: 1.0624, Val Loss: 1.5408\n",
      "Baseline Loss: 3.6187 | Actual Loss: 1.6530\n",
      "Baseline Loss: 3.5758 | Actual Loss: 0.8570\n",
      "Baseline Loss: 3.6055 | Actual Loss: 1.8766\n",
      "Baseline Loss: 3.6057 | Actual Loss: 2.7607\n",
      "Baseline Loss: 3.2392 | Actual Loss: 1.1190\n",
      "Baseline Loss: 3.3894 | Actual Loss: 1.0273\n",
      "Baseline Loss: 3.6011 | Actual Loss: 1.0258\n",
      "Baseline Loss: 3.4614 | Actual Loss: 1.2174\n",
      "Baseline Loss: 3.5625 | Actual Loss: 1.2519\n",
      "Baseline Loss: 3.4319 | Actual Loss: 0.8320\n",
      "Baseline Loss: 3.4103 | Actual Loss: 1.1379\n",
      "Baseline Loss: 3.4653 | Actual Loss: 1.0558\n",
      "Baseline Loss: 3.3995 | Actual Loss: 0.3942\n",
      "Baseline Loss: 3.4657 | Actual Loss: 0.6507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 36/1000 [00:16<07:39,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.9822 | Actual Loss: 0.5483\n",
      "Baseline Loss: 3.6889 | Actual Loss: 3.5502\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.7816\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.4517\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6080\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.7416\n",
      "Epoch 36/1000: Train Loss: 1.3099, Val Loss: 1.3958\n",
      "Baseline Loss: 3.4282 | Actual Loss: 0.6524\n",
      "Baseline Loss: 3.6639 | Actual Loss: 1.4933\n",
      "Baseline Loss: 3.4236 | Actual Loss: 0.9701\n",
      "Baseline Loss: 3.5966 | Actual Loss: 0.8525\n",
      "Baseline Loss: 3.5881 | Actual Loss: 1.0670\n",
      "Baseline Loss: 3.7322 | Actual Loss: 1.0531\n",
      "Baseline Loss: 3.2973 | Actual Loss: 0.9942\n",
      "Baseline Loss: 3.5416 | Actual Loss: 0.7610\n",
      "Baseline Loss: 3.2479 | Actual Loss: 1.4567\n",
      "Baseline Loss: 3.5532 | Actual Loss: 0.8554\n",
      "Baseline Loss: 3.4390 | Actual Loss: 0.9309\n",
      "Baseline Loss: 3.4359 | Actual Loss: 1.1580\n",
      "Baseline Loss: 3.5920 | Actual Loss: 1.3907\n",
      "Baseline Loss: 3.7831 | Actual Loss: 1.0042\n",
      "Baseline Loss: 3.4429 | Actual Loss: 0.3992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 37/1000 [00:17<07:15,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.0072 | Actual Loss: 0.6703\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.7698\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.5367\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.9085\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.7540\n",
      "Epoch 37/1000: Train Loss: 0.9818, Val Loss: 1.2422\n",
      "Baseline Loss: 3.4216 | Actual Loss: 0.6866\n",
      "Baseline Loss: 3.6185 | Actual Loss: 1.6811\n",
      "Baseline Loss: 3.5249 | Actual Loss: 1.1776\n",
      "Baseline Loss: 3.4935 | Actual Loss: 0.9407\n",
      "Baseline Loss: 3.3571 | Actual Loss: 1.0145\n",
      "Baseline Loss: 3.4655 | Actual Loss: 0.9672\n",
      "Baseline Loss: 3.5081 | Actual Loss: 0.5931\n",
      "Baseline Loss: 3.3234 | Actual Loss: 1.0111\n",
      "Baseline Loss: 3.6510 | Actual Loss: 1.1443\n",
      "Baseline Loss: 3.5748 | Actual Loss: 0.4842\n",
      "Baseline Loss: 3.4322 | Actual Loss: 1.0135\n",
      "Baseline Loss: 3.4660 | Actual Loss: 1.0035\n",
      "Baseline Loss: 3.6009 | Actual Loss: 1.4783\n",
      "Baseline Loss: 3.4467 | Actual Loss: 1.4973\n",
      "Baseline Loss: 3.4980 | Actual Loss: 0.5434\n",
      "Baseline Loss: 3.2115 | Actual Loss: 0.8758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 38/1000 [00:17<07:20,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7429 | Actual Loss: 1.7238\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.3250\n",
      "Baseline Loss: 3.5384 | Actual Loss: 1.0073\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.9569\n",
      "Epoch 38/1000: Train Loss: 1.0070, Val Loss: 1.2532\n",
      "Baseline Loss: 3.4468 | Actual Loss: 1.3539\n",
      "Baseline Loss: 3.3751 | Actual Loss: 0.7459\n",
      "Baseline Loss: 3.6552 | Actual Loss: 0.8329\n",
      "Baseline Loss: 3.7887 | Actual Loss: 2.2645\n",
      "Baseline Loss: 3.5124 | Actual Loss: 1.1012\n",
      "Baseline Loss: 3.5539 | Actual Loss: 0.7212\n",
      "Baseline Loss: 3.4727 | Actual Loss: 0.5565\n",
      "Baseline Loss: 3.4657 | Actual Loss: 1.0276\n",
      "Baseline Loss: 3.6643 | Actual Loss: 0.6901\n",
      "Baseline Loss: 3.6223 | Actual Loss: 2.4241\n",
      "Baseline Loss: 3.5358 | Actual Loss: 1.0985\n",
      "Baseline Loss: 3.3778 | Actual Loss: 0.4003\n",
      "Baseline Loss: 3.3479 | Actual Loss: 1.0838\n",
      "Baseline Loss: 3.3611 | Actual Loss: 0.4947\n",
      "Baseline Loss: 3.4851 | Actual Loss: 1.1993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 39/1000 [00:18<07:13,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.1950 | Actual Loss: 1.2223\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.6410\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.4677\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6784\n",
      "Baseline Loss: 3.4730 | Actual Loss: 1.5305\n",
      "Epoch 39/1000: Train Loss: 1.0760, Val Loss: 1.5794\n",
      "Baseline Loss: 3.6050 | Actual Loss: 0.8048\n",
      "Baseline Loss: 3.4920 | Actual Loss: 1.3757\n",
      "Baseline Loss: 3.5745 | Actual Loss: 0.9368\n",
      "Baseline Loss: 3.6054 | Actual Loss: 0.5354\n",
      "Baseline Loss: 3.6186 | Actual Loss: 0.9874\n",
      "Baseline Loss: 3.5250 | Actual Loss: 0.7499\n",
      "Baseline Loss: 3.3851 | Actual Loss: 1.1421\n",
      "Baseline Loss: 3.4931 | Actual Loss: 0.3968\n",
      "Baseline Loss: 3.4580 | Actual Loss: 0.8871\n",
      "Baseline Loss: 3.7940 | Actual Loss: 1.1826\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.3085\n",
      "Baseline Loss: 3.3715 | Actual Loss: 1.4307\n",
      "Baseline Loss: 3.3611 | Actual Loss: 1.1992\n",
      "Baseline Loss: 3.4030 | Actual Loss: 1.0246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 40/1000 [00:18<07:20,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4313 | Actual Loss: 1.0538\n",
      "Baseline Loss: 3.5091 | Actual Loss: 0.4018\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.5236\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.2715\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.7371\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.7180\n",
      "Epoch 40/1000: Train Loss: 0.9636, Val Loss: 1.0625\n",
      "Baseline Loss: 3.5409 | Actual Loss: 0.9414\n",
      "Baseline Loss: 3.5285 | Actual Loss: 0.7539\n",
      "Baseline Loss: 3.3198 | Actual Loss: 0.7822\n",
      "Baseline Loss: 3.6875 | Actual Loss: 1.0120\n",
      "Baseline Loss: 3.4814 | Actual Loss: 1.9682\n",
      "Baseline Loss: 3.5537 | Actual Loss: 1.1437\n",
      "Baseline Loss: 3.7166 | Actual Loss: 1.7272\n",
      "Baseline Loss: 3.4969 | Actual Loss: 1.4045\n",
      "Baseline Loss: 3.5375 | Actual Loss: 1.0391\n",
      "Baseline Loss: 3.3269 | Actual Loss: 1.0047\n",
      "Baseline Loss: 3.5459 | Actual Loss: 1.3511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 41/1000 [00:19<07:30,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4656 | Actual Loss: 0.9048\n",
      "Baseline Loss: 3.5535 | Actual Loss: 0.6334\n",
      "Baseline Loss: 3.5132 | Actual Loss: 0.6918\n",
      "Baseline Loss: 3.5624 | Actual Loss: 0.9288\n",
      "Baseline Loss: 3.1660 | Actual Loss: 4.0328\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.8676\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.4202\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.5368\n",
      "Baseline Loss: 3.4730 | Actual Loss: 1.0536\n",
      "Epoch 41/1000: Train Loss: 1.2700, Val Loss: 1.2195\n",
      "Baseline Loss: 3.3791 | Actual Loss: 0.9236\n",
      "Baseline Loss: 3.7889 | Actual Loss: 1.1994\n",
      "Baseline Loss: 3.3344 | Actual Loss: 1.0100\n",
      "Baseline Loss: 3.4932 | Actual Loss: 2.1212\n",
      "Baseline Loss: 3.4975 | Actual Loss: 1.2932\n",
      "Baseline Loss: 3.4966 | Actual Loss: 0.6756\n",
      "Baseline Loss: 3.6684 | Actual Loss: 0.5764\n",
      "Baseline Loss: 3.4135 | Actual Loss: 1.0408\n",
      "Baseline Loss: 3.5705 | Actual Loss: 0.4998\n",
      "Baseline Loss: 3.4440 | Actual Loss: 0.8481\n",
      "Baseline Loss: 3.5505 | Actual Loss: 0.7783\n",
      "Baseline Loss: 3.4957 | Actual Loss: 1.1166\n",
      "Baseline Loss: 3.5167 | Actual Loss: 0.7453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 42/1000 [00:19<07:17,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3638 | Actual Loss: 0.9541\n",
      "Baseline Loss: 3.4402 | Actual Loss: 0.7480\n",
      "Baseline Loss: 3.4210 | Actual Loss: 1.9649\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.0752\n",
      "Baseline Loss: 3.6229 | Actual Loss: 2.9097\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6283\n",
      "Baseline Loss: 3.4730 | Actual Loss: 2.1061\n",
      "Epoch 42/1000: Train Loss: 1.0310, Val Loss: 1.9298\n",
      "Baseline Loss: 3.4965 | Actual Loss: 1.0670\n",
      "Baseline Loss: 3.4765 | Actual Loss: 1.0051\n",
      "Baseline Loss: 3.4733 | Actual Loss: 0.7729\n",
      "Baseline Loss: 3.5459 | Actual Loss: 0.7688\n",
      "Baseline Loss: 3.5960 | Actual Loss: 1.4559\n",
      "Baseline Loss: 3.6555 | Actual Loss: 0.8549\n",
      "Baseline Loss: 3.3451 | Actual Loss: 0.9940\n",
      "Baseline Loss: 3.3379 | Actual Loss: 0.5531\n",
      "Baseline Loss: 3.5134 | Actual Loss: 0.7644\n",
      "Baseline Loss: 3.4889 | Actual Loss: 1.6315\n",
      "Baseline Loss: 3.5793 | Actual Loss: 0.6290\n",
      "Baseline Loss: 3.5794 | Actual Loss: 0.7859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 43/1000 [00:20<07:21,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7629 | Actual Loss: 1.2590\n",
      "Baseline Loss: 3.5705 | Actual Loss: 1.5903\n",
      "Baseline Loss: 3.5575 | Actual Loss: 0.8432\n",
      "Baseline Loss: 3.3313 | Actual Loss: 1.0762\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.2846\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.0438\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.8332\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.9872\n",
      "Epoch 43/1000: Train Loss: 1.0032, Val Loss: 1.0372\n",
      "Baseline Loss: 3.4388 | Actual Loss: 0.8849\n",
      "Baseline Loss: 3.5923 | Actual Loss: 0.7392\n",
      "Baseline Loss: 3.4736 | Actual Loss: 0.7588\n",
      "Baseline Loss: 3.2277 | Actual Loss: 1.0808\n",
      "Baseline Loss: 3.6315 | Actual Loss: 0.7180\n",
      "Baseline Loss: 3.5126 | Actual Loss: 0.7598\n",
      "Baseline Loss: 3.6542 | Actual Loss: 1.3845\n",
      "Baseline Loss: 3.4816 | Actual Loss: 0.6233\n",
      "Baseline Loss: 3.4581 | Actual Loss: 1.0455\n",
      "Baseline Loss: 3.5006 | Actual Loss: 1.4455\n",
      "Baseline Loss: 3.4584 | Actual Loss: 1.1709\n",
      "Baseline Loss: 3.4660 | Actual Loss: 1.2833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 44/1000 [00:20<07:29,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5840 | Actual Loss: 1.0614\n",
      "Baseline Loss: 3.5332 | Actual Loss: 0.8433\n",
      "Baseline Loss: 3.6358 | Actual Loss: 1.1580\n",
      "Baseline Loss: 3.2121 | Actual Loss: 0.6595\n",
      "Baseline Loss: 3.7429 | Actual Loss: 3.0935\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.6782\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.7572\n",
      "Baseline Loss: 3.4730 | Actual Loss: 1.1403\n",
      "Epoch 44/1000: Train Loss: 0.9760, Val Loss: 1.6673\n",
      "Baseline Loss: 3.4632 | Actual Loss: 0.9043\n",
      "Baseline Loss: 3.3546 | Actual Loss: 0.8710\n",
      "Baseline Loss: 3.5533 | Actual Loss: 1.1736\n",
      "Baseline Loss: 3.3919 | Actual Loss: 0.7888\n",
      "Baseline Loss: 3.3851 | Actual Loss: 1.1611\n",
      "Baseline Loss: 3.8209 | Actual Loss: 1.0092\n",
      "Baseline Loss: 3.7776 | Actual Loss: 1.4101\n",
      "Baseline Loss: 3.5244 | Actual Loss: 0.4998\n",
      "Baseline Loss: 3.3111 | Actual Loss: 0.8337\n",
      "Baseline Loss: 3.6549 | Actual Loss: 1.1327\n",
      "Baseline Loss: 3.4898 | Actual Loss: 1.0490\n",
      "Baseline Loss: 3.3745 | Actual Loss: 0.6214\n",
      "Baseline Loss: 3.5247 | Actual Loss: 1.0491\n",
      "Baseline Loss: 3.3636 | Actual Loss: 0.9625\n",
      "Baseline Loss: 3.6929 | Actual Loss: 0.9326\n",
      "Baseline Loss: 3.2653 | Actual Loss: 0.3546\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.0123\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.7924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 45/1000 [00:21<07:37,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5384 | Actual Loss: 0.6102\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.8679\n",
      "Epoch 45/1000: Train Loss: 0.9221, Val Loss: 1.3207\n",
      "Baseline Loss: 3.4655 | Actual Loss: 0.5637\n",
      "Baseline Loss: 3.5170 | Actual Loss: 2.9727\n",
      "Baseline Loss: 3.3936 | Actual Loss: 0.9234\n",
      "Baseline Loss: 3.3204 | Actual Loss: 0.8438\n",
      "Baseline Loss: 3.6223 | Actual Loss: 0.4534\n",
      "Baseline Loss: 3.3906 | Actual Loss: 0.6342\n",
      "Baseline Loss: 3.6594 | Actual Loss: 0.9987\n",
      "Baseline Loss: 3.7417 | Actual Loss: 0.9684\n",
      "Baseline Loss: 3.4847 | Actual Loss: 0.4520\n",
      "Baseline Loss: 3.6642 | Actual Loss: 0.9292\n",
      "Baseline Loss: 3.4849 | Actual Loss: 0.7064\n",
      "Baseline Loss: 3.5080 | Actual Loss: 1.2977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 46/1000 [00:21<07:51,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6228 | Actual Loss: 0.7293\n",
      "Baseline Loss: 3.3107 | Actual Loss: 0.8140\n",
      "Baseline Loss: 3.3781 | Actual Loss: 1.4701\n",
      "Baseline Loss: 3.3397 | Actual Loss: 0.7939\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.9178\n",
      "Baseline Loss: 3.6229 | Actual Loss: 3.6361\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.4757\n",
      "Baseline Loss: 3.4730 | Actual Loss: 1.2124\n",
      "Epoch 46/1000: Train Loss: 0.9719, Val Loss: 1.8105\n",
      "Baseline Loss: 3.4583 | Actual Loss: 0.8536\n",
      "Baseline Loss: 3.7018 | Actual Loss: 1.2334\n",
      "Baseline Loss: 3.4131 | Actual Loss: 1.5713\n",
      "Baseline Loss: 3.5489 | Actual Loss: 0.5583\n",
      "Baseline Loss: 3.5008 | Actual Loss: 1.0203\n",
      "Baseline Loss: 3.5092 | Actual Loss: 0.8513\n",
      "Baseline Loss: 3.4544 | Actual Loss: 0.7855\n",
      "Baseline Loss: 3.3895 | Actual Loss: 1.2442\n",
      "Baseline Loss: 3.3758 | Actual Loss: 1.0884\n",
      "Baseline Loss: 3.6049 | Actual Loss: 0.6143\n",
      "Baseline Loss: 3.3748 | Actual Loss: 1.1583\n",
      "Baseline Loss: 3.4884 | Actual Loss: 0.7257\n",
      "Baseline Loss: 3.6367 | Actual Loss: 0.5707\n",
      "Baseline Loss: 3.3749 | Actual Loss: 1.4201\n",
      "Baseline Loss: 3.4177 | Actual Loss: 1.1840\n",
      "Baseline Loss: 3.1962 | Actual Loss: 1.0506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 47/1000 [00:22<08:18,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7429 | Actual Loss: 1.1972\n",
      "Baseline Loss: 3.6229 | Actual Loss: 2.2085\n",
      "Baseline Loss: 3.5384 | Actual Loss: 1.1205\n",
      "Baseline Loss: 3.4730 | Actual Loss: 1.0779\n",
      "Epoch 47/1000: Train Loss: 0.9956, Val Loss: 1.4010\n",
      "Baseline Loss: 3.8608 | Actual Loss: 1.9283\n",
      "Baseline Loss: 3.4934 | Actual Loss: 1.0582\n",
      "Baseline Loss: 3.3173 | Actual Loss: 1.1722\n",
      "Baseline Loss: 3.3739 | Actual Loss: 0.9066\n",
      "Baseline Loss: 3.6361 | Actual Loss: 1.2365\n",
      "Baseline Loss: 3.4127 | Actual Loss: 0.9050\n",
      "Baseline Loss: 3.5927 | Actual Loss: 0.6452\n",
      "Baseline Loss: 3.2611 | Actual Loss: 0.8414\n",
      "Baseline Loss: 3.6504 | Actual Loss: 1.2776\n",
      "Baseline Loss: 3.6320 | Actual Loss: 0.5924\n",
      "Baseline Loss: 3.3164 | Actual Loss: 1.4204\n",
      "Baseline Loss: 3.3857 | Actual Loss: 0.7737\n",
      "Baseline Loss: 3.6003 | Actual Loss: 1.2023\n",
      "Baseline Loss: 3.6177 | Actual Loss: 0.7812\n",
      "Baseline Loss: 3.5574 | Actual Loss: 1.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 48/1000 [00:22<07:56,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.0371 | Actual Loss: 0.4545\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.6269\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.3783\n",
      "Baseline Loss: 3.5384 | Actual Loss: 1.0650\n",
      "Baseline Loss: 3.4730 | Actual Loss: 1.0241\n",
      "Epoch 48/1000: Train Loss: 1.0199, Val Loss: 1.2736\n",
      "Baseline Loss: 3.4171 | Actual Loss: 0.9260\n",
      "Baseline Loss: 3.5537 | Actual Loss: 1.4031\n",
      "Baseline Loss: 3.4626 | Actual Loss: 0.9510\n",
      "Baseline Loss: 3.6510 | Actual Loss: 0.8302\n",
      "Baseline Loss: 3.4776 | Actual Loss: 1.0357\n",
      "Baseline Loss: 3.6230 | Actual Loss: 0.7098\n",
      "Baseline Loss: 3.4218 | Actual Loss: 0.7000\n",
      "Baseline Loss: 3.5411 | Actual Loss: 0.5124\n",
      "Baseline Loss: 3.7832 | Actual Loss: 0.7312\n",
      "Baseline Loss: 3.2119 | Actual Loss: 1.0545\n",
      "Baseline Loss: 3.4767 | Actual Loss: 0.8210\n",
      "Baseline Loss: 3.4502 | Actual Loss: 0.9489\n",
      "Baseline Loss: 3.7076 | Actual Loss: 0.7277\n",
      "Baseline Loss: 3.4810 | Actual Loss: 1.1175\n",
      "Baseline Loss: 3.3651 | Actual Loss: 0.6966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 49/1000 [00:23<08:29,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.0598 | Actual Loss: 2.1848\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.5305\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.4445\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.8903\n",
      "Baseline Loss: 3.4730 | Actual Loss: 1.0398\n",
      "Epoch 49/1000: Train Loss: 0.9594, Val Loss: 1.2263\n",
      "Baseline Loss: 3.4773 | Actual Loss: 0.8515\n",
      "Baseline Loss: 3.4278 | Actual Loss: 1.0220\n",
      "Baseline Loss: 3.5836 | Actual Loss: 1.1599\n",
      "Baseline Loss: 3.4544 | Actual Loss: 0.9918\n",
      "Baseline Loss: 3.8051 | Actual Loss: 1.4456\n",
      "Baseline Loss: 3.4628 | Actual Loss: 0.6488\n",
      "Baseline Loss: 3.5414 | Actual Loss: 0.9413\n",
      "Baseline Loss: 3.4763 | Actual Loss: 0.7566\n",
      "Baseline Loss: 3.6453 | Actual Loss: 0.8782\n",
      "Baseline Loss: 3.3650 | Actual Loss: 1.5390\n",
      "Baseline Loss: 3.6142 | Actual Loss: 1.5620\n",
      "Baseline Loss: 3.3441 | Actual Loss: 1.1171\n",
      "Baseline Loss: 3.4981 | Actual Loss: 0.7523\n",
      "Baseline Loss: 3.2580 | Actual Loss: 0.9196\n",
      "Baseline Loss: 3.5248 | Actual Loss: 0.7753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 50/1000 [00:23<08:01,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5730 | Actual Loss: 3.0438\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.5198\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.5100\n",
      "Baseline Loss: 3.5384 | Actual Loss: 1.2964\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.8809\n",
      "Epoch 50/1000: Train Loss: 1.1503, Val Loss: 1.3018\n",
      "Baseline Loss: 3.5166 | Actual Loss: 1.1714\n",
      "Baseline Loss: 3.9197 | Actual Loss: 0.7496\n",
      "Baseline Loss: 3.4097 | Actual Loss: 0.7966\n",
      "Baseline Loss: 3.4855 | Actual Loss: 0.9922\n",
      "Baseline Loss: 3.6462 | Actual Loss: 0.7107\n",
      "Baseline Loss: 3.3402 | Actual Loss: 0.8453\n",
      "Baseline Loss: 3.4545 | Actual Loss: 0.9710\n",
      "Baseline Loss: 3.5209 | Actual Loss: 0.7520\n",
      "Baseline Loss: 3.5118 | Actual Loss: 1.1337\n",
      "Baseline Loss: 3.5795 | Actual Loss: 0.7134\n",
      "Baseline Loss: 3.2830 | Actual Loss: 1.0508\n",
      "Baseline Loss: 3.5866 | Actual Loss: 0.5983\n",
      "Baseline Loss: 3.3274 | Actual Loss: 1.0013\n",
      "Baseline Loss: 3.3469 | Actual Loss: 0.7323\n",
      "Baseline Loss: 3.5619 | Actual Loss: 0.9536\n",
      "Baseline Loss: 3.5720 | Actual Loss: 0.1563\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.5215\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.5763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 51/1000 [00:24<08:15,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5384 | Actual Loss: 0.6426\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.4014\n",
      "Epoch 51/1000: Train Loss: 0.8330, Val Loss: 1.2854\n",
      "Baseline Loss: 3.6226 | Actual Loss: 0.7438\n",
      "Baseline Loss: 3.5248 | Actual Loss: 0.6221\n",
      "Baseline Loss: 3.6731 | Actual Loss: 0.8174\n",
      "Baseline Loss: 3.5167 | Actual Loss: 0.8045\n",
      "Baseline Loss: 3.4537 | Actual Loss: 1.2637\n",
      "Baseline Loss: 3.4271 | Actual Loss: 1.2717\n",
      "Baseline Loss: 3.2481 | Actual Loss: 1.1998\n",
      "Baseline Loss: 3.4141 | Actual Loss: 1.5169\n",
      "Baseline Loss: 3.8484 | Actual Loss: 0.5939\n",
      "Baseline Loss: 3.4430 | Actual Loss: 1.0511\n",
      "Baseline Loss: 3.4136 | Actual Loss: 0.8672\n",
      "Baseline Loss: 3.4765 | Actual Loss: 1.1781\n",
      "Baseline Loss: 3.3472 | Actual Loss: 0.9791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 52/1000 [00:24<08:33,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4174 | Actual Loss: 0.6390\n",
      "Baseline Loss: 3.7827 | Actual Loss: 2.6518\n",
      "Baseline Loss: 3.2427 | Actual Loss: 1.2244\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.2324\n",
      "Baseline Loss: 3.6229 | Actual Loss: 2.0364\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.5624\n",
      "Baseline Loss: 3.4730 | Actual Loss: 2.7751\n",
      "Epoch 52/1000: Train Loss: 1.0890, Val Loss: 1.9016\n",
      "Baseline Loss: 3.4025 | Actual Loss: 0.5364\n",
      "Baseline Loss: 3.5667 | Actual Loss: 0.8539\n",
      "Baseline Loss: 3.4622 | Actual Loss: 0.4820\n",
      "Baseline Loss: 3.4151 | Actual Loss: 0.6841\n",
      "Baseline Loss: 3.6228 | Actual Loss: 1.4327\n",
      "Baseline Loss: 3.5036 | Actual Loss: 1.2833\n",
      "Baseline Loss: 3.5088 | Actual Loss: 2.4569\n",
      "Baseline Loss: 3.3543 | Actual Loss: 0.7442\n",
      "Baseline Loss: 3.5581 | Actual Loss: 0.4631\n",
      "Baseline Loss: 3.4256 | Actual Loss: 0.6060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 53/1000 [00:25<08:09,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4316 | Actual Loss: 0.9123\n",
      "Baseline Loss: 3.5415 | Actual Loss: 1.6525\n",
      "Baseline Loss: 3.5572 | Actual Loss: 1.0300\n",
      "Baseline Loss: 3.4660 | Actual Loss: 1.1074\n",
      "Baseline Loss: 3.4579 | Actual Loss: 0.8127\n",
      "Baseline Loss: 3.2826 | Actual Loss: 0.7245\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.3374\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.3436\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.9945\n",
      "Baseline Loss: 3.4730 | Actual Loss: 1.1925\n",
      "Epoch 53/1000: Train Loss: 0.9864, Val Loss: 1.2170\n",
      "Baseline Loss: 3.7580 | Actual Loss: 0.9373\n",
      "Baseline Loss: 3.6101 | Actual Loss: 1.0053\n",
      "Baseline Loss: 3.4063 | Actual Loss: 0.8666\n",
      "Baseline Loss: 3.2156 | Actual Loss: 1.4145\n",
      "Baseline Loss: 3.5249 | Actual Loss: 0.9422\n",
      "Baseline Loss: 3.6504 | Actual Loss: 0.9888\n",
      "Baseline Loss: 3.3574 | Actual Loss: 0.7238\n",
      "Baseline Loss: 3.5916 | Actual Loss: 1.3154\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.9328\n",
      "Baseline Loss: 3.3540 | Actual Loss: 0.5095\n",
      "Baseline Loss: 3.4885 | Actual Loss: 0.7556\n",
      "Baseline Loss: 3.6730 | Actual Loss: 0.7392\n",
      "Baseline Loss: 3.3993 | Actual Loss: 0.7184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 54/1000 [00:25<08:33,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4734 | Actual Loss: 0.9295\n",
      "Baseline Loss: 3.3856 | Actual Loss: 0.7171\n",
      "Baseline Loss: 3.5838 | Actual Loss: 0.9797\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.0420\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.0548\n",
      "Baseline Loss: 3.5384 | Actual Loss: 1.0440\n",
      "Baseline Loss: 3.4730 | Actual Loss: 1.0516\n",
      "Epoch 54/1000: Train Loss: 0.9047, Val Loss: 1.0481\n",
      "Baseline Loss: 3.7677 | Actual Loss: 2.0304\n",
      "Baseline Loss: 3.5366 | Actual Loss: 0.8160\n",
      "Baseline Loss: 3.2699 | Actual Loss: 0.9514\n",
      "Baseline Loss: 3.5834 | Actual Loss: 1.3897\n",
      "Baseline Loss: 3.5495 | Actual Loss: 1.0844\n",
      "Baseline Loss: 3.5880 | Actual Loss: 0.4242\n",
      "Baseline Loss: 3.3241 | Actual Loss: 1.9141\n",
      "Baseline Loss: 3.3225 | Actual Loss: 1.2029\n",
      "Baseline Loss: 3.7892 | Actual Loss: 2.1196\n",
      "Baseline Loss: 3.4655 | Actual Loss: 0.8161\n",
      "Baseline Loss: 3.5828 | Actual Loss: 1.2796\n",
      "Baseline Loss: 3.5751 | Actual Loss: 0.5725\n",
      "Baseline Loss: 3.4250 | Actual Loss: 0.9605\n",
      "Baseline Loss: 3.3857 | Actual Loss: 0.7715\n",
      "Baseline Loss: 3.5494 | Actual Loss: 0.7755\n",
      "Baseline Loss: 3.3833 | Actual Loss: 0.3717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 55/1000 [00:26<08:37,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7429 | Actual Loss: 1.8488\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.9721\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.7663\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.7273\n",
      "Epoch 55/1000: Train Loss: 1.0925, Val Loss: 1.0786\n",
      "Baseline Loss: 3.4547 | Actual Loss: 0.8316\n",
      "Baseline Loss: 3.3820 | Actual Loss: 1.1686\n",
      "Baseline Loss: 3.5089 | Actual Loss: 1.1214\n",
      "Baseline Loss: 3.5703 | Actual Loss: 0.5946\n",
      "Baseline Loss: 3.6787 | Actual Loss: 0.9253\n",
      "Baseline Loss: 3.4350 | Actual Loss: 0.8137\n",
      "Baseline Loss: 3.4426 | Actual Loss: 1.5985\n",
      "Baseline Loss: 3.3960 | Actual Loss: 0.4361\n",
      "Baseline Loss: 3.4879 | Actual Loss: 1.1980\n",
      "Baseline Loss: 3.7631 | Actual Loss: 0.5672\n",
      "Baseline Loss: 3.4549 | Actual Loss: 1.3602\n",
      "Baseline Loss: 3.5793 | Actual Loss: 0.7551\n",
      "Baseline Loss: 3.5962 | Actual Loss: 1.1782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 56/1000 [00:26<08:08,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4319 | Actual Loss: 0.5931\n",
      "Baseline Loss: 3.5587 | Actual Loss: 0.9543\n",
      "Baseline Loss: 3.4685 | Actual Loss: 0.6369\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.7398\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.3961\n",
      "Baseline Loss: 3.5384 | Actual Loss: 1.1946\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.7453\n",
      "Epoch 56/1000: Train Loss: 0.9208, Val Loss: 1.2689\n",
      "Baseline Loss: 3.3086 | Actual Loss: 0.8295\n",
      "Baseline Loss: 3.4434 | Actual Loss: 1.0618\n",
      "Baseline Loss: 3.4029 | Actual Loss: 1.4425\n",
      "Baseline Loss: 3.3878 | Actual Loss: 0.5828\n",
      "Baseline Loss: 3.6878 | Actual Loss: 0.9689\n",
      "Baseline Loss: 3.4695 | Actual Loss: 0.6786\n",
      "Baseline Loss: 3.5574 | Actual Loss: 0.8316\n",
      "Baseline Loss: 3.4584 | Actual Loss: 0.6506\n",
      "Baseline Loss: 3.5179 | Actual Loss: 0.8666\n",
      "Baseline Loss: 3.5371 | Actual Loss: 0.7992\n",
      "Baseline Loss: 3.5624 | Actual Loss: 2.3886\n",
      "Baseline Loss: 3.6407 | Actual Loss: 0.6761\n",
      "Baseline Loss: 3.6684 | Actual Loss: 0.9338\n",
      "Baseline Loss: 3.5623 | Actual Loss: 0.6768\n",
      "Baseline Loss: 3.6016 | Actual Loss: 1.1156\n",
      "Baseline Loss: 3.1476 | Actual Loss: 0.3592\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.6882\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.1261\n",
      "Baseline Loss: 3.5384 | Actual Loss: 1.2660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 57/1000 [00:27<08:34,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4730 | Actual Loss: 0.7297\n",
      "Epoch 57/1000: Train Loss: 0.9289, Val Loss: 1.2025\n",
      "Baseline Loss: 3.7418 | Actual Loss: 1.1915\n",
      "Baseline Loss: 3.3751 | Actual Loss: 0.8381\n",
      "Baseline Loss: 3.4657 | Actual Loss: 1.0969\n",
      "Baseline Loss: 3.4357 | Actual Loss: 1.2389\n",
      "Baseline Loss: 3.5699 | Actual Loss: 0.7256\n",
      "Baseline Loss: 3.3021 | Actual Loss: 1.0815\n",
      "Baseline Loss: 3.4431 | Actual Loss: 0.4693\n",
      "Baseline Loss: 3.6644 | Actual Loss: 0.8300\n",
      "Baseline Loss: 3.4671 | Actual Loss: 0.9220\n",
      "Baseline Loss: 3.6875 | Actual Loss: 1.4348\n",
      "Baseline Loss: 3.5919 | Actual Loss: 1.1372\n",
      "Baseline Loss: 3.5404 | Actual Loss: 0.8849\n",
      "Baseline Loss: 3.4179 | Actual Loss: 0.9515\n",
      "Baseline Loss: 3.4810 | Actual Loss: 1.1610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 58/1000 [00:28<08:43,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3713 | Actual Loss: 1.0285\n",
      "Baseline Loss: 3.0393 | Actual Loss: 0.5692\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.7703\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.5562\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.8240\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.7187\n",
      "Epoch 58/1000: Train Loss: 0.9725, Val Loss: 1.2173\n",
      "Baseline Loss: 3.4772 | Actual Loss: 1.0286\n",
      "Baseline Loss: 3.6547 | Actual Loss: 1.4539\n",
      "Baseline Loss: 3.3409 | Actual Loss: 0.7216\n",
      "Baseline Loss: 3.6142 | Actual Loss: 0.8266\n",
      "Baseline Loss: 3.3675 | Actual Loss: 0.5095\n",
      "Baseline Loss: 3.4776 | Actual Loss: 1.2173\n",
      "Baseline Loss: 3.4740 | Actual Loss: 0.8648\n",
      "Baseline Loss: 3.4071 | Actual Loss: 0.6710\n",
      "Baseline Loss: 3.4390 | Actual Loss: 1.0927\n",
      "Baseline Loss: 3.3535 | Actual Loss: 1.0485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 59/1000 [00:28<08:11,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3955 | Actual Loss: 0.5361\n",
      "Baseline Loss: 3.7629 | Actual Loss: 0.5316\n",
      "Baseline Loss: 3.5782 | Actual Loss: 0.8411\n",
      "Baseline Loss: 3.6044 | Actual Loss: 2.8686\n",
      "Baseline Loss: 3.3993 | Actual Loss: 0.8619\n",
      "Baseline Loss: 3.4894 | Actual Loss: 0.3703\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.1906\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.5057\n",
      "Baseline Loss: 3.5384 | Actual Loss: 1.1775\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.4689\n",
      "Epoch 59/1000: Train Loss: 0.9653, Val Loss: 1.0857\n",
      "Baseline Loss: 3.7571 | Actual Loss: 1.1149\n",
      "Baseline Loss: 3.4729 | Actual Loss: 1.4340\n",
      "Baseline Loss: 3.4062 | Actual Loss: 1.1267\n",
      "Baseline Loss: 3.4548 | Actual Loss: 0.9098\n",
      "Baseline Loss: 3.4585 | Actual Loss: 0.9339\n",
      "Baseline Loss: 3.6002 | Actual Loss: 1.0963\n",
      "Baseline Loss: 3.6600 | Actual Loss: 0.9007\n",
      "Baseline Loss: 3.5792 | Actual Loss: 0.8479\n",
      "Baseline Loss: 3.4401 | Actual Loss: 1.0162\n",
      "Baseline Loss: 3.4329 | Actual Loss: 0.6840\n",
      "Baseline Loss: 3.8317 | Actual Loss: 0.9900\n",
      "Baseline Loss: 3.4100 | Actual Loss: 1.4056\n",
      "Baseline Loss: 3.3751 | Actual Loss: 0.3800\n",
      "Baseline Loss: 3.4136 | Actual Loss: 0.4427\n",
      "Baseline Loss: 3.2834 | Actual Loss: 1.4942\n",
      "Baseline Loss: 3.2345 | Actual Loss: 0.7228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 60/1000 [00:29<08:16,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7429 | Actual Loss: 2.1428\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.3381\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.7924\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.6994\n",
      "Epoch 60/1000: Train Loss: 0.9687, Val Loss: 1.2432\n",
      "Baseline Loss: 3.5051 | Actual Loss: 0.8907\n",
      "Baseline Loss: 3.5250 | Actual Loss: 0.9865\n",
      "Baseline Loss: 3.5375 | Actual Loss: 0.8407\n",
      "Baseline Loss: 3.4511 | Actual Loss: 1.1587\n",
      "Baseline Loss: 3.6642 | Actual Loss: 0.4251\n",
      "Baseline Loss: 3.3582 | Actual Loss: 0.8209\n",
      "Baseline Loss: 3.3645 | Actual Loss: 0.8428\n",
      "Baseline Loss: 3.3960 | Actual Loss: 1.0770\n",
      "Baseline Loss: 3.2970 | Actual Loss: 0.5586\n",
      "Baseline Loss: 3.5255 | Actual Loss: 1.0220\n",
      "Baseline Loss: 3.4124 | Actual Loss: 0.8027\n",
      "Baseline Loss: 3.5491 | Actual Loss: 1.1502\n",
      "Baseline Loss: 3.3686 | Actual Loss: 0.8080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 61/1000 [00:29<08:27,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6503 | Actual Loss: 0.9338\n",
      "Baseline Loss: 3.6321 | Actual Loss: 0.5733\n",
      "Baseline Loss: 3.5091 | Actual Loss: 0.4086\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.5165\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.1019\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.7384\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.5210\n",
      "Epoch 61/1000: Train Loss: 0.8312, Val Loss: 1.2194\n",
      "Baseline Loss: 3.3925 | Actual Loss: 0.6055\n",
      "Baseline Loss: 3.4507 | Actual Loss: 0.6551\n",
      "Baseline Loss: 3.5793 | Actual Loss: 2.0642\n",
      "Baseline Loss: 3.4926 | Actual Loss: 0.9967\n",
      "Baseline Loss: 3.7526 | Actual Loss: 0.6719\n",
      "Baseline Loss: 3.4327 | Actual Loss: 1.6410\n",
      "Baseline Loss: 3.4665 | Actual Loss: 1.1776\n",
      "Baseline Loss: 3.5047 | Actual Loss: 1.3769\n",
      "Baseline Loss: 3.4308 | Actual Loss: 1.0995\n",
      "Baseline Loss: 3.5421 | Actual Loss: 0.5529\n",
      "Baseline Loss: 3.3654 | Actual Loss: 0.9170\n",
      "Baseline Loss: 3.5578 | Actual Loss: 0.6692\n",
      "Baseline Loss: 3.6016 | Actual Loss: 0.9896\n",
      "Baseline Loss: 3.3885 | Actual Loss: 1.1739\n",
      "Baseline Loss: 3.5747 | Actual Loss: 0.8206\n",
      "Baseline Loss: 2.9377 | Actual Loss: 0.4724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 62/1000 [00:30<08:20,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7429 | Actual Loss: 2.3374\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.1159\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.7296\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.3338\n",
      "Epoch 62/1000: Train Loss: 0.9927, Val Loss: 1.1292\n",
      "Baseline Loss: 3.6693 | Actual Loss: 2.0377\n",
      "Baseline Loss: 3.2921 | Actual Loss: 1.0232\n",
      "Baseline Loss: 3.6086 | Actual Loss: 0.7762\n",
      "Baseline Loss: 3.5411 | Actual Loss: 1.2919\n",
      "Baseline Loss: 3.3779 | Actual Loss: 2.3191\n",
      "Baseline Loss: 3.2793 | Actual Loss: 0.6846\n",
      "Baseline Loss: 3.5835 | Actual Loss: 0.1486\n",
      "Baseline Loss: 3.5743 | Actual Loss: 0.6026\n",
      "Baseline Loss: 3.3972 | Actual Loss: 1.3687\n",
      "Baseline Loss: 3.4465 | Actual Loss: 0.8974\n",
      "Baseline Loss: 3.7167 | Actual Loss: 1.0218\n",
      "Baseline Loss: 3.6698 | Actual Loss: 0.7239\n",
      "Baseline Loss: 3.4103 | Actual Loss: 0.7428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 63/1000 [00:30<08:32,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5573 | Actual Loss: 0.9944\n",
      "Baseline Loss: 3.4350 | Actual Loss: 1.0812\n",
      "Baseline Loss: 3.0451 | Actual Loss: 0.5322\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.9004\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.3528\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6822\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.3764\n",
      "Epoch 63/1000: Train Loss: 1.0154, Val Loss: 1.0779\n",
      "Baseline Loss: 3.3926 | Actual Loss: 0.4948\n",
      "Baseline Loss: 3.5662 | Actual Loss: 0.6742\n",
      "Baseline Loss: 3.5919 | Actual Loss: 0.7602\n",
      "Baseline Loss: 3.4360 | Actual Loss: 0.9194\n",
      "Baseline Loss: 3.3358 | Actual Loss: 1.9542\n",
      "Baseline Loss: 3.3675 | Actual Loss: 0.9452\n",
      "Baseline Loss: 3.7367 | Actual Loss: 1.6835\n",
      "Baseline Loss: 3.5917 | Actual Loss: 0.7446\n",
      "Baseline Loss: 3.7265 | Actual Loss: 1.7712\n",
      "Baseline Loss: 3.5451 | Actual Loss: 0.7971\n",
      "Baseline Loss: 3.5085 | Actual Loss: 0.4044\n",
      "Baseline Loss: 3.6451 | Actual Loss: 0.6454\n",
      "Baseline Loss: 3.7466 | Actual Loss: 1.4092\n",
      "Baseline Loss: 3.3251 | Actual Loss: 0.8678\n",
      "Baseline Loss: 3.4403 | Actual Loss: 0.5705\n",
      "Baseline Loss: 2.9893 | Actual Loss: 0.4896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 64/1000 [00:31<08:25,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7429 | Actual Loss: 2.3769\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.2063\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6827\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.3649\n",
      "Epoch 64/1000: Train Loss: 0.9457, Val Loss: 1.1577\n",
      "Baseline Loss: 3.5746 | Actual Loss: 2.3183\n",
      "Baseline Loss: 3.5959 | Actual Loss: 0.6325\n",
      "Baseline Loss: 3.5362 | Actual Loss: 0.9080\n",
      "Baseline Loss: 3.3232 | Actual Loss: 1.6609\n",
      "Baseline Loss: 3.7214 | Actual Loss: 1.5086\n",
      "Baseline Loss: 3.6366 | Actual Loss: 1.0936\n",
      "Baseline Loss: 3.4736 | Actual Loss: 0.6894\n",
      "Baseline Loss: 3.6046 | Actual Loss: 0.7997\n",
      "Baseline Loss: 3.4574 | Actual Loss: 0.9215\n",
      "Baseline Loss: 3.5908 | Actual Loss: 0.7973\n",
      "Baseline Loss: 3.5092 | Actual Loss: 0.6591\n",
      "Baseline Loss: 3.2522 | Actual Loss: 0.5954\n",
      "Baseline Loss: 3.5703 | Actual Loss: 0.9029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 65/1000 [00:31<08:34,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5081 | Actual Loss: 2.3134\n",
      "Baseline Loss: 3.3255 | Actual Loss: 0.7271\n",
      "Baseline Loss: 3.6066 | Actual Loss: 0.6547\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.0205\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.5221\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6293\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.4043\n",
      "Epoch 65/1000: Train Loss: 1.0739, Val Loss: 1.1441\n",
      "Baseline Loss: 3.3747 | Actual Loss: 0.7226\n",
      "Baseline Loss: 3.6095 | Actual Loss: 1.1177\n",
      "Baseline Loss: 3.4657 | Actual Loss: 1.0781\n",
      "Baseline Loss: 3.2847 | Actual Loss: 0.6286\n",
      "Baseline Loss: 3.5618 | Actual Loss: 1.3522\n",
      "Baseline Loss: 3.5956 | Actual Loss: 0.4355\n",
      "Baseline Loss: 3.5661 | Actual Loss: 0.5311\n",
      "Baseline Loss: 3.3477 | Actual Loss: 0.6033\n",
      "Baseline Loss: 3.5209 | Actual Loss: 0.1468\n",
      "Baseline Loss: 3.6132 | Actual Loss: 0.7384\n",
      "Baseline Loss: 3.6594 | Actual Loss: 0.4842\n",
      "Baseline Loss: 3.4387 | Actual Loss: 0.4428\n",
      "Baseline Loss: 3.5707 | Actual Loss: 0.9037\n",
      "Baseline Loss: 3.4316 | Actual Loss: 0.6580\n",
      "Baseline Loss: 3.4922 | Actual Loss: 1.0886\n",
      "Baseline Loss: 3.0705 | Actual Loss: 0.2288\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.0137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 66/1000 [00:32<08:26,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6229 | Actual Loss: 1.0454\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.8301\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.6130\n",
      "Epoch 66/1000: Train Loss: 0.6975, Val Loss: 1.1256\n",
      "Baseline Loss: 3.4107 | Actual Loss: 1.0549\n",
      "Baseline Loss: 3.4438 | Actual Loss: 0.6059\n",
      "Baseline Loss: 3.5880 | Actual Loss: 0.5697\n",
      "Baseline Loss: 3.5089 | Actual Loss: 1.4514\n",
      "Baseline Loss: 3.5283 | Actual Loss: 0.6761\n",
      "Baseline Loss: 3.5250 | Actual Loss: 0.4809\n",
      "Baseline Loss: 3.4391 | Actual Loss: 0.5776\n",
      "Baseline Loss: 3.6501 | Actual Loss: 0.9514\n",
      "Baseline Loss: 3.6147 | Actual Loss: 0.7025\n",
      "Baseline Loss: 3.3448 | Actual Loss: 1.1823\n",
      "Baseline Loss: 3.5042 | Actual Loss: 0.6600\n",
      "Baseline Loss: 3.3925 | Actual Loss: 0.5528\n",
      "Baseline Loss: 3.6142 | Actual Loss: 0.8723\n",
      "Baseline Loss: 3.5534 | Actual Loss: 0.3858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 67/1000 [00:32<08:17,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6049 | Actual Loss: 0.3291\n",
      "Baseline Loss: 3.5002 | Actual Loss: 0.6573\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.2815\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.9991\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.5888\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.5720\n",
      "Epoch 67/1000: Train Loss: 0.7319, Val Loss: 1.3604\n",
      "Baseline Loss: 3.4543 | Actual Loss: 0.7444\n",
      "Baseline Loss: 3.6736 | Actual Loss: 1.3268\n",
      "Baseline Loss: 3.3547 | Actual Loss: 0.7015\n",
      "Baseline Loss: 3.5716 | Actual Loss: 0.8259\n",
      "Baseline Loss: 3.5660 | Actual Loss: 1.3076\n",
      "Baseline Loss: 3.3886 | Actual Loss: 1.8571\n",
      "Baseline Loss: 3.6055 | Actual Loss: 1.5472\n",
      "Baseline Loss: 3.5833 | Actual Loss: 0.5261\n",
      "Baseline Loss: 3.4922 | Actual Loss: 0.6604\n",
      "Baseline Loss: 3.4289 | Actual Loss: 0.4498\n",
      "Baseline Loss: 3.7674 | Actual Loss: 0.7966\n",
      "Baseline Loss: 3.3818 | Actual Loss: 0.6956\n",
      "Baseline Loss: 3.5125 | Actual Loss: 0.6003\n",
      "Baseline Loss: 3.3640 | Actual Loss: 0.5758\n",
      "Baseline Loss: 3.4290 | Actual Loss: 0.9185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 68/1000 [00:33<08:39,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.1886 | Actual Loss: 0.4742\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.9319\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.0657\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.5415\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.5648\n",
      "Epoch 68/1000: Train Loss: 0.8755, Val Loss: 1.2760\n",
      "Baseline Loss: 3.5574 | Actual Loss: 0.7776\n",
      "Baseline Loss: 3.4696 | Actual Loss: 0.7091\n",
      "Baseline Loss: 3.4815 | Actual Loss: 0.6427\n",
      "Baseline Loss: 3.3925 | Actual Loss: 0.8493\n",
      "Baseline Loss: 3.3988 | Actual Loss: 1.1763\n",
      "Baseline Loss: 3.4735 | Actual Loss: 0.5784\n",
      "Baseline Loss: 3.5083 | Actual Loss: 3.4483\n",
      "Baseline Loss: 3.7885 | Actual Loss: 4.0889\n",
      "Baseline Loss: 3.3241 | Actual Loss: 1.3392\n",
      "Baseline Loss: 3.4507 | Actual Loss: 0.5143\n",
      "Baseline Loss: 3.4971 | Actual Loss: 1.4100\n",
      "Baseline Loss: 3.5162 | Actual Loss: 0.8030\n",
      "Baseline Loss: 3.3315 | Actual Loss: 0.2255\n",
      "Baseline Loss: 3.4659 | Actual Loss: 0.7595\n",
      "Baseline Loss: 3.5371 | Actual Loss: 0.4450\n",
      "Baseline Loss: 3.4115 | Actual Loss: 0.9188\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.6964\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.0072\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 69/1000 [00:33<08:32,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4730 | Actual Loss: 0.4466\n",
      "Epoch 69/1000: Train Loss: 1.1679, Val Loss: 0.9554\n",
      "Baseline Loss: 3.3509 | Actual Loss: 0.6195\n",
      "Baseline Loss: 3.7169 | Actual Loss: 0.4001\n",
      "Baseline Loss: 3.3075 | Actual Loss: 1.0919\n",
      "Baseline Loss: 3.7476 | Actual Loss: 0.8075\n",
      "Baseline Loss: 3.4628 | Actual Loss: 0.6432\n",
      "Baseline Loss: 3.4928 | Actual Loss: 1.6985\n",
      "Baseline Loss: 3.4282 | Actual Loss: 0.7539\n",
      "Baseline Loss: 3.4431 | Actual Loss: 0.8353\n",
      "Baseline Loss: 3.6696 | Actual Loss: 2.4965\n",
      "Baseline Loss: 3.7941 | Actual Loss: 0.8083\n",
      "Baseline Loss: 3.5881 | Actual Loss: 0.8581\n",
      "Baseline Loss: 3.5875 | Actual Loss: 1.0008\n",
      "Baseline Loss: 3.4325 | Actual Loss: 0.8753\n",
      "Baseline Loss: 3.3043 | Actual Loss: 0.5336\n",
      "Baseline Loss: 3.3467 | Actual Loss: 0.8722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 70/1000 [00:34<08:25,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.2189 | Actual Loss: 0.3469\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.8450\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.4487\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.7033\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.4914\n",
      "Epoch 70/1000: Train Loss: 0.9151, Val Loss: 1.1221\n",
      "Baseline Loss: 3.5664 | Actual Loss: 0.5694\n",
      "Baseline Loss: 3.6095 | Actual Loss: 1.3797\n",
      "Baseline Loss: 3.3386 | Actual Loss: 0.4916\n",
      "Baseline Loss: 3.5137 | Actual Loss: 0.5834\n",
      "Baseline Loss: 3.4811 | Actual Loss: 0.7648\n",
      "Baseline Loss: 3.5419 | Actual Loss: 0.8754\n",
      "Baseline Loss: 3.4613 | Actual Loss: 0.8225\n",
      "Baseline Loss: 3.5047 | Actual Loss: 0.6447\n",
      "Baseline Loss: 3.6502 | Actual Loss: 0.9649\n",
      "Baseline Loss: 3.4324 | Actual Loss: 0.9081\n",
      "Baseline Loss: 3.6591 | Actual Loss: 0.6507\n",
      "Baseline Loss: 3.4849 | Actual Loss: 0.8231\n",
      "Baseline Loss: 3.6005 | Actual Loss: 0.4987\n",
      "Baseline Loss: 3.3566 | Actual Loss: 1.4322\n",
      "Baseline Loss: 3.3928 | Actual Loss: 0.6926\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.8751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 71/1000 [00:35<08:46,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7429 | Actual Loss: 2.1273\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.0094\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.8077\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.5233\n",
      "Epoch 71/1000: Train Loss: 0.8736, Val Loss: 1.1169\n",
      "Baseline Loss: 3.5825 | Actual Loss: 0.5234\n",
      "Baseline Loss: 3.6369 | Actual Loss: 0.5419\n",
      "Baseline Loss: 3.4179 | Actual Loss: 1.4060\n",
      "Baseline Loss: 3.8210 | Actual Loss: 2.1811\n",
      "Baseline Loss: 3.5337 | Actual Loss: 0.8814\n",
      "Baseline Loss: 3.7215 | Actual Loss: 0.6869\n",
      "Baseline Loss: 3.3573 | Actual Loss: 0.4644\n",
      "Baseline Loss: 3.6099 | Actual Loss: 0.4699\n",
      "Baseline Loss: 3.5619 | Actual Loss: 0.8353\n",
      "Baseline Loss: 3.5577 | Actual Loss: 0.7855\n",
      "Baseline Loss: 3.6090 | Actual Loss: 0.8180\n",
      "Baseline Loss: 3.3073 | Actual Loss: 1.0593\n",
      "Baseline Loss: 3.3108 | Actual Loss: 0.5543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 72/1000 [00:35<08:43,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.2919 | Actual Loss: 0.6747\n",
      "Baseline Loss: 3.4971 | Actual Loss: 0.8855\n",
      "Baseline Loss: 3.3935 | Actual Loss: 1.9431\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.2396\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.1541\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.7284\n",
      "Baseline Loss: 3.4730 | Actual Loss: 1.4741\n",
      "Epoch 72/1000: Train Loss: 0.9194, Val Loss: 1.3990\n",
      "Baseline Loss: 3.4734 | Actual Loss: 0.4037\n",
      "Baseline Loss: 3.7032 | Actual Loss: 0.6327\n",
      "Baseline Loss: 3.6366 | Actual Loss: 1.0085\n",
      "Baseline Loss: 3.3794 | Actual Loss: 1.4924\n",
      "Baseline Loss: 3.5243 | Actual Loss: 0.8191\n",
      "Baseline Loss: 3.5023 | Actual Loss: 0.7644\n",
      "Baseline Loss: 3.4773 | Actual Loss: 0.9216\n",
      "Baseline Loss: 3.5619 | Actual Loss: 0.8441\n",
      "Baseline Loss: 3.3780 | Actual Loss: 0.7846\n",
      "Baseline Loss: 3.6274 | Actual Loss: 0.7697\n",
      "Baseline Loss: 3.6317 | Actual Loss: 0.7412\n",
      "Baseline Loss: 3.4884 | Actual Loss: 0.4972\n",
      "Baseline Loss: 3.3008 | Actual Loss: 0.7270\n",
      "Baseline Loss: 3.6099 | Actual Loss: 0.7679\n",
      "Baseline Loss: 3.5619 | Actual Loss: 0.8599\n",
      "Baseline Loss: 3.2974 | Actual Loss: 2.0284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 73/1000 [00:36<08:27,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7429 | Actual Loss: 1.9476\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.0858\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6160\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.4690\n",
      "Epoch 73/1000: Train Loss: 0.8789, Val Loss: 1.0296\n",
      "Baseline Loss: 3.5050 | Actual Loss: 0.5645\n",
      "Baseline Loss: 3.4434 | Actual Loss: 0.9401\n",
      "Baseline Loss: 3.4667 | Actual Loss: 0.5497\n",
      "Baseline Loss: 3.3573 | Actual Loss: 1.3015\n",
      "Baseline Loss: 3.5123 | Actual Loss: 1.1372\n",
      "Baseline Loss: 3.3963 | Actual Loss: 0.8050\n",
      "Baseline Loss: 3.6501 | Actual Loss: 0.5409\n",
      "Baseline Loss: 3.4884 | Actual Loss: 0.5851\n",
      "Baseline Loss: 3.5365 | Actual Loss: 1.1885\n",
      "Baseline Loss: 3.4397 | Actual Loss: 1.1763\n",
      "Baseline Loss: 3.6877 | Actual Loss: 0.4908\n",
      "Baseline Loss: 3.5005 | Actual Loss: 0.5733\n",
      "Baseline Loss: 3.5742 | Actual Loss: 0.7648\n",
      "Baseline Loss: 3.4884 | Actual Loss: 1.1411\n",
      "Baseline Loss: 3.5698 | Actual Loss: 1.1644\n",
      "Baseline Loss: 3.0957 | Actual Loss: 0.6732\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.0772\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.2229\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.7969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 74/1000 [00:36<08:29,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4730 | Actual Loss: 0.4415\n",
      "Epoch 74/1000: Train Loss: 0.8498, Val Loss: 1.1346\n",
      "Baseline Loss: 3.4702 | Actual Loss: 0.9455\n",
      "Baseline Loss: 3.4198 | Actual Loss: 0.6165\n",
      "Baseline Loss: 3.3645 | Actual Loss: 0.7561\n",
      "Baseline Loss: 3.5371 | Actual Loss: 0.6056\n",
      "Baseline Loss: 3.6232 | Actual Loss: 1.4663\n",
      "Baseline Loss: 3.3377 | Actual Loss: 0.4596\n",
      "Baseline Loss: 3.5879 | Actual Loss: 0.6951\n",
      "Baseline Loss: 3.3820 | Actual Loss: 0.7465\n",
      "Baseline Loss: 3.5546 | Actual Loss: 0.6401\n",
      "Baseline Loss: 3.5830 | Actual Loss: 0.5840\n",
      "Baseline Loss: 3.4250 | Actual Loss: 0.8415\n",
      "Baseline Loss: 3.3887 | Actual Loss: 0.5851\n",
      "Baseline Loss: 3.5015 | Actual Loss: 0.9633\n",
      "Baseline Loss: 3.5089 | Actual Loss: 0.5126\n",
      "Baseline Loss: 3.5448 | Actual Loss: 2.0434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 75/1000 [00:37<08:36,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4984 | Actual Loss: 2.1550\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.0324\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.6005\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.5028\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.5033\n",
      "Epoch 75/1000: Train Loss: 0.9135, Val Loss: 1.1598\n",
      "Baseline Loss: 3.3958 | Actual Loss: 0.7163\n",
      "Baseline Loss: 3.4541 | Actual Loss: 2.5853\n",
      "Baseline Loss: 3.5167 | Actual Loss: 0.4167\n",
      "Baseline Loss: 3.5878 | Actual Loss: 0.8389\n",
      "Baseline Loss: 3.6545 | Actual Loss: 0.9270\n",
      "Baseline Loss: 3.7785 | Actual Loss: 0.7099\n",
      "Baseline Loss: 3.5254 | Actual Loss: 0.4426\n",
      "Baseline Loss: 3.5928 | Actual Loss: 0.6855\n",
      "Baseline Loss: 3.3684 | Actual Loss: 0.8745\n",
      "Baseline Loss: 3.5049 | Actual Loss: 0.4318\n",
      "Baseline Loss: 3.4287 | Actual Loss: 0.6090\n",
      "Baseline Loss: 3.3760 | Actual Loss: 1.2507\n",
      "Baseline Loss: 3.4031 | Actual Loss: 0.9975\n",
      "Baseline Loss: 3.4821 | Actual Loss: 0.3687\n",
      "Baseline Loss: 3.4768 | Actual Loss: 0.6323\n",
      "Baseline Loss: 3.0923 | Actual Loss: 1.1652\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.8836\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.1868\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.7750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 76/1000 [00:37<08:10,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4730 | Actual Loss: 0.8910\n",
      "Epoch 76/1000: Train Loss: 0.8532, Val Loss: 1.1841\n",
      "Baseline Loss: 3.6314 | Actual Loss: 0.6796\n",
      "Baseline Loss: 3.2419 | Actual Loss: 1.6033\n",
      "Baseline Loss: 3.5413 | Actual Loss: 0.6232\n",
      "Baseline Loss: 3.8106 | Actual Loss: 1.2074\n",
      "Baseline Loss: 3.3925 | Actual Loss: 0.6169\n",
      "Baseline Loss: 3.5299 | Actual Loss: 0.6128\n",
      "Baseline Loss: 3.4364 | Actual Loss: 0.6550\n",
      "Baseline Loss: 3.5660 | Actual Loss: 0.7545\n",
      "Baseline Loss: 3.5924 | Actual Loss: 0.6352\n",
      "Baseline Loss: 3.3918 | Actual Loss: 0.7838\n",
      "Baseline Loss: 3.3270 | Actual Loss: 1.1511\n",
      "Baseline Loss: 3.3478 | Actual Loss: 0.7947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 77/1000 [00:38<08:38,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5368 | Actual Loss: 0.5617\n",
      "Baseline Loss: 3.5006 | Actual Loss: 0.2866\n",
      "Baseline Loss: 3.7625 | Actual Loss: 0.5988\n",
      "Baseline Loss: 3.3061 | Actual Loss: 0.7291\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.6976\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.0572\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6544\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.3554\n",
      "Epoch 77/1000: Train Loss: 0.7684, Val Loss: 0.9411\n",
      "New best validation loss: 0.9411\n",
      "Baseline Loss: 3.4318 | Actual Loss: 1.0352\n",
      "Baseline Loss: 3.1750 | Actual Loss: 0.5756\n",
      "Baseline Loss: 3.5706 | Actual Loss: 0.5075\n",
      "Baseline Loss: 3.3920 | Actual Loss: 0.5449\n",
      "Baseline Loss: 3.6874 | Actual Loss: 0.4606\n",
      "Baseline Loss: 3.3403 | Actual Loss: 1.0158\n",
      "Baseline Loss: 3.6454 | Actual Loss: 1.0414\n",
      "Baseline Loss: 3.7524 | Actual Loss: 0.9176\n",
      "Baseline Loss: 3.4972 | Actual Loss: 0.5345\n",
      "Baseline Loss: 3.6191 | Actual Loss: 0.4716\n",
      "Baseline Loss: 3.4064 | Actual Loss: 0.6974\n",
      "Baseline Loss: 3.4363 | Actual Loss: 0.6456\n",
      "Baseline Loss: 3.6184 | Actual Loss: 0.8142\n",
      "Baseline Loss: 3.3145 | Actual Loss: 0.7073\n",
      "Baseline Loss: 3.2705 | Actual Loss: 0.8764\n",
      "Baseline Loss: 3.5301 | Actual Loss: 0.2227\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.2483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 78/1000 [00:38<08:25,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6229 | Actual Loss: 0.9138\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.4397\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.3751\n",
      "Epoch 78/1000: Train Loss: 0.6918, Val Loss: 0.9942\n",
      "Baseline Loss: 3.5248 | Actual Loss: 0.5977\n",
      "Baseline Loss: 3.6184 | Actual Loss: 0.8401\n",
      "Baseline Loss: 3.4585 | Actual Loss: 0.6238\n",
      "Baseline Loss: 3.6735 | Actual Loss: 0.5356\n",
      "Baseline Loss: 3.6877 | Actual Loss: 0.2573\n",
      "Baseline Loss: 3.5044 | Actual Loss: 1.0159\n",
      "Baseline Loss: 3.5326 | Actual Loss: 0.5416\n",
      "Baseline Loss: 3.5789 | Actual Loss: 0.7571\n",
      "Baseline Loss: 3.4542 | Actual Loss: 1.1145\n",
      "Baseline Loss: 3.3244 | Actual Loss: 0.7372\n",
      "Baseline Loss: 3.4575 | Actual Loss: 1.4165\n",
      "Baseline Loss: 3.5613 | Actual Loss: 1.3694\n",
      "Baseline Loss: 3.4258 | Actual Loss: 0.8707\n",
      "Baseline Loss: 3.3231 | Actual Loss: 0.5942\n",
      "Baseline Loss: 3.3535 | Actual Loss: 0.9431\n",
      "Baseline Loss: 3.2494 | Actual Loss: 0.5499\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.0118\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.2646\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 79/1000 [00:39<08:41,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4730 | Actual Loss: 0.8671\n",
      "Epoch 79/1000: Train Loss: 0.7978, Val Loss: 1.1940\n",
      "Baseline Loss: 3.2822 | Actual Loss: 1.4815\n",
      "Baseline Loss: 3.5333 | Actual Loss: 0.4545\n",
      "Baseline Loss: 3.5699 | Actual Loss: 0.7768\n",
      "Baseline Loss: 3.5450 | Actual Loss: 0.5688\n",
      "Baseline Loss: 3.7017 | Actual Loss: 1.0051\n",
      "Baseline Loss: 3.4653 | Actual Loss: 1.0413\n",
      "Baseline Loss: 3.5707 | Actual Loss: 0.7116\n",
      "Baseline Loss: 3.3305 | Actual Loss: 0.8150\n",
      "Baseline Loss: 3.2213 | Actual Loss: 0.7957\n",
      "Baseline Loss: 3.7836 | Actual Loss: 1.2719\n",
      "Baseline Loss: 3.2813 | Actual Loss: 1.0221\n",
      "Baseline Loss: 3.6184 | Actual Loss: 0.7785\n",
      "Baseline Loss: 3.5125 | Actual Loss: 0.8586\n",
      "Baseline Loss: 3.5748 | Actual Loss: 1.2345\n",
      "Baseline Loss: 3.3008 | Actual Loss: 0.7486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 80/1000 [00:40<08:47,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5405 | Actual Loss: 2.5888\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.7619\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.4130\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6999\n",
      "Baseline Loss: 3.4730 | Actual Loss: 1.6006\n",
      "Epoch 80/1000: Train Loss: 1.0096, Val Loss: 1.3688\n",
      "Baseline Loss: 3.6180 | Actual Loss: 0.7340\n",
      "Baseline Loss: 3.3149 | Actual Loss: 0.9794\n",
      "Baseline Loss: 3.3512 | Actual Loss: 0.2352\n",
      "Baseline Loss: 3.7679 | Actual Loss: 0.7352\n",
      "Baseline Loss: 3.3073 | Actual Loss: 0.7565\n",
      "Baseline Loss: 3.4467 | Actual Loss: 1.1099\n",
      "Baseline Loss: 3.5838 | Actual Loss: 0.7312\n",
      "Baseline Loss: 3.4818 | Actual Loss: 3.1065\n",
      "Baseline Loss: 3.5972 | Actual Loss: 0.8645\n",
      "Baseline Loss: 3.5289 | Actual Loss: 0.8399\n",
      "Baseline Loss: 3.6007 | Actual Loss: 0.8869\n",
      "Baseline Loss: 3.5541 | Actual Loss: 0.3534\n",
      "Baseline Loss: 3.7529 | Actual Loss: 0.6968\n",
      "Baseline Loss: 3.4736 | Actual Loss: 0.6107\n",
      "Baseline Loss: 3.5253 | Actual Loss: 0.5960\n",
      "Baseline Loss: 3.2108 | Actual Loss: 2.2022\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.2050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 81/1000 [00:40<08:33,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6229 | Actual Loss: 0.9820\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6710\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.4032\n",
      "Epoch 81/1000: Train Loss: 0.9649, Val Loss: 1.0653\n",
      "Baseline Loss: 3.3508 | Actual Loss: 0.5706\n",
      "Baseline Loss: 3.4036 | Actual Loss: 0.8455\n",
      "Baseline Loss: 3.4853 | Actual Loss: 0.5288\n",
      "Baseline Loss: 3.4848 | Actual Loss: 0.7257\n",
      "Baseline Loss: 3.5838 | Actual Loss: 0.5311\n",
      "Baseline Loss: 3.3924 | Actual Loss: 0.6148\n",
      "Baseline Loss: 3.2718 | Actual Loss: 0.8816\n",
      "Baseline Loss: 3.3279 | Actual Loss: 0.5558\n",
      "Baseline Loss: 3.5704 | Actual Loss: 1.1230\n",
      "Baseline Loss: 3.6978 | Actual Loss: 0.5333\n",
      "Baseline Loss: 3.6927 | Actual Loss: 1.2651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 82/1000 [00:41<08:31,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3888 | Actual Loss: 1.7422\n",
      "Baseline Loss: 3.5551 | Actual Loss: 0.7665\n",
      "Baseline Loss: 3.8377 | Actual Loss: 0.8823\n",
      "Baseline Loss: 3.5700 | Actual Loss: 1.0035\n",
      "Baseline Loss: 3.5094 | Actual Loss: 3.2821\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.1033\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.9964\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.7167\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.6795\n",
      "Epoch 82/1000: Train Loss: 0.9907, Val Loss: 1.1239\n",
      "Baseline Loss: 3.6049 | Actual Loss: 1.2083\n",
      "Baseline Loss: 3.3860 | Actual Loss: 0.5771\n",
      "Baseline Loss: 3.6098 | Actual Loss: 0.4308\n",
      "Baseline Loss: 3.5789 | Actual Loss: 0.8920\n",
      "Baseline Loss: 3.4735 | Actual Loss: 0.7556\n",
      "Baseline Loss: 3.5332 | Actual Loss: 1.0297\n",
      "Baseline Loss: 3.6927 | Actual Loss: 0.6887\n",
      "Baseline Loss: 3.7832 | Actual Loss: 0.7053\n",
      "Baseline Loss: 3.3530 | Actual Loss: 0.7000\n",
      "Baseline Loss: 3.6047 | Actual Loss: 0.5811\n",
      "Baseline Loss: 3.7625 | Actual Loss: 2.3038\n",
      "Baseline Loss: 3.4028 | Actual Loss: 0.3313\n",
      "Baseline Loss: 3.6016 | Actual Loss: 0.6104\n",
      "Baseline Loss: 3.3850 | Actual Loss: 0.6362\n",
      "Baseline Loss: 3.4327 | Actual Loss: 1.3573\n",
      "Baseline Loss: 3.2578 | Actual Loss: 0.6952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 83/1000 [00:41<08:15,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7429 | Actual Loss: 2.4340\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.5874\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6275\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.7435\n",
      "Epoch 83/1000: Train Loss: 0.8439, Val Loss: 1.3481\n",
      "Baseline Loss: 3.5372 | Actual Loss: 0.3822\n",
      "Baseline Loss: 3.5091 | Actual Loss: 0.4928\n",
      "Baseline Loss: 3.4286 | Actual Loss: 0.7207\n",
      "Baseline Loss: 3.3828 | Actual Loss: 0.7363\n",
      "Baseline Loss: 3.4395 | Actual Loss: 0.8792\n",
      "Baseline Loss: 3.4922 | Actual Loss: 1.5120\n",
      "Baseline Loss: 3.5047 | Actual Loss: 0.8588\n",
      "Baseline Loss: 3.3680 | Actual Loss: 0.6444\n",
      "Baseline Loss: 3.5616 | Actual Loss: 0.5269\n",
      "Baseline Loss: 3.4020 | Actual Loss: 0.7450\n",
      "Baseline Loss: 3.6313 | Actual Loss: 0.9845\n",
      "Baseline Loss: 3.4544 | Actual Loss: 0.5246\n",
      "Baseline Loss: 3.5370 | Actual Loss: 1.1141\n",
      "Baseline Loss: 3.3784 | Actual Loss: 0.6404\n",
      "Baseline Loss: 3.4931 | Actual Loss: 0.7035\n",
      "Baseline Loss: 3.4996 | Actual Loss: 1.5455\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.9863\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.8649\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.5567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 84/1000 [00:42<08:27,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4730 | Actual Loss: 0.6287\n",
      "Epoch 84/1000: Train Loss: 0.8132, Val Loss: 1.2592\n",
      "Baseline Loss: 3.4577 | Actual Loss: 0.6711\n",
      "Baseline Loss: 3.3637 | Actual Loss: 0.5943\n",
      "Baseline Loss: 3.5371 | Actual Loss: 0.6685\n",
      "Baseline Loss: 3.4689 | Actual Loss: 0.8605\n",
      "Baseline Loss: 3.4587 | Actual Loss: 1.1547\n",
      "Baseline Loss: 3.4396 | Actual Loss: 1.3562\n",
      "Baseline Loss: 3.5058 | Actual Loss: 0.1495\n",
      "Baseline Loss: 3.6092 | Actual Loss: 1.0619\n",
      "Baseline Loss: 3.4505 | Actual Loss: 1.3488\n",
      "Baseline Loss: 3.4177 | Actual Loss: 1.3492\n",
      "Baseline Loss: 3.5004 | Actual Loss: 1.6986\n",
      "Baseline Loss: 3.6974 | Actual Loss: 2.2505\n",
      "Baseline Loss: 3.4511 | Actual Loss: 0.5631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 85/1000 [00:42<08:39,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3965 | Actual Loss: 0.6516\n",
      "Baseline Loss: 3.7625 | Actual Loss: 1.8010\n",
      "Baseline Loss: 3.3322 | Actual Loss: 0.3792\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.5969\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.0969\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6065\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.6531\n",
      "Epoch 85/1000: Train Loss: 1.0349, Val Loss: 0.9883\n",
      "Baseline Loss: 3.5664 | Actual Loss: 0.4743\n",
      "Baseline Loss: 3.4703 | Actual Loss: 0.7522\n",
      "Baseline Loss: 3.5747 | Actual Loss: 1.0502\n",
      "Baseline Loss: 3.4296 | Actual Loss: 0.5989\n",
      "Baseline Loss: 3.4822 | Actual Loss: 0.4025\n",
      "Baseline Loss: 3.5794 | Actual Loss: 1.3335\n",
      "Baseline Loss: 3.5495 | Actual Loss: 0.1383\n",
      "Baseline Loss: 3.4143 | Actual Loss: 0.9424\n",
      "Baseline Loss: 3.4093 | Actual Loss: 0.8299\n",
      "Baseline Loss: 3.5589 | Actual Loss: 1.0903\n",
      "Baseline Loss: 3.4586 | Actual Loss: 0.8744\n",
      "Baseline Loss: 3.4435 | Actual Loss: 1.5465\n",
      "Baseline Loss: 3.6273 | Actual Loss: 0.9106\n",
      "Baseline Loss: 3.4070 | Actual Loss: 0.3583\n",
      "Baseline Loss: 3.3444 | Actual Loss: 0.6290\n",
      "Baseline Loss: 3.2421 | Actual Loss: 0.5144\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.1281\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.6865\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▊         | 86/1000 [00:43<08:27,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4730 | Actual Loss: 0.9590\n",
      "Epoch 86/1000: Train Loss: 0.7779, Val Loss: 1.3467\n",
      "Baseline Loss: 3.6367 | Actual Loss: 0.4478\n",
      "Baseline Loss: 3.6186 | Actual Loss: 1.1200\n",
      "Baseline Loss: 3.6007 | Actual Loss: 1.6699\n",
      "Baseline Loss: 3.4888 | Actual Loss: 0.7796\n",
      "Baseline Loss: 3.4967 | Actual Loss: 0.5767\n",
      "Baseline Loss: 3.4322 | Actual Loss: 0.9177\n",
      "Baseline Loss: 3.6498 | Actual Loss: 0.3240\n",
      "Baseline Loss: 3.4246 | Actual Loss: 0.5719\n",
      "Baseline Loss: 3.4924 | Actual Loss: 0.7456\n",
      "Baseline Loss: 3.3177 | Actual Loss: 0.6371\n",
      "Baseline Loss: 3.7368 | Actual Loss: 1.0057\n",
      "Baseline Loss: 3.5167 | Actual Loss: 1.0623\n",
      "Baseline Loss: 3.2883 | Actual Loss: 1.0092\n",
      "Baseline Loss: 3.3660 | Actual Loss: 1.4061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▊         | 87/1000 [00:43<08:21,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5216 | Actual Loss: 1.1651\n",
      "Baseline Loss: 3.4021 | Actual Loss: 0.4289\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.8674\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.3353\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6229\n",
      "Baseline Loss: 3.4730 | Actual Loss: 1.0353\n",
      "Epoch 87/1000: Train Loss: 0.8667, Val Loss: 1.2152\n",
      "Baseline Loss: 3.3373 | Actual Loss: 1.0216\n",
      "Baseline Loss: 3.4820 | Actual Loss: 0.6326\n",
      "Baseline Loss: 3.3306 | Actual Loss: 0.7084\n",
      "Baseline Loss: 3.5543 | Actual Loss: 0.5455\n",
      "Baseline Loss: 3.5292 | Actual Loss: 0.9886\n",
      "Baseline Loss: 3.3553 | Actual Loss: 0.4280\n",
      "Baseline Loss: 3.8436 | Actual Loss: 1.2449\n",
      "Baseline Loss: 3.5204 | Actual Loss: 0.4248\n",
      "Baseline Loss: 3.4739 | Actual Loss: 0.5579\n",
      "Baseline Loss: 3.7219 | Actual Loss: 0.4639\n",
      "Baseline Loss: 3.4852 | Actual Loss: 0.4829\n",
      "Baseline Loss: 3.6363 | Actual Loss: 1.7529\n",
      "Baseline Loss: 3.6366 | Actual Loss: 0.4873\n",
      "Baseline Loss: 3.3271 | Actual Loss: 1.0331\n",
      "Baseline Loss: 3.4772 | Actual Loss: 0.6984\n",
      "Baseline Loss: 3.4396 | Actual Loss: 1.1338\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.9923\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.8547\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.5835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 88/1000 [00:44<08:20,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4730 | Actual Loss: 0.4843\n",
      "Epoch 88/1000: Train Loss: 0.7878, Val Loss: 1.2287\n",
      "Baseline Loss: 3.3597 | Actual Loss: 0.9518\n",
      "Baseline Loss: 3.6054 | Actual Loss: 0.7482\n",
      "Baseline Loss: 3.5088 | Actual Loss: 0.7193\n",
      "Baseline Loss: 3.5408 | Actual Loss: 0.4287\n",
      "Baseline Loss: 3.7119 | Actual Loss: 0.9435\n",
      "Baseline Loss: 3.3480 | Actual Loss: 0.6835\n",
      "Baseline Loss: 3.2600 | Actual Loss: 1.0245\n",
      "Baseline Loss: 3.4843 | Actual Loss: 0.4011\n",
      "Baseline Loss: 3.6826 | Actual Loss: 0.6507\n",
      "Baseline Loss: 3.4780 | Actual Loss: 0.5640\n",
      "Baseline Loss: 3.5206 | Actual Loss: 1.2515\n",
      "Baseline Loss: 3.4000 | Actual Loss: 0.8207\n",
      "Baseline Loss: 3.4697 | Actual Loss: 0.9833\n",
      "Baseline Loss: 3.5927 | Actual Loss: 0.5287\n",
      "Baseline Loss: 3.6054 | Actual Loss: 0.6342\n",
      "Baseline Loss: 3.0718 | Actual Loss: 0.1815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 89/1000 [00:45<08:06,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7429 | Actual Loss: 1.7177\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.4430\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.5283\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.5974\n",
      "Epoch 89/1000: Train Loss: 0.7197, Val Loss: 1.0716\n",
      "Baseline Loss: 3.5746 | Actual Loss: 1.0320\n",
      "Baseline Loss: 3.4816 | Actual Loss: 0.7151\n",
      "Baseline Loss: 3.3018 | Actual Loss: 0.4439\n",
      "Baseline Loss: 3.2132 | Actual Loss: 0.5182\n",
      "Baseline Loss: 3.6555 | Actual Loss: 0.8082\n",
      "Baseline Loss: 3.7218 | Actual Loss: 1.3047\n",
      "Baseline Loss: 3.5666 | Actual Loss: 2.9458\n",
      "Baseline Loss: 3.8215 | Actual Loss: 0.5688\n",
      "Baseline Loss: 3.4346 | Actual Loss: 0.9741\n",
      "Baseline Loss: 3.6270 | Actual Loss: 0.6181\n",
      "Baseline Loss: 3.4356 | Actual Loss: 0.4146\n",
      "Baseline Loss: 3.4785 | Actual Loss: 0.3927\n",
      "Baseline Loss: 3.5626 | Actual Loss: 0.6212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 90/1000 [00:45<08:13,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5579 | Actual Loss: 0.5642\n",
      "Baseline Loss: 3.4935 | Actual Loss: 0.5222\n",
      "Baseline Loss: 3.2345 | Actual Loss: 1.4259\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.1042\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.8251\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6415\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.3503\n",
      "Epoch 90/1000: Train Loss: 0.8669, Val Loss: 0.9803\n",
      "Baseline Loss: 3.7018 | Actual Loss: 1.1892\n",
      "Baseline Loss: 3.3922 | Actual Loss: 0.5568\n",
      "Baseline Loss: 3.3958 | Actual Loss: 0.8630\n",
      "Baseline Loss: 3.3711 | Actual Loss: 0.6168\n",
      "Baseline Loss: 3.6544 | Actual Loss: 0.8145\n",
      "Baseline Loss: 3.3178 | Actual Loss: 0.4234\n",
      "Baseline Loss: 3.6184 | Actual Loss: 0.6670\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.6521\n",
      "Baseline Loss: 3.6143 | Actual Loss: 0.7448\n",
      "Baseline Loss: 3.5578 | Actual Loss: 0.8658\n",
      "Baseline Loss: 3.2643 | Actual Loss: 0.9544\n",
      "Baseline Loss: 3.7511 | Actual Loss: 0.6004\n",
      "Baseline Loss: 3.5495 | Actual Loss: 0.4950\n",
      "Baseline Loss: 3.4437 | Actual Loss: 1.4084\n",
      "Baseline Loss: 3.3203 | Actual Loss: 1.0630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 91/1000 [00:46<08:23,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5091 | Actual Loss: 0.7010\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.9616\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.2263\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6736\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.7941\n",
      "Epoch 91/1000: Train Loss: 0.8510, Val Loss: 1.1639\n",
      "Baseline Loss: 3.6924 | Actual Loss: 0.3679\n",
      "Baseline Loss: 3.6833 | Actual Loss: 0.9293\n",
      "Baseline Loss: 3.5532 | Actual Loss: 0.4307\n",
      "Baseline Loss: 3.5204 | Actual Loss: 0.4866\n",
      "Baseline Loss: 3.5839 | Actual Loss: 1.0546\n",
      "Baseline Loss: 3.4284 | Actual Loss: 1.4786\n",
      "Baseline Loss: 3.5337 | Actual Loss: 0.5720\n",
      "Baseline Loss: 3.4364 | Actual Loss: 1.1699\n",
      "Baseline Loss: 3.4020 | Actual Loss: 1.0111\n",
      "Baseline Loss: 3.5420 | Actual Loss: 0.6523\n",
      "Baseline Loss: 3.6416 | Actual Loss: 1.4183\n",
      "Baseline Loss: 3.5041 | Actual Loss: 0.8254\n",
      "Baseline Loss: 3.3119 | Actual Loss: 0.9115\n",
      "Baseline Loss: 3.6142 | Actual Loss: 0.4142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 92/1000 [00:46<08:02,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3808 | Actual Loss: 0.6700\n",
      "Baseline Loss: 3.0785 | Actual Loss: 0.5428\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.9137\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.0497\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6892\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.6143\n",
      "Epoch 92/1000: Train Loss: 0.8085, Val Loss: 1.0667\n",
      "Baseline Loss: 3.5165 | Actual Loss: 0.6538\n",
      "Baseline Loss: 3.5209 | Actual Loss: 0.3070\n",
      "Baseline Loss: 3.4736 | Actual Loss: 0.3590\n",
      "Baseline Loss: 3.4893 | Actual Loss: 1.5534\n",
      "Baseline Loss: 3.3743 | Actual Loss: 0.9737\n",
      "Baseline Loss: 3.5966 | Actual Loss: 0.8072\n",
      "Baseline Loss: 3.5538 | Actual Loss: 1.3829\n",
      "Baseline Loss: 3.4350 | Actual Loss: 0.8322\n",
      "Baseline Loss: 3.3408 | Actual Loss: 0.4279\n",
      "Baseline Loss: 3.6186 | Actual Loss: 1.0053\n",
      "Baseline Loss: 3.4889 | Actual Loss: 0.4856\n",
      "Baseline Loss: 3.5502 | Actual Loss: 0.5553\n",
      "Baseline Loss: 3.3511 | Actual Loss: 1.0830\n",
      "Baseline Loss: 3.3582 | Actual Loss: 0.4127\n",
      "Baseline Loss: 3.4800 | Actual Loss: 0.7465\n",
      "Baseline Loss: 3.2491 | Actual Loss: 0.5728\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.5617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 93/1000 [00:47<08:07,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6229 | Actual Loss: 1.1573\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6458\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.6854\n",
      "Epoch 93/1000: Train Loss: 0.7599, Val Loss: 1.0126\n",
      "Baseline Loss: 3.5373 | Actual Loss: 0.5709\n",
      "Baseline Loss: 3.4440 | Actual Loss: 0.7181\n",
      "Baseline Loss: 3.7727 | Actual Loss: 1.1459\n",
      "Baseline Loss: 3.3958 | Actual Loss: 0.6379\n",
      "Baseline Loss: 3.4695 | Actual Loss: 0.9133\n",
      "Baseline Loss: 3.5707 | Actual Loss: 0.7762\n",
      "Baseline Loss: 3.5259 | Actual Loss: 0.9179\n",
      "Baseline Loss: 3.5579 | Actual Loss: 0.7410\n",
      "Baseline Loss: 3.4544 | Actual Loss: 3.1303\n",
      "Baseline Loss: 3.4252 | Actual Loss: 1.0011\n",
      "Baseline Loss: 3.3239 | Actual Loss: 0.7096\n",
      "Baseline Loss: 3.3718 | Actual Loss: 0.7677\n",
      "Baseline Loss: 3.6051 | Actual Loss: 0.9555\n",
      "Baseline Loss: 3.8547 | Actual Loss: 0.6679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 94/1000 [00:47<08:22,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7526 | Actual Loss: 1.1213\n",
      "Baseline Loss: 3.3577 | Actual Loss: 0.3456\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.0292\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.6784\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.4585\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.9009\n",
      "Epoch 94/1000: Train Loss: 0.9450, Val Loss: 1.0168\n",
      "Baseline Loss: 3.5452 | Actual Loss: 0.8881\n",
      "Baseline Loss: 3.4852 | Actual Loss: 0.5401\n",
      "Baseline Loss: 3.6735 | Actual Loss: 0.8560\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.6537\n",
      "Baseline Loss: 3.6050 | Actual Loss: 0.6439\n",
      "Baseline Loss: 3.2851 | Actual Loss: 0.7483\n",
      "Baseline Loss: 3.6185 | Actual Loss: 0.3105\n",
      "Baseline Loss: 3.6781 | Actual Loss: 0.3993\n",
      "Baseline Loss: 3.3721 | Actual Loss: 1.2736\n",
      "Baseline Loss: 3.2083 | Actual Loss: 0.7063\n",
      "Baseline Loss: 3.5249 | Actual Loss: 0.3831\n",
      "Baseline Loss: 3.7888 | Actual Loss: 3.5798\n",
      "Baseline Loss: 3.4626 | Actual Loss: 0.4780\n",
      "Baseline Loss: 3.6366 | Actual Loss: 2.9258\n",
      "Baseline Loss: 3.4139 | Actual Loss: 1.1141\n",
      "Baseline Loss: 2.9780 | Actual Loss: 0.3832\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.7248\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.1944\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 95/1000 [00:48<07:51,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4730 | Actual Loss: 0.6937\n",
      "Epoch 95/1000: Train Loss: 0.9927, Val Loss: 1.0605\n",
      "Baseline Loss: 3.4545 | Actual Loss: 0.2733\n",
      "Baseline Loss: 3.5934 | Actual Loss: 0.6664\n",
      "Baseline Loss: 3.4772 | Actual Loss: 1.6354\n",
      "Baseline Loss: 3.4920 | Actual Loss: 1.4857\n",
      "Baseline Loss: 3.4502 | Actual Loss: 0.4693\n",
      "Baseline Loss: 3.6684 | Actual Loss: 1.4853\n",
      "Baseline Loss: 3.4848 | Actual Loss: 1.1835\n",
      "Baseline Loss: 3.6596 | Actual Loss: 0.4591\n",
      "Baseline Loss: 3.5284 | Actual Loss: 0.7283\n",
      "Baseline Loss: 3.5789 | Actual Loss: 0.8277\n",
      "Baseline Loss: 3.3179 | Actual Loss: 0.6667\n",
      "Baseline Loss: 3.5748 | Actual Loss: 0.7409\n",
      "Baseline Loss: 3.2980 | Actual Loss: 0.7932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 96/1000 [00:48<08:05,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7275 | Actual Loss: 1.5940\n",
      "Baseline Loss: 3.4499 | Actual Loss: 0.9160\n",
      "Baseline Loss: 3.4213 | Actual Loss: 0.8595\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.7795\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.9475\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6245\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.6454\n",
      "Epoch 96/1000: Train Loss: 0.9240, Val Loss: 0.9992\n",
      "Baseline Loss: 3.3788 | Actual Loss: 0.8445\n",
      "Baseline Loss: 3.5409 | Actual Loss: 3.0396\n",
      "Baseline Loss: 3.3886 | Actual Loss: 0.6749\n",
      "Baseline Loss: 3.6505 | Actual Loss: 0.8195\n",
      "Baseline Loss: 3.6009 | Actual Loss: 1.0230\n",
      "Baseline Loss: 3.5172 | Actual Loss: 0.5909\n",
      "Baseline Loss: 3.3240 | Actual Loss: 1.6475\n",
      "Baseline Loss: 3.4812 | Actual Loss: 0.8645\n",
      "Baseline Loss: 3.6320 | Actual Loss: 0.7683\n",
      "Baseline Loss: 3.3300 | Actual Loss: 0.8924\n",
      "Baseline Loss: 3.4202 | Actual Loss: 0.6519\n",
      "Baseline Loss: 3.7425 | Actual Loss: 0.7907\n",
      "Baseline Loss: 3.3784 | Actual Loss: 0.5852\n",
      "Baseline Loss: 3.6737 | Actual Loss: 0.8460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 97/1000 [00:49<07:52,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7468 | Actual Loss: 1.0088\n",
      "Baseline Loss: 3.4792 | Actual Loss: 1.0799\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.0081\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.8578\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.9332\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.8386\n",
      "Epoch 97/1000: Train Loss: 1.0080, Val Loss: 1.1595\n",
      "Baseline Loss: 3.2765 | Actual Loss: 4.2079\n",
      "Baseline Loss: 3.4330 | Actual Loss: 0.4793\n",
      "Baseline Loss: 3.3582 | Actual Loss: 1.0596\n",
      "Baseline Loss: 3.3889 | Actual Loss: 0.6421\n",
      "Baseline Loss: 3.4778 | Actual Loss: 0.8093\n",
      "Baseline Loss: 3.5833 | Actual Loss: 0.8810\n",
      "Baseline Loss: 3.6324 | Actual Loss: 0.6216\n",
      "Baseline Loss: 3.4895 | Actual Loss: 0.7345\n",
      "Baseline Loss: 3.6011 | Actual Loss: 0.3439\n",
      "Baseline Loss: 3.4513 | Actual Loss: 0.9438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 98/1000 [00:49<07:56,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5832 | Actual Loss: 0.4410\n",
      "Baseline Loss: 3.5459 | Actual Loss: 0.5636\n",
      "Baseline Loss: 3.5535 | Actual Loss: 0.9781\n",
      "Baseline Loss: 3.7214 | Actual Loss: 1.1996\n",
      "Baseline Loss: 3.4435 | Actual Loss: 0.5767\n",
      "Baseline Loss: 3.2977 | Actual Loss: 0.8165\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.2042\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.0619\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.4664\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.7819\n",
      "Epoch 98/1000: Train Loss: 0.9562, Val Loss: 1.1286\n",
      "Baseline Loss: 3.3041 | Actual Loss: 0.5944\n",
      "Baseline Loss: 3.3171 | Actual Loss: 0.4306\n",
      "Baseline Loss: 3.3509 | Actual Loss: 0.8291\n",
      "Baseline Loss: 3.4103 | Actual Loss: 0.7482\n",
      "Baseline Loss: 3.5282 | Actual Loss: 0.9761\n",
      "Baseline Loss: 3.6925 | Actual Loss: 0.9957\n",
      "Baseline Loss: 3.5208 | Actual Loss: 0.9324\n",
      "Baseline Loss: 3.5832 | Actual Loss: 0.6900\n",
      "Baseline Loss: 3.3238 | Actual Loss: 0.6608\n",
      "Baseline Loss: 3.4691 | Actual Loss: 0.7738\n",
      "Baseline Loss: 3.5208 | Actual Loss: 0.7130\n",
      "Baseline Loss: 3.6739 | Actual Loss: 0.4706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 99/1000 [00:50<08:12,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4577 | Actual Loss: 0.9282\n",
      "Baseline Loss: 3.4853 | Actual Loss: 1.4253\n",
      "Baseline Loss: 3.5215 | Actual Loss: 1.5542\n",
      "Baseline Loss: 3.5835 | Actual Loss: 0.7241\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.2711\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.0678\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.5065\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.5077\n",
      "Epoch 99/1000: Train Loss: 0.8404, Val Loss: 1.0882\n",
      "Baseline Loss: 3.4356 | Actual Loss: 0.7019\n",
      "Baseline Loss: 3.3753 | Actual Loss: 0.3163\n",
      "Baseline Loss: 3.5204 | Actual Loss: 0.6451\n",
      "Baseline Loss: 3.3373 | Actual Loss: 1.1105\n",
      "Baseline Loss: 3.4257 | Actual Loss: 1.1346\n",
      "Baseline Loss: 3.4657 | Actual Loss: 1.0050\n",
      "Baseline Loss: 3.7776 | Actual Loss: 1.0924\n",
      "Baseline Loss: 3.6225 | Actual Loss: 0.8034\n",
      "Baseline Loss: 3.4694 | Actual Loss: 0.6096\n",
      "Baseline Loss: 3.6591 | Actual Loss: 0.8845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 100/1000 [00:50<07:50,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3823 | Actual Loss: 0.8052\n",
      "Baseline Loss: 3.4513 | Actual Loss: 0.5941\n",
      "Baseline Loss: 3.3882 | Actual Loss: 0.7275\n",
      "Baseline Loss: 3.5663 | Actual Loss: 0.5746\n",
      "Baseline Loss: 3.5410 | Actual Loss: 0.7948\n",
      "Baseline Loss: 3.3494 | Actual Loss: 0.3975\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.8065\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.0989\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.7944\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.3512\n",
      "Epoch 100/1000: Train Loss: 0.7623, Val Loss: 1.0127\n",
      "Baseline Loss: 3.5660 | Actual Loss: 0.7615\n",
      "Baseline Loss: 3.4470 | Actual Loss: 0.7361\n",
      "Baseline Loss: 3.5920 | Actual Loss: 0.5419\n",
      "Baseline Loss: 3.7619 | Actual Loss: 1.0847\n",
      "Baseline Loss: 3.5415 | Actual Loss: 0.5524\n",
      "Baseline Loss: 3.5618 | Actual Loss: 1.0338\n",
      "Baseline Loss: 3.4283 | Actual Loss: 0.8937\n",
      "Baseline Loss: 3.3391 | Actual Loss: 0.5594\n",
      "Baseline Loss: 3.5834 | Actual Loss: 0.3844\n",
      "Baseline Loss: 3.7786 | Actual Loss: 0.5780\n",
      "Baseline Loss: 3.4103 | Actual Loss: 0.6698\n",
      "Baseline Loss: 3.4517 | Actual Loss: 1.0833\n",
      "Baseline Loss: 3.3967 | Actual Loss: 0.9993\n",
      "Baseline Loss: 3.5616 | Actual Loss: 0.7078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 101/1000 [00:51<07:53,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5095 | Actual Loss: 0.3547\n",
      "Baseline Loss: 2.9606 | Actual Loss: 0.4853\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.6776\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.9826\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.5671\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.4301\n",
      "Epoch 101/1000: Train Loss: 0.7141, Val Loss: 0.9144\n",
      "New best validation loss: 0.9144\n",
      "Baseline Loss: 3.4700 | Actual Loss: 1.0604\n",
      "Baseline Loss: 3.5715 | Actual Loss: 1.4086\n",
      "Baseline Loss: 3.4062 | Actual Loss: 0.6935\n",
      "Baseline Loss: 3.7327 | Actual Loss: 0.9755\n",
      "Baseline Loss: 3.3276 | Actual Loss: 0.7902\n",
      "Baseline Loss: 3.4211 | Actual Loss: 0.7841\n",
      "Baseline Loss: 3.5660 | Actual Loss: 0.6586\n",
      "Baseline Loss: 3.2984 | Actual Loss: 0.3935\n",
      "Baseline Loss: 3.3576 | Actual Loss: 1.0431\n",
      "Baseline Loss: 3.6230 | Actual Loss: 0.5127\n",
      "Baseline Loss: 3.3615 | Actual Loss: 0.8405\n",
      "Baseline Loss: 3.4506 | Actual Loss: 0.2843\n",
      "Baseline Loss: 3.3316 | Actual Loss: 0.6991\n",
      "Baseline Loss: 3.4852 | Actual Loss: 0.8805\n",
      "Baseline Loss: 3.6458 | Actual Loss: 0.7323\n",
      "Baseline Loss: 3.5507 | Actual Loss: 0.7495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 102/1000 [00:52<08:20,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7429 | Actual Loss: 1.9190\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.8655\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6842\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.3497\n",
      "Epoch 102/1000: Train Loss: 0.7816, Val Loss: 0.9546\n",
      "Baseline Loss: 3.2975 | Actual Loss: 0.9198\n",
      "Baseline Loss: 3.4771 | Actual Loss: 1.1440\n",
      "Baseline Loss: 3.3816 | Actual Loss: 0.7118\n",
      "Baseline Loss: 3.4016 | Actual Loss: 0.7006\n",
      "Baseline Loss: 3.5045 | Actual Loss: 0.6520\n",
      "Baseline Loss: 3.5103 | Actual Loss: 0.6531\n",
      "Baseline Loss: 3.4888 | Actual Loss: 0.2436\n",
      "Baseline Loss: 3.6056 | Actual Loss: 1.1435\n",
      "Baseline Loss: 3.7572 | Actual Loss: 0.5249\n",
      "Baseline Loss: 3.2925 | Actual Loss: 0.6209\n",
      "Baseline Loss: 3.5370 | Actual Loss: 0.5654\n",
      "Baseline Loss: 3.6361 | Actual Loss: 1.0279\n",
      "Baseline Loss: 3.6496 | Actual Loss: 0.8639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 103/1000 [00:52<07:53,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4327 | Actual Loss: 0.7255\n",
      "Baseline Loss: 3.6182 | Actual Loss: 1.0520\n",
      "Baseline Loss: 3.1893 | Actual Loss: 2.9962\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.9331\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.3114\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.4346\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.8664\n",
      "Epoch 103/1000: Train Loss: 0.9091, Val Loss: 1.1364\n",
      "Baseline Loss: 3.5004 | Actual Loss: 1.0084\n",
      "Baseline Loss: 3.4494 | Actual Loss: 0.5647\n",
      "Baseline Loss: 3.3882 | Actual Loss: 1.3448\n",
      "Baseline Loss: 3.4395 | Actual Loss: 0.8760\n",
      "Baseline Loss: 3.5754 | Actual Loss: 0.7791\n",
      "Baseline Loss: 3.7320 | Actual Loss: 0.5194\n",
      "Baseline Loss: 3.6366 | Actual Loss: 0.4900\n",
      "Baseline Loss: 3.4077 | Actual Loss: 0.4176\n",
      "Baseline Loss: 3.3614 | Actual Loss: 0.6382\n",
      "Baseline Loss: 3.4776 | Actual Loss: 0.5302\n",
      "Baseline Loss: 3.6980 | Actual Loss: 0.6010\n",
      "Baseline Loss: 3.4814 | Actual Loss: 2.7773\n",
      "Baseline Loss: 3.4328 | Actual Loss: 0.7215\n",
      "Baseline Loss: 3.5422 | Actual Loss: 0.4630\n",
      "Baseline Loss: 3.5448 | Actual Loss: 0.9725\n",
      "Baseline Loss: 3.4399 | Actual Loss: 0.3670\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.0171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 104/1000 [00:53<08:08,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6229 | Actual Loss: 0.9406\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.5856\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.4264\n",
      "Epoch 104/1000: Train Loss: 0.8169, Val Loss: 0.9924\n",
      "Baseline Loss: 3.5737 | Actual Loss: 0.3588\n",
      "Baseline Loss: 3.4199 | Actual Loss: 0.7391\n",
      "Baseline Loss: 3.4654 | Actual Loss: 0.5224\n",
      "Baseline Loss: 3.4728 | Actual Loss: 0.3751\n",
      "Baseline Loss: 3.3292 | Actual Loss: 0.3147\n",
      "Baseline Loss: 3.5572 | Actual Loss: 1.0841\n",
      "Baseline Loss: 3.5967 | Actual Loss: 0.3212\n",
      "Baseline Loss: 3.4771 | Actual Loss: 0.8482\n",
      "Baseline Loss: 3.4214 | Actual Loss: 0.7745\n",
      "Baseline Loss: 3.3782 | Actual Loss: 0.8738\n",
      "Baseline Loss: 3.6632 | Actual Loss: 0.4337\n",
      "Baseline Loss: 3.7520 | Actual Loss: 2.7917\n",
      "Baseline Loss: 3.3780 | Actual Loss: 0.8616\n",
      "Baseline Loss: 3.5874 | Actual Loss: 0.5238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 105/1000 [00:53<08:17,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6181 | Actual Loss: 0.4199\n",
      "Baseline Loss: 3.5304 | Actual Loss: 1.5749\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.0511\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.0925\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.5909\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.5769\n",
      "Epoch 105/1000: Train Loss: 0.8011, Val Loss: 1.0778\n",
      "Baseline Loss: 3.6784 | Actual Loss: 2.7910\n",
      "Baseline Loss: 3.6975 | Actual Loss: 0.6764\n",
      "Baseline Loss: 3.4583 | Actual Loss: 1.1762\n",
      "Baseline Loss: 3.3638 | Actual Loss: 1.0759\n",
      "Baseline Loss: 3.4209 | Actual Loss: 0.4079\n",
      "Baseline Loss: 3.4322 | Actual Loss: 2.5595\n",
      "Baseline Loss: 3.4391 | Actual Loss: 0.7517\n",
      "Baseline Loss: 3.2535 | Actual Loss: 0.7209\n",
      "Baseline Loss: 3.4774 | Actual Loss: 0.8700\n",
      "Baseline Loss: 3.4282 | Actual Loss: 0.6784\n",
      "Baseline Loss: 3.5014 | Actual Loss: 0.5555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 106/1000 [00:54<07:49,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6451 | Actual Loss: 1.0050\n",
      "Baseline Loss: 3.5787 | Actual Loss: 0.7426\n",
      "Baseline Loss: 3.8000 | Actual Loss: 0.6020\n",
      "Baseline Loss: 3.4470 | Actual Loss: 0.8380\n",
      "Baseline Loss: 3.5078 | Actual Loss: 3.8813\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.9370\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.9235\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.5785\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.6619\n",
      "Epoch 106/1000: Train Loss: 1.2083, Val Loss: 1.0252\n",
      "Baseline Loss: 3.5097 | Actual Loss: 2.4118\n",
      "Baseline Loss: 3.4215 | Actual Loss: 0.8148\n",
      "Baseline Loss: 3.7170 | Actual Loss: 0.5210\n",
      "Baseline Loss: 3.5617 | Actual Loss: 0.9086\n",
      "Baseline Loss: 3.4575 | Actual Loss: 1.4853\n",
      "Baseline Loss: 3.3573 | Actual Loss: 0.5196\n",
      "Baseline Loss: 3.3963 | Actual Loss: 0.5516\n",
      "Baseline Loss: 3.5420 | Actual Loss: 1.3763\n",
      "Baseline Loss: 3.5302 | Actual Loss: 0.6763\n",
      "Baseline Loss: 3.5126 | Actual Loss: 1.0374\n",
      "Baseline Loss: 3.3605 | Actual Loss: 0.5661\n",
      "Baseline Loss: 3.5087 | Actual Loss: 0.7266\n",
      "Baseline Loss: 3.4076 | Actual Loss: 0.8429\n",
      "Baseline Loss: 3.5499 | Actual Loss: 0.8410\n",
      "Baseline Loss: 3.4287 | Actual Loss: 0.6365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 107/1000 [00:54<08:05,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4497 | Actual Loss: 0.4718\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.7209\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.8103\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6826\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.8499\n",
      "Epoch 107/1000: Train Loss: 0.8992, Val Loss: 1.0159\n",
      "Baseline Loss: 3.3111 | Actual Loss: 0.7466\n",
      "Baseline Loss: 3.5091 | Actual Loss: 0.6308\n",
      "Baseline Loss: 3.5543 | Actual Loss: 0.6262\n",
      "Baseline Loss: 3.5489 | Actual Loss: 0.8899\n",
      "Baseline Loss: 3.5503 | Actual Loss: 0.7895\n",
      "Baseline Loss: 3.4777 | Actual Loss: 1.0890\n",
      "Baseline Loss: 3.4923 | Actual Loss: 0.6204\n",
      "Baseline Loss: 3.5535 | Actual Loss: 0.4791\n",
      "Baseline Loss: 3.3887 | Actual Loss: 0.4834\n",
      "Baseline Loss: 3.5830 | Actual Loss: 3.4121\n",
      "Baseline Loss: 3.5210 | Actual Loss: 0.5903\n",
      "Baseline Loss: 3.5124 | Actual Loss: 0.7090\n",
      "Baseline Loss: 3.5662 | Actual Loss: 0.3891\n",
      "Baseline Loss: 3.7265 | Actual Loss: 0.5979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 108/1000 [00:55<07:55,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3903 | Actual Loss: 0.5459\n",
      "Baseline Loss: 3.0693 | Actual Loss: 1.1320\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.2640\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.4357\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.4882\n",
      "Baseline Loss: 3.4730 | Actual Loss: 1.0230\n",
      "Epoch 108/1000: Train Loss: 0.8582, Val Loss: 1.3027\n",
      "Baseline Loss: 3.5334 | Actual Loss: 0.6648\n",
      "Baseline Loss: 3.5742 | Actual Loss: 0.8340\n",
      "Baseline Loss: 3.4971 | Actual Loss: 0.6285\n",
      "Baseline Loss: 3.6971 | Actual Loss: 0.5201\n",
      "Baseline Loss: 3.5049 | Actual Loss: 2.0671\n",
      "Baseline Loss: 3.5368 | Actual Loss: 0.8061\n",
      "Baseline Loss: 3.3993 | Actual Loss: 0.2735\n",
      "Baseline Loss: 3.6371 | Actual Loss: 0.6471\n",
      "Baseline Loss: 3.3246 | Actual Loss: 2.6158\n",
      "Baseline Loss: 3.4403 | Actual Loss: 1.0240\n",
      "Baseline Loss: 3.3373 | Actual Loss: 0.1382\n",
      "Baseline Loss: 3.4510 | Actual Loss: 0.9878\n",
      "Baseline Loss: 3.5451 | Actual Loss: 1.0408\n",
      "Baseline Loss: 3.5044 | Actual Loss: 0.8892\n",
      "Baseline Loss: 3.4738 | Actual Loss: 0.8113\n",
      "Baseline Loss: 3.3754 | Actual Loss: 0.7836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 109/1000 [00:55<07:38,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7429 | Actual Loss: 1.6795\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.0199\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.5931\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.5381\n",
      "Epoch 109/1000: Train Loss: 0.9207, Val Loss: 0.9576\n",
      "Baseline Loss: 3.6099 | Actual Loss: 1.2721\n",
      "Baseline Loss: 3.4966 | Actual Loss: 1.0061\n",
      "Baseline Loss: 3.4845 | Actual Loss: 0.5296\n",
      "Baseline Loss: 3.4694 | Actual Loss: 1.7176\n",
      "Baseline Loss: 3.4922 | Actual Loss: 0.8421\n",
      "Baseline Loss: 3.3714 | Actual Loss: 1.0744\n",
      "Baseline Loss: 3.6410 | Actual Loss: 0.9647\n",
      "Baseline Loss: 3.6397 | Actual Loss: 0.9694\n",
      "Baseline Loss: 3.6102 | Actual Loss: 0.6554\n",
      "Baseline Loss: 3.5141 | Actual Loss: 0.7207\n",
      "Baseline Loss: 3.5012 | Actual Loss: 0.7879\n",
      "Baseline Loss: 3.2901 | Actual Loss: 0.9946\n",
      "Baseline Loss: 3.6643 | Actual Loss: 0.9050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 110/1000 [00:56<07:59,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4248 | Actual Loss: 0.3791\n",
      "Baseline Loss: 3.6273 | Actual Loss: 0.9026\n",
      "Baseline Loss: 3.3839 | Actual Loss: 0.1686\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.7230\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.1329\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6289\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.8939\n",
      "Epoch 110/1000: Train Loss: 0.8681, Val Loss: 1.0947\n",
      "Baseline Loss: 3.5250 | Actual Loss: 0.7727\n",
      "Baseline Loss: 3.5924 | Actual Loss: 0.5409\n",
      "Baseline Loss: 3.6367 | Actual Loss: 0.7366\n",
      "Baseline Loss: 3.7366 | Actual Loss: 0.4165\n",
      "Baseline Loss: 3.5249 | Actual Loss: 0.7399\n",
      "Baseline Loss: 3.3717 | Actual Loss: 1.0898\n",
      "Baseline Loss: 3.5214 | Actual Loss: 0.5637\n",
      "Baseline Loss: 3.5129 | Actual Loss: 1.3669\n",
      "Baseline Loss: 3.3006 | Actual Loss: 0.6568\n",
      "Baseline Loss: 3.7269 | Actual Loss: 0.4912\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.5413\n",
      "Baseline Loss: 3.5456 | Actual Loss: 1.7786\n",
      "Baseline Loss: 3.5006 | Actual Loss: 1.3260\n",
      "Baseline Loss: 3.5451 | Actual Loss: 0.5629\n",
      "Baseline Loss: 3.4247 | Actual Loss: 0.6961\n",
      "Baseline Loss: 2.9802 | Actual Loss: 0.3308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 111/1000 [00:56<07:59,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7429 | Actual Loss: 1.9784\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.1030\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.4978\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.6347\n",
      "Epoch 111/1000: Train Loss: 0.7882, Val Loss: 1.0535\n",
      "Baseline Loss: 3.5375 | Actual Loss: 0.3609\n",
      "Baseline Loss: 3.3044 | Actual Loss: 0.3516\n",
      "Baseline Loss: 3.5337 | Actual Loss: 0.2923\n",
      "Baseline Loss: 3.5368 | Actual Loss: 2.1247\n",
      "Baseline Loss: 3.4112 | Actual Loss: 0.8828\n",
      "Baseline Loss: 3.4742 | Actual Loss: 0.8763\n",
      "Baseline Loss: 3.5524 | Actual Loss: 0.6850\n",
      "Baseline Loss: 3.6545 | Actual Loss: 0.9170\n",
      "Baseline Loss: 3.6455 | Actual Loss: 0.5667\n",
      "Baseline Loss: 3.5216 | Actual Loss: 1.2080\n",
      "Baseline Loss: 3.7211 | Actual Loss: 0.7270\n",
      "Baseline Loss: 3.3283 | Actual Loss: 1.0708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 112/1000 [00:57<07:55,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4352 | Actual Loss: 0.8633\n",
      "Baseline Loss: 3.5825 | Actual Loss: 0.6829\n",
      "Baseline Loss: 3.4136 | Actual Loss: 0.6466\n",
      "Baseline Loss: 3.2482 | Actual Loss: 0.5478\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.0008\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.3010\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.4913\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.8654\n",
      "Epoch 112/1000: Train Loss: 0.8002, Val Loss: 1.1646\n",
      "Baseline Loss: 3.4169 | Actual Loss: 0.5062\n",
      "Baseline Loss: 3.5371 | Actual Loss: 1.0970\n",
      "Baseline Loss: 3.6266 | Actual Loss: 0.7417\n",
      "Baseline Loss: 3.3483 | Actual Loss: 0.7981\n",
      "Baseline Loss: 3.4390 | Actual Loss: 0.6566\n",
      "Baseline Loss: 3.3452 | Actual Loss: 0.5101\n",
      "Baseline Loss: 3.4442 | Actual Loss: 1.1898\n",
      "Baseline Loss: 3.5416 | Actual Loss: 3.6155\n",
      "Baseline Loss: 3.4090 | Actual Loss: 2.6477\n",
      "Baseline Loss: 3.5833 | Actual Loss: 0.9267\n",
      "Baseline Loss: 3.5585 | Actual Loss: 0.4668\n",
      "Baseline Loss: 3.5879 | Actual Loss: 0.8163\n",
      "Baseline Loss: 3.4656 | Actual Loss: 0.8993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█▏        | 113/1000 [00:57<08:10,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5421 | Actual Loss: 0.9809\n",
      "Baseline Loss: 3.5625 | Actual Loss: 0.5111\n",
      "Baseline Loss: 2.9741 | Actual Loss: 0.5067\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.9669\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.0019\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.5300\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.7244\n",
      "Epoch 113/1000: Train Loss: 1.0544, Val Loss: 1.0558\n",
      "Baseline Loss: 3.4930 | Actual Loss: 0.7341\n",
      "Baseline Loss: 3.5830 | Actual Loss: 0.7811\n",
      "Baseline Loss: 3.4690 | Actual Loss: 1.0447\n",
      "Baseline Loss: 3.5625 | Actual Loss: 0.6305\n",
      "Baseline Loss: 3.4108 | Actual Loss: 0.5859\n",
      "Baseline Loss: 3.4396 | Actual Loss: 0.9958\n",
      "Baseline Loss: 3.3024 | Actual Loss: 0.8145\n",
      "Baseline Loss: 3.5570 | Actual Loss: 0.6984\n",
      "Baseline Loss: 3.3996 | Actual Loss: 1.1777\n",
      "Baseline Loss: 3.5165 | Actual Loss: 1.7546\n",
      "Baseline Loss: 3.4624 | Actual Loss: 0.7638\n",
      "Baseline Loss: 3.6232 | Actual Loss: 1.4199\n",
      "Baseline Loss: 3.8156 | Actual Loss: 0.7472\n",
      "Baseline Loss: 3.5370 | Actual Loss: 0.3438\n",
      "Baseline Loss: 3.4969 | Actual Loss: 0.7495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█▏        | 114/1000 [00:58<08:20,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.1380 | Actual Loss: 1.0660\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.1424\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.9218\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.9296\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.6334\n",
      "Epoch 114/1000: Train Loss: 0.8942, Val Loss: 1.1568\n",
      "Baseline Loss: 3.4971 | Actual Loss: 0.4979\n",
      "Baseline Loss: 3.7320 | Actual Loss: 0.4585\n",
      "Baseline Loss: 3.6687 | Actual Loss: 0.7652\n",
      "Baseline Loss: 3.4930 | Actual Loss: 0.7309\n",
      "Baseline Loss: 3.6096 | Actual Loss: 0.7215\n",
      "Baseline Loss: 3.5124 | Actual Loss: 0.5278\n",
      "Baseline Loss: 3.6226 | Actual Loss: 1.3574\n",
      "Baseline Loss: 3.3150 | Actual Loss: 0.6961\n",
      "Baseline Loss: 3.3930 | Actual Loss: 0.7915\n",
      "Baseline Loss: 3.4287 | Actual Loss: 1.1285\n",
      "Baseline Loss: 3.2917 | Actual Loss: 1.3089\n",
      "Baseline Loss: 3.4803 | Actual Loss: 0.6081\n",
      "Baseline Loss: 3.5367 | Actual Loss: 1.2857\n",
      "Baseline Loss: 3.5787 | Actual Loss: 0.5393\n",
      "Baseline Loss: 3.4057 | Actual Loss: 0.5825\n",
      "Baseline Loss: 3.1333 | Actual Loss: 0.4365\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.7233\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.1135\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 115/1000 [00:59<08:10,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4730 | Actual Loss: 0.4670\n",
      "Epoch 115/1000: Train Loss: 0.7773, Val Loss: 0.9931\n",
      "Baseline Loss: 3.4538 | Actual Loss: 0.5323\n",
      "Baseline Loss: 3.5128 | Actual Loss: 0.9907\n",
      "Baseline Loss: 3.3975 | Actual Loss: 0.8472\n",
      "Baseline Loss: 3.3895 | Actual Loss: 1.3894\n",
      "Baseline Loss: 3.3883 | Actual Loss: 0.5457\n",
      "Baseline Loss: 3.4847 | Actual Loss: 0.3162\n",
      "Baseline Loss: 3.7224 | Actual Loss: 0.7390\n",
      "Baseline Loss: 3.4512 | Actual Loss: 0.7555\n",
      "Baseline Loss: 3.6135 | Actual Loss: 0.3722\n",
      "Baseline Loss: 3.6597 | Actual Loss: 1.1851\n",
      "Baseline Loss: 3.5447 | Actual Loss: 1.3469\n",
      "Baseline Loss: 3.6093 | Actual Loss: 0.4365\n",
      "Baseline Loss: 3.4806 | Actual Loss: 0.4688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 116/1000 [00:59<08:24,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3240 | Actual Loss: 0.6470\n",
      "Baseline Loss: 3.5492 | Actual Loss: 1.3910\n",
      "Baseline Loss: 3.6289 | Actual Loss: 4.1064\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.1066\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.3499\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6506\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.6660\n",
      "Epoch 116/1000: Train Loss: 1.0044, Val Loss: 1.1933\n",
      "Baseline Loss: 3.3276 | Actual Loss: 0.7959\n",
      "Baseline Loss: 3.6000 | Actual Loss: 0.8145\n",
      "Baseline Loss: 3.4318 | Actual Loss: 0.4955\n",
      "Baseline Loss: 3.3276 | Actual Loss: 0.7953\n",
      "Baseline Loss: 3.4686 | Actual Loss: 0.4228\n",
      "Baseline Loss: 3.8488 | Actual Loss: 0.7182\n",
      "Baseline Loss: 3.3402 | Actual Loss: 0.8610\n",
      "Baseline Loss: 3.5300 | Actual Loss: 0.5108\n",
      "Baseline Loss: 3.6451 | Actual Loss: 0.7451\n",
      "Baseline Loss: 3.4177 | Actual Loss: 0.6426\n",
      "Baseline Loss: 3.4206 | Actual Loss: 0.6683\n",
      "Baseline Loss: 3.6547 | Actual Loss: 0.5264\n",
      "Baseline Loss: 3.5043 | Actual Loss: 0.8506\n",
      "Baseline Loss: 3.5794 | Actual Loss: 0.3773\n",
      "Baseline Loss: 3.5535 | Actual Loss: 1.3121\n",
      "Baseline Loss: 3.3394 | Actual Loss: 0.2647\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.9218\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.8446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 117/1000 [01:00<08:28,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5384 | Actual Loss: 0.5375\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.7487\n",
      "Epoch 117/1000: Train Loss: 0.6751, Val Loss: 1.0131\n",
      "Baseline Loss: 3.5216 | Actual Loss: 0.2965\n",
      "Baseline Loss: 3.7574 | Actual Loss: 0.4168\n",
      "Baseline Loss: 3.5248 | Actual Loss: 0.7284\n",
      "Baseline Loss: 3.2922 | Actual Loss: 0.9910\n",
      "Baseline Loss: 3.6588 | Actual Loss: 0.7790\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.6524\n",
      "Baseline Loss: 3.3687 | Actual Loss: 0.5281\n",
      "Baseline Loss: 3.3616 | Actual Loss: 0.5134\n",
      "Baseline Loss: 3.4580 | Actual Loss: 1.0166\n",
      "Baseline Loss: 3.5408 | Actual Loss: 1.0510\n",
      "Baseline Loss: 3.3042 | Actual Loss: 0.8925\n",
      "Baseline Loss: 3.4769 | Actual Loss: 0.8063\n",
      "Baseline Loss: 3.3929 | Actual Loss: 0.6161\n",
      "Baseline Loss: 3.4958 | Actual Loss: 0.4323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 118/1000 [01:00<08:12,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5961 | Actual Loss: 1.4352\n",
      "Baseline Loss: 3.0526 | Actual Loss: 1.2795\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.5786\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.3471\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.7302\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.6683\n",
      "Epoch 118/1000: Train Loss: 0.7772, Val Loss: 1.0810\n",
      "Baseline Loss: 3.5667 | Actual Loss: 0.9877\n",
      "Baseline Loss: 3.5534 | Actual Loss: 0.3622\n",
      "Baseline Loss: 3.5534 | Actual Loss: 0.6852\n",
      "Baseline Loss: 3.7422 | Actual Loss: 0.6429\n",
      "Baseline Loss: 3.5328 | Actual Loss: 0.5615\n",
      "Baseline Loss: 3.4741 | Actual Loss: 0.1630\n",
      "Baseline Loss: 3.3918 | Actual Loss: 0.8209\n",
      "Baseline Loss: 3.4034 | Actual Loss: 1.2614\n",
      "Baseline Loss: 3.4216 | Actual Loss: 1.3228\n",
      "Baseline Loss: 3.5003 | Actual Loss: 1.0295\n",
      "Baseline Loss: 3.4223 | Actual Loss: 0.3444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 119/1000 [01:01<08:20,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3929 | Actual Loss: 0.6055\n",
      "Baseline Loss: 3.3850 | Actual Loss: 0.6051\n",
      "Baseline Loss: 3.3649 | Actual Loss: 0.8562\n",
      "Baseline Loss: 3.7027 | Actual Loss: 0.6469\n",
      "Baseline Loss: 3.3229 | Actual Loss: 0.4589\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.4253\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.1898\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6027\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.6822\n",
      "Epoch 119/1000: Train Loss: 0.7096, Val Loss: 0.9750\n",
      "Baseline Loss: 3.6599 | Actual Loss: 3.4219\n",
      "Baseline Loss: 3.5672 | Actual Loss: 0.7963\n",
      "Baseline Loss: 3.5968 | Actual Loss: 2.9922\n",
      "Baseline Loss: 3.3042 | Actual Loss: 0.6112\n",
      "Baseline Loss: 3.4134 | Actual Loss: 1.1565\n",
      "Baseline Loss: 3.3476 | Actual Loss: 0.8156\n",
      "Baseline Loss: 3.5417 | Actual Loss: 0.4964\n",
      "Baseline Loss: 3.4177 | Actual Loss: 0.5215\n",
      "Baseline Loss: 3.4357 | Actual Loss: 0.3328\n",
      "Baseline Loss: 3.5877 | Actual Loss: 3.8821\n",
      "Baseline Loss: 3.6678 | Actual Loss: 2.7770\n",
      "Baseline Loss: 3.3401 | Actual Loss: 0.9614\n",
      "Baseline Loss: 3.4849 | Actual Loss: 0.7052\n",
      "Baseline Loss: 3.5753 | Actual Loss: 0.5601\n",
      "Baseline Loss: 3.7372 | Actual Loss: 0.3563\n",
      "Baseline Loss: 3.2186 | Actual Loss: 0.6560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 120/1000 [01:01<08:09,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7429 | Actual Loss: 1.6419\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.8217\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.5350\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.7233\n",
      "Epoch 120/1000: Train Loss: 1.3152, Val Loss: 0.9305\n",
      "Baseline Loss: 3.4314 | Actual Loss: 0.6803\n",
      "Baseline Loss: 3.2562 | Actual Loss: 0.6784\n",
      "Baseline Loss: 3.3993 | Actual Loss: 0.8997\n",
      "Baseline Loss: 3.2926 | Actual Loss: 0.9623\n",
      "Baseline Loss: 3.6364 | Actual Loss: 2.0761\n",
      "Baseline Loss: 3.4580 | Actual Loss: 0.8537\n",
      "Baseline Loss: 3.4063 | Actual Loss: 0.8406\n",
      "Baseline Loss: 3.5122 | Actual Loss: 0.7471\n",
      "Baseline Loss: 3.9887 | Actual Loss: 1.2060\n",
      "Baseline Loss: 3.5206 | Actual Loss: 0.8519\n",
      "Baseline Loss: 3.6226 | Actual Loss: 0.8552\n",
      "Baseline Loss: 3.6135 | Actual Loss: 1.1526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 121/1000 [01:02<08:23,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5920 | Actual Loss: 0.9116\n",
      "Baseline Loss: 3.5527 | Actual Loss: 0.5426\n",
      "Baseline Loss: 3.4325 | Actual Loss: 0.6289\n",
      "Baseline Loss: 3.2653 | Actual Loss: 0.6446\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.6200\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.2760\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.7350\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.6364\n",
      "Epoch 121/1000: Train Loss: 0.9082, Val Loss: 1.0668\n",
      "Baseline Loss: 3.6092 | Actual Loss: 0.8487\n",
      "Baseline Loss: 3.6972 | Actual Loss: 0.4577\n",
      "Baseline Loss: 3.5578 | Actual Loss: 0.9009\n",
      "Baseline Loss: 3.4544 | Actual Loss: 0.8485\n",
      "Baseline Loss: 3.2977 | Actual Loss: 1.0072\n",
      "Baseline Loss: 3.5012 | Actual Loss: 1.0920\n",
      "Baseline Loss: 3.2444 | Actual Loss: 0.7449\n",
      "Baseline Loss: 3.3958 | Actual Loss: 0.4609\n",
      "Baseline Loss: 3.6833 | Actual Loss: 0.9060\n",
      "Baseline Loss: 3.5451 | Actual Loss: 1.5448\n",
      "Baseline Loss: 3.6688 | Actual Loss: 0.4233\n",
      "Baseline Loss: 3.3814 | Actual Loss: 0.7093\n",
      "Baseline Loss: 3.4544 | Actual Loss: 0.5548\n",
      "Baseline Loss: 3.6148 | Actual Loss: 0.9372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 122/1000 [01:03<08:25,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4168 | Actual Loss: 0.3542\n",
      "Baseline Loss: 3.2668 | Actual Loss: 0.8029\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.7239\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.8877\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.5692\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.7977\n",
      "Epoch 122/1000: Train Loss: 0.7871, Val Loss: 0.9946\n",
      "Baseline Loss: 3.4579 | Actual Loss: 0.4782\n",
      "Baseline Loss: 3.3818 | Actual Loss: 0.5606\n",
      "Baseline Loss: 3.4613 | Actual Loss: 0.8740\n",
      "Baseline Loss: 3.5277 | Actual Loss: 0.4804\n",
      "Baseline Loss: 3.4889 | Actual Loss: 0.6831\n",
      "Baseline Loss: 3.7521 | Actual Loss: 0.4771\n",
      "Baseline Loss: 3.4388 | Actual Loss: 1.0557\n",
      "Baseline Loss: 3.4352 | Actual Loss: 0.4374\n",
      "Baseline Loss: 3.4217 | Actual Loss: 0.7630\n",
      "Baseline Loss: 3.6645 | Actual Loss: 0.6519\n",
      "Baseline Loss: 3.5375 | Actual Loss: 0.4776\n",
      "Baseline Loss: 3.4397 | Actual Loss: 0.6368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 123/1000 [01:03<08:11,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5165 | Actual Loss: 0.7084\n",
      "Baseline Loss: 3.3340 | Actual Loss: 0.8388\n",
      "Baseline Loss: 3.4034 | Actual Loss: 1.9715\n",
      "Baseline Loss: 3.9410 | Actual Loss: 0.6427\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.7156\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.8064\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.8716\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.5372\n",
      "Epoch 123/1000: Train Loss: 0.7336, Val Loss: 0.9827\n",
      "Baseline Loss: 3.2706 | Actual Loss: 0.9966\n",
      "Baseline Loss: 3.4096 | Actual Loss: 0.5851\n",
      "Baseline Loss: 3.3997 | Actual Loss: 0.5668\n",
      "Baseline Loss: 3.6280 | Actual Loss: 0.9589\n",
      "Baseline Loss: 3.5328 | Actual Loss: 0.6481\n",
      "Baseline Loss: 3.5123 | Actual Loss: 1.2447\n",
      "Baseline Loss: 3.3757 | Actual Loss: 1.0429\n",
      "Baseline Loss: 3.4965 | Actual Loss: 0.7203\n",
      "Baseline Loss: 3.4362 | Actual Loss: 0.5729\n",
      "Baseline Loss: 3.6828 | Actual Loss: 3.3147\n",
      "Baseline Loss: 3.6927 | Actual Loss: 0.5207\n",
      "Baseline Loss: 3.5326 | Actual Loss: 0.3739\n",
      "Baseline Loss: 3.7322 | Actual Loss: 0.8945\n",
      "Baseline Loss: 3.3639 | Actual Loss: 0.7202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 124/1000 [01:04<08:25,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6226 | Actual Loss: 0.6771\n",
      "Baseline Loss: 3.2424 | Actual Loss: 0.9453\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.7948\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.9626\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.8243\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.6471\n",
      "Epoch 124/1000: Train Loss: 0.9239, Val Loss: 1.0572\n",
      "Baseline Loss: 3.4553 | Actual Loss: 0.8170\n",
      "Baseline Loss: 3.4227 | Actual Loss: 0.8060\n",
      "Baseline Loss: 3.8435 | Actual Loss: 0.8022\n",
      "Baseline Loss: 3.5365 | Actual Loss: 0.5812\n",
      "Baseline Loss: 3.4278 | Actual Loss: 0.6125\n",
      "Baseline Loss: 3.5790 | Actual Loss: 0.4815\n",
      "Baseline Loss: 3.5967 | Actual Loss: 0.7610\n",
      "Baseline Loss: 3.4141 | Actual Loss: 0.3436\n",
      "Baseline Loss: 3.5667 | Actual Loss: 0.5333\n",
      "Baseline Loss: 3.3846 | Actual Loss: 0.5802\n",
      "Baseline Loss: 3.4028 | Actual Loss: 0.9326\n",
      "Baseline Loss: 3.6461 | Actual Loss: 0.8773\n",
      "Baseline Loss: 3.3674 | Actual Loss: 1.3226\n",
      "Baseline Loss: 3.6092 | Actual Loss: 0.9952\n",
      "Baseline Loss: 3.4776 | Actual Loss: 0.6946\n",
      "Baseline Loss: 3.1953 | Actual Loss: 0.3888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▎        | 125/1000 [01:04<08:27,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7429 | Actual Loss: 1.6848\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.0526\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6527\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.7091\n",
      "Epoch 125/1000: Train Loss: 0.7206, Val Loss: 1.0248\n",
      "Baseline Loss: 3.4895 | Actual Loss: 0.5477\n",
      "Baseline Loss: 3.4931 | Actual Loss: 1.1106\n",
      "Baseline Loss: 3.5168 | Actual Loss: 1.3572\n",
      "Baseline Loss: 3.4468 | Actual Loss: 0.6159\n",
      "Baseline Loss: 3.3855 | Actual Loss: 0.2980\n",
      "Baseline Loss: 3.6054 | Actual Loss: 0.8784\n",
      "Baseline Loss: 3.2275 | Actual Loss: 0.8236\n",
      "Baseline Loss: 3.5829 | Actual Loss: 0.3767\n",
      "Baseline Loss: 3.4625 | Actual Loss: 0.8239\n",
      "Baseline Loss: 3.4363 | Actual Loss: 1.3442\n",
      "Baseline Loss: 3.4963 | Actual Loss: 0.8621\n",
      "Baseline Loss: 3.6832 | Actual Loss: 0.7036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 126/1000 [01:05<08:13,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4536 | Actual Loss: 0.6265\n",
      "Baseline Loss: 3.5451 | Actual Loss: 0.7517\n",
      "Baseline Loss: 3.7627 | Actual Loss: 3.1090\n",
      "Baseline Loss: 3.3226 | Actual Loss: 0.3897\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.5588\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.0170\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.5518\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.8427\n",
      "Epoch 126/1000: Train Loss: 0.9137, Val Loss: 0.9926\n",
      "Baseline Loss: 3.6137 | Actual Loss: 0.3564\n",
      "Baseline Loss: 3.6692 | Actual Loss: 0.6103\n",
      "Baseline Loss: 3.4932 | Actual Loss: 0.5643\n",
      "Baseline Loss: 3.5748 | Actual Loss: 0.5273\n",
      "Baseline Loss: 3.3173 | Actual Loss: 0.7440\n",
      "Baseline Loss: 3.3685 | Actual Loss: 0.7257\n",
      "Baseline Loss: 3.5168 | Actual Loss: 0.9400\n",
      "Baseline Loss: 3.6019 | Actual Loss: 1.6867\n",
      "Baseline Loss: 3.5089 | Actual Loss: 0.5244\n",
      "Baseline Loss: 3.3535 | Actual Loss: 0.7357\n",
      "Baseline Loss: 3.5647 | Actual Loss: 1.0019\n",
      "Baseline Loss: 3.5338 | Actual Loss: 1.0519\n",
      "Baseline Loss: 3.4858 | Actual Loss: 1.2979\n",
      "Baseline Loss: 3.4695 | Actual Loss: 0.6835\n",
      "Baseline Loss: 3.9561 | Actual Loss: 0.1435\n",
      "Baseline Loss: 3.1956 | Actual Loss: 2.5654\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.6202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 127/1000 [01:05<08:21,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6229 | Actual Loss: 1.0515\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6464\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.6051\n",
      "Epoch 127/1000: Train Loss: 0.8849, Val Loss: 0.9808\n",
      "Baseline Loss: 3.4932 | Actual Loss: 0.7135\n",
      "Baseline Loss: 3.4284 | Actual Loss: 0.8135\n",
      "Baseline Loss: 3.6234 | Actual Loss: 0.4516\n",
      "Baseline Loss: 3.5332 | Actual Loss: 0.7273\n",
      "Baseline Loss: 3.5798 | Actual Loss: 1.0957\n",
      "Baseline Loss: 3.4035 | Actual Loss: 0.7219\n",
      "Baseline Loss: 3.5622 | Actual Loss: 1.3090\n",
      "Baseline Loss: 3.4738 | Actual Loss: 0.6310\n",
      "Baseline Loss: 3.7732 | Actual Loss: 0.3346\n",
      "Baseline Loss: 3.4102 | Actual Loss: 0.6232\n",
      "Baseline Loss: 3.5208 | Actual Loss: 0.6423\n",
      "Baseline Loss: 3.4894 | Actual Loss: 1.3694\n",
      "Baseline Loss: 3.6193 | Actual Loss: 1.1546\n",
      "Baseline Loss: 3.4465 | Actual Loss: 0.7134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 128/1000 [01:06<08:06,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4346 | Actual Loss: 0.6971\n",
      "Baseline Loss: 3.3751 | Actual Loss: 0.6117\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.8541\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.1098\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6428\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.6389\n",
      "Epoch 128/1000: Train Loss: 0.7881, Val Loss: 1.0614\n",
      "Baseline Loss: 3.5006 | Actual Loss: 0.6476\n",
      "Baseline Loss: 3.4900 | Actual Loss: 0.6976\n",
      "Baseline Loss: 3.3791 | Actual Loss: 0.9305\n",
      "Baseline Loss: 3.5359 | Actual Loss: 0.9655\n",
      "Baseline Loss: 3.4685 | Actual Loss: 0.3307\n",
      "Baseline Loss: 3.4578 | Actual Loss: 0.5831\n",
      "Baseline Loss: 3.5343 | Actual Loss: 0.7369\n",
      "Baseline Loss: 3.5016 | Actual Loss: 1.5005\n",
      "Baseline Loss: 3.5581 | Actual Loss: 0.9202\n",
      "Baseline Loss: 3.4430 | Actual Loss: 0.7504\n",
      "Baseline Loss: 3.7317 | Actual Loss: 3.0092\n",
      "Baseline Loss: 3.4033 | Actual Loss: 0.5902\n",
      "Baseline Loss: 3.4661 | Actual Loss: 1.7195\n",
      "Baseline Loss: 3.4280 | Actual Loss: 0.9116\n",
      "Baseline Loss: 3.6405 | Actual Loss: 0.8148\n",
      "Baseline Loss: 3.2665 | Actual Loss: 0.2627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 129/1000 [01:07<08:17,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7429 | Actual Loss: 1.4351\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.0028\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.8311\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.5280\n",
      "Epoch 129/1000: Train Loss: 0.9607, Val Loss: 0.9492\n",
      "Baseline Loss: 3.4508 | Actual Loss: 0.5713\n",
      "Baseline Loss: 3.4459 | Actual Loss: 0.4818\n",
      "Baseline Loss: 3.6922 | Actual Loss: 0.8535\n",
      "Baseline Loss: 3.6782 | Actual Loss: 0.5249\n",
      "Baseline Loss: 3.3748 | Actual Loss: 0.8851\n",
      "Baseline Loss: 3.4970 | Actual Loss: 1.3546\n",
      "Baseline Loss: 3.5832 | Actual Loss: 1.0898\n",
      "Baseline Loss: 3.7478 | Actual Loss: 1.0755\n",
      "Baseline Loss: 3.3335 | Actual Loss: 0.5607\n",
      "Baseline Loss: 3.5010 | Actual Loss: 1.0483\n",
      "Baseline Loss: 3.5081 | Actual Loss: 0.6722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 130/1000 [01:07<08:23,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3996 | Actual Loss: 0.6213\n",
      "Baseline Loss: 3.6102 | Actual Loss: 0.4809\n",
      "Baseline Loss: 3.3924 | Actual Loss: 0.9568\n",
      "Baseline Loss: 3.4425 | Actual Loss: 0.8511\n",
      "Baseline Loss: 3.4112 | Actual Loss: 0.4491\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.3951\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.1192\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.7403\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.6504\n",
      "Epoch 130/1000: Train Loss: 0.7798, Val Loss: 0.9763\n",
      "Baseline Loss: 3.6228 | Actual Loss: 0.6273\n",
      "Baseline Loss: 3.7417 | Actual Loss: 1.0297\n",
      "Baseline Loss: 3.5043 | Actual Loss: 1.5224\n",
      "Baseline Loss: 3.5459 | Actual Loss: 0.5763\n",
      "Baseline Loss: 3.6355 | Actual Loss: 0.6719\n",
      "Baseline Loss: 3.4062 | Actual Loss: 1.1349\n",
      "Baseline Loss: 3.3409 | Actual Loss: 0.9162\n",
      "Baseline Loss: 3.3124 | Actual Loss: 0.6467\n",
      "Baseline Loss: 3.5712 | Actual Loss: 0.5746\n",
      "Baseline Loss: 3.4143 | Actual Loss: 0.6069\n",
      "Baseline Loss: 3.4424 | Actual Loss: 1.0619\n",
      "Baseline Loss: 3.3956 | Actual Loss: 0.5800\n",
      "Baseline Loss: 3.5162 | Actual Loss: 0.5693\n",
      "Baseline Loss: 3.8488 | Actual Loss: 0.8456\n",
      "Baseline Loss: 3.5123 | Actual Loss: 0.7579\n",
      "Baseline Loss: 3.6056 | Actual Loss: 0.7749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 131/1000 [01:08<08:10,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7429 | Actual Loss: 1.7673\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.3113\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6472\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.6573\n",
      "Epoch 131/1000: Train Loss: 0.8060, Val Loss: 1.0958\n",
      "Baseline Loss: 3.5213 | Actual Loss: 0.5661\n",
      "Baseline Loss: 3.4821 | Actual Loss: 0.6934\n",
      "Baseline Loss: 3.5885 | Actual Loss: 0.4984\n",
      "Baseline Loss: 3.5788 | Actual Loss: 0.5869\n",
      "Baseline Loss: 3.5619 | Actual Loss: 0.5949\n",
      "Baseline Loss: 3.4143 | Actual Loss: 0.8842\n",
      "Baseline Loss: 3.4429 | Actual Loss: 0.8434\n",
      "Baseline Loss: 3.6598 | Actual Loss: 1.0032\n",
      "Baseline Loss: 3.4103 | Actual Loss: 0.9131\n",
      "Baseline Loss: 3.4036 | Actual Loss: 1.5080\n",
      "Baseline Loss: 3.5574 | Actual Loss: 1.5226\n",
      "Baseline Loss: 3.3989 | Actual Loss: 0.7175\n",
      "Baseline Loss: 3.7211 | Actual Loss: 0.5974\n",
      "Baseline Loss: 3.3895 | Actual Loss: 1.3191\n",
      "Baseline Loss: 3.4286 | Actual Loss: 0.7203\n",
      "Baseline Loss: 3.5195 | Actual Loss: 0.1594\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.8618\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.9963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 132/1000 [01:08<08:13,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5384 | Actual Loss: 0.6979\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.6670\n",
      "Epoch 132/1000: Train Loss: 0.8205, Val Loss: 1.0557\n",
      "Baseline Loss: 3.4694 | Actual Loss: 0.7956\n",
      "Baseline Loss: 3.6453 | Actual Loss: 0.4728\n",
      "Baseline Loss: 3.6049 | Actual Loss: 0.6520\n",
      "Baseline Loss: 3.4511 | Actual Loss: 0.8241\n",
      "Baseline Loss: 3.5204 | Actual Loss: 0.6612\n",
      "Baseline Loss: 3.4468 | Actual Loss: 0.7587\n",
      "Baseline Loss: 3.4655 | Actual Loss: 0.9796\n",
      "Baseline Loss: 3.8956 | Actual Loss: 0.9783\n",
      "Baseline Loss: 3.5379 | Actual Loss: 0.9775\n",
      "Baseline Loss: 3.4650 | Actual Loss: 0.9641\n",
      "Baseline Loss: 3.4396 | Actual Loss: 0.4725\n",
      "Baseline Loss: 3.4281 | Actual Loss: 0.7477\n",
      "Baseline Loss: 3.5200 | Actual Loss: 0.8829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 133/1000 [01:09<08:16,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4619 | Actual Loss: 0.4095\n",
      "Baseline Loss: 3.6971 | Actual Loss: 0.3620\n",
      "Baseline Loss: 3.4028 | Actual Loss: 0.3710\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.6942\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.7856\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.5830\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.6450\n",
      "Epoch 133/1000: Train Loss: 0.7068, Val Loss: 0.9270\n",
      "Baseline Loss: 3.3889 | Actual Loss: 0.4768\n",
      "Baseline Loss: 3.4568 | Actual Loss: 0.7386\n",
      "Baseline Loss: 3.4364 | Actual Loss: 0.4102\n",
      "Baseline Loss: 3.4469 | Actual Loss: 0.8773\n",
      "Baseline Loss: 3.9126 | Actual Loss: 0.8554\n",
      "Baseline Loss: 3.5581 | Actual Loss: 0.8148\n",
      "Baseline Loss: 3.5295 | Actual Loss: 1.2670\n",
      "Baseline Loss: 3.3267 | Actual Loss: 0.5644\n",
      "Baseline Loss: 3.3713 | Actual Loss: 0.6681\n",
      "Baseline Loss: 3.6228 | Actual Loss: 0.6785\n",
      "Baseline Loss: 3.5789 | Actual Loss: 1.0782\n",
      "Baseline Loss: 3.6365 | Actual Loss: 0.4221\n",
      "Baseline Loss: 3.3961 | Actual Loss: 1.0774\n",
      "Baseline Loss: 3.5870 | Actual Loss: 0.3958\n",
      "Baseline Loss: 3.4729 | Actual Loss: 0.7530\n",
      "Baseline Loss: 3.0195 | Actual Loss: 0.5137\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.6287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 134/1000 [01:09<08:05,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6229 | Actual Loss: 1.0934\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.7383\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.5460\n",
      "Epoch 134/1000: Train Loss: 0.7245, Val Loss: 1.0016\n",
      "Baseline Loss: 3.3209 | Actual Loss: 0.6917\n",
      "Baseline Loss: 3.9129 | Actual Loss: 0.7582\n",
      "Baseline Loss: 3.4970 | Actual Loss: 0.6960\n",
      "Baseline Loss: 3.4543 | Actual Loss: 1.3013\n",
      "Baseline Loss: 3.4767 | Actual Loss: 0.4341\n",
      "Baseline Loss: 3.5288 | Actual Loss: 0.5388\n",
      "Baseline Loss: 3.6089 | Actual Loss: 0.4392\n",
      "Baseline Loss: 3.5498 | Actual Loss: 0.5082\n",
      "Baseline Loss: 3.4888 | Actual Loss: 0.7722\n",
      "Baseline Loss: 3.4773 | Actual Loss: 0.4765\n",
      "Baseline Loss: 3.3696 | Actual Loss: 0.4240\n",
      "Baseline Loss: 3.7519 | Actual Loss: 0.4817\n",
      "Baseline Loss: 3.3820 | Actual Loss: 0.4777\n",
      "Baseline Loss: 3.3754 | Actual Loss: 0.9424\n",
      "Baseline Loss: 3.5419 | Actual Loss: 0.8486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▎        | 135/1000 [01:10<07:59,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.0204 | Actual Loss: 0.6373\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.5089\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.2108\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.7142\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.5993\n",
      "Epoch 135/1000: Train Loss: 0.6517, Val Loss: 1.0083\n",
      "Baseline Loss: 3.4216 | Actual Loss: 0.7744\n",
      "Baseline Loss: 3.4317 | Actual Loss: 0.9586\n",
      "Baseline Loss: 3.4655 | Actual Loss: 0.7627\n",
      "Baseline Loss: 3.4823 | Actual Loss: 0.7102\n",
      "Baseline Loss: 3.7072 | Actual Loss: 1.5248\n",
      "Baseline Loss: 3.2957 | Actual Loss: 0.8355\n",
      "Baseline Loss: 3.4740 | Actual Loss: 1.0055\n",
      "Baseline Loss: 3.5700 | Actual Loss: 0.2428\n",
      "Baseline Loss: 3.4925 | Actual Loss: 0.8459\n",
      "Baseline Loss: 3.4583 | Actual Loss: 0.7730\n",
      "Baseline Loss: 3.5281 | Actual Loss: 0.2076\n",
      "Baseline Loss: 3.5956 | Actual Loss: 0.8237\n",
      "Baseline Loss: 3.4459 | Actual Loss: 0.5123\n",
      "Baseline Loss: 3.6231 | Actual Loss: 0.9126\n",
      "Baseline Loss: 3.6008 | Actual Loss: 1.3278\n",
      "Baseline Loss: 3.5091 | Actual Loss: 0.4299\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.9154\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.0250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▎        | 136/1000 [01:10<08:01,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5384 | Actual Loss: 0.5592\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.6350\n",
      "Epoch 136/1000: Train Loss: 0.7905, Val Loss: 1.0336\n",
      "Baseline Loss: 3.4393 | Actual Loss: 0.7370\n",
      "Baseline Loss: 3.6317 | Actual Loss: 0.7372\n",
      "Baseline Loss: 3.6447 | Actual Loss: 0.6380\n",
      "Baseline Loss: 3.2477 | Actual Loss: 1.1250\n",
      "Baseline Loss: 3.4333 | Actual Loss: 0.4734\n",
      "Baseline Loss: 3.3406 | Actual Loss: 0.5540\n",
      "Baseline Loss: 3.5420 | Actual Loss: 0.3332\n",
      "Baseline Loss: 3.5410 | Actual Loss: 0.7857\n",
      "Baseline Loss: 3.3149 | Actual Loss: 0.4168\n",
      "Baseline Loss: 3.7366 | Actual Loss: 0.6453\n",
      "Baseline Loss: 3.4977 | Actual Loss: 0.6672\n",
      "Baseline Loss: 3.3969 | Actual Loss: 0.5596\n",
      "Baseline Loss: 3.6363 | Actual Loss: 1.2054\n",
      "Baseline Loss: 3.5537 | Actual Loss: 0.8820\n",
      "Baseline Loss: 3.3043 | Actual Loss: 0.3786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▎        | 137/1000 [01:11<07:54,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.8208 | Actual Loss: 3.6220\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.8273\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.0868\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6258\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.6121\n",
      "Epoch 137/1000: Train Loss: 0.8600, Val Loss: 1.0380\n",
      "Baseline Loss: 3.4970 | Actual Loss: 0.6308\n",
      "Baseline Loss: 3.5700 | Actual Loss: 0.8883\n",
      "Baseline Loss: 3.3757 | Actual Loss: 0.7727\n",
      "Baseline Loss: 3.5410 | Actual Loss: 0.8938\n",
      "Baseline Loss: 3.4818 | Actual Loss: 1.3157\n",
      "Baseline Loss: 3.4849 | Actual Loss: 0.8272\n",
      "Baseline Loss: 3.3112 | Actual Loss: 0.6471\n",
      "Baseline Loss: 3.5922 | Actual Loss: 0.4525\n",
      "Baseline Loss: 3.5952 | Actual Loss: 0.7974\n",
      "Baseline Loss: 3.5075 | Actual Loss: 0.7318\n",
      "Baseline Loss: 3.3751 | Actual Loss: 0.5717\n",
      "Baseline Loss: 3.6358 | Actual Loss: 0.9217\n",
      "Baseline Loss: 3.3991 | Actual Loss: 0.5728\n",
      "Baseline Loss: 3.5701 | Actual Loss: 0.5579\n",
      "Baseline Loss: 3.6219 | Actual Loss: 1.6766\n",
      "Baseline Loss: 3.3310 | Actual Loss: 0.7385\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.7822\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.5569\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.5451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 138/1000 [01:12<07:51,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4730 | Actual Loss: 0.7668\n",
      "Epoch 138/1000: Train Loss: 0.8123, Val Loss: 1.1627\n",
      "Baseline Loss: 3.5287 | Actual Loss: 0.9325\n",
      "Baseline Loss: 3.4702 | Actual Loss: 0.7663\n",
      "Baseline Loss: 3.6455 | Actual Loss: 1.5205\n",
      "Baseline Loss: 3.4321 | Actual Loss: 0.6195\n",
      "Baseline Loss: 3.3959 | Actual Loss: 0.4248\n",
      "Baseline Loss: 3.4212 | Actual Loss: 0.5918\n",
      "Baseline Loss: 3.4211 | Actual Loss: 1.9923\n",
      "Baseline Loss: 3.5620 | Actual Loss: 0.6716\n",
      "Baseline Loss: 3.4591 | Actual Loss: 0.9155\n",
      "Baseline Loss: 3.5197 | Actual Loss: 0.7265\n",
      "Baseline Loss: 3.5197 | Actual Loss: 0.4863\n",
      "Baseline Loss: 3.6231 | Actual Loss: 0.7005\n",
      "Baseline Loss: 3.4810 | Actual Loss: 0.9648\n",
      "Baseline Loss: 3.4425 | Actual Loss: 0.2587\n",
      "Baseline Loss: 3.4171 | Actual Loss: 0.6683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 139/1000 [01:12<07:50,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7659 | Actual Loss: 3.8864\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.0007\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.7746\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.5652\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.6155\n",
      "Epoch 139/1000: Train Loss: 1.0079, Val Loss: 0.9890\n",
      "Baseline Loss: 3.6782 | Actual Loss: 0.6385\n",
      "Baseline Loss: 3.4542 | Actual Loss: 0.3878\n",
      "Baseline Loss: 3.4241 | Actual Loss: 0.4428\n",
      "Baseline Loss: 3.4358 | Actual Loss: 0.7011\n",
      "Baseline Loss: 3.3435 | Actual Loss: 0.5792\n",
      "Baseline Loss: 3.6735 | Actual Loss: 1.6012\n",
      "Baseline Loss: 3.4065 | Actual Loss: 0.5100\n",
      "Baseline Loss: 3.4037 | Actual Loss: 0.4942\n",
      "Baseline Loss: 3.5662 | Actual Loss: 0.9558\n",
      "Baseline Loss: 3.4621 | Actual Loss: 0.5084\n",
      "Baseline Loss: 3.4960 | Actual Loss: 0.7819\n",
      "Baseline Loss: 3.6549 | Actual Loss: 1.0111\n",
      "Baseline Loss: 3.4429 | Actual Loss: 0.5894\n",
      "Baseline Loss: 3.4596 | Actual Loss: 0.7193\n",
      "Baseline Loss: 3.6085 | Actual Loss: 0.7986\n",
      "Baseline Loss: 3.3052 | Actual Loss: 3.2094\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.0591\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.9443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 140/1000 [01:13<07:43,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5384 | Actual Loss: 0.6935\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.6579\n",
      "Epoch 140/1000: Train Loss: 0.8705, Val Loss: 1.0887\n",
      "Baseline Loss: 3.5706 | Actual Loss: 0.4974\n",
      "Baseline Loss: 3.5008 | Actual Loss: 0.9844\n",
      "Baseline Loss: 3.4282 | Actual Loss: 0.6220\n",
      "Baseline Loss: 3.5743 | Actual Loss: 1.0462\n",
      "Baseline Loss: 3.7221 | Actual Loss: 0.7343\n",
      "Baseline Loss: 3.3583 | Actual Loss: 0.6208\n",
      "Baseline Loss: 3.4885 | Actual Loss: 0.6890\n",
      "Baseline Loss: 3.5453 | Actual Loss: 0.3952\n",
      "Baseline Loss: 3.5660 | Actual Loss: 1.4212\n",
      "Baseline Loss: 3.3340 | Actual Loss: 0.7414\n",
      "Baseline Loss: 3.3819 | Actual Loss: 0.7983\n",
      "Baseline Loss: 3.4025 | Actual Loss: 0.5245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 141/1000 [01:13<07:51,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5254 | Actual Loss: 0.8472\n",
      "Baseline Loss: 3.5706 | Actual Loss: 0.4641\n",
      "Baseline Loss: 3.6046 | Actual Loss: 0.9323\n",
      "Baseline Loss: 3.1956 | Actual Loss: 0.3654\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.7219\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.9336\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6419\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.6477\n",
      "Epoch 141/1000: Train Loss: 0.7302, Val Loss: 0.9863\n",
      "Baseline Loss: 3.5533 | Actual Loss: 0.6499\n",
      "Baseline Loss: 3.3212 | Actual Loss: 0.8478\n",
      "Baseline Loss: 3.4776 | Actual Loss: 0.5668\n",
      "Baseline Loss: 3.5656 | Actual Loss: 0.5630\n",
      "Baseline Loss: 3.3820 | Actual Loss: 0.7432\n",
      "Baseline Loss: 3.5123 | Actual Loss: 0.2478\n",
      "Baseline Loss: 3.4965 | Actual Loss: 0.5003\n",
      "Baseline Loss: 3.5126 | Actual Loss: 0.4930\n",
      "Baseline Loss: 3.5624 | Actual Loss: 0.9259\n",
      "Baseline Loss: 3.4427 | Actual Loss: 1.2265\n",
      "Baseline Loss: 3.4434 | Actual Loss: 1.0607\n",
      "Baseline Loss: 3.6728 | Actual Loss: 0.8392\n",
      "Baseline Loss: 3.6093 | Actual Loss: 0.5909\n",
      "Baseline Loss: 3.4619 | Actual Loss: 1.0827\n",
      "Baseline Loss: 3.3857 | Actual Loss: 0.4105\n",
      "Baseline Loss: 3.3476 | Actual Loss: 2.4357\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.7902\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.1113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 142/1000 [01:14<07:46,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5384 | Actual Loss: 0.7504\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.6373\n",
      "Epoch 142/1000: Train Loss: 0.8240, Val Loss: 1.0723\n",
      "Baseline Loss: 3.4436 | Actual Loss: 0.9883\n",
      "Baseline Loss: 3.8155 | Actual Loss: 0.5919\n",
      "Baseline Loss: 3.5963 | Actual Loss: 0.6305\n",
      "Baseline Loss: 3.3051 | Actual Loss: 0.7712\n",
      "Baseline Loss: 3.4619 | Actual Loss: 0.5765\n",
      "Baseline Loss: 3.4859 | Actual Loss: 0.6805\n",
      "Baseline Loss: 3.3444 | Actual Loss: 0.6019\n",
      "Baseline Loss: 3.4931 | Actual Loss: 0.6422\n",
      "Baseline Loss: 3.6417 | Actual Loss: 0.6964\n",
      "Baseline Loss: 3.5586 | Actual Loss: 0.5553\n",
      "Baseline Loss: 3.4074 | Actual Loss: 0.7357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 143/1000 [01:14<07:53,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5044 | Actual Loss: 0.7992\n",
      "Baseline Loss: 3.6144 | Actual Loss: 0.3929\n",
      "Baseline Loss: 3.4177 | Actual Loss: 1.0845\n",
      "Baseline Loss: 3.4250 | Actual Loss: 0.5239\n",
      "Baseline Loss: 3.1609 | Actual Loss: 0.8000\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.8216\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.9376\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.5739\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.5326\n",
      "Epoch 143/1000: Train Loss: 0.6919, Val Loss: 0.9664\n",
      "Baseline Loss: 3.5792 | Actual Loss: 0.6267\n",
      "Baseline Loss: 3.5130 | Actual Loss: 0.6803\n",
      "Baseline Loss: 3.6051 | Actual Loss: 0.8434\n",
      "Baseline Loss: 3.4739 | Actual Loss: 0.9470\n",
      "Baseline Loss: 3.4901 | Actual Loss: 1.6350\n",
      "Baseline Loss: 3.6270 | Actual Loss: 3.4290\n",
      "Baseline Loss: 3.4577 | Actual Loss: 0.8129\n",
      "Baseline Loss: 3.5873 | Actual Loss: 1.8797\n",
      "Baseline Loss: 3.4177 | Actual Loss: 0.5850\n",
      "Baseline Loss: 3.4777 | Actual Loss: 0.9027\n",
      "Baseline Loss: 3.6093 | Actual Loss: 0.4087\n",
      "Baseline Loss: 3.3923 | Actual Loss: 0.9460\n",
      "Baseline Loss: 3.3172 | Actual Loss: 0.4356\n",
      "Baseline Loss: 3.5574 | Actual Loss: 1.2861\n",
      "Baseline Loss: 3.2873 | Actual Loss: 0.6571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 144/1000 [01:15<07:53,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3767 | Actual Loss: 0.3078\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.0554\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.0484\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6670\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.6946\n",
      "Epoch 144/1000: Train Loss: 1.0239, Val Loss: 1.1164\n",
      "Baseline Loss: 3.5282 | Actual Loss: 1.2534\n",
      "Baseline Loss: 3.6046 | Actual Loss: 1.1026\n",
      "Baseline Loss: 3.7679 | Actual Loss: 0.6415\n",
      "Baseline Loss: 3.5451 | Actual Loss: 0.2704\n",
      "Baseline Loss: 3.4281 | Actual Loss: 0.4714\n",
      "Baseline Loss: 3.4502 | Actual Loss: 0.8436\n",
      "Baseline Loss: 3.5163 | Actual Loss: 0.7788\n",
      "Baseline Loss: 3.4359 | Actual Loss: 0.7040\n",
      "Baseline Loss: 3.4891 | Actual Loss: 0.7700\n",
      "Baseline Loss: 3.5244 | Actual Loss: 0.6345\n",
      "Baseline Loss: 3.4925 | Actual Loss: 0.7849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 145/1000 [01:15<07:45,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4062 | Actual Loss: 0.3171\n",
      "Baseline Loss: 3.2588 | Actual Loss: 0.7938\n",
      "Baseline Loss: 3.3787 | Actual Loss: 0.8078\n",
      "Baseline Loss: 3.6361 | Actual Loss: 0.7049\n",
      "Baseline Loss: 3.3400 | Actual Loss: 0.3646\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.6111\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.9725\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6157\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.7513\n",
      "Epoch 145/1000: Train Loss: 0.7027, Val Loss: 0.9877\n",
      "Baseline Loss: 3.4425 | Actual Loss: 0.7250\n",
      "Baseline Loss: 3.6282 | Actual Loss: 0.4977\n",
      "Baseline Loss: 3.6597 | Actual Loss: 0.7001\n",
      "Baseline Loss: 3.4350 | Actual Loss: 0.6972\n",
      "Baseline Loss: 3.6319 | Actual Loss: 0.5111\n",
      "Baseline Loss: 3.3574 | Actual Loss: 0.8338\n",
      "Baseline Loss: 3.6143 | Actual Loss: 2.8171\n",
      "Baseline Loss: 3.6314 | Actual Loss: 0.6137\n",
      "Baseline Loss: 3.4029 | Actual Loss: 0.4718\n",
      "Baseline Loss: 3.7116 | Actual Loss: 0.7402\n",
      "Baseline Loss: 3.3782 | Actual Loss: 0.5159\n",
      "Baseline Loss: 3.3990 | Actual Loss: 2.8656\n",
      "Baseline Loss: 3.6923 | Actual Loss: 3.1468\n",
      "Baseline Loss: 3.4058 | Actual Loss: 1.0573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 146/1000 [01:16<07:50,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.2121 | Actual Loss: 0.9085\n",
      "Baseline Loss: 3.3839 | Actual Loss: 0.3635\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.4497\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.1147\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6979\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.5369\n",
      "Epoch 146/1000: Train Loss: 1.0916, Val Loss: 0.9498\n",
      "Baseline Loss: 3.4774 | Actual Loss: 0.8032\n",
      "Baseline Loss: 3.4622 | Actual Loss: 0.5053\n",
      "Baseline Loss: 3.6363 | Actual Loss: 0.9112\n",
      "Baseline Loss: 3.3816 | Actual Loss: 1.0374\n",
      "Baseline Loss: 3.4468 | Actual Loss: 0.7498\n",
      "Baseline Loss: 3.3276 | Actual Loss: 0.6830\n",
      "Baseline Loss: 3.5748 | Actual Loss: 0.7388\n",
      "Baseline Loss: 3.6313 | Actual Loss: 0.6473\n",
      "Baseline Loss: 3.5414 | Actual Loss: 0.5476\n",
      "Baseline Loss: 3.5218 | Actual Loss: 3.4062\n",
      "Baseline Loss: 3.4735 | Actual Loss: 0.4625\n",
      "Baseline Loss: 3.3711 | Actual Loss: 0.7900\n",
      "Baseline Loss: 3.7999 | Actual Loss: 2.4191\n",
      "Baseline Loss: 3.5129 | Actual Loss: 0.9570\n",
      "Baseline Loss: 3.4581 | Actual Loss: 0.7922\n",
      "Baseline Loss: 3.2728 | Actual Loss: 0.6440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 147/1000 [01:17<08:02,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7429 | Actual Loss: 1.5665\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.1120\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.7085\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.6897\n",
      "Epoch 147/1000: Train Loss: 1.0059, Val Loss: 1.0192\n",
      "Baseline Loss: 3.2448 | Actual Loss: 0.8006\n",
      "Baseline Loss: 3.5786 | Actual Loss: 0.7278\n",
      "Baseline Loss: 3.4812 | Actual Loss: 0.6563\n",
      "Baseline Loss: 3.3077 | Actual Loss: 0.8728\n",
      "Baseline Loss: 3.5171 | Actual Loss: 0.8099\n",
      "Baseline Loss: 3.4399 | Actual Loss: 0.3850\n",
      "Baseline Loss: 3.3310 | Actual Loss: 0.7846\n",
      "Baseline Loss: 3.6135 | Actual Loss: 0.4985\n",
      "Baseline Loss: 3.7023 | Actual Loss: 0.6045\n",
      "Baseline Loss: 3.4141 | Actual Loss: 0.6388\n",
      "Baseline Loss: 3.8430 | Actual Loss: 0.9036\n",
      "Baseline Loss: 3.7529 | Actual Loss: 0.9107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 148/1000 [01:17<07:50,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4697 | Actual Loss: 0.8266\n",
      "Baseline Loss: 3.4888 | Actual Loss: 0.5735\n",
      "Baseline Loss: 3.4624 | Actual Loss: 0.4597\n",
      "Baseline Loss: 3.5298 | Actual Loss: 0.6577\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.5873\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.8648\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.7605\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.6963\n",
      "Epoch 148/1000: Train Loss: 0.6944, Val Loss: 0.9772\n",
      "Baseline Loss: 3.7888 | Actual Loss: 0.5817\n",
      "Baseline Loss: 3.4438 | Actual Loss: 0.2670\n",
      "Baseline Loss: 3.3726 | Actual Loss: 0.5364\n",
      "Baseline Loss: 3.4814 | Actual Loss: 1.0342\n",
      "Baseline Loss: 3.4435 | Actual Loss: 1.0598\n",
      "Baseline Loss: 3.5703 | Actual Loss: 1.0579\n",
      "Baseline Loss: 3.5711 | Actual Loss: 0.8362\n",
      "Baseline Loss: 3.3580 | Actual Loss: 1.4268\n",
      "Baseline Loss: 3.6973 | Actual Loss: 0.5644\n",
      "Baseline Loss: 3.4587 | Actual Loss: 1.2052\n",
      "Baseline Loss: 3.5163 | Actual Loss: 0.6838\n",
      "Baseline Loss: 3.4040 | Actual Loss: 0.6062\n",
      "Baseline Loss: 3.4922 | Actual Loss: 0.4579\n",
      "Baseline Loss: 3.4163 | Actual Loss: 0.4799\n",
      "Baseline Loss: 3.7883 | Actual Loss: 0.5728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 149/1000 [01:18<07:48,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.0579 | Actual Loss: 0.5629\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.5276\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.1851\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6833\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.6830\n",
      "Epoch 149/1000: Train Loss: 0.7458, Val Loss: 1.2697\n",
      "Baseline Loss: 3.4430 | Actual Loss: 0.4280\n",
      "Baseline Loss: 3.6644 | Actual Loss: 3.3395\n",
      "Baseline Loss: 3.4656 | Actual Loss: 0.8079\n",
      "Baseline Loss: 3.4280 | Actual Loss: 0.8066\n",
      "Baseline Loss: 3.7274 | Actual Loss: 0.9836\n",
      "Baseline Loss: 3.5282 | Actual Loss: 0.7831\n",
      "Baseline Loss: 3.3820 | Actual Loss: 0.5504\n",
      "Baseline Loss: 3.3271 | Actual Loss: 0.7017\n",
      "Baseline Loss: 3.4513 | Actual Loss: 0.9227\n",
      "Baseline Loss: 3.4098 | Actual Loss: 0.6317\n",
      "Baseline Loss: 3.4581 | Actual Loss: 0.6849\n",
      "Baseline Loss: 3.7669 | Actual Loss: 0.4287\n",
      "Baseline Loss: 3.7369 | Actual Loss: 3.3496\n",
      "Baseline Loss: 3.3751 | Actual Loss: 0.8723\n",
      "Baseline Loss: 3.4027 | Actual Loss: 1.6282\n",
      "Baseline Loss: 3.2192 | Actual Loss: 0.8321\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.5435\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.6866\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 150/1000 [01:18<07:44,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4730 | Actual Loss: 0.4991\n",
      "Epoch 150/1000: Train Loss: 1.1094, Val Loss: 0.8387\n",
      "New best validation loss: 0.8387\n",
      "Baseline Loss: 3.4713 | Actual Loss: 0.7897\n",
      "Baseline Loss: 3.6353 | Actual Loss: 1.0386\n",
      "Baseline Loss: 3.5710 | Actual Loss: 0.8792\n",
      "Baseline Loss: 3.4783 | Actual Loss: 0.8375\n",
      "Baseline Loss: 3.4688 | Actual Loss: 1.7373\n",
      "Baseline Loss: 3.6140 | Actual Loss: 1.4480\n",
      "Baseline Loss: 3.6280 | Actual Loss: 0.7782\n",
      "Baseline Loss: 3.4391 | Actual Loss: 0.7779\n",
      "Baseline Loss: 3.3819 | Actual Loss: 1.0054\n",
      "Baseline Loss: 3.4736 | Actual Loss: 0.7645\n",
      "Baseline Loss: 3.5129 | Actual Loss: 0.6569\n",
      "Baseline Loss: 3.6640 | Actual Loss: 0.6268\n",
      "Baseline Loss: 3.4392 | Actual Loss: 0.6716\n",
      "Baseline Loss: 3.4773 | Actual Loss: 0.4854\n",
      "Baseline Loss: 3.4774 | Actual Loss: 0.7928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 151/1000 [01:19<07:36,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.1038 | Actual Loss: 0.4976\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.9712\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.8513\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6550\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.7407\n",
      "Epoch 151/1000: Train Loss: 0.8617, Val Loss: 1.0546\n",
      "Baseline Loss: 3.2614 | Actual Loss: 0.7144\n",
      "Baseline Loss: 3.5503 | Actual Loss: 0.8522\n",
      "Baseline Loss: 3.3904 | Actual Loss: 0.7542\n",
      "Baseline Loss: 3.6366 | Actual Loss: 0.5995\n",
      "Baseline Loss: 3.6934 | Actual Loss: 0.8629\n",
      "Baseline Loss: 3.4049 | Actual Loss: 0.6426\n",
      "Baseline Loss: 3.3926 | Actual Loss: 0.8740\n",
      "Baseline Loss: 3.3366 | Actual Loss: 0.5377\n",
      "Baseline Loss: 3.4248 | Actual Loss: 0.8698\n",
      "Baseline Loss: 3.4430 | Actual Loss: 1.0117\n",
      "Baseline Loss: 3.5206 | Actual Loss: 1.3274\n",
      "Baseline Loss: 3.5196 | Actual Loss: 0.7402\n",
      "Baseline Loss: 3.4284 | Actual Loss: 0.4234\n",
      "Baseline Loss: 3.5793 | Actual Loss: 1.1998\n",
      "Baseline Loss: 3.7069 | Actual Loss: 0.8676\n",
      "Baseline Loss: 3.4789 | Actual Loss: 4.2449\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.8122\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.7066\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.5722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 152/1000 [01:19<07:40,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4730 | Actual Loss: 0.7063\n",
      "Epoch 152/1000: Train Loss: 1.0326, Val Loss: 0.9493\n",
      "Baseline Loss: 3.7733 | Actual Loss: 0.5023\n",
      "Baseline Loss: 3.6544 | Actual Loss: 0.5143\n",
      "Baseline Loss: 3.4322 | Actual Loss: 0.7320\n",
      "Baseline Loss: 3.6132 | Actual Loss: 0.5375\n",
      "Baseline Loss: 3.7781 | Actual Loss: 3.8746\n",
      "Baseline Loss: 3.3814 | Actual Loss: 0.5362\n",
      "Baseline Loss: 3.3681 | Actual Loss: 0.9084\n",
      "Baseline Loss: 3.5625 | Actual Loss: 0.4712\n",
      "Baseline Loss: 3.3265 | Actual Loss: 0.5327\n",
      "Baseline Loss: 3.3349 | Actual Loss: 0.8740\n",
      "Baseline Loss: 3.5283 | Actual Loss: 1.0678\n",
      "Baseline Loss: 3.5293 | Actual Loss: 0.5926\n",
      "Baseline Loss: 3.3153 | Actual Loss: 0.6809\n",
      "Baseline Loss: 3.5833 | Actual Loss: 0.6235\n",
      "Baseline Loss: 3.3447 | Actual Loss: 0.5693\n",
      "Baseline Loss: 3.6286 | Actual Loss: 0.2410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 153/1000 [01:20<07:17,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7429 | Actual Loss: 2.1388\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.9103\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6031\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.6165\n",
      "Epoch 153/1000: Train Loss: 0.8286, Val Loss: 1.0672\n",
      "Baseline Loss: 3.3651 | Actual Loss: 0.4229\n",
      "Baseline Loss: 3.6642 | Actual Loss: 0.8754\n",
      "Baseline Loss: 3.4550 | Actual Loss: 0.6508\n",
      "Baseline Loss: 3.4473 | Actual Loss: 0.9440\n",
      "Baseline Loss: 3.7996 | Actual Loss: 2.3496\n",
      "Baseline Loss: 3.2952 | Actual Loss: 0.8529\n",
      "Baseline Loss: 3.5249 | Actual Loss: 0.1768\n",
      "Baseline Loss: 3.3655 | Actual Loss: 0.6610\n",
      "Baseline Loss: 3.3607 | Actual Loss: 0.9485\n",
      "Baseline Loss: 3.4134 | Actual Loss: 0.6719\n",
      "Baseline Loss: 3.4280 | Actual Loss: 0.4646\n",
      "Baseline Loss: 3.6640 | Actual Loss: 0.6239\n",
      "Baseline Loss: 3.5012 | Actual Loss: 0.6297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 154/1000 [01:20<07:33,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4474 | Actual Loss: 1.0448\n",
      "Baseline Loss: 3.6551 | Actual Loss: 0.4804\n",
      "Baseline Loss: 3.3476 | Actual Loss: 1.7286\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.6955\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.9658\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.4814\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.6029\n",
      "Epoch 154/1000: Train Loss: 0.8454, Val Loss: 0.9364\n",
      "Baseline Loss: 3.5452 | Actual Loss: 0.4699\n",
      "Baseline Loss: 3.6784 | Actual Loss: 0.7692\n",
      "Baseline Loss: 3.4855 | Actual Loss: 0.5895\n",
      "Baseline Loss: 3.6498 | Actual Loss: 0.9543\n",
      "Baseline Loss: 3.3930 | Actual Loss: 0.6857\n",
      "Baseline Loss: 3.4504 | Actual Loss: 0.6872\n",
      "Baseline Loss: 3.7369 | Actual Loss: 3.8014\n",
      "Baseline Loss: 3.4543 | Actual Loss: 0.5341\n",
      "Baseline Loss: 3.5009 | Actual Loss: 0.7866\n",
      "Baseline Loss: 3.4616 | Actual Loss: 1.7645\n",
      "Baseline Loss: 3.3610 | Actual Loss: 2.6803\n",
      "Baseline Loss: 3.4810 | Actual Loss: 0.7380\n",
      "Baseline Loss: 3.4063 | Actual Loss: 0.4632\n",
      "Baseline Loss: 3.5875 | Actual Loss: 0.6165\n",
      "Baseline Loss: 3.3990 | Actual Loss: 0.5159\n",
      "Baseline Loss: 3.0645 | Actual Loss: 0.1642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 155/1000 [01:21<07:34,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7429 | Actual Loss: 1.8029\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.3498\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6854\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.6577\n",
      "Epoch 155/1000: Train Loss: 1.0138, Val Loss: 1.1239\n",
      "Baseline Loss: 3.4547 | Actual Loss: 0.3254\n",
      "Baseline Loss: 3.5626 | Actual Loss: 0.5368\n",
      "Baseline Loss: 3.2666 | Actual Loss: 0.4581\n",
      "Baseline Loss: 3.4357 | Actual Loss: 0.5184\n",
      "Baseline Loss: 3.4842 | Actual Loss: 0.4492\n",
      "Baseline Loss: 3.3779 | Actual Loss: 0.6566\n",
      "Baseline Loss: 3.4137 | Actual Loss: 1.0631\n",
      "Baseline Loss: 3.5042 | Actual Loss: 1.1087\n",
      "Baseline Loss: 3.4396 | Actual Loss: 0.9723\n",
      "Baseline Loss: 3.5918 | Actual Loss: 1.4414\n",
      "Baseline Loss: 3.4617 | Actual Loss: 0.2546\n",
      "Baseline Loss: 3.3790 | Actual Loss: 1.1665\n",
      "Baseline Loss: 3.6604 | Actual Loss: 0.5068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 156/1000 [01:21<07:18,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7372 | Actual Loss: 0.4916\n",
      "Baseline Loss: 3.5203 | Actual Loss: 1.1712\n",
      "Baseline Loss: 3.1660 | Actual Loss: 1.2545\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.1543\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.0577\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.7800\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.7916\n",
      "Epoch 156/1000: Train Loss: 0.7735, Val Loss: 1.1959\n",
      "Baseline Loss: 3.4290 | Actual Loss: 0.8701\n",
      "Baseline Loss: 3.5421 | Actual Loss: 1.4218\n",
      "Baseline Loss: 3.6324 | Actual Loss: 0.4801\n",
      "Baseline Loss: 3.5530 | Actual Loss: 0.5108\n",
      "Baseline Loss: 3.7365 | Actual Loss: 0.6646\n",
      "Baseline Loss: 3.4107 | Actual Loss: 0.9816\n",
      "Baseline Loss: 3.3823 | Actual Loss: 0.6319\n",
      "Baseline Loss: 3.4972 | Actual Loss: 0.4457\n",
      "Baseline Loss: 3.4583 | Actual Loss: 0.7408\n",
      "Baseline Loss: 3.6089 | Actual Loss: 2.6799\n",
      "Baseline Loss: 3.3749 | Actual Loss: 0.5156\n",
      "Baseline Loss: 3.5085 | Actual Loss: 1.2115\n",
      "Baseline Loss: 3.3463 | Actual Loss: 0.8903\n",
      "Baseline Loss: 3.4662 | Actual Loss: 0.3165\n",
      "Baseline Loss: 3.6180 | Actual Loss: 0.9239\n",
      "Baseline Loss: 3.2176 | Actual Loss: 0.6312\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.7479\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.7456\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 157/1000 [01:22<07:29,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4730 | Actual Loss: 0.7773\n",
      "Epoch 157/1000: Train Loss: 0.8698, Val Loss: 1.2355\n",
      "Baseline Loss: 3.3820 | Actual Loss: 0.7985\n",
      "Baseline Loss: 3.3683 | Actual Loss: 0.8720\n",
      "Baseline Loss: 3.6140 | Actual Loss: 1.0503\n",
      "Baseline Loss: 3.5789 | Actual Loss: 0.5302\n",
      "Baseline Loss: 3.4857 | Actual Loss: 0.9073\n",
      "Baseline Loss: 3.5965 | Actual Loss: 0.8486\n",
      "Baseline Loss: 3.6146 | Actual Loss: 0.5668\n",
      "Baseline Loss: 3.4895 | Actual Loss: 0.9635\n",
      "Baseline Loss: 3.5366 | Actual Loss: 0.4089\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.6911\n",
      "Baseline Loss: 3.5210 | Actual Loss: 0.5111\n",
      "Baseline Loss: 3.4732 | Actual Loss: 0.6931\n",
      "Baseline Loss: 3.4975 | Actual Loss: 0.7165\n",
      "Baseline Loss: 3.3920 | Actual Loss: 1.1251\n",
      "Baseline Loss: 3.4351 | Actual Loss: 0.7278\n",
      "Baseline Loss: 3.3664 | Actual Loss: 0.2406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 158/1000 [01:22<07:06,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7429 | Actual Loss: 1.9303\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.0024\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.5419\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.8701\n",
      "Epoch 158/1000: Train Loss: 0.7282, Val Loss: 1.0862\n",
      "Baseline Loss: 3.5287 | Actual Loss: 0.9231\n",
      "Baseline Loss: 3.4922 | Actual Loss: 0.4475\n",
      "Baseline Loss: 3.3639 | Actual Loss: 0.7277\n",
      "Baseline Loss: 3.5881 | Actual Loss: 0.8122\n",
      "Baseline Loss: 3.4388 | Actual Loss: 0.6397\n",
      "Baseline Loss: 3.5712 | Actual Loss: 2.6835\n",
      "Baseline Loss: 3.3406 | Actual Loss: 0.3775\n",
      "Baseline Loss: 3.5245 | Actual Loss: 0.5645\n",
      "Baseline Loss: 3.5125 | Actual Loss: 0.6384\n",
      "Baseline Loss: 3.6557 | Actual Loss: 0.8501\n",
      "Baseline Loss: 3.5172 | Actual Loss: 0.5365\n",
      "Baseline Loss: 3.4630 | Actual Loss: 0.8113\n",
      "Baseline Loss: 3.6972 | Actual Loss: 2.0547\n",
      "Baseline Loss: 3.6403 | Actual Loss: 0.2949\n",
      "Baseline Loss: 3.3891 | Actual Loss: 0.6570\n",
      "Baseline Loss: 3.0513 | Actual Loss: 0.7231\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.1913\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.2570\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 159/1000 [01:23<07:29,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4730 | Actual Loss: 0.6350\n",
      "Epoch 159/1000: Train Loss: 0.8588, Val Loss: 1.1861\n",
      "Baseline Loss: 3.6831 | Actual Loss: 0.5615\n",
      "Baseline Loss: 3.4267 | Actual Loss: 0.5001\n",
      "Baseline Loss: 3.5923 | Actual Loss: 0.7203\n",
      "Baseline Loss: 3.2822 | Actual Loss: 0.6633\n",
      "Baseline Loss: 3.6736 | Actual Loss: 0.5070\n",
      "Baseline Loss: 3.5919 | Actual Loss: 0.5232\n",
      "Baseline Loss: 3.5928 | Actual Loss: 0.5634\n",
      "Baseline Loss: 3.5628 | Actual Loss: 0.5726\n",
      "Baseline Loss: 3.5786 | Actual Loss: 1.7884\n",
      "Baseline Loss: 3.5706 | Actual Loss: 0.7042\n",
      "Baseline Loss: 3.3149 | Actual Loss: 1.0839\n",
      "Baseline Loss: 3.2792 | Actual Loss: 1.1761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 160/1000 [01:23<07:33,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5411 | Actual Loss: 0.7509\n",
      "Baseline Loss: 3.4246 | Actual Loss: 0.4152\n",
      "Baseline Loss: 3.4212 | Actual Loss: 1.1861\n",
      "Baseline Loss: 3.4592 | Actual Loss: 0.1282\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.2849\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.9890\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.4625\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.5939\n",
      "Epoch 160/1000: Train Loss: 0.7403, Val Loss: 1.0826\n",
      "Baseline Loss: 3.5833 | Actual Loss: 0.7917\n",
      "Baseline Loss: 3.4696 | Actual Loss: 1.1716\n",
      "Baseline Loss: 3.4543 | Actual Loss: 0.7852\n",
      "Baseline Loss: 3.2684 | Actual Loss: 0.7251\n",
      "Baseline Loss: 3.4478 | Actual Loss: 0.4234\n",
      "Baseline Loss: 3.5047 | Actual Loss: 0.6340\n",
      "Baseline Loss: 3.3964 | Actual Loss: 1.0060\n",
      "Baseline Loss: 3.4387 | Actual Loss: 0.6635\n",
      "Baseline Loss: 3.5367 | Actual Loss: 0.6032\n",
      "Baseline Loss: 3.8156 | Actual Loss: 1.0169\n",
      "Baseline Loss: 3.6594 | Actual Loss: 0.7221\n",
      "Baseline Loss: 3.5923 | Actual Loss: 0.8004\n",
      "Baseline Loss: 3.4508 | Actual Loss: 0.3554\n",
      "Baseline Loss: 3.5746 | Actual Loss: 0.9609\n",
      "Baseline Loss: 3.7326 | Actual Loss: 0.6791\n",
      "Baseline Loss: 2.8785 | Actual Loss: 0.5979\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.9307\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.6282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 161/1000 [01:24<07:29,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5384 | Actual Loss: 0.6012\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.6752\n",
      "Epoch 161/1000: Train Loss: 0.7460, Val Loss: 0.9588\n",
      "Baseline Loss: 3.7889 | Actual Loss: 0.4155\n",
      "Baseline Loss: 3.4928 | Actual Loss: 0.7448\n",
      "Baseline Loss: 3.4283 | Actual Loss: 0.8651\n",
      "Baseline Loss: 3.5051 | Actual Loss: 0.7552\n",
      "Baseline Loss: 3.4621 | Actual Loss: 0.9093\n",
      "Baseline Loss: 3.4033 | Actual Loss: 0.3737\n",
      "Baseline Loss: 3.5574 | Actual Loss: 0.8730\n",
      "Baseline Loss: 3.4958 | Actual Loss: 0.5214\n",
      "Baseline Loss: 3.4467 | Actual Loss: 0.7113\n",
      "Baseline Loss: 3.5575 | Actual Loss: 0.9742\n",
      "Baseline Loss: 3.6274 | Actual Loss: 0.6332\n",
      "Baseline Loss: 3.3510 | Actual Loss: 0.7026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 162/1000 [01:25<07:33,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5832 | Actual Loss: 0.9894\n",
      "Baseline Loss: 3.5331 | Actual Loss: 0.2334\n",
      "Baseline Loss: 3.6237 | Actual Loss: 0.6024\n",
      "Baseline Loss: 3.3485 | Actual Loss: 4.1010\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.5608\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.8750\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.7346\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.5918\n",
      "Epoch 162/1000: Train Loss: 0.9004, Val Loss: 0.9406\n",
      "Baseline Loss: 3.3406 | Actual Loss: 0.6937\n",
      "Baseline Loss: 3.3071 | Actual Loss: 0.7685\n",
      "Baseline Loss: 3.9072 | Actual Loss: 0.6497\n",
      "Baseline Loss: 3.3094 | Actual Loss: 0.6612\n",
      "Baseline Loss: 3.5328 | Actual Loss: 0.6136\n",
      "Baseline Loss: 3.4464 | Actual Loss: 0.5584\n",
      "Baseline Loss: 3.6273 | Actual Loss: 0.6377\n",
      "Baseline Loss: 3.5249 | Actual Loss: 0.2927\n",
      "Baseline Loss: 3.5255 | Actual Loss: 0.8716\n",
      "Baseline Loss: 3.5165 | Actual Loss: 0.4656\n",
      "Baseline Loss: 3.4703 | Actual Loss: 0.5855\n",
      "Baseline Loss: 3.5455 | Actual Loss: 0.5712\n",
      "Baseline Loss: 3.4519 | Actual Loss: 0.5601\n",
      "Baseline Loss: 3.4954 | Actual Loss: 0.6312\n",
      "Baseline Loss: 3.4133 | Actual Loss: 3.1147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▋        | 163/1000 [01:25<07:32,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4786 | Actual Loss: 0.6162\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.7255\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.9357\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.7019\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.7592\n",
      "Epoch 163/1000: Train Loss: 0.7682, Val Loss: 1.0306\n",
      "Baseline Loss: 3.4501 | Actual Loss: 0.3555\n",
      "Baseline Loss: 3.3009 | Actual Loss: 0.4992\n",
      "Baseline Loss: 3.5966 | Actual Loss: 0.8315\n",
      "Baseline Loss: 3.6782 | Actual Loss: 0.8648\n",
      "Baseline Loss: 3.3822 | Actual Loss: 0.6914\n",
      "Baseline Loss: 3.5575 | Actual Loss: 0.5987\n",
      "Baseline Loss: 3.3655 | Actual Loss: 0.7160\n",
      "Baseline Loss: 3.4437 | Actual Loss: 1.1959\n",
      "Baseline Loss: 3.3965 | Actual Loss: 0.3244\n",
      "Baseline Loss: 3.6974 | Actual Loss: 0.2853\n",
      "Baseline Loss: 3.5251 | Actual Loss: 1.5699\n",
      "Baseline Loss: 3.5498 | Actual Loss: 0.6668\n",
      "Baseline Loss: 3.6360 | Actual Loss: 0.3047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▋        | 164/1000 [01:26<07:28,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5875 | Actual Loss: 0.9233\n",
      "Baseline Loss: 3.5914 | Actual Loss: 0.9575\n",
      "Baseline Loss: 3.3664 | Actual Loss: 1.3087\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.5983\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.2117\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6498\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.6839\n",
      "Epoch 164/1000: Train Loss: 0.7558, Val Loss: 1.0359\n",
      "Baseline Loss: 3.5533 | Actual Loss: 1.6986\n",
      "Baseline Loss: 3.4172 | Actual Loss: 0.6775\n",
      "Baseline Loss: 3.7375 | Actual Loss: 0.4507\n",
      "Baseline Loss: 3.4363 | Actual Loss: 1.5079\n",
      "Baseline Loss: 3.5367 | Actual Loss: 0.6826\n",
      "Baseline Loss: 3.5918 | Actual Loss: 0.7945\n",
      "Baseline Loss: 3.6877 | Actual Loss: 0.9383\n",
      "Baseline Loss: 3.4899 | Actual Loss: 0.7167\n",
      "Baseline Loss: 3.3883 | Actual Loss: 0.4836\n",
      "Baseline Loss: 3.4883 | Actual Loss: 0.2599\n",
      "Baseline Loss: 3.4318 | Actual Loss: 0.6909\n",
      "Baseline Loss: 3.6823 | Actual Loss: 1.2474\n",
      "Baseline Loss: 3.4685 | Actual Loss: 0.3713\n",
      "Baseline Loss: 3.3741 | Actual Loss: 0.7806\n",
      "Baseline Loss: 3.4402 | Actual Loss: 0.3136\n",
      "Baseline Loss: 3.3412 | Actual Loss: 3.7937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▋        | 165/1000 [01:26<07:35,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7429 | Actual Loss: 1.7794\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.2502\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6169\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.7195\n",
      "Epoch 165/1000: Train Loss: 0.9630, Val Loss: 1.0915\n",
      "Baseline Loss: 3.4259 | Actual Loss: 0.9592\n",
      "Baseline Loss: 3.4294 | Actual Loss: 1.2092\n",
      "Baseline Loss: 3.4240 | Actual Loss: 0.4661\n",
      "Baseline Loss: 3.4725 | Actual Loss: 0.5831\n",
      "Baseline Loss: 3.2883 | Actual Loss: 0.7211\n",
      "Baseline Loss: 3.5087 | Actual Loss: 0.4793\n",
      "Baseline Loss: 3.6733 | Actual Loss: 3.5579\n",
      "Baseline Loss: 3.5410 | Actual Loss: 0.5572\n",
      "Baseline Loss: 3.3454 | Actual Loss: 0.7762\n",
      "Baseline Loss: 3.4626 | Actual Loss: 0.4261\n",
      "Baseline Loss: 3.6409 | Actual Loss: 0.4975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 166/1000 [01:27<07:37,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5878 | Actual Loss: 0.3362\n",
      "Baseline Loss: 3.6086 | Actual Loss: 0.5682\n",
      "Baseline Loss: 3.5416 | Actual Loss: 2.1938\n",
      "Baseline Loss: 3.6355 | Actual Loss: 0.6854\n",
      "Baseline Loss: 3.1386 | Actual Loss: 0.4292\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.8357\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.0226\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.5987\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.6577\n",
      "Epoch 166/1000: Train Loss: 0.9029, Val Loss: 1.2787\n",
      "Baseline Loss: 3.5411 | Actual Loss: 0.7521\n",
      "Baseline Loss: 3.5215 | Actual Loss: 1.1676\n",
      "Baseline Loss: 3.6686 | Actual Loss: 0.7506\n",
      "Baseline Loss: 3.4396 | Actual Loss: 1.1114\n",
      "Baseline Loss: 3.3743 | Actual Loss: 0.7430\n",
      "Baseline Loss: 3.6234 | Actual Loss: 0.6546\n",
      "Baseline Loss: 3.5535 | Actual Loss: 0.7681\n",
      "Baseline Loss: 3.6324 | Actual Loss: 0.4444\n",
      "Baseline Loss: 3.4817 | Actual Loss: 1.2170\n",
      "Baseline Loss: 3.3103 | Actual Loss: 0.4984\n",
      "Baseline Loss: 3.5873 | Actual Loss: 0.3474\n",
      "Baseline Loss: 3.3501 | Actual Loss: 0.7252\n",
      "Baseline Loss: 3.5705 | Actual Loss: 0.4274\n",
      "Baseline Loss: 3.5048 | Actual Loss: 0.4336\n",
      "Baseline Loss: 3.3472 | Actual Loss: 0.5725\n",
      "Baseline Loss: 3.6645 | Actual Loss: 0.2098\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.8016\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.2716\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 167/1000 [01:27<07:20,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4730 | Actual Loss: 0.7555\n",
      "Epoch 167/1000: Train Loss: 0.6764, Val Loss: 1.1266\n",
      "Baseline Loss: 3.5664 | Actual Loss: 1.0444\n",
      "Baseline Loss: 3.3758 | Actual Loss: 0.4747\n",
      "Baseline Loss: 3.5420 | Actual Loss: 1.3339\n",
      "Baseline Loss: 3.5800 | Actual Loss: 0.6354\n",
      "Baseline Loss: 3.6739 | Actual Loss: 0.7768\n",
      "Baseline Loss: 3.4628 | Actual Loss: 0.3962\n",
      "Baseline Loss: 3.3610 | Actual Loss: 0.7240\n",
      "Baseline Loss: 3.6782 | Actual Loss: 0.3780\n",
      "Baseline Loss: 3.4033 | Actual Loss: 0.8314\n",
      "Baseline Loss: 3.4738 | Actual Loss: 1.2559\n",
      "Baseline Loss: 3.4806 | Actual Loss: 0.5451\n",
      "Baseline Loss: 3.7524 | Actual Loss: 0.7795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 168/1000 [01:28<07:24,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6459 | Actual Loss: 1.4869\n",
      "Baseline Loss: 3.3576 | Actual Loss: 0.5203\n",
      "Baseline Loss: 3.4346 | Actual Loss: 1.0809\n",
      "Baseline Loss: 3.3574 | Actual Loss: 3.4550\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.9124\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.7133\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.5535\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.6202\n",
      "Epoch 168/1000: Train Loss: 0.9824, Val Loss: 0.9498\n",
      "Baseline Loss: 3.3787 | Actual Loss: 0.9129\n",
      "Baseline Loss: 3.1978 | Actual Loss: 0.7760\n",
      "Baseline Loss: 3.5707 | Actual Loss: 0.9069\n",
      "Baseline Loss: 3.5008 | Actual Loss: 0.9400\n",
      "Baseline Loss: 3.2861 | Actual Loss: 0.5902\n",
      "Baseline Loss: 3.4319 | Actual Loss: 1.6158\n",
      "Baseline Loss: 3.3848 | Actual Loss: 0.6681\n",
      "Baseline Loss: 3.4141 | Actual Loss: 0.5002\n",
      "Baseline Loss: 3.6188 | Actual Loss: 0.7718\n",
      "Baseline Loss: 3.9251 | Actual Loss: 0.3912\n",
      "Baseline Loss: 3.4067 | Actual Loss: 0.2044\n",
      "Baseline Loss: 3.7166 | Actual Loss: 0.5848\n",
      "Baseline Loss: 3.4384 | Actual Loss: 0.7184\n",
      "Baseline Loss: 3.5209 | Actual Loss: 1.3440\n",
      "Baseline Loss: 3.9635 | Actual Loss: 0.8830\n",
      "Baseline Loss: 3.4018 | Actual Loss: 0.7938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 169/1000 [01:28<07:41,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7429 | Actual Loss: 1.9545\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.0743\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.5871\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.9857\n",
      "Epoch 169/1000: Train Loss: 0.7876, Val Loss: 1.1504\n",
      "Baseline Loss: 3.3551 | Actual Loss: 0.7500\n",
      "Baseline Loss: 3.6013 | Actual Loss: 0.8206\n",
      "Baseline Loss: 3.3508 | Actual Loss: 0.6133\n",
      "Baseline Loss: 3.4464 | Actual Loss: 0.4275\n",
      "Baseline Loss: 3.5532 | Actual Loss: 0.5383\n",
      "Baseline Loss: 3.5575 | Actual Loss: 2.3122\n",
      "Baseline Loss: 3.7025 | Actual Loss: 0.7277\n",
      "Baseline Loss: 3.4739 | Actual Loss: 1.0189\n",
      "Baseline Loss: 3.5375 | Actual Loss: 1.4720\n",
      "Baseline Loss: 3.6742 | Actual Loss: 0.1638\n",
      "Baseline Loss: 3.2955 | Actual Loss: 0.7509\n",
      "Baseline Loss: 3.5214 | Actual Loss: 0.3789\n",
      "Baseline Loss: 3.6274 | Actual Loss: 0.4752\n",
      "Baseline Loss: 3.4468 | Actual Loss: 0.2997\n",
      "Baseline Loss: 3.3678 | Actual Loss: 0.8938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 170/1000 [01:29<07:17,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3485 | Actual Loss: 0.4844\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.2074\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.1206\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.5155\n",
      "Baseline Loss: 3.4730 | Actual Loss: 1.2503\n",
      "Epoch 170/1000: Train Loss: 0.7579, Val Loss: 1.2735\n",
      "Baseline Loss: 3.4661 | Actual Loss: 0.7787\n",
      "Baseline Loss: 3.6318 | Actual Loss: 0.4814\n",
      "Baseline Loss: 3.5961 | Actual Loss: 0.4195\n",
      "Baseline Loss: 3.6096 | Actual Loss: 1.3444\n",
      "Baseline Loss: 3.4178 | Actual Loss: 0.9331\n",
      "Baseline Loss: 3.4252 | Actual Loss: 0.2523\n",
      "Baseline Loss: 3.4136 | Actual Loss: 0.3842\n",
      "Baseline Loss: 3.5318 | Actual Loss: 1.1790\n",
      "Baseline Loss: 3.7727 | Actual Loss: 1.1622\n",
      "Baseline Loss: 3.5920 | Actual Loss: 0.7407\n",
      "Baseline Loss: 3.6931 | Actual Loss: 0.6806\n",
      "Baseline Loss: 3.4029 | Actual Loss: 0.9856\n",
      "Baseline Loss: 3.4061 | Actual Loss: 0.6518\n",
      "Baseline Loss: 3.6318 | Actual Loss: 0.5090\n",
      "Baseline Loss: 3.4358 | Actual Loss: 1.5495\n",
      "Baseline Loss: 3.0976 | Actual Loss: 0.9635\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.8951\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.1309\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 171/1000 [01:29<07:19,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4730 | Actual Loss: 0.8627\n",
      "Epoch 171/1000: Train Loss: 0.8135, Val Loss: 1.1235\n",
      "Baseline Loss: 3.3584 | Actual Loss: 0.6173\n",
      "Baseline Loss: 3.5009 | Actual Loss: 0.8457\n",
      "Baseline Loss: 3.4438 | Actual Loss: 0.5760\n",
      "Baseline Loss: 3.3436 | Actual Loss: 0.6510\n",
      "Baseline Loss: 3.4506 | Actual Loss: 0.7993\n",
      "Baseline Loss: 3.7729 | Actual Loss: 1.1687\n",
      "Baseline Loss: 3.6406 | Actual Loss: 1.2627\n",
      "Baseline Loss: 3.4553 | Actual Loss: 0.7314\n",
      "Baseline Loss: 3.7063 | Actual Loss: 0.3506\n",
      "Baseline Loss: 3.5160 | Actual Loss: 1.1012\n",
      "Baseline Loss: 3.5287 | Actual Loss: 0.4585\n",
      "Baseline Loss: 3.5047 | Actual Loss: 1.0859\n",
      "Baseline Loss: 3.6184 | Actual Loss: 0.6544\n",
      "Baseline Loss: 3.6735 | Actual Loss: 0.9624\n",
      "Baseline Loss: 3.6141 | Actual Loss: 0.6392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 172/1000 [01:30<07:35,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.0405 | Actual Loss: 1.7898\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.3610\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.7536\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.5579\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.5817\n",
      "Epoch 172/1000: Train Loss: 0.8559, Val Loss: 1.0636\n",
      "Baseline Loss: 3.4734 | Actual Loss: 0.4185\n",
      "Baseline Loss: 3.4517 | Actual Loss: 1.0281\n",
      "Baseline Loss: 3.4423 | Actual Loss: 0.2722\n",
      "Baseline Loss: 3.6466 | Actual Loss: 0.7496\n",
      "Baseline Loss: 3.4579 | Actual Loss: 0.6727\n",
      "Baseline Loss: 3.3615 | Actual Loss: 0.3919\n",
      "Baseline Loss: 3.6550 | Actual Loss: 0.8562\n",
      "Baseline Loss: 3.3812 | Actual Loss: 0.7127\n",
      "Baseline Loss: 3.6143 | Actual Loss: 1.0560\n",
      "Baseline Loss: 3.8214 | Actual Loss: 1.1711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 173/1000 [01:30<07:08,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5661 | Actual Loss: 0.3812\n",
      "Baseline Loss: 3.3578 | Actual Loss: 1.4234\n",
      "Baseline Loss: 3.4696 | Actual Loss: 1.4265\n",
      "Baseline Loss: 3.3377 | Actual Loss: 0.7793\n",
      "Baseline Loss: 3.3403 | Actual Loss: 0.7369\n",
      "Baseline Loss: 3.4399 | Actual Loss: 0.3375\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.5113\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.9345\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.5355\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.5189\n",
      "Epoch 173/1000: Train Loss: 0.7759, Val Loss: 0.8751\n",
      "Baseline Loss: 3.4661 | Actual Loss: 0.4555\n",
      "Baseline Loss: 3.6502 | Actual Loss: 0.6564\n",
      "Baseline Loss: 3.4851 | Actual Loss: 0.7955\n",
      "Baseline Loss: 3.5489 | Actual Loss: 0.9930\n",
      "Baseline Loss: 3.7323 | Actual Loss: 1.5138\n",
      "Baseline Loss: 3.2628 | Actual Loss: 0.4147\n",
      "Baseline Loss: 3.5212 | Actual Loss: 1.0394\n",
      "Baseline Loss: 3.5018 | Actual Loss: 0.5116\n",
      "Baseline Loss: 3.3999 | Actual Loss: 0.9934\n",
      "Baseline Loss: 3.5421 | Actual Loss: 0.6178\n",
      "Baseline Loss: 3.5129 | Actual Loss: 0.9031\n",
      "Baseline Loss: 3.4573 | Actual Loss: 0.7572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 174/1000 [01:31<07:36,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5414 | Actual Loss: 0.8175\n",
      "Baseline Loss: 3.6686 | Actual Loss: 0.7489\n",
      "Baseline Loss: 3.4135 | Actual Loss: 0.8567\n",
      "Baseline Loss: 3.3220 | Actual Loss: 1.7491\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.8147\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.2502\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6186\n",
      "Baseline Loss: 3.4730 | Actual Loss: 1.5575\n",
      "Epoch 174/1000: Train Loss: 0.8640, Val Loss: 1.3103\n",
      "Baseline Loss: 3.3375 | Actual Loss: 0.5116\n",
      "Baseline Loss: 3.4929 | Actual Loss: 0.8570\n",
      "Baseline Loss: 3.3337 | Actual Loss: 0.3669\n",
      "Baseline Loss: 3.6781 | Actual Loss: 0.4871\n",
      "Baseline Loss: 3.6461 | Actual Loss: 0.7686\n",
      "Baseline Loss: 3.6274 | Actual Loss: 0.5407\n",
      "Baseline Loss: 3.3925 | Actual Loss: 0.3608\n",
      "Baseline Loss: 3.5961 | Actual Loss: 0.6886\n",
      "Baseline Loss: 3.5666 | Actual Loss: 0.3655\n",
      "Baseline Loss: 3.5086 | Actual Loss: 1.7865\n",
      "Baseline Loss: 3.4811 | Actual Loss: 0.4191\n",
      "Baseline Loss: 3.7172 | Actual Loss: 1.3832\n",
      "Baseline Loss: 3.6004 | Actual Loss: 0.9158\n",
      "Baseline Loss: 3.4359 | Actual Loss: 0.7536\n",
      "Baseline Loss: 3.4035 | Actual Loss: 1.8474\n",
      "Baseline Loss: 3.0387 | Actual Loss: 0.1225\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.8090\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.0262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 175/1000 [01:31<07:12,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5384 | Actual Loss: 0.6812\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.9456\n",
      "Epoch 175/1000: Train Loss: 0.7609, Val Loss: 1.1155\n",
      "Baseline Loss: 3.2151 | Actual Loss: 0.7284\n",
      "Baseline Loss: 3.8654 | Actual Loss: 1.7752\n",
      "Baseline Loss: 3.8379 | Actual Loss: 2.4826\n",
      "Baseline Loss: 3.5251 | Actual Loss: 0.7206\n",
      "Baseline Loss: 3.5420 | Actual Loss: 0.4240\n",
      "Baseline Loss: 3.4282 | Actual Loss: 0.5368\n",
      "Baseline Loss: 3.5919 | Actual Loss: 0.8477\n",
      "Baseline Loss: 3.5709 | Actual Loss: 0.6901\n",
      "Baseline Loss: 3.4463 | Actual Loss: 0.9854\n",
      "Baseline Loss: 3.5747 | Actual Loss: 0.1498\n",
      "Baseline Loss: 3.4859 | Actual Loss: 1.8758\n",
      "Baseline Loss: 3.5703 | Actual Loss: 0.3066\n",
      "Baseline Loss: 3.3282 | Actual Loss: 0.7022\n",
      "Baseline Loss: 3.4065 | Actual Loss: 0.7222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 176/1000 [01:32<07:11,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3303 | Actual Loss: 0.5432\n",
      "Baseline Loss: 3.0153 | Actual Loss: 0.1501\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.5235\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.3321\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.5943\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.6612\n",
      "Epoch 176/1000: Train Loss: 0.8525, Val Loss: 1.0278\n",
      "Baseline Loss: 3.4703 | Actual Loss: 0.7409\n",
      "Baseline Loss: 3.5528 | Actual Loss: 0.4282\n",
      "Baseline Loss: 3.3098 | Actual Loss: 0.9370\n",
      "Baseline Loss: 3.3749 | Actual Loss: 1.3863\n",
      "Baseline Loss: 3.5662 | Actual Loss: 0.2965\n",
      "Baseline Loss: 3.5122 | Actual Loss: 0.6331\n",
      "Baseline Loss: 3.5883 | Actual Loss: 0.7521\n",
      "Baseline Loss: 3.5918 | Actual Loss: 0.1717\n",
      "Baseline Loss: 3.6184 | Actual Loss: 0.6203\n",
      "Baseline Loss: 3.4617 | Actual Loss: 0.5882\n",
      "Baseline Loss: 3.5786 | Actual Loss: 1.9949\n",
      "Baseline Loss: 3.4280 | Actual Loss: 0.5230\n",
      "Baseline Loss: 3.4542 | Actual Loss: 1.4193\n",
      "Baseline Loss: 3.4999 | Actual Loss: 0.7627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 177/1000 [01:33<07:39,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4239 | Actual Loss: 0.8673\n",
      "Baseline Loss: 3.4207 | Actual Loss: 0.5470\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.0552\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.4298\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6667\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.7120\n",
      "Epoch 177/1000: Train Loss: 0.7918, Val Loss: 1.2159\n",
      "Baseline Loss: 3.4974 | Actual Loss: 0.7764\n",
      "Baseline Loss: 3.5160 | Actual Loss: 0.6990\n",
      "Baseline Loss: 3.4350 | Actual Loss: 0.6714\n",
      "Baseline Loss: 3.3655 | Actual Loss: 0.9383\n",
      "Baseline Loss: 3.4885 | Actual Loss: 0.7056\n",
      "Baseline Loss: 3.4513 | Actual Loss: 0.8208\n",
      "Baseline Loss: 3.4430 | Actual Loss: 0.5605\n",
      "Baseline Loss: 3.5568 | Actual Loss: 0.9355\n",
      "Baseline Loss: 3.5792 | Actual Loss: 0.8625\n",
      "Baseline Loss: 3.5746 | Actual Loss: 0.9559\n",
      "Baseline Loss: 3.6141 | Actual Loss: 0.6245\n",
      "Baseline Loss: 3.5447 | Actual Loss: 2.0129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 178/1000 [01:33<07:13,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6185 | Actual Loss: 0.4515\n",
      "Baseline Loss: 3.3441 | Actual Loss: 1.1513\n",
      "Baseline Loss: 3.4505 | Actual Loss: 0.5833\n",
      "Baseline Loss: 3.1818 | Actual Loss: 0.5060\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.3658\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.8910\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.7670\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.5893\n",
      "Epoch 178/1000: Train Loss: 0.8285, Val Loss: 0.9033\n",
      "Baseline Loss: 3.4936 | Actual Loss: 0.4430\n",
      "Baseline Loss: 3.5338 | Actual Loss: 1.0236\n",
      "Baseline Loss: 3.5327 | Actual Loss: 0.6262\n",
      "Baseline Loss: 3.4611 | Actual Loss: 0.5102\n",
      "Baseline Loss: 3.4890 | Actual Loss: 0.7383\n",
      "Baseline Loss: 3.5585 | Actual Loss: 0.5185\n",
      "Baseline Loss: 3.6929 | Actual Loss: 1.3390\n",
      "Baseline Loss: 3.6590 | Actual Loss: 0.5757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 179/1000 [01:34<07:09,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6005 | Actual Loss: 0.8891\n",
      "Baseline Loss: 3.3080 | Actual Loss: 0.8771\n",
      "Baseline Loss: 3.3952 | Actual Loss: 1.1955\n",
      "Baseline Loss: 3.5794 | Actual Loss: 0.5851\n",
      "Baseline Loss: 3.4622 | Actual Loss: 1.9976\n",
      "Baseline Loss: 3.2955 | Actual Loss: 0.4823\n",
      "Baseline Loss: 3.3406 | Actual Loss: 0.5499\n",
      "Baseline Loss: 3.6289 | Actual Loss: 2.1238\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.7894\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.1543\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6860\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.6359\n",
      "Epoch 179/1000: Train Loss: 0.9047, Val Loss: 1.0664\n",
      "Baseline Loss: 3.5924 | Actual Loss: 0.3790\n",
      "Baseline Loss: 3.3952 | Actual Loss: 0.8514\n",
      "Baseline Loss: 3.3711 | Actual Loss: 1.0090\n",
      "Baseline Loss: 3.8718 | Actual Loss: 1.1619\n",
      "Baseline Loss: 3.5498 | Actual Loss: 0.6618\n",
      "Baseline Loss: 3.5081 | Actual Loss: 0.4827\n",
      "Baseline Loss: 3.5415 | Actual Loss: 1.0397\n",
      "Baseline Loss: 3.3972 | Actual Loss: 1.9776\n",
      "Baseline Loss: 3.4810 | Actual Loss: 0.9850\n",
      "Baseline Loss: 3.4243 | Actual Loss: 0.6340\n",
      "Baseline Loss: 3.6232 | Actual Loss: 0.3289\n",
      "Baseline Loss: 3.3314 | Actual Loss: 0.4221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 180/1000 [01:34<07:32,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5619 | Actual Loss: 0.4707\n",
      "Baseline Loss: 3.5287 | Actual Loss: 1.2892\n",
      "Baseline Loss: 3.5668 | Actual Loss: 0.6347\n",
      "Baseline Loss: 3.3745 | Actual Loss: 1.0598\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.5565\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.9279\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.7401\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.7968\n",
      "Epoch 180/1000: Train Loss: 0.8367, Val Loss: 1.0053\n",
      "Baseline Loss: 3.6643 | Actual Loss: 0.7511\n",
      "Baseline Loss: 3.5129 | Actual Loss: 0.8323\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.4343\n",
      "Baseline Loss: 3.2734 | Actual Loss: 0.5671\n",
      "Baseline Loss: 3.6186 | Actual Loss: 0.8686\n",
      "Baseline Loss: 3.5570 | Actual Loss: 0.5821\n",
      "Baseline Loss: 3.5203 | Actual Loss: 0.3510\n",
      "Baseline Loss: 3.4773 | Actual Loss: 1.5499\n",
      "Baseline Loss: 3.5447 | Actual Loss: 1.4210\n",
      "Baseline Loss: 3.2732 | Actual Loss: 0.7260\n",
      "Baseline Loss: 3.5569 | Actual Loss: 1.2137\n",
      "Baseline Loss: 3.2845 | Actual Loss: 0.8054\n",
      "Baseline Loss: 3.5416 | Actual Loss: 1.0086\n",
      "Baseline Loss: 3.4322 | Actual Loss: 0.6691\n",
      "Baseline Loss: 3.4890 | Actual Loss: 0.4634\n",
      "Baseline Loss: 3.7015 | Actual Loss: 0.7681\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.8141\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.9812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 181/1000 [01:35<07:09,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5384 | Actual Loss: 0.6603\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.6030\n",
      "Epoch 181/1000: Train Loss: 0.8132, Val Loss: 1.0146\n",
      "Baseline Loss: 3.5168 | Actual Loss: 1.0395\n",
      "Baseline Loss: 3.6223 | Actual Loss: 0.5619\n",
      "Baseline Loss: 3.2962 | Actual Loss: 1.2618\n",
      "Baseline Loss: 3.3919 | Actual Loss: 3.0295\n",
      "Baseline Loss: 3.3246 | Actual Loss: 0.4073\n",
      "Baseline Loss: 3.4738 | Actual Loss: 0.6425\n",
      "Baseline Loss: 3.6694 | Actual Loss: 0.6051\n",
      "Baseline Loss: 3.4178 | Actual Loss: 0.8608\n",
      "Baseline Loss: 3.4580 | Actual Loss: 1.1028\n",
      "Baseline Loss: 3.5256 | Actual Loss: 0.6110\n",
      "Baseline Loss: 3.5458 | Actual Loss: 0.9953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 182/1000 [01:35<07:19,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5161 | Actual Loss: 0.6600\n",
      "Baseline Loss: 3.4774 | Actual Loss: 0.6822\n",
      "Baseline Loss: 3.6051 | Actual Loss: 1.0321\n",
      "Baseline Loss: 3.3961 | Actual Loss: 0.6079\n",
      "Baseline Loss: 3.4309 | Actual Loss: 0.3404\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.8428\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.9673\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6211\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.7579\n",
      "Epoch 182/1000: Train Loss: 0.9025, Val Loss: 1.0473\n",
      "Baseline Loss: 3.4473 | Actual Loss: 1.3890\n",
      "Baseline Loss: 3.5016 | Actual Loss: 0.4952\n",
      "Baseline Loss: 3.6417 | Actual Loss: 0.3956\n",
      "Baseline Loss: 3.4067 | Actual Loss: 0.4399\n",
      "Baseline Loss: 3.4470 | Actual Loss: 0.6024\n",
      "Baseline Loss: 3.4029 | Actual Loss: 0.7388\n",
      "Baseline Loss: 3.3897 | Actual Loss: 1.0266\n",
      "Baseline Loss: 3.4516 | Actual Loss: 0.6331\n",
      "Baseline Loss: 3.6503 | Actual Loss: 0.4562\n",
      "Baseline Loss: 3.6590 | Actual Loss: 0.4602\n",
      "Baseline Loss: 3.4431 | Actual Loss: 0.7914\n",
      "Baseline Loss: 3.7273 | Actual Loss: 2.7790\n",
      "Baseline Loss: 3.5143 | Actual Loss: 0.9096\n",
      "Baseline Loss: 3.5047 | Actual Loss: 0.9566\n",
      "Baseline Loss: 3.4198 | Actual Loss: 0.5868\n",
      "Baseline Loss: 3.4112 | Actual Loss: 2.8526\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.8829\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.9570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 183/1000 [01:36<07:25,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5384 | Actual Loss: 0.6592\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.7806\n",
      "Epoch 183/1000: Train Loss: 0.9696, Val Loss: 1.0699\n",
      "Baseline Loss: 3.3773 | Actual Loss: 0.9904\n",
      "Baseline Loss: 3.4480 | Actual Loss: 0.3172\n",
      "Baseline Loss: 3.5331 | Actual Loss: 0.4198\n",
      "Baseline Loss: 3.4739 | Actual Loss: 1.2173\n",
      "Baseline Loss: 3.3510 | Actual Loss: 0.7199\n",
      "Baseline Loss: 3.7369 | Actual Loss: 1.0967\n",
      "Baseline Loss: 3.7322 | Actual Loss: 0.6416\n",
      "Baseline Loss: 3.5384 | Actual Loss: 3.0048\n",
      "Baseline Loss: 3.4858 | Actual Loss: 0.6655\n",
      "Baseline Loss: 3.5327 | Actual Loss: 0.6673\n",
      "Baseline Loss: 3.4699 | Actual Loss: 0.6032\n",
      "Baseline Loss: 3.4544 | Actual Loss: 0.3878\n",
      "Baseline Loss: 3.7075 | Actual Loss: 0.7148\n",
      "Baseline Loss: 3.4330 | Actual Loss: 0.4868\n",
      "Baseline Loss: 3.3082 | Actual Loss: 1.4529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 184/1000 [01:36<07:05,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3751 | Actual Loss: 0.6503\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.8856\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.0769\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.7912\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.7271\n",
      "Epoch 184/1000: Train Loss: 0.8773, Val Loss: 1.1202\n",
      "Baseline Loss: 3.2886 | Actual Loss: 0.7857\n",
      "Baseline Loss: 3.7624 | Actual Loss: 0.6210\n",
      "Baseline Loss: 3.4323 | Actual Loss: 0.8595\n",
      "Baseline Loss: 3.4247 | Actual Loss: 0.5995\n",
      "Baseline Loss: 3.5411 | Actual Loss: 0.7805\n",
      "Baseline Loss: 3.5495 | Actual Loss: 0.6009\n",
      "Baseline Loss: 3.6545 | Actual Loss: 1.0017\n",
      "Baseline Loss: 3.4114 | Actual Loss: 0.5131\n",
      "Baseline Loss: 3.5748 | Actual Loss: 0.6439\n",
      "Baseline Loss: 3.7068 | Actual Loss: 0.7178\n",
      "Baseline Loss: 3.4468 | Actual Loss: 0.7509\n",
      "Baseline Loss: 3.5168 | Actual Loss: 0.7715\n",
      "Baseline Loss: 3.5671 | Actual Loss: 1.1554\n",
      "Baseline Loss: 3.4280 | Actual Loss: 1.1193\n",
      "Baseline Loss: 3.5086 | Actual Loss: 0.5726\n",
      "Baseline Loss: 3.3742 | Actual Loss: 0.3553\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.7713\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.1381\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 185/1000 [01:37<07:18,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4730 | Actual Loss: 0.5950\n",
      "Epoch 185/1000: Train Loss: 0.7405, Val Loss: 1.0467\n",
      "Baseline Loss: 3.5098 | Actual Loss: 0.3429\n",
      "Baseline Loss: 3.3173 | Actual Loss: 0.7335\n",
      "Baseline Loss: 3.5707 | Actual Loss: 0.8407\n",
      "Baseline Loss: 3.3580 | Actual Loss: 0.9903\n",
      "Baseline Loss: 3.4504 | Actual Loss: 3.4257\n",
      "Baseline Loss: 3.5417 | Actual Loss: 0.5545\n",
      "Baseline Loss: 3.4212 | Actual Loss: 0.6924\n",
      "Baseline Loss: 3.4514 | Actual Loss: 1.1091\n",
      "Baseline Loss: 3.5242 | Actual Loss: 0.5053\n",
      "Baseline Loss: 3.4860 | Actual Loss: 0.6179\n",
      "Baseline Loss: 3.7025 | Actual Loss: 2.5245\n",
      "Baseline Loss: 3.4243 | Actual Loss: 0.7590\n",
      "Baseline Loss: 3.4071 | Actual Loss: 0.6778\n",
      "Baseline Loss: 3.4769 | Actual Loss: 0.4556\n",
      "Baseline Loss: 3.4889 | Actual Loss: 0.6861\n",
      "Baseline Loss: 3.4981 | Actual Loss: 0.5297\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.5497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▊        | 186/1000 [01:37<07:06,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6229 | Actual Loss: 1.1884\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.4302\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.4501\n",
      "Epoch 186/1000: Train Loss: 0.9653, Val Loss: 0.9046\n",
      "Baseline Loss: 3.4585 | Actual Loss: 0.7094\n",
      "Baseline Loss: 3.6280 | Actual Loss: 1.1780\n",
      "Baseline Loss: 3.7323 | Actual Loss: 1.0582\n",
      "Baseline Loss: 3.6324 | Actual Loss: 1.5299\n",
      "Baseline Loss: 3.3969 | Actual Loss: 0.4852\n",
      "Baseline Loss: 3.2153 | Actual Loss: 0.8335\n",
      "Baseline Loss: 3.4246 | Actual Loss: 0.6495\n",
      "Baseline Loss: 3.5795 | Actual Loss: 0.7015\n",
      "Baseline Loss: 3.4967 | Actual Loss: 1.1316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▊        | 187/1000 [01:38<07:17,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4626 | Actual Loss: 0.5107\n",
      "Baseline Loss: 3.5492 | Actual Loss: 0.7318\n",
      "Baseline Loss: 3.5372 | Actual Loss: 0.5929\n",
      "Baseline Loss: 3.8488 | Actual Loss: 1.6832\n",
      "Baseline Loss: 3.2654 | Actual Loss: 0.8028\n",
      "Baseline Loss: 3.4889 | Actual Loss: 0.6699\n",
      "Baseline Loss: 3.1679 | Actual Loss: 0.5061\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.6525\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.2984\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.5951\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.4959\n",
      "Epoch 187/1000: Train Loss: 0.8609, Val Loss: 1.0105\n",
      "Baseline Loss: 3.6234 | Actual Loss: 0.2346\n",
      "Baseline Loss: 3.4774 | Actual Loss: 0.2827\n",
      "Baseline Loss: 3.4654 | Actual Loss: 0.6560\n",
      "Baseline Loss: 3.6181 | Actual Loss: 0.5081\n",
      "Baseline Loss: 3.4033 | Actual Loss: 0.5230\n",
      "Baseline Loss: 3.3881 | Actual Loss: 0.6979\n",
      "Baseline Loss: 3.4467 | Actual Loss: 0.9894\n",
      "Baseline Loss: 3.4579 | Actual Loss: 0.8875\n",
      "Baseline Loss: 3.7476 | Actual Loss: 2.0838\n",
      "Baseline Loss: 3.4971 | Actual Loss: 0.6998\n",
      "Baseline Loss: 3.5408 | Actual Loss: 0.8512\n",
      "Baseline Loss: 3.4784 | Actual Loss: 1.7205\n",
      "Baseline Loss: 3.4761 | Actual Loss: 0.8895\n",
      "Baseline Loss: 3.4822 | Actual Loss: 0.2317\n",
      "Baseline Loss: 3.5251 | Actual Loss: 0.3762\n",
      "Baseline Loss: 3.3754 | Actual Loss: 2.8781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 188/1000 [01:38<07:23,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7429 | Actual Loss: 1.7833\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.2651\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.5996\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.6006\n",
      "Epoch 188/1000: Train Loss: 0.9069, Val Loss: 1.0621\n",
      "Baseline Loss: 3.2913 | Actual Loss: 0.4304\n",
      "Baseline Loss: 3.3956 | Actual Loss: 0.6381\n",
      "Baseline Loss: 3.4619 | Actual Loss: 0.5857\n",
      "Baseline Loss: 3.5800 | Actual Loss: 1.5650\n",
      "Baseline Loss: 3.6593 | Actual Loss: 0.9841\n",
      "Baseline Loss: 3.7120 | Actual Loss: 1.2373\n",
      "Baseline Loss: 3.4504 | Actual Loss: 0.6947\n",
      "Baseline Loss: 3.7161 | Actual Loss: 0.5659\n",
      "Baseline Loss: 3.2824 | Actual Loss: 0.7219\n",
      "Baseline Loss: 3.3484 | Actual Loss: 1.3225\n",
      "Baseline Loss: 3.5206 | Actual Loss: 0.6623\n",
      "Baseline Loss: 3.6361 | Actual Loss: 0.6242\n",
      "Baseline Loss: 3.3928 | Actual Loss: 0.8623\n",
      "Baseline Loss: 3.7025 | Actual Loss: 0.5231\n",
      "Baseline Loss: 3.4742 | Actual Loss: 0.5725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 189/1000 [01:39<07:08,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.8937 | Actual Loss: 2.9263\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.0124\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.9916\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.5405\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.7620\n",
      "Epoch 189/1000: Train Loss: 0.9323, Val Loss: 1.0766\n",
      "Baseline Loss: 3.5835 | Actual Loss: 0.9785\n",
      "Baseline Loss: 3.4446 | Actual Loss: 0.6050\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.5961\n",
      "Baseline Loss: 3.4745 | Actual Loss: 1.6813\n",
      "Baseline Loss: 3.8489 | Actual Loss: 2.8227\n",
      "Baseline Loss: 3.2909 | Actual Loss: 1.1455\n",
      "Baseline Loss: 3.5533 | Actual Loss: 0.8437\n",
      "Baseline Loss: 3.5209 | Actual Loss: 0.7711\n",
      "Baseline Loss: 3.6047 | Actual Loss: 0.3872\n",
      "Baseline Loss: 3.3373 | Actual Loss: 0.9758\n",
      "Baseline Loss: 3.3988 | Actual Loss: 1.6925\n",
      "Baseline Loss: 3.4888 | Actual Loss: 0.6417\n",
      "Baseline Loss: 3.6226 | Actual Loss: 1.1306\n",
      "Baseline Loss: 3.4776 | Actual Loss: 0.4592\n",
      "Baseline Loss: 3.3574 | Actual Loss: 1.1114\n",
      "Baseline Loss: 3.4981 | Actual Loss: 0.8519\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.6998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 190/1000 [01:40<07:21,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6229 | Actual Loss: 1.0227\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.5177\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.5722\n",
      "Epoch 190/1000: Train Loss: 1.0434, Val Loss: 0.9531\n",
      "Baseline Loss: 3.4690 | Actual Loss: 0.8892\n",
      "Baseline Loss: 3.5835 | Actual Loss: 0.3631\n",
      "Baseline Loss: 3.4808 | Actual Loss: 1.0271\n",
      "Baseline Loss: 3.5912 | Actual Loss: 0.5126\n",
      "Baseline Loss: 3.7319 | Actual Loss: 0.4789\n",
      "Baseline Loss: 3.4511 | Actual Loss: 0.4328\n",
      "Baseline Loss: 3.3463 | Actual Loss: 0.8690\n",
      "Baseline Loss: 3.5326 | Actual Loss: 0.8435\n",
      "Baseline Loss: 3.6684 | Actual Loss: 0.6716\n",
      "Baseline Loss: 3.2827 | Actual Loss: 0.9981\n",
      "Baseline Loss: 3.7520 | Actual Loss: 1.1526\n",
      "Baseline Loss: 3.5258 | Actual Loss: 0.9376\n",
      "Baseline Loss: 3.3414 | Actual Loss: 0.5558\n",
      "Baseline Loss: 3.3712 | Actual Loss: 1.3031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 191/1000 [01:40<07:22,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4245 | Actual Loss: 0.3292\n",
      "Baseline Loss: 3.3491 | Actual Loss: 0.1605\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.5202\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.2961\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6382\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.8208\n",
      "Epoch 191/1000: Train Loss: 0.7203, Val Loss: 1.0688\n",
      "Baseline Loss: 3.3054 | Actual Loss: 0.6559\n",
      "Baseline Loss: 3.5376 | Actual Loss: 0.5666\n",
      "Baseline Loss: 3.3686 | Actual Loss: 0.8537\n",
      "Baseline Loss: 3.2848 | Actual Loss: 1.1256\n",
      "Baseline Loss: 3.7273 | Actual Loss: 0.7159\n",
      "Baseline Loss: 3.6871 | Actual Loss: 3.1694\n",
      "Baseline Loss: 3.5959 | Actual Loss: 0.8415\n",
      "Baseline Loss: 3.4103 | Actual Loss: 0.5911\n",
      "Baseline Loss: 3.3182 | Actual Loss: 0.5634\n",
      "Baseline Loss: 3.4777 | Actual Loss: 0.8726\n",
      "Baseline Loss: 3.5409 | Actual Loss: 1.2581\n",
      "Baseline Loss: 3.5700 | Actual Loss: 0.8393\n",
      "Baseline Loss: 3.5622 | Actual Loss: 0.7711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 192/1000 [01:41<07:02,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3987 | Actual Loss: 0.7890\n",
      "Baseline Loss: 3.6056 | Actual Loss: 0.5807\n",
      "Baseline Loss: 3.6765 | Actual Loss: 0.8780\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.5834\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.1028\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.7587\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.5727\n",
      "Epoch 192/1000: Train Loss: 0.9420, Val Loss: 1.0044\n",
      "Baseline Loss: 3.5056 | Actual Loss: 0.6719\n",
      "Baseline Loss: 3.4654 | Actual Loss: 0.2614\n",
      "Baseline Loss: 3.5538 | Actual Loss: 1.2958\n",
      "Baseline Loss: 3.4688 | Actual Loss: 0.7220\n",
      "Baseline Loss: 3.4735 | Actual Loss: 0.9438\n",
      "Baseline Loss: 3.4536 | Actual Loss: 0.5411\n",
      "Baseline Loss: 3.5499 | Actual Loss: 0.6706\n",
      "Baseline Loss: 3.6182 | Actual Loss: 0.6953\n",
      "Baseline Loss: 3.4745 | Actual Loss: 0.6553\n",
      "Baseline Loss: 3.5446 | Actual Loss: 0.6436\n",
      "Baseline Loss: 3.3429 | Actual Loss: 0.3477\n",
      "Baseline Loss: 3.3715 | Actual Loss: 0.4667\n",
      "Baseline Loss: 3.4019 | Actual Loss: 0.6452\n",
      "Baseline Loss: 3.4029 | Actual Loss: 0.4640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 193/1000 [01:41<07:24,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6459 | Actual Loss: 0.4263\n",
      "Baseline Loss: 3.6645 | Actual Loss: 0.8564\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.0898\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.2243\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.7125\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.6212\n",
      "Epoch 193/1000: Train Loss: 0.6442, Val Loss: 1.1620\n",
      "Baseline Loss: 3.4068 | Actual Loss: 2.0515\n",
      "Baseline Loss: 3.4399 | Actual Loss: 0.5599\n",
      "Baseline Loss: 3.4427 | Actual Loss: 1.3836\n",
      "Baseline Loss: 3.3580 | Actual Loss: 0.5909\n",
      "Baseline Loss: 3.5874 | Actual Loss: 0.3342\n",
      "Baseline Loss: 3.5581 | Actual Loss: 0.5059\n",
      "Baseline Loss: 3.3565 | Actual Loss: 0.5793\n",
      "Baseline Loss: 3.5494 | Actual Loss: 0.7045\n",
      "Baseline Loss: 3.6002 | Actual Loss: 0.5847\n",
      "Baseline Loss: 3.6541 | Actual Loss: 1.0880\n",
      "Baseline Loss: 3.5788 | Actual Loss: 0.4179\n",
      "Baseline Loss: 3.5878 | Actual Loss: 0.6072\n",
      "Baseline Loss: 3.5458 | Actual Loss: 0.7057\n",
      "Baseline Loss: 3.3265 | Actual Loss: 0.7433\n",
      "Baseline Loss: 3.5259 | Actual Loss: 0.5105\n",
      "Baseline Loss: 3.6533 | Actual Loss: 0.3315\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.4203\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.0201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 194/1000 [01:42<07:19,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5384 | Actual Loss: 0.6334\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.6110\n",
      "Epoch 194/1000: Train Loss: 0.7312, Val Loss: 0.9212\n",
      "Baseline Loss: 3.5209 | Actual Loss: 0.6058\n",
      "Baseline Loss: 3.5790 | Actual Loss: 0.6026\n",
      "Baseline Loss: 3.4036 | Actual Loss: 0.7307\n",
      "Baseline Loss: 3.5655 | Actual Loss: 0.7941\n",
      "Baseline Loss: 3.5407 | Actual Loss: 0.8043\n",
      "Baseline Loss: 3.4615 | Actual Loss: 0.9522\n",
      "Baseline Loss: 3.5320 | Actual Loss: 0.8987\n",
      "Baseline Loss: 3.6775 | Actual Loss: 0.8042\n",
      "Baseline Loss: 3.5923 | Actual Loss: 0.6333\n",
      "Baseline Loss: 3.3334 | Actual Loss: 1.0123\n",
      "Baseline Loss: 3.4205 | Actual Loss: 1.1315\n",
      "Baseline Loss: 3.5743 | Actual Loss: 0.6273\n",
      "Baseline Loss: 3.6005 | Actual Loss: 3.3696\n",
      "Baseline Loss: 3.4290 | Actual Loss: 0.7895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 195/1000 [01:42<06:57,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5573 | Actual Loss: 0.8525\n",
      "Baseline Loss: 2.9902 | Actual Loss: 0.5509\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.7206\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.0115\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6482\n",
      "Baseline Loss: 3.4730 | Actual Loss: 1.1519\n",
      "Epoch 195/1000: Train Loss: 0.9475, Val Loss: 1.1330\n",
      "Baseline Loss: 3.4544 | Actual Loss: 0.9213\n",
      "Baseline Loss: 3.4626 | Actual Loss: 0.6558\n",
      "Baseline Loss: 3.7419 | Actual Loss: 0.3494\n",
      "Baseline Loss: 3.5662 | Actual Loss: 1.2104\n",
      "Baseline Loss: 3.4391 | Actual Loss: 0.9858\n",
      "Baseline Loss: 3.5125 | Actual Loss: 0.3143\n",
      "Baseline Loss: 3.3610 | Actual Loss: 0.7943\n",
      "Baseline Loss: 3.3001 | Actual Loss: 0.7901\n",
      "Baseline Loss: 3.4782 | Actual Loss: 1.1217\n",
      "Baseline Loss: 3.5705 | Actual Loss: 0.4382\n",
      "Baseline Loss: 3.4738 | Actual Loss: 0.6514\n",
      "Baseline Loss: 3.5485 | Actual Loss: 0.4040\n",
      "Baseline Loss: 3.4035 | Actual Loss: 2.5833\n",
      "Baseline Loss: 3.2418 | Actual Loss: 0.7508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 196/1000 [01:43<07:16,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5452 | Actual Loss: 0.3733\n",
      "Baseline Loss: 3.2498 | Actual Loss: 0.8607\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.7102\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.9440\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.7128\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.5471\n",
      "Epoch 196/1000: Train Loss: 0.8253, Val Loss: 0.9785\n",
      "Baseline Loss: 3.7116 | Actual Loss: 0.8165\n",
      "Baseline Loss: 3.5913 | Actual Loss: 0.7137\n",
      "Baseline Loss: 3.5539 | Actual Loss: 0.6230\n",
      "Baseline Loss: 3.2966 | Actual Loss: 1.1632\n",
      "Baseline Loss: 3.6026 | Actual Loss: 0.5908\n",
      "Baseline Loss: 3.3818 | Actual Loss: 0.6913\n",
      "Baseline Loss: 3.5795 | Actual Loss: 0.4431\n",
      "Baseline Loss: 3.5126 | Actual Loss: 0.8296\n",
      "Baseline Loss: 3.5784 | Actual Loss: 1.4138\n",
      "Baseline Loss: 3.4888 | Actual Loss: 0.7124\n",
      "Baseline Loss: 3.6177 | Actual Loss: 0.5578\n",
      "Baseline Loss: 3.5080 | Actual Loss: 0.9274\n",
      "Baseline Loss: 3.2062 | Actual Loss: 0.8457\n",
      "Baseline Loss: 3.4288 | Actual Loss: 0.5970\n",
      "Baseline Loss: 3.4436 | Actual Loss: 1.1150\n",
      "Baseline Loss: 3.5298 | Actual Loss: 4.1626\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.9502\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.9966\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.5843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 197/1000 [01:43<07:14,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4730 | Actual Loss: 0.6206\n",
      "Epoch 197/1000: Train Loss: 1.0127, Val Loss: 1.0379\n",
      "Baseline Loss: 3.4468 | Actual Loss: 0.9260\n",
      "Baseline Loss: 3.4180 | Actual Loss: 1.3810\n",
      "Baseline Loss: 3.6833 | Actual Loss: 1.0993\n",
      "Baseline Loss: 3.4967 | Actual Loss: 0.5800\n",
      "Baseline Loss: 3.6683 | Actual Loss: 1.5510\n",
      "Baseline Loss: 3.4772 | Actual Loss: 0.6899\n",
      "Baseline Loss: 3.3787 | Actual Loss: 0.6816\n",
      "Baseline Loss: 3.6975 | Actual Loss: 0.8567\n",
      "Baseline Loss: 3.4182 | Actual Loss: 0.5625\n",
      "Baseline Loss: 3.5457 | Actual Loss: 0.5251\n",
      "Baseline Loss: 3.5371 | Actual Loss: 0.6787\n",
      "Baseline Loss: 3.3270 | Actual Loss: 0.4920\n",
      "Baseline Loss: 3.3917 | Actual Loss: 0.8250\n",
      "Baseline Loss: 3.4663 | Actual Loss: 0.9927\n",
      "Baseline Loss: 3.4356 | Actual Loss: 0.5012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 198/1000 [01:44<07:06,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4299 | Actual Loss: 0.3081\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.7390\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.9924\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.7290\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.7554\n",
      "Epoch 198/1000: Train Loss: 0.7907, Val Loss: 1.0540\n",
      "Baseline Loss: 3.4063 | Actual Loss: 0.5055\n",
      "Baseline Loss: 3.6838 | Actual Loss: 0.5728\n",
      "Baseline Loss: 3.4447 | Actual Loss: 0.6951\n",
      "Baseline Loss: 3.4431 | Actual Loss: 0.9349\n",
      "Baseline Loss: 3.5825 | Actual Loss: 0.5064\n",
      "Baseline Loss: 3.6688 | Actual Loss: 0.7300\n",
      "Baseline Loss: 3.6142 | Actual Loss: 0.6851\n",
      "Baseline Loss: 3.6224 | Actual Loss: 0.8330\n",
      "Baseline Loss: 3.3881 | Actual Loss: 0.7029\n",
      "Baseline Loss: 3.6225 | Actual Loss: 0.5194\n",
      "Baseline Loss: 3.4245 | Actual Loss: 2.2580\n",
      "Baseline Loss: 3.5245 | Actual Loss: 1.5664\n",
      "Baseline Loss: 3.4777 | Actual Loss: 0.7071\n",
      "Baseline Loss: 3.4705 | Actual Loss: 0.9856\n",
      "Baseline Loss: 3.3406 | Actual Loss: 1.1247\n",
      "Baseline Loss: 3.2584 | Actual Loss: 3.4897\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.9279\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.9184\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 199/1000 [01:44<07:13,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4730 | Actual Loss: 0.8832\n",
      "Epoch 199/1000: Train Loss: 1.0510, Val Loss: 1.0860\n",
      "Baseline Loss: 3.4027 | Actual Loss: 0.4933\n",
      "Baseline Loss: 3.5743 | Actual Loss: 1.3148\n",
      "Baseline Loss: 3.4723 | Actual Loss: 3.3235\n",
      "Baseline Loss: 3.4771 | Actual Loss: 0.7091\n",
      "Baseline Loss: 3.5459 | Actual Loss: 1.4602\n",
      "Baseline Loss: 3.5088 | Actual Loss: 0.7862\n",
      "Baseline Loss: 3.4650 | Actual Loss: 0.7968\n",
      "Baseline Loss: 3.5373 | Actual Loss: 0.7618\n",
      "Baseline Loss: 3.4210 | Actual Loss: 0.6288\n",
      "Baseline Loss: 3.5417 | Actual Loss: 0.7311\n",
      "Baseline Loss: 3.5009 | Actual Loss: 0.6614\n",
      "Baseline Loss: 3.4432 | Actual Loss: 0.6182\n",
      "Baseline Loss: 3.4467 | Actual Loss: 0.5541\n",
      "Baseline Loss: 3.5329 | Actual Loss: 0.4923\n",
      "Baseline Loss: 3.5092 | Actual Loss: 0.6237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 199/1000 [01:45<07:04,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6524 | Actual Loss: 3.1489\n",
      "Baseline Loss: 3.7429 | Actual Loss: 1.7856\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.9028\n",
      "Baseline Loss: 3.5384 | Actual Loss: 0.6533\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.6513\n",
      "Epoch 200/1000: Train Loss: 1.0690, Val Loss: 0.9983\n",
      "\n",
      "Early stopping at epoch 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8386703357100487"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devices = [\"cuda\" if torch.cuda.is_available() else \"cpu\"]\n",
    "model6 = GNNModelWithNewLoss(\n",
    "        num_node_features=data_list[0].x.shape[1],\n",
    "        num_edge_features=data_list[0].edge_attr.shape[1],\n",
    "        num_global_features=0,\n",
    "        cov_num= 6,\n",
    "        hidden_dim=512,\n",
    "        dropout_rate=0.1,\n",
    "        property_index= 2,\n",
    "        save_path= 'premodels_new_og/6/2' \n",
    "    ).to(devices[0])\n",
    "\n",
    "model6.train_model(\n",
    "    data_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b01e3575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training will be saved to: premodels_new_og/9/0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8098 | Actual Loss: 2.7736\n",
      "Baseline Loss: 2.7834 | Actual Loss: 2.7570\n",
      "Baseline Loss: 2.8119 | Actual Loss: 2.6699\n",
      "Baseline Loss: 2.7985 | Actual Loss: 2.5605\n",
      "Baseline Loss: 2.7859 | Actual Loss: 2.4264\n",
      "Baseline Loss: 2.8016 | Actual Loss: 2.3660\n",
      "Baseline Loss: 2.8180 | Actual Loss: 2.0808\n",
      "Baseline Loss: 2.8000 | Actual Loss: 2.0499\n",
      "Baseline Loss: 2.8490 | Actual Loss: 2.0468\n",
      "Baseline Loss: 2.8587 | Actual Loss: 2.0116\n",
      "Baseline Loss: 2.8176 | Actual Loss: 1.7800\n",
      "Baseline Loss: 2.8062 | Actual Loss: 1.7507\n",
      "Baseline Loss: 2.7584 | Actual Loss: 1.5493\n",
      "Baseline Loss: 2.7880 | Actual Loss: 1.7187\n",
      "Baseline Loss: 2.8843 | Actual Loss: 1.9089\n",
      "Baseline Loss: 2.7001 | Actual Loss: 1.6281\n",
      "Baseline Loss: 2.9000 | Actual Loss: 1.7189\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.7459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 1/1000 [00:00<11:24,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8529 | Actual Loss: 1.7716\n",
      "Baseline Loss: 2.7244 | Actual Loss: 1.4734\n",
      "Epoch 1/1000: Train Loss: 2.1299, Val Loss: 1.6775\n",
      "New best validation loss: 1.6775\n",
      "Baseline Loss: 2.8426 | Actual Loss: 1.5240\n",
      "Baseline Loss: 2.8728 | Actual Loss: 1.5607\n",
      "Baseline Loss: 2.8663 | Actual Loss: 1.8415\n",
      "Baseline Loss: 2.8414 | Actual Loss: 1.6059\n",
      "Baseline Loss: 2.8571 | Actual Loss: 1.7195\n",
      "Baseline Loss: 2.8154 | Actual Loss: 1.5995\n",
      "Baseline Loss: 2.8525 | Actual Loss: 1.6953\n",
      "Baseline Loss: 2.7593 | Actual Loss: 1.5283\n",
      "Baseline Loss: 2.7896 | Actual Loss: 1.6070\n",
      "Baseline Loss: 2.8722 | Actual Loss: 1.7003\n",
      "Baseline Loss: 2.8176 | Actual Loss: 1.5653\n",
      "Baseline Loss: 2.7466 | Actual Loss: 1.4250\n",
      "Baseline Loss: 2.7172 | Actual Loss: 1.3014\n",
      "Baseline Loss: 2.8315 | Actual Loss: 1.6631\n",
      "Baseline Loss: 2.7703 | Actual Loss: 1.1681\n",
      "Baseline Loss: 2.4852 | Actual Loss: 1.0081\n",
      "Baseline Loss: 2.9000 | Actual Loss: 1.2880\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.3883\n",
      "Baseline Loss: 2.8529 | Actual Loss: 1.4747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 2/1000 [00:01<10:57,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7244 | Actual Loss: 1.2486\n",
      "Epoch 2/1000: Train Loss: 1.5321, Val Loss: 1.3499\n",
      "New best validation loss: 1.3499\n",
      "Baseline Loss: 2.8981 | Actual Loss: 1.7459\n",
      "Baseline Loss: 2.7927 | Actual Loss: 1.3938\n",
      "Baseline Loss: 2.8394 | Actual Loss: 1.3886\n",
      "Baseline Loss: 2.8393 | Actual Loss: 1.1262\n",
      "Baseline Loss: 2.8914 | Actual Loss: 1.6588\n",
      "Baseline Loss: 2.8103 | Actual Loss: 1.1746\n",
      "Baseline Loss: 2.8084 | Actual Loss: 1.3274\n",
      "Baseline Loss: 2.8047 | Actual Loss: 1.2566\n",
      "Baseline Loss: 2.7842 | Actual Loss: 1.3432\n",
      "Baseline Loss: 2.7812 | Actual Loss: 1.3019\n",
      "Baseline Loss: 2.8230 | Actual Loss: 1.1306\n",
      "Baseline Loss: 2.8171 | Actual Loss: 1.0528\n",
      "Baseline Loss: 2.8088 | Actual Loss: 1.1409\n",
      "Baseline Loss: 2.7996 | Actual Loss: 1.0671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 3/1000 [00:01<10:00,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7767 | Actual Loss: 1.3693\n",
      "Baseline Loss: 2.5415 | Actual Loss: 0.8355\n",
      "Baseline Loss: 2.9000 | Actual Loss: 1.1425\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.5806\n",
      "Baseline Loss: 2.8529 | Actual Loss: 1.4044\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.9464\n",
      "Epoch 3/1000: Train Loss: 1.2696, Val Loss: 1.2685\n",
      "New best validation loss: 1.2685\n",
      "Baseline Loss: 2.8019 | Actual Loss: 1.1114\n",
      "Baseline Loss: 2.8929 | Actual Loss: 1.5588\n",
      "Baseline Loss: 2.8657 | Actual Loss: 1.4267\n",
      "Baseline Loss: 2.7997 | Actual Loss: 0.8304\n",
      "Baseline Loss: 2.7427 | Actual Loss: 1.4722\n",
      "Baseline Loss: 2.8466 | Actual Loss: 1.2730\n",
      "Baseline Loss: 2.8702 | Actual Loss: 1.1579\n",
      "Baseline Loss: 2.8040 | Actual Loss: 1.0891\n",
      "Baseline Loss: 2.8513 | Actual Loss: 1.1670\n",
      "Baseline Loss: 2.8188 | Actual Loss: 1.0789\n",
      "Baseline Loss: 2.7744 | Actual Loss: 1.3376\n",
      "Baseline Loss: 2.7321 | Actual Loss: 0.8268\n",
      "Baseline Loss: 2.8140 | Actual Loss: 1.0928\n",
      "Baseline Loss: 2.8189 | Actual Loss: 1.0259\n",
      "Baseline Loss: 2.8446 | Actual Loss: 1.0924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 4/1000 [00:02<10:33,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.4512 | Actual Loss: 1.3525\n",
      "Baseline Loss: 2.9000 | Actual Loss: 1.1775\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.3811\n",
      "Baseline Loss: 2.8529 | Actual Loss: 1.2355\n",
      "Baseline Loss: 2.7244 | Actual Loss: 1.0170\n",
      "Epoch 4/1000: Train Loss: 1.1808, Val Loss: 1.2028\n",
      "New best validation loss: 1.2028\n",
      "Baseline Loss: 2.8810 | Actual Loss: 1.3290\n",
      "Baseline Loss: 2.7162 | Actual Loss: 1.1764\n",
      "Baseline Loss: 2.8585 | Actual Loss: 1.3357\n",
      "Baseline Loss: 2.8584 | Actual Loss: 1.0544\n",
      "Baseline Loss: 2.8636 | Actual Loss: 0.9704\n",
      "Baseline Loss: 2.8130 | Actual Loss: 0.9311\n",
      "Baseline Loss: 2.8309 | Actual Loss: 0.9523\n",
      "Baseline Loss: 2.8326 | Actual Loss: 0.8021\n",
      "Baseline Loss: 2.7763 | Actual Loss: 0.8127\n",
      "Baseline Loss: 2.8356 | Actual Loss: 0.9827\n",
      "Baseline Loss: 2.8133 | Actual Loss: 0.6616\n",
      "Baseline Loss: 2.8137 | Actual Loss: 0.7492\n",
      "Baseline Loss: 2.8287 | Actual Loss: 0.9764\n",
      "Baseline Loss: 2.7556 | Actual Loss: 0.5658\n",
      "Baseline Loss: 2.8590 | Actual Loss: 1.1263\n",
      "Baseline Loss: 2.6905 | Actual Loss: 0.6631\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.8644\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.2741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 5/1000 [00:03<10:33,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8529 | Actual Loss: 0.9071\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.7982\n",
      "Epoch 5/1000: Train Loss: 0.9431, Val Loss: 0.9610\n",
      "New best validation loss: 0.9610\n",
      "Baseline Loss: 2.8337 | Actual Loss: 1.0759\n",
      "Baseline Loss: 2.7837 | Actual Loss: 0.7052\n",
      "Baseline Loss: 2.8608 | Actual Loss: 0.9784\n",
      "Baseline Loss: 2.8018 | Actual Loss: 1.2519\n",
      "Baseline Loss: 2.7928 | Actual Loss: 0.7788\n",
      "Baseline Loss: 2.8844 | Actual Loss: 0.8762\n",
      "Baseline Loss: 2.7552 | Actual Loss: 0.8229\n",
      "Baseline Loss: 2.8258 | Actual Loss: 0.8215\n",
      "Baseline Loss: 2.8565 | Actual Loss: 0.8982\n",
      "Baseline Loss: 2.8577 | Actual Loss: 0.5364\n",
      "Baseline Loss: 2.7612 | Actual Loss: 0.8179\n",
      "Baseline Loss: 2.8211 | Actual Loss: 1.1179\n",
      "Baseline Loss: 2.8650 | Actual Loss: 0.8134\n",
      "Baseline Loss: 2.7834 | Actual Loss: 0.8547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 6/1000 [00:03<10:02,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7620 | Actual Loss: 0.7923\n",
      "Baseline Loss: 2.5574 | Actual Loss: 0.4235\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.9108\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.4113\n",
      "Baseline Loss: 2.8529 | Actual Loss: 1.0557\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.9012\n",
      "Epoch 6/1000: Train Loss: 0.8478, Val Loss: 1.0697\n",
      "Baseline Loss: 2.8217 | Actual Loss: 0.6672\n",
      "Baseline Loss: 2.8020 | Actual Loss: 0.6653\n",
      "Baseline Loss: 2.8239 | Actual Loss: 1.5244\n",
      "Baseline Loss: 2.7319 | Actual Loss: 0.9514\n",
      "Baseline Loss: 2.7882 | Actual Loss: 0.7816\n",
      "Baseline Loss: 2.8478 | Actual Loss: 0.8357\n",
      "Baseline Loss: 2.8758 | Actual Loss: 0.7896\n",
      "Baseline Loss: 2.8360 | Actual Loss: 0.9203\n",
      "Baseline Loss: 2.8003 | Actual Loss: 1.0174\n",
      "Baseline Loss: 2.8439 | Actual Loss: 0.5077\n",
      "Baseline Loss: 2.8284 | Actual Loss: 0.6765\n",
      "Baseline Loss: 2.8443 | Actual Loss: 1.6085\n",
      "Baseline Loss: 2.8361 | Actual Loss: 1.3255\n",
      "Baseline Loss: 2.7972 | Actual Loss: 1.0787\n",
      "Baseline Loss: 2.7746 | Actual Loss: 1.1981\n",
      "Baseline Loss: 2.5751 | Actual Loss: 1.0173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 7/1000 [00:04<10:23,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9000 | Actual Loss: 0.8697\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.1122\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.9368\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.8403\n",
      "Epoch 7/1000: Train Loss: 0.9728, Val Loss: 0.9397\n",
      "New best validation loss: 0.9397\n",
      "Baseline Loss: 2.8640 | Actual Loss: 0.8838\n",
      "Baseline Loss: 2.8268 | Actual Loss: 0.7076\n",
      "Baseline Loss: 2.7936 | Actual Loss: 0.6295\n",
      "Baseline Loss: 2.7795 | Actual Loss: 0.6598\n",
      "Baseline Loss: 2.8065 | Actual Loss: 0.8508\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.9235\n",
      "Baseline Loss: 2.8290 | Actual Loss: 1.0076\n",
      "Baseline Loss: 2.7886 | Actual Loss: 0.8557\n",
      "Baseline Loss: 2.8678 | Actual Loss: 1.0642\n",
      "Baseline Loss: 2.8137 | Actual Loss: 0.7964\n",
      "Baseline Loss: 2.8174 | Actual Loss: 0.7870\n",
      "Baseline Loss: 2.8148 | Actual Loss: 0.6015\n",
      "Baseline Loss: 2.8104 | Actual Loss: 0.6866\n",
      "Baseline Loss: 2.8807 | Actual Loss: 0.7288\n",
      "Baseline Loss: 2.8121 | Actual Loss: 0.9328\n",
      "Baseline Loss: 2.4339 | Actual Loss: 0.3911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 8/1000 [00:05<10:20,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9000 | Actual Loss: 0.6938\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.3044\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.9204\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.8711\n",
      "Epoch 8/1000: Train Loss: 0.7817, Val Loss: 0.9474\n",
      "Baseline Loss: 2.8592 | Actual Loss: 1.6294\n",
      "Baseline Loss: 2.8382 | Actual Loss: 1.2220\n",
      "Baseline Loss: 2.7747 | Actual Loss: 0.8509\n",
      "Baseline Loss: 2.8627 | Actual Loss: 0.6598\n",
      "Baseline Loss: 2.8071 | Actual Loss: 0.9520\n",
      "Baseline Loss: 2.8855 | Actual Loss: 0.6659\n",
      "Baseline Loss: 2.8228 | Actual Loss: 0.6110\n",
      "Baseline Loss: 2.8036 | Actual Loss: 0.8381\n",
      "Baseline Loss: 2.8026 | Actual Loss: 1.1212\n",
      "Baseline Loss: 2.8552 | Actual Loss: 0.5634\n",
      "Baseline Loss: 2.7932 | Actual Loss: 0.6339\n",
      "Baseline Loss: 2.7724 | Actual Loss: 0.6125\n",
      "Baseline Loss: 2.8626 | Actual Loss: 1.0163\n",
      "Baseline Loss: 2.8025 | Actual Loss: 0.8485\n",
      "Baseline Loss: 2.8255 | Actual Loss: 0.6992\n",
      "Baseline Loss: 2.5011 | Actual Loss: 0.2431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 9/1000 [00:05<10:09,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9000 | Actual Loss: 0.6535\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.3844\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.6533\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.8099\n",
      "Epoch 9/1000: Train Loss: 0.8229, Val Loss: 0.8753\n",
      "New best validation loss: 0.8753\n",
      "Baseline Loss: 2.9052 | Actual Loss: 0.9696\n",
      "Baseline Loss: 2.8315 | Actual Loss: 0.9637\n",
      "Baseline Loss: 2.9180 | Actual Loss: 0.5426\n",
      "Baseline Loss: 2.7800 | Actual Loss: 0.7802\n",
      "Baseline Loss: 2.8978 | Actual Loss: 0.5355\n",
      "Baseline Loss: 2.8567 | Actual Loss: 0.9688\n",
      "Baseline Loss: 2.7521 | Actual Loss: 0.7722\n",
      "Baseline Loss: 2.8829 | Actual Loss: 0.7171\n",
      "Baseline Loss: 2.7669 | Actual Loss: 0.6199\n",
      "Baseline Loss: 2.7902 | Actual Loss: 0.6448\n",
      "Baseline Loss: 2.8059 | Actual Loss: 0.5534\n",
      "Baseline Loss: 2.7548 | Actual Loss: 1.7140\n",
      "Baseline Loss: 2.8281 | Actual Loss: 0.7151\n",
      "Baseline Loss: 2.8301 | Actual Loss: 0.8759\n",
      "Baseline Loss: 2.8526 | Actual Loss: 0.4829\n",
      "Baseline Loss: 2.5918 | Actual Loss: 0.5263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 10/1000 [00:06<10:23,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9000 | Actual Loss: 0.5946\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.3180\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.8102\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.7760\n",
      "Epoch 10/1000: Train Loss: 0.7739, Val Loss: 0.8747\n",
      "New best validation loss: 0.8747\n",
      "Baseline Loss: 2.8171 | Actual Loss: 0.4071\n",
      "Baseline Loss: 2.8429 | Actual Loss: 0.7758\n",
      "Baseline Loss: 2.7481 | Actual Loss: 0.4747\n",
      "Baseline Loss: 2.7790 | Actual Loss: 1.0120\n",
      "Baseline Loss: 2.8520 | Actual Loss: 0.7407\n",
      "Baseline Loss: 2.8104 | Actual Loss: 0.9805\n",
      "Baseline Loss: 2.8157 | Actual Loss: 0.7664\n",
      "Baseline Loss: 2.8699 | Actual Loss: 1.1289\n",
      "Baseline Loss: 2.8338 | Actual Loss: 0.5587\n",
      "Baseline Loss: 2.7942 | Actual Loss: 0.5491\n",
      "Baseline Loss: 2.8532 | Actual Loss: 0.3932\n",
      "Baseline Loss: 2.8143 | Actual Loss: 0.3166\n",
      "Baseline Loss: 2.9151 | Actual Loss: 0.8979\n",
      "Baseline Loss: 2.7995 | Actual Loss: 0.4975\n",
      "Baseline Loss: 2.7788 | Actual Loss: 0.7372\n",
      "Baseline Loss: 2.3788 | Actual Loss: 0.9816\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.7112\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.0288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 11/1000 [00:06<10:40,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8529 | Actual Loss: 0.8572\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.7520\n",
      "Epoch 11/1000: Train Loss: 0.7011, Val Loss: 0.8373\n",
      "New best validation loss: 0.8373\n",
      "Baseline Loss: 2.8491 | Actual Loss: 0.6313\n",
      "Baseline Loss: 2.7862 | Actual Loss: 0.5661\n",
      "Baseline Loss: 2.8486 | Actual Loss: 1.1519\n",
      "Baseline Loss: 2.7576 | Actual Loss: 0.5370\n",
      "Baseline Loss: 2.8847 | Actual Loss: 0.4222\n",
      "Baseline Loss: 2.7550 | Actual Loss: 0.8491\n",
      "Baseline Loss: 2.7853 | Actual Loss: 0.5054\n",
      "Baseline Loss: 2.7592 | Actual Loss: 0.8023\n",
      "Baseline Loss: 2.8425 | Actual Loss: 0.7800\n",
      "Baseline Loss: 2.7935 | Actual Loss: 0.5758\n",
      "Baseline Loss: 2.9128 | Actual Loss: 0.8445\n",
      "Baseline Loss: 2.8503 | Actual Loss: 0.8682\n",
      "Baseline Loss: 2.8691 | Actual Loss: 0.7924\n",
      "Baseline Loss: 2.7927 | Actual Loss: 0.5222\n",
      "Baseline Loss: 2.8147 | Actual Loss: 0.7810\n",
      "Baseline Loss: 2.6170 | Actual Loss: 0.4195\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.6756\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.0221\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.8315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 12/1000 [00:07<10:25,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7244 | Actual Loss: 0.8570\n",
      "Epoch 12/1000: Train Loss: 0.6906, Val Loss: 0.8465\n",
      "Baseline Loss: 2.7811 | Actual Loss: 0.8971\n",
      "Baseline Loss: 2.7940 | Actual Loss: 0.7435\n",
      "Baseline Loss: 2.8464 | Actual Loss: 0.5451\n",
      "Baseline Loss: 2.8732 | Actual Loss: 0.4262\n",
      "Baseline Loss: 2.7964 | Actual Loss: 0.8732\n",
      "Baseline Loss: 2.8644 | Actual Loss: 0.9241\n",
      "Baseline Loss: 2.8480 | Actual Loss: 0.5851\n",
      "Baseline Loss: 2.8695 | Actual Loss: 0.5423\n",
      "Baseline Loss: 2.8065 | Actual Loss: 0.6099\n",
      "Baseline Loss: 2.8080 | Actual Loss: 0.6667\n",
      "Baseline Loss: 2.8184 | Actual Loss: 0.5836\n",
      "Baseline Loss: 2.7758 | Actual Loss: 0.3240\n",
      "Baseline Loss: 2.7997 | Actual Loss: 1.0179\n",
      "Baseline Loss: 2.8592 | Actual Loss: 0.2738\n",
      "Baseline Loss: 2.7719 | Actual Loss: 0.6404\n",
      "Baseline Loss: 2.4636 | Actual Loss: 0.5538\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.5549\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.0678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏         | 13/1000 [00:08<10:38,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8529 | Actual Loss: 0.8606\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.7379\n",
      "Epoch 13/1000: Train Loss: 0.6379, Val Loss: 0.8053\n",
      "New best validation loss: 0.8053\n",
      "Baseline Loss: 2.8200 | Actual Loss: 0.8865\n",
      "Baseline Loss: 2.7967 | Actual Loss: 0.3704\n",
      "Baseline Loss: 2.8257 | Actual Loss: 0.4973\n",
      "Baseline Loss: 2.8645 | Actual Loss: 0.4545\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.7817\n",
      "Baseline Loss: 2.7761 | Actual Loss: 0.4396\n",
      "Baseline Loss: 2.8774 | Actual Loss: 1.4113\n",
      "Baseline Loss: 2.8768 | Actual Loss: 0.4362\n",
      "Baseline Loss: 2.8250 | Actual Loss: 0.7279\n",
      "Baseline Loss: 2.8261 | Actual Loss: 0.6195\n",
      "Baseline Loss: 2.8414 | Actual Loss: 0.7036\n",
      "Baseline Loss: 2.8433 | Actual Loss: 0.8869\n",
      "Baseline Loss: 2.8337 | Actual Loss: 0.4126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏         | 14/1000 [00:08<10:49,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7950 | Actual Loss: 0.5223\n",
      "Baseline Loss: 2.7735 | Actual Loss: 0.5041\n",
      "Baseline Loss: 2.4000 | Actual Loss: 0.3439\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.6352\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.4444\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.5749\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.5136\n",
      "Epoch 14/1000: Train Loss: 0.6249, Val Loss: 0.7920\n",
      "New best validation loss: 0.7920\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.6827\n",
      "Baseline Loss: 2.8067 | Actual Loss: 0.5033\n",
      "Baseline Loss: 2.7653 | Actual Loss: 1.3916\n",
      "Baseline Loss: 2.8784 | Actual Loss: 0.4681\n",
      "Baseline Loss: 2.7631 | Actual Loss: 0.5781\n",
      "Baseline Loss: 2.8715 | Actual Loss: 0.7956\n",
      "Baseline Loss: 2.8573 | Actual Loss: 0.9268\n",
      "Baseline Loss: 2.8369 | Actual Loss: 0.6738\n",
      "Baseline Loss: 2.7625 | Actual Loss: 1.0864\n",
      "Baseline Loss: 2.8524 | Actual Loss: 1.0145\n",
      "Baseline Loss: 2.8425 | Actual Loss: 0.3379\n",
      "Baseline Loss: 2.7812 | Actual Loss: 0.3533\n",
      "Baseline Loss: 2.7374 | Actual Loss: 0.4486\n",
      "Baseline Loss: 2.8255 | Actual Loss: 0.4829\n",
      "Baseline Loss: 2.8213 | Actual Loss: 0.4568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 15/1000 [00:09<10:30,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5364 | Actual Loss: 0.4531\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.6233\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.7790\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.6057\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.5968\n",
      "Epoch 15/1000: Train Loss: 0.6658, Val Loss: 0.9012\n",
      "Baseline Loss: 2.8092 | Actual Loss: 0.3412\n",
      "Baseline Loss: 2.7721 | Actual Loss: 0.7215\n",
      "Baseline Loss: 2.8349 | Actual Loss: 0.5850\n",
      "Baseline Loss: 2.7731 | Actual Loss: 0.3909\n",
      "Baseline Loss: 2.8440 | Actual Loss: 0.5713\n",
      "Baseline Loss: 2.8182 | Actual Loss: 0.5854\n",
      "Baseline Loss: 2.8205 | Actual Loss: 0.4522\n",
      "Baseline Loss: 2.8170 | Actual Loss: 0.5469\n",
      "Baseline Loss: 2.8183 | Actual Loss: 0.9595\n",
      "Baseline Loss: 2.8675 | Actual Loss: 0.3089\n",
      "Baseline Loss: 2.8080 | Actual Loss: 0.7744\n",
      "Baseline Loss: 2.8281 | Actual Loss: 0.5285\n",
      "Baseline Loss: 2.8064 | Actual Loss: 0.5153\n",
      "Baseline Loss: 2.7759 | Actual Loss: 0.6321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 16/1000 [00:10<10:39,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8472 | Actual Loss: 0.4698\n",
      "Baseline Loss: 2.4474 | Actual Loss: 0.6910\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.7504\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.9849\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.4671\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.5829\n",
      "Epoch 16/1000: Train Loss: 0.5671, Val Loss: 0.9463\n",
      "Baseline Loss: 2.9387 | Actual Loss: 0.3134\n",
      "Baseline Loss: 2.8017 | Actual Loss: 0.6378\n",
      "Baseline Loss: 2.7919 | Actual Loss: 0.8553\n",
      "Baseline Loss: 2.8346 | Actual Loss: 0.3719\n",
      "Baseline Loss: 2.7790 | Actual Loss: 0.4951\n",
      "Baseline Loss: 2.8402 | Actual Loss: 1.3016\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5118\n",
      "Baseline Loss: 2.8225 | Actual Loss: 0.4639\n",
      "Baseline Loss: 2.8695 | Actual Loss: 0.4621\n",
      "Baseline Loss: 2.8385 | Actual Loss: 1.7284\n",
      "Baseline Loss: 2.8168 | Actual Loss: 0.4365\n",
      "Baseline Loss: 2.8172 | Actual Loss: 0.3404\n",
      "Baseline Loss: 2.8421 | Actual Loss: 0.3923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 17/1000 [00:10<10:29,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8022 | Actual Loss: 0.7677\n",
      "Baseline Loss: 2.8119 | Actual Loss: 0.5787\n",
      "Baseline Loss: 2.5499 | Actual Loss: 1.7547\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.5042\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.6880\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.6089\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.5058\n",
      "Epoch 17/1000: Train Loss: 0.7132, Val Loss: 0.8267\n",
      "Baseline Loss: 2.9114 | Actual Loss: 0.5453\n",
      "Baseline Loss: 2.8311 | Actual Loss: 0.4655\n",
      "Baseline Loss: 2.8226 | Actual Loss: 0.3131\n",
      "Baseline Loss: 2.8423 | Actual Loss: 0.7973\n",
      "Baseline Loss: 2.8374 | Actual Loss: 0.1743\n",
      "Baseline Loss: 2.7718 | Actual Loss: 0.6344\n",
      "Baseline Loss: 2.8249 | Actual Loss: 0.5295\n",
      "Baseline Loss: 2.8376 | Actual Loss: 0.4787\n",
      "Baseline Loss: 2.8393 | Actual Loss: 1.2150\n",
      "Baseline Loss: 2.7666 | Actual Loss: 0.6674\n",
      "Baseline Loss: 2.8685 | Actual Loss: 0.4892\n",
      "Baseline Loss: 2.7958 | Actual Loss: 0.4580\n",
      "Baseline Loss: 2.7777 | Actual Loss: 0.1874\n",
      "Baseline Loss: 2.8283 | Actual Loss: 0.6200\n",
      "Baseline Loss: 2.7690 | Actual Loss: 0.4253\n",
      "Baseline Loss: 2.5294 | Actual Loss: 0.5605\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.4313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 18/1000 [00:11<10:20,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8053 | Actual Loss: 1.0518\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.6063\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.4818\n",
      "Epoch 18/1000: Train Loss: 0.5351, Val Loss: 0.6428\n",
      "New best validation loss: 0.6428\n",
      "Baseline Loss: 2.8244 | Actual Loss: 0.4492\n",
      "Baseline Loss: 2.7499 | Actual Loss: 0.3845\n",
      "Baseline Loss: 2.8396 | Actual Loss: 0.6731\n",
      "Baseline Loss: 2.8146 | Actual Loss: 0.4114\n",
      "Baseline Loss: 2.8375 | Actual Loss: 0.2584\n",
      "Baseline Loss: 2.7790 | Actual Loss: 0.8075\n",
      "Baseline Loss: 2.8526 | Actual Loss: 0.5559\n",
      "Baseline Loss: 2.9072 | Actual Loss: 0.8267\n",
      "Baseline Loss: 2.8414 | Actual Loss: 0.5294\n",
      "Baseline Loss: 2.7956 | Actual Loss: 0.7979\n",
      "Baseline Loss: 2.8111 | Actual Loss: 0.5999\n",
      "Baseline Loss: 2.7885 | Actual Loss: 0.4153\n",
      "Baseline Loss: 2.8053 | Actual Loss: 0.5850\n",
      "Baseline Loss: 2.8425 | Actual Loss: 0.3364\n",
      "Baseline Loss: 2.7966 | Actual Loss: 0.5931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 19/1000 [00:12<10:39,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6038 | Actual Loss: 0.4391\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.3984\n",
      "Baseline Loss: 2.8053 | Actual Loss: 0.9295\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.6155\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.5757\n",
      "Epoch 19/1000: Train Loss: 0.5414, Val Loss: 0.6298\n",
      "New best validation loss: 0.6298\n",
      "Baseline Loss: 2.8852 | Actual Loss: 0.4721\n",
      "Baseline Loss: 2.8172 | Actual Loss: 0.4927\n",
      "Baseline Loss: 2.7909 | Actual Loss: 0.2053\n",
      "Baseline Loss: 2.7710 | Actual Loss: 0.1675\n",
      "Baseline Loss: 2.9382 | Actual Loss: 0.7941\n",
      "Baseline Loss: 2.8317 | Actual Loss: 0.3936\n",
      "Baseline Loss: 2.7806 | Actual Loss: 0.4808\n",
      "Baseline Loss: 2.8510 | Actual Loss: 0.5136\n",
      "Baseline Loss: 2.7811 | Actual Loss: 0.2568\n",
      "Baseline Loss: 2.8110 | Actual Loss: 0.9620\n",
      "Baseline Loss: 2.8338 | Actual Loss: 0.3449\n",
      "Baseline Loss: 2.7798 | Actual Loss: 0.6890\n",
      "Baseline Loss: 2.8085 | Actual Loss: 0.4686\n",
      "Baseline Loss: 2.8482 | Actual Loss: 0.3188\n",
      "Baseline Loss: 2.7801 | Actual Loss: 0.7141\n",
      "Baseline Loss: 2.4131 | Actual Loss: 0.1374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 20/1000 [00:12<10:10,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9000 | Actual Loss: 0.2836\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.1145\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.5821\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.5699\n",
      "Epoch 20/1000: Train Loss: 0.4632, Val Loss: 0.6375\n",
      "Baseline Loss: 2.7774 | Actual Loss: 0.9089\n",
      "Baseline Loss: 2.8458 | Actual Loss: 0.3759\n",
      "Baseline Loss: 2.7923 | Actual Loss: 0.5397\n",
      "Baseline Loss: 2.8765 | Actual Loss: 0.3980\n",
      "Baseline Loss: 2.8159 | Actual Loss: 0.1664\n",
      "Baseline Loss: 2.8821 | Actual Loss: 0.2698\n",
      "Baseline Loss: 2.7955 | Actual Loss: 0.5234\n",
      "Baseline Loss: 2.8513 | Actual Loss: 0.3958\n",
      "Baseline Loss: 2.7965 | Actual Loss: 0.4712\n",
      "Baseline Loss: 2.8019 | Actual Loss: 0.6842\n",
      "Baseline Loss: 2.8251 | Actual Loss: 0.6361\n",
      "Baseline Loss: 2.7933 | Actual Loss: 0.2955\n",
      "Baseline Loss: 2.7924 | Actual Loss: 0.7002\n",
      "Baseline Loss: 2.8135 | Actual Loss: 0.8765\n",
      "Baseline Loss: 2.8438 | Actual Loss: 0.4077\n",
      "Baseline Loss: 2.4431 | Actual Loss: 0.1709\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.3160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 21/1000 [00:13<10:25,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8053 | Actual Loss: 1.1821\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.6723\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.4536\n",
      "Epoch 21/1000: Train Loss: 0.4888, Val Loss: 0.6560\n",
      "Baseline Loss: 2.8185 | Actual Loss: 0.6456\n",
      "Baseline Loss: 2.7413 | Actual Loss: 0.4486\n",
      "Baseline Loss: 2.8777 | Actual Loss: 1.6728\n",
      "Baseline Loss: 2.8133 | Actual Loss: 0.5629\n",
      "Baseline Loss: 2.8885 | Actual Loss: 0.5502\n",
      "Baseline Loss: 2.8349 | Actual Loss: 1.1893\n",
      "Baseline Loss: 2.7430 | Actual Loss: 0.2278\n",
      "Baseline Loss: 2.8425 | Actual Loss: 0.3407\n",
      "Baseline Loss: 2.7564 | Actual Loss: 0.5732\n",
      "Baseline Loss: 2.8275 | Actual Loss: 0.2321\n",
      "Baseline Loss: 2.8110 | Actual Loss: 0.4027\n",
      "Baseline Loss: 2.8678 | Actual Loss: 2.3673\n",
      "Baseline Loss: 2.8750 | Actual Loss: 0.8920\n",
      "Baseline Loss: 2.8086 | Actual Loss: 0.1893\n",
      "Baseline Loss: 2.7810 | Actual Loss: 1.6260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 22/1000 [00:14<10:43,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5033 | Actual Loss: 0.4747\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.3566\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.0535\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.5616\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.3958\n",
      "Epoch 22/1000: Train Loss: 0.7747, Val Loss: 0.5919\n",
      "New best validation loss: 0.5919\n",
      "Baseline Loss: 2.8798 | Actual Loss: 0.4395\n",
      "Baseline Loss: 2.7806 | Actual Loss: 0.6586\n",
      "Baseline Loss: 2.7563 | Actual Loss: 0.5808\n",
      "Baseline Loss: 2.7927 | Actual Loss: 0.6136\n",
      "Baseline Loss: 2.8138 | Actual Loss: 0.6466\n",
      "Baseline Loss: 2.8192 | Actual Loss: 0.7991\n",
      "Baseline Loss: 2.9006 | Actual Loss: 0.7251\n",
      "Baseline Loss: 2.7957 | Actual Loss: 0.2999\n",
      "Baseline Loss: 2.8434 | Actual Loss: 1.4896\n",
      "Baseline Loss: 2.8211 | Actual Loss: 1.3546\n",
      "Baseline Loss: 2.7996 | Actual Loss: 0.3087\n",
      "Baseline Loss: 2.8539 | Actual Loss: 0.3340\n",
      "Baseline Loss: 2.8501 | Actual Loss: 0.4072\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.5546\n",
      "Baseline Loss: 2.8680 | Actual Loss: 0.3919\n",
      "Baseline Loss: 2.4901 | Actual Loss: 0.1234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 23/1000 [00:14<10:46,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9000 | Actual Loss: 0.4669\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.0427\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.6872\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.5761\n",
      "Epoch 23/1000: Train Loss: 0.6080, Val Loss: 0.6932\n",
      "Baseline Loss: 2.7891 | Actual Loss: 0.2888\n",
      "Baseline Loss: 2.7827 | Actual Loss: 0.8702\n",
      "Baseline Loss: 2.7860 | Actual Loss: 0.3232\n",
      "Baseline Loss: 2.9022 | Actual Loss: 0.3685\n",
      "Baseline Loss: 2.8219 | Actual Loss: 0.3811\n",
      "Baseline Loss: 2.9185 | Actual Loss: 0.1570\n",
      "Baseline Loss: 2.8552 | Actual Loss: 0.6037\n",
      "Baseline Loss: 2.8053 | Actual Loss: 0.6796\n",
      "Baseline Loss: 2.7926 | Actual Loss: 0.4973\n",
      "Baseline Loss: 2.7625 | Actual Loss: 0.2197\n",
      "Baseline Loss: 2.7915 | Actual Loss: 1.3997\n",
      "Baseline Loss: 2.8398 | Actual Loss: 0.4726\n",
      "Baseline Loss: 2.8524 | Actual Loss: 0.3547\n",
      "Baseline Loss: 2.8380 | Actual Loss: 0.3459\n",
      "Baseline Loss: 2.8719 | Actual Loss: 0.4512\n",
      "Baseline Loss: 2.5259 | Actual Loss: 0.1473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 24/1000 [00:15<10:24,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9000 | Actual Loss: 0.5778\n",
      "Baseline Loss: 2.8053 | Actual Loss: 2.4801\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.4127\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.5123\n",
      "Epoch 24/1000: Train Loss: 0.4725, Val Loss: 0.9957\n",
      "Baseline Loss: 2.8406 | Actual Loss: 0.8010\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.3683\n",
      "Baseline Loss: 2.8152 | Actual Loss: 0.4660\n",
      "Baseline Loss: 2.7916 | Actual Loss: 1.8884\n",
      "Baseline Loss: 2.8333 | Actual Loss: 0.2808\n",
      "Baseline Loss: 2.7809 | Actual Loss: 2.3022\n",
      "Baseline Loss: 2.8473 | Actual Loss: 0.7106\n",
      "Baseline Loss: 2.8671 | Actual Loss: 1.4767\n",
      "Baseline Loss: 2.8719 | Actual Loss: 0.7459\n",
      "Baseline Loss: 2.8222 | Actual Loss: 0.7312\n",
      "Baseline Loss: 2.8160 | Actual Loss: 0.4398\n",
      "Baseline Loss: 2.8069 | Actual Loss: 0.2461\n",
      "Baseline Loss: 2.8116 | Actual Loss: 0.5121\n",
      "Baseline Loss: 2.7683 | Actual Loss: 0.9541\n",
      "Baseline Loss: 2.8215 | Actual Loss: 0.5168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▎         | 25/1000 [00:16<10:34,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5164 | Actual Loss: 0.2536\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.4004\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.0903\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.8408\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.5487\n",
      "Epoch 25/1000: Train Loss: 0.7933, Val Loss: 0.7200\n",
      "Baseline Loss: 2.8154 | Actual Loss: 0.5738\n",
      "Baseline Loss: 2.8428 | Actual Loss: 0.3326\n",
      "Baseline Loss: 2.8568 | Actual Loss: 0.4652\n",
      "Baseline Loss: 2.7978 | Actual Loss: 0.3301\n",
      "Baseline Loss: 2.8668 | Actual Loss: 0.3159\n",
      "Baseline Loss: 2.8747 | Actual Loss: 0.4130\n",
      "Baseline Loss: 2.7888 | Actual Loss: 2.4943\n",
      "Baseline Loss: 2.7962 | Actual Loss: 2.2893\n",
      "Baseline Loss: 2.8540 | Actual Loss: 2.2494\n",
      "Baseline Loss: 2.7959 | Actual Loss: 1.0456\n",
      "Baseline Loss: 2.8852 | Actual Loss: 1.5854\n",
      "Baseline Loss: 2.8598 | Actual Loss: 1.6107\n",
      "Baseline Loss: 2.8306 | Actual Loss: 1.2439\n",
      "Baseline Loss: 2.7893 | Actual Loss: 0.4781\n",
      "Baseline Loss: 2.8018 | Actual Loss: 1.1866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 26/1000 [00:16<10:21,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5045 | Actual Loss: 1.3678\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.5764\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.0890\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.7103\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.6725\n",
      "Epoch 26/1000: Train Loss: 1.1239, Val Loss: 0.7621\n",
      "Baseline Loss: 2.8190 | Actual Loss: 0.6265\n",
      "Baseline Loss: 2.8332 | Actual Loss: 0.5478\n",
      "Baseline Loss: 2.9013 | Actual Loss: 0.3841\n",
      "Baseline Loss: 2.8791 | Actual Loss: 1.6412\n",
      "Baseline Loss: 2.7842 | Actual Loss: 0.6915\n",
      "Baseline Loss: 2.7803 | Actual Loss: 1.0870\n",
      "Baseline Loss: 2.8373 | Actual Loss: 0.5288\n",
      "Baseline Loss: 2.8658 | Actual Loss: 0.5808\n",
      "Baseline Loss: 2.8182 | Actual Loss: 0.4074\n",
      "Baseline Loss: 2.7779 | Actual Loss: 0.3874\n",
      "Baseline Loss: 2.8317 | Actual Loss: 0.7356\n",
      "Baseline Loss: 2.8830 | Actual Loss: 0.7386\n",
      "Baseline Loss: 2.7936 | Actual Loss: 0.2751\n",
      "Baseline Loss: 2.7866 | Actual Loss: 0.4808\n",
      "Baseline Loss: 2.7429 | Actual Loss: 1.1300\n",
      "Baseline Loss: 2.5427 | Actual Loss: 0.2032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 27/1000 [00:17<10:23,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9000 | Actual Loss: 0.3936\n",
      "Baseline Loss: 2.8053 | Actual Loss: 0.9328\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.7113\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.5572\n",
      "Epoch 27/1000: Train Loss: 0.6529, Val Loss: 0.6487\n",
      "Baseline Loss: 2.9456 | Actual Loss: 0.7900\n",
      "Baseline Loss: 2.8400 | Actual Loss: 0.5638\n",
      "Baseline Loss: 2.8083 | Actual Loss: 0.7382\n",
      "Baseline Loss: 2.8558 | Actual Loss: 0.5354\n",
      "Baseline Loss: 2.8102 | Actual Loss: 0.4672\n",
      "Baseline Loss: 2.7513 | Actual Loss: 0.5813\n",
      "Baseline Loss: 2.8705 | Actual Loss: 0.3400\n",
      "Baseline Loss: 2.8203 | Actual Loss: 0.3971\n",
      "Baseline Loss: 2.8312 | Actual Loss: 0.1293\n",
      "Baseline Loss: 2.8160 | Actual Loss: 0.3147\n",
      "Baseline Loss: 2.8524 | Actual Loss: 0.4868\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.3702\n",
      "Baseline Loss: 2.7880 | Actual Loss: 0.7044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 28/1000 [00:17<10:48,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7987 | Actual Loss: 0.2747\n",
      "Baseline Loss: 2.7794 | Actual Loss: 0.5900\n",
      "Baseline Loss: 2.4928 | Actual Loss: 1.4898\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.3539\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.0413\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.5240\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.4059\n",
      "Epoch 28/1000: Train Loss: 0.5483, Val Loss: 0.5813\n",
      "New best validation loss: 0.5813\n",
      "Baseline Loss: 2.8244 | Actual Loss: 0.5971\n",
      "Baseline Loss: 2.8590 | Actual Loss: 0.4284\n",
      "Baseline Loss: 2.7895 | Actual Loss: 1.9843\n",
      "Baseline Loss: 2.7939 | Actual Loss: 0.5571\n",
      "Baseline Loss: 2.8006 | Actual Loss: 0.2682\n",
      "Baseline Loss: 2.7927 | Actual Loss: 0.5254\n",
      "Baseline Loss: 2.8374 | Actual Loss: 0.6407\n",
      "Baseline Loss: 2.8009 | Actual Loss: 0.4400\n",
      "Baseline Loss: 2.7749 | Actual Loss: 0.6596\n",
      "Baseline Loss: 2.9275 | Actual Loss: 0.4320\n",
      "Baseline Loss: 2.7843 | Actual Loss: 0.8679\n",
      "Baseline Loss: 2.9446 | Actual Loss: 0.3078\n",
      "Baseline Loss: 2.8265 | Actual Loss: 0.3719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 29/1000 [00:18<10:27,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8421 | Actual Loss: 0.4997\n",
      "Baseline Loss: 2.8638 | Actual Loss: 0.5617\n",
      "Baseline Loss: 2.4422 | Actual Loss: 0.3965\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.6283\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.9673\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.7111\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.4461\n",
      "Epoch 29/1000: Train Loss: 0.5961, Val Loss: 0.9382\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.3692\n",
      "Baseline Loss: 2.8024 | Actual Loss: 1.3099\n",
      "Baseline Loss: 2.8194 | Actual Loss: 0.1549\n",
      "Baseline Loss: 2.8506 | Actual Loss: 0.6295\n",
      "Baseline Loss: 2.7592 | Actual Loss: 0.3811\n",
      "Baseline Loss: 2.7854 | Actual Loss: 0.6032\n",
      "Baseline Loss: 2.8653 | Actual Loss: 0.4351\n",
      "Baseline Loss: 2.7810 | Actual Loss: 0.3276\n",
      "Baseline Loss: 2.8988 | Actual Loss: 0.3389\n",
      "Baseline Loss: 2.8042 | Actual Loss: 0.3376\n",
      "Baseline Loss: 2.7916 | Actual Loss: 0.5363\n",
      "Baseline Loss: 2.7875 | Actual Loss: 0.2775\n",
      "Baseline Loss: 2.8082 | Actual Loss: 0.5047\n",
      "Baseline Loss: 2.7921 | Actual Loss: 0.8824\n",
      "Baseline Loss: 2.8169 | Actual Loss: 0.3675\n",
      "Baseline Loss: 2.6863 | Actual Loss: 0.7075\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.3129\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.0017\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.5193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 30/1000 [00:19<10:30,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7244 | Actual Loss: 0.4683\n",
      "Epoch 30/1000: Train Loss: 0.5102, Val Loss: 0.5755\n",
      "New best validation loss: 0.5755\n",
      "Baseline Loss: 2.8626 | Actual Loss: 0.2242\n",
      "Baseline Loss: 2.7939 | Actual Loss: 0.5067\n",
      "Baseline Loss: 2.8151 | Actual Loss: 0.4079\n",
      "Baseline Loss: 2.9213 | Actual Loss: 0.6198\n",
      "Baseline Loss: 2.8256 | Actual Loss: 0.3512\n",
      "Baseline Loss: 2.8129 | Actual Loss: 0.4046\n",
      "Baseline Loss: 2.7117 | Actual Loss: 0.3506\n",
      "Baseline Loss: 2.8433 | Actual Loss: 0.4334\n",
      "Baseline Loss: 2.8110 | Actual Loss: 0.2149\n",
      "Baseline Loss: 2.7389 | Actual Loss: 0.9224\n",
      "Baseline Loss: 2.8281 | Actual Loss: 0.4299\n",
      "Baseline Loss: 2.8171 | Actual Loss: 0.3123\n",
      "Baseline Loss: 2.8111 | Actual Loss: 0.7815\n",
      "Baseline Loss: 2.8869 | Actual Loss: 1.5822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 31/1000 [00:19<10:23,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8573 | Actual Loss: 0.5663\n",
      "Baseline Loss: 2.4530 | Actual Loss: 0.3681\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.5374\n",
      "Baseline Loss: 2.8053 | Actual Loss: 0.9481\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.7534\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.4849\n",
      "Epoch 31/1000: Train Loss: 0.5297, Val Loss: 0.6810\n",
      "Baseline Loss: 2.8086 | Actual Loss: 0.9249\n",
      "Baseline Loss: 2.7782 | Actual Loss: 0.3915\n",
      "Baseline Loss: 2.8048 | Actual Loss: 0.8703\n",
      "Baseline Loss: 2.8171 | Actual Loss: 0.7730\n",
      "Baseline Loss: 2.8034 | Actual Loss: 0.8174\n",
      "Baseline Loss: 2.8384 | Actual Loss: 0.4220\n",
      "Baseline Loss: 2.8626 | Actual Loss: 0.6317\n",
      "Baseline Loss: 2.7774 | Actual Loss: 0.6277\n",
      "Baseline Loss: 2.8564 | Actual Loss: 0.3553\n",
      "Baseline Loss: 2.7895 | Actual Loss: 0.5315\n",
      "Baseline Loss: 2.8214 | Actual Loss: 0.6168\n",
      "Baseline Loss: 2.8127 | Actual Loss: 0.2253\n",
      "Baseline Loss: 2.7948 | Actual Loss: 0.1774\n",
      "Baseline Loss: 2.8526 | Actual Loss: 0.9014\n",
      "Baseline Loss: 2.8119 | Actual Loss: 0.7959\n",
      "Baseline Loss: 2.6031 | Actual Loss: 0.2487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 32/1000 [00:20<10:12,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9000 | Actual Loss: 0.5432\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.2633\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.4899\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.4601\n",
      "Epoch 32/1000: Train Loss: 0.5819, Val Loss: 0.6891\n",
      "Baseline Loss: 2.7906 | Actual Loss: 0.2620\n",
      "Baseline Loss: 2.8307 | Actual Loss: 0.4404\n",
      "Baseline Loss: 2.8497 | Actual Loss: 0.5675\n",
      "Baseline Loss: 2.8343 | Actual Loss: 0.3716\n",
      "Baseline Loss: 2.8463 | Actual Loss: 1.8390\n",
      "Baseline Loss: 2.7731 | Actual Loss: 0.3288\n",
      "Baseline Loss: 2.7718 | Actual Loss: 0.4833\n",
      "Baseline Loss: 2.8281 | Actual Loss: 0.3760\n",
      "Baseline Loss: 2.8689 | Actual Loss: 0.0843\n",
      "Baseline Loss: 2.8052 | Actual Loss: 0.2281\n",
      "Baseline Loss: 2.8162 | Actual Loss: 0.6366\n",
      "Baseline Loss: 2.8050 | Actual Loss: 0.6992\n",
      "Baseline Loss: 2.8643 | Actual Loss: 0.4474\n",
      "Baseline Loss: 2.7799 | Actual Loss: 0.1935\n",
      "Baseline Loss: 2.7796 | Actual Loss: 0.3804\n",
      "Baseline Loss: 2.6070 | Actual Loss: 0.3307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 33/1000 [00:21<10:19,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9000 | Actual Loss: 0.3405\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.0725\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.5493\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.4888\n",
      "Epoch 33/1000: Train Loss: 0.4793, Val Loss: 0.6127\n",
      "Baseline Loss: 2.7964 | Actual Loss: 0.2769\n",
      "Baseline Loss: 2.7671 | Actual Loss: 0.2062\n",
      "Baseline Loss: 2.8306 | Actual Loss: 1.4845\n",
      "Baseline Loss: 2.8530 | Actual Loss: 0.4760\n",
      "Baseline Loss: 2.7860 | Actual Loss: 0.4144\n",
      "Baseline Loss: 2.8496 | Actual Loss: 0.3027\n",
      "Baseline Loss: 2.7971 | Actual Loss: 0.2159\n",
      "Baseline Loss: 2.8701 | Actual Loss: 0.7562\n",
      "Baseline Loss: 2.7928 | Actual Loss: 0.5369\n",
      "Baseline Loss: 2.8753 | Actual Loss: 0.2433\n",
      "Baseline Loss: 2.8032 | Actual Loss: 0.2348\n",
      "Baseline Loss: 2.8024 | Actual Loss: 0.4331\n",
      "Baseline Loss: 2.7576 | Actual Loss: 0.2338\n",
      "Baseline Loss: 2.7931 | Actual Loss: 1.3368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 34/1000 [00:21<10:31,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8605 | Actual Loss: 2.0234\n",
      "Baseline Loss: 2.5868 | Actual Loss: 0.7203\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.7022\n",
      "Baseline Loss: 2.8053 | Actual Loss: 2.5084\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.5050\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.5757\n",
      "Epoch 34/1000: Train Loss: 0.6184, Val Loss: 1.0728\n",
      "Baseline Loss: 2.8664 | Actual Loss: 2.2280\n",
      "Baseline Loss: 2.8504 | Actual Loss: 2.1433\n",
      "Baseline Loss: 2.8111 | Actual Loss: 1.5358\n",
      "Baseline Loss: 2.8920 | Actual Loss: 0.7192\n",
      "Baseline Loss: 2.8061 | Actual Loss: 1.6890\n",
      "Baseline Loss: 2.7743 | Actual Loss: 0.2198\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.9460\n",
      "Baseline Loss: 2.8218 | Actual Loss: 0.3999\n",
      "Baseline Loss: 2.7599 | Actual Loss: 0.4611\n",
      "Baseline Loss: 2.8010 | Actual Loss: 0.6416\n",
      "Baseline Loss: 2.7780 | Actual Loss: 0.4399\n",
      "Baseline Loss: 2.8475 | Actual Loss: 0.3609\n",
      "Baseline Loss: 2.8034 | Actual Loss: 0.4652\n",
      "Baseline Loss: 2.7892 | Actual Loss: 0.5968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 35/1000 [00:22<10:18,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7834 | Actual Loss: 0.4938\n",
      "Baseline Loss: 2.6597 | Actual Loss: 0.1504\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.5723\n",
      "Baseline Loss: 2.8053 | Actual Loss: 0.9672\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.5991\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.4736\n",
      "Epoch 35/1000: Train Loss: 0.8432, Val Loss: 0.6531\n",
      "Baseline Loss: 2.7239 | Actual Loss: 0.3511\n",
      "Baseline Loss: 2.8331 | Actual Loss: 0.4892\n",
      "Baseline Loss: 2.8656 | Actual Loss: 0.8204\n",
      "Baseline Loss: 2.7447 | Actual Loss: 0.7564\n",
      "Baseline Loss: 2.7911 | Actual Loss: 0.4705\n",
      "Baseline Loss: 2.8260 | Actual Loss: 0.4884\n",
      "Baseline Loss: 2.8330 | Actual Loss: 0.6520\n",
      "Baseline Loss: 2.8713 | Actual Loss: 0.4120\n",
      "Baseline Loss: 2.8154 | Actual Loss: 0.6230\n",
      "Baseline Loss: 2.8722 | Actual Loss: 0.5081\n",
      "Baseline Loss: 2.8271 | Actual Loss: 0.6493\n",
      "Baseline Loss: 2.7427 | Actual Loss: 0.4948\n",
      "Baseline Loss: 2.8586 | Actual Loss: 0.3408\n",
      "Baseline Loss: 2.8536 | Actual Loss: 0.2547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 36/1000 [00:23<10:20,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8951 | Actual Loss: 0.2797\n",
      "Baseline Loss: 2.5720 | Actual Loss: 0.3013\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.3657\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.0020\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.5326\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.4358\n",
      "Epoch 36/1000: Train Loss: 0.4932, Val Loss: 0.5840\n",
      "Baseline Loss: 2.7817 | Actual Loss: 0.3366\n",
      "Baseline Loss: 2.8861 | Actual Loss: 0.9028\n",
      "Baseline Loss: 2.8358 | Actual Loss: 0.5127\n",
      "Baseline Loss: 2.7409 | Actual Loss: 0.8105\n",
      "Baseline Loss: 2.8770 | Actual Loss: 0.4804\n",
      "Baseline Loss: 2.7724 | Actual Loss: 0.4099\n",
      "Baseline Loss: 2.7792 | Actual Loss: 0.4867\n",
      "Baseline Loss: 2.7924 | Actual Loss: 0.2844\n",
      "Baseline Loss: 2.8284 | Actual Loss: 0.4560\n",
      "Baseline Loss: 2.8595 | Actual Loss: 0.2138\n",
      "Baseline Loss: 2.8829 | Actual Loss: 0.1775\n",
      "Baseline Loss: 2.8090 | Actual Loss: 1.0412\n",
      "Baseline Loss: 2.7896 | Actual Loss: 0.2587\n",
      "Baseline Loss: 2.7472 | Actual Loss: 0.4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 37/1000 [00:23<10:22,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8408 | Actual Loss: 0.3403\n",
      "Baseline Loss: 2.5058 | Actual Loss: 0.3573\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.5375\n",
      "Baseline Loss: 2.8053 | Actual Loss: 2.4878\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.6106\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.3948\n",
      "Epoch 37/1000: Train Loss: 0.4668, Val Loss: 1.0077\n",
      "Baseline Loss: 2.7657 | Actual Loss: 0.2970\n",
      "Baseline Loss: 2.8151 | Actual Loss: 1.0341\n",
      "Baseline Loss: 2.8154 | Actual Loss: 0.3409\n",
      "Baseline Loss: 2.8112 | Actual Loss: 1.1359\n",
      "Baseline Loss: 2.8705 | Actual Loss: 1.1914\n",
      "Baseline Loss: 2.8874 | Actual Loss: 0.3078\n",
      "Baseline Loss: 2.8032 | Actual Loss: 0.2708\n",
      "Baseline Loss: 2.8217 | Actual Loss: 0.5197\n",
      "Baseline Loss: 2.8001 | Actual Loss: 0.5755\n",
      "Baseline Loss: 2.8524 | Actual Loss: 0.3049\n",
      "Baseline Loss: 2.7906 | Actual Loss: 0.5021\n",
      "Baseline Loss: 2.8431 | Actual Loss: 0.2655\n",
      "Baseline Loss: 2.9206 | Actual Loss: 0.4301\n",
      "Baseline Loss: 2.8013 | Actual Loss: 0.3474\n",
      "Baseline Loss: 2.8281 | Actual Loss: 0.8521\n",
      "Baseline Loss: 2.6159 | Actual Loss: 0.2832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 38/1000 [00:24<10:11,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9000 | Actual Loss: 0.4310\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.8630\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.5943\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.4552\n",
      "Epoch 38/1000: Train Loss: 0.5412, Val Loss: 0.8359\n",
      "Baseline Loss: 2.8813 | Actual Loss: 0.4973\n",
      "Baseline Loss: 2.7767 | Actual Loss: 0.3103\n",
      "Baseline Loss: 2.7629 | Actual Loss: 0.3159\n",
      "Baseline Loss: 2.8122 | Actual Loss: 0.8295\n",
      "Baseline Loss: 2.8555 | Actual Loss: 0.2470\n",
      "Baseline Loss: 2.7889 | Actual Loss: 0.1108\n",
      "Baseline Loss: 2.8088 | Actual Loss: 0.9118\n",
      "Baseline Loss: 2.8351 | Actual Loss: 0.1704\n",
      "Baseline Loss: 2.8092 | Actual Loss: 0.1630\n",
      "Baseline Loss: 2.7633 | Actual Loss: 0.2645\n",
      "Baseline Loss: 2.8048 | Actual Loss: 0.5076\n",
      "Baseline Loss: 2.9108 | Actual Loss: 0.4374\n",
      "Baseline Loss: 2.8375 | Actual Loss: 0.4870\n",
      "Baseline Loss: 2.8452 | Actual Loss: 0.6832\n",
      "Baseline Loss: 2.7642 | Actual Loss: 2.1564\n",
      "Baseline Loss: 2.5064 | Actual Loss: 0.3420\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.5183\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.3398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 39/1000 [00:25<10:19,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8529 | Actual Loss: 0.3824\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.4520\n",
      "Epoch 39/1000: Train Loss: 0.5271, Val Loss: 0.6731\n",
      "Baseline Loss: 2.7937 | Actual Loss: 0.2879\n",
      "Baseline Loss: 2.7698 | Actual Loss: 0.3474\n",
      "Baseline Loss: 2.8816 | Actual Loss: 0.2784\n",
      "Baseline Loss: 2.7875 | Actual Loss: 0.2920\n",
      "Baseline Loss: 2.8483 | Actual Loss: 0.8262\n",
      "Baseline Loss: 2.8987 | Actual Loss: 0.2096\n",
      "Baseline Loss: 2.8569 | Actual Loss: 0.2140\n",
      "Baseline Loss: 2.7964 | Actual Loss: 0.2207\n",
      "Baseline Loss: 2.7852 | Actual Loss: 0.5312\n",
      "Baseline Loss: 2.8701 | Actual Loss: 1.2405\n",
      "Baseline Loss: 2.8405 | Actual Loss: 0.1945\n",
      "Baseline Loss: 2.7849 | Actual Loss: 0.3484\n",
      "Baseline Loss: 2.8202 | Actual Loss: 0.1888\n",
      "Baseline Loss: 2.8215 | Actual Loss: 0.5821\n",
      "Baseline Loss: 2.7794 | Actual Loss: 0.7579\n",
      "Baseline Loss: 2.5677 | Actual Loss: 0.4138\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.3577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 40/1000 [00:25<10:30,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8053 | Actual Loss: 0.9211\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.5690\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.5892\n",
      "Epoch 40/1000: Train Loss: 0.4333, Val Loss: 0.6093\n",
      "Baseline Loss: 2.9017 | Actual Loss: 1.0373\n",
      "Baseline Loss: 2.7506 | Actual Loss: 0.7684\n",
      "Baseline Loss: 2.8159 | Actual Loss: 0.5079\n",
      "Baseline Loss: 2.8357 | Actual Loss: 0.4750\n",
      "Baseline Loss: 2.8174 | Actual Loss: 0.2752\n",
      "Baseline Loss: 2.8726 | Actual Loss: 0.5504\n",
      "Baseline Loss: 2.7615 | Actual Loss: 0.4189\n",
      "Baseline Loss: 2.8300 | Actual Loss: 0.2806\n",
      "Baseline Loss: 2.8925 | Actual Loss: 0.5508\n",
      "Baseline Loss: 2.8079 | Actual Loss: 0.6519\n",
      "Baseline Loss: 2.8315 | Actual Loss: 0.3341\n",
      "Baseline Loss: 2.8504 | Actual Loss: 1.7900\n",
      "Baseline Loss: 2.8059 | Actual Loss: 0.5867\n",
      "Baseline Loss: 2.8071 | Actual Loss: 0.3340\n",
      "Baseline Loss: 2.9166 | Actual Loss: 0.8374\n",
      "Baseline Loss: 2.3694 | Actual Loss: 0.3947\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.3239\n",
      "Baseline Loss: 2.8053 | Actual Loss: 0.9365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 41/1000 [00:26<10:15,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8529 | Actual Loss: 0.6373\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.5797\n",
      "Epoch 41/1000: Train Loss: 0.6121, Val Loss: 0.6193\n",
      "Baseline Loss: 2.8724 | Actual Loss: 0.3052\n",
      "Baseline Loss: 2.8339 | Actual Loss: 0.5517\n",
      "Baseline Loss: 2.7408 | Actual Loss: 0.5521\n",
      "Baseline Loss: 2.8344 | Actual Loss: 0.7723\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.5909\n",
      "Baseline Loss: 2.8400 | Actual Loss: 0.5634\n",
      "Baseline Loss: 2.7720 | Actual Loss: 0.2269\n",
      "Baseline Loss: 2.8224 | Actual Loss: 0.4835\n",
      "Baseline Loss: 2.7819 | Actual Loss: 0.1636\n",
      "Baseline Loss: 2.8149 | Actual Loss: 0.4520\n",
      "Baseline Loss: 2.8306 | Actual Loss: 0.9229\n",
      "Baseline Loss: 2.8419 | Actual Loss: 0.1769\n",
      "Baseline Loss: 2.7715 | Actual Loss: 0.2828\n",
      "Baseline Loss: 2.8938 | Actual Loss: 1.4682\n",
      "Baseline Loss: 2.8428 | Actual Loss: 0.1733\n",
      "Baseline Loss: 2.5344 | Actual Loss: 1.8026\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.3797\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.1017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 42/1000 [00:26<10:19,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8529 | Actual Loss: 0.3713\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.4595\n",
      "Epoch 42/1000: Train Loss: 0.5930, Val Loss: 0.5781\n",
      "Baseline Loss: 2.8072 | Actual Loss: 0.3378\n",
      "Baseline Loss: 2.7865 | Actual Loss: 0.2261\n",
      "Baseline Loss: 2.8104 | Actual Loss: 0.2132\n",
      "Baseline Loss: 2.8288 | Actual Loss: 0.3724\n",
      "Baseline Loss: 2.8388 | Actual Loss: 0.6098\n",
      "Baseline Loss: 2.8241 | Actual Loss: 0.2637\n",
      "Baseline Loss: 2.7793 | Actual Loss: 0.3961\n",
      "Baseline Loss: 2.7859 | Actual Loss: 0.6132\n",
      "Baseline Loss: 2.7721 | Actual Loss: 0.3221\n",
      "Baseline Loss: 2.8792 | Actual Loss: 0.2430\n",
      "Baseline Loss: 2.8626 | Actual Loss: 1.1602\n",
      "Baseline Loss: 2.8571 | Actual Loss: 0.1795\n",
      "Baseline Loss: 2.8190 | Actual Loss: 0.4565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 43/1000 [00:27<10:27,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8093 | Actual Loss: 0.4949\n",
      "Baseline Loss: 2.8790 | Actual Loss: 0.6315\n",
      "Baseline Loss: 2.5559 | Actual Loss: 0.3752\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.3841\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.0758\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.7245\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.5431\n",
      "Epoch 43/1000: Train Loss: 0.4309, Val Loss: 0.6819\n",
      "Baseline Loss: 2.7767 | Actual Loss: 0.5961\n",
      "Baseline Loss: 2.8785 | Actual Loss: 0.4795\n",
      "Baseline Loss: 2.8166 | Actual Loss: 0.6852\n",
      "Baseline Loss: 2.8200 | Actual Loss: 0.0602\n",
      "Baseline Loss: 2.8864 | Actual Loss: 0.5080\n",
      "Baseline Loss: 2.8028 | Actual Loss: 0.3563\n",
      "Baseline Loss: 2.7967 | Actual Loss: 0.3594\n",
      "Baseline Loss: 2.7827 | Actual Loss: 0.6239\n",
      "Baseline Loss: 2.7777 | Actual Loss: 0.3495\n",
      "Baseline Loss: 2.8264 | Actual Loss: 0.7746\n",
      "Baseline Loss: 2.8382 | Actual Loss: 0.3410\n",
      "Baseline Loss: 2.8166 | Actual Loss: 0.2068\n",
      "Baseline Loss: 2.8135 | Actual Loss: 0.2190\n",
      "Baseline Loss: 2.8428 | Actual Loss: 1.4208\n",
      "Baseline Loss: 2.8064 | Actual Loss: 0.5016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 44/1000 [00:28<10:13,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5092 | Actual Loss: 0.1283\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.4272\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.7681\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.4721\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.4520\n",
      "Epoch 44/1000: Train Loss: 0.4756, Val Loss: 0.7798\n",
      "Baseline Loss: 2.8055 | Actual Loss: 0.3559\n",
      "Baseline Loss: 2.8617 | Actual Loss: 0.3109\n",
      "Baseline Loss: 2.8513 | Actual Loss: 0.4571\n",
      "Baseline Loss: 2.8051 | Actual Loss: 1.0766\n",
      "Baseline Loss: 2.8573 | Actual Loss: 0.2781\n",
      "Baseline Loss: 2.8281 | Actual Loss: 0.2152\n",
      "Baseline Loss: 2.7950 | Actual Loss: 0.2537\n",
      "Baseline Loss: 2.8428 | Actual Loss: 0.5032\n",
      "Baseline Loss: 2.8152 | Actual Loss: 1.6710\n",
      "Baseline Loss: 2.8650 | Actual Loss: 0.3249\n",
      "Baseline Loss: 2.7968 | Actual Loss: 0.6411\n",
      "Baseline Loss: 2.8254 | Actual Loss: 0.3896\n",
      "Baseline Loss: 2.7774 | Actual Loss: 0.3485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 45/1000 [00:28<10:25,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7777 | Actual Loss: 1.3236\n",
      "Baseline Loss: 2.7422 | Actual Loss: 0.1945\n",
      "Baseline Loss: 2.6604 | Actual Loss: 0.2340\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.7764\n",
      "Baseline Loss: 2.8053 | Actual Loss: 2.3338\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.3955\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.3644\n",
      "Epoch 45/1000: Train Loss: 0.5361, Val Loss: 0.9675\n",
      "Baseline Loss: 2.8657 | Actual Loss: 0.1878\n",
      "Baseline Loss: 2.8440 | Actual Loss: 0.2783\n",
      "Baseline Loss: 2.9146 | Actual Loss: 1.4747\n",
      "Baseline Loss: 2.7779 | Actual Loss: 0.6213\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.4216\n",
      "Baseline Loss: 2.8531 | Actual Loss: 0.5898\n",
      "Baseline Loss: 2.8026 | Actual Loss: 0.1518\n",
      "Baseline Loss: 2.7936 | Actual Loss: 0.2842\n",
      "Baseline Loss: 2.8127 | Actual Loss: 0.5885\n",
      "Baseline Loss: 2.8072 | Actual Loss: 0.2555\n",
      "Baseline Loss: 2.7877 | Actual Loss: 0.1541\n",
      "Baseline Loss: 2.7858 | Actual Loss: 0.7733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 46/1000 [00:29<10:29,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7315 | Actual Loss: 0.3085\n",
      "Baseline Loss: 2.8558 | Actual Loss: 0.4550\n",
      "Baseline Loss: 2.8281 | Actual Loss: 0.3542\n",
      "Baseline Loss: 2.6218 | Actual Loss: 0.4342\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.5896\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.1445\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.4023\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.3845\n",
      "Epoch 46/1000: Train Loss: 0.4583, Val Loss: 0.6302\n",
      "Baseline Loss: 2.9063 | Actual Loss: 0.4766\n",
      "Baseline Loss: 2.7695 | Actual Loss: 0.4122\n",
      "Baseline Loss: 2.8021 | Actual Loss: 0.4479\n",
      "Baseline Loss: 2.8258 | Actual Loss: 0.5778\n",
      "Baseline Loss: 2.7962 | Actual Loss: 0.3972\n",
      "Baseline Loss: 2.8289 | Actual Loss: 0.6923\n",
      "Baseline Loss: 2.8175 | Actual Loss: 0.5827\n",
      "Baseline Loss: 2.8506 | Actual Loss: 0.4969\n",
      "Baseline Loss: 2.8179 | Actual Loss: 0.4119\n",
      "Baseline Loss: 2.7745 | Actual Loss: 0.3634\n",
      "Baseline Loss: 2.8979 | Actual Loss: 0.2577\n",
      "Baseline Loss: 2.8277 | Actual Loss: 0.3438\n",
      "Baseline Loss: 2.7947 | Actual Loss: 0.3229\n",
      "Baseline Loss: 2.7978 | Actual Loss: 0.2709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 47/1000 [00:30<10:14,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7735 | Actual Loss: 0.4465\n",
      "Baseline Loss: 2.5026 | Actual Loss: 1.3996\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.6490\n",
      "Baseline Loss: 2.8053 | Actual Loss: 2.1019\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.5725\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.4627\n",
      "Epoch 47/1000: Train Loss: 0.4938, Val Loss: 0.9466\n",
      "Baseline Loss: 2.7950 | Actual Loss: 0.2430\n",
      "Baseline Loss: 2.7821 | Actual Loss: 0.2968\n",
      "Baseline Loss: 2.7613 | Actual Loss: 0.5688\n",
      "Baseline Loss: 2.8656 | Actual Loss: 0.1781\n",
      "Baseline Loss: 2.7790 | Actual Loss: 0.2493\n",
      "Baseline Loss: 2.8350 | Actual Loss: 0.5566\n",
      "Baseline Loss: 2.8397 | Actual Loss: 0.3809\n",
      "Baseline Loss: 2.8904 | Actual Loss: 0.3451\n",
      "Baseline Loss: 2.8858 | Actual Loss: 0.6552\n",
      "Baseline Loss: 2.8831 | Actual Loss: 0.3077\n",
      "Baseline Loss: 2.7849 | Actual Loss: 0.2609\n",
      "Baseline Loss: 2.7824 | Actual Loss: 0.4355\n",
      "Baseline Loss: 2.8052 | Actual Loss: 0.6093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 48/1000 [00:30<10:18,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8325 | Actual Loss: 0.3123\n",
      "Baseline Loss: 2.7323 | Actual Loss: 0.2176\n",
      "Baseline Loss: 2.5304 | Actual Loss: 0.3897\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.5002\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.0121\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.5173\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.5469\n",
      "Epoch 48/1000: Train Loss: 0.3754, Val Loss: 0.6441\n",
      "Baseline Loss: 2.7605 | Actual Loss: 0.5180\n",
      "Baseline Loss: 2.7822 | Actual Loss: 0.1697\n",
      "Baseline Loss: 2.8558 | Actual Loss: 0.2516\n",
      "Baseline Loss: 2.7585 | Actual Loss: 0.2743\n",
      "Baseline Loss: 2.8407 | Actual Loss: 0.2779\n",
      "Baseline Loss: 2.8275 | Actual Loss: 0.5369\n",
      "Baseline Loss: 2.8410 | Actual Loss: 0.3908\n",
      "Baseline Loss: 2.7926 | Actual Loss: 0.9739\n",
      "Baseline Loss: 2.9529 | Actual Loss: 0.3511\n",
      "Baseline Loss: 2.7962 | Actual Loss: 0.2042\n",
      "Baseline Loss: 2.7954 | Actual Loss: 0.4724\n",
      "Baseline Loss: 2.7522 | Actual Loss: 1.1255\n",
      "Baseline Loss: 2.8792 | Actual Loss: 0.4192\n",
      "Baseline Loss: 2.7969 | Actual Loss: 0.6180\n",
      "Baseline Loss: 2.8118 | Actual Loss: 0.2359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 49/1000 [00:31<10:10,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.3970 | Actual Loss: 0.3589\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.4138\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.2147\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.5002\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.5410\n",
      "Epoch 49/1000: Train Loss: 0.4486, Val Loss: 0.6674\n",
      "Baseline Loss: 2.8892 | Actual Loss: 0.1223\n",
      "Baseline Loss: 2.8202 | Actual Loss: 0.6886\n",
      "Baseline Loss: 2.8455 | Actual Loss: 0.2036\n",
      "Baseline Loss: 2.7829 | Actual Loss: 0.2518\n",
      "Baseline Loss: 2.8144 | Actual Loss: 1.1717\n",
      "Baseline Loss: 2.7975 | Actual Loss: 0.4538\n",
      "Baseline Loss: 2.8196 | Actual Loss: 1.3444\n",
      "Baseline Loss: 2.8323 | Actual Loss: 0.7306\n",
      "Baseline Loss: 2.8559 | Actual Loss: 0.2455\n",
      "Baseline Loss: 2.7592 | Actual Loss: 0.4120\n",
      "Baseline Loss: 2.7924 | Actual Loss: 0.3481\n",
      "Baseline Loss: 2.8350 | Actual Loss: 0.3196\n",
      "Baseline Loss: 2.8186 | Actual Loss: 0.7584\n",
      "Baseline Loss: 2.8196 | Actual Loss: 0.4225\n",
      "Baseline Loss: 2.7852 | Actual Loss: 0.7322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 50/1000 [00:32<09:57,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6922 | Actual Loss: 0.8086\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.8702\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.0771\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.8713\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.6239\n",
      "Epoch 50/1000: Train Loss: 0.5634, Val Loss: 0.8606\n",
      "Baseline Loss: 2.8455 | Actual Loss: 0.6433\n",
      "Baseline Loss: 2.7811 | Actual Loss: 0.4363\n",
      "Baseline Loss: 2.8528 | Actual Loss: 0.8462\n",
      "Baseline Loss: 2.7991 | Actual Loss: 1.1632\n",
      "Baseline Loss: 2.8261 | Actual Loss: 0.6952\n",
      "Baseline Loss: 2.7827 | Actual Loss: 0.2538\n",
      "Baseline Loss: 2.8276 | Actual Loss: 0.2936\n",
      "Baseline Loss: 2.8011 | Actual Loss: 0.5105\n",
      "Baseline Loss: 2.8264 | Actual Loss: 0.3053\n",
      "Baseline Loss: 2.8065 | Actual Loss: 0.3397\n",
      "Baseline Loss: 2.8467 | Actual Loss: 0.4188\n",
      "Baseline Loss: 2.7731 | Actual Loss: 0.2701\n",
      "Baseline Loss: 2.8182 | Actual Loss: 0.5873\n",
      "Baseline Loss: 2.8364 | Actual Loss: 0.3999\n",
      "Baseline Loss: 2.8446 | Actual Loss: 0.7516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 51/1000 [00:32<09:57,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5409 | Actual Loss: 0.4493\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.8573\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.5850\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.4218\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.4030\n",
      "Epoch 51/1000: Train Loss: 0.5228, Val Loss: 0.8168\n",
      "Baseline Loss: 2.8430 | Actual Loss: 2.3175\n",
      "Baseline Loss: 2.7872 | Actual Loss: 0.3585\n",
      "Baseline Loss: 2.7578 | Actual Loss: 0.2678\n",
      "Baseline Loss: 2.8308 | Actual Loss: 0.7721\n",
      "Baseline Loss: 2.7953 | Actual Loss: 0.4706\n",
      "Baseline Loss: 2.7845 | Actual Loss: 0.2948\n",
      "Baseline Loss: 2.7952 | Actual Loss: 0.3270\n",
      "Baseline Loss: 2.8138 | Actual Loss: 0.2114\n",
      "Baseline Loss: 2.8127 | Actual Loss: 0.4892\n",
      "Baseline Loss: 2.7841 | Actual Loss: 0.3827\n",
      "Baseline Loss: 2.8414 | Actual Loss: 0.2175\n",
      "Baseline Loss: 2.7825 | Actual Loss: 0.2280\n",
      "Baseline Loss: 2.8620 | Actual Loss: 0.3105\n",
      "Baseline Loss: 2.8701 | Actual Loss: 0.2934\n",
      "Baseline Loss: 2.8309 | Actual Loss: 0.6541\n",
      "Baseline Loss: 2.5946 | Actual Loss: 0.4416\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.4722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 52/1000 [00:33<09:50,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8053 | Actual Loss: 1.2842\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.4990\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.4060\n",
      "Epoch 52/1000: Train Loss: 0.5023, Val Loss: 0.6653\n",
      "Baseline Loss: 2.8454 | Actual Loss: 0.2893\n",
      "Baseline Loss: 2.8163 | Actual Loss: 0.5770\n",
      "Baseline Loss: 2.7640 | Actual Loss: 0.8602\n",
      "Baseline Loss: 2.8235 | Actual Loss: 0.4852\n",
      "Baseline Loss: 2.7788 | Actual Loss: 1.8616\n",
      "Baseline Loss: 2.8909 | Actual Loss: 0.2762\n",
      "Baseline Loss: 2.8659 | Actual Loss: 0.6135\n",
      "Baseline Loss: 2.7924 | Actual Loss: 0.2580\n",
      "Baseline Loss: 2.7822 | Actual Loss: 0.4066\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2592\n",
      "Baseline Loss: 2.7886 | Actual Loss: 0.2015\n",
      "Baseline Loss: 2.8040 | Actual Loss: 0.1763\n",
      "Baseline Loss: 2.8458 | Actual Loss: 0.2597\n",
      "Baseline Loss: 2.8103 | Actual Loss: 0.2131\n",
      "Baseline Loss: 2.7795 | Actual Loss: 0.2298\n",
      "Baseline Loss: 2.3562 | Actual Loss: 0.1933\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.4129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 53/1000 [00:33<09:44,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8053 | Actual Loss: 0.9970\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.4838\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.4999\n",
      "Epoch 53/1000: Train Loss: 0.4475, Val Loss: 0.5984\n",
      "Baseline Loss: 2.8464 | Actual Loss: 0.5353\n",
      "Baseline Loss: 2.8114 | Actual Loss: 0.5231\n",
      "Baseline Loss: 2.8146 | Actual Loss: 0.4491\n",
      "Baseline Loss: 2.8483 | Actual Loss: 0.1937\n",
      "Baseline Loss: 2.8203 | Actual Loss: 2.4217\n",
      "Baseline Loss: 2.7907 | Actual Loss: 0.1472\n",
      "Baseline Loss: 2.8340 | Actual Loss: 0.2600\n",
      "Baseline Loss: 2.8727 | Actual Loss: 0.2147\n",
      "Baseline Loss: 2.8102 | Actual Loss: 0.1976\n",
      "Baseline Loss: 2.8132 | Actual Loss: 0.4022\n",
      "Baseline Loss: 2.8200 | Actual Loss: 2.3858\n",
      "Baseline Loss: 2.8301 | Actual Loss: 0.2439\n",
      "Baseline Loss: 2.7937 | Actual Loss: 0.4376\n",
      "Baseline Loss: 2.7710 | Actual Loss: 0.2669\n",
      "Baseline Loss: 2.7659 | Actual Loss: 0.3182\n",
      "Baseline Loss: 2.5020 | Actual Loss: 0.3112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 54/1000 [00:34<10:02,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9000 | Actual Loss: 0.1791\n",
      "Baseline Loss: 2.8053 | Actual Loss: 0.7127\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.4759\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.4495\n",
      "Epoch 54/1000: Train Loss: 0.5818, Val Loss: 0.4543\n",
      "New best validation loss: 0.4543\n",
      "Baseline Loss: 2.7668 | Actual Loss: 0.1534\n",
      "Baseline Loss: 2.8094 | Actual Loss: 0.6869\n",
      "Baseline Loss: 2.8441 | Actual Loss: 0.4419\n",
      "Baseline Loss: 2.7925 | Actual Loss: 0.7140\n",
      "Baseline Loss: 2.8533 | Actual Loss: 0.9451\n",
      "Baseline Loss: 2.8335 | Actual Loss: 0.7903\n",
      "Baseline Loss: 2.8123 | Actual Loss: 0.2701\n",
      "Baseline Loss: 2.7860 | Actual Loss: 0.3687\n",
      "Baseline Loss: 2.7940 | Actual Loss: 0.3065\n",
      "Baseline Loss: 2.7914 | Actual Loss: 0.3684\n",
      "Baseline Loss: 2.8232 | Actual Loss: 0.4889\n",
      "Baseline Loss: 2.8726 | Actual Loss: 1.2571\n",
      "Baseline Loss: 2.8466 | Actual Loss: 0.5127\n",
      "Baseline Loss: 2.8551 | Actual Loss: 0.4683\n",
      "Baseline Loss: 2.8502 | Actual Loss: 0.4902\n",
      "Baseline Loss: 2.5439 | Actual Loss: 0.3841\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.6207\n",
      "Baseline Loss: 2.8053 | Actual Loss: 0.9714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 55/1000 [00:35<09:32,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8529 | Actual Loss: 0.6450\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.4872\n",
      "Epoch 55/1000: Train Loss: 0.5404, Val Loss: 0.6811\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6478\n",
      "Baseline Loss: 2.8523 | Actual Loss: 0.1830\n",
      "Baseline Loss: 2.7829 | Actual Loss: 0.4091\n",
      "Baseline Loss: 2.8120 | Actual Loss: 0.5152\n",
      "Baseline Loss: 2.7620 | Actual Loss: 0.5058\n",
      "Baseline Loss: 2.9101 | Actual Loss: 0.2437\n",
      "Baseline Loss: 2.8267 | Actual Loss: 0.2328\n",
      "Baseline Loss: 2.7729 | Actual Loss: 0.4003\n",
      "Baseline Loss: 2.7974 | Actual Loss: 0.2085\n",
      "Baseline Loss: 2.7919 | Actual Loss: 0.2336\n",
      "Baseline Loss: 2.9022 | Actual Loss: 0.1514\n",
      "Baseline Loss: 2.8007 | Actual Loss: 0.1948\n",
      "Baseline Loss: 2.8574 | Actual Loss: 0.5111\n",
      "Baseline Loss: 2.8456 | Actual Loss: 0.1530\n",
      "Baseline Loss: 2.7714 | Actual Loss: 0.4047\n",
      "Baseline Loss: 2.5601 | Actual Loss: 0.1506\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.5826\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.0014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 56/1000 [00:35<09:48,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8529 | Actual Loss: 0.6968\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.6460\n",
      "Epoch 56/1000: Train Loss: 0.3216, Val Loss: 0.7317\n",
      "Baseline Loss: 2.8415 | Actual Loss: 0.5680\n",
      "Baseline Loss: 2.7229 | Actual Loss: 0.4710\n",
      "Baseline Loss: 2.8849 | Actual Loss: 0.6576\n",
      "Baseline Loss: 2.8818 | Actual Loss: 0.4580\n",
      "Baseline Loss: 2.8497 | Actual Loss: 0.1945\n",
      "Baseline Loss: 2.7395 | Actual Loss: 0.2378\n",
      "Baseline Loss: 2.7870 | Actual Loss: 0.3545\n",
      "Baseline Loss: 2.7739 | Actual Loss: 0.2503\n",
      "Baseline Loss: 2.8201 | Actual Loss: 1.3381\n",
      "Baseline Loss: 2.8800 | Actual Loss: 0.5763\n",
      "Baseline Loss: 2.8045 | Actual Loss: 0.3705\n",
      "Baseline Loss: 2.8563 | Actual Loss: 1.0026\n",
      "Baseline Loss: 2.8076 | Actual Loss: 2.2792\n",
      "Baseline Loss: 2.8567 | Actual Loss: 0.3598\n",
      "Baseline Loss: 2.8055 | Actual Loss: 0.3117\n",
      "Baseline Loss: 2.4901 | Actual Loss: 0.1782\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.4535\n",
      "Baseline Loss: 2.8053 | Actual Loss: 0.8182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 57/1000 [00:36<09:57,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8529 | Actual Loss: 0.6180\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.5279\n",
      "Epoch 57/1000: Train Loss: 0.6005, Val Loss: 0.6044\n",
      "Baseline Loss: 2.8666 | Actual Loss: 0.7315\n",
      "Baseline Loss: 2.8574 | Actual Loss: 0.8334\n",
      "Baseline Loss: 2.8192 | Actual Loss: 0.1701\n",
      "Baseline Loss: 2.7607 | Actual Loss: 0.3626\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.4052\n",
      "Baseline Loss: 2.8956 | Actual Loss: 0.4807\n",
      "Baseline Loss: 2.7611 | Actual Loss: 0.1650\n",
      "Baseline Loss: 2.7925 | Actual Loss: 0.2446\n",
      "Baseline Loss: 2.9168 | Actual Loss: 0.3480\n",
      "Baseline Loss: 2.7858 | Actual Loss: 0.4658\n",
      "Baseline Loss: 2.7749 | Actual Loss: 0.2506\n",
      "Baseline Loss: 2.8163 | Actual Loss: 0.2172\n",
      "Baseline Loss: 2.8831 | Actual Loss: 0.2385\n",
      "Baseline Loss: 2.8438 | Actual Loss: 0.4762\n",
      "Baseline Loss: 2.7684 | Actual Loss: 0.3335\n",
      "Baseline Loss: 2.5502 | Actual Loss: 0.1015\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.2521\n",
      "Baseline Loss: 2.8053 | Actual Loss: 0.7730\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.5328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 58/1000 [00:37<09:51,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7244 | Actual Loss: 0.4952\n",
      "Epoch 58/1000: Train Loss: 0.3640, Val Loss: 0.5133\n",
      "Baseline Loss: 2.7753 | Actual Loss: 0.4607\n",
      "Baseline Loss: 2.7838 | Actual Loss: 0.4032\n",
      "Baseline Loss: 2.7961 | Actual Loss: 0.3498\n",
      "Baseline Loss: 2.8356 | Actual Loss: 0.2283\n",
      "Baseline Loss: 2.8093 | Actual Loss: 0.3807\n",
      "Baseline Loss: 2.8135 | Actual Loss: 0.5994\n",
      "Baseline Loss: 2.8393 | Actual Loss: 0.2450\n",
      "Baseline Loss: 2.7865 | Actual Loss: 0.3268\n",
      "Baseline Loss: 2.7543 | Actual Loss: 0.1878\n",
      "Baseline Loss: 2.8260 | Actual Loss: 0.1540\n",
      "Baseline Loss: 2.8626 | Actual Loss: 0.2113\n",
      "Baseline Loss: 2.8862 | Actual Loss: 0.2792\n",
      "Baseline Loss: 2.8029 | Actual Loss: 0.2471\n",
      "Baseline Loss: 2.7917 | Actual Loss: 0.2858\n",
      "Baseline Loss: 2.8185 | Actual Loss: 0.1478\n",
      "Baseline Loss: 2.4293 | Actual Loss: 0.4015\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.5916\n",
      "Baseline Loss: 2.8053 | Actual Loss: 2.6372\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.2660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 59/1000 [00:37<09:58,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7244 | Actual Loss: 0.4531\n",
      "Epoch 59/1000: Train Loss: 0.3068, Val Loss: 0.9870\n",
      "Baseline Loss: 2.8710 | Actual Loss: 0.2571\n",
      "Baseline Loss: 2.7716 | Actual Loss: 0.3868\n",
      "Baseline Loss: 2.8860 | Actual Loss: 2.4446\n",
      "Baseline Loss: 2.7192 | Actual Loss: 0.2652\n",
      "Baseline Loss: 2.7883 | Actual Loss: 0.9081\n",
      "Baseline Loss: 2.7846 | Actual Loss: 0.4272\n",
      "Baseline Loss: 2.7567 | Actual Loss: 0.2755\n",
      "Baseline Loss: 2.8133 | Actual Loss: 0.2876\n",
      "Baseline Loss: 2.8718 | Actual Loss: 0.5156\n",
      "Baseline Loss: 2.7932 | Actual Loss: 0.2094\n",
      "Baseline Loss: 2.9058 | Actual Loss: 0.4311\n",
      "Baseline Loss: 2.7657 | Actual Loss: 0.2547\n",
      "Baseline Loss: 2.8400 | Actual Loss: 0.5648\n",
      "Baseline Loss: 2.8696 | Actual Loss: 0.1902\n",
      "Baseline Loss: 2.8581 | Actual Loss: 0.3129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 60/1000 [00:38<09:53,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5959 | Actual Loss: 0.0505\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.1823\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.1763\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.4046\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.4655\n",
      "Epoch 60/1000: Train Loss: 0.4863, Val Loss: 0.5572\n",
      "Baseline Loss: 2.8909 | Actual Loss: 0.1269\n",
      "Baseline Loss: 2.7571 | Actual Loss: 0.2354\n",
      "Baseline Loss: 2.8121 | Actual Loss: 0.3458\n",
      "Baseline Loss: 2.8339 | Actual Loss: 0.5174\n",
      "Baseline Loss: 2.7794 | Actual Loss: 0.1962\n",
      "Baseline Loss: 2.7712 | Actual Loss: 0.5383\n",
      "Baseline Loss: 2.7630 | Actual Loss: 0.7233\n",
      "Baseline Loss: 2.7972 | Actual Loss: 0.2792\n",
      "Baseline Loss: 2.7738 | Actual Loss: 0.6960\n",
      "Baseline Loss: 2.9053 | Actual Loss: 0.5661\n",
      "Baseline Loss: 2.8103 | Actual Loss: 0.3194\n",
      "Baseline Loss: 2.8150 | Actual Loss: 0.4017\n",
      "Baseline Loss: 2.8506 | Actual Loss: 0.4123\n",
      "Baseline Loss: 2.8777 | Actual Loss: 0.3077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 61/1000 [00:38<09:47,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9102 | Actual Loss: 0.3507\n",
      "Baseline Loss: 2.4058 | Actual Loss: 0.4679\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.3756\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.7064\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.4986\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.4216\n",
      "Epoch 61/1000: Train Loss: 0.4053, Val Loss: 0.7506\n",
      "Baseline Loss: 2.7991 | Actual Loss: 0.8687\n",
      "Baseline Loss: 2.8346 | Actual Loss: 0.5825\n",
      "Baseline Loss: 2.8198 | Actual Loss: 0.3684\n",
      "Baseline Loss: 2.9011 | Actual Loss: 1.6414\n",
      "Baseline Loss: 2.8081 | Actual Loss: 0.3504\n",
      "Baseline Loss: 2.7415 | Actual Loss: 0.2630\n",
      "Baseline Loss: 2.7926 | Actual Loss: 0.2600\n",
      "Baseline Loss: 2.8333 | Actual Loss: 0.7441\n",
      "Baseline Loss: 2.8531 | Actual Loss: 0.2668\n",
      "Baseline Loss: 2.8003 | Actual Loss: 0.4925\n",
      "Baseline Loss: 2.8079 | Actual Loss: 0.2363\n",
      "Baseline Loss: 2.7868 | Actual Loss: 0.1351\n",
      "Baseline Loss: 2.8690 | Actual Loss: 0.1439\n",
      "Baseline Loss: 2.8393 | Actual Loss: 0.4780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 62/1000 [00:39<09:49,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8357 | Actual Loss: 2.5386\n",
      "Baseline Loss: 2.4837 | Actual Loss: 0.6339\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.3734\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.4569\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.3627\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.4161\n",
      "Epoch 62/1000: Train Loss: 0.6252, Val Loss: 0.6523\n",
      "Baseline Loss: 2.7940 | Actual Loss: 0.3334\n",
      "Baseline Loss: 2.8710 | Actual Loss: 0.4254\n",
      "Baseline Loss: 2.8655 | Actual Loss: 0.1377\n",
      "Baseline Loss: 2.8223 | Actual Loss: 0.2427\n",
      "Baseline Loss: 2.8065 | Actual Loss: 0.1874\n",
      "Baseline Loss: 2.7939 | Actual Loss: 0.3533\n",
      "Baseline Loss: 2.7877 | Actual Loss: 0.1861\n",
      "Baseline Loss: 2.9299 | Actual Loss: 1.6821\n",
      "Baseline Loss: 2.8149 | Actual Loss: 0.2739\n",
      "Baseline Loss: 2.7818 | Actual Loss: 0.4466\n",
      "Baseline Loss: 2.7985 | Actual Loss: 0.2958\n",
      "Baseline Loss: 2.8713 | Actual Loss: 0.7027\n",
      "Baseline Loss: 2.8363 | Actual Loss: 0.2306\n",
      "Baseline Loss: 2.7820 | Actual Loss: 0.4360\n",
      "Baseline Loss: 2.8279 | Actual Loss: 0.6474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 63/1000 [00:40<09:48,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.4015 | Actual Loss: 0.2639\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.8002\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.0613\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.4917\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.3424\n",
      "Epoch 63/1000: Train Loss: 0.4278, Val Loss: 0.6739\n",
      "Baseline Loss: 2.9029 | Actual Loss: 0.4290\n",
      "Baseline Loss: 2.7718 | Actual Loss: 0.2429\n",
      "Baseline Loss: 2.8220 | Actual Loss: 0.4310\n",
      "Baseline Loss: 2.8186 | Actual Loss: 0.7638\n",
      "Baseline Loss: 2.7790 | Actual Loss: 0.2563\n",
      "Baseline Loss: 2.8336 | Actual Loss: 0.1868\n",
      "Baseline Loss: 2.7477 | Actual Loss: 0.8541\n",
      "Baseline Loss: 2.8099 | Actual Loss: 0.1229\n",
      "Baseline Loss: 2.8010 | Actual Loss: 0.2004\n",
      "Baseline Loss: 2.7798 | Actual Loss: 0.2650\n",
      "Baseline Loss: 2.8515 | Actual Loss: 0.2465\n",
      "Baseline Loss: 2.8023 | Actual Loss: 0.4703\n",
      "Baseline Loss: 2.8340 | Actual Loss: 1.3122\n",
      "Baseline Loss: 2.8378 | Actual Loss: 1.2480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 64/1000 [00:40<09:36,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8787 | Actual Loss: 0.3845\n",
      "Baseline Loss: 2.5493 | Actual Loss: 0.1240\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.3232\n",
      "Baseline Loss: 2.8053 | Actual Loss: 0.9858\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.4891\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.3483\n",
      "Epoch 64/1000: Train Loss: 0.4711, Val Loss: 0.5366\n",
      "Baseline Loss: 2.7971 | Actual Loss: 0.0889\n",
      "Baseline Loss: 2.7808 | Actual Loss: 0.4277\n",
      "Baseline Loss: 2.7914 | Actual Loss: 0.1593\n",
      "Baseline Loss: 2.8319 | Actual Loss: 0.3193\n",
      "Baseline Loss: 2.8375 | Actual Loss: 0.4446\n",
      "Baseline Loss: 2.9172 | Actual Loss: 0.5074\n",
      "Baseline Loss: 2.8103 | Actual Loss: 0.5291\n",
      "Baseline Loss: 2.7929 | Actual Loss: 1.4712\n",
      "Baseline Loss: 2.8571 | Actual Loss: 0.2360\n",
      "Baseline Loss: 2.8050 | Actual Loss: 0.3740\n",
      "Baseline Loss: 2.8070 | Actual Loss: 0.2325\n",
      "Baseline Loss: 2.8177 | Actual Loss: 0.9179\n",
      "Baseline Loss: 2.8531 | Actual Loss: 0.2922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 65/1000 [00:41<09:46,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7988 | Actual Loss: 0.6809\n",
      "Baseline Loss: 2.8113 | Actual Loss: 0.2482\n",
      "Baseline Loss: 2.5662 | Actual Loss: 1.8645\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.4394\n",
      "Baseline Loss: 2.8053 | Actual Loss: 0.8195\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.4759\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.3336\n",
      "Epoch 65/1000: Train Loss: 0.5496, Val Loss: 0.5171\n",
      "Baseline Loss: 2.7633 | Actual Loss: 0.4570\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.4720\n",
      "Baseline Loss: 2.8308 | Actual Loss: 0.4088\n",
      "Baseline Loss: 2.7907 | Actual Loss: 0.2938\n",
      "Baseline Loss: 2.7715 | Actual Loss: 0.2449\n",
      "Baseline Loss: 2.8013 | Actual Loss: 0.2176\n",
      "Baseline Loss: 2.8273 | Actual Loss: 0.6616\n",
      "Baseline Loss: 2.8524 | Actual Loss: 0.3267\n",
      "Baseline Loss: 2.7755 | Actual Loss: 0.4584\n",
      "Baseline Loss: 2.8462 | Actual Loss: 0.1254\n",
      "Baseline Loss: 2.8399 | Actual Loss: 0.4840\n",
      "Baseline Loss: 2.8690 | Actual Loss: 0.6036\n",
      "Baseline Loss: 2.8076 | Actual Loss: 0.3275\n",
      "Baseline Loss: 2.8574 | Actual Loss: 0.5163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 66/1000 [00:42<09:37,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8543 | Actual Loss: 0.4608\n",
      "Baseline Loss: 2.5074 | Actual Loss: 0.3059\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.3082\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.1860\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.4962\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.3653\n",
      "Epoch 66/1000: Train Loss: 0.3978, Val Loss: 0.5889\n",
      "Baseline Loss: 2.8909 | Actual Loss: 0.2252\n",
      "Baseline Loss: 2.7718 | Actual Loss: 1.3381\n",
      "Baseline Loss: 2.8330 | Actual Loss: 0.3025\n",
      "Baseline Loss: 2.8681 | Actual Loss: 0.3794\n",
      "Baseline Loss: 2.8042 | Actual Loss: 0.3599\n",
      "Baseline Loss: 2.8416 | Actual Loss: 0.4306\n",
      "Baseline Loss: 2.8411 | Actual Loss: 0.2466\n",
      "Baseline Loss: 2.8292 | Actual Loss: 1.4379\n",
      "Baseline Loss: 2.7845 | Actual Loss: 0.6019\n",
      "Baseline Loss: 2.7653 | Actual Loss: 0.2762\n",
      "Baseline Loss: 2.8782 | Actual Loss: 0.1578\n",
      "Baseline Loss: 2.8845 | Actual Loss: 0.8397\n",
      "Baseline Loss: 2.8634 | Actual Loss: 0.5173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 67/1000 [00:42<09:48,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8055 | Actual Loss: 0.2461\n",
      "Baseline Loss: 2.7830 | Actual Loss: 0.4300\n",
      "Baseline Loss: 2.4886 | Actual Loss: 0.1163\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.3550\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.2573\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.5045\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.3633\n",
      "Epoch 67/1000: Train Loss: 0.4941, Val Loss: 0.6200\n",
      "Baseline Loss: 2.8403 | Actual Loss: 0.2258\n",
      "Baseline Loss: 2.7860 | Actual Loss: 0.2271\n",
      "Baseline Loss: 2.8177 | Actual Loss: 0.1907\n",
      "Baseline Loss: 2.8174 | Actual Loss: 0.2948\n",
      "Baseline Loss: 2.8174 | Actual Loss: 0.2110\n",
      "Baseline Loss: 2.8128 | Actual Loss: 0.3601\n",
      "Baseline Loss: 2.8072 | Actual Loss: 0.4888\n",
      "Baseline Loss: 2.8643 | Actual Loss: 0.5891\n",
      "Baseline Loss: 2.8468 | Actual Loss: 0.2142\n",
      "Baseline Loss: 2.7519 | Actual Loss: 0.1456\n",
      "Baseline Loss: 2.8584 | Actual Loss: 0.2915\n",
      "Baseline Loss: 2.8346 | Actual Loss: 0.5849\n",
      "Baseline Loss: 2.7938 | Actual Loss: 0.3083\n",
      "Baseline Loss: 2.8128 | Actual Loss: 0.2633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 68/1000 [00:43<10:02,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8438 | Actual Loss: 0.2148\n",
      "Baseline Loss: 2.5689 | Actual Loss: 0.2138\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.2003\n",
      "Baseline Loss: 2.8053 | Actual Loss: 0.9398\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.3874\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.4791\n",
      "Epoch 68/1000: Train Loss: 0.3015, Val Loss: 0.5017\n",
      "Baseline Loss: 2.8935 | Actual Loss: 0.2718\n",
      "Baseline Loss: 2.7639 | Actual Loss: 0.0779\n",
      "Baseline Loss: 2.7865 | Actual Loss: 0.4820\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5242\n",
      "Baseline Loss: 2.7540 | Actual Loss: 0.4576\n",
      "Baseline Loss: 2.8318 | Actual Loss: 0.0779\n",
      "Baseline Loss: 2.8196 | Actual Loss: 0.2824\n",
      "Baseline Loss: 2.8268 | Actual Loss: 0.3114\n",
      "Baseline Loss: 2.7830 | Actual Loss: 0.6591\n",
      "Baseline Loss: 2.7977 | Actual Loss: 1.6741\n",
      "Baseline Loss: 2.7799 | Actual Loss: 0.1990\n",
      "Baseline Loss: 2.8264 | Actual Loss: 0.2781\n",
      "Baseline Loss: 2.7639 | Actual Loss: 0.3630\n",
      "Baseline Loss: 2.8225 | Actual Loss: 0.3717\n",
      "Baseline Loss: 2.9024 | Actual Loss: 0.1281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 69/1000 [00:44<09:51,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6239 | Actual Loss: 0.1811\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.2936\n",
      "Baseline Loss: 2.8053 | Actual Loss: 0.9361\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.4782\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.4645\n",
      "Epoch 69/1000: Train Loss: 0.3962, Val Loss: 0.5431\n",
      "Baseline Loss: 2.8082 | Actual Loss: 0.1645\n",
      "Baseline Loss: 2.7956 | Actual Loss: 0.3648\n",
      "Baseline Loss: 2.8586 | Actual Loss: 0.5743\n",
      "Baseline Loss: 2.8487 | Actual Loss: 2.3716\n",
      "Baseline Loss: 2.7582 | Actual Loss: 0.3172\n",
      "Baseline Loss: 2.8230 | Actual Loss: 0.3196\n",
      "Baseline Loss: 2.8578 | Actual Loss: 1.8844\n",
      "Baseline Loss: 2.8671 | Actual Loss: 0.3370\n",
      "Baseline Loss: 2.8402 | Actual Loss: 0.3897\n",
      "Baseline Loss: 2.8495 | Actual Loss: 0.4979\n",
      "Baseline Loss: 2.7999 | Actual Loss: 0.2528\n",
      "Baseline Loss: 2.8978 | Actual Loss: 0.2737\n",
      "Baseline Loss: 2.7775 | Actual Loss: 0.3777\n",
      "Baseline Loss: 2.8751 | Actual Loss: 0.4128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 70/1000 [00:44<09:56,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8072 | Actual Loss: 0.4447\n",
      "Baseline Loss: 2.5843 | Actual Loss: 0.0794\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.4264\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.0618\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.5415\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.3961\n",
      "Epoch 70/1000: Train Loss: 0.5664, Val Loss: 0.6065\n",
      "Baseline Loss: 2.8455 | Actual Loss: 0.4883\n",
      "Baseline Loss: 2.7900 | Actual Loss: 0.1248\n",
      "Baseline Loss: 2.8526 | Actual Loss: 0.1999\n",
      "Baseline Loss: 2.7922 | Actual Loss: 0.3468\n",
      "Baseline Loss: 2.8123 | Actual Loss: 0.2061\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.3714\n",
      "Baseline Loss: 2.7834 | Actual Loss: 0.4130\n",
      "Baseline Loss: 2.8304 | Actual Loss: 0.5313\n",
      "Baseline Loss: 2.8315 | Actual Loss: 0.3341\n",
      "Baseline Loss: 2.9042 | Actual Loss: 0.5011\n",
      "Baseline Loss: 2.8066 | Actual Loss: 0.4640\n",
      "Baseline Loss: 2.7955 | Actual Loss: 0.2880\n",
      "Baseline Loss: 2.8114 | Actual Loss: 0.3411\n",
      "Baseline Loss: 2.7966 | Actual Loss: 0.1911\n",
      "Baseline Loss: 2.7864 | Actual Loss: 0.2295\n",
      "Baseline Loss: 2.5033 | Actual Loss: 0.2441\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.3895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 71/1000 [00:45<09:58,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8053 | Actual Loss: 1.1534\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.3312\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.3686\n",
      "Epoch 71/1000: Train Loss: 0.3297, Val Loss: 0.5607\n",
      "Baseline Loss: 2.8146 | Actual Loss: 0.4668\n",
      "Baseline Loss: 2.8277 | Actual Loss: 1.0318\n",
      "Baseline Loss: 2.7984 | Actual Loss: 0.5148\n",
      "Baseline Loss: 2.8166 | Actual Loss: 0.1059\n",
      "Baseline Loss: 2.8031 | Actual Loss: 0.7083\n",
      "Baseline Loss: 2.7601 | Actual Loss: 0.3795\n",
      "Baseline Loss: 2.8357 | Actual Loss: 0.2073\n",
      "Baseline Loss: 2.9079 | Actual Loss: 0.2401\n",
      "Baseline Loss: 2.7939 | Actual Loss: 0.1673\n",
      "Baseline Loss: 2.8183 | Actual Loss: 0.3023\n",
      "Baseline Loss: 2.8224 | Actual Loss: 0.3642\n",
      "Baseline Loss: 2.8349 | Actual Loss: 0.1325\n",
      "Baseline Loss: 2.8138 | Actual Loss: 1.4655\n",
      "Baseline Loss: 2.8055 | Actual Loss: 0.1266\n",
      "Baseline Loss: 2.8510 | Actual Loss: 1.0440\n",
      "Baseline Loss: 2.5971 | Actual Loss: 0.2572\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.2142\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.0292\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.5168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 72/1000 [00:45<09:48,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7244 | Actual Loss: 0.4465\n",
      "Epoch 72/1000: Train Loss: 0.4696, Val Loss: 0.5517\n",
      "Baseline Loss: 2.8171 | Actual Loss: 0.4879\n",
      "Baseline Loss: 2.8722 | Actual Loss: 0.3025\n",
      "Baseline Loss: 2.7268 | Actual Loss: 0.3477\n",
      "Baseline Loss: 2.8721 | Actual Loss: 0.3797\n",
      "Baseline Loss: 2.8417 | Actual Loss: 0.2307\n",
      "Baseline Loss: 2.8488 | Actual Loss: 0.1904\n",
      "Baseline Loss: 2.8081 | Actual Loss: 0.5401\n",
      "Baseline Loss: 2.8161 | Actual Loss: 0.4358\n",
      "Baseline Loss: 2.8202 | Actual Loss: 0.8695\n",
      "Baseline Loss: 2.8098 | Actual Loss: 2.0933\n",
      "Baseline Loss: 2.8786 | Actual Loss: 0.2036\n",
      "Baseline Loss: 2.7982 | Actual Loss: 0.2610\n",
      "Baseline Loss: 2.7882 | Actual Loss: 0.5795\n",
      "Baseline Loss: 2.8170 | Actual Loss: 0.1700\n",
      "Baseline Loss: 2.7929 | Actual Loss: 0.6131\n",
      "Baseline Loss: 2.4519 | Actual Loss: 0.2373\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.4911\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.2157\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.5213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 73/1000 [00:46<09:47,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7244 | Actual Loss: 0.3621\n",
      "Epoch 73/1000: Train Loss: 0.4964, Val Loss: 0.6476\n",
      "Baseline Loss: 2.7979 | Actual Loss: 0.2555\n",
      "Baseline Loss: 2.7694 | Actual Loss: 0.4691\n",
      "Baseline Loss: 2.8470 | Actual Loss: 0.4863\n",
      "Baseline Loss: 2.8916 | Actual Loss: 0.3536\n",
      "Baseline Loss: 2.9045 | Actual Loss: 0.5096\n",
      "Baseline Loss: 2.8621 | Actual Loss: 0.4704\n",
      "Baseline Loss: 2.7741 | Actual Loss: 0.3541\n",
      "Baseline Loss: 2.8046 | Actual Loss: 0.3322\n",
      "Baseline Loss: 2.7822 | Actual Loss: 0.1651\n",
      "Baseline Loss: 2.8335 | Actual Loss: 0.0806\n",
      "Baseline Loss: 2.7722 | Actual Loss: 0.3025\n",
      "Baseline Loss: 2.7293 | Actual Loss: 0.5878\n",
      "Baseline Loss: 2.8772 | Actual Loss: 0.4291\n",
      "Baseline Loss: 2.8552 | Actual Loss: 0.0991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 74/1000 [00:47<09:31,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8620 | Actual Loss: 0.2128\n",
      "Baseline Loss: 2.5883 | Actual Loss: 0.1961\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.2884\n",
      "Baseline Loss: 2.8053 | Actual Loss: 0.8477\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.4951\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.4599\n",
      "Epoch 74/1000: Train Loss: 0.3315, Val Loss: 0.5228\n",
      "Baseline Loss: 2.8229 | Actual Loss: 0.6514\n",
      "Baseline Loss: 2.8115 | Actual Loss: 0.1253\n",
      "Baseline Loss: 2.8693 | Actual Loss: 0.3368\n",
      "Baseline Loss: 2.8010 | Actual Loss: 0.5867\n",
      "Baseline Loss: 2.8713 | Actual Loss: 0.2422\n",
      "Baseline Loss: 2.8475 | Actual Loss: 0.5150\n",
      "Baseline Loss: 2.7862 | Actual Loss: 0.1934\n",
      "Baseline Loss: 2.8150 | Actual Loss: 0.2325\n",
      "Baseline Loss: 2.7812 | Actual Loss: 0.4557\n",
      "Baseline Loss: 2.8724 | Actual Loss: 0.3011\n",
      "Baseline Loss: 2.7658 | Actual Loss: 0.8945\n",
      "Baseline Loss: 2.8525 | Actual Loss: 0.5773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 75/1000 [00:47<09:45,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8351 | Actual Loss: 0.1681\n",
      "Baseline Loss: 2.8668 | Actual Loss: 0.1704\n",
      "Baseline Loss: 2.8275 | Actual Loss: 0.2180\n",
      "Baseline Loss: 2.6339 | Actual Loss: 0.2310\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.5573\n",
      "Baseline Loss: 2.8053 | Actual Loss: 2.6164\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.5269\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.4218\n",
      "Epoch 75/1000: Train Loss: 0.3687, Val Loss: 1.0306\n",
      "Baseline Loss: 2.7822 | Actual Loss: 0.2297\n",
      "Baseline Loss: 2.8589 | Actual Loss: 1.7254\n",
      "Baseline Loss: 2.7537 | Actual Loss: 0.2151\n",
      "Baseline Loss: 2.7622 | Actual Loss: 0.1666\n",
      "Baseline Loss: 2.8295 | Actual Loss: 0.5248\n",
      "Baseline Loss: 2.8358 | Actual Loss: 0.4420\n",
      "Baseline Loss: 2.7375 | Actual Loss: 0.2363\n",
      "Baseline Loss: 2.8273 | Actual Loss: 0.5303\n",
      "Baseline Loss: 2.8069 | Actual Loss: 0.4117\n",
      "Baseline Loss: 2.8996 | Actual Loss: 0.5271\n",
      "Baseline Loss: 2.8456 | Actual Loss: 0.4183\n",
      "Baseline Loss: 2.7873 | Actual Loss: 0.3893\n",
      "Baseline Loss: 2.8415 | Actual Loss: 0.3137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 76/1000 [00:48<09:46,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8618 | Actual Loss: 0.2829\n",
      "Baseline Loss: 2.8656 | Actual Loss: 0.4125\n",
      "Baseline Loss: 2.6421 | Actual Loss: 0.5230\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.1445\n",
      "Baseline Loss: 2.8053 | Actual Loss: 0.8851\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.5655\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.4611\n",
      "Epoch 76/1000: Train Loss: 0.4593, Val Loss: 0.5141\n",
      "Baseline Loss: 2.8089 | Actual Loss: 0.3186\n",
      "Baseline Loss: 2.8799 | Actual Loss: 0.2303\n",
      "Baseline Loss: 2.8947 | Actual Loss: 0.1780\n",
      "Baseline Loss: 2.7957 | Actual Loss: 0.5185\n",
      "Baseline Loss: 2.9047 | Actual Loss: 0.4478\n",
      "Baseline Loss: 2.8685 | Actual Loss: 1.8106\n",
      "Baseline Loss: 2.8995 | Actual Loss: 0.1606\n",
      "Baseline Loss: 2.8415 | Actual Loss: 2.5918\n",
      "Baseline Loss: 2.8050 | Actual Loss: 0.5279\n",
      "Baseline Loss: 2.7865 | Actual Loss: 0.4772\n",
      "Baseline Loss: 2.8046 | Actual Loss: 0.2107\n",
      "Baseline Loss: 2.8269 | Actual Loss: 0.7094\n",
      "Baseline Loss: 2.8650 | Actual Loss: 0.2414\n",
      "Baseline Loss: 2.7391 | Actual Loss: 0.5587\n",
      "Baseline Loss: 2.7971 | Actual Loss: 0.4843\n",
      "Baseline Loss: 2.4722 | Actual Loss: 0.3792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 77/1000 [00:49<09:31,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9000 | Actual Loss: 0.4617\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.5856\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.4724\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.4963\n",
      "Epoch 77/1000: Train Loss: 0.6153, Val Loss: 0.7540\n",
      "Baseline Loss: 2.8009 | Actual Loss: 0.2162\n",
      "Baseline Loss: 2.7872 | Actual Loss: 0.7495\n",
      "Baseline Loss: 2.7894 | Actual Loss: 0.4346\n",
      "Baseline Loss: 2.8666 | Actual Loss: 0.6513\n",
      "Baseline Loss: 2.8088 | Actual Loss: 0.3970\n",
      "Baseline Loss: 2.8624 | Actual Loss: 0.5155\n",
      "Baseline Loss: 2.7962 | Actual Loss: 0.5828\n",
      "Baseline Loss: 2.8340 | Actual Loss: 0.4890\n",
      "Baseline Loss: 2.8089 | Actual Loss: 0.5229\n",
      "Baseline Loss: 2.8179 | Actual Loss: 0.1670\n",
      "Baseline Loss: 2.8312 | Actual Loss: 0.6875\n",
      "Baseline Loss: 2.8089 | Actual Loss: 0.5167\n",
      "Baseline Loss: 2.7824 | Actual Loss: 0.4030\n",
      "Baseline Loss: 2.8539 | Actual Loss: 0.5112\n",
      "Baseline Loss: 2.8046 | Actual Loss: 1.0387\n",
      "Baseline Loss: 2.4627 | Actual Loss: 0.2118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 78/1000 [00:49<09:36,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9000 | Actual Loss: 0.2567\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.7999\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.4964\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.3335\n",
      "Epoch 78/1000: Train Loss: 0.5059, Val Loss: 0.7216\n",
      "Baseline Loss: 2.8920 | Actual Loss: 1.0955\n",
      "Baseline Loss: 2.9108 | Actual Loss: 0.4367\n",
      "Baseline Loss: 2.8392 | Actual Loss: 0.2663\n",
      "Baseline Loss: 2.7765 | Actual Loss: 0.2801\n",
      "Baseline Loss: 2.8073 | Actual Loss: 0.2168\n",
      "Baseline Loss: 2.7718 | Actual Loss: 0.1928\n",
      "Baseline Loss: 2.7652 | Actual Loss: 0.3918\n",
      "Baseline Loss: 2.8524 | Actual Loss: 0.3779\n",
      "Baseline Loss: 2.7898 | Actual Loss: 0.2262\n",
      "Baseline Loss: 2.7925 | Actual Loss: 0.1927\n",
      "Baseline Loss: 2.7756 | Actual Loss: 0.3336\n",
      "Baseline Loss: 2.7938 | Actual Loss: 0.4636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 79/1000 [00:50<09:42,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8414 | Actual Loss: 1.0654\n",
      "Baseline Loss: 2.9017 | Actual Loss: 1.3815\n",
      "Baseline Loss: 2.8059 | Actual Loss: 0.1386\n",
      "Baseline Loss: 2.5300 | Actual Loss: 2.0773\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.5026\n",
      "Baseline Loss: 2.8053 | Actual Loss: 2.7458\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.3603\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.3808\n",
      "Epoch 79/1000: Train Loss: 0.5711, Val Loss: 0.9974\n",
      "Baseline Loss: 2.7790 | Actual Loss: 0.6241\n",
      "Baseline Loss: 2.8547 | Actual Loss: 0.8366\n",
      "Baseline Loss: 2.8294 | Actual Loss: 0.2394\n",
      "Baseline Loss: 2.8192 | Actual Loss: 0.5037\n",
      "Baseline Loss: 2.8639 | Actual Loss: 0.4710\n",
      "Baseline Loss: 2.7716 | Actual Loss: 0.4219\n",
      "Baseline Loss: 2.8159 | Actual Loss: 0.3332\n",
      "Baseline Loss: 2.8673 | Actual Loss: 0.4524\n",
      "Baseline Loss: 2.8107 | Actual Loss: 0.3858\n",
      "Baseline Loss: 2.8095 | Actual Loss: 0.2444\n",
      "Baseline Loss: 2.8390 | Actual Loss: 0.4959\n",
      "Baseline Loss: 2.8355 | Actual Loss: 1.3814\n",
      "Baseline Loss: 2.7556 | Actual Loss: 0.1602\n",
      "Baseline Loss: 2.8649 | Actual Loss: 0.3283\n",
      "Baseline Loss: 2.8636 | Actual Loss: 0.6650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 80/1000 [00:50<09:27,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6604 | Actual Loss: 2.1648\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.4864\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.9909\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.3254\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.3635\n",
      "Epoch 80/1000: Train Loss: 0.6068, Val Loss: 0.7915\n",
      "Baseline Loss: 2.8137 | Actual Loss: 1.3204\n",
      "Baseline Loss: 2.7968 | Actual Loss: 0.1402\n",
      "Baseline Loss: 2.8623 | Actual Loss: 1.4412\n",
      "Baseline Loss: 2.8352 | Actual Loss: 0.2741\n",
      "Baseline Loss: 2.7243 | Actual Loss: 2.0959\n",
      "Baseline Loss: 2.7860 | Actual Loss: 0.6075\n",
      "Baseline Loss: 2.8251 | Actual Loss: 1.7605\n",
      "Baseline Loss: 2.8327 | Actual Loss: 0.4637\n",
      "Baseline Loss: 2.7920 | Actual Loss: 0.3906\n",
      "Baseline Loss: 2.8044 | Actual Loss: 0.7256\n",
      "Baseline Loss: 2.8484 | Actual Loss: 0.1521\n",
      "Baseline Loss: 2.8497 | Actual Loss: 0.4311\n",
      "Baseline Loss: 2.8253 | Actual Loss: 0.2960\n",
      "Baseline Loss: 2.8419 | Actual Loss: 0.4633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 81/1000 [00:51<09:36,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8009 | Actual Loss: 1.3664\n",
      "Baseline Loss: 2.5924 | Actual Loss: 0.0742\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.3547\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.8519\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.4439\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.3268\n",
      "Epoch 81/1000: Train Loss: 0.7502, Val Loss: 0.7443\n",
      "Baseline Loss: 2.8904 | Actual Loss: 0.4266\n",
      "Baseline Loss: 2.8159 | Actual Loss: 0.2339\n",
      "Baseline Loss: 2.7914 | Actual Loss: 0.2773\n",
      "Baseline Loss: 2.8634 | Actual Loss: 0.4362\n",
      "Baseline Loss: 2.8108 | Actual Loss: 0.0869\n",
      "Baseline Loss: 2.8037 | Actual Loss: 0.2873\n",
      "Baseline Loss: 2.8157 | Actual Loss: 0.3845\n",
      "Baseline Loss: 2.7836 | Actual Loss: 0.0948\n",
      "Baseline Loss: 2.7900 | Actual Loss: 0.4358\n",
      "Baseline Loss: 2.8318 | Actual Loss: 0.3509\n",
      "Baseline Loss: 2.8490 | Actual Loss: 0.1955\n",
      "Baseline Loss: 2.8467 | Actual Loss: 0.3687\n",
      "Baseline Loss: 2.8105 | Actual Loss: 0.3759\n",
      "Baseline Loss: 2.8090 | Actual Loss: 0.1804\n",
      "Baseline Loss: 2.8421 | Actual Loss: 0.3691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 82/1000 [00:52<09:41,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5668 | Actual Loss: 1.9442\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.3090\n",
      "Baseline Loss: 2.8053 | Actual Loss: 0.9121\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.5490\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.3204\n",
      "Epoch 82/1000: Train Loss: 0.4030, Val Loss: 0.5226\n",
      "Baseline Loss: 2.8421 | Actual Loss: 1.8195\n",
      "Baseline Loss: 2.8071 | Actual Loss: 0.4529\n",
      "Baseline Loss: 2.8491 | Actual Loss: 0.3772\n",
      "Baseline Loss: 2.7958 | Actual Loss: 0.1496\n",
      "Baseline Loss: 2.7719 | Actual Loss: 0.3357\n",
      "Baseline Loss: 2.7952 | Actual Loss: 0.6501\n",
      "Baseline Loss: 2.7790 | Actual Loss: 0.3160\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.4597\n",
      "Baseline Loss: 2.8030 | Actual Loss: 0.2931\n",
      "Baseline Loss: 2.8374 | Actual Loss: 0.1826\n",
      "Baseline Loss: 2.8314 | Actual Loss: 0.2228\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.2862\n",
      "Baseline Loss: 2.7735 | Actual Loss: 0.2367\n",
      "Baseline Loss: 2.8158 | Actual Loss: 0.3595\n",
      "Baseline Loss: 2.7740 | Actual Loss: 0.3129\n",
      "Baseline Loss: 2.5859 | Actual Loss: 0.0719\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.2910\n",
      "Baseline Loss: 2.8053 | Actual Loss: 0.9017\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.5177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 83/1000 [00:52<09:26,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7244 | Actual Loss: 0.3631\n",
      "Epoch 83/1000: Train Loss: 0.4079, Val Loss: 0.5184\n",
      "Baseline Loss: 2.8390 | Actual Loss: 0.2839\n",
      "Baseline Loss: 2.7926 | Actual Loss: 0.9555\n",
      "Baseline Loss: 2.7985 | Actual Loss: 0.1240\n",
      "Baseline Loss: 2.8670 | Actual Loss: 0.3318\n",
      "Baseline Loss: 2.8300 | Actual Loss: 0.2108\n",
      "Baseline Loss: 2.8335 | Actual Loss: 1.0842\n",
      "Baseline Loss: 2.8561 | Actual Loss: 0.1423\n",
      "Baseline Loss: 2.8348 | Actual Loss: 0.3404\n",
      "Baseline Loss: 2.8078 | Actual Loss: 0.0649\n",
      "Baseline Loss: 2.7195 | Actual Loss: 0.1621\n",
      "Baseline Loss: 2.8257 | Actual Loss: 0.2172\n",
      "Baseline Loss: 2.7410 | Actual Loss: 0.2585\n",
      "Baseline Loss: 2.8672 | Actual Loss: 0.4172\n",
      "Baseline Loss: 2.8555 | Actual Loss: 0.5671\n",
      "Baseline Loss: 2.8511 | Actual Loss: 0.2103\n",
      "Baseline Loss: 2.6526 | Actual Loss: 0.2954\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.2854\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.2198\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.5102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 84/1000 [00:53<09:36,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7244 | Actual Loss: 0.4240\n",
      "Epoch 84/1000: Train Loss: 0.3541, Val Loss: 0.6099\n",
      "Baseline Loss: 2.8726 | Actual Loss: 0.2794\n",
      "Baseline Loss: 2.7725 | Actual Loss: 0.3498\n",
      "Baseline Loss: 2.7997 | Actual Loss: 0.3888\n",
      "Baseline Loss: 2.8811 | Actual Loss: 0.4617\n",
      "Baseline Loss: 2.7573 | Actual Loss: 0.2805\n",
      "Baseline Loss: 2.7955 | Actual Loss: 0.3343\n",
      "Baseline Loss: 2.8098 | Actual Loss: 0.3042\n",
      "Baseline Loss: 2.8422 | Actual Loss: 0.2575\n",
      "Baseline Loss: 2.8752 | Actual Loss: 0.1192\n",
      "Baseline Loss: 2.9006 | Actual Loss: 0.9433\n",
      "Baseline Loss: 2.7848 | Actual Loss: 0.1506\n",
      "Baseline Loss: 2.8071 | Actual Loss: 0.5147\n",
      "Baseline Loss: 2.7433 | Actual Loss: 0.2934\n",
      "Baseline Loss: 2.7837 | Actual Loss: 0.2451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 85/1000 [00:54<09:37,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8151 | Actual Loss: 0.3214\n",
      "Baseline Loss: 2.6992 | Actual Loss: 0.2844\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.2198\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.9001\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.4767\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.3614\n",
      "Epoch 85/1000: Train Loss: 0.3455, Val Loss: 0.7395\n",
      "Baseline Loss: 2.8624 | Actual Loss: 0.1331\n",
      "Baseline Loss: 2.7810 | Actual Loss: 0.4224\n",
      "Baseline Loss: 2.7894 | Actual Loss: 2.1768\n",
      "Baseline Loss: 2.7391 | Actual Loss: 0.2273\n",
      "Baseline Loss: 2.8092 | Actual Loss: 0.4192\n",
      "Baseline Loss: 2.9092 | Actual Loss: 0.4117\n",
      "Baseline Loss: 2.8975 | Actual Loss: 0.3080\n",
      "Baseline Loss: 2.8138 | Actual Loss: 0.2971\n",
      "Baseline Loss: 2.8427 | Actual Loss: 0.5494\n",
      "Baseline Loss: 2.7613 | Actual Loss: 0.2699\n",
      "Baseline Loss: 2.7732 | Actual Loss: 0.4543\n",
      "Baseline Loss: 2.8926 | Actual Loss: 0.1887\n",
      "Baseline Loss: 2.7972 | Actual Loss: 0.2403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▊         | 86/1000 [00:54<09:22,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8642 | Actual Loss: 0.2229\n",
      "Baseline Loss: 2.8188 | Actual Loss: 0.2098\n",
      "Baseline Loss: 2.4165 | Actual Loss: 0.0866\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.3350\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.3874\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.4736\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.3280\n",
      "Epoch 86/1000: Train Loss: 0.4136, Val Loss: 0.6310\n",
      "Baseline Loss: 2.7804 | Actual Loss: 0.1214\n",
      "Baseline Loss: 2.7568 | Actual Loss: 0.1708\n",
      "Baseline Loss: 2.7610 | Actual Loss: 0.2339\n",
      "Baseline Loss: 2.7807 | Actual Loss: 0.2733\n",
      "Baseline Loss: 2.8438 | Actual Loss: 0.1745\n",
      "Baseline Loss: 2.7972 | Actual Loss: 0.4321\n",
      "Baseline Loss: 2.8402 | Actual Loss: 0.5852\n",
      "Baseline Loss: 2.7977 | Actual Loss: 0.3607\n",
      "Baseline Loss: 2.8352 | Actual Loss: 0.5936\n",
      "Baseline Loss: 2.8683 | Actual Loss: 0.1969\n",
      "Baseline Loss: 2.8839 | Actual Loss: 0.3219\n",
      "Baseline Loss: 2.8691 | Actual Loss: 0.3501\n",
      "Baseline Loss: 2.8144 | Actual Loss: 0.1835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▊         | 87/1000 [00:55<09:33,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8439 | Actual Loss: 0.1777\n",
      "Baseline Loss: 2.8209 | Actual Loss: 0.3011\n",
      "Baseline Loss: 2.5335 | Actual Loss: 0.1744\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.3097\n",
      "Baseline Loss: 2.8053 | Actual Loss: 0.8974\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.4792\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.4106\n",
      "Epoch 87/1000: Train Loss: 0.2907, Val Loss: 0.5242\n",
      "Baseline Loss: 2.7715 | Actual Loss: 0.6240\n",
      "Baseline Loss: 2.7615 | Actual Loss: 0.4659\n",
      "Baseline Loss: 2.7695 | Actual Loss: 0.4675\n",
      "Baseline Loss: 2.7919 | Actual Loss: 0.2075\n",
      "Baseline Loss: 2.7894 | Actual Loss: 0.3946\n",
      "Baseline Loss: 2.8464 | Actual Loss: 0.2290\n",
      "Baseline Loss: 2.8237 | Actual Loss: 0.4157\n",
      "Baseline Loss: 2.8439 | Actual Loss: 0.2722\n",
      "Baseline Loss: 2.7836 | Actual Loss: 0.1429\n",
      "Baseline Loss: 2.8337 | Actual Loss: 0.2062\n",
      "Baseline Loss: 2.8364 | Actual Loss: 0.3795\n",
      "Baseline Loss: 2.8022 | Actual Loss: 0.0920\n",
      "Baseline Loss: 2.8512 | Actual Loss: 0.8130\n",
      "Baseline Loss: 2.9182 | Actual Loss: 0.2205\n",
      "Baseline Loss: 2.8882 | Actual Loss: 0.6953\n",
      "Baseline Loss: 2.5946 | Actual Loss: 1.6785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 88/1000 [00:55<09:19,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9000 | Actual Loss: 0.3430\n",
      "Baseline Loss: 2.8053 | Actual Loss: 0.8181\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.4792\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.4413\n",
      "Epoch 88/1000: Train Loss: 0.4565, Val Loss: 0.5204\n",
      "Baseline Loss: 2.7954 | Actual Loss: 0.2969\n",
      "Baseline Loss: 2.8447 | Actual Loss: 0.1508\n",
      "Baseline Loss: 2.8279 | Actual Loss: 0.7658\n",
      "Baseline Loss: 2.8281 | Actual Loss: 0.1112\n",
      "Baseline Loss: 2.8244 | Actual Loss: 0.3646\n",
      "Baseline Loss: 2.7899 | Actual Loss: 0.8264\n",
      "Baseline Loss: 2.8051 | Actual Loss: 0.7499\n",
      "Baseline Loss: 2.8351 | Actual Loss: 0.2102\n",
      "Baseline Loss: 2.7905 | Actual Loss: 0.2565\n",
      "Baseline Loss: 2.8145 | Actual Loss: 0.2875\n",
      "Baseline Loss: 2.8286 | Actual Loss: 0.5763\n",
      "Baseline Loss: 2.8721 | Actual Loss: 0.2147\n",
      "Baseline Loss: 2.7946 | Actual Loss: 0.2915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 89/1000 [00:56<09:39,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7421 | Actual Loss: 0.5085\n",
      "Baseline Loss: 2.8624 | Actual Loss: 0.2518\n",
      "Baseline Loss: 2.6171 | Actual Loss: 0.0361\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.2699\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.1302\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.4729\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.4085\n",
      "Epoch 89/1000: Train Loss: 0.3687, Val Loss: 0.5704\n",
      "Baseline Loss: 2.8113 | Actual Loss: 0.2402\n",
      "Baseline Loss: 2.8570 | Actual Loss: 0.1096\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.3143\n",
      "Baseline Loss: 2.8150 | Actual Loss: 0.1813\n",
      "Baseline Loss: 2.8707 | Actual Loss: 1.3546\n",
      "Baseline Loss: 2.8203 | Actual Loss: 1.6085\n",
      "Baseline Loss: 2.7870 | Actual Loss: 0.4321\n",
      "Baseline Loss: 2.8081 | Actual Loss: 0.0637\n",
      "Baseline Loss: 2.8970 | Actual Loss: 0.3441\n",
      "Baseline Loss: 2.7646 | Actual Loss: 0.2030\n",
      "Baseline Loss: 2.8343 | Actual Loss: 0.3900\n",
      "Baseline Loss: 2.8237 | Actual Loss: 0.3149\n",
      "Baseline Loss: 2.8172 | Actual Loss: 0.2557\n",
      "Baseline Loss: 2.8009 | Actual Loss: 0.1919\n",
      "Baseline Loss: 2.7925 | Actual Loss: 0.4024\n",
      "Baseline Loss: 2.4777 | Actual Loss: 0.0846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 90/1000 [00:57<09:37,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9000 | Actual Loss: 0.3159\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.6344\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.4755\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.4161\n",
      "Epoch 90/1000: Train Loss: 0.4057, Val Loss: 0.7105\n",
      "Baseline Loss: 2.8156 | Actual Loss: 0.1715\n",
      "Baseline Loss: 2.7554 | Actual Loss: 0.2044\n",
      "Baseline Loss: 2.8260 | Actual Loss: 0.1799\n",
      "Baseline Loss: 2.8313 | Actual Loss: 0.1707\n",
      "Baseline Loss: 2.8096 | Actual Loss: 0.3583\n",
      "Baseline Loss: 2.8579 | Actual Loss: 1.6773\n",
      "Baseline Loss: 2.7946 | Actual Loss: 0.3043\n",
      "Baseline Loss: 2.8087 | Actual Loss: 0.2399\n",
      "Baseline Loss: 2.7909 | Actual Loss: 0.3958\n",
      "Baseline Loss: 2.7974 | Actual Loss: 0.2114\n",
      "Baseline Loss: 2.8556 | Actual Loss: 0.2271\n",
      "Baseline Loss: 2.8113 | Actual Loss: 0.4112\n",
      "Baseline Loss: 2.8076 | Actual Loss: 0.4048\n",
      "Baseline Loss: 2.8524 | Actual Loss: 0.1894\n",
      "Baseline Loss: 2.8750 | Actual Loss: 0.2604\n",
      "Baseline Loss: 2.5890 | Actual Loss: 0.2419\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.4570\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.1339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 91/1000 [00:57<09:24,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8529 | Actual Loss: 0.4500\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.3096\n",
      "Epoch 91/1000: Train Loss: 0.3530, Val Loss: 0.5876\n",
      "Baseline Loss: 2.7962 | Actual Loss: 0.2762\n",
      "Baseline Loss: 2.8030 | Actual Loss: 0.2884\n",
      "Baseline Loss: 2.7982 | Actual Loss: 0.2510\n",
      "Baseline Loss: 2.8149 | Actual Loss: 0.3318\n",
      "Baseline Loss: 2.9029 | Actual Loss: 0.1128\n",
      "Baseline Loss: 2.8822 | Actual Loss: 0.2597\n",
      "Baseline Loss: 2.8555 | Actual Loss: 0.3913\n",
      "Baseline Loss: 2.7308 | Actual Loss: 0.2536\n",
      "Baseline Loss: 2.8355 | Actual Loss: 0.2627\n",
      "Baseline Loss: 2.8304 | Actual Loss: 0.2272\n",
      "Baseline Loss: 2.8125 | Actual Loss: 0.0753\n",
      "Baseline Loss: 2.8438 | Actual Loss: 0.4337\n",
      "Baseline Loss: 2.8532 | Actual Loss: 0.2150\n",
      "Baseline Loss: 2.8312 | Actual Loss: 0.3246\n",
      "Baseline Loss: 2.8868 | Actual Loss: 0.5983\n",
      "Baseline Loss: 2.4993 | Actual Loss: 0.5302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 92/1000 [00:58<09:42,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9000 | Actual Loss: 0.3281\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.0619\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.4780\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.4073\n",
      "Epoch 92/1000: Train Loss: 0.3020, Val Loss: 0.5688\n",
      "Baseline Loss: 2.8337 | Actual Loss: 0.2526\n",
      "Baseline Loss: 2.8318 | Actual Loss: 0.2604\n",
      "Baseline Loss: 2.8009 | Actual Loss: 0.2849\n",
      "Baseline Loss: 2.7637 | Actual Loss: 0.5601\n",
      "Baseline Loss: 2.8768 | Actual Loss: 0.5150\n",
      "Baseline Loss: 2.8301 | Actual Loss: 1.7833\n",
      "Baseline Loss: 2.7938 | Actual Loss: 0.2219\n",
      "Baseline Loss: 2.7209 | Actual Loss: 1.0410\n",
      "Baseline Loss: 2.7727 | Actual Loss: 0.1948\n",
      "Baseline Loss: 2.8681 | Actual Loss: 0.1734\n",
      "Baseline Loss: 2.9231 | Actual Loss: 0.3592\n",
      "Baseline Loss: 2.7910 | Actual Loss: 0.2511\n",
      "Baseline Loss: 2.8931 | Actual Loss: 0.5435\n",
      "Baseline Loss: 2.8114 | Actual Loss: 0.1916\n",
      "Baseline Loss: 2.7715 | Actual Loss: 0.2843\n",
      "Baseline Loss: 2.4562 | Actual Loss: 0.1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 93/1000 [00:59<09:45,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9000 | Actual Loss: 0.3457\n",
      "Baseline Loss: 2.8053 | Actual Loss: 0.8261\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.4801\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.4530\n",
      "Epoch 93/1000: Train Loss: 0.4392, Val Loss: 0.5262\n",
      "Baseline Loss: 2.7555 | Actual Loss: 0.1455\n",
      "Baseline Loss: 2.7839 | Actual Loss: 0.2360\n",
      "Baseline Loss: 2.7814 | Actual Loss: 0.0846\n",
      "Baseline Loss: 2.8926 | Actual Loss: 0.3002\n",
      "Baseline Loss: 2.9082 | Actual Loss: 0.1374\n",
      "Baseline Loss: 2.9123 | Actual Loss: 0.3222\n",
      "Baseline Loss: 2.8250 | Actual Loss: 0.3071\n",
      "Baseline Loss: 2.8290 | Actual Loss: 0.2105\n",
      "Baseline Loss: 2.7573 | Actual Loss: 0.0692\n",
      "Baseline Loss: 2.7733 | Actual Loss: 0.1036\n",
      "Baseline Loss: 2.7992 | Actual Loss: 0.6553\n",
      "Baseline Loss: 2.8565 | Actual Loss: 1.3938\n",
      "Baseline Loss: 2.8066 | Actual Loss: 0.4462\n",
      "Baseline Loss: 2.7638 | Actual Loss: 0.4308\n",
      "Baseline Loss: 2.8670 | Actual Loss: 0.2790\n",
      "Baseline Loss: 2.6647 | Actual Loss: 0.3865\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.4069\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.2026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 94/1000 [00:59<09:56,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8529 | Actual Loss: 0.5251\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.3499\n",
      "Epoch 94/1000: Train Loss: 0.3442, Val Loss: 0.6211\n",
      "Baseline Loss: 2.9221 | Actual Loss: 0.2290\n",
      "Baseline Loss: 2.7732 | Actual Loss: 0.1281\n",
      "Baseline Loss: 2.7990 | Actual Loss: 0.6420\n",
      "Baseline Loss: 2.8028 | Actual Loss: 0.1195\n",
      "Baseline Loss: 2.8140 | Actual Loss: 0.3736\n",
      "Baseline Loss: 2.8287 | Actual Loss: 0.2602\n",
      "Baseline Loss: 2.8296 | Actual Loss: 0.2128\n",
      "Baseline Loss: 2.7544 | Actual Loss: 0.3943\n",
      "Baseline Loss: 2.8392 | Actual Loss: 0.2354\n",
      "Baseline Loss: 2.8343 | Actual Loss: 0.4815\n",
      "Baseline Loss: 2.8486 | Actual Loss: 0.2065\n",
      "Baseline Loss: 2.8849 | Actual Loss: 0.2818\n",
      "Baseline Loss: 2.7557 | Actual Loss: 0.9785\n",
      "Baseline Loss: 2.8157 | Actual Loss: 0.3995\n",
      "Baseline Loss: 2.8156 | Actual Loss: 0.2973\n",
      "Baseline Loss: 2.6983 | Actual Loss: 1.2201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 95/1000 [01:00<09:33,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9000 | Actual Loss: 0.4193\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.1338\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.4780\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.3482\n",
      "Epoch 95/1000: Train Loss: 0.4038, Val Loss: 0.5948\n",
      "Baseline Loss: 2.8314 | Actual Loss: 0.0924\n",
      "Baseline Loss: 2.8638 | Actual Loss: 0.2517\n",
      "Baseline Loss: 2.8135 | Actual Loss: 0.1985\n",
      "Baseline Loss: 2.8151 | Actual Loss: 0.1436\n",
      "Baseline Loss: 2.8357 | Actual Loss: 0.9714\n",
      "Baseline Loss: 2.8114 | Actual Loss: 0.3009\n",
      "Baseline Loss: 2.8686 | Actual Loss: 0.1818\n",
      "Baseline Loss: 2.8333 | Actual Loss: 0.0977\n",
      "Baseline Loss: 2.8500 | Actual Loss: 0.3471\n",
      "Baseline Loss: 2.7361 | Actual Loss: 0.1286\n",
      "Baseline Loss: 2.7659 | Actual Loss: 0.1668\n",
      "Baseline Loss: 2.7793 | Actual Loss: 0.2945\n",
      "Baseline Loss: 2.8690 | Actual Loss: 0.4138\n",
      "Baseline Loss: 2.8736 | Actual Loss: 2.0995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 96/1000 [01:01<09:47,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8417 | Actual Loss: 0.4365\n",
      "Baseline Loss: 2.5883 | Actual Loss: 0.1526\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.2739\n",
      "Baseline Loss: 2.8053 | Actual Loss: 0.8747\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.4397\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.3692\n",
      "Epoch 96/1000: Train Loss: 0.3923, Val Loss: 0.4893\n",
      "Baseline Loss: 2.8026 | Actual Loss: 0.3364\n",
      "Baseline Loss: 2.8094 | Actual Loss: 0.1176\n",
      "Baseline Loss: 2.8080 | Actual Loss: 0.2115\n",
      "Baseline Loss: 2.7863 | Actual Loss: 0.1272\n",
      "Baseline Loss: 2.7974 | Actual Loss: 0.4961\n",
      "Baseline Loss: 2.8720 | Actual Loss: 0.1366\n",
      "Baseline Loss: 2.8864 | Actual Loss: 0.3241\n",
      "Baseline Loss: 2.8051 | Actual Loss: 0.5284\n",
      "Baseline Loss: 2.8611 | Actual Loss: 1.9918\n",
      "Baseline Loss: 2.7775 | Actual Loss: 0.2681\n",
      "Baseline Loss: 2.8108 | Actual Loss: 0.3967\n",
      "Baseline Loss: 2.8667 | Actual Loss: 0.1791\n",
      "Baseline Loss: 2.8706 | Actual Loss: 0.3303\n",
      "Baseline Loss: 2.7927 | Actual Loss: 1.3717\n",
      "Baseline Loss: 2.7885 | Actual Loss: 0.1715\n",
      "Baseline Loss: 2.4831 | Actual Loss: 0.3038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 97/1000 [01:01<09:36,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9000 | Actual Loss: 0.3327\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.0982\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.4774\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.4278\n",
      "Epoch 97/1000: Train Loss: 0.4557, Val Loss: 0.5840\n",
      "Baseline Loss: 2.8150 | Actual Loss: 0.7636\n",
      "Baseline Loss: 2.8444 | Actual Loss: 0.3119\n",
      "Baseline Loss: 2.7786 | Actual Loss: 2.0890\n",
      "Baseline Loss: 2.8162 | Actual Loss: 0.3761\n",
      "Baseline Loss: 2.7664 | Actual Loss: 0.3274\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.2148\n",
      "Baseline Loss: 2.7896 | Actual Loss: 0.2589\n",
      "Baseline Loss: 2.8025 | Actual Loss: 0.1874\n",
      "Baseline Loss: 2.8025 | Actual Loss: 0.0881\n",
      "Baseline Loss: 2.7865 | Actual Loss: 0.1763\n",
      "Baseline Loss: 2.8261 | Actual Loss: 0.2549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 98/1000 [01:02<09:30,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8187 | Actual Loss: 0.1243\n",
      "Baseline Loss: 2.8826 | Actual Loss: 0.3343\n",
      "Baseline Loss: 2.8070 | Actual Loss: 0.3748\n",
      "Baseline Loss: 2.9025 | Actual Loss: 0.3959\n",
      "Baseline Loss: 2.6604 | Actual Loss: 0.2544\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.3003\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.0292\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.3505\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.4062\n",
      "Epoch 98/1000: Train Loss: 0.4083, Val Loss: 0.5216\n",
      "Baseline Loss: 2.8185 | Actual Loss: 0.2063\n",
      "Baseline Loss: 2.8083 | Actual Loss: 0.1802\n",
      "Baseline Loss: 2.7837 | Actual Loss: 0.0746\n",
      "Baseline Loss: 2.8205 | Actual Loss: 0.4818\n",
      "Baseline Loss: 2.8545 | Actual Loss: 0.4133\n",
      "Baseline Loss: 2.7511 | Actual Loss: 0.1579\n",
      "Baseline Loss: 2.8094 | Actual Loss: 0.4077\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.1165\n",
      "Baseline Loss: 2.8035 | Actual Loss: 0.2144\n",
      "Baseline Loss: 2.8779 | Actual Loss: 0.1799\n",
      "Baseline Loss: 2.7663 | Actual Loss: 0.4190\n",
      "Baseline Loss: 2.7860 | Actual Loss: 0.1558\n",
      "Baseline Loss: 2.7991 | Actual Loss: 0.2052\n",
      "Baseline Loss: 2.7554 | Actual Loss: 0.4289\n",
      "Baseline Loss: 2.7934 | Actual Loss: 0.0766\n",
      "Baseline Loss: 2.5677 | Actual Loss: 0.1818\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.2412\n",
      "Baseline Loss: 2.8053 | Actual Loss: 2.1571\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.4543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 99/1000 [01:02<09:33,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7244 | Actual Loss: 0.3638\n",
      "Epoch 99/1000: Train Loss: 0.2437, Val Loss: 0.8041\n",
      "Baseline Loss: 2.7175 | Actual Loss: 0.1057\n",
      "Baseline Loss: 2.7617 | Actual Loss: 0.3530\n",
      "Baseline Loss: 2.8567 | Actual Loss: 1.6689\n",
      "Baseline Loss: 2.8258 | Actual Loss: 0.2034\n",
      "Baseline Loss: 2.7859 | Actual Loss: 0.1074\n",
      "Baseline Loss: 2.7611 | Actual Loss: 0.2175\n",
      "Baseline Loss: 2.8053 | Actual Loss: 0.1688\n",
      "Baseline Loss: 2.8477 | Actual Loss: 0.4787\n",
      "Baseline Loss: 2.9098 | Actual Loss: 0.4564\n",
      "Baseline Loss: 2.8202 | Actual Loss: 0.2638\n",
      "Baseline Loss: 2.8261 | Actual Loss: 0.0975\n",
      "Baseline Loss: 2.8501 | Actual Loss: 0.1725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 100/1000 [01:03<09:25,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8887 | Actual Loss: 0.2879\n",
      "Baseline Loss: 2.8140 | Actual Loss: 0.1724\n",
      "Baseline Loss: 2.8562 | Actual Loss: 0.3768\n",
      "Baseline Loss: 2.4594 | Actual Loss: 0.2458\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.3416\n",
      "Baseline Loss: 2.8053 | Actual Loss: 0.9131\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.5252\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.2538\n",
      "Epoch 100/1000: Train Loss: 0.3360, Val Loss: 0.5084\n",
      "Baseline Loss: 2.7550 | Actual Loss: 0.1739\n",
      "Baseline Loss: 2.8302 | Actual Loss: 0.1913\n",
      "Baseline Loss: 2.8294 | Actual Loss: 0.7163\n",
      "Baseline Loss: 2.8485 | Actual Loss: 0.1858\n",
      "Baseline Loss: 2.8590 | Actual Loss: 0.5761\n",
      "Baseline Loss: 2.7840 | Actual Loss: 0.3827\n",
      "Baseline Loss: 2.8170 | Actual Loss: 0.2234\n",
      "Baseline Loss: 2.9625 | Actual Loss: 0.4129\n",
      "Baseline Loss: 2.9156 | Actual Loss: 0.5035\n",
      "Baseline Loss: 2.7849 | Actual Loss: 1.2030\n",
      "Baseline Loss: 2.8226 | Actual Loss: 0.2899\n",
      "Baseline Loss: 2.8251 | Actual Loss: 0.3202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 101/1000 [01:04<09:26,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7979 | Actual Loss: 0.2532\n",
      "Baseline Loss: 2.8032 | Actual Loss: 0.1595\n",
      "Baseline Loss: 2.8276 | Actual Loss: 0.4244\n",
      "Baseline Loss: 2.4504 | Actual Loss: 0.1764\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.3114\n",
      "Baseline Loss: 2.8053 | Actual Loss: 0.7929\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.4793\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.4450\n",
      "Epoch 101/1000: Train Loss: 0.3870, Val Loss: 0.5072\n",
      "Baseline Loss: 2.8245 | Actual Loss: 0.1543\n",
      "Baseline Loss: 2.8724 | Actual Loss: 0.6465\n",
      "Baseline Loss: 2.7750 | Actual Loss: 0.4896\n",
      "Baseline Loss: 2.7821 | Actual Loss: 0.2888\n",
      "Baseline Loss: 2.8392 | Actual Loss: 0.4920\n",
      "Baseline Loss: 2.7872 | Actual Loss: 0.8293\n",
      "Baseline Loss: 2.8669 | Actual Loss: 0.3278\n",
      "Baseline Loss: 2.7972 | Actual Loss: 0.3556\n",
      "Baseline Loss: 2.8060 | Actual Loss: 0.3690\n",
      "Baseline Loss: 2.8060 | Actual Loss: 0.6088\n",
      "Baseline Loss: 2.7815 | Actual Loss: 0.2491\n",
      "Baseline Loss: 2.8010 | Actual Loss: 0.2970\n",
      "Baseline Loss: 2.8774 | Actual Loss: 0.5232\n",
      "Baseline Loss: 2.8049 | Actual Loss: 0.1590\n",
      "Baseline Loss: 2.8616 | Actual Loss: 0.4052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 102/1000 [01:04<09:12,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5332 | Actual Loss: 1.9869\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.3097\n",
      "Baseline Loss: 2.8053 | Actual Loss: 0.8809\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.4785\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.4785\n",
      "Epoch 102/1000: Train Loss: 0.5114, Val Loss: 0.5369\n",
      "Baseline Loss: 2.8035 | Actual Loss: 0.2386\n",
      "Baseline Loss: 2.7783 | Actual Loss: 0.2565\n",
      "Baseline Loss: 2.8134 | Actual Loss: 0.4852\n",
      "Baseline Loss: 2.8731 | Actual Loss: 0.6626\n",
      "Baseline Loss: 2.8205 | Actual Loss: 0.3588\n",
      "Baseline Loss: 2.7965 | Actual Loss: 0.2637\n",
      "Baseline Loss: 2.8505 | Actual Loss: 0.3940\n",
      "Baseline Loss: 2.8335 | Actual Loss: 1.2941\n",
      "Baseline Loss: 2.8364 | Actual Loss: 0.4044\n",
      "Baseline Loss: 2.8084 | Actual Loss: 0.3336\n",
      "Baseline Loss: 2.8043 | Actual Loss: 0.4133\n",
      "Baseline Loss: 2.8052 | Actual Loss: 0.1810\n",
      "Baseline Loss: 2.7964 | Actual Loss: 0.1131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 103/1000 [01:05<09:25,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7879 | Actual Loss: 0.2594\n",
      "Baseline Loss: 2.7962 | Actual Loss: 0.1108\n",
      "Baseline Loss: 2.6263 | Actual Loss: 0.2829\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.3639\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.5048\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.4631\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.4220\n",
      "Epoch 103/1000: Train Loss: 0.3783, Val Loss: 0.6885\n",
      "Baseline Loss: 2.8622 | Actual Loss: 0.2206\n",
      "Baseline Loss: 2.7907 | Actual Loss: 0.0831\n",
      "Baseline Loss: 2.9206 | Actual Loss: 0.2097\n",
      "Baseline Loss: 2.8013 | Actual Loss: 1.7354\n",
      "Baseline Loss: 2.8740 | Actual Loss: 0.2632\n",
      "Baseline Loss: 2.7718 | Actual Loss: 0.1746\n",
      "Baseline Loss: 2.8390 | Actual Loss: 0.3057\n",
      "Baseline Loss: 2.8157 | Actual Loss: 0.1649\n",
      "Baseline Loss: 2.8443 | Actual Loss: 0.4971\n",
      "Baseline Loss: 2.7770 | Actual Loss: 0.2177\n",
      "Baseline Loss: 2.8615 | Actual Loss: 0.4375\n",
      "Baseline Loss: 2.7441 | Actual Loss: 0.3393\n",
      "Baseline Loss: 2.8820 | Actual Loss: 0.3695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 103/1000 [01:06<09:35,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8501 | Actual Loss: 0.2862\n",
      "Baseline Loss: 2.7895 | Actual Loss: 0.1901\n",
      "Baseline Loss: 2.4568 | Actual Loss: 1.1143\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.3170\n",
      "Baseline Loss: 2.8053 | Actual Loss: 0.9306\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.4931\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.2883\n",
      "Epoch 104/1000: Train Loss: 0.4130, Val Loss: 0.5073\n",
      "\n",
      "Early stopping at epoch 104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4542819857597351"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devices = [\"cuda\" if torch.cuda.is_available() else \"cpu\"]\n",
    "model7 = GNNModelWithNewLoss(\n",
    "        num_node_features=data_list[0].x.shape[1],\n",
    "        num_edge_features=data_list[0].edge_attr.shape[1],\n",
    "        num_global_features=0,\n",
    "        cov_num= 9,\n",
    "        hidden_dim=512,\n",
    "        dropout_rate=0.1,\n",
    "        property_index= 0,\n",
    "        save_path= 'premodels_new_og/9/0' \n",
    "    ).to(devices[0])\n",
    "\n",
    "model7.train_model(\n",
    "    data_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc31e0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training will be saved to: premodels_new_og/9/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6961 | Actual Loss: 2.6897\n",
      "Baseline Loss: 2.6464 | Actual Loss: 2.6544\n",
      "Baseline Loss: 2.6599 | Actual Loss: 2.6441\n",
      "Baseline Loss: 2.6713 | Actual Loss: 2.6371\n",
      "Baseline Loss: 2.6661 | Actual Loss: 2.5639\n",
      "Baseline Loss: 2.6340 | Actual Loss: 2.5322\n",
      "Baseline Loss: 2.6645 | Actual Loss: 2.5437\n",
      "Baseline Loss: 2.6880 | Actual Loss: 2.4696\n",
      "Baseline Loss: 2.6835 | Actual Loss: 2.3356\n",
      "Baseline Loss: 2.7078 | Actual Loss: 2.2561\n",
      "Baseline Loss: 2.6859 | Actual Loss: 2.1988\n",
      "Baseline Loss: 2.6583 | Actual Loss: 2.1652\n",
      "Baseline Loss: 2.7007 | Actual Loss: 2.0843\n",
      "Baseline Loss: 2.6370 | Actual Loss: 1.8808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 1/1000 [00:00<09:26,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6766 | Actual Loss: 2.0808\n",
      "Baseline Loss: 2.2585 | Actual Loss: 1.5543\n",
      "Baseline Loss: 2.6755 | Actual Loss: 1.9744\n",
      "Baseline Loss: 2.6640 | Actual Loss: 1.8117\n",
      "Baseline Loss: 2.6853 | Actual Loss: 1.9864\n",
      "Baseline Loss: 2.6128 | Actual Loss: 1.7182\n",
      "Epoch 1/1000: Train Loss: 2.3307, Val Loss: 1.8727\n",
      "New best validation loss: 1.8727\n",
      "Baseline Loss: 2.6712 | Actual Loss: 1.9185\n",
      "Baseline Loss: 2.6387 | Actual Loss: 1.8555\n",
      "Baseline Loss: 2.6863 | Actual Loss: 1.7829\n",
      "Baseline Loss: 2.7229 | Actual Loss: 1.7878\n",
      "Baseline Loss: 2.6493 | Actual Loss: 1.8600\n",
      "Baseline Loss: 2.6547 | Actual Loss: 1.8872\n",
      "Baseline Loss: 2.6422 | Actual Loss: 1.7520\n",
      "Baseline Loss: 2.6564 | Actual Loss: 1.6600\n",
      "Baseline Loss: 2.6610 | Actual Loss: 1.8790\n",
      "Baseline Loss: 2.6525 | Actual Loss: 1.7701\n",
      "Baseline Loss: 2.6558 | Actual Loss: 1.7508\n",
      "Baseline Loss: 2.7208 | Actual Loss: 1.8384\n",
      "Baseline Loss: 2.6450 | Actual Loss: 1.6180\n",
      "Baseline Loss: 2.6988 | Actual Loss: 1.7068\n",
      "Baseline Loss: 2.6805 | Actual Loss: 1.7483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 2/1000 [00:01<10:05,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2860 | Actual Loss: 1.3756\n",
      "Baseline Loss: 2.6755 | Actual Loss: 1.7031\n",
      "Baseline Loss: 2.6640 | Actual Loss: 1.5690\n",
      "Baseline Loss: 2.6853 | Actual Loss: 1.7679\n",
      "Baseline Loss: 2.6128 | Actual Loss: 1.5934\n",
      "Epoch 2/1000: Train Loss: 1.7619, Val Loss: 1.6584\n",
      "New best validation loss: 1.6584\n",
      "Baseline Loss: 2.6853 | Actual Loss: 1.6128\n",
      "Baseline Loss: 2.6853 | Actual Loss: 1.6375\n",
      "Baseline Loss: 2.7035 | Actual Loss: 1.6448\n",
      "Baseline Loss: 2.6972 | Actual Loss: 1.6038\n",
      "Baseline Loss: 2.6634 | Actual Loss: 1.6432\n",
      "Baseline Loss: 2.6502 | Actual Loss: 1.6804\n",
      "Baseline Loss: 2.6420 | Actual Loss: 1.6234\n",
      "Baseline Loss: 2.6663 | Actual Loss: 1.6121\n",
      "Baseline Loss: 2.6587 | Actual Loss: 1.8060\n",
      "Baseline Loss: 2.6765 | Actual Loss: 1.5726\n",
      "Baseline Loss: 2.6454 | Actual Loss: 1.5344\n",
      "Baseline Loss: 2.6605 | Actual Loss: 1.5031\n",
      "Baseline Loss: 2.6715 | Actual Loss: 1.8505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 3/1000 [00:01<10:52,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6925 | Actual Loss: 1.8870\n",
      "Baseline Loss: 2.6424 | Actual Loss: 1.8230\n",
      "Baseline Loss: 2.2633 | Actual Loss: 1.1417\n",
      "Baseline Loss: 2.6755 | Actual Loss: 1.4812\n",
      "Baseline Loss: 2.6640 | Actual Loss: 1.4623\n",
      "Baseline Loss: 2.6853 | Actual Loss: 1.5898\n",
      "Baseline Loss: 2.6128 | Actual Loss: 1.2571\n",
      "Epoch 3/1000: Train Loss: 1.6360, Val Loss: 1.4476\n",
      "New best validation loss: 1.4476\n",
      "Baseline Loss: 2.6557 | Actual Loss: 1.6146\n",
      "Baseline Loss: 2.6838 | Actual Loss: 1.5824\n",
      "Baseline Loss: 2.6808 | Actual Loss: 1.7092\n",
      "Baseline Loss: 2.6885 | Actual Loss: 1.5643\n",
      "Baseline Loss: 2.6583 | Actual Loss: 1.5557\n",
      "Baseline Loss: 2.7001 | Actual Loss: 1.6523\n",
      "Baseline Loss: 2.6849 | Actual Loss: 1.6835\n",
      "Baseline Loss: 2.6616 | Actual Loss: 1.5693\n",
      "Baseline Loss: 2.6783 | Actual Loss: 1.3262\n",
      "Baseline Loss: 2.6345 | Actual Loss: 1.4343\n",
      "Baseline Loss: 2.6717 | Actual Loss: 1.2687\n",
      "Baseline Loss: 2.6697 | Actual Loss: 1.3375\n",
      "Baseline Loss: 2.6841 | Actual Loss: 1.1781\n",
      "Baseline Loss: 2.6930 | Actual Loss: 1.1235\n",
      "Baseline Loss: 2.6873 | Actual Loss: 1.2115\n",
      "Baseline Loss: 2.3226 | Actual Loss: 1.0408\n",
      "Baseline Loss: 2.6755 | Actual Loss: 1.3710\n",
      "Baseline Loss: 2.6640 | Actual Loss: 1.1401\n",
      "Baseline Loss: 2.6853 | Actual Loss: 1.4533\n",
      "Baseline Loss: 2.6128 | Actual Loss: 1.1448\n",
      "Epoch 4/1000: Train Loss: 1.4282, Val Loss: 1.2773\n",
      "New best validation loss: 1.2773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 4/1000 [00:02<10:55,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6648 | Actual Loss: 1.5467\n",
      "Baseline Loss: 2.6518 | Actual Loss: 1.7011\n",
      "Baseline Loss: 2.6738 | Actual Loss: 1.1826\n",
      "Baseline Loss: 2.6385 | Actual Loss: 1.0060\n",
      "Baseline Loss: 2.6698 | Actual Loss: 1.3464\n",
      "Baseline Loss: 2.6908 | Actual Loss: 1.2982\n",
      "Baseline Loss: 2.7007 | Actual Loss: 1.1423\n",
      "Baseline Loss: 2.6503 | Actual Loss: 0.9766\n",
      "Baseline Loss: 2.7113 | Actual Loss: 0.8615\n",
      "Baseline Loss: 2.6769 | Actual Loss: 1.3511\n",
      "Baseline Loss: 2.6790 | Actual Loss: 1.0941\n",
      "Baseline Loss: 2.6559 | Actual Loss: 1.1610\n",
      "Baseline Loss: 2.6790 | Actual Loss: 0.9744\n",
      "Baseline Loss: 2.6778 | Actual Loss: 1.1049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 5/1000 [00:03<10:17,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6545 | Actual Loss: 1.0444\n",
      "Baseline Loss: 2.2744 | Actual Loss: 0.9072\n",
      "Baseline Loss: 2.6755 | Actual Loss: 1.2582\n",
      "Baseline Loss: 2.6640 | Actual Loss: 1.1422\n",
      "Baseline Loss: 2.6853 | Actual Loss: 1.1448\n",
      "Baseline Loss: 2.6128 | Actual Loss: 1.0613\n",
      "Epoch 5/1000: Train Loss: 1.1686, Val Loss: 1.1516\n",
      "New best validation loss: 1.1516\n",
      "Baseline Loss: 2.6865 | Actual Loss: 1.2194\n",
      "Baseline Loss: 2.6266 | Actual Loss: 0.9451\n",
      "Baseline Loss: 2.6643 | Actual Loss: 1.0389\n",
      "Baseline Loss: 2.6752 | Actual Loss: 1.1284\n",
      "Baseline Loss: 2.6582 | Actual Loss: 0.8869\n",
      "Baseline Loss: 2.6891 | Actual Loss: 1.2956\n",
      "Baseline Loss: 2.6718 | Actual Loss: 1.1963\n",
      "Baseline Loss: 2.6954 | Actual Loss: 1.0468\n",
      "Baseline Loss: 2.6626 | Actual Loss: 0.9654\n",
      "Baseline Loss: 2.6505 | Actual Loss: 1.2282\n",
      "Baseline Loss: 2.6690 | Actual Loss: 1.0070\n",
      "Baseline Loss: 2.6552 | Actual Loss: 0.9114\n",
      "Baseline Loss: 2.6594 | Actual Loss: 1.1919\n",
      "Baseline Loss: 2.6662 | Actual Loss: 0.9177\n",
      "Baseline Loss: 2.6997 | Actual Loss: 1.0150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 6/1000 [00:03<10:41,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2972 | Actual Loss: 0.4793\n",
      "Baseline Loss: 2.6755 | Actual Loss: 1.3014\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.9609\n",
      "Baseline Loss: 2.6853 | Actual Loss: 1.0368\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.8418\n",
      "Epoch 6/1000: Train Loss: 1.0296, Val Loss: 1.0352\n",
      "New best validation loss: 1.0352\n",
      "Baseline Loss: 2.7064 | Actual Loss: 1.1036\n",
      "Baseline Loss: 2.6478 | Actual Loss: 1.2564\n",
      "Baseline Loss: 2.6743 | Actual Loss: 1.0327\n",
      "Baseline Loss: 2.6413 | Actual Loss: 0.8952\n",
      "Baseline Loss: 2.6496 | Actual Loss: 0.6605\n",
      "Baseline Loss: 2.7084 | Actual Loss: 1.2049\n",
      "Baseline Loss: 2.6978 | Actual Loss: 1.1988\n",
      "Baseline Loss: 2.7385 | Actual Loss: 1.1385\n",
      "Baseline Loss: 2.6638 | Actual Loss: 0.8118\n",
      "Baseline Loss: 2.6652 | Actual Loss: 1.1095\n",
      "Baseline Loss: 2.6903 | Actual Loss: 0.8673\n",
      "Baseline Loss: 2.6614 | Actual Loss: 1.0541\n",
      "Baseline Loss: 2.6501 | Actual Loss: 1.0625\n",
      "Baseline Loss: 2.6559 | Actual Loss: 1.0941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 7/1000 [00:04<10:51,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6684 | Actual Loss: 1.0325\n",
      "Baseline Loss: 2.2392 | Actual Loss: 0.9582\n",
      "Baseline Loss: 2.6755 | Actual Loss: 1.3062\n",
      "Baseline Loss: 2.6640 | Actual Loss: 1.0487\n",
      "Baseline Loss: 2.6853 | Actual Loss: 1.1728\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.7795\n",
      "Epoch 7/1000: Train Loss: 1.0300, Val Loss: 1.0768\n",
      "Baseline Loss: 2.6703 | Actual Loss: 1.0884\n",
      "Baseline Loss: 2.6832 | Actual Loss: 0.8714\n",
      "Baseline Loss: 2.6674 | Actual Loss: 0.6470\n",
      "Baseline Loss: 2.6533 | Actual Loss: 0.9398\n",
      "Baseline Loss: 2.6962 | Actual Loss: 0.7963\n",
      "Baseline Loss: 2.6808 | Actual Loss: 1.1464\n",
      "Baseline Loss: 2.6639 | Actual Loss: 1.2629\n",
      "Baseline Loss: 2.6649 | Actual Loss: 1.1243\n",
      "Baseline Loss: 2.7005 | Actual Loss: 1.0089\n",
      "Baseline Loss: 2.6821 | Actual Loss: 0.9959\n",
      "Baseline Loss: 2.6780 | Actual Loss: 0.7581\n",
      "Baseline Loss: 2.7012 | Actual Loss: 0.9178\n",
      "Baseline Loss: 2.6844 | Actual Loss: 1.1401\n",
      "Baseline Loss: 2.6544 | Actual Loss: 0.8239\n",
      "Baseline Loss: 2.6576 | Actual Loss: 0.8662\n",
      "Baseline Loss: 2.2507 | Actual Loss: 0.2949\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.9856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 8/1000 [00:05<10:16,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6640 | Actual Loss: 0.9479\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.8714\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.9148\n",
      "Epoch 8/1000: Train Loss: 0.9176, Val Loss: 0.9299\n",
      "New best validation loss: 0.9299\n",
      "Baseline Loss: 2.6293 | Actual Loss: 1.0246\n",
      "Baseline Loss: 2.7041 | Actual Loss: 0.8493\n",
      "Baseline Loss: 2.6696 | Actual Loss: 0.8502\n",
      "Baseline Loss: 2.6778 | Actual Loss: 1.1676\n",
      "Baseline Loss: 2.6838 | Actual Loss: 0.9307\n",
      "Baseline Loss: 2.6521 | Actual Loss: 0.9976\n",
      "Baseline Loss: 2.6636 | Actual Loss: 1.1045\n",
      "Baseline Loss: 2.6199 | Actual Loss: 1.0791\n",
      "Baseline Loss: 2.6818 | Actual Loss: 0.6643\n",
      "Baseline Loss: 2.6744 | Actual Loss: 0.7066\n",
      "Baseline Loss: 2.6588 | Actual Loss: 0.9827\n",
      "Baseline Loss: 2.6827 | Actual Loss: 0.6947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 9/1000 [00:05<10:32,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6695 | Actual Loss: 1.2907\n",
      "Baseline Loss: 2.6448 | Actual Loss: 0.7309\n",
      "Baseline Loss: 2.6665 | Actual Loss: 0.7816\n",
      "Baseline Loss: 2.3687 | Actual Loss: 0.4530\n",
      "Baseline Loss: 2.6755 | Actual Loss: 1.1159\n",
      "Baseline Loss: 2.6640 | Actual Loss: 1.0817\n",
      "Baseline Loss: 2.6853 | Actual Loss: 1.0300\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.7727\n",
      "Epoch 9/1000: Train Loss: 0.8943, Val Loss: 1.0001\n",
      "Baseline Loss: 2.6820 | Actual Loss: 0.9530\n",
      "Baseline Loss: 2.6966 | Actual Loss: 0.8576\n",
      "Baseline Loss: 2.6102 | Actual Loss: 1.1487\n",
      "Baseline Loss: 2.6717 | Actual Loss: 0.6393\n",
      "Baseline Loss: 2.6750 | Actual Loss: 0.7173\n",
      "Baseline Loss: 2.6772 | Actual Loss: 0.9939\n",
      "Baseline Loss: 2.6822 | Actual Loss: 0.8378\n",
      "Baseline Loss: 2.6939 | Actual Loss: 0.4498\n",
      "Baseline Loss: 2.6831 | Actual Loss: 0.6507\n",
      "Baseline Loss: 2.6721 | Actual Loss: 1.2368\n",
      "Baseline Loss: 2.6603 | Actual Loss: 0.9299\n",
      "Baseline Loss: 2.7092 | Actual Loss: 0.6029\n",
      "Baseline Loss: 2.6491 | Actual Loss: 0.9775\n",
      "Baseline Loss: 2.6664 | Actual Loss: 0.5891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 10/1000 [00:06<10:41,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6579 | Actual Loss: 0.7216\n",
      "Baseline Loss: 2.2242 | Actual Loss: 0.5964\n",
      "Baseline Loss: 2.6755 | Actual Loss: 1.9366\n",
      "Baseline Loss: 2.6640 | Actual Loss: 1.1393\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5124\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.7425\n",
      "Epoch 10/1000: Train Loss: 0.8064, Val Loss: 1.0827\n",
      "Baseline Loss: 2.7004 | Actual Loss: 1.4807\n",
      "Baseline Loss: 2.6430 | Actual Loss: 1.2720\n",
      "Baseline Loss: 2.6837 | Actual Loss: 1.3154\n",
      "Baseline Loss: 2.6420 | Actual Loss: 0.8462\n",
      "Baseline Loss: 2.6892 | Actual Loss: 1.1132\n",
      "Baseline Loss: 2.6806 | Actual Loss: 0.7478\n",
      "Baseline Loss: 2.6283 | Actual Loss: 0.7589\n",
      "Baseline Loss: 2.6631 | Actual Loss: 0.8363\n",
      "Baseline Loss: 2.6692 | Actual Loss: 1.1334\n",
      "Baseline Loss: 2.6698 | Actual Loss: 0.7365\n",
      "Baseline Loss: 2.6693 | Actual Loss: 0.3780\n",
      "Baseline Loss: 2.6692 | Actual Loss: 0.9134\n",
      "Baseline Loss: 2.6526 | Actual Loss: 0.6971\n",
      "Baseline Loss: 2.6668 | Actual Loss: 0.7121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 11/1000 [00:07<10:32,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6809 | Actual Loss: 1.4193\n",
      "Baseline Loss: 2.2215 | Actual Loss: 0.4556\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.9492\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.9012\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.7724\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.6563\n",
      "Epoch 11/1000: Train Loss: 0.9260, Val Loss: 0.8198\n",
      "New best validation loss: 0.8198\n",
      "Baseline Loss: 2.6553 | Actual Loss: 0.5720\n",
      "Baseline Loss: 2.6884 | Actual Loss: 0.9748\n",
      "Baseline Loss: 2.7044 | Actual Loss: 0.6114\n",
      "Baseline Loss: 2.6817 | Actual Loss: 1.1771\n",
      "Baseline Loss: 2.6747 | Actual Loss: 0.9264\n",
      "Baseline Loss: 2.6637 | Actual Loss: 0.9668\n",
      "Baseline Loss: 2.6449 | Actual Loss: 0.7580\n",
      "Baseline Loss: 2.6414 | Actual Loss: 0.7501\n",
      "Baseline Loss: 2.6601 | Actual Loss: 0.8754\n",
      "Baseline Loss: 2.6593 | Actual Loss: 0.9028\n",
      "Baseline Loss: 2.6467 | Actual Loss: 0.7120\n",
      "Baseline Loss: 2.7110 | Actual Loss: 0.5859\n",
      "Baseline Loss: 2.6912 | Actual Loss: 0.6909\n",
      "Baseline Loss: 2.6863 | Actual Loss: 0.4248\n",
      "Baseline Loss: 2.7217 | Actual Loss: 0.8152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 12/1000 [00:07<10:40,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2227 | Actual Loss: 0.4078\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.7137\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.9231\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.7050\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.6976\n",
      "Epoch 12/1000: Train Loss: 0.7595, Val Loss: 0.7598\n",
      "New best validation loss: 0.7598\n",
      "Baseline Loss: 2.6954 | Actual Loss: 0.7965\n",
      "Baseline Loss: 2.6777 | Actual Loss: 0.8049\n",
      "Baseline Loss: 2.6844 | Actual Loss: 0.9691\n",
      "Baseline Loss: 2.6437 | Actual Loss: 0.9746\n",
      "Baseline Loss: 2.6563 | Actual Loss: 0.4496\n",
      "Baseline Loss: 2.6395 | Actual Loss: 0.9644\n",
      "Baseline Loss: 2.7236 | Actual Loss: 0.6155\n",
      "Baseline Loss: 2.6492 | Actual Loss: 0.4142\n",
      "Baseline Loss: 2.6795 | Actual Loss: 1.8033\n",
      "Baseline Loss: 2.6797 | Actual Loss: 1.6280\n",
      "Baseline Loss: 2.6545 | Actual Loss: 1.1292\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.6916\n",
      "Baseline Loss: 2.6810 | Actual Loss: 0.6709\n",
      "Baseline Loss: 2.6622 | Actual Loss: 0.8666\n",
      "Baseline Loss: 2.6811 | Actual Loss: 0.9514\n",
      "Baseline Loss: 2.2726 | Actual Loss: 0.7155\n",
      "Baseline Loss: 2.6755 | Actual Loss: 1.0414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏         | 13/1000 [00:08<10:08,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6640 | Actual Loss: 1.0091\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.9819\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.8460\n",
      "Epoch 13/1000: Train Loss: 0.9028, Val Loss: 0.9696\n",
      "Baseline Loss: 2.7121 | Actual Loss: 0.8171\n",
      "Baseline Loss: 2.6602 | Actual Loss: 1.0674\n",
      "Baseline Loss: 2.6609 | Actual Loss: 0.6981\n",
      "Baseline Loss: 2.7287 | Actual Loss: 0.6517\n",
      "Baseline Loss: 2.6854 | Actual Loss: 1.0932\n",
      "Baseline Loss: 2.6663 | Actual Loss: 0.9678\n",
      "Baseline Loss: 2.6757 | Actual Loss: 0.9727\n",
      "Baseline Loss: 2.6527 | Actual Loss: 0.5658\n",
      "Baseline Loss: 2.6396 | Actual Loss: 0.7480\n",
      "Baseline Loss: 2.6972 | Actual Loss: 0.6439\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.7744\n",
      "Baseline Loss: 2.6760 | Actual Loss: 0.9263\n",
      "Baseline Loss: 2.6511 | Actual Loss: 0.6496\n",
      "Baseline Loss: 2.6733 | Actual Loss: 0.9656\n",
      "Baseline Loss: 2.6947 | Actual Loss: 0.4827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏         | 14/1000 [00:08<10:31,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2564 | Actual Loss: 0.2256\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.8211\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.9181\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.7182\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.4941\n",
      "Epoch 14/1000: Train Loss: 0.7656, Val Loss: 0.7379\n",
      "New best validation loss: 0.7379\n",
      "Baseline Loss: 2.6787 | Actual Loss: 0.7441\n",
      "Baseline Loss: 2.6892 | Actual Loss: 0.6811\n",
      "Baseline Loss: 2.6992 | Actual Loss: 0.7354\n",
      "Baseline Loss: 2.6596 | Actual Loss: 1.1019\n",
      "Baseline Loss: 2.6798 | Actual Loss: 0.8777\n",
      "Baseline Loss: 2.6534 | Actual Loss: 1.0586\n",
      "Baseline Loss: 2.6630 | Actual Loss: 0.7003\n",
      "Baseline Loss: 2.6753 | Actual Loss: 0.5349\n",
      "Baseline Loss: 2.6687 | Actual Loss: 0.3466\n",
      "Baseline Loss: 2.6972 | Actual Loss: 0.5610\n",
      "Baseline Loss: 2.6382 | Actual Loss: 0.6740\n",
      "Baseline Loss: 2.6817 | Actual Loss: 0.7946\n",
      "Baseline Loss: 2.6859 | Actual Loss: 0.6513\n",
      "Baseline Loss: 2.6726 | Actual Loss: 0.9058\n",
      "Baseline Loss: 2.6387 | Actual Loss: 0.5143\n",
      "Baseline Loss: 2.3202 | Actual Loss: 0.3001\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.6374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 15/1000 [00:09<10:29,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6640 | Actual Loss: 0.8938\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.7674\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3517\n",
      "Epoch 15/1000: Train Loss: 0.6989, Val Loss: 0.6626\n",
      "New best validation loss: 0.6626\n",
      "Baseline Loss: 2.6624 | Actual Loss: 0.7352\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.7568\n",
      "Baseline Loss: 2.6801 | Actual Loss: 0.6232\n",
      "Baseline Loss: 2.6619 | Actual Loss: 0.7283\n",
      "Baseline Loss: 2.6579 | Actual Loss: 0.6129\n",
      "Baseline Loss: 2.6836 | Actual Loss: 0.7469\n",
      "Baseline Loss: 2.6917 | Actual Loss: 0.7525\n",
      "Baseline Loss: 2.6568 | Actual Loss: 0.5255\n",
      "Baseline Loss: 2.6641 | Actual Loss: 0.6435\n",
      "Baseline Loss: 2.6568 | Actual Loss: 0.8674\n",
      "Baseline Loss: 2.7222 | Actual Loss: 0.7880\n",
      "Baseline Loss: 2.6932 | Actual Loss: 0.8368\n",
      "Baseline Loss: 2.6717 | Actual Loss: 0.7512\n",
      "Baseline Loss: 2.6534 | Actual Loss: 0.6560\n",
      "Baseline Loss: 2.6670 | Actual Loss: 1.1186\n",
      "Baseline Loss: 2.2753 | Actual Loss: 0.6898\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.9170\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.9228\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.7927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 16/1000 [00:10<10:16,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6128 | Actual Loss: 0.5346\n",
      "Epoch 16/1000: Train Loss: 0.7395, Val Loss: 0.7918\n",
      "Baseline Loss: 2.7048 | Actual Loss: 0.7037\n",
      "Baseline Loss: 2.6523 | Actual Loss: 0.7312\n",
      "Baseline Loss: 2.7182 | Actual Loss: 0.7849\n",
      "Baseline Loss: 2.6962 | Actual Loss: 1.2511\n",
      "Baseline Loss: 2.6919 | Actual Loss: 1.2627\n",
      "Baseline Loss: 2.6714 | Actual Loss: 0.8422\n",
      "Baseline Loss: 2.6773 | Actual Loss: 0.7269\n",
      "Baseline Loss: 2.6658 | Actual Loss: 0.5769\n",
      "Baseline Loss: 2.6542 | Actual Loss: 0.7807\n",
      "Baseline Loss: 2.6695 | Actual Loss: 1.0523\n",
      "Baseline Loss: 2.6748 | Actual Loss: 0.5641\n",
      "Baseline Loss: 2.6948 | Actual Loss: 0.5335\n",
      "Baseline Loss: 2.6642 | Actual Loss: 0.5093\n",
      "Baseline Loss: 2.6357 | Actual Loss: 0.5244\n",
      "Baseline Loss: 2.6815 | Actual Loss: 0.9783\n",
      "Baseline Loss: 2.3101 | Actual Loss: 0.6839\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.6539\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.7779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 17/1000 [00:10<10:32,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6853 | Actual Loss: 0.4732\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3761\n",
      "Epoch 17/1000: Train Loss: 0.7816, Val Loss: 0.5703\n",
      "New best validation loss: 0.5703\n",
      "Baseline Loss: 2.6969 | Actual Loss: 0.7237\n",
      "Baseline Loss: 2.6967 | Actual Loss: 0.6241\n",
      "Baseline Loss: 2.6814 | Actual Loss: 0.6389\n",
      "Baseline Loss: 2.6787 | Actual Loss: 0.7775\n",
      "Baseline Loss: 2.6773 | Actual Loss: 0.6801\n",
      "Baseline Loss: 2.6811 | Actual Loss: 0.4919\n",
      "Baseline Loss: 2.6709 | Actual Loss: 0.9375\n",
      "Baseline Loss: 2.6815 | Actual Loss: 0.4762\n",
      "Baseline Loss: 2.6666 | Actual Loss: 0.8499\n",
      "Baseline Loss: 2.6850 | Actual Loss: 0.8795\n",
      "Baseline Loss: 2.6682 | Actual Loss: 0.7795\n",
      "Baseline Loss: 2.6756 | Actual Loss: 0.6681\n",
      "Baseline Loss: 2.6641 | Actual Loss: 1.0205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 18/1000 [00:11<10:06,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6755 | Actual Loss: 0.5092\n",
      "Baseline Loss: 2.6550 | Actual Loss: 0.6303\n",
      "Baseline Loss: 2.2862 | Actual Loss: 0.3011\n",
      "Baseline Loss: 2.6755 | Actual Loss: 1.3614\n",
      "Baseline Loss: 2.6640 | Actual Loss: 1.2207\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.6579\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.9645\n",
      "Epoch 18/1000: Train Loss: 0.6867, Val Loss: 1.0511\n",
      "Baseline Loss: 2.6760 | Actual Loss: 1.0937\n",
      "Baseline Loss: 2.6330 | Actual Loss: 1.2674\n",
      "Baseline Loss: 2.7077 | Actual Loss: 1.4003\n",
      "Baseline Loss: 2.6669 | Actual Loss: 0.9427\n",
      "Baseline Loss: 2.7094 | Actual Loss: 0.8405\n",
      "Baseline Loss: 2.6189 | Actual Loss: 0.5212\n",
      "Baseline Loss: 2.6863 | Actual Loss: 1.5579\n",
      "Baseline Loss: 2.6891 | Actual Loss: 0.4621\n",
      "Baseline Loss: 2.6703 | Actual Loss: 0.5698\n",
      "Baseline Loss: 2.6847 | Actual Loss: 0.6978\n",
      "Baseline Loss: 2.6803 | Actual Loss: 0.5526\n",
      "Baseline Loss: 2.6729 | Actual Loss: 0.6454\n",
      "Baseline Loss: 2.6710 | Actual Loss: 0.7189\n",
      "Baseline Loss: 2.6923 | Actual Loss: 0.8741\n",
      "Baseline Loss: 2.6856 | Actual Loss: 0.7820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 19/1000 [00:12<10:17,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.3159 | Actual Loss: 0.2891\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.9777\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.9624\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.3640\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2978\n",
      "Epoch 19/1000: Train Loss: 0.8260, Val Loss: 0.6505\n",
      "Baseline Loss: 2.6969 | Actual Loss: 1.9721\n",
      "Baseline Loss: 2.6771 | Actual Loss: 0.4825\n",
      "Baseline Loss: 2.6809 | Actual Loss: 0.8302\n",
      "Baseline Loss: 2.6784 | Actual Loss: 0.4185\n",
      "Baseline Loss: 2.6725 | Actual Loss: 0.4974\n",
      "Baseline Loss: 2.6243 | Actual Loss: 1.7671\n",
      "Baseline Loss: 2.6576 | Actual Loss: 0.7401\n",
      "Baseline Loss: 2.7016 | Actual Loss: 1.1310\n",
      "Baseline Loss: 2.6895 | Actual Loss: 0.4632\n",
      "Baseline Loss: 2.6816 | Actual Loss: 0.5477\n",
      "Baseline Loss: 2.6609 | Actual Loss: 0.5171\n",
      "Baseline Loss: 2.6581 | Actual Loss: 0.7006\n",
      "Baseline Loss: 2.6593 | Actual Loss: 1.2337\n",
      "Baseline Loss: 2.6920 | Actual Loss: 0.6034\n",
      "Baseline Loss: 2.6705 | Actual Loss: 1.4947\n",
      "Baseline Loss: 2.2954 | Actual Loss: 1.4407\n",
      "Baseline Loss: 2.6755 | Actual Loss: 1.6075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 20/1000 [00:12<10:25,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6640 | Actual Loss: 1.3033\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5753\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.9936\n",
      "Epoch 20/1000: Train Loss: 0.9275, Val Loss: 1.1199\n",
      "Baseline Loss: 2.6893 | Actual Loss: 1.1471\n",
      "Baseline Loss: 2.6945 | Actual Loss: 0.5834\n",
      "Baseline Loss: 2.7052 | Actual Loss: 0.8549\n",
      "Baseline Loss: 2.6591 | Actual Loss: 0.8717\n",
      "Baseline Loss: 2.6610 | Actual Loss: 0.5081\n",
      "Baseline Loss: 2.6917 | Actual Loss: 0.7819\n",
      "Baseline Loss: 2.6876 | Actual Loss: 0.9616\n",
      "Baseline Loss: 2.6955 | Actual Loss: 0.5052\n",
      "Baseline Loss: 2.6533 | Actual Loss: 0.6011\n",
      "Baseline Loss: 2.6281 | Actual Loss: 0.8916\n",
      "Baseline Loss: 2.6804 | Actual Loss: 0.4978\n",
      "Baseline Loss: 2.6879 | Actual Loss: 1.3686\n",
      "Baseline Loss: 2.6863 | Actual Loss: 1.5356\n",
      "Baseline Loss: 2.6655 | Actual Loss: 1.2896\n",
      "Baseline Loss: 2.7048 | Actual Loss: 1.4671\n",
      "Baseline Loss: 2.2066 | Actual Loss: 1.2928\n",
      "Baseline Loss: 2.6755 | Actual Loss: 1.4008\n",
      "Baseline Loss: 2.6640 | Actual Loss: 1.2816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 21/1000 [00:13<10:42,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6853 | Actual Loss: 1.0647\n",
      "Baseline Loss: 2.6128 | Actual Loss: 1.0192\n",
      "Epoch 21/1000: Train Loss: 0.9474, Val Loss: 1.1916\n",
      "Baseline Loss: 2.6995 | Actual Loss: 1.3089\n",
      "Baseline Loss: 2.6658 | Actual Loss: 1.3573\n",
      "Baseline Loss: 2.7063 | Actual Loss: 1.1501\n",
      "Baseline Loss: 2.6746 | Actual Loss: 0.9627\n",
      "Baseline Loss: 2.6529 | Actual Loss: 0.5600\n",
      "Baseline Loss: 2.7016 | Actual Loss: 0.6578\n",
      "Baseline Loss: 2.6874 | Actual Loss: 0.6709\n",
      "Baseline Loss: 2.6266 | Actual Loss: 0.7043\n",
      "Baseline Loss: 2.6424 | Actual Loss: 0.6545\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.9835\n",
      "Baseline Loss: 2.6557 | Actual Loss: 0.8142\n",
      "Baseline Loss: 2.6851 | Actual Loss: 0.7351\n",
      "Baseline Loss: 2.6879 | Actual Loss: 0.7882\n",
      "Baseline Loss: 2.6625 | Actual Loss: 0.6047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 22/1000 [00:13<10:11,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6635 | Actual Loss: 0.5519\n",
      "Baseline Loss: 2.3752 | Actual Loss: 0.7056\n",
      "Baseline Loss: 2.6755 | Actual Loss: 1.2454\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.9562\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.3963\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.5719\n",
      "Epoch 22/1000: Train Loss: 0.8256, Val Loss: 0.7924\n",
      "Baseline Loss: 2.7009 | Actual Loss: 0.5004\n",
      "Baseline Loss: 2.6417 | Actual Loss: 0.4135\n",
      "Baseline Loss: 2.7085 | Actual Loss: 1.0269\n",
      "Baseline Loss: 2.6685 | Actual Loss: 0.5308\n",
      "Baseline Loss: 2.6491 | Actual Loss: 0.7521\n",
      "Baseline Loss: 2.6933 | Actual Loss: 0.7513\n",
      "Baseline Loss: 2.6821 | Actual Loss: 0.7701\n",
      "Baseline Loss: 2.6510 | Actual Loss: 0.4301\n",
      "Baseline Loss: 2.7111 | Actual Loss: 0.6679\n",
      "Baseline Loss: 2.6517 | Actual Loss: 0.7159\n",
      "Baseline Loss: 2.6696 | Actual Loss: 0.8301\n",
      "Baseline Loss: 2.6978 | Actual Loss: 0.8361\n",
      "Baseline Loss: 2.6572 | Actual Loss: 0.6074\n",
      "Baseline Loss: 2.6602 | Actual Loss: 0.6213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 23/1000 [00:14<10:19,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6560 | Actual Loss: 0.7033\n",
      "Baseline Loss: 2.3104 | Actual Loss: 0.4975\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.6373\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.8264\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.6017\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3718\n",
      "Epoch 23/1000: Train Loss: 0.6659, Val Loss: 0.6093\n",
      "Baseline Loss: 2.6529 | Actual Loss: 0.5616\n",
      "Baseline Loss: 2.7011 | Actual Loss: 0.7545\n",
      "Baseline Loss: 2.6806 | Actual Loss: 0.5653\n",
      "Baseline Loss: 2.6553 | Actual Loss: 0.6850\n",
      "Baseline Loss: 2.6472 | Actual Loss: 0.4859\n",
      "Baseline Loss: 2.6709 | Actual Loss: 0.3328\n",
      "Baseline Loss: 2.6536 | Actual Loss: 1.1735\n",
      "Baseline Loss: 2.6656 | Actual Loss: 0.7055\n",
      "Baseline Loss: 2.6873 | Actual Loss: 1.2525\n",
      "Baseline Loss: 2.6719 | Actual Loss: 0.7641\n",
      "Baseline Loss: 2.6576 | Actual Loss: 0.9858\n",
      "Baseline Loss: 2.6836 | Actual Loss: 0.4412\n",
      "Baseline Loss: 2.6904 | Actual Loss: 0.5348\n",
      "Baseline Loss: 2.6905 | Actual Loss: 0.6372\n",
      "Baseline Loss: 2.6597 | Actual Loss: 0.4353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 24/1000 [00:15<10:22,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2724 | Actual Loss: 0.8068\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.7302\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.7676\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4429\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.4699\n",
      "Epoch 24/1000: Train Loss: 0.6951, Val Loss: 0.6026\n",
      "Baseline Loss: 2.6323 | Actual Loss: 0.6850\n",
      "Baseline Loss: 2.6863 | Actual Loss: 0.4530\n",
      "Baseline Loss: 2.6796 | Actual Loss: 0.5423\n",
      "Baseline Loss: 2.6775 | Actual Loss: 0.4523\n",
      "Baseline Loss: 2.7011 | Actual Loss: 0.7149\n",
      "Baseline Loss: 2.6724 | Actual Loss: 0.4441\n",
      "Baseline Loss: 2.6746 | Actual Loss: 1.1851\n",
      "Baseline Loss: 2.7201 | Actual Loss: 0.4717\n",
      "Baseline Loss: 2.6652 | Actual Loss: 0.4810\n",
      "Baseline Loss: 2.6609 | Actual Loss: 0.5101\n",
      "Baseline Loss: 2.6579 | Actual Loss: 0.5387\n",
      "Baseline Loss: 2.6747 | Actual Loss: 0.3501\n",
      "Baseline Loss: 2.6810 | Actual Loss: 1.8136\n",
      "Baseline Loss: 2.6866 | Actual Loss: 1.7975\n",
      "Baseline Loss: 2.6780 | Actual Loss: 0.7609\n",
      "Baseline Loss: 2.2879 | Actual Loss: 0.4433\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.8411\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.9516\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.3486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▎         | 25/1000 [00:15<09:57,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6128 | Actual Loss: 0.4967\n",
      "Epoch 25/1000: Train Loss: 0.7277, Val Loss: 0.6595\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.7441\n",
      "Baseline Loss: 2.6327 | Actual Loss: 0.6329\n",
      "Baseline Loss: 2.6369 | Actual Loss: 0.5973\n",
      "Baseline Loss: 2.6829 | Actual Loss: 0.6772\n",
      "Baseline Loss: 2.6692 | Actual Loss: 0.4798\n",
      "Baseline Loss: 2.6566 | Actual Loss: 0.8273\n",
      "Baseline Loss: 2.6682 | Actual Loss: 0.6099\n",
      "Baseline Loss: 2.6678 | Actual Loss: 1.1063\n",
      "Baseline Loss: 2.6472 | Actual Loss: 0.5062\n",
      "Baseline Loss: 2.6942 | Actual Loss: 0.3883\n",
      "Baseline Loss: 2.7025 | Actual Loss: 0.6010\n",
      "Baseline Loss: 2.7064 | Actual Loss: 0.8356\n",
      "Baseline Loss: 2.6438 | Actual Loss: 0.3805\n",
      "Baseline Loss: 2.7103 | Actual Loss: 0.6907\n",
      "Baseline Loss: 2.6545 | Actual Loss: 0.8224\n",
      "Baseline Loss: 2.3260 | Actual Loss: 0.2993\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.6443\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.8801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 26/1000 [00:16<10:20,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6853 | Actual Loss: 0.4436\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3063\n",
      "Epoch 26/1000: Train Loss: 0.6374, Val Loss: 0.5686\n",
      "New best validation loss: 0.5686\n",
      "Baseline Loss: 2.7002 | Actual Loss: 0.9056\n",
      "Baseline Loss: 2.6729 | Actual Loss: 0.7538\n",
      "Baseline Loss: 2.6720 | Actual Loss: 0.3274\n",
      "Baseline Loss: 2.6743 | Actual Loss: 0.7320\n",
      "Baseline Loss: 2.6649 | Actual Loss: 0.5508\n",
      "Baseline Loss: 2.6604 | Actual Loss: 0.5203\n",
      "Baseline Loss: 2.6699 | Actual Loss: 0.9112\n",
      "Baseline Loss: 2.6461 | Actual Loss: 0.5108\n",
      "Baseline Loss: 2.6735 | Actual Loss: 0.7145\n",
      "Baseline Loss: 2.6769 | Actual Loss: 0.4497\n",
      "Baseline Loss: 2.6888 | Actual Loss: 0.8449\n",
      "Baseline Loss: 2.7090 | Actual Loss: 0.7542\n",
      "Baseline Loss: 2.6678 | Actual Loss: 0.3583\n",
      "Baseline Loss: 2.6863 | Actual Loss: 0.7156\n",
      "Baseline Loss: 2.6502 | Actual Loss: 0.4519\n",
      "Baseline Loss: 2.2987 | Actual Loss: 0.5366\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.9289\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.8175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 27/1000 [00:17<10:22,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6853 | Actual Loss: 0.4821\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2949\n",
      "Epoch 27/1000: Train Loss: 0.6274, Val Loss: 0.6308\n",
      "Baseline Loss: 2.6772 | Actual Loss: 0.4303\n",
      "Baseline Loss: 2.6629 | Actual Loss: 0.4162\n",
      "Baseline Loss: 2.6505 | Actual Loss: 0.9245\n",
      "Baseline Loss: 2.7140 | Actual Loss: 0.5178\n",
      "Baseline Loss: 2.6607 | Actual Loss: 0.3472\n",
      "Baseline Loss: 2.6833 | Actual Loss: 0.6133\n",
      "Baseline Loss: 2.6438 | Actual Loss: 0.3089\n",
      "Baseline Loss: 2.6593 | Actual Loss: 1.3187\n",
      "Baseline Loss: 2.7028 | Actual Loss: 0.5247\n",
      "Baseline Loss: 2.7088 | Actual Loss: 0.3503\n",
      "Baseline Loss: 2.6546 | Actual Loss: 0.3195\n",
      "Baseline Loss: 2.6777 | Actual Loss: 0.6541\n",
      "Baseline Loss: 2.6956 | Actual Loss: 0.5334\n",
      "Baseline Loss: 2.6650 | Actual Loss: 0.9534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 28/1000 [00:17<09:56,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7033 | Actual Loss: 0.9880\n",
      "Baseline Loss: 2.2812 | Actual Loss: 0.6223\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.6178\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.9646\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.6587\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3096\n",
      "Epoch 28/1000: Train Loss: 0.6139, Val Loss: 0.6377\n",
      "Baseline Loss: 2.6672 | Actual Loss: 0.6576\n",
      "Baseline Loss: 2.6462 | Actual Loss: 0.3783\n",
      "Baseline Loss: 2.6993 | Actual Loss: 0.6345\n",
      "Baseline Loss: 2.6892 | Actual Loss: 1.1028\n",
      "Baseline Loss: 2.6736 | Actual Loss: 1.0545\n",
      "Baseline Loss: 2.6546 | Actual Loss: 0.3890\n",
      "Baseline Loss: 2.6741 | Actual Loss: 0.4028\n",
      "Baseline Loss: 2.7218 | Actual Loss: 1.3163\n",
      "Baseline Loss: 2.6645 | Actual Loss: 0.5313\n",
      "Baseline Loss: 2.6160 | Actual Loss: 0.6527\n",
      "Baseline Loss: 2.6720 | Actual Loss: 0.7184\n",
      "Baseline Loss: 2.7234 | Actual Loss: 0.8173\n",
      "Baseline Loss: 2.6610 | Actual Loss: 0.6286\n",
      "Baseline Loss: 2.6848 | Actual Loss: 0.5735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 29/1000 [00:18<10:02,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6694 | Actual Loss: 0.7019\n",
      "Baseline Loss: 2.2856 | Actual Loss: 0.4161\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5976\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.8265\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4532\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3731\n",
      "Epoch 29/1000: Train Loss: 0.6860, Val Loss: 0.5626\n",
      "New best validation loss: 0.5626\n",
      "Baseline Loss: 2.6680 | Actual Loss: 0.5146\n",
      "Baseline Loss: 2.6585 | Actual Loss: 0.7721\n",
      "Baseline Loss: 2.6430 | Actual Loss: 0.3820\n",
      "Baseline Loss: 2.6653 | Actual Loss: 0.3882\n",
      "Baseline Loss: 2.6739 | Actual Loss: 0.1467\n",
      "Baseline Loss: 2.7083 | Actual Loss: 0.5874\n",
      "Baseline Loss: 2.7126 | Actual Loss: 0.6742\n",
      "Baseline Loss: 2.7024 | Actual Loss: 1.0431\n",
      "Baseline Loss: 2.6641 | Actual Loss: 0.8065\n",
      "Baseline Loss: 2.6733 | Actual Loss: 1.3694\n",
      "Baseline Loss: 2.6531 | Actual Loss: 0.5453\n",
      "Baseline Loss: 2.6369 | Actual Loss: 0.7056\n",
      "Baseline Loss: 2.7111 | Actual Loss: 0.3221\n",
      "Baseline Loss: 2.6945 | Actual Loss: 0.6537\n",
      "Baseline Loss: 2.6938 | Actual Loss: 0.6221\n",
      "Baseline Loss: 2.2330 | Actual Loss: 0.3358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 30/1000 [00:19<10:25,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6755 | Actual Loss: 0.5189\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.8548\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4881\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2566\n",
      "Epoch 30/1000: Train Loss: 0.6168, Val Loss: 0.5296\n",
      "New best validation loss: 0.5296\n",
      "Baseline Loss: 2.6520 | Actual Loss: 1.4421\n",
      "Baseline Loss: 2.6406 | Actual Loss: 0.6468\n",
      "Baseline Loss: 2.7177 | Actual Loss: 0.8265\n",
      "Baseline Loss: 2.7066 | Actual Loss: 0.6124\n",
      "Baseline Loss: 2.6883 | Actual Loss: 0.5650\n",
      "Baseline Loss: 2.6635 | Actual Loss: 1.0731\n",
      "Baseline Loss: 2.6632 | Actual Loss: 0.7397\n",
      "Baseline Loss: 2.6839 | Actual Loss: 1.3140\n",
      "Baseline Loss: 2.6848 | Actual Loss: 0.4485\n",
      "Baseline Loss: 2.6747 | Actual Loss: 0.5674\n",
      "Baseline Loss: 2.6799 | Actual Loss: 0.3338\n",
      "Baseline Loss: 2.6789 | Actual Loss: 0.7308\n",
      "Baseline Loss: 2.6966 | Actual Loss: 1.0430\n",
      "Baseline Loss: 2.6714 | Actual Loss: 0.5315\n",
      "Baseline Loss: 2.6975 | Actual Loss: 0.3126\n",
      "Baseline Loss: 2.2334 | Actual Loss: 0.1899\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.8543\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.7722\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 31/1000 [00:19<09:55,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6128 | Actual Loss: 0.3813\n",
      "Epoch 31/1000: Train Loss: 0.7111, Val Loss: 0.6096\n",
      "Baseline Loss: 2.6904 | Actual Loss: 0.6396\n",
      "Baseline Loss: 2.6940 | Actual Loss: 0.6795\n",
      "Baseline Loss: 2.6530 | Actual Loss: 0.5792\n",
      "Baseline Loss: 2.6562 | Actual Loss: 0.5640\n",
      "Baseline Loss: 2.6978 | Actual Loss: 0.3806\n",
      "Baseline Loss: 2.6406 | Actual Loss: 0.2038\n",
      "Baseline Loss: 2.6822 | Actual Loss: 1.2066\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.3467\n",
      "Baseline Loss: 2.6757 | Actual Loss: 0.3629\n",
      "Baseline Loss: 2.6359 | Actual Loss: 0.5421\n",
      "Baseline Loss: 2.6676 | Actual Loss: 0.4463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 32/1000 [00:20<10:11,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6899 | Actual Loss: 1.0992\n",
      "Baseline Loss: 2.7179 | Actual Loss: 0.3556\n",
      "Baseline Loss: 2.6610 | Actual Loss: 0.1877\n",
      "Baseline Loss: 2.6659 | Actual Loss: 0.4586\n",
      "Baseline Loss: 2.3354 | Actual Loss: 0.5606\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5770\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.8127\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4526\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2244\n",
      "Epoch 32/1000: Train Loss: 0.5383, Val Loss: 0.5167\n",
      "New best validation loss: 0.5167\n",
      "Baseline Loss: 2.6254 | Actual Loss: 0.5885\n",
      "Baseline Loss: 2.6777 | Actual Loss: 0.3315\n",
      "Baseline Loss: 2.6388 | Actual Loss: 0.8646\n",
      "Baseline Loss: 2.6609 | Actual Loss: 1.0005\n",
      "Baseline Loss: 2.6575 | Actual Loss: 0.3838\n",
      "Baseline Loss: 2.6848 | Actual Loss: 0.3869\n",
      "Baseline Loss: 2.6793 | Actual Loss: 0.6852\n",
      "Baseline Loss: 2.6678 | Actual Loss: 0.3121\n",
      "Baseline Loss: 2.6613 | Actual Loss: 2.0967\n",
      "Baseline Loss: 2.7006 | Actual Loss: 0.7371\n",
      "Baseline Loss: 2.6375 | Actual Loss: 0.6338\n",
      "Baseline Loss: 2.6520 | Actual Loss: 0.6722\n",
      "Baseline Loss: 2.6449 | Actual Loss: 0.4543\n",
      "Baseline Loss: 2.6746 | Actual Loss: 0.5475\n",
      "Baseline Loss: 2.6952 | Actual Loss: 0.5372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 33/1000 [00:20<10:00,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2632 | Actual Loss: 0.3294\n",
      "Baseline Loss: 2.6755 | Actual Loss: 1.0140\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.8891\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.3805\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3447\n",
      "Epoch 33/1000: Train Loss: 0.6601, Val Loss: 0.6571\n",
      "Baseline Loss: 2.7056 | Actual Loss: 0.6586\n",
      "Baseline Loss: 2.6693 | Actual Loss: 0.8498\n",
      "Baseline Loss: 2.6904 | Actual Loss: 0.5578\n",
      "Baseline Loss: 2.6669 | Actual Loss: 0.2410\n",
      "Baseline Loss: 2.7107 | Actual Loss: 0.7491\n",
      "Baseline Loss: 2.6591 | Actual Loss: 0.7243\n",
      "Baseline Loss: 2.6473 | Actual Loss: 0.3596\n",
      "Baseline Loss: 2.6496 | Actual Loss: 0.4639\n",
      "Baseline Loss: 2.6813 | Actual Loss: 1.2273\n",
      "Baseline Loss: 2.7164 | Actual Loss: 0.4401\n",
      "Baseline Loss: 2.6771 | Actual Loss: 1.2285\n",
      "Baseline Loss: 2.6728 | Actual Loss: 0.6574\n",
      "Baseline Loss: 2.6627 | Actual Loss: 1.8247\n",
      "Baseline Loss: 2.6836 | Actual Loss: 0.3148\n",
      "Baseline Loss: 2.6436 | Actual Loss: 0.6236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 34/1000 [00:21<10:04,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2520 | Actual Loss: 1.2824\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5356\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.8471\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5084\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2685\n",
      "Epoch 34/1000: Train Loss: 0.7627, Val Loss: 0.5399\n",
      "Baseline Loss: 2.6756 | Actual Loss: 0.7040\n",
      "Baseline Loss: 2.6614 | Actual Loss: 0.7943\n",
      "Baseline Loss: 2.6668 | Actual Loss: 0.6699\n",
      "Baseline Loss: 2.6539 | Actual Loss: 0.6145\n",
      "Baseline Loss: 2.7009 | Actual Loss: 0.5185\n",
      "Baseline Loss: 2.7071 | Actual Loss: 1.3552\n",
      "Baseline Loss: 2.6590 | Actual Loss: 1.7999\n",
      "Baseline Loss: 2.6849 | Actual Loss: 0.1835\n",
      "Baseline Loss: 2.6627 | Actual Loss: 0.3910\n",
      "Baseline Loss: 2.6523 | Actual Loss: 0.7451\n",
      "Baseline Loss: 2.6665 | Actual Loss: 0.7419\n",
      "Baseline Loss: 2.6790 | Actual Loss: 0.8048\n",
      "Baseline Loss: 2.6695 | Actual Loss: 0.9064\n",
      "Baseline Loss: 2.7227 | Actual Loss: 1.1359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 35/1000 [00:22<10:20,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6698 | Actual Loss: 0.3278\n",
      "Baseline Loss: 2.2059 | Actual Loss: 0.2710\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5607\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.8465\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4483\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2393\n",
      "Epoch 35/1000: Train Loss: 0.7477, Val Loss: 0.5237\n",
      "Baseline Loss: 2.6796 | Actual Loss: 0.4133\n",
      "Baseline Loss: 2.7002 | Actual Loss: 0.5464\n",
      "Baseline Loss: 2.6529 | Actual Loss: 0.5934\n",
      "Baseline Loss: 2.6721 | Actual Loss: 0.6181\n",
      "Baseline Loss: 2.6679 | Actual Loss: 0.4636\n",
      "Baseline Loss: 2.6868 | Actual Loss: 0.6620\n",
      "Baseline Loss: 2.6744 | Actual Loss: 0.4235\n",
      "Baseline Loss: 2.6487 | Actual Loss: 0.5569\n",
      "Baseline Loss: 2.6844 | Actual Loss: 0.5612\n",
      "Baseline Loss: 2.6660 | Actual Loss: 0.8656\n",
      "Baseline Loss: 2.6913 | Actual Loss: 0.4422\n",
      "Baseline Loss: 2.6685 | Actual Loss: 0.9932\n",
      "Baseline Loss: 2.6133 | Actual Loss: 0.8081\n",
      "Baseline Loss: 2.6836 | Actual Loss: 0.6252\n",
      "Baseline Loss: 2.7108 | Actual Loss: 0.8554\n",
      "Baseline Loss: 2.2617 | Actual Loss: 0.7029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 36/1000 [00:22<10:09,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6755 | Actual Loss: 0.4930\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.8305\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5677\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3332\n",
      "Epoch 36/1000: Train Loss: 0.6332, Val Loss: 0.5561\n",
      "Baseline Loss: 2.6716 | Actual Loss: 0.6715\n",
      "Baseline Loss: 2.7098 | Actual Loss: 0.5133\n",
      "Baseline Loss: 2.6728 | Actual Loss: 0.5922\n",
      "Baseline Loss: 2.6961 | Actual Loss: 0.3190\n",
      "Baseline Loss: 2.6768 | Actual Loss: 0.7490\n",
      "Baseline Loss: 2.6949 | Actual Loss: 1.1978\n",
      "Baseline Loss: 2.6449 | Actual Loss: 1.1235\n",
      "Baseline Loss: 2.7199 | Actual Loss: 1.6129\n",
      "Baseline Loss: 2.6424 | Actual Loss: 0.8880\n",
      "Baseline Loss: 2.6596 | Actual Loss: 0.8397\n",
      "Baseline Loss: 2.6646 | Actual Loss: 0.4280\n",
      "Baseline Loss: 2.6527 | Actual Loss: 0.4511\n",
      "Baseline Loss: 2.6543 | Actual Loss: 0.5943\n",
      "Baseline Loss: 2.6630 | Actual Loss: 0.5664\n",
      "Baseline Loss: 2.6623 | Actual Loss: 0.3829\n",
      "Baseline Loss: 2.2747 | Actual Loss: 0.9362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 37/1000 [00:23<10:12,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6755 | Actual Loss: 0.7520\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.8546\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.6655\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.5440\n",
      "Epoch 37/1000: Train Loss: 0.7416, Val Loss: 0.7040\n",
      "Baseline Loss: 2.6937 | Actual Loss: 0.6893\n",
      "Baseline Loss: 2.6205 | Actual Loss: 0.8434\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.8369\n",
      "Baseline Loss: 2.6605 | Actual Loss: 0.7385\n",
      "Baseline Loss: 2.6685 | Actual Loss: 0.7023\n",
      "Baseline Loss: 2.6680 | Actual Loss: 0.6901\n",
      "Baseline Loss: 2.7066 | Actual Loss: 0.7511\n",
      "Baseline Loss: 2.6735 | Actual Loss: 0.6893\n",
      "Baseline Loss: 2.7113 | Actual Loss: 0.2607\n",
      "Baseline Loss: 2.6758 | Actual Loss: 1.3166\n",
      "Baseline Loss: 2.6806 | Actual Loss: 0.3256\n",
      "Baseline Loss: 2.6845 | Actual Loss: 1.4165\n",
      "Baseline Loss: 2.7610 | Actual Loss: 1.2702\n",
      "Baseline Loss: 2.6612 | Actual Loss: 1.5334\n",
      "Baseline Loss: 2.6651 | Actual Loss: 0.2531\n",
      "Baseline Loss: 2.2635 | Actual Loss: 0.7806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 38/1000 [00:24<09:54,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6755 | Actual Loss: 1.1731\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6757\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.3407\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.4299\n",
      "Epoch 38/1000: Train Loss: 0.8186, Val Loss: 0.6548\n",
      "Baseline Loss: 2.6614 | Actual Loss: 0.7264\n",
      "Baseline Loss: 2.7170 | Actual Loss: 0.4924\n",
      "Baseline Loss: 2.6697 | Actual Loss: 0.5894\n",
      "Baseline Loss: 2.6961 | Actual Loss: 0.5633\n",
      "Baseline Loss: 2.6777 | Actual Loss: 0.5289\n",
      "Baseline Loss: 2.6778 | Actual Loss: 0.7147\n",
      "Baseline Loss: 2.6668 | Actual Loss: 0.7644\n",
      "Baseline Loss: 2.6763 | Actual Loss: 0.6096\n",
      "Baseline Loss: 2.6973 | Actual Loss: 0.6979\n",
      "Baseline Loss: 2.6344 | Actual Loss: 0.4147\n",
      "Baseline Loss: 2.6959 | Actual Loss: 0.2066\n",
      "Baseline Loss: 2.6309 | Actual Loss: 0.6154\n",
      "Baseline Loss: 2.6956 | Actual Loss: 0.3006\n",
      "Baseline Loss: 2.6417 | Actual Loss: 0.7759\n",
      "Baseline Loss: 2.6572 | Actual Loss: 0.6744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 39/1000 [00:24<10:10,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2498 | Actual Loss: 1.3764\n",
      "Baseline Loss: 2.6755 | Actual Loss: 1.7860\n",
      "Baseline Loss: 2.6640 | Actual Loss: 1.0034\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4298\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.9130\n",
      "Epoch 39/1000: Train Loss: 0.6282, Val Loss: 1.0330\n",
      "Baseline Loss: 2.6635 | Actual Loss: 0.5433\n",
      "Baseline Loss: 2.6895 | Actual Loss: 0.4338\n",
      "Baseline Loss: 2.6760 | Actual Loss: 0.4049\n",
      "Baseline Loss: 2.6743 | Actual Loss: 0.5508\n",
      "Baseline Loss: 2.7445 | Actual Loss: 0.2936\n",
      "Baseline Loss: 2.6595 | Actual Loss: 0.9624\n",
      "Baseline Loss: 2.6228 | Actual Loss: 0.5312\n",
      "Baseline Loss: 2.6998 | Actual Loss: 0.6151\n",
      "Baseline Loss: 2.6584 | Actual Loss: 0.6783\n",
      "Baseline Loss: 2.6347 | Actual Loss: 0.8364\n",
      "Baseline Loss: 2.6660 | Actual Loss: 0.7618\n",
      "Baseline Loss: 2.7452 | Actual Loss: 0.6916\n",
      "Baseline Loss: 2.6587 | Actual Loss: 0.6662\n",
      "Baseline Loss: 2.6751 | Actual Loss: 0.5765\n",
      "Baseline Loss: 2.6638 | Actual Loss: 0.4785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 40/1000 [00:25<10:36,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2603 | Actual Loss: 0.2360\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4668\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.7436\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4979\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2538\n",
      "Epoch 40/1000: Train Loss: 0.5788, Val Loss: 0.4905\n",
      "New best validation loss: 0.4905\n",
      "Baseline Loss: 2.6733 | Actual Loss: 0.6050\n",
      "Baseline Loss: 2.6654 | Actual Loss: 0.6770\n",
      "Baseline Loss: 2.6608 | Actual Loss: 0.5730\n",
      "Baseline Loss: 2.6635 | Actual Loss: 0.9259\n",
      "Baseline Loss: 2.6699 | Actual Loss: 0.4642\n",
      "Baseline Loss: 2.6832 | Actual Loss: 0.4292\n",
      "Baseline Loss: 2.6791 | Actual Loss: 0.1693\n",
      "Baseline Loss: 2.6766 | Actual Loss: 0.8642\n",
      "Baseline Loss: 2.6649 | Actual Loss: 0.4288\n",
      "Baseline Loss: 2.6598 | Actual Loss: 0.6414\n",
      "Baseline Loss: 2.6959 | Actual Loss: 0.7382\n",
      "Baseline Loss: 2.6551 | Actual Loss: 0.7203\n",
      "Baseline Loss: 2.6685 | Actual Loss: 0.5187\n",
      "Baseline Loss: 2.6591 | Actual Loss: 0.4032\n",
      "Baseline Loss: 2.6562 | Actual Loss: 0.4954\n",
      "Baseline Loss: 2.2522 | Actual Loss: 0.2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 41/1000 [00:26<10:42,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6755 | Actual Loss: 0.5940\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.8079\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.3728\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3103\n",
      "Epoch 41/1000: Train Loss: 0.5535, Val Loss: 0.5212\n",
      "Baseline Loss: 2.6874 | Actual Loss: 1.1556\n",
      "Baseline Loss: 2.6646 | Actual Loss: 0.2872\n",
      "Baseline Loss: 2.6882 | Actual Loss: 0.7001\n",
      "Baseline Loss: 2.6777 | Actual Loss: 0.3658\n",
      "Baseline Loss: 2.6832 | Actual Loss: 0.8034\n",
      "Baseline Loss: 2.6932 | Actual Loss: 0.9838\n",
      "Baseline Loss: 2.6607 | Actual Loss: 0.6453\n",
      "Baseline Loss: 2.6764 | Actual Loss: 0.8724\n",
      "Baseline Loss: 2.6777 | Actual Loss: 0.5952\n",
      "Baseline Loss: 2.6646 | Actual Loss: 0.5518\n",
      "Baseline Loss: 2.6659 | Actual Loss: 0.2979\n",
      "Baseline Loss: 2.6941 | Actual Loss: 0.3788\n",
      "Baseline Loss: 2.6561 | Actual Loss: 0.7970\n",
      "Baseline Loss: 2.7041 | Actual Loss: 1.8991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 42/1000 [00:26<10:24,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6864 | Actual Loss: 0.4668\n",
      "Baseline Loss: 2.2226 | Actual Loss: 0.5419\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.9570\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6393\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.3493\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3784\n",
      "Epoch 42/1000: Train Loss: 0.7089, Val Loss: 0.5810\n",
      "Baseline Loss: 2.6850 | Actual Loss: 0.6082\n",
      "Baseline Loss: 2.6159 | Actual Loss: 0.2394\n",
      "Baseline Loss: 2.6842 | Actual Loss: 1.3330\n",
      "Baseline Loss: 2.6734 | Actual Loss: 1.0223\n",
      "Baseline Loss: 2.6860 | Actual Loss: 0.4240\n",
      "Baseline Loss: 2.6915 | Actual Loss: 0.7546\n",
      "Baseline Loss: 2.7372 | Actual Loss: 0.7424\n",
      "Baseline Loss: 2.6760 | Actual Loss: 0.5089\n",
      "Baseline Loss: 2.6859 | Actual Loss: 0.5921\n",
      "Baseline Loss: 2.6851 | Actual Loss: 0.2867\n",
      "Baseline Loss: 2.6555 | Actual Loss: 0.4712\n",
      "Baseline Loss: 2.6845 | Actual Loss: 0.5415\n",
      "Baseline Loss: 2.6592 | Actual Loss: 0.3107\n",
      "Baseline Loss: 2.6829 | Actual Loss: 0.3266\n",
      "Baseline Loss: 2.6850 | Actual Loss: 0.5676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 43/1000 [00:27<10:43,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2765 | Actual Loss: 0.2151\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.6026\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6552\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4323\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2187\n",
      "Epoch 43/1000: Train Loss: 0.5590, Val Loss: 0.4772\n",
      "New best validation loss: 0.4772\n",
      "Baseline Loss: 2.6590 | Actual Loss: 0.8405\n",
      "Baseline Loss: 2.6686 | Actual Loss: 0.3278\n",
      "Baseline Loss: 2.6593 | Actual Loss: 0.6619\n",
      "Baseline Loss: 2.6575 | Actual Loss: 0.4442\n",
      "Baseline Loss: 2.7406 | Actual Loss: 0.3945\n",
      "Baseline Loss: 2.6877 | Actual Loss: 0.9115\n",
      "Baseline Loss: 2.6718 | Actual Loss: 0.5339\n",
      "Baseline Loss: 2.6587 | Actual Loss: 0.8263\n",
      "Baseline Loss: 2.6876 | Actual Loss: 0.2375\n",
      "Baseline Loss: 2.6754 | Actual Loss: 1.1407\n",
      "Baseline Loss: 2.6622 | Actual Loss: 0.5786\n",
      "Baseline Loss: 2.6753 | Actual Loss: 0.6284\n",
      "Baseline Loss: 2.6648 | Actual Loss: 0.3133\n",
      "Baseline Loss: 2.6487 | Actual Loss: 0.3170\n",
      "Baseline Loss: 2.6731 | Actual Loss: 0.3226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 44/1000 [00:28<10:34,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2428 | Actual Loss: 0.3844\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5505\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.7378\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2773\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3427\n",
      "Epoch 44/1000: Train Loss: 0.5540, Val Loss: 0.4771\n",
      "New best validation loss: 0.4771\n",
      "Baseline Loss: 2.6744 | Actual Loss: 0.5667\n",
      "Baseline Loss: 2.6658 | Actual Loss: 0.1920\n",
      "Baseline Loss: 2.6283 | Actual Loss: 1.4441\n",
      "Baseline Loss: 2.6931 | Actual Loss: 0.8895\n",
      "Baseline Loss: 2.6330 | Actual Loss: 1.1993\n",
      "Baseline Loss: 2.6915 | Actual Loss: 0.4771\n",
      "Baseline Loss: 2.6657 | Actual Loss: 0.6922\n",
      "Baseline Loss: 2.6562 | Actual Loss: 0.4820\n",
      "Baseline Loss: 2.7170 | Actual Loss: 0.4439\n",
      "Baseline Loss: 2.6839 | Actual Loss: 0.7822\n",
      "Baseline Loss: 2.6482 | Actual Loss: 0.5389\n",
      "Baseline Loss: 2.6791 | Actual Loss: 0.6312\n",
      "Baseline Loss: 2.6444 | Actual Loss: 0.3785\n",
      "Baseline Loss: 2.7369 | Actual Loss: 0.4676\n",
      "Baseline Loss: 2.6651 | Actual Loss: 0.4134\n",
      "Baseline Loss: 2.2856 | Actual Loss: 0.2384\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.8912\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 45/1000 [00:28<10:13,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6853 | Actual Loss: 0.4218\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3965\n",
      "Epoch 45/1000: Train Loss: 0.6148, Val Loss: 0.5977\n",
      "Baseline Loss: 2.7179 | Actual Loss: 0.7450\n",
      "Baseline Loss: 2.6836 | Actual Loss: 0.5481\n",
      "Baseline Loss: 2.6645 | Actual Loss: 0.3069\n",
      "Baseline Loss: 2.7012 | Actual Loss: 1.4185\n",
      "Baseline Loss: 2.6488 | Actual Loss: 0.4759\n",
      "Baseline Loss: 2.6628 | Actual Loss: 0.5389\n",
      "Baseline Loss: 2.7103 | Actual Loss: 0.9349\n",
      "Baseline Loss: 2.6494 | Actual Loss: 0.3065\n",
      "Baseline Loss: 2.7059 | Actual Loss: 0.5637\n",
      "Baseline Loss: 2.6969 | Actual Loss: 0.2986\n",
      "Baseline Loss: 2.6551 | Actual Loss: 0.5040\n",
      "Baseline Loss: 2.6609 | Actual Loss: 0.6016\n",
      "Baseline Loss: 2.6569 | Actual Loss: 0.5810\n",
      "Baseline Loss: 2.6812 | Actual Loss: 0.3207\n",
      "Baseline Loss: 2.6313 | Actual Loss: 0.6771\n",
      "Baseline Loss: 2.2402 | Actual Loss: 0.1301\n",
      "Baseline Loss: 2.6755 | Actual Loss: 1.6583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 46/1000 [00:29<10:12,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6640 | Actual Loss: 0.8418\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.3486\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.7108\n",
      "Epoch 46/1000: Train Loss: 0.5595, Val Loss: 0.8899\n",
      "Baseline Loss: 2.6939 | Actual Loss: 0.1366\n",
      "Baseline Loss: 2.6438 | Actual Loss: 0.8152\n",
      "Baseline Loss: 2.6821 | Actual Loss: 0.5533\n",
      "Baseline Loss: 2.6825 | Actual Loss: 1.3419\n",
      "Baseline Loss: 2.6570 | Actual Loss: 1.6574\n",
      "Baseline Loss: 2.6526 | Actual Loss: 0.6535\n",
      "Baseline Loss: 2.7062 | Actual Loss: 1.3195\n",
      "Baseline Loss: 2.6856 | Actual Loss: 0.7646\n",
      "Baseline Loss: 2.7261 | Actual Loss: 0.7971\n",
      "Baseline Loss: 2.6620 | Actual Loss: 0.7794\n",
      "Baseline Loss: 2.6295 | Actual Loss: 0.6485\n",
      "Baseline Loss: 2.6361 | Actual Loss: 0.4798\n",
      "Baseline Loss: 2.6873 | Actual Loss: 0.9037\n",
      "Baseline Loss: 2.6313 | Actual Loss: 0.3902\n",
      "Baseline Loss: 2.6610 | Actual Loss: 0.9263\n",
      "Baseline Loss: 2.2850 | Actual Loss: 0.2420\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.6651\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.7166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 47/1000 [00:29<10:21,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6853 | Actual Loss: 0.4083\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.1995\n",
      "Epoch 47/1000: Train Loss: 0.7756, Val Loss: 0.4974\n",
      "Baseline Loss: 2.6691 | Actual Loss: 0.7824\n",
      "Baseline Loss: 2.7399 | Actual Loss: 0.8383\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.4665\n",
      "Baseline Loss: 2.6940 | Actual Loss: 0.7534\n",
      "Baseline Loss: 2.6464 | Actual Loss: 0.4536\n",
      "Baseline Loss: 2.6717 | Actual Loss: 0.5902\n",
      "Baseline Loss: 2.6704 | Actual Loss: 0.6338\n",
      "Baseline Loss: 2.6520 | Actual Loss: 0.4828\n",
      "Baseline Loss: 2.6419 | Actual Loss: 0.6715\n",
      "Baseline Loss: 2.6506 | Actual Loss: 0.3482\n",
      "Baseline Loss: 2.6402 | Actual Loss: 0.3714\n",
      "Baseline Loss: 2.6682 | Actual Loss: 0.1495\n",
      "Baseline Loss: 2.7051 | Actual Loss: 0.7022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 48/1000 [00:30<09:52,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6689 | Actual Loss: 0.5651\n",
      "Baseline Loss: 2.6693 | Actual Loss: 0.9288\n",
      "Baseline Loss: 2.2608 | Actual Loss: 0.2858\n",
      "Baseline Loss: 2.6755 | Actual Loss: 1.4395\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.7641\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2263\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2516\n",
      "Epoch 48/1000: Train Loss: 0.5640, Val Loss: 0.6704\n",
      "Baseline Loss: 2.6759 | Actual Loss: 0.4121\n",
      "Baseline Loss: 2.7032 | Actual Loss: 0.4001\n",
      "Baseline Loss: 2.6613 | Actual Loss: 0.4895\n",
      "Baseline Loss: 2.6925 | Actual Loss: 0.7658\n",
      "Baseline Loss: 2.6697 | Actual Loss: 0.3931\n",
      "Baseline Loss: 2.6363 | Actual Loss: 0.6338\n",
      "Baseline Loss: 2.6621 | Actual Loss: 0.5541\n",
      "Baseline Loss: 2.6718 | Actual Loss: 0.5167\n",
      "Baseline Loss: 2.6757 | Actual Loss: 0.9835\n",
      "Baseline Loss: 2.6592 | Actual Loss: 0.5126\n",
      "Baseline Loss: 2.6942 | Actual Loss: 0.5885\n",
      "Baseline Loss: 2.6745 | Actual Loss: 0.6460\n",
      "Baseline Loss: 2.6392 | Actual Loss: 0.4716\n",
      "Baseline Loss: 2.6790 | Actual Loss: 1.0928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 49/1000 [00:31<10:11,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6723 | Actual Loss: 0.2270\n",
      "Baseline Loss: 2.3536 | Actual Loss: 1.0002\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.7778\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.7131\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2593\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2065\n",
      "Epoch 49/1000: Train Loss: 0.6055, Val Loss: 0.4892\n",
      "Baseline Loss: 2.6526 | Actual Loss: 0.5287\n",
      "Baseline Loss: 2.6768 | Actual Loss: 0.3645\n",
      "Baseline Loss: 2.6757 | Actual Loss: 0.2190\n",
      "Baseline Loss: 2.6786 | Actual Loss: 0.3994\n",
      "Baseline Loss: 2.6806 | Actual Loss: 0.4335\n",
      "Baseline Loss: 2.6677 | Actual Loss: 0.2659\n",
      "Baseline Loss: 2.6669 | Actual Loss: 0.6139\n",
      "Baseline Loss: 2.6743 | Actual Loss: 0.6862\n",
      "Baseline Loss: 2.6647 | Actual Loss: 0.4446\n",
      "Baseline Loss: 2.6469 | Actual Loss: 0.5148\n",
      "Baseline Loss: 2.7054 | Actual Loss: 0.5981\n",
      "Baseline Loss: 2.6811 | Actual Loss: 0.1456\n",
      "Baseline Loss: 2.6764 | Actual Loss: 0.4145\n",
      "Baseline Loss: 2.6714 | Actual Loss: 0.3768\n",
      "Baseline Loss: 2.6648 | Actual Loss: 1.2298\n",
      "Baseline Loss: 2.2939 | Actual Loss: 0.7623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 50/1000 [00:31<10:15,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6755 | Actual Loss: 0.9101\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6901\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.3845\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2973\n",
      "Epoch 50/1000: Train Loss: 0.4998, Val Loss: 0.5705\n",
      "Baseline Loss: 2.7194 | Actual Loss: 0.5290\n",
      "Baseline Loss: 2.6652 | Actual Loss: 1.2268\n",
      "Baseline Loss: 2.6728 | Actual Loss: 0.5143\n",
      "Baseline Loss: 2.6561 | Actual Loss: 0.4507\n",
      "Baseline Loss: 2.6580 | Actual Loss: 0.2842\n",
      "Baseline Loss: 2.6720 | Actual Loss: 0.8436\n",
      "Baseline Loss: 2.6529 | Actual Loss: 0.6521\n",
      "Baseline Loss: 2.6752 | Actual Loss: 0.3236\n",
      "Baseline Loss: 2.6459 | Actual Loss: 0.7988\n",
      "Baseline Loss: 2.6745 | Actual Loss: 0.4014\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.5235\n",
      "Baseline Loss: 2.6570 | Actual Loss: 0.4423\n",
      "Baseline Loss: 2.7164 | Actual Loss: 0.2364\n",
      "Baseline Loss: 2.6455 | Actual Loss: 1.0264\n",
      "Baseline Loss: 2.6565 | Actual Loss: 0.3810\n",
      "Baseline Loss: 2.2924 | Actual Loss: 0.4064\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4410\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.7510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 51/1000 [00:32<10:05,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6853 | Actual Loss: 0.2397\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2164\n",
      "Epoch 51/1000: Train Loss: 0.5650, Val Loss: 0.4120\n",
      "New best validation loss: 0.4120\n",
      "Baseline Loss: 2.6565 | Actual Loss: 0.3005\n",
      "Baseline Loss: 2.6810 | Actual Loss: 0.3676\n",
      "Baseline Loss: 2.6429 | Actual Loss: 0.4923\n",
      "Baseline Loss: 2.6927 | Actual Loss: 0.5221\n",
      "Baseline Loss: 2.6555 | Actual Loss: 0.5904\n",
      "Baseline Loss: 2.6716 | Actual Loss: 0.8928\n",
      "Baseline Loss: 2.6735 | Actual Loss: 1.2639\n",
      "Baseline Loss: 2.6810 | Actual Loss: 2.1614\n",
      "Baseline Loss: 2.6517 | Actual Loss: 0.3733\n",
      "Baseline Loss: 2.6940 | Actual Loss: 0.9744\n",
      "Baseline Loss: 2.6545 | Actual Loss: 0.4449\n",
      "Baseline Loss: 2.6843 | Actual Loss: 0.2944\n",
      "Baseline Loss: 2.6573 | Actual Loss: 0.4575\n",
      "Baseline Loss: 2.7146 | Actual Loss: 0.4276\n",
      "Baseline Loss: 2.6642 | Actual Loss: 0.6580\n",
      "Baseline Loss: 2.2975 | Actual Loss: 0.2920\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4757\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 52/1000 [00:33<10:26,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6853 | Actual Loss: 0.3362\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2507\n",
      "Epoch 52/1000: Train Loss: 0.6571, Val Loss: 0.4093\n",
      "New best validation loss: 0.4093\n",
      "Baseline Loss: 2.6782 | Actual Loss: 0.7303\n",
      "Baseline Loss: 2.6753 | Actual Loss: 0.5096\n",
      "Baseline Loss: 2.6349 | Actual Loss: 0.4931\n",
      "Baseline Loss: 2.6626 | Actual Loss: 0.4356\n",
      "Baseline Loss: 2.7109 | Actual Loss: 0.4919\n",
      "Baseline Loss: 2.6685 | Actual Loss: 0.3757\n",
      "Baseline Loss: 2.6383 | Actual Loss: 0.5492\n",
      "Baseline Loss: 2.7203 | Actual Loss: 0.5365\n",
      "Baseline Loss: 2.6649 | Actual Loss: 0.3336\n",
      "Baseline Loss: 2.7194 | Actual Loss: 0.6788\n",
      "Baseline Loss: 2.6565 | Actual Loss: 0.4778\n",
      "Baseline Loss: 2.6769 | Actual Loss: 0.4921\n",
      "Baseline Loss: 2.6739 | Actual Loss: 0.4248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 53/1000 [00:33<10:03,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6923 | Actual Loss: 0.4910\n",
      "Baseline Loss: 2.6849 | Actual Loss: 0.4046\n",
      "Baseline Loss: 2.2457 | Actual Loss: 0.1606\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.8553\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.9434\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2477\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2079\n",
      "Epoch 53/1000: Train Loss: 0.4741, Val Loss: 0.5636\n",
      "Baseline Loss: 2.6757 | Actual Loss: 0.3456\n",
      "Baseline Loss: 2.6824 | Actual Loss: 0.2915\n",
      "Baseline Loss: 2.6315 | Actual Loss: 0.4083\n",
      "Baseline Loss: 2.6586 | Actual Loss: 0.2140\n",
      "Baseline Loss: 2.6649 | Actual Loss: 0.5968\n",
      "Baseline Loss: 2.6971 | Actual Loss: 1.7550\n",
      "Baseline Loss: 2.6720 | Actual Loss: 0.8623\n",
      "Baseline Loss: 2.6681 | Actual Loss: 0.9298\n",
      "Baseline Loss: 2.6608 | Actual Loss: 0.7668\n",
      "Baseline Loss: 2.7103 | Actual Loss: 0.6691\n",
      "Baseline Loss: 2.6981 | Actual Loss: 0.5599\n",
      "Baseline Loss: 2.6618 | Actual Loss: 0.5695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 54/1000 [00:34<10:09,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6823 | Actual Loss: 0.7549\n",
      "Baseline Loss: 2.7103 | Actual Loss: 0.2990\n",
      "Baseline Loss: 2.6394 | Actual Loss: 0.5944\n",
      "Baseline Loss: 2.2981 | Actual Loss: 0.3918\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4701\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6089\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2656\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3118\n",
      "Epoch 54/1000: Train Loss: 0.6256, Val Loss: 0.4141\n",
      "Baseline Loss: 2.6910 | Actual Loss: 0.5839\n",
      "Baseline Loss: 2.6661 | Actual Loss: 0.1875\n",
      "Baseline Loss: 2.6507 | Actual Loss: 1.1878\n",
      "Baseline Loss: 2.6736 | Actual Loss: 0.5259\n",
      "Baseline Loss: 2.6328 | Actual Loss: 0.5209\n",
      "Baseline Loss: 2.6988 | Actual Loss: 0.4724\n",
      "Baseline Loss: 2.6641 | Actual Loss: 0.2912\n",
      "Baseline Loss: 2.6966 | Actual Loss: 0.3533\n",
      "Baseline Loss: 2.6814 | Actual Loss: 0.3868\n",
      "Baseline Loss: 2.6843 | Actual Loss: 0.3360\n",
      "Baseline Loss: 2.6714 | Actual Loss: 1.2083\n",
      "Baseline Loss: 2.7062 | Actual Loss: 0.7225\n",
      "Baseline Loss: 2.6417 | Actual Loss: 0.8229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 55/1000 [00:35<10:13,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6769 | Actual Loss: 0.4487\n",
      "Baseline Loss: 2.6918 | Actual Loss: 0.3048\n",
      "Baseline Loss: 2.3141 | Actual Loss: 0.8801\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.6962\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6861\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2289\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2140\n",
      "Epoch 55/1000: Train Loss: 0.5771, Val Loss: 0.4563\n",
      "Baseline Loss: 2.6362 | Actual Loss: 1.6860\n",
      "Baseline Loss: 2.6712 | Actual Loss: 0.6767\n",
      "Baseline Loss: 2.6720 | Actual Loss: 0.3151\n",
      "Baseline Loss: 2.6534 | Actual Loss: 0.5132\n",
      "Baseline Loss: 2.6743 | Actual Loss: 0.7883\n",
      "Baseline Loss: 2.6685 | Actual Loss: 0.5027\n",
      "Baseline Loss: 2.6575 | Actual Loss: 0.5870\n",
      "Baseline Loss: 2.6772 | Actual Loss: 0.4829\n",
      "Baseline Loss: 2.6849 | Actual Loss: 0.5425\n",
      "Baseline Loss: 2.6449 | Actual Loss: 0.3318\n",
      "Baseline Loss: 2.7059 | Actual Loss: 0.4022\n",
      "Baseline Loss: 2.7188 | Actual Loss: 0.5211\n",
      "Baseline Loss: 2.6653 | Actual Loss: 0.2169\n",
      "Baseline Loss: 2.6889 | Actual Loss: 0.5405\n",
      "Baseline Loss: 2.6500 | Actual Loss: 0.4591\n",
      "Baseline Loss: 2.2821 | Actual Loss: 0.3277\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.8284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 56/1000 [00:35<09:53,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6640 | Actual Loss: 0.6120\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4501\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3872\n",
      "Epoch 56/1000: Train Loss: 0.5559, Val Loss: 0.5694\n",
      "Baseline Loss: 2.6753 | Actual Loss: 0.5180\n",
      "Baseline Loss: 2.6597 | Actual Loss: 0.4484\n",
      "Baseline Loss: 2.6359 | Actual Loss: 0.5256\n",
      "Baseline Loss: 2.6654 | Actual Loss: 0.3254\n",
      "Baseline Loss: 2.6914 | Actual Loss: 0.4031\n",
      "Baseline Loss: 2.6503 | Actual Loss: 0.6226\n",
      "Baseline Loss: 2.6607 | Actual Loss: 0.3370\n",
      "Baseline Loss: 2.6766 | Actual Loss: 0.5194\n",
      "Baseline Loss: 2.6920 | Actual Loss: 0.2804\n",
      "Baseline Loss: 2.6913 | Actual Loss: 0.3967\n",
      "Baseline Loss: 2.6170 | Actual Loss: 0.7582\n",
      "Baseline Loss: 2.6236 | Actual Loss: 0.6014\n",
      "Baseline Loss: 2.6951 | Actual Loss: 0.5029\n",
      "Baseline Loss: 2.6776 | Actual Loss: 0.4838\n",
      "Baseline Loss: 2.7195 | Actual Loss: 0.5805\n",
      "Baseline Loss: 2.2990 | Actual Loss: 0.2757\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 57/1000 [00:36<09:46,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6640 | Actual Loss: 0.7578\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4431\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.1980\n",
      "Epoch 57/1000: Train Loss: 0.4737, Val Loss: 0.4644\n",
      "Baseline Loss: 2.6609 | Actual Loss: 0.3064\n",
      "Baseline Loss: 2.6826 | Actual Loss: 0.6762\n",
      "Baseline Loss: 2.6504 | Actual Loss: 0.4771\n",
      "Baseline Loss: 2.6838 | Actual Loss: 0.2540\n",
      "Baseline Loss: 2.6598 | Actual Loss: 0.2867\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.4892\n",
      "Baseline Loss: 2.6617 | Actual Loss: 1.9560\n",
      "Baseline Loss: 2.6934 | Actual Loss: 0.5476\n",
      "Baseline Loss: 2.6794 | Actual Loss: 1.4810\n",
      "Baseline Loss: 2.6458 | Actual Loss: 1.5693\n",
      "Baseline Loss: 2.7234 | Actual Loss: 1.8015\n",
      "Baseline Loss: 2.6456 | Actual Loss: 1.0994\n",
      "Baseline Loss: 2.6724 | Actual Loss: 0.5230\n",
      "Baseline Loss: 2.6607 | Actual Loss: 0.5747\n",
      "Baseline Loss: 2.7070 | Actual Loss: 0.3494\n",
      "Baseline Loss: 2.2664 | Actual Loss: 0.4406\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5389\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.7882\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 58/1000 [00:36<09:40,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6128 | Actual Loss: 0.4862\n",
      "Epoch 58/1000: Train Loss: 0.8020, Val Loss: 0.5838\n",
      "Baseline Loss: 2.6972 | Actual Loss: 0.5416\n",
      "Baseline Loss: 2.6327 | Actual Loss: 0.5315\n",
      "Baseline Loss: 2.6554 | Actual Loss: 0.5388\n",
      "Baseline Loss: 2.6805 | Actual Loss: 0.5771\n",
      "Baseline Loss: 2.6790 | Actual Loss: 0.3209\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.4543\n",
      "Baseline Loss: 2.6392 | Actual Loss: 0.3970\n",
      "Baseline Loss: 2.6571 | Actual Loss: 0.7193\n",
      "Baseline Loss: 2.6898 | Actual Loss: 0.8373\n",
      "Baseline Loss: 2.7264 | Actual Loss: 0.7154\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4001\n",
      "Baseline Loss: 2.6570 | Actual Loss: 0.6623\n",
      "Baseline Loss: 2.6920 | Actual Loss: 0.3878\n",
      "Baseline Loss: 2.6579 | Actual Loss: 1.0333\n",
      "Baseline Loss: 2.6741 | Actual Loss: 0.4240\n",
      "Baseline Loss: 2.2579 | Actual Loss: 0.3867\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5554\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.7795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 59/1000 [00:37<09:56,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6853 | Actual Loss: 0.4837\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.5107\n",
      "Epoch 59/1000: Train Loss: 0.5579, Val Loss: 0.5823\n",
      "Baseline Loss: 2.6811 | Actual Loss: 0.4512\n",
      "Baseline Loss: 2.6937 | Actual Loss: 0.5684\n",
      "Baseline Loss: 2.6826 | Actual Loss: 0.5507\n",
      "Baseline Loss: 2.6423 | Actual Loss: 0.2598\n",
      "Baseline Loss: 2.7052 | Actual Loss: 0.2732\n",
      "Baseline Loss: 2.6877 | Actual Loss: 0.3133\n",
      "Baseline Loss: 2.6353 | Actual Loss: 0.5446\n",
      "Baseline Loss: 2.6646 | Actual Loss: 0.4317\n",
      "Baseline Loss: 2.6698 | Actual Loss: 0.4306\n",
      "Baseline Loss: 2.6571 | Actual Loss: 0.5387\n",
      "Baseline Loss: 2.7140 | Actual Loss: 0.4482\n",
      "Baseline Loss: 2.6773 | Actual Loss: 0.9474\n",
      "Baseline Loss: 2.6772 | Actual Loss: 1.8530\n",
      "Baseline Loss: 2.6534 | Actual Loss: 0.2554\n",
      "Baseline Loss: 2.6510 | Actual Loss: 0.5438\n",
      "Baseline Loss: 2.3308 | Actual Loss: 0.2918\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.6036\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.7871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 60/1000 [00:38<09:57,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6853 | Actual Loss: 0.3918\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2775\n",
      "Epoch 60/1000: Train Loss: 0.5439, Val Loss: 0.5150\n",
      "Baseline Loss: 2.6612 | Actual Loss: 0.5402\n",
      "Baseline Loss: 2.7284 | Actual Loss: 0.3227\n",
      "Baseline Loss: 2.7072 | Actual Loss: 0.4626\n",
      "Baseline Loss: 2.7203 | Actual Loss: 0.2425\n",
      "Baseline Loss: 2.6436 | Actual Loss: 0.3513\n",
      "Baseline Loss: 2.6533 | Actual Loss: 0.3418\n",
      "Baseline Loss: 2.6535 | Actual Loss: 0.9283\n",
      "Baseline Loss: 2.6859 | Actual Loss: 0.8359\n",
      "Baseline Loss: 2.6660 | Actual Loss: 0.5691\n",
      "Baseline Loss: 2.6521 | Actual Loss: 0.5729\n",
      "Baseline Loss: 2.6933 | Actual Loss: 0.4575\n",
      "Baseline Loss: 2.6625 | Actual Loss: 2.1832\n",
      "Baseline Loss: 2.6727 | Actual Loss: 0.3857\n",
      "Baseline Loss: 2.6563 | Actual Loss: 0.5744\n",
      "Baseline Loss: 2.6761 | Actual Loss: 0.5757\n",
      "Baseline Loss: 2.2456 | Actual Loss: 0.4973\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5835\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.9924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 61/1000 [00:38<10:06,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6853 | Actual Loss: 0.7094\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3609\n",
      "Epoch 61/1000: Train Loss: 0.6151, Val Loss: 0.6616\n",
      "Baseline Loss: 2.6757 | Actual Loss: 0.8410\n",
      "Baseline Loss: 2.6824 | Actual Loss: 0.4861\n",
      "Baseline Loss: 2.6818 | Actual Loss: 0.5342\n",
      "Baseline Loss: 2.6669 | Actual Loss: 0.5990\n",
      "Baseline Loss: 2.6882 | Actual Loss: 0.3172\n",
      "Baseline Loss: 2.6528 | Actual Loss: 0.3676\n",
      "Baseline Loss: 2.6654 | Actual Loss: 0.5975\n",
      "Baseline Loss: 2.6559 | Actual Loss: 0.3270\n",
      "Baseline Loss: 2.6682 | Actual Loss: 0.6478\n",
      "Baseline Loss: 2.6843 | Actual Loss: 0.9214\n",
      "Baseline Loss: 2.6932 | Actual Loss: 0.7797\n",
      "Baseline Loss: 2.6707 | Actual Loss: 0.2396\n",
      "Baseline Loss: 2.6896 | Actual Loss: 0.4686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 62/1000 [00:39<09:52,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6676 | Actual Loss: 0.8891\n",
      "Baseline Loss: 2.6732 | Actual Loss: 0.5779\n",
      "Baseline Loss: 2.3017 | Actual Loss: 1.0058\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.6162\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.7062\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.3642\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3982\n",
      "Epoch 62/1000: Train Loss: 0.6000, Val Loss: 0.5212\n",
      "Baseline Loss: 2.6836 | Actual Loss: 0.4184\n",
      "Baseline Loss: 2.6701 | Actual Loss: 0.4403\n",
      "Baseline Loss: 2.6919 | Actual Loss: 0.4158\n",
      "Baseline Loss: 2.6557 | Actual Loss: 0.5256\n",
      "Baseline Loss: 2.6404 | Actual Loss: 0.6385\n",
      "Baseline Loss: 2.6752 | Actual Loss: 0.3946\n",
      "Baseline Loss: 2.6974 | Actual Loss: 0.9203\n",
      "Baseline Loss: 2.6744 | Actual Loss: 0.4517\n",
      "Baseline Loss: 2.6814 | Actual Loss: 0.3752\n",
      "Baseline Loss: 2.6538 | Actual Loss: 0.6841\n",
      "Baseline Loss: 2.6580 | Actual Loss: 0.3703\n",
      "Baseline Loss: 2.6737 | Actual Loss: 0.7423\n",
      "Baseline Loss: 2.6981 | Actual Loss: 0.4241\n",
      "Baseline Loss: 2.7009 | Actual Loss: 0.1500\n",
      "Baseline Loss: 2.6583 | Actual Loss: 0.5927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 63/1000 [00:40<09:58,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2433 | Actual Loss: 0.2056\n",
      "Baseline Loss: 2.6755 | Actual Loss: 1.0158\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.7915\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.3693\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.6644\n",
      "Epoch 63/1000: Train Loss: 0.4843, Val Loss: 0.7103\n",
      "Baseline Loss: 2.6894 | Actual Loss: 0.4305\n",
      "Baseline Loss: 2.6564 | Actual Loss: 0.3970\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.2158\n",
      "Baseline Loss: 2.6844 | Actual Loss: 2.1198\n",
      "Baseline Loss: 2.6581 | Actual Loss: 0.2219\n",
      "Baseline Loss: 2.7025 | Actual Loss: 0.3137\n",
      "Baseline Loss: 2.6689 | Actual Loss: 0.6162\n",
      "Baseline Loss: 2.6768 | Actual Loss: 0.4064\n",
      "Baseline Loss: 2.6908 | Actual Loss: 1.9616\n",
      "Baseline Loss: 2.6876 | Actual Loss: 0.5920\n",
      "Baseline Loss: 2.6849 | Actual Loss: 0.4342\n",
      "Baseline Loss: 2.6609 | Actual Loss: 0.5205\n",
      "Baseline Loss: 2.6622 | Actual Loss: 0.9140\n",
      "Baseline Loss: 2.6670 | Actual Loss: 0.7142\n",
      "Baseline Loss: 2.6743 | Actual Loss: 0.3268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 64/1000 [00:40<09:57,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.3166 | Actual Loss: 0.2892\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5110\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.7216\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4041\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2920\n",
      "Epoch 64/1000: Train Loss: 0.6546, Val Loss: 0.4822\n",
      "Baseline Loss: 2.6419 | Actual Loss: 0.8203\n",
      "Baseline Loss: 2.6989 | Actual Loss: 0.4680\n",
      "Baseline Loss: 2.6582 | Actual Loss: 0.3011\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.3260\n",
      "Baseline Loss: 2.6641 | Actual Loss: 0.5388\n",
      "Baseline Loss: 2.6801 | Actual Loss: 0.9637\n",
      "Baseline Loss: 2.6631 | Actual Loss: 1.0265\n",
      "Baseline Loss: 2.6998 | Actual Loss: 0.7603\n",
      "Baseline Loss: 2.6407 | Actual Loss: 0.6869\n",
      "Baseline Loss: 2.6512 | Actual Loss: 0.5507\n",
      "Baseline Loss: 2.6414 | Actual Loss: 0.6262\n",
      "Baseline Loss: 2.6978 | Actual Loss: 0.5534\n",
      "Baseline Loss: 2.6980 | Actual Loss: 0.2527\n",
      "Baseline Loss: 2.6598 | Actual Loss: 0.9263\n",
      "Baseline Loss: 2.6879 | Actual Loss: 0.2414\n",
      "Baseline Loss: 2.2525 | Actual Loss: 0.2109\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5810\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6417\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 65/1000 [00:41<09:41,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6128 | Actual Loss: 0.3501\n",
      "Epoch 65/1000: Train Loss: 0.5783, Val Loss: 0.5008\n",
      "Baseline Loss: 2.7163 | Actual Loss: 0.5520\n",
      "Baseline Loss: 2.6932 | Actual Loss: 0.4454\n",
      "Baseline Loss: 2.6872 | Actual Loss: 0.6318\n",
      "Baseline Loss: 2.6970 | Actual Loss: 0.7477\n",
      "Baseline Loss: 2.6688 | Actual Loss: 0.4181\n",
      "Baseline Loss: 2.6745 | Actual Loss: 0.5292\n",
      "Baseline Loss: 2.6313 | Actual Loss: 0.6685\n",
      "Baseline Loss: 2.6737 | Actual Loss: 0.4798\n",
      "Baseline Loss: 2.6676 | Actual Loss: 0.3827\n",
      "Baseline Loss: 2.6662 | Actual Loss: 0.5262\n",
      "Baseline Loss: 2.6868 | Actual Loss: 0.4267\n",
      "Baseline Loss: 2.6841 | Actual Loss: 0.3811\n",
      "Baseline Loss: 2.6707 | Actual Loss: 0.3986\n",
      "Baseline Loss: 2.6694 | Actual Loss: 0.3047\n",
      "Baseline Loss: 2.6756 | Actual Loss: 1.3308\n",
      "Baseline Loss: 2.2652 | Actual Loss: 0.5707\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.6396\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.7643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 66/1000 [00:42<09:55,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6853 | Actual Loss: 0.2309\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2731\n",
      "Epoch 66/1000: Train Loss: 0.5496, Val Loss: 0.4770\n",
      "Baseline Loss: 2.6820 | Actual Loss: 0.1851\n",
      "Baseline Loss: 2.6592 | Actual Loss: 0.6814\n",
      "Baseline Loss: 2.6844 | Actual Loss: 0.5506\n",
      "Baseline Loss: 2.6962 | Actual Loss: 0.4782\n",
      "Baseline Loss: 2.6665 | Actual Loss: 0.3580\n",
      "Baseline Loss: 2.6641 | Actual Loss: 0.2945\n",
      "Baseline Loss: 2.6739 | Actual Loss: 0.6229\n",
      "Baseline Loss: 2.6696 | Actual Loss: 0.2288\n",
      "Baseline Loss: 2.6519 | Actual Loss: 0.5542\n",
      "Baseline Loss: 2.6815 | Actual Loss: 0.5916\n",
      "Baseline Loss: 2.7481 | Actual Loss: 2.0493\n",
      "Baseline Loss: 2.6803 | Actual Loss: 0.7780\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.1576\n",
      "Baseline Loss: 2.6600 | Actual Loss: 0.5036\n",
      "Baseline Loss: 2.6565 | Actual Loss: 0.7368\n",
      "Baseline Loss: 2.3220 | Actual Loss: 0.3225\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4992\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.8219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 67/1000 [00:42<09:56,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6853 | Actual Loss: 0.4139\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.1919\n",
      "Epoch 67/1000: Train Loss: 0.5683, Val Loss: 0.4817\n",
      "Baseline Loss: 2.6699 | Actual Loss: 0.6928\n",
      "Baseline Loss: 2.6472 | Actual Loss: 0.4518\n",
      "Baseline Loss: 2.6643 | Actual Loss: 0.4074\n",
      "Baseline Loss: 2.6598 | Actual Loss: 1.2140\n",
      "Baseline Loss: 2.7079 | Actual Loss: 0.4673\n",
      "Baseline Loss: 2.6462 | Actual Loss: 0.4295\n",
      "Baseline Loss: 2.7321 | Actual Loss: 0.4022\n",
      "Baseline Loss: 2.6890 | Actual Loss: 0.3539\n",
      "Baseline Loss: 2.6478 | Actual Loss: 0.4162\n",
      "Baseline Loss: 2.6981 | Actual Loss: 0.3162\n",
      "Baseline Loss: 2.6711 | Actual Loss: 0.2038\n",
      "Baseline Loss: 2.6675 | Actual Loss: 0.5221\n",
      "Baseline Loss: 2.6741 | Actual Loss: 0.3011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 68/1000 [00:43<09:39,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6952 | Actual Loss: 0.1568\n",
      "Baseline Loss: 2.6741 | Actual Loss: 0.7863\n",
      "Baseline Loss: 2.2120 | Actual Loss: 0.3775\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5542\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.7713\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5267\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2656\n",
      "Epoch 68/1000: Train Loss: 0.4687, Val Loss: 0.5294\n",
      "Baseline Loss: 2.6825 | Actual Loss: 0.6380\n",
      "Baseline Loss: 2.6478 | Actual Loss: 0.3421\n",
      "Baseline Loss: 2.6585 | Actual Loss: 0.6423\n",
      "Baseline Loss: 2.6897 | Actual Loss: 0.4825\n",
      "Baseline Loss: 2.6780 | Actual Loss: 0.5876\n",
      "Baseline Loss: 2.6872 | Actual Loss: 0.3340\n",
      "Baseline Loss: 2.7073 | Actual Loss: 0.4552\n",
      "Baseline Loss: 2.6571 | Actual Loss: 0.5558\n",
      "Baseline Loss: 2.6895 | Actual Loss: 0.6352\n",
      "Baseline Loss: 2.6728 | Actual Loss: 0.2386\n",
      "Baseline Loss: 2.6721 | Actual Loss: 1.1838\n",
      "Baseline Loss: 2.6692 | Actual Loss: 0.2661\n",
      "Baseline Loss: 2.6728 | Actual Loss: 0.3508\n",
      "Baseline Loss: 2.6808 | Actual Loss: 0.5313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 69/1000 [00:43<09:53,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6842 | Actual Loss: 0.4396\n",
      "Baseline Loss: 2.2171 | Actual Loss: 0.3324\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4960\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6798\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4626\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2594\n",
      "Epoch 69/1000: Train Loss: 0.5009, Val Loss: 0.4744\n",
      "Baseline Loss: 2.6832 | Actual Loss: 0.5332\n",
      "Baseline Loss: 2.6893 | Actual Loss: 0.2370\n",
      "Baseline Loss: 2.6762 | Actual Loss: 0.3996\n",
      "Baseline Loss: 2.6908 | Actual Loss: 0.4706\n",
      "Baseline Loss: 2.6410 | Actual Loss: 0.2507\n",
      "Baseline Loss: 2.6363 | Actual Loss: 0.2935\n",
      "Baseline Loss: 2.6581 | Actual Loss: 0.3881\n",
      "Baseline Loss: 2.7052 | Actual Loss: 0.2628\n",
      "Baseline Loss: 2.6664 | Actual Loss: 0.4555\n",
      "Baseline Loss: 2.7041 | Actual Loss: 0.3972\n",
      "Baseline Loss: 2.6973 | Actual Loss: 0.3918\n",
      "Baseline Loss: 2.6809 | Actual Loss: 0.4228\n",
      "Baseline Loss: 2.6871 | Actual Loss: 0.6376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 70/1000 [00:44<09:58,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6788 | Actual Loss: 0.4759\n",
      "Baseline Loss: 2.6686 | Actual Loss: 0.5368\n",
      "Baseline Loss: 2.2922 | Actual Loss: 0.1799\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5817\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.7013\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.3426\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3935\n",
      "Epoch 70/1000: Train Loss: 0.3958, Val Loss: 0.5048\n",
      "Baseline Loss: 2.7235 | Actual Loss: 0.1506\n",
      "Baseline Loss: 2.6629 | Actual Loss: 0.4615\n",
      "Baseline Loss: 2.6343 | Actual Loss: 0.2463\n",
      "Baseline Loss: 2.6632 | Actual Loss: 0.7066\n",
      "Baseline Loss: 2.6585 | Actual Loss: 0.3327\n",
      "Baseline Loss: 2.6211 | Actual Loss: 0.4283\n",
      "Baseline Loss: 2.6998 | Actual Loss: 0.4767\n",
      "Baseline Loss: 2.6831 | Actual Loss: 0.4845\n",
      "Baseline Loss: 2.6711 | Actual Loss: 0.9736\n",
      "Baseline Loss: 2.6597 | Actual Loss: 0.3191\n",
      "Baseline Loss: 2.6718 | Actual Loss: 0.1855\n",
      "Baseline Loss: 2.6478 | Actual Loss: 0.3797\n",
      "Baseline Loss: 2.7353 | Actual Loss: 0.5959\n",
      "Baseline Loss: 2.6658 | Actual Loss: 0.4073\n",
      "Baseline Loss: 2.7305 | Actual Loss: 0.2184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 71/1000 [00:45<09:42,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2734 | Actual Loss: 0.4042\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.6154\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.7651\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.3652\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3816\n",
      "Epoch 71/1000: Train Loss: 0.4232, Val Loss: 0.5318\n",
      "Baseline Loss: 2.6406 | Actual Loss: 0.5393\n",
      "Baseline Loss: 2.6406 | Actual Loss: 0.7221\n",
      "Baseline Loss: 2.6848 | Actual Loss: 0.4218\n",
      "Baseline Loss: 2.7092 | Actual Loss: 0.6012\n",
      "Baseline Loss: 2.6802 | Actual Loss: 0.3731\n",
      "Baseline Loss: 2.6763 | Actual Loss: 0.3400\n",
      "Baseline Loss: 2.6785 | Actual Loss: 0.4796\n",
      "Baseline Loss: 2.6687 | Actual Loss: 0.2865\n",
      "Baseline Loss: 2.6703 | Actual Loss: 0.4218\n",
      "Baseline Loss: 2.6672 | Actual Loss: 0.5217\n",
      "Baseline Loss: 2.6910 | Actual Loss: 0.5866\n",
      "Baseline Loss: 2.6266 | Actual Loss: 0.3041\n",
      "Baseline Loss: 2.6649 | Actual Loss: 0.3648\n",
      "Baseline Loss: 2.6736 | Actual Loss: 0.5912\n",
      "Baseline Loss: 2.6549 | Actual Loss: 0.5746\n",
      "Baseline Loss: 2.2856 | Actual Loss: 0.1119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 72/1000 [00:45<09:37,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6755 | Actual Loss: 0.8257\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.8338\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.3262\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3899\n",
      "Epoch 72/1000: Train Loss: 0.4525, Val Loss: 0.5939\n",
      "Baseline Loss: 2.6737 | Actual Loss: 0.5297\n",
      "Baseline Loss: 2.7128 | Actual Loss: 1.5632\n",
      "Baseline Loss: 2.6963 | Actual Loss: 0.2199\n",
      "Baseline Loss: 2.6753 | Actual Loss: 0.5969\n",
      "Baseline Loss: 2.6729 | Actual Loss: 0.6063\n",
      "Baseline Loss: 2.6689 | Actual Loss: 0.6717\n",
      "Baseline Loss: 2.6721 | Actual Loss: 0.6594\n",
      "Baseline Loss: 2.6692 | Actual Loss: 0.3332\n",
      "Baseline Loss: 2.6596 | Actual Loss: 0.1505\n",
      "Baseline Loss: 2.6478 | Actual Loss: 0.6031\n",
      "Baseline Loss: 2.6775 | Actual Loss: 0.2679\n",
      "Baseline Loss: 2.6764 | Actual Loss: 0.2805\n",
      "Baseline Loss: 2.7292 | Actual Loss: 0.1751\n",
      "Baseline Loss: 2.6487 | Actual Loss: 0.6522\n",
      "Baseline Loss: 2.6830 | Actual Loss: 0.2451\n",
      "Baseline Loss: 2.2617 | Actual Loss: 0.2900\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5317\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.8778\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 73/1000 [00:46<09:31,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6128 | Actual Loss: 0.6003\n",
      "Epoch 73/1000: Train Loss: 0.4903, Val Loss: 0.6185\n",
      "Baseline Loss: 2.7091 | Actual Loss: 0.3956\n",
      "Baseline Loss: 2.6844 | Actual Loss: 0.3697\n",
      "Baseline Loss: 2.7152 | Actual Loss: 0.4853\n",
      "Baseline Loss: 2.6793 | Actual Loss: 0.5766\n",
      "Baseline Loss: 2.6493 | Actual Loss: 1.2501\n",
      "Baseline Loss: 2.6591 | Actual Loss: 1.7232\n",
      "Baseline Loss: 2.6596 | Actual Loss: 1.0038\n",
      "Baseline Loss: 2.6800 | Actual Loss: 0.1286\n",
      "Baseline Loss: 2.6547 | Actual Loss: 0.5091\n",
      "Baseline Loss: 2.6612 | Actual Loss: 0.3632\n",
      "Baseline Loss: 2.6672 | Actual Loss: 0.4295\n",
      "Baseline Loss: 2.6771 | Actual Loss: 0.4657\n",
      "Baseline Loss: 2.6586 | Actual Loss: 0.5442\n",
      "Baseline Loss: 2.6650 | Actual Loss: 0.3580\n",
      "Baseline Loss: 2.7058 | Actual Loss: 0.5105\n",
      "Baseline Loss: 2.2602 | Actual Loss: 0.2118\n",
      "Baseline Loss: 2.6755 | Actual Loss: 1.0420\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.9516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 74/1000 [00:47<09:46,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6853 | Actual Loss: 0.4220\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.8189\n",
      "Epoch 74/1000: Train Loss: 0.5828, Val Loss: 0.8086\n",
      "Baseline Loss: 2.6976 | Actual Loss: 0.4724\n",
      "Baseline Loss: 2.6718 | Actual Loss: 1.1210\n",
      "Baseline Loss: 2.6342 | Actual Loss: 0.3361\n",
      "Baseline Loss: 2.7219 | Actual Loss: 0.4159\n",
      "Baseline Loss: 2.6375 | Actual Loss: 0.5078\n",
      "Baseline Loss: 2.6885 | Actual Loss: 0.3876\n",
      "Baseline Loss: 2.6495 | Actual Loss: 0.3648\n",
      "Baseline Loss: 2.7276 | Actual Loss: 0.3915\n",
      "Baseline Loss: 2.6407 | Actual Loss: 0.4581\n",
      "Baseline Loss: 2.6837 | Actual Loss: 0.3154\n",
      "Baseline Loss: 2.6732 | Actual Loss: 0.3805\n",
      "Baseline Loss: 2.6687 | Actual Loss: 0.5579\n",
      "Baseline Loss: 2.6490 | Actual Loss: 0.4396\n",
      "Baseline Loss: 2.6656 | Actual Loss: 0.1943\n",
      "Baseline Loss: 2.7073 | Actual Loss: 0.2858\n",
      "Baseline Loss: 2.2305 | Actual Loss: 0.5679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 75/1000 [00:47<09:53,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6755 | Actual Loss: 1.1347\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.7458\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.3842\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.6460\n",
      "Epoch 75/1000: Train Loss: 0.4498, Val Loss: 0.7277\n",
      "Baseline Loss: 2.6759 | Actual Loss: 0.2234\n",
      "Baseline Loss: 2.7012 | Actual Loss: 0.2614\n",
      "Baseline Loss: 2.6620 | Actual Loss: 0.5944\n",
      "Baseline Loss: 2.6445 | Actual Loss: 2.3330\n",
      "Baseline Loss: 2.6515 | Actual Loss: 0.2495\n",
      "Baseline Loss: 2.6999 | Actual Loss: 0.3617\n",
      "Baseline Loss: 2.6641 | Actual Loss: 1.8286\n",
      "Baseline Loss: 2.6802 | Actual Loss: 0.2560\n",
      "Baseline Loss: 2.6578 | Actual Loss: 0.3399\n",
      "Baseline Loss: 2.6707 | Actual Loss: 0.5745\n",
      "Baseline Loss: 2.6830 | Actual Loss: 0.3370\n",
      "Baseline Loss: 2.6791 | Actual Loss: 0.3397\n",
      "Baseline Loss: 2.6427 | Actual Loss: 0.4666\n",
      "Baseline Loss: 2.6848 | Actual Loss: 0.5260\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.3926\n",
      "Baseline Loss: 2.2812 | Actual Loss: 0.5095\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5488\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.7702\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 76/1000 [00:48<09:37,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6128 | Actual Loss: 0.2797\n",
      "Epoch 76/1000: Train Loss: 0.5996, Val Loss: 0.5177\n",
      "Baseline Loss: 2.6803 | Actual Loss: 0.2954\n",
      "Baseline Loss: 2.6627 | Actual Loss: 1.1356\n",
      "Baseline Loss: 2.6547 | Actual Loss: 0.4590\n",
      "Baseline Loss: 2.6567 | Actual Loss: 0.2713\n",
      "Baseline Loss: 2.6645 | Actual Loss: 0.4799\n",
      "Baseline Loss: 2.6626 | Actual Loss: 0.4878\n",
      "Baseline Loss: 2.6340 | Actual Loss: 1.5222\n",
      "Baseline Loss: 2.7024 | Actual Loss: 0.3583\n",
      "Baseline Loss: 2.6724 | Actual Loss: 0.4443\n",
      "Baseline Loss: 2.6607 | Actual Loss: 0.5124\n",
      "Baseline Loss: 2.6711 | Actual Loss: 0.5305\n",
      "Baseline Loss: 2.6947 | Actual Loss: 0.5883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 77/1000 [00:48<09:41,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7200 | Actual Loss: 0.3728\n",
      "Baseline Loss: 2.6676 | Actual Loss: 0.4896\n",
      "Baseline Loss: 2.6890 | Actual Loss: 0.5657\n",
      "Baseline Loss: 2.2954 | Actual Loss: 0.4699\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4201\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5934\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.3812\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.4082\n",
      "Epoch 77/1000: Train Loss: 0.5614, Val Loss: 0.4507\n",
      "Baseline Loss: 2.6775 | Actual Loss: 0.5232\n",
      "Baseline Loss: 2.7188 | Actual Loss: 0.4010\n",
      "Baseline Loss: 2.6470 | Actual Loss: 0.2805\n",
      "Baseline Loss: 2.6872 | Actual Loss: 0.6890\n",
      "Baseline Loss: 2.6637 | Actual Loss: 0.3284\n",
      "Baseline Loss: 2.7026 | Actual Loss: 0.1367\n",
      "Baseline Loss: 2.6618 | Actual Loss: 0.2366\n",
      "Baseline Loss: 2.6352 | Actual Loss: 1.0251\n",
      "Baseline Loss: 2.6503 | Actual Loss: 0.4006\n",
      "Baseline Loss: 2.7678 | Actual Loss: 0.2897\n",
      "Baseline Loss: 2.6418 | Actual Loss: 0.6901\n",
      "Baseline Loss: 2.6668 | Actual Loss: 0.5110\n",
      "Baseline Loss: 2.6457 | Actual Loss: 0.4491\n",
      "Baseline Loss: 2.6407 | Actual Loss: 0.5712\n",
      "Baseline Loss: 2.7034 | Actual Loss: 0.4856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 78/1000 [00:49<09:30,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2398 | Actual Loss: 0.0997\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5367\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6143\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4213\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.4250\n",
      "Epoch 78/1000: Train Loss: 0.4449, Val Loss: 0.4993\n",
      "Baseline Loss: 2.6584 | Actual Loss: 0.5134\n",
      "Baseline Loss: 2.6793 | Actual Loss: 0.3116\n",
      "Baseline Loss: 2.6737 | Actual Loss: 0.4467\n",
      "Baseline Loss: 2.6906 | Actual Loss: 0.3609\n",
      "Baseline Loss: 2.6805 | Actual Loss: 0.3471\n",
      "Baseline Loss: 2.6642 | Actual Loss: 0.3222\n",
      "Baseline Loss: 2.7035 | Actual Loss: 0.2629\n",
      "Baseline Loss: 2.6866 | Actual Loss: 0.2063\n",
      "Baseline Loss: 2.6656 | Actual Loss: 0.4941\n",
      "Baseline Loss: 2.6329 | Actual Loss: 0.1128\n",
      "Baseline Loss: 2.7308 | Actual Loss: 0.2727\n",
      "Baseline Loss: 2.6688 | Actual Loss: 0.4223\n",
      "Baseline Loss: 2.6335 | Actual Loss: 0.4457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 79/1000 [00:50<09:44,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6502 | Actual Loss: 0.3344\n",
      "Baseline Loss: 2.6677 | Actual Loss: 0.4553\n",
      "Baseline Loss: 2.3150 | Actual Loss: 0.0939\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4514\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5059\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2960\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2968\n",
      "Epoch 79/1000: Train Loss: 0.3376, Val Loss: 0.3875\n",
      "New best validation loss: 0.3875\n",
      "Baseline Loss: 2.6823 | Actual Loss: 0.6264\n",
      "Baseline Loss: 2.7154 | Actual Loss: 0.6879\n",
      "Baseline Loss: 2.6924 | Actual Loss: 0.2092\n",
      "Baseline Loss: 2.6361 | Actual Loss: 0.2435\n",
      "Baseline Loss: 2.6829 | Actual Loss: 0.5027\n",
      "Baseline Loss: 2.7041 | Actual Loss: 0.4819\n",
      "Baseline Loss: 2.6960 | Actual Loss: 0.5017\n",
      "Baseline Loss: 2.6669 | Actual Loss: 0.3135\n",
      "Baseline Loss: 2.6725 | Actual Loss: 0.3216\n",
      "Baseline Loss: 2.7027 | Actual Loss: 0.5577\n",
      "Baseline Loss: 2.6904 | Actual Loss: 0.3646\n",
      "Baseline Loss: 2.6584 | Actual Loss: 0.2002\n",
      "Baseline Loss: 2.6656 | Actual Loss: 0.1997\n",
      "Baseline Loss: 2.6581 | Actual Loss: 0.3846\n",
      "Baseline Loss: 2.6625 | Actual Loss: 0.6005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 80/1000 [00:50<09:54,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2393 | Actual Loss: 0.2590\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5803\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.7276\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.4487\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3836\n",
      "Epoch 80/1000: Train Loss: 0.4034, Val Loss: 0.5350\n",
      "Baseline Loss: 2.6793 | Actual Loss: 0.2808\n",
      "Baseline Loss: 2.7020 | Actual Loss: 0.2498\n",
      "Baseline Loss: 2.6973 | Actual Loss: 1.2590\n",
      "Baseline Loss: 2.6707 | Actual Loss: 0.5045\n",
      "Baseline Loss: 2.6830 | Actual Loss: 0.4116\n",
      "Baseline Loss: 2.6973 | Actual Loss: 0.4016\n",
      "Baseline Loss: 2.6568 | Actual Loss: 0.5110\n",
      "Baseline Loss: 2.6628 | Actual Loss: 0.3252\n",
      "Baseline Loss: 2.7134 | Actual Loss: 0.4177\n",
      "Baseline Loss: 2.6533 | Actual Loss: 0.5652\n",
      "Baseline Loss: 2.6695 | Actual Loss: 0.8704\n",
      "Baseline Loss: 2.6579 | Actual Loss: 0.5684\n",
      "Baseline Loss: 2.7029 | Actual Loss: 0.2152\n",
      "Baseline Loss: 2.6889 | Actual Loss: 0.4110\n",
      "Baseline Loss: 2.6375 | Actual Loss: 0.0474\n",
      "Baseline Loss: 2.2297 | Actual Loss: 0.1641\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5142\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 81/1000 [00:51<09:57,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6853 | Actual Loss: 0.3294\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3465\n",
      "Epoch 81/1000: Train Loss: 0.4502, Val Loss: 0.4516\n",
      "Baseline Loss: 2.6594 | Actual Loss: 0.5529\n",
      "Baseline Loss: 2.6891 | Actual Loss: 0.3957\n",
      "Baseline Loss: 2.7064 | Actual Loss: 0.3748\n",
      "Baseline Loss: 2.6921 | Actual Loss: 0.3892\n",
      "Baseline Loss: 2.6534 | Actual Loss: 0.2712\n",
      "Baseline Loss: 2.7272 | Actual Loss: 0.3917\n",
      "Baseline Loss: 2.6829 | Actual Loss: 0.5227\n",
      "Baseline Loss: 2.6867 | Actual Loss: 0.6572\n",
      "Baseline Loss: 2.6618 | Actual Loss: 0.3102\n",
      "Baseline Loss: 2.6708 | Actual Loss: 0.3497\n",
      "Baseline Loss: 2.6712 | Actual Loss: 0.5118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 82/1000 [00:52<09:40,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6726 | Actual Loss: 0.2746\n",
      "Baseline Loss: 2.6313 | Actual Loss: 0.8523\n",
      "Baseline Loss: 2.6650 | Actual Loss: 0.1689\n",
      "Baseline Loss: 2.6673 | Actual Loss: 0.1719\n",
      "Baseline Loss: 2.2933 | Actual Loss: 0.2882\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5141\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6350\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2842\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2576\n",
      "Epoch 82/1000: Train Loss: 0.4052, Val Loss: 0.4227\n",
      "Baseline Loss: 2.6776 | Actual Loss: 0.2094\n",
      "Baseline Loss: 2.6772 | Actual Loss: 0.2288\n",
      "Baseline Loss: 2.6574 | Actual Loss: 0.4065\n",
      "Baseline Loss: 2.6555 | Actual Loss: 0.2477\n",
      "Baseline Loss: 2.6782 | Actual Loss: 0.5236\n",
      "Baseline Loss: 2.6778 | Actual Loss: 0.3926\n",
      "Baseline Loss: 2.6723 | Actual Loss: 1.4170\n",
      "Baseline Loss: 2.6802 | Actual Loss: 0.2275\n",
      "Baseline Loss: 2.6903 | Actual Loss: 0.3384\n",
      "Baseline Loss: 2.6394 | Actual Loss: 0.2991\n",
      "Baseline Loss: 2.6711 | Actual Loss: 0.4140\n",
      "Baseline Loss: 2.6987 | Actual Loss: 0.2925\n",
      "Baseline Loss: 2.6649 | Actual Loss: 0.9911\n",
      "Baseline Loss: 2.6830 | Actual Loss: 0.3473\n",
      "Baseline Loss: 2.6357 | Actual Loss: 0.6601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 83/1000 [00:52<09:41,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.3345 | Actual Loss: 0.6217\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.7528\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6784\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2190\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3610\n",
      "Epoch 83/1000: Train Loss: 0.4761, Val Loss: 0.5028\n",
      "Baseline Loss: 2.6849 | Actual Loss: 0.6274\n",
      "Baseline Loss: 2.6728 | Actual Loss: 0.4646\n",
      "Baseline Loss: 2.6795 | Actual Loss: 0.4064\n",
      "Baseline Loss: 2.7117 | Actual Loss: 0.3168\n",
      "Baseline Loss: 2.6303 | Actual Loss: 0.5815\n",
      "Baseline Loss: 2.6769 | Actual Loss: 0.5071\n",
      "Baseline Loss: 2.6743 | Actual Loss: 0.1785\n",
      "Baseline Loss: 2.6895 | Actual Loss: 0.4468\n",
      "Baseline Loss: 2.6872 | Actual Loss: 0.4188\n",
      "Baseline Loss: 2.6672 | Actual Loss: 0.2893\n",
      "Baseline Loss: 2.6508 | Actual Loss: 0.7964\n",
      "Baseline Loss: 2.6437 | Actual Loss: 0.1491\n",
      "Baseline Loss: 2.6584 | Actual Loss: 0.4830\n",
      "Baseline Loss: 2.6818 | Actual Loss: 0.1108\n",
      "Baseline Loss: 2.6999 | Actual Loss: 0.1653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 84/1000 [00:53<09:55,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2418 | Actual Loss: 0.1810\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4719\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6101\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2794\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3042\n",
      "Epoch 84/1000: Train Loss: 0.3827, Val Loss: 0.4164\n",
      "Baseline Loss: 2.6555 | Actual Loss: 0.1614\n",
      "Baseline Loss: 2.6616 | Actual Loss: 0.2717\n",
      "Baseline Loss: 2.7038 | Actual Loss: 0.1847\n",
      "Baseline Loss: 2.6707 | Actual Loss: 0.4531\n",
      "Baseline Loss: 2.7205 | Actual Loss: 0.3280\n",
      "Baseline Loss: 2.6572 | Actual Loss: 0.7185\n",
      "Baseline Loss: 2.6804 | Actual Loss: 0.2954\n",
      "Baseline Loss: 2.6823 | Actual Loss: 0.0922\n",
      "Baseline Loss: 2.6992 | Actual Loss: 0.2656\n",
      "Baseline Loss: 2.6637 | Actual Loss: 0.3975\n",
      "Baseline Loss: 2.6810 | Actual Loss: 0.5209\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.3387\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3601\n",
      "Baseline Loss: 2.6839 | Actual Loss: 0.6263\n",
      "Baseline Loss: 2.6786 | Actual Loss: 0.3413\n",
      "Baseline Loss: 2.2077 | Actual Loss: 0.2790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 85/1000 [00:54<09:44,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6755 | Actual Loss: 0.4736\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6087\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.3286\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.1931\n",
      "Epoch 85/1000: Train Loss: 0.3522, Val Loss: 0.4010\n",
      "Baseline Loss: 2.6822 | Actual Loss: 0.2648\n",
      "Baseline Loss: 2.7511 | Actual Loss: 0.4707\n",
      "Baseline Loss: 2.6582 | Actual Loss: 0.7612\n",
      "Baseline Loss: 2.6625 | Actual Loss: 0.2507\n",
      "Baseline Loss: 2.6943 | Actual Loss: 0.2910\n",
      "Baseline Loss: 2.6747 | Actual Loss: 0.5144\n",
      "Baseline Loss: 2.6459 | Actual Loss: 0.4242\n",
      "Baseline Loss: 2.6815 | Actual Loss: 0.4741\n",
      "Baseline Loss: 2.6686 | Actual Loss: 0.3979\n",
      "Baseline Loss: 2.6580 | Actual Loss: 0.4375\n",
      "Baseline Loss: 2.6928 | Actual Loss: 0.2890\n",
      "Baseline Loss: 2.6546 | Actual Loss: 0.4508\n",
      "Baseline Loss: 2.7096 | Actual Loss: 0.5987\n",
      "Baseline Loss: 2.6642 | Actual Loss: 0.3520\n",
      "Baseline Loss: 2.6553 | Actual Loss: 0.2203\n",
      "Baseline Loss: 2.2659 | Actual Loss: 0.3635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▊         | 86/1000 [00:54<09:42,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6755 | Actual Loss: 0.4239\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6612\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2738\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3211\n",
      "Epoch 86/1000: Train Loss: 0.4100, Val Loss: 0.4200\n",
      "Baseline Loss: 2.7104 | Actual Loss: 0.2725\n",
      "Baseline Loss: 2.7005 | Actual Loss: 0.3964\n",
      "Baseline Loss: 2.6668 | Actual Loss: 0.2400\n",
      "Baseline Loss: 2.7138 | Actual Loss: 0.1922\n",
      "Baseline Loss: 2.6732 | Actual Loss: 0.2580\n",
      "Baseline Loss: 2.6492 | Actual Loss: 0.2271\n",
      "Baseline Loss: 2.6515 | Actual Loss: 0.3535\n",
      "Baseline Loss: 2.6599 | Actual Loss: 0.6084\n",
      "Baseline Loss: 2.6586 | Actual Loss: 0.7196\n",
      "Baseline Loss: 2.6725 | Actual Loss: 0.2331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▊         | 87/1000 [00:55<09:42,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7345 | Actual Loss: 1.7678\n",
      "Baseline Loss: 2.6385 | Actual Loss: 0.5644\n",
      "Baseline Loss: 2.6678 | Actual Loss: 0.4361\n",
      "Baseline Loss: 2.6792 | Actual Loss: 0.5523\n",
      "Baseline Loss: 2.6749 | Actual Loss: 0.2556\n",
      "Baseline Loss: 2.2785 | Actual Loss: 0.1577\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4659\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6791\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.3181\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2517\n",
      "Epoch 87/1000: Train Loss: 0.4522, Val Loss: 0.4287\n",
      "Baseline Loss: 2.6696 | Actual Loss: 0.3187\n",
      "Baseline Loss: 2.6728 | Actual Loss: 0.6187\n",
      "Baseline Loss: 2.6641 | Actual Loss: 0.2808\n",
      "Baseline Loss: 2.6959 | Actual Loss: 0.1924\n",
      "Baseline Loss: 2.7053 | Actual Loss: 0.3548\n",
      "Baseline Loss: 2.6259 | Actual Loss: 0.3458\n",
      "Baseline Loss: 2.6494 | Actual Loss: 1.0324\n",
      "Baseline Loss: 2.6712 | Actual Loss: 0.3132\n",
      "Baseline Loss: 2.6526 | Actual Loss: 0.4038\n",
      "Baseline Loss: 2.7038 | Actual Loss: 0.4189\n",
      "Baseline Loss: 2.7169 | Actual Loss: 0.4498\n",
      "Baseline Loss: 2.6959 | Actual Loss: 0.3438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 88/1000 [00:55<09:30,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6575 | Actual Loss: 0.1987\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3755\n",
      "Baseline Loss: 2.6960 | Actual Loss: 0.2945\n",
      "Baseline Loss: 2.3098 | Actual Loss: 0.4214\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4099\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6650\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2835\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3854\n",
      "Epoch 88/1000: Train Loss: 0.3977, Val Loss: 0.4360\n",
      "Baseline Loss: 2.6534 | Actual Loss: 0.4273\n",
      "Baseline Loss: 2.6786 | Actual Loss: 0.2585\n",
      "Baseline Loss: 2.6864 | Actual Loss: 0.2280\n",
      "Baseline Loss: 2.6730 | Actual Loss: 0.3249\n",
      "Baseline Loss: 2.6610 | Actual Loss: 0.3704\n",
      "Baseline Loss: 2.6672 | Actual Loss: 0.5238\n",
      "Baseline Loss: 2.6682 | Actual Loss: 0.4840\n",
      "Baseline Loss: 2.6558 | Actual Loss: 0.2457\n",
      "Baseline Loss: 2.6628 | Actual Loss: 0.2268\n",
      "Baseline Loss: 2.6752 | Actual Loss: 0.2489\n",
      "Baseline Loss: 2.7224 | Actual Loss: 0.6660\n",
      "Baseline Loss: 2.6525 | Actual Loss: 0.6051\n",
      "Baseline Loss: 2.6728 | Actual Loss: 0.2803\n",
      "Baseline Loss: 2.6681 | Actual Loss: 0.1036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 89/1000 [00:56<09:33,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6932 | Actual Loss: 0.3260\n",
      "Baseline Loss: 2.2461 | Actual Loss: 0.1915\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4521\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5377\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.3109\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3093\n",
      "Epoch 89/1000: Train Loss: 0.3444, Val Loss: 0.4025\n",
      "Baseline Loss: 2.6497 | Actual Loss: 0.2149\n",
      "Baseline Loss: 2.6891 | Actual Loss: 0.3575\n",
      "Baseline Loss: 2.6506 | Actual Loss: 0.5055\n",
      "Baseline Loss: 2.7002 | Actual Loss: 0.4867\n",
      "Baseline Loss: 2.6519 | Actual Loss: 1.0203\n",
      "Baseline Loss: 2.6669 | Actual Loss: 0.2530\n",
      "Baseline Loss: 2.6963 | Actual Loss: 0.3876\n",
      "Baseline Loss: 2.7084 | Actual Loss: 0.2377\n",
      "Baseline Loss: 2.6680 | Actual Loss: 0.3233\n",
      "Baseline Loss: 2.6444 | Actual Loss: 0.4996\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.6496\n",
      "Baseline Loss: 2.6648 | Actual Loss: 0.3449\n",
      "Baseline Loss: 2.6468 | Actual Loss: 0.5034\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.2656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 90/1000 [00:57<09:37,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6687 | Actual Loss: 0.2101\n",
      "Baseline Loss: 2.2488 | Actual Loss: 0.1688\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5015\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.8529\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.3714\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.4264\n",
      "Epoch 90/1000: Train Loss: 0.4018, Val Loss: 0.5381\n",
      "Baseline Loss: 2.6646 | Actual Loss: 1.0724\n",
      "Baseline Loss: 2.6362 | Actual Loss: 0.3447\n",
      "Baseline Loss: 2.6557 | Actual Loss: 0.2689\n",
      "Baseline Loss: 2.6332 | Actual Loss: 0.4888\n",
      "Baseline Loss: 2.6455 | Actual Loss: 0.1209\n",
      "Baseline Loss: 2.6794 | Actual Loss: 0.3437\n",
      "Baseline Loss: 2.6584 | Actual Loss: 0.2246\n",
      "Baseline Loss: 2.6308 | Actual Loss: 1.0197\n",
      "Baseline Loss: 2.6845 | Actual Loss: 0.4752\n",
      "Baseline Loss: 2.6656 | Actual Loss: 0.4670\n",
      "Baseline Loss: 2.6476 | Actual Loss: 0.6327\n",
      "Baseline Loss: 2.6871 | Actual Loss: 0.2533\n",
      "Baseline Loss: 2.7135 | Actual Loss: 0.2798\n",
      "Baseline Loss: 2.6756 | Actual Loss: 0.5071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 91/1000 [00:57<09:27,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6910 | Actual Loss: 0.4876\n",
      "Baseline Loss: 2.2821 | Actual Loss: 1.6098\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5532\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.7643\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.3053\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3864\n",
      "Epoch 91/1000: Train Loss: 0.5373, Val Loss: 0.5023\n",
      "Baseline Loss: 2.6916 | Actual Loss: 0.3129\n",
      "Baseline Loss: 2.6557 | Actual Loss: 0.4858\n",
      "Baseline Loss: 2.6573 | Actual Loss: 0.2654\n",
      "Baseline Loss: 2.6733 | Actual Loss: 0.3409\n",
      "Baseline Loss: 2.6929 | Actual Loss: 0.4904\n",
      "Baseline Loss: 2.6467 | Actual Loss: 0.1908\n",
      "Baseline Loss: 2.6828 | Actual Loss: 0.1918\n",
      "Baseline Loss: 2.6698 | Actual Loss: 0.8888\n",
      "Baseline Loss: 2.6614 | Actual Loss: 0.3863\n",
      "Baseline Loss: 2.6720 | Actual Loss: 0.2421\n",
      "Baseline Loss: 2.6684 | Actual Loss: 0.2179\n",
      "Baseline Loss: 2.6622 | Actual Loss: 0.2508\n",
      "Baseline Loss: 2.6199 | Actual Loss: 0.4220\n",
      "Baseline Loss: 2.7273 | Actual Loss: 0.4385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 92/1000 [00:58<09:28,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6888 | Actual Loss: 0.3038\n",
      "Baseline Loss: 2.2710 | Actual Loss: 0.2351\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.6736\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6182\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.3270\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2033\n",
      "Epoch 92/1000: Train Loss: 0.3540, Val Loss: 0.4555\n",
      "Baseline Loss: 2.6529 | Actual Loss: 0.3975\n",
      "Baseline Loss: 2.6468 | Actual Loss: 0.5122\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.4723\n",
      "Baseline Loss: 2.6918 | Actual Loss: 0.1924\n",
      "Baseline Loss: 2.7266 | Actual Loss: 0.2496\n",
      "Baseline Loss: 2.6993 | Actual Loss: 0.3066\n",
      "Baseline Loss: 2.6856 | Actual Loss: 0.5938\n",
      "Baseline Loss: 2.6636 | Actual Loss: 0.3925\n",
      "Baseline Loss: 2.6667 | Actual Loss: 0.5574\n",
      "Baseline Loss: 2.6346 | Actual Loss: 0.4549\n",
      "Baseline Loss: 2.6522 | Actual Loss: 0.2398\n",
      "Baseline Loss: 2.6712 | Actual Loss: 0.3111\n",
      "Baseline Loss: 2.6850 | Actual Loss: 0.3023\n",
      "Baseline Loss: 2.6954 | Actual Loss: 0.6387\n",
      "Baseline Loss: 2.6468 | Actual Loss: 0.4662\n",
      "Baseline Loss: 2.2912 | Actual Loss: 0.1536\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 93/1000 [00:59<09:17,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6640 | Actual Loss: 0.6658\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2825\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3018\n",
      "Epoch 93/1000: Train Loss: 0.3900, Val Loss: 0.4131\n",
      "Baseline Loss: 2.6636 | Actual Loss: 0.3516\n",
      "Baseline Loss: 2.6810 | Actual Loss: 0.3913\n",
      "Baseline Loss: 2.6793 | Actual Loss: 0.3811\n",
      "Baseline Loss: 2.6614 | Actual Loss: 0.2209\n",
      "Baseline Loss: 2.6982 | Actual Loss: 0.2706\n",
      "Baseline Loss: 2.6443 | Actual Loss: 0.8745\n",
      "Baseline Loss: 2.6697 | Actual Loss: 0.1603\n",
      "Baseline Loss: 2.7039 | Actual Loss: 0.5146\n",
      "Baseline Loss: 2.6935 | Actual Loss: 0.2191\n",
      "Baseline Loss: 2.6395 | Actual Loss: 0.4348\n",
      "Baseline Loss: 2.6560 | Actual Loss: 0.5090\n",
      "Baseline Loss: 2.6674 | Actual Loss: 0.3137\n",
      "Baseline Loss: 2.6665 | Actual Loss: 0.4971\n",
      "Baseline Loss: 2.6812 | Actual Loss: 0.2064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 94/1000 [00:59<09:26,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6883 | Actual Loss: 0.2493\n",
      "Baseline Loss: 2.3274 | Actual Loss: 0.2024\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4976\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5370\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.3901\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2335\n",
      "Epoch 94/1000: Train Loss: 0.3623, Val Loss: 0.4146\n",
      "Baseline Loss: 2.7200 | Actual Loss: 0.5514\n",
      "Baseline Loss: 2.6665 | Actual Loss: 0.3633\n",
      "Baseline Loss: 2.6575 | Actual Loss: 0.3109\n",
      "Baseline Loss: 2.6825 | Actual Loss: 0.1476\n",
      "Baseline Loss: 2.6376 | Actual Loss: 0.4275\n",
      "Baseline Loss: 2.6572 | Actual Loss: 0.3764\n",
      "Baseline Loss: 2.6540 | Actual Loss: 0.5112\n",
      "Baseline Loss: 2.6904 | Actual Loss: 0.5150\n",
      "Baseline Loss: 2.7386 | Actual Loss: 0.4647\n",
      "Baseline Loss: 2.6893 | Actual Loss: 0.3621\n",
      "Baseline Loss: 2.6524 | Actual Loss: 0.0818\n",
      "Baseline Loss: 2.7060 | Actual Loss: 0.3622\n",
      "Baseline Loss: 2.6398 | Actual Loss: 0.3370\n",
      "Baseline Loss: 2.6385 | Actual Loss: 0.4244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 95/1000 [01:00<09:33,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6626 | Actual Loss: 0.3072\n",
      "Baseline Loss: 2.2301 | Actual Loss: 0.1551\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.6318\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5683\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2530\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3343\n",
      "Epoch 95/1000: Train Loss: 0.3561, Val Loss: 0.4469\n",
      "Baseline Loss: 2.6734 | Actual Loss: 1.0547\n",
      "Baseline Loss: 2.7364 | Actual Loss: 0.5635\n",
      "Baseline Loss: 2.6877 | Actual Loss: 0.7428\n",
      "Baseline Loss: 2.6672 | Actual Loss: 0.2682\n",
      "Baseline Loss: 2.6650 | Actual Loss: 0.3031\n",
      "Baseline Loss: 2.6665 | Actual Loss: 0.3756\n",
      "Baseline Loss: 2.6685 | Actual Loss: 0.4316\n",
      "Baseline Loss: 2.6481 | Actual Loss: 0.3908\n",
      "Baseline Loss: 2.7071 | Actual Loss: 0.2172\n",
      "Baseline Loss: 2.6536 | Actual Loss: 0.3059\n",
      "Baseline Loss: 2.6672 | Actual Loss: 0.3278\n",
      "Baseline Loss: 2.6928 | Actual Loss: 0.3500\n",
      "Baseline Loss: 2.6482 | Actual Loss: 0.3215\n",
      "Baseline Loss: 2.6587 | Actual Loss: 0.4713\n",
      "Baseline Loss: 2.6592 | Actual Loss: 0.2140\n",
      "Baseline Loss: 2.3232 | Actual Loss: 0.2083\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5313\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.7085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 96/1000 [01:00<09:20,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6853 | Actual Loss: 0.2797\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2781\n",
      "Epoch 96/1000: Train Loss: 0.4091, Val Loss: 0.4494\n",
      "Baseline Loss: 2.6508 | Actual Loss: 0.2560\n",
      "Baseline Loss: 2.6743 | Actual Loss: 0.1843\n",
      "Baseline Loss: 2.6851 | Actual Loss: 0.3136\n",
      "Baseline Loss: 2.6742 | Actual Loss: 0.1892\n",
      "Baseline Loss: 2.6504 | Actual Loss: 0.4264\n",
      "Baseline Loss: 2.6794 | Actual Loss: 0.2949\n",
      "Baseline Loss: 2.6859 | Actual Loss: 0.5230\n",
      "Baseline Loss: 2.7038 | Actual Loss: 0.7983\n",
      "Baseline Loss: 2.7113 | Actual Loss: 0.4884\n",
      "Baseline Loss: 2.6206 | Actual Loss: 0.3218\n",
      "Baseline Loss: 2.6819 | Actual Loss: 0.2728\n",
      "Baseline Loss: 2.6930 | Actual Loss: 0.1823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 97/1000 [01:01<09:30,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6251 | Actual Loss: 0.4367\n",
      "Baseline Loss: 2.6523 | Actual Loss: 0.3953\n",
      "Baseline Loss: 2.6802 | Actual Loss: 0.3214\n",
      "Baseline Loss: 2.3129 | Actual Loss: 0.1302\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.3965\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.4794\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2344\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3134\n",
      "Epoch 97/1000: Train Loss: 0.3459, Val Loss: 0.3559\n",
      "New best validation loss: 0.3559\n",
      "Baseline Loss: 2.6568 | Actual Loss: 0.3207\n",
      "Baseline Loss: 2.6896 | Actual Loss: 0.3414\n",
      "Baseline Loss: 2.6695 | Actual Loss: 0.2751\n",
      "Baseline Loss: 2.7100 | Actual Loss: 0.5906\n",
      "Baseline Loss: 2.6562 | Actual Loss: 0.4745\n",
      "Baseline Loss: 2.6844 | Actual Loss: 0.2668\n",
      "Baseline Loss: 2.6788 | Actual Loss: 0.2792\n",
      "Baseline Loss: 2.6752 | Actual Loss: 0.2414\n",
      "Baseline Loss: 2.6994 | Actual Loss: 0.6849\n",
      "Baseline Loss: 2.6706 | Actual Loss: 0.3338\n",
      "Baseline Loss: 2.6973 | Actual Loss: 0.2125\n",
      "Baseline Loss: 2.6729 | Actual Loss: 0.4443\n",
      "Baseline Loss: 2.6772 | Actual Loss: 0.2438\n",
      "Baseline Loss: 2.6629 | Actual Loss: 0.2892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 98/1000 [01:02<09:21,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6577 | Actual Loss: 0.5127\n",
      "Baseline Loss: 2.2491 | Actual Loss: 0.0743\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.8450\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6006\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.3221\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.4317\n",
      "Epoch 98/1000: Train Loss: 0.3491, Val Loss: 0.5498\n",
      "Baseline Loss: 2.6355 | Actual Loss: 0.4884\n",
      "Baseline Loss: 2.6430 | Actual Loss: 0.3273\n",
      "Baseline Loss: 2.7239 | Actual Loss: 0.2825\n",
      "Baseline Loss: 2.6564 | Actual Loss: 0.4768\n",
      "Baseline Loss: 2.6551 | Actual Loss: 0.3244\n",
      "Baseline Loss: 2.7031 | Actual Loss: 0.4780\n",
      "Baseline Loss: 2.6699 | Actual Loss: 0.4580\n",
      "Baseline Loss: 2.6753 | Actual Loss: 0.4565\n",
      "Baseline Loss: 2.6723 | Actual Loss: 0.4413\n",
      "Baseline Loss: 2.6674 | Actual Loss: 0.3160\n",
      "Baseline Loss: 2.6927 | Actual Loss: 0.2113\n",
      "Baseline Loss: 2.6609 | Actual Loss: 0.2696\n",
      "Baseline Loss: 2.6446 | Actual Loss: 0.2141\n",
      "Baseline Loss: 2.6933 | Actual Loss: 0.2031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 99/1000 [01:02<09:27,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6636 | Actual Loss: 0.3420\n",
      "Baseline Loss: 2.2838 | Actual Loss: 0.0942\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4491\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6284\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.3035\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2706\n",
      "Epoch 99/1000: Train Loss: 0.3365, Val Loss: 0.4129\n",
      "Baseline Loss: 2.6733 | Actual Loss: 0.7186\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.6040\n",
      "Baseline Loss: 2.6868 | Actual Loss: 0.3774\n",
      "Baseline Loss: 2.6636 | Actual Loss: 0.2632\n",
      "Baseline Loss: 2.6579 | Actual Loss: 0.3626\n",
      "Baseline Loss: 2.6230 | Actual Loss: 0.4070\n",
      "Baseline Loss: 2.6656 | Actual Loss: 0.4456\n",
      "Baseline Loss: 2.6520 | Actual Loss: 0.4347\n",
      "Baseline Loss: 2.6874 | Actual Loss: 0.3526\n",
      "Baseline Loss: 2.6878 | Actual Loss: 0.4260\n",
      "Baseline Loss: 2.6622 | Actual Loss: 0.5382\n",
      "Baseline Loss: 2.6643 | Actual Loss: 0.3881\n",
      "Baseline Loss: 2.6953 | Actual Loss: 0.3606\n",
      "Baseline Loss: 2.6919 | Actual Loss: 0.2333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 100/1000 [01:03<09:31,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6899 | Actual Loss: 0.3927\n",
      "Baseline Loss: 2.3600 | Actual Loss: 0.0719\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5278\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6356\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2765\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.4803\n",
      "Epoch 100/1000: Train Loss: 0.3985, Val Loss: 0.4800\n",
      "Baseline Loss: 2.6373 | Actual Loss: 0.2699\n",
      "Baseline Loss: 2.7394 | Actual Loss: 0.3633\n",
      "Baseline Loss: 2.6800 | Actual Loss: 0.3708\n",
      "Baseline Loss: 2.6389 | Actual Loss: 0.3558\n",
      "Baseline Loss: 2.6701 | Actual Loss: 0.3240\n",
      "Baseline Loss: 2.6672 | Actual Loss: 0.2577\n",
      "Baseline Loss: 2.6654 | Actual Loss: 0.4013\n",
      "Baseline Loss: 2.6914 | Actual Loss: 0.2284\n",
      "Baseline Loss: 2.6672 | Actual Loss: 0.6284\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.2948\n",
      "Baseline Loss: 2.6547 | Actual Loss: 0.2128\n",
      "Baseline Loss: 2.6877 | Actual Loss: 0.2298\n",
      "Baseline Loss: 2.6747 | Actual Loss: 0.2601\n",
      "Baseline Loss: 2.6485 | Actual Loss: 0.3155\n",
      "Baseline Loss: 2.6745 | Actual Loss: 0.3059\n",
      "Baseline Loss: 2.2364 | Actual Loss: 0.1842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 101/1000 [01:04<09:42,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6755 | Actual Loss: 0.4240\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.7089\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2439\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2469\n",
      "Epoch 101/1000: Train Loss: 0.3127, Val Loss: 0.4059\n",
      "Baseline Loss: 2.6990 | Actual Loss: 0.4095\n",
      "Baseline Loss: 2.7184 | Actual Loss: 1.4079\n",
      "Baseline Loss: 2.6941 | Actual Loss: 0.1609\n",
      "Baseline Loss: 2.7057 | Actual Loss: 0.4729\n",
      "Baseline Loss: 2.6903 | Actual Loss: 0.2445\n",
      "Baseline Loss: 2.6682 | Actual Loss: 0.2174\n",
      "Baseline Loss: 2.6528 | Actual Loss: 0.4661\n",
      "Baseline Loss: 2.6529 | Actual Loss: 0.6582\n",
      "Baseline Loss: 2.6327 | Actual Loss: 0.2040\n",
      "Baseline Loss: 2.6487 | Actual Loss: 0.3790\n",
      "Baseline Loss: 2.6613 | Actual Loss: 0.4132\n",
      "Baseline Loss: 2.6555 | Actual Loss: 0.1640\n",
      "Baseline Loss: 2.6939 | Actual Loss: 0.3430\n",
      "Baseline Loss: 2.6707 | Actual Loss: 0.3853\n",
      "Baseline Loss: 2.6761 | Actual Loss: 0.4180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 102/1000 [01:04<09:20,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2221 | Actual Loss: 0.5008\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4665\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.7191\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2141\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.4546\n",
      "Epoch 102/1000: Train Loss: 0.4278, Val Loss: 0.4636\n",
      "Baseline Loss: 2.6995 | Actual Loss: 0.2415\n",
      "Baseline Loss: 2.7164 | Actual Loss: 0.3901\n",
      "Baseline Loss: 2.6439 | Actual Loss: 0.6832\n",
      "Baseline Loss: 2.6417 | Actual Loss: 0.5486\n",
      "Baseline Loss: 2.6382 | Actual Loss: 0.3723\n",
      "Baseline Loss: 2.6780 | Actual Loss: 0.3899\n",
      "Baseline Loss: 2.6771 | Actual Loss: 0.9844\n",
      "Baseline Loss: 2.6305 | Actual Loss: 0.3499\n",
      "Baseline Loss: 2.7019 | Actual Loss: 0.3888\n",
      "Baseline Loss: 2.7033 | Actual Loss: 0.1566\n",
      "Baseline Loss: 2.6934 | Actual Loss: 0.4354\n",
      "Baseline Loss: 2.6570 | Actual Loss: 0.3539\n",
      "Baseline Loss: 2.6509 | Actual Loss: 0.1405\n",
      "Baseline Loss: 2.6970 | Actual Loss: 0.4928\n",
      "Baseline Loss: 2.6562 | Actual Loss: 0.3363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 103/1000 [01:05<09:32,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2291 | Actual Loss: 0.2810\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5440\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6699\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2324\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.4330\n",
      "Epoch 103/1000: Train Loss: 0.4091, Val Loss: 0.4698\n",
      "Baseline Loss: 2.6928 | Actual Loss: 0.3300\n",
      "Baseline Loss: 2.6974 | Actual Loss: 0.2408\n",
      "Baseline Loss: 2.6725 | Actual Loss: 0.4359\n",
      "Baseline Loss: 2.6831 | Actual Loss: 0.6145\n",
      "Baseline Loss: 2.6724 | Actual Loss: 0.3021\n",
      "Baseline Loss: 2.6761 | Actual Loss: 0.2797\n",
      "Baseline Loss: 2.6813 | Actual Loss: 0.2411\n",
      "Baseline Loss: 2.6426 | Actual Loss: 0.3910\n",
      "Baseline Loss: 2.6499 | Actual Loss: 0.3913\n",
      "Baseline Loss: 2.6708 | Actual Loss: 0.2918\n",
      "Baseline Loss: 2.6890 | Actual Loss: 0.1925\n",
      "Baseline Loss: 2.6874 | Actual Loss: 0.4147\n",
      "Baseline Loss: 2.6941 | Actual Loss: 0.4837\n",
      "Baseline Loss: 2.6977 | Actual Loss: 0.3416\n",
      "Baseline Loss: 2.6702 | Actual Loss: 0.3542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 104/1000 [01:06<09:35,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2993 | Actual Loss: 0.3598\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5623\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5964\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2345\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.4997\n",
      "Epoch 104/1000: Train Loss: 0.3540, Val Loss: 0.4732\n",
      "Baseline Loss: 2.6839 | Actual Loss: 0.3074\n",
      "Baseline Loss: 2.6666 | Actual Loss: 0.1600\n",
      "Baseline Loss: 2.6645 | Actual Loss: 0.2715\n",
      "Baseline Loss: 2.7044 | Actual Loss: 0.2831\n",
      "Baseline Loss: 2.6357 | Actual Loss: 0.5925\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.1711\n",
      "Baseline Loss: 2.6682 | Actual Loss: 1.4597\n",
      "Baseline Loss: 2.7019 | Actual Loss: 0.0997\n",
      "Baseline Loss: 2.6916 | Actual Loss: 0.3232\n",
      "Baseline Loss: 2.6541 | Actual Loss: 0.4009\n",
      "Baseline Loss: 2.6689 | Actual Loss: 0.5149\n",
      "Baseline Loss: 2.7005 | Actual Loss: 0.2787\n",
      "Baseline Loss: 2.6360 | Actual Loss: 0.2683\n",
      "Baseline Loss: 2.6623 | Actual Loss: 0.2471\n",
      "Baseline Loss: 2.6953 | Actual Loss: 0.3695\n",
      "Baseline Loss: 2.3218 | Actual Loss: 0.2492\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 105/1000 [01:06<09:22,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6640 | Actual Loss: 0.7206\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.1915\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.4234\n",
      "Epoch 105/1000: Train Loss: 0.3748, Val Loss: 0.4485\n",
      "Baseline Loss: 2.7134 | Actual Loss: 0.3841\n",
      "Baseline Loss: 2.7156 | Actual Loss: 0.3410\n",
      "Baseline Loss: 2.6654 | Actual Loss: 0.1766\n",
      "Baseline Loss: 2.6702 | Actual Loss: 0.4643\n",
      "Baseline Loss: 2.6929 | Actual Loss: 0.1816\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.6042\n",
      "Baseline Loss: 2.6963 | Actual Loss: 0.3216\n",
      "Baseline Loss: 2.6448 | Actual Loss: 0.4280\n",
      "Baseline Loss: 2.6558 | Actual Loss: 0.2195\n",
      "Baseline Loss: 2.6553 | Actual Loss: 0.3454\n",
      "Baseline Loss: 2.7310 | Actual Loss: 0.3284\n",
      "Baseline Loss: 2.6996 | Actual Loss: 0.3907\n",
      "Baseline Loss: 2.6557 | Actual Loss: 0.3330\n",
      "Baseline Loss: 2.6475 | Actual Loss: 0.1057\n",
      "Baseline Loss: 2.6772 | Actual Loss: 0.6118\n",
      "Baseline Loss: 2.2492 | Actual Loss: 0.0945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 106/1000 [01:07<09:26,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6755 | Actual Loss: 0.4199\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6992\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2418\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.4877\n",
      "Epoch 106/1000: Train Loss: 0.3332, Val Loss: 0.4622\n",
      "Baseline Loss: 2.6744 | Actual Loss: 0.4295\n",
      "Baseline Loss: 2.6391 | Actual Loss: 0.4964\n",
      "Baseline Loss: 2.7103 | Actual Loss: 0.4027\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.3253\n",
      "Baseline Loss: 2.6699 | Actual Loss: 0.2149\n",
      "Baseline Loss: 2.6616 | Actual Loss: 0.2336\n",
      "Baseline Loss: 2.6568 | Actual Loss: 0.2714\n",
      "Baseline Loss: 2.6715 | Actual Loss: 0.2982\n",
      "Baseline Loss: 2.6617 | Actual Loss: 0.2717\n",
      "Baseline Loss: 2.6690 | Actual Loss: 0.6721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 107/1000 [01:07<09:25,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6961 | Actual Loss: 0.2103\n",
      "Baseline Loss: 2.7090 | Actual Loss: 0.2877\n",
      "Baseline Loss: 2.6985 | Actual Loss: 0.7446\n",
      "Baseline Loss: 2.6729 | Actual Loss: 0.8724\n",
      "Baseline Loss: 2.6847 | Actual Loss: 0.4468\n",
      "Baseline Loss: 2.2351 | Actual Loss: 0.1612\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.3855\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5567\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2168\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3438\n",
      "Epoch 107/1000: Train Loss: 0.3962, Val Loss: 0.3757\n",
      "Baseline Loss: 2.6558 | Actual Loss: 0.4650\n",
      "Baseline Loss: 2.6766 | Actual Loss: 0.2117\n",
      "Baseline Loss: 2.6584 | Actual Loss: 0.3807\n",
      "Baseline Loss: 2.6829 | Actual Loss: 0.4017\n",
      "Baseline Loss: 2.6555 | Actual Loss: 0.3050\n",
      "Baseline Loss: 2.6804 | Actual Loss: 0.3271\n",
      "Baseline Loss: 2.6925 | Actual Loss: 0.7040\n",
      "Baseline Loss: 2.7177 | Actual Loss: 0.1461\n",
      "Baseline Loss: 2.6734 | Actual Loss: 0.2279\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3160\n",
      "Baseline Loss: 2.6736 | Actual Loss: 0.4658\n",
      "Baseline Loss: 2.6743 | Actual Loss: 0.4099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 108/1000 [01:08<09:18,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6941 | Actual Loss: 0.2134\n",
      "Baseline Loss: 2.6955 | Actual Loss: 0.3723\n",
      "Baseline Loss: 2.6586 | Actual Loss: 0.3430\n",
      "Baseline Loss: 2.2614 | Actual Loss: 0.1175\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4724\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6152\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2185\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2578\n",
      "Epoch 108/1000: Train Loss: 0.3379, Val Loss: 0.3910\n",
      "Baseline Loss: 2.6723 | Actual Loss: 0.4253\n",
      "Baseline Loss: 2.6656 | Actual Loss: 0.3463\n",
      "Baseline Loss: 2.6940 | Actual Loss: 0.4160\n",
      "Baseline Loss: 2.6520 | Actual Loss: 0.2189\n",
      "Baseline Loss: 2.7065 | Actual Loss: 0.2448\n",
      "Baseline Loss: 2.6626 | Actual Loss: 0.3605\n",
      "Baseline Loss: 2.6552 | Actual Loss: 0.3449\n",
      "Baseline Loss: 2.6709 | Actual Loss: 0.6343\n",
      "Baseline Loss: 2.6848 | Actual Loss: 0.5587\n",
      "Baseline Loss: 2.6998 | Actual Loss: 0.3201\n",
      "Baseline Loss: 2.6974 | Actual Loss: 0.4325\n",
      "Baseline Loss: 2.6536 | Actual Loss: 0.4055\n",
      "Baseline Loss: 2.6581 | Actual Loss: 0.8174\n",
      "Baseline Loss: 2.6420 | Actual Loss: 0.2451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 109/1000 [01:09<09:19,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6560 | Actual Loss: 0.3980\n",
      "Baseline Loss: 2.3311 | Actual Loss: 0.2411\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5935\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6956\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2206\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3960\n",
      "Epoch 109/1000: Train Loss: 0.4006, Val Loss: 0.4764\n",
      "Baseline Loss: 2.6828 | Actual Loss: 0.1324\n",
      "Baseline Loss: 2.6408 | Actual Loss: 0.6162\n",
      "Baseline Loss: 2.6393 | Actual Loss: 0.2715\n",
      "Baseline Loss: 2.6771 | Actual Loss: 0.1924\n",
      "Baseline Loss: 2.6815 | Actual Loss: 0.1891\n",
      "Baseline Loss: 2.6677 | Actual Loss: 0.2089\n",
      "Baseline Loss: 2.6988 | Actual Loss: 0.3077\n",
      "Baseline Loss: 2.7134 | Actual Loss: 0.4067\n",
      "Baseline Loss: 2.6693 | Actual Loss: 0.7178\n",
      "Baseline Loss: 2.6871 | Actual Loss: 0.3908\n",
      "Baseline Loss: 2.6797 | Actual Loss: 0.2802\n",
      "Baseline Loss: 2.7098 | Actual Loss: 0.2413\n",
      "Baseline Loss: 2.6535 | Actual Loss: 0.6064\n",
      "Baseline Loss: 2.6612 | Actual Loss: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 110/1000 [01:09<09:35,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6724 | Actual Loss: 0.4125\n",
      "Baseline Loss: 2.2323 | Actual Loss: 0.8250\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5624\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5876\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2174\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.4249\n",
      "Epoch 110/1000: Train Loss: 0.3914, Val Loss: 0.4481\n",
      "Baseline Loss: 2.6548 | Actual Loss: 0.2609\n",
      "Baseline Loss: 2.6945 | Actual Loss: 0.1486\n",
      "Baseline Loss: 2.6523 | Actual Loss: 0.3961\n",
      "Baseline Loss: 2.7003 | Actual Loss: 0.6874\n",
      "Baseline Loss: 2.6746 | Actual Loss: 0.4475\n",
      "Baseline Loss: 2.6762 | Actual Loss: 0.2209\n",
      "Baseline Loss: 2.6821 | Actual Loss: 0.4820\n",
      "Baseline Loss: 2.6438 | Actual Loss: 0.5570\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.5956\n",
      "Baseline Loss: 2.6442 | Actual Loss: 0.4539\n",
      "Baseline Loss: 2.6499 | Actual Loss: 0.2030\n",
      "Baseline Loss: 2.7269 | Actual Loss: 0.2797\n",
      "Baseline Loss: 2.6602 | Actual Loss: 0.3422\n",
      "Baseline Loss: 2.6846 | Actual Loss: 0.1020\n",
      "Baseline Loss: 2.6605 | Actual Loss: 0.4851\n",
      "Baseline Loss: 2.2800 | Actual Loss: 0.4342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 111/1000 [01:10<09:09,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6755 | Actual Loss: 0.4637\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6395\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2977\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2991\n",
      "Epoch 111/1000: Train Loss: 0.3810, Val Loss: 0.4250\n",
      "Baseline Loss: 2.6883 | Actual Loss: 0.4710\n",
      "Baseline Loss: 2.6993 | Actual Loss: 0.2111\n",
      "Baseline Loss: 2.6810 | Actual Loss: 0.3877\n",
      "Baseline Loss: 2.6812 | Actual Loss: 0.4014\n",
      "Baseline Loss: 2.6942 | Actual Loss: 0.3350\n",
      "Baseline Loss: 2.6648 | Actual Loss: 0.3500\n",
      "Baseline Loss: 2.6752 | Actual Loss: 0.5288\n",
      "Baseline Loss: 2.6769 | Actual Loss: 0.4614\n",
      "Baseline Loss: 2.6668 | Actual Loss: 0.1023\n",
      "Baseline Loss: 2.7286 | Actual Loss: 0.3585\n",
      "Baseline Loss: 2.6720 | Actual Loss: 0.2940\n",
      "Baseline Loss: 2.6524 | Actual Loss: 0.1672\n",
      "Baseline Loss: 2.6632 | Actual Loss: 1.5145\n",
      "Baseline Loss: 2.6437 | Actual Loss: 0.3485\n",
      "Baseline Loss: 2.6751 | Actual Loss: 0.2677\n",
      "Baseline Loss: 2.2254 | Actual Loss: 0.2935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 112/1000 [01:11<09:21,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6755 | Actual Loss: 0.4400\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5717\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.1981\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3432\n",
      "Epoch 112/1000: Train Loss: 0.4058, Val Loss: 0.3882\n",
      "Baseline Loss: 2.6468 | Actual Loss: 0.4320\n",
      "Baseline Loss: 2.6512 | Actual Loss: 0.5050\n",
      "Baseline Loss: 2.6570 | Actual Loss: 0.1217\n",
      "Baseline Loss: 2.7257 | Actual Loss: 0.2718\n",
      "Baseline Loss: 2.6915 | Actual Loss: 0.4341\n",
      "Baseline Loss: 2.6407 | Actual Loss: 0.3658\n",
      "Baseline Loss: 2.6720 | Actual Loss: 0.2659\n",
      "Baseline Loss: 2.6683 | Actual Loss: 0.8896\n",
      "Baseline Loss: 2.6540 | Actual Loss: 0.2884\n",
      "Baseline Loss: 2.6824 | Actual Loss: 0.3071\n",
      "Baseline Loss: 2.6790 | Actual Loss: 0.2823\n",
      "Baseline Loss: 2.6343 | Actual Loss: 0.7995\n",
      "Baseline Loss: 2.6664 | Actual Loss: 0.3157\n",
      "Baseline Loss: 2.6517 | Actual Loss: 0.1147\n",
      "Baseline Loss: 2.7481 | Actual Loss: 0.2485\n",
      "Baseline Loss: 2.2264 | Actual Loss: 0.1661\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.6184\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6026\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█▏        | 113/1000 [01:11<09:02,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6128 | Actual Loss: 0.2501\n",
      "Epoch 113/1000: Train Loss: 0.3630, Val Loss: 0.4186\n",
      "Baseline Loss: 2.6837 | Actual Loss: 0.5206\n",
      "Baseline Loss: 2.7059 | Actual Loss: 0.2114\n",
      "Baseline Loss: 2.6528 | Actual Loss: 0.3941\n",
      "Baseline Loss: 2.6917 | Actual Loss: 0.8897\n",
      "Baseline Loss: 2.6647 | Actual Loss: 0.1677\n",
      "Baseline Loss: 2.6487 | Actual Loss: 0.2776\n",
      "Baseline Loss: 2.6737 | Actual Loss: 0.3362\n",
      "Baseline Loss: 2.6747 | Actual Loss: 0.2231\n",
      "Baseline Loss: 2.6549 | Actual Loss: 0.3834\n",
      "Baseline Loss: 2.6726 | Actual Loss: 0.3067\n",
      "Baseline Loss: 2.6726 | Actual Loss: 0.4077\n",
      "Baseline Loss: 2.6765 | Actual Loss: 0.3328\n",
      "Baseline Loss: 2.6670 | Actual Loss: 0.4907\n",
      "Baseline Loss: 2.6804 | Actual Loss: 0.1956\n",
      "Baseline Loss: 2.6487 | Actual Loss: 0.2654\n",
      "Baseline Loss: 2.2499 | Actual Loss: 0.1395\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4612\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.7455\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.1966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█▏        | 114/1000 [01:12<09:06,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6128 | Actual Loss: 0.2859\n",
      "Epoch 114/1000: Train Loss: 0.3464, Val Loss: 0.4223\n",
      "Baseline Loss: 2.6392 | Actual Loss: 0.1931\n",
      "Baseline Loss: 2.6707 | Actual Loss: 0.4202\n",
      "Baseline Loss: 2.6420 | Actual Loss: 0.1782\n",
      "Baseline Loss: 2.6796 | Actual Loss: 0.4302\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.1683\n",
      "Baseline Loss: 2.7065 | Actual Loss: 0.2829\n",
      "Baseline Loss: 2.6550 | Actual Loss: 0.4254\n",
      "Baseline Loss: 2.6774 | Actual Loss: 0.4089\n",
      "Baseline Loss: 2.6682 | Actual Loss: 0.2824\n",
      "Baseline Loss: 2.6877 | Actual Loss: 0.3921\n",
      "Baseline Loss: 2.7051 | Actual Loss: 0.2085\n",
      "Baseline Loss: 2.7021 | Actual Loss: 0.2909\n",
      "Baseline Loss: 2.6686 | Actual Loss: 0.4363\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.1759\n",
      "Baseline Loss: 2.6812 | Actual Loss: 0.1830\n",
      "Baseline Loss: 2.2231 | Actual Loss: 0.1594\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.6183\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 115/1000 [01:12<09:19,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6853 | Actual Loss: 0.3857\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2717\n",
      "Epoch 115/1000: Train Loss: 0.2897, Val Loss: 0.4883\n",
      "Baseline Loss: 2.6670 | Actual Loss: 0.4107\n",
      "Baseline Loss: 2.7176 | Actual Loss: 0.1906\n",
      "Baseline Loss: 2.7062 | Actual Loss: 0.2738\n",
      "Baseline Loss: 2.6393 | Actual Loss: 0.5289\n",
      "Baseline Loss: 2.6928 | Actual Loss: 0.3218\n",
      "Baseline Loss: 2.6735 | Actual Loss: 0.2717\n",
      "Baseline Loss: 2.6728 | Actual Loss: 0.2643\n",
      "Baseline Loss: 2.6207 | Actual Loss: 0.8086\n",
      "Baseline Loss: 2.6694 | Actual Loss: 0.5570\n",
      "Baseline Loss: 2.6549 | Actual Loss: 0.3175\n",
      "Baseline Loss: 2.6923 | Actual Loss: 0.1827\n",
      "Baseline Loss: 2.6620 | Actual Loss: 0.1613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 116/1000 [01:13<09:01,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6445 | Actual Loss: 0.4162\n",
      "Baseline Loss: 2.6769 | Actual Loss: 0.4396\n",
      "Baseline Loss: 2.6523 | Actual Loss: 0.3547\n",
      "Baseline Loss: 2.3336 | Actual Loss: 0.1210\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5701\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.7006\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.3237\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2370\n",
      "Epoch 116/1000: Train Loss: 0.3513, Val Loss: 0.4579\n",
      "Baseline Loss: 2.6353 | Actual Loss: 0.2312\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.2668\n",
      "Baseline Loss: 2.6705 | Actual Loss: 0.4132\n",
      "Baseline Loss: 2.6635 | Actual Loss: 0.3485\n",
      "Baseline Loss: 2.6615 | Actual Loss: 0.2499\n",
      "Baseline Loss: 2.6865 | Actual Loss: 0.1763\n",
      "Baseline Loss: 2.6584 | Actual Loss: 0.6216\n",
      "Baseline Loss: 2.6823 | Actual Loss: 0.2298\n",
      "Baseline Loss: 2.6668 | Actual Loss: 0.5154\n",
      "Baseline Loss: 2.6842 | Actual Loss: 0.2713\n",
      "Baseline Loss: 2.6593 | Actual Loss: 0.2227\n",
      "Baseline Loss: 2.7188 | Actual Loss: 0.3766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 117/1000 [01:14<09:16,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6772 | Actual Loss: 0.2374\n",
      "Baseline Loss: 2.6567 | Actual Loss: 0.3844\n",
      "Baseline Loss: 2.6884 | Actual Loss: 0.3541\n",
      "Baseline Loss: 2.2773 | Actual Loss: 0.3406\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4791\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5852\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2097\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2972\n",
      "Epoch 117/1000: Train Loss: 0.3275, Val Loss: 0.3928\n",
      "Baseline Loss: 2.6854 | Actual Loss: 0.2796\n",
      "Baseline Loss: 2.6778 | Actual Loss: 0.4260\n",
      "Baseline Loss: 2.6645 | Actual Loss: 0.2345\n",
      "Baseline Loss: 2.6584 | Actual Loss: 0.4261\n",
      "Baseline Loss: 2.6707 | Actual Loss: 0.4692\n",
      "Baseline Loss: 2.6599 | Actual Loss: 0.4040\n",
      "Baseline Loss: 2.6577 | Actual Loss: 0.2936\n",
      "Baseline Loss: 2.6989 | Actual Loss: 0.2916\n",
      "Baseline Loss: 2.6587 | Actual Loss: 0.3066\n",
      "Baseline Loss: 2.7039 | Actual Loss: 0.1187\n",
      "Baseline Loss: 2.7094 | Actual Loss: 0.1306\n",
      "Baseline Loss: 2.6646 | Actual Loss: 1.2689\n",
      "Baseline Loss: 2.6727 | Actual Loss: 0.1643\n",
      "Baseline Loss: 2.6427 | Actual Loss: 0.3222\n",
      "Baseline Loss: 2.6637 | Actual Loss: 0.1437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 118/1000 [01:14<08:59,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2066 | Actual Loss: 0.4421\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5199\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6885\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2249\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2898\n",
      "Epoch 118/1000: Train Loss: 0.3576, Val Loss: 0.4308\n",
      "Baseline Loss: 2.6467 | Actual Loss: 0.5341\n",
      "Baseline Loss: 2.6901 | Actual Loss: 0.4340\n",
      "Baseline Loss: 2.7043 | Actual Loss: 0.2586\n",
      "Baseline Loss: 2.6597 | Actual Loss: 0.2880\n",
      "Baseline Loss: 2.6838 | Actual Loss: 0.5360\n",
      "Baseline Loss: 2.6723 | Actual Loss: 0.5380\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4808\n",
      "Baseline Loss: 2.6503 | Actual Loss: 0.3312\n",
      "Baseline Loss: 2.6523 | Actual Loss: 0.3254\n",
      "Baseline Loss: 2.6793 | Actual Loss: 0.3297\n",
      "Baseline Loss: 2.6639 | Actual Loss: 0.3711\n",
      "Baseline Loss: 2.6515 | Actual Loss: 0.1748\n",
      "Baseline Loss: 2.6948 | Actual Loss: 0.2301\n",
      "Baseline Loss: 2.6951 | Actual Loss: 0.5691\n",
      "Baseline Loss: 2.6521 | Actual Loss: 0.1326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 119/1000 [01:15<09:08,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.3168 | Actual Loss: 0.4955\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4323\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5742\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2463\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2993\n",
      "Epoch 119/1000: Train Loss: 0.3768, Val Loss: 0.3880\n",
      "Baseline Loss: 2.6836 | Actual Loss: 0.1809\n",
      "Baseline Loss: 2.6702 | Actual Loss: 0.3990\n",
      "Baseline Loss: 2.6802 | Actual Loss: 0.3731\n",
      "Baseline Loss: 2.6445 | Actual Loss: 0.2893\n",
      "Baseline Loss: 2.6343 | Actual Loss: 0.2369\n",
      "Baseline Loss: 2.6260 | Actual Loss: 0.3701\n",
      "Baseline Loss: 2.6983 | Actual Loss: 0.7447\n",
      "Baseline Loss: 2.6735 | Actual Loss: 0.2408\n",
      "Baseline Loss: 2.6712 | Actual Loss: 0.7448\n",
      "Baseline Loss: 2.7100 | Actual Loss: 0.1765\n",
      "Baseline Loss: 2.6740 | Actual Loss: 0.3819\n",
      "Baseline Loss: 2.6461 | Actual Loss: 0.4694\n",
      "Baseline Loss: 2.6832 | Actual Loss: 0.3217\n",
      "Baseline Loss: 2.6488 | Actual Loss: 0.2881\n",
      "Baseline Loss: 2.6983 | Actual Loss: 0.2379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 120/1000 [01:16<09:20,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2751 | Actual Loss: 0.1330\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4361\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.7289\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2448\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.4695\n",
      "Epoch 120/1000: Train Loss: 0.3493, Val Loss: 0.4698\n",
      "Baseline Loss: 2.6805 | Actual Loss: 0.2188\n",
      "Baseline Loss: 2.6739 | Actual Loss: 0.2594\n",
      "Baseline Loss: 2.6888 | Actual Loss: 0.2460\n",
      "Baseline Loss: 2.6672 | Actual Loss: 0.1298\n",
      "Baseline Loss: 2.6452 | Actual Loss: 0.3699\n",
      "Baseline Loss: 2.6886 | Actual Loss: 0.4056\n",
      "Baseline Loss: 2.6824 | Actual Loss: 0.2442\n",
      "Baseline Loss: 2.6550 | Actual Loss: 0.5761\n",
      "Baseline Loss: 2.6870 | Actual Loss: 0.3566\n",
      "Baseline Loss: 2.6965 | Actual Loss: 0.2444\n",
      "Baseline Loss: 2.6707 | Actual Loss: 0.7122\n",
      "Baseline Loss: 2.6532 | Actual Loss: 0.3321\n",
      "Baseline Loss: 2.6875 | Actual Loss: 0.2039\n",
      "Baseline Loss: 2.6886 | Actual Loss: 0.5564\n",
      "Baseline Loss: 2.6342 | Actual Loss: 0.1955\n",
      "Baseline Loss: 2.2803 | Actual Loss: 1.1362\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.3975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 121/1000 [01:16<09:26,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6640 | Actual Loss: 0.6980\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2455\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2605\n",
      "Epoch 121/1000: Train Loss: 0.3867, Val Loss: 0.4004\n",
      "Baseline Loss: 2.6882 | Actual Loss: 0.1975\n",
      "Baseline Loss: 2.6800 | Actual Loss: 0.1659\n",
      "Baseline Loss: 2.6437 | Actual Loss: 0.5574\n",
      "Baseline Loss: 2.6934 | Actual Loss: 0.1498\n",
      "Baseline Loss: 2.6956 | Actual Loss: 0.3114\n",
      "Baseline Loss: 2.6664 | Actual Loss: 0.3298\n",
      "Baseline Loss: 2.6610 | Actual Loss: 0.2926\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.2043\n",
      "Baseline Loss: 2.6585 | Actual Loss: 0.2991\n",
      "Baseline Loss: 2.6929 | Actual Loss: 0.6570\n",
      "Baseline Loss: 2.6527 | Actual Loss: 0.5087\n",
      "Baseline Loss: 2.6612 | Actual Loss: 0.3394\n",
      "Baseline Loss: 2.6893 | Actual Loss: 0.4282\n",
      "Baseline Loss: 2.6954 | Actual Loss: 0.3251\n",
      "Baseline Loss: 2.6534 | Actual Loss: 0.4565\n",
      "Baseline Loss: 2.3092 | Actual Loss: 0.2085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 122/1000 [01:17<09:01,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6755 | Actual Loss: 0.6347\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.7025\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2236\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3476\n",
      "Epoch 122/1000: Train Loss: 0.3395, Val Loss: 0.4771\n",
      "Baseline Loss: 2.6925 | Actual Loss: 0.1975\n",
      "Baseline Loss: 2.6578 | Actual Loss: 0.2913\n",
      "Baseline Loss: 2.6527 | Actual Loss: 0.4843\n",
      "Baseline Loss: 2.6528 | Actual Loss: 0.3420\n",
      "Baseline Loss: 2.6747 | Actual Loss: 0.3989\n",
      "Baseline Loss: 2.6575 | Actual Loss: 0.6228\n",
      "Baseline Loss: 2.6953 | Actual Loss: 0.3657\n",
      "Baseline Loss: 2.7194 | Actual Loss: 0.4794\n",
      "Baseline Loss: 2.7231 | Actual Loss: 0.4446\n",
      "Baseline Loss: 2.6583 | Actual Loss: 0.1866\n",
      "Baseline Loss: 2.6529 | Actual Loss: 0.3874\n",
      "Baseline Loss: 2.6787 | Actual Loss: 1.4390\n",
      "Baseline Loss: 2.6968 | Actual Loss: 0.0994\n",
      "Baseline Loss: 2.6451 | Actual Loss: 0.6164\n",
      "Baseline Loss: 2.6708 | Actual Loss: 0.3229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 123/1000 [01:17<09:10,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.3275 | Actual Loss: 0.1858\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5576\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5013\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2078\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.4175\n",
      "Epoch 123/1000: Train Loss: 0.4290, Val Loss: 0.4210\n",
      "Baseline Loss: 2.7169 | Actual Loss: 0.1598\n",
      "Baseline Loss: 2.6488 | Actual Loss: 1.4467\n",
      "Baseline Loss: 2.6580 | Actual Loss: 0.2006\n",
      "Baseline Loss: 2.7040 | Actual Loss: 0.2648\n",
      "Baseline Loss: 2.6580 | Actual Loss: 0.7224\n",
      "Baseline Loss: 2.6405 | Actual Loss: 0.6226\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.3972\n",
      "Baseline Loss: 2.6393 | Actual Loss: 0.9216\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2300\n",
      "Baseline Loss: 2.6788 | Actual Loss: 0.2607\n",
      "Baseline Loss: 2.6704 | Actual Loss: 0.4132\n",
      "Baseline Loss: 2.6890 | Actual Loss: 0.4493\n",
      "Baseline Loss: 2.6759 | Actual Loss: 0.7502\n",
      "Baseline Loss: 2.7428 | Actual Loss: 0.4363\n",
      "Baseline Loss: 2.6714 | Actual Loss: 0.2156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 124/1000 [01:18<09:19,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2416 | Actual Loss: 0.2046\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5983\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5962\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2173\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.4449\n",
      "Epoch 124/1000: Train Loss: 0.4810, Val Loss: 0.4642\n",
      "Baseline Loss: 2.6641 | Actual Loss: 0.2540\n",
      "Baseline Loss: 2.6702 | Actual Loss: 0.5142\n",
      "Baseline Loss: 2.6701 | Actual Loss: 0.7458\n",
      "Baseline Loss: 2.6940 | Actual Loss: 0.1742\n",
      "Baseline Loss: 2.6691 | Actual Loss: 1.3136\n",
      "Baseline Loss: 2.6591 | Actual Loss: 0.2378\n",
      "Baseline Loss: 2.6705 | Actual Loss: 0.8761\n",
      "Baseline Loss: 2.6983 | Actual Loss: 0.6591\n",
      "Baseline Loss: 2.6713 | Actual Loss: 0.1710\n",
      "Baseline Loss: 2.6450 | Actual Loss: 0.3627\n",
      "Baseline Loss: 2.6302 | Actual Loss: 0.4399\n",
      "Baseline Loss: 2.6624 | Actual Loss: 0.2852\n",
      "Baseline Loss: 2.6752 | Actual Loss: 0.1629\n",
      "Baseline Loss: 2.7310 | Actual Loss: 0.4048\n",
      "Baseline Loss: 2.7097 | Actual Loss: 0.3155\n",
      "Baseline Loss: 2.2957 | Actual Loss: 0.2148\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4741\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5993\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▎        | 125/1000 [01:19<08:59,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6128 | Actual Loss: 0.5291\n",
      "Epoch 125/1000: Train Loss: 0.4457, Val Loss: 0.4571\n",
      "Baseline Loss: 2.7195 | Actual Loss: 0.3550\n",
      "Baseline Loss: 2.6698 | Actual Loss: 0.3194\n",
      "Baseline Loss: 2.6735 | Actual Loss: 0.3298\n",
      "Baseline Loss: 2.6469 | Actual Loss: 0.3697\n",
      "Baseline Loss: 2.6765 | Actual Loss: 0.1935\n",
      "Baseline Loss: 2.7016 | Actual Loss: 0.1399\n",
      "Baseline Loss: 2.6777 | Actual Loss: 0.3948\n",
      "Baseline Loss: 2.6379 | Actual Loss: 1.4746\n",
      "Baseline Loss: 2.6679 | Actual Loss: 0.3076\n",
      "Baseline Loss: 2.6843 | Actual Loss: 0.4377\n",
      "Baseline Loss: 2.6525 | Actual Loss: 0.1967\n",
      "Baseline Loss: 2.6782 | Actual Loss: 0.2525\n",
      "Baseline Loss: 2.6833 | Actual Loss: 1.1618\n",
      "Baseline Loss: 2.6752 | Actual Loss: 0.4842\n",
      "Baseline Loss: 2.6824 | Actual Loss: 0.2719\n",
      "Baseline Loss: 2.2193 | Actual Loss: 0.0894\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 126/1000 [01:19<09:04,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6640 | Actual Loss: 0.5448\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2284\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2528\n",
      "Epoch 126/1000: Train Loss: 0.4237, Val Loss: 0.3733\n",
      "Baseline Loss: 2.6625 | Actual Loss: 0.1841\n",
      "Baseline Loss: 2.6717 | Actual Loss: 0.9404\n",
      "Baseline Loss: 2.6761 | Actual Loss: 0.1984\n",
      "Baseline Loss: 2.6713 | Actual Loss: 0.5994\n",
      "Baseline Loss: 2.6488 | Actual Loss: 0.4160\n",
      "Baseline Loss: 2.6610 | Actual Loss: 0.3993\n",
      "Baseline Loss: 2.6591 | Actual Loss: 0.4044\n",
      "Baseline Loss: 2.6769 | Actual Loss: 0.3800\n",
      "Baseline Loss: 2.6593 | Actual Loss: 0.4877\n",
      "Baseline Loss: 2.6648 | Actual Loss: 0.6336\n",
      "Baseline Loss: 2.6847 | Actual Loss: 0.4257\n",
      "Baseline Loss: 2.7131 | Actual Loss: 0.2381\n",
      "Baseline Loss: 2.6692 | Actual Loss: 0.2559\n",
      "Baseline Loss: 2.6529 | Actual Loss: 0.2617\n",
      "Baseline Loss: 2.6586 | Actual Loss: 0.2062\n",
      "Baseline Loss: 2.2918 | Actual Loss: 0.2552\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4595\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 127/1000 [01:20<09:12,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6853 | Actual Loss: 0.2053\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3100\n",
      "Epoch 127/1000: Train Loss: 0.3929, Val Loss: 0.4115\n",
      "Baseline Loss: 2.6648 | Actual Loss: 0.2468\n",
      "Baseline Loss: 2.7157 | Actual Loss: 0.2974\n",
      "Baseline Loss: 2.6811 | Actual Loss: 0.2872\n",
      "Baseline Loss: 2.6707 | Actual Loss: 0.4966\n",
      "Baseline Loss: 2.6766 | Actual Loss: 0.6237\n",
      "Baseline Loss: 2.6664 | Actual Loss: 0.6113\n",
      "Baseline Loss: 2.6991 | Actual Loss: 0.3606\n",
      "Baseline Loss: 2.6446 | Actual Loss: 0.2386\n",
      "Baseline Loss: 2.6385 | Actual Loss: 0.5507\n",
      "Baseline Loss: 2.6462 | Actual Loss: 1.3752\n",
      "Baseline Loss: 2.6369 | Actual Loss: 0.2393\n",
      "Baseline Loss: 2.6723 | Actual Loss: 0.1958\n",
      "Baseline Loss: 2.7086 | Actual Loss: 0.4152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 128/1000 [01:21<08:57,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6743 | Actual Loss: 0.4664\n",
      "Baseline Loss: 2.6764 | Actual Loss: 0.3986\n",
      "Baseline Loss: 2.3119 | Actual Loss: 0.1968\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.3658\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5973\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2026\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3814\n",
      "Epoch 128/1000: Train Loss: 0.4375, Val Loss: 0.3868\n",
      "Baseline Loss: 2.7043 | Actual Loss: 0.2781\n",
      "Baseline Loss: 2.6792 | Actual Loss: 0.3296\n",
      "Baseline Loss: 2.6807 | Actual Loss: 0.4402\n",
      "Baseline Loss: 2.7119 | Actual Loss: 0.2232\n",
      "Baseline Loss: 2.6517 | Actual Loss: 0.3535\n",
      "Baseline Loss: 2.6874 | Actual Loss: 1.2278\n",
      "Baseline Loss: 2.6880 | Actual Loss: 0.1631\n",
      "Baseline Loss: 2.6711 | Actual Loss: 0.3397\n",
      "Baseline Loss: 2.6461 | Actual Loss: 0.4006\n",
      "Baseline Loss: 2.6444 | Actual Loss: 0.3051\n",
      "Baseline Loss: 2.6796 | Actual Loss: 0.1904\n",
      "Baseline Loss: 2.6848 | Actual Loss: 0.2281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 129/1000 [01:21<09:04,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6897 | Actual Loss: 0.5700\n",
      "Baseline Loss: 2.6750 | Actual Loss: 0.4432\n",
      "Baseline Loss: 2.6270 | Actual Loss: 0.1733\n",
      "Baseline Loss: 2.2637 | Actual Loss: 0.0740\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5268\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6659\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2186\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.4791\n",
      "Epoch 129/1000: Train Loss: 0.3587, Val Loss: 0.4726\n",
      "Baseline Loss: 2.6998 | Actual Loss: 0.3272\n",
      "Baseline Loss: 2.6583 | Actual Loss: 0.3858\n",
      "Baseline Loss: 2.6169 | Actual Loss: 0.3279\n",
      "Baseline Loss: 2.6934 | Actual Loss: 0.3004\n",
      "Baseline Loss: 2.7248 | Actual Loss: 0.2827\n",
      "Baseline Loss: 2.6775 | Actual Loss: 0.3357\n",
      "Baseline Loss: 2.6590 | Actual Loss: 0.3149\n",
      "Baseline Loss: 2.6659 | Actual Loss: 0.2485\n",
      "Baseline Loss: 2.6879 | Actual Loss: 0.1650\n",
      "Baseline Loss: 2.6906 | Actual Loss: 0.1738\n",
      "Baseline Loss: 2.6382 | Actual Loss: 0.4756\n",
      "Baseline Loss: 2.7098 | Actual Loss: 0.3950\n",
      "Baseline Loss: 2.7145 | Actual Loss: 0.5469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 130/1000 [01:22<09:10,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6965 | Actual Loss: 0.3469\n",
      "Baseline Loss: 2.6389 | Actual Loss: 0.1951\n",
      "Baseline Loss: 2.2492 | Actual Loss: 0.2098\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.6593\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5819\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2428\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3612\n",
      "Epoch 130/1000: Train Loss: 0.3144, Val Loss: 0.4613\n",
      "Baseline Loss: 2.6582 | Actual Loss: 0.5647\n",
      "Baseline Loss: 2.6827 | Actual Loss: 0.2247\n",
      "Baseline Loss: 2.7366 | Actual Loss: 0.1609\n",
      "Baseline Loss: 2.6441 | Actual Loss: 0.1848\n",
      "Baseline Loss: 2.6824 | Actual Loss: 0.6623\n",
      "Baseline Loss: 2.6595 | Actual Loss: 0.4023\n",
      "Baseline Loss: 2.6308 | Actual Loss: 0.4840\n",
      "Baseline Loss: 2.7090 | Actual Loss: 0.2449\n",
      "Baseline Loss: 2.6731 | Actual Loss: 0.3421\n",
      "Baseline Loss: 2.6710 | Actual Loss: 0.2970\n",
      "Baseline Loss: 2.6844 | Actual Loss: 0.3325\n",
      "Baseline Loss: 2.6775 | Actual Loss: 0.2531\n",
      "Baseline Loss: 2.6508 | Actual Loss: 0.3879\n",
      "Baseline Loss: 2.6894 | Actual Loss: 0.6572\n",
      "Baseline Loss: 2.6498 | Actual Loss: 0.5579\n",
      "Baseline Loss: 2.3285 | Actual Loss: 0.2583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 131/1000 [01:22<08:58,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6755 | Actual Loss: 0.4864\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5691\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2372\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3448\n",
      "Epoch 131/1000: Train Loss: 0.3759, Val Loss: 0.4094\n",
      "Baseline Loss: 2.6605 | Actual Loss: 0.3783\n",
      "Baseline Loss: 2.6545 | Actual Loss: 0.3490\n",
      "Baseline Loss: 2.6643 | Actual Loss: 0.4100\n",
      "Baseline Loss: 2.6905 | Actual Loss: 0.3345\n",
      "Baseline Loss: 2.6449 | Actual Loss: 0.5374\n",
      "Baseline Loss: 2.7194 | Actual Loss: 0.1521\n",
      "Baseline Loss: 2.6478 | Actual Loss: 0.4591\n",
      "Baseline Loss: 2.7081 | Actual Loss: 0.3232\n",
      "Baseline Loss: 2.6738 | Actual Loss: 0.4017\n",
      "Baseline Loss: 2.6643 | Actual Loss: 0.1576\n",
      "Baseline Loss: 2.6712 | Actual Loss: 0.2808\n",
      "Baseline Loss: 2.6683 | Actual Loss: 0.3740\n",
      "Baseline Loss: 2.6740 | Actual Loss: 0.6705\n",
      "Baseline Loss: 2.7084 | Actual Loss: 0.2405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 132/1000 [01:23<09:03,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6797 | Actual Loss: 0.1824\n",
      "Baseline Loss: 2.2663 | Actual Loss: 0.1988\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5005\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5622\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2115\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3874\n",
      "Epoch 132/1000: Train Loss: 0.3406, Val Loss: 0.4154\n",
      "Baseline Loss: 2.6719 | Actual Loss: 0.3291\n",
      "Baseline Loss: 2.6645 | Actual Loss: 0.2711\n",
      "Baseline Loss: 2.6924 | Actual Loss: 0.3582\n",
      "Baseline Loss: 2.6626 | Actual Loss: 0.2124\n",
      "Baseline Loss: 2.6523 | Actual Loss: 0.4424\n",
      "Baseline Loss: 2.6608 | Actual Loss: 0.2815\n",
      "Baseline Loss: 2.6773 | Actual Loss: 0.1777\n",
      "Baseline Loss: 2.7317 | Actual Loss: 1.2534\n",
      "Baseline Loss: 2.6829 | Actual Loss: 0.3679\n",
      "Baseline Loss: 2.6615 | Actual Loss: 0.3378\n",
      "Baseline Loss: 2.6737 | Actual Loss: 0.3821\n",
      "Baseline Loss: 2.6324 | Actual Loss: 0.1462\n",
      "Baseline Loss: 2.6728 | Actual Loss: 0.4358\n",
      "Baseline Loss: 2.6656 | Actual Loss: 0.8008\n",
      "Baseline Loss: 2.6613 | Actual Loss: 0.5386\n",
      "Baseline Loss: 2.3260 | Actual Loss: 0.1340\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.3593\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 133/1000 [01:24<08:51,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6853 | Actual Loss: 0.2530\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2456\n",
      "Epoch 133/1000: Train Loss: 0.4043, Val Loss: 0.3648\n",
      "Baseline Loss: 2.6656 | Actual Loss: 0.2647\n",
      "Baseline Loss: 2.6702 | Actual Loss: 0.3871\n",
      "Baseline Loss: 2.6456 | Actual Loss: 0.2346\n",
      "Baseline Loss: 2.7031 | Actual Loss: 0.5681\n",
      "Baseline Loss: 2.6418 | Actual Loss: 0.3001\n",
      "Baseline Loss: 2.6806 | Actual Loss: 0.3861\n",
      "Baseline Loss: 2.6615 | Actual Loss: 0.3935\n",
      "Baseline Loss: 2.7065 | Actual Loss: 0.2779\n",
      "Baseline Loss: 2.6484 | Actual Loss: 0.4483\n",
      "Baseline Loss: 2.6391 | Actual Loss: 0.4302\n",
      "Baseline Loss: 2.6873 | Actual Loss: 0.5229\n",
      "Baseline Loss: 2.7075 | Actual Loss: 0.5118\n",
      "Baseline Loss: 2.6542 | Actual Loss: 0.3492\n",
      "Baseline Loss: 2.6555 | Actual Loss: 0.2393\n",
      "Baseline Loss: 2.6676 | Actual Loss: 0.2816\n",
      "Baseline Loss: 2.3119 | Actual Loss: 0.2953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 134/1000 [01:24<09:06,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6755 | Actual Loss: 0.4528\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5880\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2310\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2712\n",
      "Epoch 134/1000: Train Loss: 0.3682, Val Loss: 0.3858\n",
      "Baseline Loss: 2.6975 | Actual Loss: 0.3559\n",
      "Baseline Loss: 2.6896 | Actual Loss: 0.5950\n",
      "Baseline Loss: 2.6692 | Actual Loss: 0.1682\n",
      "Baseline Loss: 2.6467 | Actual Loss: 0.5364\n",
      "Baseline Loss: 2.6367 | Actual Loss: 0.5712\n",
      "Baseline Loss: 2.7224 | Actual Loss: 0.7372\n",
      "Baseline Loss: 2.7035 | Actual Loss: 0.4945\n",
      "Baseline Loss: 2.6810 | Actual Loss: 0.3931\n",
      "Baseline Loss: 2.6204 | Actual Loss: 0.1746\n",
      "Baseline Loss: 2.6863 | Actual Loss: 0.3142\n",
      "Baseline Loss: 2.6799 | Actual Loss: 0.3242\n",
      "Baseline Loss: 2.6536 | Actual Loss: 0.2968\n",
      "Baseline Loss: 2.6783 | Actual Loss: 0.2868\n",
      "Baseline Loss: 2.6923 | Actual Loss: 0.3682\n",
      "Baseline Loss: 2.6927 | Actual Loss: 0.2203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▎        | 135/1000 [01:25<09:12,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2490 | Actual Loss: 0.2436\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5220\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5671\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2318\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3567\n",
      "Epoch 135/1000: Train Loss: 0.3800, Val Loss: 0.4194\n",
      "Baseline Loss: 2.6809 | Actual Loss: 0.1132\n",
      "Baseline Loss: 2.6572 | Actual Loss: 0.4259\n",
      "Baseline Loss: 2.6742 | Actual Loss: 0.4911\n",
      "Baseline Loss: 2.6892 | Actual Loss: 0.5006\n",
      "Baseline Loss: 2.6870 | Actual Loss: 0.3972\n",
      "Baseline Loss: 2.6633 | Actual Loss: 0.3832\n",
      "Baseline Loss: 2.6746 | Actual Loss: 0.2391\n",
      "Baseline Loss: 2.6860 | Actual Loss: 0.6107\n",
      "Baseline Loss: 2.6685 | Actual Loss: 0.4936\n",
      "Baseline Loss: 2.6622 | Actual Loss: 0.2865\n",
      "Baseline Loss: 2.7219 | Actual Loss: 0.1524\n",
      "Baseline Loss: 2.6344 | Actual Loss: 0.1676\n",
      "Baseline Loss: 2.7296 | Actual Loss: 0.4787\n",
      "Baseline Loss: 2.6913 | Actual Loss: 0.3911\n",
      "Baseline Loss: 2.6560 | Actual Loss: 0.4375\n",
      "Baseline Loss: 2.2486 | Actual Loss: 0.6826\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.3872\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▎        | 136/1000 [01:26<08:59,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6853 | Actual Loss: 0.2710\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3440\n",
      "Epoch 136/1000: Train Loss: 0.3907, Val Loss: 0.3821\n",
      "Baseline Loss: 2.6574 | Actual Loss: 0.1831\n",
      "Baseline Loss: 2.7053 | Actual Loss: 0.3402\n",
      "Baseline Loss: 2.7085 | Actual Loss: 0.3416\n",
      "Baseline Loss: 2.6912 | Actual Loss: 0.5978\n",
      "Baseline Loss: 2.6681 | Actual Loss: 0.4050\n",
      "Baseline Loss: 2.6810 | Actual Loss: 0.2781\n",
      "Baseline Loss: 2.6549 | Actual Loss: 0.1734\n",
      "Baseline Loss: 2.6360 | Actual Loss: 0.4447\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.6818\n",
      "Baseline Loss: 2.6707 | Actual Loss: 0.1848\n",
      "Baseline Loss: 2.6547 | Actual Loss: 0.5161\n",
      "Baseline Loss: 2.6932 | Actual Loss: 0.3232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▎        | 137/1000 [01:26<08:54,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6670 | Actual Loss: 0.3574\n",
      "Baseline Loss: 2.6791 | Actual Loss: 0.4525\n",
      "Baseline Loss: 2.6563 | Actual Loss: 0.2691\n",
      "Baseline Loss: 2.2316 | Actual Loss: 0.0698\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5232\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5696\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2397\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2179\n",
      "Epoch 137/1000: Train Loss: 0.3511, Val Loss: 0.3876\n",
      "Baseline Loss: 2.7041 | Actual Loss: 0.2918\n",
      "Baseline Loss: 2.6764 | Actual Loss: 0.2736\n",
      "Baseline Loss: 2.6701 | Actual Loss: 0.1947\n",
      "Baseline Loss: 2.6481 | Actual Loss: 0.2814\n",
      "Baseline Loss: 2.6944 | Actual Loss: 0.2443\n",
      "Baseline Loss: 2.6904 | Actual Loss: 0.3781\n",
      "Baseline Loss: 2.6637 | Actual Loss: 0.5726\n",
      "Baseline Loss: 2.7236 | Actual Loss: 0.3923\n",
      "Baseline Loss: 2.6606 | Actual Loss: 0.1954\n",
      "Baseline Loss: 2.6815 | Actual Loss: 0.5360\n",
      "Baseline Loss: 2.6423 | Actual Loss: 0.2608\n",
      "Baseline Loss: 2.6759 | Actual Loss: 0.6413\n",
      "Baseline Loss: 2.6891 | Actual Loss: 0.1935\n",
      "Baseline Loss: 2.6533 | Actual Loss: 0.2340\n",
      "Baseline Loss: 2.6427 | Actual Loss: 0.5398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 138/1000 [01:27<08:50,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2582 | Actual Loss: 0.3597\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4184\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6258\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2926\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3651\n",
      "Epoch 138/1000: Train Loss: 0.3493, Val Loss: 0.4255\n",
      "Baseline Loss: 2.6527 | Actual Loss: 0.3239\n",
      "Baseline Loss: 2.6909 | Actual Loss: 0.3225\n",
      "Baseline Loss: 2.6547 | Actual Loss: 0.4169\n",
      "Baseline Loss: 2.7005 | Actual Loss: 0.2475\n",
      "Baseline Loss: 2.6790 | Actual Loss: 0.4624\n",
      "Baseline Loss: 2.6560 | Actual Loss: 0.2782\n",
      "Baseline Loss: 2.6681 | Actual Loss: 0.1078\n",
      "Baseline Loss: 2.6597 | Actual Loss: 0.4140\n",
      "Baseline Loss: 2.6562 | Actual Loss: 0.3231\n",
      "Baseline Loss: 2.7251 | Actual Loss: 0.3714\n",
      "Baseline Loss: 2.6793 | Actual Loss: 0.3015\n",
      "Baseline Loss: 2.6531 | Actual Loss: 0.3661\n",
      "Baseline Loss: 2.7227 | Actual Loss: 0.2337\n",
      "Baseline Loss: 2.6667 | Actual Loss: 0.3223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 139/1000 [01:27<09:03,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6808 | Actual Loss: 0.4947\n",
      "Baseline Loss: 2.3020 | Actual Loss: 0.1181\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4187\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5438\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2321\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3734\n",
      "Epoch 139/1000: Train Loss: 0.3190, Val Loss: 0.3920\n",
      "Baseline Loss: 2.6429 | Actual Loss: 0.4658\n",
      "Baseline Loss: 2.6581 | Actual Loss: 0.5814\n",
      "Baseline Loss: 2.7085 | Actual Loss: 0.1748\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.5474\n",
      "Baseline Loss: 2.6951 | Actual Loss: 0.5248\n",
      "Baseline Loss: 2.6731 | Actual Loss: 0.3087\n",
      "Baseline Loss: 2.6617 | Actual Loss: 0.4324\n",
      "Baseline Loss: 2.6834 | Actual Loss: 0.3402\n",
      "Baseline Loss: 2.6945 | Actual Loss: 0.2330\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.2470\n",
      "Baseline Loss: 2.6288 | Actual Loss: 0.5086\n",
      "Baseline Loss: 2.6890 | Actual Loss: 0.3571\n",
      "Baseline Loss: 2.6545 | Actual Loss: 0.1183\n",
      "Baseline Loss: 2.6178 | Actual Loss: 0.4271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 140/1000 [01:28<09:09,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6825 | Actual Loss: 0.5055\n",
      "Baseline Loss: 2.3156 | Actual Loss: 0.2019\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.6801\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5393\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2636\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.4036\n",
      "Epoch 140/1000: Train Loss: 0.3734, Val Loss: 0.4716\n",
      "Baseline Loss: 2.6480 | Actual Loss: 0.2228\n",
      "Baseline Loss: 2.6747 | Actual Loss: 0.1474\n",
      "Baseline Loss: 2.6609 | Actual Loss: 0.2720\n",
      "Baseline Loss: 2.7028 | Actual Loss: 0.4659\n",
      "Baseline Loss: 2.6824 | Actual Loss: 0.4805\n",
      "Baseline Loss: 2.6453 | Actual Loss: 0.3217\n",
      "Baseline Loss: 2.7026 | Actual Loss: 0.3999\n",
      "Baseline Loss: 2.6457 | Actual Loss: 0.3697\n",
      "Baseline Loss: 2.6626 | Actual Loss: 0.3742\n",
      "Baseline Loss: 2.6393 | Actual Loss: 0.2418\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.2739\n",
      "Baseline Loss: 2.7062 | Actual Loss: 0.5047\n",
      "Baseline Loss: 2.7197 | Actual Loss: 0.8223\n",
      "Baseline Loss: 2.6712 | Actual Loss: 0.5365\n",
      "Baseline Loss: 2.7116 | Actual Loss: 0.2827\n",
      "Baseline Loss: 2.2230 | Actual Loss: 0.3339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 141/1000 [01:29<09:18,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6755 | Actual Loss: 0.4830\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5983\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2208\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2434\n",
      "Epoch 141/1000: Train Loss: 0.3781, Val Loss: 0.3864\n",
      "Baseline Loss: 2.6495 | Actual Loss: 0.2873\n",
      "Baseline Loss: 2.6572 | Actual Loss: 0.2656\n",
      "Baseline Loss: 2.6767 | Actual Loss: 0.6026\n",
      "Baseline Loss: 2.6632 | Actual Loss: 1.0392\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4512\n",
      "Baseline Loss: 2.6797 | Actual Loss: 0.3564\n",
      "Baseline Loss: 2.6672 | Actual Loss: 0.4370\n",
      "Baseline Loss: 2.6452 | Actual Loss: 0.1977\n",
      "Baseline Loss: 2.6727 | Actual Loss: 0.6289\n",
      "Baseline Loss: 2.6660 | Actual Loss: 0.2507\n",
      "Baseline Loss: 2.6505 | Actual Loss: 0.2534\n",
      "Baseline Loss: 2.6915 | Actual Loss: 0.4026\n",
      "Baseline Loss: 2.6969 | Actual Loss: 0.2768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 142/1000 [01:29<08:58,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7256 | Actual Loss: 0.3908\n",
      "Baseline Loss: 2.6772 | Actual Loss: 0.5294\n",
      "Baseline Loss: 2.2555 | Actual Loss: 0.3751\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5347\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6154\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2377\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2666\n",
      "Epoch 142/1000: Train Loss: 0.4215, Val Loss: 0.4136\n",
      "Baseline Loss: 2.6585 | Actual Loss: 0.3652\n",
      "Baseline Loss: 2.6848 | Actual Loss: 0.4225\n",
      "Baseline Loss: 2.6740 | Actual Loss: 0.3784\n",
      "Baseline Loss: 2.6401 | Actual Loss: 0.3246\n",
      "Baseline Loss: 2.6767 | Actual Loss: 0.3116\n",
      "Baseline Loss: 2.7195 | Actual Loss: 0.1536\n",
      "Baseline Loss: 2.6774 | Actual Loss: 0.2985\n",
      "Baseline Loss: 2.6997 | Actual Loss: 0.5232\n",
      "Baseline Loss: 2.6683 | Actual Loss: 0.2587\n",
      "Baseline Loss: 2.6652 | Actual Loss: 0.4884\n",
      "Baseline Loss: 2.6131 | Actual Loss: 0.2355\n",
      "Baseline Loss: 2.6936 | Actual Loss: 0.3122\n",
      "Baseline Loss: 2.6673 | Actual Loss: 0.3444\n",
      "Baseline Loss: 2.6635 | Actual Loss: 0.3519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 143/1000 [01:30<09:03,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7279 | Actual Loss: 0.2116\n",
      "Baseline Loss: 2.2769 | Actual Loss: 0.4185\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4336\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5913\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2265\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.1863\n",
      "Epoch 143/1000: Train Loss: 0.3374, Val Loss: 0.3594\n",
      "Baseline Loss: 2.7020 | Actual Loss: 0.3369\n",
      "Baseline Loss: 2.6546 | Actual Loss: 0.4977\n",
      "Baseline Loss: 2.6784 | Actual Loss: 0.3164\n",
      "Baseline Loss: 2.6685 | Actual Loss: 0.2604\n",
      "Baseline Loss: 2.6563 | Actual Loss: 0.3021\n",
      "Baseline Loss: 2.6762 | Actual Loss: 0.2552\n",
      "Baseline Loss: 2.7220 | Actual Loss: 0.2068\n",
      "Baseline Loss: 2.6627 | Actual Loss: 0.4083\n",
      "Baseline Loss: 2.6933 | Actual Loss: 0.3065\n",
      "Baseline Loss: 2.6875 | Actual Loss: 0.3117\n",
      "Baseline Loss: 2.6532 | Actual Loss: 0.4196\n",
      "Baseline Loss: 2.6679 | Actual Loss: 0.3056\n",
      "Baseline Loss: 2.6721 | Actual Loss: 1.3302\n",
      "Baseline Loss: 2.6972 | Actual Loss: 0.2048\n",
      "Baseline Loss: 2.6744 | Actual Loss: 0.3140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 144/1000 [01:31<09:12,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2599 | Actual Loss: 0.1482\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4061\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.4997\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2041\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2935\n",
      "Epoch 144/1000: Train Loss: 0.3703, Val Loss: 0.3508\n",
      "New best validation loss: 0.3508\n",
      "Baseline Loss: 2.6982 | Actual Loss: 0.5276\n",
      "Baseline Loss: 2.6636 | Actual Loss: 0.3037\n",
      "Baseline Loss: 2.6464 | Actual Loss: 0.2074\n",
      "Baseline Loss: 2.6675 | Actual Loss: 0.1477\n",
      "Baseline Loss: 2.6627 | Actual Loss: 0.3760\n",
      "Baseline Loss: 2.6957 | Actual Loss: 0.3140\n",
      "Baseline Loss: 2.6387 | Actual Loss: 0.3737\n",
      "Baseline Loss: 2.6714 | Actual Loss: 0.4614\n",
      "Baseline Loss: 2.6702 | Actual Loss: 0.2962\n",
      "Baseline Loss: 2.6498 | Actual Loss: 0.4578\n",
      "Baseline Loss: 2.6895 | Actual Loss: 0.1283\n",
      "Baseline Loss: 2.6459 | Actual Loss: 0.6680\n",
      "Baseline Loss: 2.6633 | Actual Loss: 0.2209\n",
      "Baseline Loss: 2.6751 | Actual Loss: 0.3952\n",
      "Baseline Loss: 2.7002 | Actual Loss: 0.4578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 145/1000 [01:31<09:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.3038 | Actual Loss: 0.3556\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5318\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5638\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2431\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2946\n",
      "Epoch 145/1000: Train Loss: 0.3557, Val Loss: 0.4083\n",
      "Baseline Loss: 2.7161 | Actual Loss: 0.2272\n",
      "Baseline Loss: 2.6496 | Actual Loss: 0.9716\n",
      "Baseline Loss: 2.6887 | Actual Loss: 0.2239\n",
      "Baseline Loss: 2.6528 | Actual Loss: 0.3105\n",
      "Baseline Loss: 2.6720 | Actual Loss: 0.4105\n",
      "Baseline Loss: 2.6625 | Actual Loss: 0.5596\n",
      "Baseline Loss: 2.6678 | Actual Loss: 0.3959\n",
      "Baseline Loss: 2.6708 | Actual Loss: 1.0243\n",
      "Baseline Loss: 2.6741 | Actual Loss: 0.2455\n",
      "Baseline Loss: 2.6769 | Actual Loss: 0.3549\n",
      "Baseline Loss: 2.6727 | Actual Loss: 0.1998\n",
      "Baseline Loss: 2.6887 | Actual Loss: 0.7942\n",
      "Baseline Loss: 2.6344 | Actual Loss: 0.2668\n",
      "Baseline Loss: 2.7162 | Actual Loss: 0.5281\n",
      "Baseline Loss: 2.6528 | Actual Loss: 0.2134\n",
      "Baseline Loss: 2.3053 | Actual Loss: 1.9034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 146/1000 [01:32<09:03,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6755 | Actual Loss: 0.4024\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5238\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2276\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2222\n",
      "Epoch 146/1000: Train Loss: 0.5394, Val Loss: 0.3440\n",
      "New best validation loss: 0.3440\n",
      "Baseline Loss: 2.6402 | Actual Loss: 0.2426\n",
      "Baseline Loss: 2.6660 | Actual Loss: 0.3580\n",
      "Baseline Loss: 2.7133 | Actual Loss: 0.2933\n",
      "Baseline Loss: 2.6470 | Actual Loss: 0.4602\n",
      "Baseline Loss: 2.6783 | Actual Loss: 0.3764\n",
      "Baseline Loss: 2.6812 | Actual Loss: 0.3053\n",
      "Baseline Loss: 2.6504 | Actual Loss: 0.4131\n",
      "Baseline Loss: 2.6472 | Actual Loss: 0.3843\n",
      "Baseline Loss: 2.6659 | Actual Loss: 0.2329\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3703\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.3253\n",
      "Baseline Loss: 2.6748 | Actual Loss: 1.2506\n",
      "Baseline Loss: 2.6919 | Actual Loss: 0.3612\n",
      "Baseline Loss: 2.6670 | Actual Loss: 0.1857\n",
      "Baseline Loss: 2.6753 | Actual Loss: 0.1342\n",
      "Baseline Loss: 2.3065 | Actual Loss: 1.5886\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4608\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 147/1000 [01:33<09:11,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6853 | Actual Loss: 0.2355\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2422\n",
      "Epoch 147/1000: Train Loss: 0.4551, Val Loss: 0.3890\n",
      "Baseline Loss: 2.6725 | Actual Loss: 0.3578\n",
      "Baseline Loss: 2.6547 | Actual Loss: 0.2823\n",
      "Baseline Loss: 2.7053 | Actual Loss: 0.2137\n",
      "Baseline Loss: 2.6566 | Actual Loss: 0.2550\n",
      "Baseline Loss: 2.6908 | Actual Loss: 0.1886\n",
      "Baseline Loss: 2.6654 | Actual Loss: 0.5200\n",
      "Baseline Loss: 2.6874 | Actual Loss: 0.5200\n",
      "Baseline Loss: 2.6922 | Actual Loss: 0.2464\n",
      "Baseline Loss: 2.6280 | Actual Loss: 0.5074\n",
      "Baseline Loss: 2.7492 | Actual Loss: 0.3308\n",
      "Baseline Loss: 2.6424 | Actual Loss: 0.1442\n",
      "Baseline Loss: 2.6517 | Actual Loss: 0.3793\n",
      "Baseline Loss: 2.6379 | Actual Loss: 0.5024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 148/1000 [01:33<08:48,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7011 | Actual Loss: 0.4618\n",
      "Baseline Loss: 2.6516 | Actual Loss: 0.1875\n",
      "Baseline Loss: 2.2348 | Actual Loss: 0.1704\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5514\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6756\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2371\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.4790\n",
      "Epoch 148/1000: Train Loss: 0.3292, Val Loss: 0.4857\n",
      "Baseline Loss: 2.6910 | Actual Loss: 0.3738\n",
      "Baseline Loss: 2.6842 | Actual Loss: 0.4180\n",
      "Baseline Loss: 2.6775 | Actual Loss: 0.3411\n",
      "Baseline Loss: 2.6941 | Actual Loss: 0.4953\n",
      "Baseline Loss: 2.6569 | Actual Loss: 0.2427\n",
      "Baseline Loss: 2.6657 | Actual Loss: 0.4548\n",
      "Baseline Loss: 2.6656 | Actual Loss: 0.5669\n",
      "Baseline Loss: 2.6493 | Actual Loss: 0.4145\n",
      "Baseline Loss: 2.6331 | Actual Loss: 0.4384\n",
      "Baseline Loss: 2.6783 | Actual Loss: 0.2127\n",
      "Baseline Loss: 2.6926 | Actual Loss: 0.6013\n",
      "Baseline Loss: 2.6953 | Actual Loss: 0.6067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 149/1000 [01:34<08:52,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6671 | Actual Loss: 0.3033\n",
      "Baseline Loss: 2.6745 | Actual Loss: 0.3575\n",
      "Baseline Loss: 2.6643 | Actual Loss: 0.7659\n",
      "Baseline Loss: 2.2608 | Actual Loss: 0.1163\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4314\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6388\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2166\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.1861\n",
      "Epoch 149/1000: Train Loss: 0.4193, Val Loss: 0.3682\n",
      "Baseline Loss: 2.6687 | Actual Loss: 0.2538\n",
      "Baseline Loss: 2.6721 | Actual Loss: 0.2991\n",
      "Baseline Loss: 2.6845 | Actual Loss: 0.2376\n",
      "Baseline Loss: 2.6750 | Actual Loss: 0.2824\n",
      "Baseline Loss: 2.6689 | Actual Loss: 0.3015\n",
      "Baseline Loss: 2.6689 | Actual Loss: 0.6401\n",
      "Baseline Loss: 2.6944 | Actual Loss: 0.1871\n",
      "Baseline Loss: 2.6395 | Actual Loss: 0.3370\n",
      "Baseline Loss: 2.6504 | Actual Loss: 0.3175\n",
      "Baseline Loss: 2.6919 | Actual Loss: 0.2645\n",
      "Baseline Loss: 2.6894 | Actual Loss: 0.3406\n",
      "Baseline Loss: 2.6388 | Actual Loss: 0.2420\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.5744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 150/1000 [01:34<09:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6960 | Actual Loss: 0.5087\n",
      "Baseline Loss: 2.7053 | Actual Loss: 0.3397\n",
      "Baseline Loss: 2.2656 | Actual Loss: 0.0896\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5307\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6223\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2363\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3696\n",
      "Epoch 150/1000: Train Loss: 0.3260, Val Loss: 0.4397\n",
      "Baseline Loss: 2.6833 | Actual Loss: 0.2690\n",
      "Baseline Loss: 2.6636 | Actual Loss: 0.3471\n",
      "Baseline Loss: 2.6829 | Actual Loss: 0.3179\n",
      "Baseline Loss: 2.6092 | Actual Loss: 0.3009\n",
      "Baseline Loss: 2.6775 | Actual Loss: 0.3242\n",
      "Baseline Loss: 2.6645 | Actual Loss: 0.7858\n",
      "Baseline Loss: 2.6717 | Actual Loss: 0.1328\n",
      "Baseline Loss: 2.6756 | Actual Loss: 0.4481\n",
      "Baseline Loss: 2.6503 | Actual Loss: 0.4287\n",
      "Baseline Loss: 2.7150 | Actual Loss: 1.4271\n",
      "Baseline Loss: 2.6611 | Actual Loss: 0.2347\n",
      "Baseline Loss: 2.6808 | Actual Loss: 0.2705\n",
      "Baseline Loss: 2.6795 | Actual Loss: 0.3968\n",
      "Baseline Loss: 2.6414 | Actual Loss: 0.2225\n",
      "Baseline Loss: 2.6663 | Actual Loss: 1.5703\n",
      "Baseline Loss: 2.3301 | Actual Loss: 0.2398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 151/1000 [01:35<08:46,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6755 | Actual Loss: 0.5096\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5461\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2120\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3468\n",
      "Epoch 151/1000: Train Loss: 0.4823, Val Loss: 0.4036\n",
      "Baseline Loss: 2.6897 | Actual Loss: 0.2221\n",
      "Baseline Loss: 2.6350 | Actual Loss: 0.1626\n",
      "Baseline Loss: 2.6782 | Actual Loss: 0.4642\n",
      "Baseline Loss: 2.6419 | Actual Loss: 0.2157\n",
      "Baseline Loss: 2.6900 | Actual Loss: 0.3682\n",
      "Baseline Loss: 2.6470 | Actual Loss: 0.2612\n",
      "Baseline Loss: 2.6564 | Actual Loss: 0.1592\n",
      "Baseline Loss: 2.6780 | Actual Loss: 0.1809\n",
      "Baseline Loss: 2.6350 | Actual Loss: 0.5017\n",
      "Baseline Loss: 2.6756 | Actual Loss: 0.5705\n",
      "Baseline Loss: 2.6491 | Actual Loss: 0.3285\n",
      "Baseline Loss: 2.6899 | Actual Loss: 0.1897\n",
      "Baseline Loss: 2.6873 | Actual Loss: 0.4287\n",
      "Baseline Loss: 2.7030 | Actual Loss: 0.3135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 152/1000 [01:36<08:55,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7265 | Actual Loss: 0.1458\n",
      "Baseline Loss: 2.3120 | Actual Loss: 0.2456\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.6208\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6494\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2232\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2906\n",
      "Epoch 152/1000: Train Loss: 0.2974, Val Loss: 0.4460\n",
      "Baseline Loss: 2.6551 | Actual Loss: 0.2937\n",
      "Baseline Loss: 2.6986 | Actual Loss: 0.2925\n",
      "Baseline Loss: 2.6431 | Actual Loss: 0.3234\n",
      "Baseline Loss: 2.6897 | Actual Loss: 0.6279\n",
      "Baseline Loss: 2.6704 | Actual Loss: 0.2528\n",
      "Baseline Loss: 2.6635 | Actual Loss: 0.5116\n",
      "Baseline Loss: 2.6656 | Actual Loss: 0.4892\n",
      "Baseline Loss: 2.6714 | Actual Loss: 0.2840\n",
      "Baseline Loss: 2.6629 | Actual Loss: 0.3734\n",
      "Baseline Loss: 2.7146 | Actual Loss: 0.4173\n",
      "Baseline Loss: 2.7006 | Actual Loss: 0.1776\n",
      "Baseline Loss: 2.6830 | Actual Loss: 0.1660\n",
      "Baseline Loss: 2.6498 | Actual Loss: 0.7425\n",
      "Baseline Loss: 2.6935 | Actual Loss: 0.2904\n",
      "Baseline Loss: 2.6868 | Actual Loss: 0.2493\n",
      "Baseline Loss: 2.2002 | Actual Loss: 0.1210\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.6557\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 153/1000 [01:36<08:42,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6853 | Actual Loss: 0.2498\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3445\n",
      "Epoch 153/1000: Train Loss: 0.3508, Val Loss: 0.4519\n",
      "Baseline Loss: 2.6753 | Actual Loss: 0.2032\n",
      "Baseline Loss: 2.6766 | Actual Loss: 0.2119\n",
      "Baseline Loss: 2.6744 | Actual Loss: 0.4296\n",
      "Baseline Loss: 2.7209 | Actual Loss: 0.4802\n",
      "Baseline Loss: 2.6900 | Actual Loss: 0.4468\n",
      "Baseline Loss: 2.6743 | Actual Loss: 0.2145\n",
      "Baseline Loss: 2.6763 | Actual Loss: 0.4082\n",
      "Baseline Loss: 2.6244 | Actual Loss: 0.3481\n",
      "Baseline Loss: 2.6628 | Actual Loss: 0.3940\n",
      "Baseline Loss: 2.6607 | Actual Loss: 0.2160\n",
      "Baseline Loss: 2.6524 | Actual Loss: 0.3173\n",
      "Baseline Loss: 2.6361 | Actual Loss: 0.3552\n",
      "Baseline Loss: 2.7681 | Actual Loss: 0.3409\n",
      "Baseline Loss: 2.6781 | Actual Loss: 0.6491\n",
      "Baseline Loss: 2.6637 | Actual Loss: 0.2300\n",
      "Baseline Loss: 2.2711 | Actual Loss: 0.5952\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 154/1000 [01:37<08:55,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6640 | Actual Loss: 0.4707\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2224\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.1866\n",
      "Epoch 154/1000: Train Loss: 0.3650, Val Loss: 0.3290\n",
      "New best validation loss: 0.3290\n",
      "Baseline Loss: 2.6431 | Actual Loss: 0.4305\n",
      "Baseline Loss: 2.6299 | Actual Loss: 0.2556\n",
      "Baseline Loss: 2.6610 | Actual Loss: 0.4217\n",
      "Baseline Loss: 2.6610 | Actual Loss: 0.3265\n",
      "Baseline Loss: 2.7041 | Actual Loss: 0.1619\n",
      "Baseline Loss: 2.7038 | Actual Loss: 0.2180\n",
      "Baseline Loss: 2.7027 | Actual Loss: 0.1527\n",
      "Baseline Loss: 2.6514 | Actual Loss: 0.4652\n",
      "Baseline Loss: 2.6926 | Actual Loss: 0.4559\n",
      "Baseline Loss: 2.6850 | Actual Loss: 0.2543\n",
      "Baseline Loss: 2.6530 | Actual Loss: 0.3487\n",
      "Baseline Loss: 2.7047 | Actual Loss: 0.2324\n",
      "Baseline Loss: 2.6847 | Actual Loss: 0.3195\n",
      "Baseline Loss: 2.6620 | Actual Loss: 0.3394\n",
      "Baseline Loss: 2.6764 | Actual Loss: 1.0212\n",
      "Baseline Loss: 2.2676 | Actual Loss: 0.0868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 155/1000 [01:38<09:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6755 | Actual Loss: 0.4446\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5291\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2346\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2784\n",
      "Epoch 155/1000: Train Loss: 0.3431, Val Loss: 0.3717\n",
      "Baseline Loss: 2.6711 | Actual Loss: 0.2926\n",
      "Baseline Loss: 2.6982 | Actual Loss: 0.1493\n",
      "Baseline Loss: 2.7006 | Actual Loss: 0.4670\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3078\n",
      "Baseline Loss: 2.6715 | Actual Loss: 0.0717\n",
      "Baseline Loss: 2.6968 | Actual Loss: 0.4740\n",
      "Baseline Loss: 2.6794 | Actual Loss: 0.9051\n",
      "Baseline Loss: 2.6115 | Actual Loss: 0.2201\n",
      "Baseline Loss: 2.6625 | Actual Loss: 0.1643\n",
      "Baseline Loss: 2.6192 | Actual Loss: 0.3645\n",
      "Baseline Loss: 2.6848 | Actual Loss: 0.3390\n",
      "Baseline Loss: 2.6731 | Actual Loss: 0.2939\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.3403\n",
      "Baseline Loss: 2.7066 | Actual Loss: 0.3389\n",
      "Baseline Loss: 2.6963 | Actual Loss: 0.4497\n",
      "Baseline Loss: 2.2652 | Actual Loss: 0.0922\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4827\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 156/1000 [01:38<08:52,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6853 | Actual Loss: 0.2283\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2022\n",
      "Epoch 156/1000: Train Loss: 0.3294, Val Loss: 0.3735\n",
      "Baseline Loss: 2.6622 | Actual Loss: 0.2329\n",
      "Baseline Loss: 2.6869 | Actual Loss: 0.5039\n",
      "Baseline Loss: 2.6681 | Actual Loss: 0.7586\n",
      "Baseline Loss: 2.6792 | Actual Loss: 0.2292\n",
      "Baseline Loss: 2.6605 | Actual Loss: 0.2349\n",
      "Baseline Loss: 2.6549 | Actual Loss: 0.5130\n",
      "Baseline Loss: 2.6669 | Actual Loss: 0.1653\n",
      "Baseline Loss: 2.7191 | Actual Loss: 0.1572\n",
      "Baseline Loss: 2.6948 | Actual Loss: 0.4394\n",
      "Baseline Loss: 2.6889 | Actual Loss: 0.4177\n",
      "Baseline Loss: 2.6717 | Actual Loss: 0.2657\n",
      "Baseline Loss: 2.6673 | Actual Loss: 0.2267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 157/1000 [01:39<08:55,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6752 | Actual Loss: 0.1638\n",
      "Baseline Loss: 2.6947 | Actual Loss: 0.2795\n",
      "Baseline Loss: 2.6313 | Actual Loss: 0.5256\n",
      "Baseline Loss: 2.2341 | Actual Loss: 0.6574\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5355\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.4762\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2333\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2670\n",
      "Epoch 157/1000: Train Loss: 0.3607, Val Loss: 0.3780\n",
      "Baseline Loss: 2.6566 | Actual Loss: 0.4082\n",
      "Baseline Loss: 2.6761 | Actual Loss: 0.4595\n",
      "Baseline Loss: 2.6786 | Actual Loss: 0.3055\n",
      "Baseline Loss: 2.6789 | Actual Loss: 0.2216\n",
      "Baseline Loss: 2.7045 | Actual Loss: 0.4079\n",
      "Baseline Loss: 2.6714 | Actual Loss: 0.4197\n",
      "Baseline Loss: 2.6754 | Actual Loss: 0.5383\n",
      "Baseline Loss: 2.6495 | Actual Loss: 0.1399\n",
      "Baseline Loss: 2.7313 | Actual Loss: 0.6576\n",
      "Baseline Loss: 2.6851 | Actual Loss: 0.4384\n",
      "Baseline Loss: 2.6611 | Actual Loss: 0.1994\n",
      "Baseline Loss: 2.6777 | Actual Loss: 0.3890\n",
      "Baseline Loss: 2.6870 | Actual Loss: 0.1447\n",
      "Baseline Loss: 2.6977 | Actual Loss: 0.1744\n",
      "Baseline Loss: 2.6752 | Actual Loss: 0.4148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 158/1000 [01:39<08:41,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2224 | Actual Loss: 0.5113\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4028\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5444\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2323\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.1643\n",
      "Epoch 158/1000: Train Loss: 0.3644, Val Loss: 0.3359\n",
      "Baseline Loss: 2.6290 | Actual Loss: 0.1223\n",
      "Baseline Loss: 2.6562 | Actual Loss: 0.3635\n",
      "Baseline Loss: 2.6721 | Actual Loss: 0.1795\n",
      "Baseline Loss: 2.7320 | Actual Loss: 0.2821\n",
      "Baseline Loss: 2.6527 | Actual Loss: 0.1537\n",
      "Baseline Loss: 2.6780 | Actual Loss: 0.3713\n",
      "Baseline Loss: 2.6756 | Actual Loss: 0.2271\n",
      "Baseline Loss: 2.6632 | Actual Loss: 0.1582\n",
      "Baseline Loss: 2.6583 | Actual Loss: 0.7292\n",
      "Baseline Loss: 2.6870 | Actual Loss: 0.1435\n",
      "Baseline Loss: 2.6535 | Actual Loss: 0.3525\n",
      "Baseline Loss: 2.7021 | Actual Loss: 0.2758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 159/1000 [01:40<08:52,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6504 | Actual Loss: 0.2065\n",
      "Baseline Loss: 2.6605 | Actual Loss: 0.4006\n",
      "Baseline Loss: 2.6731 | Actual Loss: 0.5101\n",
      "Baseline Loss: 2.2830 | Actual Loss: 0.1970\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4398\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.3969\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2719\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2218\n",
      "Epoch 159/1000: Train Loss: 0.2920, Val Loss: 0.3326\n",
      "Baseline Loss: 2.6878 | Actual Loss: 0.3422\n",
      "Baseline Loss: 2.6779 | Actual Loss: 0.4285\n",
      "Baseline Loss: 2.6466 | Actual Loss: 0.5905\n",
      "Baseline Loss: 2.6328 | Actual Loss: 0.2370\n",
      "Baseline Loss: 2.6476 | Actual Loss: 0.2991\n",
      "Baseline Loss: 2.6779 | Actual Loss: 0.4311\n",
      "Baseline Loss: 2.6562 | Actual Loss: 0.2601\n",
      "Baseline Loss: 2.6587 | Actual Loss: 0.2216\n",
      "Baseline Loss: 2.6763 | Actual Loss: 0.1890\n",
      "Baseline Loss: 2.6827 | Actual Loss: 0.1675\n",
      "Baseline Loss: 2.6878 | Actual Loss: 0.5632\n",
      "Baseline Loss: 2.6872 | Actual Loss: 0.4484\n",
      "Baseline Loss: 2.6515 | Actual Loss: 0.4169\n",
      "Baseline Loss: 2.6718 | Actual Loss: 0.2892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 160/1000 [01:41<08:58,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6522 | Actual Loss: 0.3769\n",
      "Baseline Loss: 2.3372 | Actual Loss: 0.2346\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4757\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6899\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2109\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3047\n",
      "Epoch 160/1000: Train Loss: 0.3435, Val Loss: 0.4203\n",
      "Baseline Loss: 2.6987 | Actual Loss: 0.3454\n",
      "Baseline Loss: 2.6909 | Actual Loss: 0.3851\n",
      "Baseline Loss: 2.6419 | Actual Loss: 0.3203\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.5003\n",
      "Baseline Loss: 2.6739 | Actual Loss: 0.2074\n",
      "Baseline Loss: 2.6500 | Actual Loss: 0.2342\n",
      "Baseline Loss: 2.6646 | Actual Loss: 0.3019\n",
      "Baseline Loss: 2.7004 | Actual Loss: 0.1207\n",
      "Baseline Loss: 2.5977 | Actual Loss: 0.2904\n",
      "Baseline Loss: 2.6844 | Actual Loss: 0.2790\n",
      "Baseline Loss: 2.6612 | Actual Loss: 0.2525\n",
      "Baseline Loss: 2.6699 | Actual Loss: 0.1426\n",
      "Baseline Loss: 2.6587 | Actual Loss: 0.7024\n",
      "Baseline Loss: 2.6962 | Actual Loss: 0.3321\n",
      "Baseline Loss: 2.6983 | Actual Loss: 0.3205\n",
      "Baseline Loss: 2.2930 | Actual Loss: 0.2885\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5690\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.7013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 161/1000 [01:41<09:06,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6853 | Actual Loss: 0.2603\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3373\n",
      "Epoch 161/1000: Train Loss: 0.3140, Val Loss: 0.4670\n",
      "Baseline Loss: 2.6797 | Actual Loss: 0.3664\n",
      "Baseline Loss: 2.6734 | Actual Loss: 0.3038\n",
      "Baseline Loss: 2.6685 | Actual Loss: 0.0815\n",
      "Baseline Loss: 2.6933 | Actual Loss: 0.6163\n",
      "Baseline Loss: 2.6621 | Actual Loss: 0.2097\n",
      "Baseline Loss: 2.6632 | Actual Loss: 0.3452\n",
      "Baseline Loss: 2.6639 | Actual Loss: 0.1076\n",
      "Baseline Loss: 2.6556 | Actual Loss: 0.4462\n",
      "Baseline Loss: 2.6664 | Actual Loss: 0.2815\n",
      "Baseline Loss: 2.6790 | Actual Loss: 0.7181\n",
      "Baseline Loss: 2.7132 | Actual Loss: 0.3298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 162/1000 [01:42<08:45,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6755 | Actual Loss: 0.2638\n",
      "Baseline Loss: 2.6426 | Actual Loss: 0.3466\n",
      "Baseline Loss: 2.6601 | Actual Loss: 0.3018\n",
      "Baseline Loss: 2.6671 | Actual Loss: 0.2733\n",
      "Baseline Loss: 2.3288 | Actual Loss: 0.2129\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5478\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6241\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2559\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.1904\n",
      "Epoch 162/1000: Train Loss: 0.3253, Val Loss: 0.4045\n",
      "Baseline Loss: 2.6811 | Actual Loss: 0.1518\n",
      "Baseline Loss: 2.6850 | Actual Loss: 0.3974\n",
      "Baseline Loss: 2.7479 | Actual Loss: 0.2833\n",
      "Baseline Loss: 2.6699 | Actual Loss: 0.4717\n",
      "Baseline Loss: 2.6429 | Actual Loss: 0.5841\n",
      "Baseline Loss: 2.6528 | Actual Loss: 0.4744\n",
      "Baseline Loss: 2.6504 | Actual Loss: 0.1444\n",
      "Baseline Loss: 2.6762 | Actual Loss: 0.3550\n",
      "Baseline Loss: 2.6788 | Actual Loss: 0.3122\n",
      "Baseline Loss: 2.6547 | Actual Loss: 0.2260\n",
      "Baseline Loss: 2.6829 | Actual Loss: 0.1877\n",
      "Baseline Loss: 2.6683 | Actual Loss: 0.5465\n",
      "Baseline Loss: 2.6730 | Actual Loss: 0.3320\n",
      "Baseline Loss: 2.6882 | Actual Loss: 0.7811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▋        | 163/1000 [01:43<08:53,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6824 | Actual Loss: 0.1541\n",
      "Baseline Loss: 2.2231 | Actual Loss: 0.2339\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5274\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6334\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2080\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3117\n",
      "Epoch 163/1000: Train Loss: 0.3522, Val Loss: 0.4201\n",
      "Baseline Loss: 2.6637 | Actual Loss: 0.2513\n",
      "Baseline Loss: 2.7205 | Actual Loss: 0.2886\n",
      "Baseline Loss: 2.6743 | Actual Loss: 0.2936\n",
      "Baseline Loss: 2.6714 | Actual Loss: 0.6592\n",
      "Baseline Loss: 2.6473 | Actual Loss: 0.3834\n",
      "Baseline Loss: 2.6781 | Actual Loss: 0.8928\n",
      "Baseline Loss: 2.6890 | Actual Loss: 0.5471\n",
      "Baseline Loss: 2.6348 | Actual Loss: 0.2875\n",
      "Baseline Loss: 2.6771 | Actual Loss: 0.4479\n",
      "Baseline Loss: 2.7196 | Actual Loss: 0.4973\n",
      "Baseline Loss: 2.6739 | Actual Loss: 0.1937\n",
      "Baseline Loss: 2.6524 | Actual Loss: 0.4006\n",
      "Baseline Loss: 2.7228 | Actual Loss: 0.2592\n",
      "Baseline Loss: 2.6677 | Actual Loss: 0.3155\n",
      "Baseline Loss: 2.6762 | Actual Loss: 0.1350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▋        | 164/1000 [01:43<08:52,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2489 | Actual Loss: 0.1082\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5966\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6838\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2152\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2958\n",
      "Epoch 164/1000: Train Loss: 0.3726, Val Loss: 0.4478\n",
      "Baseline Loss: 2.6692 | Actual Loss: 0.2941\n",
      "Baseline Loss: 2.6529 | Actual Loss: 0.2812\n",
      "Baseline Loss: 2.6768 | Actual Loss: 0.3872\n",
      "Baseline Loss: 2.6737 | Actual Loss: 0.1775\n",
      "Baseline Loss: 2.7290 | Actual Loss: 0.3425\n",
      "Baseline Loss: 2.6634 | Actual Loss: 0.5319\n",
      "Baseline Loss: 2.6544 | Actual Loss: 0.3240\n",
      "Baseline Loss: 2.6759 | Actual Loss: 0.3224\n",
      "Baseline Loss: 2.7016 | Actual Loss: 0.3789\n",
      "Baseline Loss: 2.6489 | Actual Loss: 0.3747\n",
      "Baseline Loss: 2.6651 | Actual Loss: 0.4053\n",
      "Baseline Loss: 2.6623 | Actual Loss: 0.3083\n",
      "Baseline Loss: 2.6417 | Actual Loss: 0.2177\n",
      "Baseline Loss: 2.6791 | Actual Loss: 0.3102\n",
      "Baseline Loss: 2.6524 | Actual Loss: 0.1354\n",
      "Baseline Loss: 2.2643 | Actual Loss: 0.2291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▋        | 165/1000 [01:44<08:42,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6755 | Actual Loss: 0.4234\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5989\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2114\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3395\n",
      "Epoch 165/1000: Train Loss: 0.3138, Val Loss: 0.3933\n",
      "Baseline Loss: 2.6824 | Actual Loss: 0.3626\n",
      "Baseline Loss: 2.6382 | Actual Loss: 0.8216\n",
      "Baseline Loss: 2.6717 | Actual Loss: 0.2778\n",
      "Baseline Loss: 2.6685 | Actual Loss: 0.9823\n",
      "Baseline Loss: 2.7070 | Actual Loss: 0.3242\n",
      "Baseline Loss: 2.6828 | Actual Loss: 0.2793\n",
      "Baseline Loss: 2.6639 | Actual Loss: 0.2221\n",
      "Baseline Loss: 2.6491 | Actual Loss: 0.2993\n",
      "Baseline Loss: 2.6846 | Actual Loss: 0.1960\n",
      "Baseline Loss: 2.6642 | Actual Loss: 0.4862\n",
      "Baseline Loss: 2.6874 | Actual Loss: 0.2549\n",
      "Baseline Loss: 2.6449 | Actual Loss: 0.3362\n",
      "Baseline Loss: 2.6641 | Actual Loss: 0.2412\n",
      "Baseline Loss: 2.6596 | Actual Loss: 0.3002\n",
      "Baseline Loss: 2.7294 | Actual Loss: 0.2888\n",
      "Baseline Loss: 2.2616 | Actual Loss: 0.1679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 166/1000 [01:45<08:50,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6755 | Actual Loss: 0.5175\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6187\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2618\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3664\n",
      "Epoch 166/1000: Train Loss: 0.3650, Val Loss: 0.4411\n",
      "Baseline Loss: 2.6921 | Actual Loss: 0.3468\n",
      "Baseline Loss: 2.6921 | Actual Loss: 0.1922\n",
      "Baseline Loss: 2.6650 | Actual Loss: 0.2935\n",
      "Baseline Loss: 2.6767 | Actual Loss: 0.2368\n",
      "Baseline Loss: 2.6540 | Actual Loss: 0.2527\n",
      "Baseline Loss: 2.6892 | Actual Loss: 0.9524\n",
      "Baseline Loss: 2.7113 | Actual Loss: 0.2528\n",
      "Baseline Loss: 2.6443 | Actual Loss: 0.4568\n",
      "Baseline Loss: 2.6947 | Actual Loss: 0.3987\n",
      "Baseline Loss: 2.6745 | Actual Loss: 0.1487\n",
      "Baseline Loss: 2.6901 | Actual Loss: 0.5672\n",
      "Baseline Loss: 2.6479 | Actual Loss: 0.3213\n",
      "Baseline Loss: 2.6560 | Actual Loss: 0.4621\n",
      "Baseline Loss: 2.6877 | Actual Loss: 1.0100\n",
      "Baseline Loss: 2.6774 | Actual Loss: 0.3695\n",
      "Baseline Loss: 2.2346 | Actual Loss: 0.7186\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 167/1000 [01:45<09:02,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6640 | Actual Loss: 0.5892\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2115\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2063\n",
      "Epoch 167/1000: Train Loss: 0.4362, Val Loss: 0.3698\n",
      "Baseline Loss: 2.6788 | Actual Loss: 0.3339\n",
      "Baseline Loss: 2.6831 | Actual Loss: 0.6150\n",
      "Baseline Loss: 2.7311 | Actual Loss: 0.1801\n",
      "Baseline Loss: 2.7192 | Actual Loss: 0.3588\n",
      "Baseline Loss: 2.6738 | Actual Loss: 0.3193\n",
      "Baseline Loss: 2.6661 | Actual Loss: 0.1951\n",
      "Baseline Loss: 2.6459 | Actual Loss: 0.3121\n",
      "Baseline Loss: 2.6517 | Actual Loss: 0.5112\n",
      "Baseline Loss: 2.6659 | Actual Loss: 0.2480\n",
      "Baseline Loss: 2.6521 | Actual Loss: 0.7903\n",
      "Baseline Loss: 2.6730 | Actual Loss: 0.3886\n",
      "Baseline Loss: 2.7139 | Actual Loss: 0.4519\n",
      "Baseline Loss: 2.6279 | Actual Loss: 0.3013\n",
      "Baseline Loss: 2.7161 | Actual Loss: 0.2739\n",
      "Baseline Loss: 2.6592 | Actual Loss: 0.2974\n",
      "Baseline Loss: 2.2588 | Actual Loss: 0.0953\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4911\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5699\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 168/1000 [01:46<08:51,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6128 | Actual Loss: 0.2751\n",
      "Epoch 168/1000: Train Loss: 0.3545, Val Loss: 0.4005\n",
      "Baseline Loss: 2.6423 | Actual Loss: 0.5207\n",
      "Baseline Loss: 2.6711 | Actual Loss: 0.3716\n",
      "Baseline Loss: 2.6799 | Actual Loss: 0.1577\n",
      "Baseline Loss: 2.7098 | Actual Loss: 0.3383\n",
      "Baseline Loss: 2.6871 | Actual Loss: 0.3511\n",
      "Baseline Loss: 2.6729 | Actual Loss: 0.3384\n",
      "Baseline Loss: 2.6606 | Actual Loss: 0.2673\n",
      "Baseline Loss: 2.7161 | Actual Loss: 0.3427\n",
      "Baseline Loss: 2.6745 | Actual Loss: 0.2461\n",
      "Baseline Loss: 2.6747 | Actual Loss: 0.2901\n",
      "Baseline Loss: 2.6841 | Actual Loss: 0.5909\n",
      "Baseline Loss: 2.6616 | Actual Loss: 0.1804\n",
      "Baseline Loss: 2.6471 | Actual Loss: 0.4548\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3063\n",
      "Baseline Loss: 2.6571 | Actual Loss: 0.5169\n",
      "Baseline Loss: 2.2224 | Actual Loss: 0.3040\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.7236\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5661\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 169/1000 [01:47<08:50,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6128 | Actual Loss: 0.2264\n",
      "Epoch 169/1000: Train Loss: 0.3486, Val Loss: 0.4438\n",
      "Baseline Loss: 2.6806 | Actual Loss: 0.4225\n",
      "Baseline Loss: 2.7098 | Actual Loss: 0.6894\n",
      "Baseline Loss: 2.6724 | Actual Loss: 0.1916\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4154\n",
      "Baseline Loss: 2.6603 | Actual Loss: 0.5270\n",
      "Baseline Loss: 2.6574 | Actual Loss: 0.1897\n",
      "Baseline Loss: 2.7016 | Actual Loss: 0.4039\n",
      "Baseline Loss: 2.6800 | Actual Loss: 0.5954\n",
      "Baseline Loss: 2.7073 | Actual Loss: 0.3345\n",
      "Baseline Loss: 2.6608 | Actual Loss: 0.5176\n",
      "Baseline Loss: 2.6579 | Actual Loss: 0.4155\n",
      "Baseline Loss: 2.6768 | Actual Loss: 0.2869\n",
      "Baseline Loss: 2.6442 | Actual Loss: 0.7846\n",
      "Baseline Loss: 2.6694 | Actual Loss: 0.3731\n",
      "Baseline Loss: 2.6764 | Actual Loss: 0.2075\n",
      "Baseline Loss: 2.3236 | Actual Loss: 1.2287\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5573\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 170/1000 [01:47<09:00,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6853 | Actual Loss: 0.2411\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3955\n",
      "Epoch 170/1000: Train Loss: 0.4740, Val Loss: 0.4343\n",
      "Baseline Loss: 2.6786 | Actual Loss: 0.2928\n",
      "Baseline Loss: 2.6500 | Actual Loss: 0.2332\n",
      "Baseline Loss: 2.6592 | Actual Loss: 0.6711\n",
      "Baseline Loss: 2.6756 | Actual Loss: 0.9147\n",
      "Baseline Loss: 2.6871 | Actual Loss: 0.4786\n",
      "Baseline Loss: 2.6805 | Actual Loss: 0.4053\n",
      "Baseline Loss: 2.6603 | Actual Loss: 0.2158\n",
      "Baseline Loss: 2.6750 | Actual Loss: 0.3750\n",
      "Baseline Loss: 2.6524 | Actual Loss: 0.4368\n",
      "Baseline Loss: 2.6681 | Actual Loss: 0.2272\n",
      "Baseline Loss: 2.6893 | Actual Loss: 0.2242\n",
      "Baseline Loss: 2.6692 | Actual Loss: 0.3498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 171/1000 [01:48<08:38,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6460 | Actual Loss: 0.4173\n",
      "Baseline Loss: 2.6607 | Actual Loss: 0.2520\n",
      "Baseline Loss: 2.6759 | Actual Loss: 0.3686\n",
      "Baseline Loss: 2.3579 | Actual Loss: 1.3283\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.3856\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.4795\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2370\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3936\n",
      "Epoch 171/1000: Train Loss: 0.4494, Val Loss: 0.3739\n",
      "Baseline Loss: 2.6882 | Actual Loss: 0.3842\n",
      "Baseline Loss: 2.6886 | Actual Loss: 0.6546\n",
      "Baseline Loss: 2.6974 | Actual Loss: 0.2884\n",
      "Baseline Loss: 2.6926 | Actual Loss: 0.1555\n",
      "Baseline Loss: 2.6458 | Actual Loss: 0.5794\n",
      "Baseline Loss: 2.6730 | Actual Loss: 0.9203\n",
      "Baseline Loss: 2.6425 | Actual Loss: 0.3472\n",
      "Baseline Loss: 2.6692 | Actual Loss: 0.5019\n",
      "Baseline Loss: 2.7108 | Actual Loss: 0.3171\n",
      "Baseline Loss: 2.6314 | Actual Loss: 0.4102\n",
      "Baseline Loss: 2.6620 | Actual Loss: 0.2901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 172/1000 [01:48<08:38,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6619 | Actual Loss: 0.1859\n",
      "Baseline Loss: 2.6582 | Actual Loss: 0.3175\n",
      "Baseline Loss: 2.6815 | Actual Loss: 0.1429\n",
      "Baseline Loss: 2.6473 | Actual Loss: 0.3900\n",
      "Baseline Loss: 2.3351 | Actual Loss: 0.1888\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.6892\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5169\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2226\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3402\n",
      "Epoch 172/1000: Train Loss: 0.3796, Val Loss: 0.4422\n",
      "Baseline Loss: 2.6877 | Actual Loss: 0.4805\n",
      "Baseline Loss: 2.6547 | Actual Loss: 1.2898\n",
      "Baseline Loss: 2.6489 | Actual Loss: 0.3035\n",
      "Baseline Loss: 2.6774 | Actual Loss: 0.1640\n",
      "Baseline Loss: 2.7064 | Actual Loss: 0.6384\n",
      "Baseline Loss: 2.6455 | Actual Loss: 0.3988\n",
      "Baseline Loss: 2.6860 | Actual Loss: 0.4890\n",
      "Baseline Loss: 2.7440 | Actual Loss: 0.3139\n",
      "Baseline Loss: 2.6782 | Actual Loss: 0.3025\n",
      "Baseline Loss: 2.6675 | Actual Loss: 0.4076\n",
      "Baseline Loss: 2.6427 | Actual Loss: 0.3759\n",
      "Baseline Loss: 2.6734 | Actual Loss: 0.1557\n",
      "Baseline Loss: 2.6909 | Actual Loss: 0.2318\n",
      "Baseline Loss: 2.6539 | Actual Loss: 0.4685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 173/1000 [01:49<08:33,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6857 | Actual Loss: 0.3705\n",
      "Baseline Loss: 2.1984 | Actual Loss: 0.1824\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.3693\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6684\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2251\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3478\n",
      "Epoch 173/1000: Train Loss: 0.4108, Val Loss: 0.4027\n",
      "Baseline Loss: 2.6643 | Actual Loss: 0.2123\n",
      "Baseline Loss: 2.6283 | Actual Loss: 0.3292\n",
      "Baseline Loss: 2.6137 | Actual Loss: 0.2187\n",
      "Baseline Loss: 2.6932 | Actual Loss: 0.5079\n",
      "Baseline Loss: 2.7141 | Actual Loss: 0.2338\n",
      "Baseline Loss: 2.6475 | Actual Loss: 0.4541\n",
      "Baseline Loss: 2.6334 | Actual Loss: 0.4826\n",
      "Baseline Loss: 2.6703 | Actual Loss: 0.5429\n",
      "Baseline Loss: 2.7125 | Actual Loss: 0.3055\n",
      "Baseline Loss: 2.6424 | Actual Loss: 0.3205\n",
      "Baseline Loss: 2.6486 | Actual Loss: 0.3401\n",
      "Baseline Loss: 2.6729 | Actual Loss: 0.2016\n",
      "Baseline Loss: 2.7136 | Actual Loss: 0.1652\n",
      "Baseline Loss: 2.7294 | Actual Loss: 0.4796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 174/1000 [01:50<08:40,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7201 | Actual Loss: 0.3579\n",
      "Baseline Loss: 2.3137 | Actual Loss: 0.1532\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4144\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5898\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2269\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2595\n",
      "Epoch 174/1000: Train Loss: 0.3316, Val Loss: 0.3727\n",
      "Baseline Loss: 2.6670 | Actual Loss: 0.3178\n",
      "Baseline Loss: 2.6676 | Actual Loss: 0.2730\n",
      "Baseline Loss: 2.6925 | Actual Loss: 0.2099\n",
      "Baseline Loss: 2.6454 | Actual Loss: 0.2652\n",
      "Baseline Loss: 2.7517 | Actual Loss: 0.3884\n",
      "Baseline Loss: 2.7072 | Actual Loss: 0.3088\n",
      "Baseline Loss: 2.6678 | Actual Loss: 0.2882\n",
      "Baseline Loss: 2.6572 | Actual Loss: 0.1700\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3388\n",
      "Baseline Loss: 2.6629 | Actual Loss: 0.4115\n",
      "Baseline Loss: 2.6813 | Actual Loss: 0.2113\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.2736\n",
      "Baseline Loss: 2.6373 | Actual Loss: 0.2253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 175/1000 [01:50<08:54,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6948 | Actual Loss: 0.8095\n",
      "Baseline Loss: 2.6519 | Actual Loss: 0.4690\n",
      "Baseline Loss: 2.2429 | Actual Loss: 0.1554\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5552\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6757\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2432\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2297\n",
      "Epoch 175/1000: Train Loss: 0.3197, Val Loss: 0.4259\n",
      "Baseline Loss: 2.6952 | Actual Loss: 0.3166\n",
      "Baseline Loss: 2.6419 | Actual Loss: 0.8154\n",
      "Baseline Loss: 2.6777 | Actual Loss: 0.3285\n",
      "Baseline Loss: 2.6784 | Actual Loss: 0.4175\n",
      "Baseline Loss: 2.6597 | Actual Loss: 0.4942\n",
      "Baseline Loss: 2.6991 | Actual Loss: 0.2531\n",
      "Baseline Loss: 2.6791 | Actual Loss: 0.2678\n",
      "Baseline Loss: 2.6946 | Actual Loss: 0.5101\n",
      "Baseline Loss: 2.6808 | Actual Loss: 0.2502\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2606\n",
      "Baseline Loss: 2.6824 | Actual Loss: 0.3531\n",
      "Baseline Loss: 2.6696 | Actual Loss: 0.2719\n",
      "Baseline Loss: 2.6526 | Actual Loss: 0.4394\n",
      "Baseline Loss: 2.6414 | Actual Loss: 0.2542\n",
      "Baseline Loss: 2.6391 | Actual Loss: 0.2694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 176/1000 [01:51<08:32,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2821 | Actual Loss: 0.3181\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4836\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.7016\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.1989\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3623\n",
      "Epoch 176/1000: Train Loss: 0.3638, Val Loss: 0.4366\n",
      "Baseline Loss: 2.7077 | Actual Loss: 0.5091\n",
      "Baseline Loss: 2.6681 | Actual Loss: 0.1712\n",
      "Baseline Loss: 2.6650 | Actual Loss: 0.4175\n",
      "Baseline Loss: 2.6275 | Actual Loss: 0.2009\n",
      "Baseline Loss: 2.6737 | Actual Loss: 0.2531\n",
      "Baseline Loss: 2.6895 | Actual Loss: 0.4200\n",
      "Baseline Loss: 2.6679 | Actual Loss: 0.2329\n",
      "Baseline Loss: 2.6752 | Actual Loss: 0.4466\n",
      "Baseline Loss: 2.6768 | Actual Loss: 0.2550\n",
      "Baseline Loss: 2.7057 | Actual Loss: 0.2784\n",
      "Baseline Loss: 2.6816 | Actual Loss: 0.5223\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.4326\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.2969\n",
      "Baseline Loss: 2.6773 | Actual Loss: 0.1897\n",
      "Baseline Loss: 2.6660 | Actual Loss: 0.3983\n",
      "Baseline Loss: 2.2596 | Actual Loss: 0.1654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 177/1000 [01:52<08:35,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6755 | Actual Loss: 0.5920\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.7608\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2139\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3692\n",
      "Epoch 177/1000: Train Loss: 0.3244, Val Loss: 0.4839\n",
      "Baseline Loss: 2.6823 | Actual Loss: 0.1970\n",
      "Baseline Loss: 2.6851 | Actual Loss: 1.7067\n",
      "Baseline Loss: 2.6867 | Actual Loss: 0.4089\n",
      "Baseline Loss: 2.6290 | Actual Loss: 0.5496\n",
      "Baseline Loss: 2.6838 | Actual Loss: 0.2474\n",
      "Baseline Loss: 2.6522 | Actual Loss: 0.1499\n",
      "Baseline Loss: 2.6593 | Actual Loss: 0.3441\n",
      "Baseline Loss: 2.7022 | Actual Loss: 0.3179\n",
      "Baseline Loss: 2.6584 | Actual Loss: 0.2846\n",
      "Baseline Loss: 2.6491 | Actual Loss: 0.2765\n",
      "Baseline Loss: 2.6697 | Actual Loss: 0.2768\n",
      "Baseline Loss: 2.7111 | Actual Loss: 0.3861\n",
      "Baseline Loss: 2.6588 | Actual Loss: 0.2449\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.1239\n",
      "Baseline Loss: 2.6694 | Actual Loss: 0.5474\n",
      "Baseline Loss: 2.3880 | Actual Loss: 1.9458\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 178/1000 [01:52<08:30,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6640 | Actual Loss: 0.5873\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.1974\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2791\n",
      "Epoch 178/1000: Train Loss: 0.5005, Val Loss: 0.3907\n",
      "Baseline Loss: 2.6753 | Actual Loss: 0.5946\n",
      "Baseline Loss: 2.6458 | Actual Loss: 0.2460\n",
      "Baseline Loss: 2.6927 | Actual Loss: 0.2987\n",
      "Baseline Loss: 2.6509 | Actual Loss: 0.5296\n",
      "Baseline Loss: 2.7007 | Actual Loss: 0.4277\n",
      "Baseline Loss: 2.7019 | Actual Loss: 0.4464\n",
      "Baseline Loss: 2.6623 | Actual Loss: 0.2821\n",
      "Baseline Loss: 2.6879 | Actual Loss: 0.2702\n",
      "Baseline Loss: 2.6683 | Actual Loss: 0.5854\n",
      "Baseline Loss: 2.6954 | Actual Loss: 0.2604\n",
      "Baseline Loss: 2.6714 | Actual Loss: 0.3450\n",
      "Baseline Loss: 2.6582 | Actual Loss: 0.2560\n",
      "Baseline Loss: 2.6708 | Actual Loss: 0.3214\n",
      "Baseline Loss: 2.6750 | Actual Loss: 0.5104\n",
      "Baseline Loss: 2.6739 | Actual Loss: 0.2291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 179/1000 [01:53<08:39,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2625 | Actual Loss: 0.5068\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4725\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5868\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2398\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3377\n",
      "Epoch 179/1000: Train Loss: 0.3819, Val Loss: 0.4092\n",
      "Baseline Loss: 2.6617 | Actual Loss: 0.4249\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.1180\n",
      "Baseline Loss: 2.6892 | Actual Loss: 0.3987\n",
      "Baseline Loss: 2.6945 | Actual Loss: 0.1298\n",
      "Baseline Loss: 2.6630 | Actual Loss: 0.5399\n",
      "Baseline Loss: 2.6423 | Actual Loss: 0.4620\n",
      "Baseline Loss: 2.6689 | Actual Loss: 0.1266\n",
      "Baseline Loss: 2.6974 | Actual Loss: 0.1809\n",
      "Baseline Loss: 2.7019 | Actual Loss: 0.4341\n",
      "Baseline Loss: 2.6529 | Actual Loss: 0.2030\n",
      "Baseline Loss: 2.6960 | Actual Loss: 0.1975\n",
      "Baseline Loss: 2.7163 | Actual Loss: 0.2362\n",
      "Baseline Loss: 2.6463 | Actual Loss: 0.3537\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4378\n",
      "Baseline Loss: 2.6804 | Actual Loss: 0.2094\n",
      "Baseline Loss: 2.2278 | Actual Loss: 0.1831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 180/1000 [01:53<08:39,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6755 | Actual Loss: 0.4531\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6057\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.1995\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2578\n",
      "Epoch 180/1000: Train Loss: 0.2897, Val Loss: 0.3790\n",
      "Baseline Loss: 2.7076 | Actual Loss: 0.3539\n",
      "Baseline Loss: 2.6649 | Actual Loss: 0.2947\n",
      "Baseline Loss: 2.6584 | Actual Loss: 0.2843\n",
      "Baseline Loss: 2.6800 | Actual Loss: 0.2565\n",
      "Baseline Loss: 2.6827 | Actual Loss: 0.2870\n",
      "Baseline Loss: 2.6625 | Actual Loss: 0.2448\n",
      "Baseline Loss: 2.7006 | Actual Loss: 0.2580\n",
      "Baseline Loss: 2.6898 | Actual Loss: 0.3212\n",
      "Baseline Loss: 2.6709 | Actual Loss: 0.5439\n",
      "Baseline Loss: 2.6303 | Actual Loss: 0.1270\n",
      "Baseline Loss: 2.6575 | Actual Loss: 0.4325\n",
      "Baseline Loss: 2.6354 | Actual Loss: 0.3730\n",
      "Baseline Loss: 2.6828 | Actual Loss: 0.4717\n",
      "Baseline Loss: 2.6649 | Actual Loss: 0.1666\n",
      "Baseline Loss: 2.6521 | Actual Loss: 0.2567\n",
      "Baseline Loss: 2.2634 | Actual Loss: 0.2034\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.3679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 181/1000 [01:54<08:52,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6640 | Actual Loss: 0.5756\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.1969\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3862\n",
      "Epoch 181/1000: Train Loss: 0.3047, Val Loss: 0.3816\n",
      "Baseline Loss: 2.6653 | Actual Loss: 0.3541\n",
      "Baseline Loss: 2.6927 | Actual Loss: 0.4433\n",
      "Baseline Loss: 2.6772 | Actual Loss: 0.4374\n",
      "Baseline Loss: 2.6616 | Actual Loss: 0.3966\n",
      "Baseline Loss: 2.6642 | Actual Loss: 0.1900\n",
      "Baseline Loss: 2.6817 | Actual Loss: 1.2077\n",
      "Baseline Loss: 2.6930 | Actual Loss: 0.1855\n",
      "Baseline Loss: 2.7332 | Actual Loss: 0.4808\n",
      "Baseline Loss: 2.6854 | Actual Loss: 0.6025\n",
      "Baseline Loss: 2.6540 | Actual Loss: 0.3140\n",
      "Baseline Loss: 2.6441 | Actual Loss: 0.3011\n",
      "Baseline Loss: 2.6709 | Actual Loss: 0.2801\n",
      "Baseline Loss: 2.6541 | Actual Loss: 0.3492\n",
      "Baseline Loss: 2.6697 | Actual Loss: 0.4446\n",
      "Baseline Loss: 2.6848 | Actual Loss: 0.3871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 182/1000 [01:55<08:36,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.3454 | Actual Loss: 0.2209\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.7384\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.7336\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2414\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3077\n",
      "Epoch 182/1000: Train Loss: 0.4122, Val Loss: 0.5053\n",
      "Baseline Loss: 2.6497 | Actual Loss: 0.9733\n",
      "Baseline Loss: 2.6729 | Actual Loss: 0.3560\n",
      "Baseline Loss: 2.6792 | Actual Loss: 1.9345\n",
      "Baseline Loss: 2.7172 | Actual Loss: 0.2964\n",
      "Baseline Loss: 2.6782 | Actual Loss: 0.2294\n",
      "Baseline Loss: 2.6488 | Actual Loss: 0.4609\n",
      "Baseline Loss: 2.6920 | Actual Loss: 0.4475\n",
      "Baseline Loss: 2.6878 | Actual Loss: 0.5841\n",
      "Baseline Loss: 2.6463 | Actual Loss: 0.2418\n",
      "Baseline Loss: 2.6481 | Actual Loss: 0.2241\n",
      "Baseline Loss: 2.6704 | Actual Loss: 0.3994\n",
      "Baseline Loss: 2.7040 | Actual Loss: 0.3184\n",
      "Baseline Loss: 2.6728 | Actual Loss: 0.3292\n",
      "Baseline Loss: 2.6504 | Actual Loss: 0.2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 183/1000 [01:55<08:50,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6643 | Actual Loss: 0.2518\n",
      "Baseline Loss: 2.3208 | Actual Loss: 0.1170\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5664\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5249\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2395\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3947\n",
      "Epoch 183/1000: Train Loss: 0.4604, Val Loss: 0.4314\n",
      "Baseline Loss: 2.6752 | Actual Loss: 0.2845\n",
      "Baseline Loss: 2.6506 | Actual Loss: 0.3365\n",
      "Baseline Loss: 2.7004 | Actual Loss: 0.6332\n",
      "Baseline Loss: 2.6715 | Actual Loss: 0.2827\n",
      "Baseline Loss: 2.6942 | Actual Loss: 0.2690\n",
      "Baseline Loss: 2.6516 | Actual Loss: 0.5187\n",
      "Baseline Loss: 2.6874 | Actual Loss: 0.4845\n",
      "Baseline Loss: 2.6701 | Actual Loss: 2.2247\n",
      "Baseline Loss: 2.6319 | Actual Loss: 0.2374\n",
      "Baseline Loss: 2.6858 | Actual Loss: 0.2232\n",
      "Baseline Loss: 2.6826 | Actual Loss: 0.2648\n",
      "Baseline Loss: 2.6406 | Actual Loss: 0.4729\n",
      "Baseline Loss: 2.7081 | Actual Loss: 0.4670\n",
      "Baseline Loss: 2.7002 | Actual Loss: 0.3935\n",
      "Baseline Loss: 2.6746 | Actual Loss: 0.3400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 184/1000 [01:56<08:50,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.3341 | Actual Loss: 1.7231\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4331\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5048\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2142\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3222\n",
      "Epoch 184/1000: Train Loss: 0.5722, Val Loss: 0.3686\n",
      "Baseline Loss: 2.6826 | Actual Loss: 0.3759\n",
      "Baseline Loss: 2.6743 | Actual Loss: 0.3300\n",
      "Baseline Loss: 2.6753 | Actual Loss: 0.1508\n",
      "Baseline Loss: 2.6737 | Actual Loss: 0.5814\n",
      "Baseline Loss: 2.6688 | Actual Loss: 0.1579\n",
      "Baseline Loss: 2.6776 | Actual Loss: 0.3717\n",
      "Baseline Loss: 2.6658 | Actual Loss: 0.2222\n",
      "Baseline Loss: 2.6524 | Actual Loss: 0.4586\n",
      "Baseline Loss: 2.6580 | Actual Loss: 0.3737\n",
      "Baseline Loss: 2.6585 | Actual Loss: 0.8618\n",
      "Baseline Loss: 2.6979 | Actual Loss: 0.3324\n",
      "Baseline Loss: 2.6874 | Actual Loss: 0.4874\n",
      "Baseline Loss: 2.6818 | Actual Loss: 0.3780\n",
      "Baseline Loss: 2.7064 | Actual Loss: 0.4102\n",
      "Baseline Loss: 2.6535 | Actual Loss: 0.3347\n",
      "Baseline Loss: 2.2853 | Actual Loss: 0.3054\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4610\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 185/1000 [01:57<08:39,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6853 | Actual Loss: 0.1966\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2970\n",
      "Epoch 185/1000: Train Loss: 0.3833, Val Loss: 0.3818\n",
      "Baseline Loss: 2.6544 | Actual Loss: 0.4592\n",
      "Baseline Loss: 2.6690 | Actual Loss: 0.1848\n",
      "Baseline Loss: 2.6812 | Actual Loss: 1.3083\n",
      "Baseline Loss: 2.6835 | Actual Loss: 0.4268\n",
      "Baseline Loss: 2.6980 | Actual Loss: 0.2552\n",
      "Baseline Loss: 2.6560 | Actual Loss: 0.3830\n",
      "Baseline Loss: 2.6496 | Actual Loss: 0.1112\n",
      "Baseline Loss: 2.6824 | Actual Loss: 0.2964\n",
      "Baseline Loss: 2.6672 | Actual Loss: 0.2306\n",
      "Baseline Loss: 2.6850 | Actual Loss: 1.6176\n",
      "Baseline Loss: 2.6509 | Actual Loss: 0.5455\n",
      "Baseline Loss: 2.6752 | Actual Loss: 0.4228\n",
      "Baseline Loss: 2.6546 | Actual Loss: 0.3182\n",
      "Baseline Loss: 2.6899 | Actual Loss: 0.4119\n",
      "Baseline Loss: 2.6701 | Actual Loss: 0.2114\n",
      "Baseline Loss: 2.2649 | Actual Loss: 0.2179\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.6015\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▊        | 186/1000 [01:57<08:38,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6853 | Actual Loss: 0.2052\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3016\n",
      "Epoch 186/1000: Train Loss: 0.4626, Val Loss: 0.4056\n",
      "Baseline Loss: 2.6558 | Actual Loss: 0.3297\n",
      "Baseline Loss: 2.6830 | Actual Loss: 0.6108\n",
      "Baseline Loss: 2.7268 | Actual Loss: 0.1577\n",
      "Baseline Loss: 2.6746 | Actual Loss: 0.6921\n",
      "Baseline Loss: 2.6617 | Actual Loss: 0.3419\n",
      "Baseline Loss: 2.6615 | Actual Loss: 0.2928\n",
      "Baseline Loss: 2.6806 | Actual Loss: 0.5876\n",
      "Baseline Loss: 2.7153 | Actual Loss: 0.3704\n",
      "Baseline Loss: 2.6773 | Actual Loss: 0.3606\n",
      "Baseline Loss: 2.6850 | Actual Loss: 0.7356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▊        | 187/1000 [01:58<08:36,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6914 | Actual Loss: 0.2208\n",
      "Baseline Loss: 2.6912 | Actual Loss: 0.1325\n",
      "Baseline Loss: 2.6327 | Actual Loss: 0.2355\n",
      "Baseline Loss: 2.6887 | Actual Loss: 0.2546\n",
      "Baseline Loss: 2.6555 | Actual Loss: 0.2857\n",
      "Baseline Loss: 2.2803 | Actual Loss: 2.1244\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.3897\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5426\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2183\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3770\n",
      "Epoch 187/1000: Train Loss: 0.4833, Val Loss: 0.3819\n",
      "Baseline Loss: 2.7217 | Actual Loss: 0.1590\n",
      "Baseline Loss: 2.7081 | Actual Loss: 0.4360\n",
      "Baseline Loss: 2.6817 | Actual Loss: 0.3759\n",
      "Baseline Loss: 2.6738 | Actual Loss: 0.2831\n",
      "Baseline Loss: 2.6660 | Actual Loss: 0.5152\n",
      "Baseline Loss: 2.6903 | Actual Loss: 0.3896\n",
      "Baseline Loss: 2.6846 | Actual Loss: 0.4593\n",
      "Baseline Loss: 2.6557 | Actual Loss: 0.6392\n",
      "Baseline Loss: 2.6786 | Actual Loss: 0.1626\n",
      "Baseline Loss: 2.6790 | Actual Loss: 0.2262\n",
      "Baseline Loss: 2.6591 | Actual Loss: 0.2203\n",
      "Baseline Loss: 2.6915 | Actual Loss: 0.5791\n",
      "Baseline Loss: 2.6698 | Actual Loss: 0.2450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 188/1000 [01:59<08:29,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6482 | Actual Loss: 0.1485\n",
      "Baseline Loss: 2.6538 | Actual Loss: 0.2594\n",
      "Baseline Loss: 2.2817 | Actual Loss: 1.7220\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5079\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5974\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2362\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.1966\n",
      "Epoch 188/1000: Train Loss: 0.4263, Val Loss: 0.3845\n",
      "Baseline Loss: 2.6670 | Actual Loss: 0.4618\n",
      "Baseline Loss: 2.6915 | Actual Loss: 0.4117\n",
      "Baseline Loss: 2.6509 | Actual Loss: 0.6046\n",
      "Baseline Loss: 2.6956 | Actual Loss: 0.1877\n",
      "Baseline Loss: 2.6605 | Actual Loss: 0.2599\n",
      "Baseline Loss: 2.6925 | Actual Loss: 0.2556\n",
      "Baseline Loss: 2.6605 | Actual Loss: 0.1898\n",
      "Baseline Loss: 2.6762 | Actual Loss: 0.4200\n",
      "Baseline Loss: 2.6871 | Actual Loss: 0.3493\n",
      "Baseline Loss: 2.6736 | Actual Loss: 0.3180\n",
      "Baseline Loss: 2.6616 | Actual Loss: 0.3455\n",
      "Baseline Loss: 2.6650 | Actual Loss: 0.1506\n",
      "Baseline Loss: 2.6485 | Actual Loss: 0.1613\n",
      "Baseline Loss: 2.6348 | Actual Loss: 0.2951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 189/1000 [01:59<08:34,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7401 | Actual Loss: 0.6707\n",
      "Baseline Loss: 2.2653 | Actual Loss: 0.0944\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5536\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6547\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2152\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2473\n",
      "Epoch 189/1000: Train Loss: 0.3235, Val Loss: 0.4177\n",
      "Baseline Loss: 2.6307 | Actual Loss: 0.4328\n",
      "Baseline Loss: 2.6653 | Actual Loss: 0.4719\n",
      "Baseline Loss: 2.6626 | Actual Loss: 0.5641\n",
      "Baseline Loss: 2.6702 | Actual Loss: 0.3397\n",
      "Baseline Loss: 2.6740 | Actual Loss: 0.2878\n",
      "Baseline Loss: 2.6627 | Actual Loss: 0.3125\n",
      "Baseline Loss: 2.7167 | Actual Loss: 0.1620\n",
      "Baseline Loss: 2.6960 | Actual Loss: 0.2636\n",
      "Baseline Loss: 2.6500 | Actual Loss: 0.1467\n",
      "Baseline Loss: 2.7046 | Actual Loss: 0.1887\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.2601\n",
      "Baseline Loss: 2.6472 | Actual Loss: 0.5301\n",
      "Baseline Loss: 2.6750 | Actual Loss: 0.3445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 190/1000 [02:00<08:33,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6993 | Actual Loss: 0.2322\n",
      "Baseline Loss: 2.6694 | Actual Loss: 0.3116\n",
      "Baseline Loss: 2.2754 | Actual Loss: 0.4134\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4925\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.4940\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.1898\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3901\n",
      "Epoch 190/1000: Train Loss: 0.3289, Val Loss: 0.3916\n",
      "Baseline Loss: 2.6725 | Actual Loss: 0.3810\n",
      "Baseline Loss: 2.7038 | Actual Loss: 0.1539\n",
      "Baseline Loss: 2.6713 | Actual Loss: 0.2969\n",
      "Baseline Loss: 2.6504 | Actual Loss: 0.2930\n",
      "Baseline Loss: 2.6689 | Actual Loss: 0.3901\n",
      "Baseline Loss: 2.7025 | Actual Loss: 0.2661\n",
      "Baseline Loss: 2.6637 | Actual Loss: 0.1803\n",
      "Baseline Loss: 2.6354 | Actual Loss: 0.2683\n",
      "Baseline Loss: 2.7398 | Actual Loss: 0.2013\n",
      "Baseline Loss: 2.6429 | Actual Loss: 0.4495\n",
      "Baseline Loss: 2.6707 | Actual Loss: 0.3199\n",
      "Baseline Loss: 2.6936 | Actual Loss: 0.3769\n",
      "Baseline Loss: 2.6468 | Actual Loss: 0.2905\n",
      "Baseline Loss: 2.6874 | Actual Loss: 0.2256\n",
      "Baseline Loss: 2.6813 | Actual Loss: 1.5106\n",
      "Baseline Loss: 2.2470 | Actual Loss: 0.2076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 191/1000 [02:00<08:24,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6755 | Actual Loss: 0.7533\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5496\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.3030\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2335\n",
      "Epoch 191/1000: Train Loss: 0.3632, Val Loss: 0.4599\n",
      "Baseline Loss: 2.6781 | Actual Loss: 0.3495\n",
      "Baseline Loss: 2.7060 | Actual Loss: 0.3673\n",
      "Baseline Loss: 2.6506 | Actual Loss: 0.4143\n",
      "Baseline Loss: 2.6650 | Actual Loss: 0.3200\n",
      "Baseline Loss: 2.6849 | Actual Loss: 0.1282\n",
      "Baseline Loss: 2.6905 | Actual Loss: 0.2012\n",
      "Baseline Loss: 2.6481 | Actual Loss: 0.2265\n",
      "Baseline Loss: 2.6606 | Actual Loss: 0.2272\n",
      "Baseline Loss: 2.6766 | Actual Loss: 1.8464\n",
      "Baseline Loss: 2.6710 | Actual Loss: 0.5112\n",
      "Baseline Loss: 2.7215 | Actual Loss: 0.3815\n",
      "Baseline Loss: 2.6761 | Actual Loss: 0.4761\n",
      "Baseline Loss: 2.6559 | Actual Loss: 0.5144\n",
      "Baseline Loss: 2.6759 | Actual Loss: 0.1960\n",
      "Baseline Loss: 2.6810 | Actual Loss: 0.4286\n",
      "Baseline Loss: 2.2379 | Actual Loss: 1.4701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 192/1000 [02:01<08:27,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6755 | Actual Loss: 0.4230\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5919\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2327\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2170\n",
      "Epoch 192/1000: Train Loss: 0.5037, Val Loss: 0.3662\n",
      "Baseline Loss: 2.6742 | Actual Loss: 0.4932\n",
      "Baseline Loss: 2.6815 | Actual Loss: 0.2053\n",
      "Baseline Loss: 2.6638 | Actual Loss: 0.2072\n",
      "Baseline Loss: 2.6981 | Actual Loss: 0.2511\n",
      "Baseline Loss: 2.6689 | Actual Loss: 0.4557\n",
      "Baseline Loss: 2.6419 | Actual Loss: 0.7578\n",
      "Baseline Loss: 2.6661 | Actual Loss: 0.3035\n",
      "Baseline Loss: 2.6991 | Actual Loss: 0.4044\n",
      "Baseline Loss: 2.6909 | Actual Loss: 0.3358\n",
      "Baseline Loss: 2.6719 | Actual Loss: 0.3330\n",
      "Baseline Loss: 2.7048 | Actual Loss: 0.5274\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2262\n",
      "Baseline Loss: 2.6563 | Actual Loss: 0.2086\n",
      "Baseline Loss: 2.6772 | Actual Loss: 0.1582\n",
      "Baseline Loss: 2.6541 | Actual Loss: 0.3073\n",
      "Baseline Loss: 2.2246 | Actual Loss: 0.1530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 193/1000 [02:02<08:22,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6755 | Actual Loss: 0.5372\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6061\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.1928\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3242\n",
      "Epoch 193/1000: Train Loss: 0.3330, Val Loss: 0.4151\n",
      "Baseline Loss: 2.6406 | Actual Loss: 0.2102\n",
      "Baseline Loss: 2.6488 | Actual Loss: 0.2827\n",
      "Baseline Loss: 2.6795 | Actual Loss: 0.1819\n",
      "Baseline Loss: 2.6755 | Actual Loss: 1.6394\n",
      "Baseline Loss: 2.6669 | Actual Loss: 0.2744\n",
      "Baseline Loss: 2.6440 | Actual Loss: 0.5695\n",
      "Baseline Loss: 2.7175 | Actual Loss: 0.2960\n",
      "Baseline Loss: 2.6725 | Actual Loss: 0.2061\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.3532\n",
      "Baseline Loss: 2.6324 | Actual Loss: 0.1827\n",
      "Baseline Loss: 2.6627 | Actual Loss: 0.5454\n",
      "Baseline Loss: 2.7092 | Actual Loss: 0.3200\n",
      "Baseline Loss: 2.6690 | Actual Loss: 0.4630\n",
      "Baseline Loss: 2.6926 | Actual Loss: 0.2431\n",
      "Baseline Loss: 2.6841 | Actual Loss: 0.2331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 194/1000 [02:02<08:32,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2111 | Actual Loss: 0.1247\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4731\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6451\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2285\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3047\n",
      "Epoch 194/1000: Train Loss: 0.3828, Val Loss: 0.4128\n",
      "Baseline Loss: 2.6976 | Actual Loss: 0.6552\n",
      "Baseline Loss: 2.7144 | Actual Loss: 0.4680\n",
      "Baseline Loss: 2.6882 | Actual Loss: 0.3315\n",
      "Baseline Loss: 2.6375 | Actual Loss: 0.4172\n",
      "Baseline Loss: 2.6615 | Actual Loss: 0.3075\n",
      "Baseline Loss: 2.6605 | Actual Loss: 0.6440\n",
      "Baseline Loss: 2.6623 | Actual Loss: 0.4702\n",
      "Baseline Loss: 2.6573 | Actual Loss: 0.1332\n",
      "Baseline Loss: 2.6985 | Actual Loss: 0.5985\n",
      "Baseline Loss: 2.6463 | Actual Loss: 0.2271\n",
      "Baseline Loss: 2.6626 | Actual Loss: 0.2880\n",
      "Baseline Loss: 2.6426 | Actual Loss: 0.3306\n",
      "Baseline Loss: 2.6880 | Actual Loss: 0.3068\n",
      "Baseline Loss: 2.6883 | Actual Loss: 0.5822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 195/1000 [02:03<08:41,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6941 | Actual Loss: 0.3769\n",
      "Baseline Loss: 2.2871 | Actual Loss: 0.1913\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4401\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6811\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2271\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2191\n",
      "Epoch 195/1000: Train Loss: 0.3955, Val Loss: 0.3918\n",
      "Baseline Loss: 2.6215 | Actual Loss: 0.1366\n",
      "Baseline Loss: 2.6957 | Actual Loss: 0.4086\n",
      "Baseline Loss: 2.6783 | Actual Loss: 0.4338\n",
      "Baseline Loss: 2.7047 | Actual Loss: 0.2640\n",
      "Baseline Loss: 2.6847 | Actual Loss: 0.3302\n",
      "Baseline Loss: 2.6501 | Actual Loss: 0.3123\n",
      "Baseline Loss: 2.6669 | Actual Loss: 0.3153\n",
      "Baseline Loss: 2.6626 | Actual Loss: 0.4069\n",
      "Baseline Loss: 2.6848 | Actual Loss: 0.7861\n",
      "Baseline Loss: 2.6544 | Actual Loss: 0.3338\n",
      "Baseline Loss: 2.6737 | Actual Loss: 0.5429\n",
      "Baseline Loss: 2.6544 | Actual Loss: 0.3787\n",
      "Baseline Loss: 2.6906 | Actual Loss: 0.3575\n",
      "Baseline Loss: 2.6623 | Actual Loss: 0.4191\n",
      "Baseline Loss: 2.6803 | Actual Loss: 0.5239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 196/1000 [02:04<08:32,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2555 | Actual Loss: 0.6587\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.7333\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5920\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.1804\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2030\n",
      "Epoch 196/1000: Train Loss: 0.4130, Val Loss: 0.4272\n",
      "Baseline Loss: 2.6708 | Actual Loss: 0.1648\n",
      "Baseline Loss: 2.6719 | Actual Loss: 0.4669\n",
      "Baseline Loss: 2.7041 | Actual Loss: 0.2705\n",
      "Baseline Loss: 2.6525 | Actual Loss: 0.3303\n",
      "Baseline Loss: 2.7021 | Actual Loss: 1.0093\n",
      "Baseline Loss: 2.6756 | Actual Loss: 0.1727\n",
      "Baseline Loss: 2.6436 | Actual Loss: 0.2582\n",
      "Baseline Loss: 2.6831 | Actual Loss: 0.2475\n",
      "Baseline Loss: 2.6447 | Actual Loss: 0.2906\n",
      "Baseline Loss: 2.6884 | Actual Loss: 0.1828\n",
      "Baseline Loss: 2.6551 | Actual Loss: 0.1628\n",
      "Baseline Loss: 2.6736 | Actual Loss: 0.4310\n",
      "Baseline Loss: 2.6450 | Actual Loss: 0.3822\n",
      "Baseline Loss: 2.6445 | Actual Loss: 0.2967\n",
      "Baseline Loss: 2.6888 | Actual Loss: 0.3191\n",
      "Baseline Loss: 2.3291 | Actual Loss: 0.3236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 197/1000 [02:04<08:30,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6755 | Actual Loss: 0.4137\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5610\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2512\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3634\n",
      "Epoch 197/1000: Train Loss: 0.3318, Val Loss: 0.3973\n",
      "Baseline Loss: 2.7072 | Actual Loss: 0.4267\n",
      "Baseline Loss: 2.6545 | Actual Loss: 0.2341\n",
      "Baseline Loss: 2.6715 | Actual Loss: 0.0740\n",
      "Baseline Loss: 2.6536 | Actual Loss: 0.2000\n",
      "Baseline Loss: 2.6495 | Actual Loss: 0.3562\n",
      "Baseline Loss: 2.6447 | Actual Loss: 0.2343\n",
      "Baseline Loss: 2.7085 | Actual Loss: 0.1414\n",
      "Baseline Loss: 2.6599 | Actual Loss: 0.5283\n",
      "Baseline Loss: 2.6890 | Actual Loss: 0.4569\n",
      "Baseline Loss: 2.6686 | Actual Loss: 0.4488\n",
      "Baseline Loss: 2.6620 | Actual Loss: 0.2156\n",
      "Baseline Loss: 2.6603 | Actual Loss: 0.2693\n",
      "Baseline Loss: 2.6542 | Actual Loss: 0.5220\n",
      "Baseline Loss: 2.6800 | Actual Loss: 0.4678\n",
      "Baseline Loss: 2.6739 | Actual Loss: 0.3726\n",
      "Baseline Loss: 2.2470 | Actual Loss: 0.9038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 198/1000 [02:05<08:24,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6755 | Actual Loss: 0.5602\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5219\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2326\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3511\n",
      "Epoch 198/1000: Train Loss: 0.3657, Val Loss: 0.4164\n",
      "Baseline Loss: 2.6354 | Actual Loss: 0.3005\n",
      "Baseline Loss: 2.6882 | Actual Loss: 0.4392\n",
      "Baseline Loss: 2.6838 | Actual Loss: 0.3638\n",
      "Baseline Loss: 2.6806 | Actual Loss: 0.3508\n",
      "Baseline Loss: 2.6794 | Actual Loss: 0.5151\n",
      "Baseline Loss: 2.6970 | Actual Loss: 0.2799\n",
      "Baseline Loss: 2.7017 | Actual Loss: 0.4295\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.4890\n",
      "Baseline Loss: 2.6567 | Actual Loss: 0.2549\n",
      "Baseline Loss: 2.6771 | Actual Loss: 0.3384\n",
      "Baseline Loss: 2.6487 | Actual Loss: 0.5043\n",
      "Baseline Loss: 2.6889 | Actual Loss: 0.2132\n",
      "Baseline Loss: 2.6444 | Actual Loss: 0.4997\n",
      "Baseline Loss: 2.6263 | Actual Loss: 0.1451\n",
      "Baseline Loss: 2.6645 | Actual Loss: 0.2410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 199/1000 [02:06<08:32,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2924 | Actual Loss: 0.0990\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5427\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6884\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2318\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.2355\n",
      "Epoch 199/1000: Train Loss: 0.3415, Val Loss: 0.4246\n",
      "Baseline Loss: 2.6486 | Actual Loss: 0.2547\n",
      "Baseline Loss: 2.6751 | Actual Loss: 0.8031\n",
      "Baseline Loss: 2.6812 | Actual Loss: 0.4850\n",
      "Baseline Loss: 2.6879 | Actual Loss: 0.2632\n",
      "Baseline Loss: 2.6706 | Actual Loss: 0.5689\n",
      "Baseline Loss: 2.6781 | Actual Loss: 1.9874\n",
      "Baseline Loss: 2.6664 | Actual Loss: 0.2472\n",
      "Baseline Loss: 2.6838 | Actual Loss: 0.3315\n",
      "Baseline Loss: 2.6365 | Actual Loss: 0.2423\n",
      "Baseline Loss: 2.6704 | Actual Loss: 0.3718\n",
      "Baseline Loss: 2.6737 | Actual Loss: 0.4044\n",
      "Baseline Loss: 2.6844 | Actual Loss: 0.7111\n",
      "Baseline Loss: 2.6490 | Actual Loss: 0.2561\n",
      "Baseline Loss: 2.6901 | Actual Loss: 0.2182\n",
      "Baseline Loss: 2.6769 | Actual Loss: 0.3299\n",
      "Baseline Loss: 2.2963 | Actual Loss: 0.1867\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5550\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.4778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 200/1000 [02:06<08:22,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6853 | Actual Loss: 0.2014\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3172\n",
      "Epoch 200/1000: Train Loss: 0.4788, Val Loss: 0.3879\n",
      "Baseline Loss: 2.7048 | Actual Loss: 0.1687\n",
      "Baseline Loss: 2.6319 | Actual Loss: 0.2286\n",
      "Baseline Loss: 2.6795 | Actual Loss: 0.2306\n",
      "Baseline Loss: 2.6740 | Actual Loss: 0.4454\n",
      "Baseline Loss: 2.7137 | Actual Loss: 0.3800\n",
      "Baseline Loss: 2.7069 | Actual Loss: 0.3618\n",
      "Baseline Loss: 2.6627 | Actual Loss: 0.2859\n",
      "Baseline Loss: 2.6680 | Actual Loss: 0.2615\n",
      "Baseline Loss: 2.6551 | Actual Loss: 0.3073\n",
      "Baseline Loss: 2.7064 | Actual Loss: 0.3155\n",
      "Baseline Loss: 2.7301 | Actual Loss: 0.5238\n",
      "Baseline Loss: 2.6915 | Actual Loss: 0.4347\n",
      "Baseline Loss: 2.6291 | Actual Loss: 0.5082\n",
      "Baseline Loss: 2.6533 | Actual Loss: 0.1301\n",
      "Baseline Loss: 2.6559 | Actual Loss: 0.3369\n",
      "Baseline Loss: 2.2479 | Actual Loss: 0.0784\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4565\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 201/1000 [02:07<08:34,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6853 | Actual Loss: 0.2468\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3568\n",
      "Epoch 201/1000: Train Loss: 0.3123, Val Loss: 0.4223\n",
      "Baseline Loss: 2.6711 | Actual Loss: 0.4756\n",
      "Baseline Loss: 2.6529 | Actual Loss: 0.2522\n",
      "Baseline Loss: 2.6899 | Actual Loss: 1.2264\n",
      "Baseline Loss: 2.6790 | Actual Loss: 0.2997\n",
      "Baseline Loss: 2.6587 | Actual Loss: 0.3805\n",
      "Baseline Loss: 2.7163 | Actual Loss: 0.3256\n",
      "Baseline Loss: 2.6854 | Actual Loss: 0.4221\n",
      "Baseline Loss: 2.6809 | Actual Loss: 0.3587\n",
      "Baseline Loss: 2.6641 | Actual Loss: 0.5149\n",
      "Baseline Loss: 2.6756 | Actual Loss: 0.3671\n",
      "Baseline Loss: 2.6684 | Actual Loss: 0.2530\n",
      "Baseline Loss: 2.7070 | Actual Loss: 0.2412\n",
      "Baseline Loss: 2.6555 | Actual Loss: 0.4198\n",
      "Baseline Loss: 2.6842 | Actual Loss: 0.4066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 202/1000 [02:07<08:17,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6982 | Actual Loss: 0.1289\n",
      "Baseline Loss: 2.3071 | Actual Loss: 0.5815\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4795\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6039\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.1917\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3365\n",
      "Epoch 202/1000: Train Loss: 0.4159, Val Loss: 0.4029\n",
      "Baseline Loss: 2.6387 | Actual Loss: 0.4501\n",
      "Baseline Loss: 2.6360 | Actual Loss: 0.3396\n",
      "Baseline Loss: 2.6844 | Actual Loss: 0.6110\n",
      "Baseline Loss: 2.6731 | Actual Loss: 0.8195\n",
      "Baseline Loss: 2.7021 | Actual Loss: 0.5898\n",
      "Baseline Loss: 2.7096 | Actual Loss: 0.3289\n",
      "Baseline Loss: 2.6835 | Actual Loss: 0.2004\n",
      "Baseline Loss: 2.6438 | Actual Loss: 0.1760\n",
      "Baseline Loss: 2.6702 | Actual Loss: 0.1468\n",
      "Baseline Loss: 2.6445 | Actual Loss: 0.3225\n",
      "Baseline Loss: 2.6484 | Actual Loss: 0.5607\n",
      "Baseline Loss: 2.6671 | Actual Loss: 0.3902\n",
      "Baseline Loss: 2.6783 | Actual Loss: 1.7814\n",
      "Baseline Loss: 2.7150 | Actual Loss: 0.3285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 203/1000 [02:08<08:17,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6682 | Actual Loss: 0.4044\n",
      "Baseline Loss: 2.3877 | Actual Loss: 0.3501\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5006\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6275\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2594\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.1840\n",
      "Epoch 203/1000: Train Loss: 0.4875, Val Loss: 0.3929\n",
      "Baseline Loss: 2.6528 | Actual Loss: 0.1905\n",
      "Baseline Loss: 2.7013 | Actual Loss: 0.6877\n",
      "Baseline Loss: 2.6836 | Actual Loss: 0.5031\n",
      "Baseline Loss: 2.6669 | Actual Loss: 0.2850\n",
      "Baseline Loss: 2.6756 | Actual Loss: 0.2667\n",
      "Baseline Loss: 2.6695 | Actual Loss: 0.4575\n",
      "Baseline Loss: 2.6759 | Actual Loss: 0.2242\n",
      "Baseline Loss: 2.6487 | Actual Loss: 0.1590\n",
      "Baseline Loss: 2.7008 | Actual Loss: 0.4982\n",
      "Baseline Loss: 2.6595 | Actual Loss: 0.3391\n",
      "Baseline Loss: 2.6808 | Actual Loss: 0.3497\n",
      "Baseline Loss: 2.6735 | Actual Loss: 0.0764\n",
      "Baseline Loss: 2.7255 | Actual Loss: 0.2777\n",
      "Baseline Loss: 2.6405 | Actual Loss: 0.2969\n",
      "Baseline Loss: 2.6379 | Actual Loss: 0.4979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 203/1000 [02:09<08:27,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2608 | Actual Loss: 0.3451\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4585\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5959\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2005\n",
      "Baseline Loss: 2.6128 | Actual Loss: 0.3199\n",
      "Epoch 204/1000: Train Loss: 0.3409, Val Loss: 0.3937\n",
      "\n",
      "Early stopping at epoch 204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3290429376065731"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devices = [\"cuda\" if torch.cuda.is_available() else \"cpu\"]\n",
    "model8 = GNNModelWithNewLoss(\n",
    "        num_node_features=data_list[0].x.shape[1],\n",
    "        num_edge_features=data_list[0].edge_attr.shape[1],\n",
    "        num_global_features=0,\n",
    "        cov_num= 9,\n",
    "        hidden_dim=512,\n",
    "        dropout_rate=0.1,\n",
    "        property_index= 1,\n",
    "        save_path= 'premodels_new_og/9/1' \n",
    "    ).to(devices[0])\n",
    "\n",
    "model8.train_model(\n",
    "    data_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "364f6bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training will be saved to: premodels_new_og/9/9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7268 | Actual Loss: 3.6878\n",
      "Baseline Loss: 3.5328 | Actual Loss: 3.5152\n",
      "Baseline Loss: 3.3798 | Actual Loss: 3.3201\n",
      "Baseline Loss: 3.8157 | Actual Loss: 3.7051\n",
      "Baseline Loss: 3.5451 | Actual Loss: 3.5164\n",
      "Baseline Loss: 3.6321 | Actual Loss: 3.4646\n",
      "Baseline Loss: 3.3999 | Actual Loss: 3.3227\n",
      "Baseline Loss: 3.5878 | Actual Loss: 3.4581\n",
      "Baseline Loss: 3.5167 | Actual Loss: 3.3025\n",
      "Baseline Loss: 3.5617 | Actual Loss: 3.4735\n",
      "Baseline Loss: 3.4694 | Actual Loss: 3.1448\n",
      "Baseline Loss: 3.5414 | Actual Loss: 3.2405\n",
      "Baseline Loss: 3.5749 | Actual Loss: 3.3002\n",
      "Baseline Loss: 3.6096 | Actual Loss: 3.4210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 1/1000 [00:00<09:43,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3509 | Actual Loss: 2.8639\n",
      "Baseline Loss: 3.3925 | Actual Loss: 2.8888\n",
      "Baseline Loss: 3.3892 | Actual Loss: 2.6005\n",
      "Baseline Loss: 3.5623 | Actual Loss: 3.1921\n",
      "Baseline Loss: 3.2385 | Actual Loss: 2.6366\n",
      "Baseline Loss: 3.3263 | Actual Loss: 2.8558\n",
      "Epoch 1/1000: Train Loss: 3.3516, Val Loss: 2.8213\n",
      "New best validation loss: 2.8213\n",
      "Baseline Loss: 3.6684 | Actual Loss: 3.1874\n",
      "Baseline Loss: 3.4699 | Actual Loss: 2.9807\n",
      "Baseline Loss: 3.5095 | Actual Loss: 2.5770\n",
      "Baseline Loss: 3.6319 | Actual Loss: 3.2276\n",
      "Baseline Loss: 3.3961 | Actual Loss: 2.8300\n",
      "Baseline Loss: 3.3488 | Actual Loss: 2.5170\n",
      "Baseline Loss: 3.7314 | Actual Loss: 2.7760\n",
      "Baseline Loss: 3.4278 | Actual Loss: 2.4035\n",
      "Baseline Loss: 3.5918 | Actual Loss: 2.5575\n",
      "Baseline Loss: 3.8104 | Actual Loss: 2.6967\n",
      "Baseline Loss: 3.7369 | Actual Loss: 2.9829\n",
      "Baseline Loss: 3.2611 | Actual Loss: 2.3474\n",
      "Baseline Loss: 3.6826 | Actual Loss: 2.5851\n",
      "Baseline Loss: 3.5282 | Actual Loss: 2.3858\n",
      "Baseline Loss: 3.4169 | Actual Loss: 2.6030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 2/1000 [00:01<10:13,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4598 | Actual Loss: 2.1965\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.9151\n",
      "Baseline Loss: 3.5623 | Actual Loss: 2.2770\n",
      "Baseline Loss: 3.2385 | Actual Loss: 2.2237\n",
      "Baseline Loss: 3.3263 | Actual Loss: 1.7708\n",
      "Epoch 2/1000: Train Loss: 2.6784, Val Loss: 2.0466\n",
      "New best validation loss: 2.0466\n",
      "Baseline Loss: 4.1745 | Actual Loss: 2.9807\n",
      "Baseline Loss: 3.6930 | Actual Loss: 2.4520\n",
      "Baseline Loss: 3.4074 | Actual Loss: 1.9971\n",
      "Baseline Loss: 3.4589 | Actual Loss: 2.2186\n",
      "Baseline Loss: 3.4542 | Actual Loss: 2.0516\n",
      "Baseline Loss: 3.6370 | Actual Loss: 2.0312\n",
      "Baseline Loss: 3.5331 | Actual Loss: 2.0306\n",
      "Baseline Loss: 3.5051 | Actual Loss: 1.9841\n",
      "Baseline Loss: 3.7371 | Actual Loss: 2.4178\n",
      "Baseline Loss: 3.5747 | Actual Loss: 2.0497\n",
      "Baseline Loss: 3.3895 | Actual Loss: 1.7492\n",
      "Baseline Loss: 3.5699 | Actual Loss: 2.0872\n",
      "Baseline Loss: 3.7373 | Actual Loss: 1.9740\n",
      "Baseline Loss: 3.4211 | Actual Loss: 2.4294\n",
      "Baseline Loss: 3.5379 | Actual Loss: 2.0782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 3/1000 [00:01<10:35,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3735 | Actual Loss: 1.8828\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.4722\n",
      "Baseline Loss: 3.5623 | Actual Loss: 2.2820\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.8448\n",
      "Baseline Loss: 3.3263 | Actual Loss: 1.6874\n",
      "Epoch 3/1000: Train Loss: 2.1509, Val Loss: 1.8216\n",
      "New best validation loss: 1.8216\n",
      "Baseline Loss: 3.5495 | Actual Loss: 1.6256\n",
      "Baseline Loss: 3.3996 | Actual Loss: 1.9023\n",
      "Baseline Loss: 3.5962 | Actual Loss: 1.7348\n",
      "Baseline Loss: 3.4419 | Actual Loss: 2.0300\n",
      "Baseline Loss: 3.7170 | Actual Loss: 1.4162\n",
      "Baseline Loss: 3.6773 | Actual Loss: 2.2911\n",
      "Baseline Loss: 3.5619 | Actual Loss: 1.8341\n",
      "Baseline Loss: 3.4360 | Actual Loss: 1.3446\n",
      "Baseline Loss: 3.3551 | Actual Loss: 1.7472\n",
      "Baseline Loss: 3.6454 | Actual Loss: 2.0630\n",
      "Baseline Loss: 3.5580 | Actual Loss: 1.7178\n",
      "Baseline Loss: 3.7322 | Actual Loss: 2.4068\n",
      "Baseline Loss: 3.4699 | Actual Loss: 1.6730\n",
      "Baseline Loss: 3.7322 | Actual Loss: 1.3604\n",
      "Baseline Loss: 3.6454 | Actual Loss: 1.6904\n",
      "Baseline Loss: 3.4692 | Actual Loss: 1.7263\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.5566\n",
      "Baseline Loss: 3.5623 | Actual Loss: 2.2220\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.8727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 4/1000 [00:02<10:13,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3263 | Actual Loss: 1.4319\n",
      "Epoch 4/1000: Train Loss: 1.7852, Val Loss: 1.7708\n",
      "New best validation loss: 1.7708\n",
      "Baseline Loss: 3.6782 | Actual Loss: 2.0219\n",
      "Baseline Loss: 3.6737 | Actual Loss: 1.9387\n",
      "Baseline Loss: 3.6790 | Actual Loss: 1.4593\n",
      "Baseline Loss: 3.5212 | Actual Loss: 1.3100\n",
      "Baseline Loss: 3.6007 | Actual Loss: 1.4358\n",
      "Baseline Loss: 3.5248 | Actual Loss: 2.1862\n",
      "Baseline Loss: 3.4662 | Actual Loss: 1.4331\n",
      "Baseline Loss: 3.7466 | Actual Loss: 1.7140\n",
      "Baseline Loss: 3.3277 | Actual Loss: 1.9054\n",
      "Baseline Loss: 3.4721 | Actual Loss: 1.7621\n",
      "Baseline Loss: 3.5751 | Actual Loss: 2.1153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 5/1000 [00:03<10:28,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5005 | Actual Loss: 1.5537\n",
      "Baseline Loss: 3.5016 | Actual Loss: 1.6336\n",
      "Baseline Loss: 3.7999 | Actual Loss: 1.7405\n",
      "Baseline Loss: 3.4982 | Actual Loss: 1.3958\n",
      "Baseline Loss: 3.4303 | Actual Loss: 2.2298\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.1285\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.7510\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.6631\n",
      "Baseline Loss: 3.3263 | Actual Loss: 1.3758\n",
      "Epoch 5/1000: Train Loss: 1.7397, Val Loss: 1.4796\n",
      "New best validation loss: 1.4796\n",
      "Baseline Loss: 3.5455 | Actual Loss: 1.4758\n",
      "Baseline Loss: 3.6973 | Actual Loss: 2.2794\n",
      "Baseline Loss: 3.5157 | Actual Loss: 1.9177\n",
      "Baseline Loss: 3.6010 | Actual Loss: 1.8319\n",
      "Baseline Loss: 3.5711 | Actual Loss: 2.1244\n",
      "Baseline Loss: 3.4323 | Actual Loss: 1.7611\n",
      "Baseline Loss: 3.6051 | Actual Loss: 1.6702\n",
      "Baseline Loss: 3.9950 | Actual Loss: 1.2904\n",
      "Baseline Loss: 3.6185 | Actual Loss: 2.2442\n",
      "Baseline Loss: 3.8103 | Actual Loss: 1.2149\n",
      "Baseline Loss: 3.5290 | Actual Loss: 1.5048\n",
      "Baseline Loss: 3.4243 | Actual Loss: 1.2876\n",
      "Baseline Loss: 3.3237 | Actual Loss: 1.9563\n",
      "Baseline Loss: 3.5003 | Actual Loss: 1.5168\n",
      "Baseline Loss: 3.5619 | Actual Loss: 1.3761\n",
      "Baseline Loss: 3.1458 | Actual Loss: 1.7666\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.1609\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.6750\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.5736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 6/1000 [00:03<10:35,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3263 | Actual Loss: 1.2949\n",
      "Epoch 6/1000: Train Loss: 1.7012, Val Loss: 1.4261\n",
      "New best validation loss: 1.4261\n",
      "Baseline Loss: 3.2640 | Actual Loss: 1.7464\n",
      "Baseline Loss: 3.6738 | Actual Loss: 1.3324\n",
      "Baseline Loss: 3.6141 | Actual Loss: 1.3682\n",
      "Baseline Loss: 3.5877 | Actual Loss: 1.6961\n",
      "Baseline Loss: 3.4504 | Actual Loss: 1.3600\n",
      "Baseline Loss: 3.6230 | Actual Loss: 1.6843\n",
      "Baseline Loss: 3.4031 | Actual Loss: 1.2388\n",
      "Baseline Loss: 3.7268 | Actual Loss: 1.6436\n",
      "Baseline Loss: 3.7320 | Actual Loss: 1.6159\n",
      "Baseline Loss: 3.5789 | Actual Loss: 1.7955\n",
      "Baseline Loss: 3.4364 | Actual Loss: 1.0436\n",
      "Baseline Loss: 3.4247 | Actual Loss: 1.1463\n",
      "Baseline Loss: 3.6790 | Actual Loss: 0.9307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 7/1000 [00:04<10:12,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7029 | Actual Loss: 1.9850\n",
      "Baseline Loss: 3.5614 | Actual Loss: 1.5025\n",
      "Baseline Loss: 3.2504 | Actual Loss: 1.5489\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.1309\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.6649\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.5971\n",
      "Baseline Loss: 3.3263 | Actual Loss: 1.0604\n",
      "Epoch 7/1000: Train Loss: 1.4774, Val Loss: 1.3633\n",
      "New best validation loss: 1.3633\n",
      "Baseline Loss: 3.2612 | Actual Loss: 1.3202\n",
      "Baseline Loss: 3.3046 | Actual Loss: 1.6132\n",
      "Baseline Loss: 3.6407 | Actual Loss: 1.2636\n",
      "Baseline Loss: 3.6181 | Actual Loss: 2.1154\n",
      "Baseline Loss: 3.5364 | Actual Loss: 1.4175\n",
      "Baseline Loss: 3.6052 | Actual Loss: 1.2396\n",
      "Baseline Loss: 3.4898 | Actual Loss: 1.4634\n",
      "Baseline Loss: 3.5503 | Actual Loss: 1.2957\n",
      "Baseline Loss: 3.3887 | Actual Loss: 1.4119\n",
      "Baseline Loss: 3.7165 | Actual Loss: 1.6269\n",
      "Baseline Loss: 3.6826 | Actual Loss: 1.9695\n",
      "Baseline Loss: 3.8161 | Actual Loss: 1.0758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 8/1000 [00:05<10:29,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6137 | Actual Loss: 1.2206\n",
      "Baseline Loss: 3.6550 | Actual Loss: 1.0692\n",
      "Baseline Loss: 3.4206 | Actual Loss: 1.1170\n",
      "Baseline Loss: 3.4792 | Actual Loss: 1.4269\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.0943\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.5831\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.5912\n",
      "Baseline Loss: 3.3263 | Actual Loss: 1.0161\n",
      "Epoch 8/1000: Train Loss: 1.4154, Val Loss: 1.3212\n",
      "New best validation loss: 1.3212\n",
      "Baseline Loss: 3.5965 | Actual Loss: 1.9790\n",
      "Baseline Loss: 3.5457 | Actual Loss: 0.9806\n",
      "Baseline Loss: 3.4932 | Actual Loss: 1.4712\n",
      "Baseline Loss: 3.3315 | Actual Loss: 1.4939\n",
      "Baseline Loss: 3.6407 | Actual Loss: 1.5772\n",
      "Baseline Loss: 3.6313 | Actual Loss: 1.8848\n",
      "Baseline Loss: 3.4923 | Actual Loss: 1.3680\n",
      "Baseline Loss: 3.6462 | Actual Loss: 1.3485\n",
      "Baseline Loss: 3.4799 | Actual Loss: 0.7235\n",
      "Baseline Loss: 3.6505 | Actual Loss: 1.2331\n",
      "Baseline Loss: 3.7023 | Actual Loss: 1.1252\n",
      "Baseline Loss: 3.4504 | Actual Loss: 1.7496\n",
      "Baseline Loss: 3.6277 | Actual Loss: 1.4003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 9/1000 [00:05<10:27,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6636 | Actual Loss: 1.2547\n",
      "Baseline Loss: 3.6010 | Actual Loss: 1.4099\n",
      "Baseline Loss: 3.4494 | Actual Loss: 0.9569\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.1582\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.4398\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.4213\n",
      "Baseline Loss: 3.3263 | Actual Loss: 1.0106\n",
      "Epoch 9/1000: Train Loss: 1.3723, Val Loss: 1.2575\n",
      "New best validation loss: 1.2575\n",
      "Baseline Loss: 3.7421 | Actual Loss: 1.1959\n",
      "Baseline Loss: 3.6010 | Actual Loss: 1.2954\n",
      "Baseline Loss: 3.5159 | Actual Loss: 1.1523\n",
      "Baseline Loss: 3.3208 | Actual Loss: 0.9761\n",
      "Baseline Loss: 3.6549 | Actual Loss: 2.4846\n",
      "Baseline Loss: 3.5051 | Actual Loss: 1.5065\n",
      "Baseline Loss: 3.5838 | Actual Loss: 1.1302\n",
      "Baseline Loss: 3.3816 | Actual Loss: 0.9872\n",
      "Baseline Loss: 3.4657 | Actual Loss: 1.1802\n",
      "Baseline Loss: 3.7628 | Actual Loss: 0.9041\n",
      "Baseline Loss: 3.5704 | Actual Loss: 1.3812\n",
      "Baseline Loss: 3.4402 | Actual Loss: 1.1561\n",
      "Baseline Loss: 3.6873 | Actual Loss: 0.9491\n",
      "Baseline Loss: 3.4960 | Actual Loss: 0.9221\n",
      "Baseline Loss: 3.5540 | Actual Loss: 1.7577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 10/1000 [00:06<10:06,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.8643 | Actual Loss: 1.6797\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.0373\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.4688\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.2137\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.9124\n",
      "Epoch 10/1000: Train Loss: 1.2912, Val Loss: 1.1580\n",
      "New best validation loss: 1.1580\n",
      "Baseline Loss: 3.4700 | Actual Loss: 1.0118\n",
      "Baseline Loss: 3.7219 | Actual Loss: 1.1343\n",
      "Baseline Loss: 3.7574 | Actual Loss: 1.2039\n",
      "Baseline Loss: 3.4972 | Actual Loss: 1.2531\n",
      "Baseline Loss: 3.6004 | Actual Loss: 0.8936\n",
      "Baseline Loss: 3.5251 | Actual Loss: 1.4615\n",
      "Baseline Loss: 3.5581 | Actual Loss: 1.7222\n",
      "Baseline Loss: 3.6827 | Actual Loss: 2.3630\n",
      "Baseline Loss: 3.4209 | Actual Loss: 1.2594\n",
      "Baseline Loss: 3.4959 | Actual Loss: 0.8037\n",
      "Baseline Loss: 3.5709 | Actual Loss: 1.2620\n",
      "Baseline Loss: 3.3866 | Actual Loss: 1.2434\n",
      "Baseline Loss: 3.4039 | Actual Loss: 1.2689\n",
      "Baseline Loss: 3.6234 | Actual Loss: 0.9294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 11/1000 [00:06<10:24,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7369 | Actual Loss: 0.9892\n",
      "Baseline Loss: 3.7795 | Actual Loss: 2.9868\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.0174\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.5580\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.2964\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.9060\n",
      "Epoch 11/1000: Train Loss: 1.3616, Val Loss: 1.1945\n",
      "Baseline Loss: 3.4848 | Actual Loss: 1.4798\n",
      "Baseline Loss: 3.5823 | Actual Loss: 1.9684\n",
      "Baseline Loss: 3.7221 | Actual Loss: 1.2621\n",
      "Baseline Loss: 3.3882 | Actual Loss: 0.9846\n",
      "Baseline Loss: 3.4131 | Actual Loss: 1.0635\n",
      "Baseline Loss: 3.7065 | Actual Loss: 1.0754\n",
      "Baseline Loss: 3.4818 | Actual Loss: 0.8260\n",
      "Baseline Loss: 3.5448 | Actual Loss: 1.8479\n",
      "Baseline Loss: 3.5408 | Actual Loss: 0.5120\n",
      "Baseline Loss: 3.4864 | Actual Loss: 1.3242\n",
      "Baseline Loss: 3.5494 | Actual Loss: 2.0985\n",
      "Baseline Loss: 3.5790 | Actual Loss: 1.4455\n",
      "Baseline Loss: 3.6366 | Actual Loss: 1.3243\n",
      "Baseline Loss: 3.4882 | Actual Loss: 1.0726\n",
      "Baseline Loss: 3.4932 | Actual Loss: 1.2951\n",
      "Baseline Loss: 3.4695 | Actual Loss: 0.9756\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.0777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 12/1000 [00:07<10:31,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5623 | Actual Loss: 1.7702\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.3251\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.9043\n",
      "Epoch 12/1000: Train Loss: 1.2847, Val Loss: 1.2693\n",
      "Baseline Loss: 3.4388 | Actual Loss: 1.0354\n",
      "Baseline Loss: 3.4212 | Actual Loss: 1.7051\n",
      "Baseline Loss: 3.5453 | Actual Loss: 1.3497\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.5460\n",
      "Baseline Loss: 3.6508 | Actual Loss: 1.4906\n",
      "Baseline Loss: 3.5051 | Actual Loss: 1.1167\n",
      "Baseline Loss: 3.5251 | Actual Loss: 1.3856\n",
      "Baseline Loss: 3.4122 | Actual Loss: 1.2690\n",
      "Baseline Loss: 3.6232 | Actual Loss: 0.9316\n",
      "Baseline Loss: 3.8045 | Actual Loss: 1.2990\n",
      "Baseline Loss: 3.6138 | Actual Loss: 1.5764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏         | 13/1000 [00:08<10:09,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6982 | Actual Loss: 1.3820\n",
      "Baseline Loss: 3.4103 | Actual Loss: 1.4277\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.0757\n",
      "Baseline Loss: 3.5827 | Actual Loss: 1.2451\n",
      "Baseline Loss: 3.6059 | Actual Loss: 0.2588\n",
      "Baseline Loss: 3.3892 | Actual Loss: 0.9709\n",
      "Baseline Loss: 3.5623 | Actual Loss: 2.9342\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.3422\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.9532\n",
      "Epoch 13/1000: Train Loss: 1.1934, Val Loss: 1.5501\n",
      "Baseline Loss: 3.3048 | Actual Loss: 1.2103\n",
      "Baseline Loss: 3.5792 | Actual Loss: 1.3794\n",
      "Baseline Loss: 3.4251 | Actual Loss: 1.4932\n",
      "Baseline Loss: 3.5494 | Actual Loss: 1.0677\n",
      "Baseline Loss: 3.6095 | Actual Loss: 0.9861\n",
      "Baseline Loss: 3.5413 | Actual Loss: 1.2469\n",
      "Baseline Loss: 3.6011 | Actual Loss: 1.4930\n",
      "Baseline Loss: 3.4735 | Actual Loss: 1.0735\n",
      "Baseline Loss: 3.4257 | Actual Loss: 0.6494\n",
      "Baseline Loss: 3.5495 | Actual Loss: 0.8865\n",
      "Baseline Loss: 3.4360 | Actual Loss: 2.5966\n",
      "Baseline Loss: 3.6504 | Actual Loss: 3.4016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏         | 14/1000 [00:08<10:15,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6885 | Actual Loss: 1.4445\n",
      "Baseline Loss: 3.4733 | Actual Loss: 1.4295\n",
      "Baseline Loss: 3.6007 | Actual Loss: 1.6247\n",
      "Baseline Loss: 3.3670 | Actual Loss: 2.1377\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.2110\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.6787\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.5447\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.9832\n",
      "Epoch 14/1000: Train Loss: 1.5075, Val Loss: 1.3544\n",
      "Baseline Loss: 3.6545 | Actual Loss: 1.4720\n",
      "Baseline Loss: 3.5299 | Actual Loss: 1.1355\n",
      "Baseline Loss: 3.5663 | Actual Loss: 1.4274\n",
      "Baseline Loss: 3.4735 | Actual Loss: 1.6353\n",
      "Baseline Loss: 3.5583 | Actual Loss: 1.2523\n",
      "Baseline Loss: 3.4655 | Actual Loss: 0.8499\n",
      "Baseline Loss: 3.5614 | Actual Loss: 1.1194\n",
      "Baseline Loss: 3.4168 | Actual Loss: 1.0018\n",
      "Baseline Loss: 3.5834 | Actual Loss: 1.2553\n",
      "Baseline Loss: 3.5126 | Actual Loss: 1.1674\n",
      "Baseline Loss: 3.5704 | Actual Loss: 2.5777\n",
      "Baseline Loss: 3.4931 | Actual Loss: 1.9884\n",
      "Baseline Loss: 3.4402 | Actual Loss: 0.8469\n",
      "Baseline Loss: 3.7115 | Actual Loss: 2.3470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 15/1000 [00:09<10:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.9014 | Actual Loss: 2.7921\n",
      "Baseline Loss: 3.2807 | Actual Loss: 0.8629\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.0687\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.6788\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.5638\n",
      "Baseline Loss: 3.3263 | Actual Loss: 1.1581\n",
      "Epoch 15/1000: Train Loss: 1.4832, Val Loss: 1.3674\n",
      "Baseline Loss: 3.5828 | Actual Loss: 1.3071\n",
      "Baseline Loss: 3.4771 | Actual Loss: 1.0040\n",
      "Baseline Loss: 3.7474 | Actual Loss: 1.4896\n",
      "Baseline Loss: 3.4890 | Actual Loss: 1.4432\n",
      "Baseline Loss: 3.5212 | Actual Loss: 1.1366\n",
      "Baseline Loss: 3.4967 | Actual Loss: 1.2756\n",
      "Baseline Loss: 3.5091 | Actual Loss: 1.4375\n",
      "Baseline Loss: 3.3760 | Actual Loss: 1.5985\n",
      "Baseline Loss: 3.6590 | Actual Loss: 1.5191\n",
      "Baseline Loss: 3.4404 | Actual Loss: 0.5564\n",
      "Baseline Loss: 3.7417 | Actual Loss: 1.2253\n",
      "Baseline Loss: 3.5620 | Actual Loss: 0.7512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 16/1000 [00:10<10:21,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6137 | Actual Loss: 1.9799\n",
      "Baseline Loss: 3.4876 | Actual Loss: 1.2187\n",
      "Baseline Loss: 3.5416 | Actual Loss: 1.6040\n",
      "Baseline Loss: 3.4021 | Actual Loss: 1.1701\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.1762\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.5537\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.2900\n",
      "Baseline Loss: 3.3263 | Actual Loss: 1.0012\n",
      "Epoch 16/1000: Train Loss: 1.2948, Val Loss: 1.2553\n",
      "Baseline Loss: 3.4898 | Actual Loss: 0.9094\n",
      "Baseline Loss: 3.6507 | Actual Loss: 1.6672\n",
      "Baseline Loss: 3.8214 | Actual Loss: 1.6363\n",
      "Baseline Loss: 3.4076 | Actual Loss: 1.4475\n",
      "Baseline Loss: 3.8212 | Actual Loss: 3.0550\n",
      "Baseline Loss: 3.4116 | Actual Loss: 2.4275\n",
      "Baseline Loss: 3.5742 | Actual Loss: 0.7528\n",
      "Baseline Loss: 3.6640 | Actual Loss: 0.9832\n",
      "Baseline Loss: 3.4853 | Actual Loss: 1.8715\n",
      "Baseline Loss: 3.5619 | Actual Loss: 0.7749\n",
      "Baseline Loss: 3.5092 | Actual Loss: 1.5145\n",
      "Baseline Loss: 3.5206 | Actual Loss: 1.0624\n",
      "Baseline Loss: 3.4431 | Actual Loss: 1.2644\n",
      "Baseline Loss: 3.4359 | Actual Loss: 1.3102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 17/1000 [00:10<10:20,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4855 | Actual Loss: 1.6653\n",
      "Baseline Loss: 3.3403 | Actual Loss: 0.7954\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.1313\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.6312\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.5863\n",
      "Baseline Loss: 3.3263 | Actual Loss: 1.2976\n",
      "Epoch 17/1000: Train Loss: 1.4461, Val Loss: 1.4116\n",
      "Baseline Loss: 3.6365 | Actual Loss: 1.5331\n",
      "Baseline Loss: 3.5458 | Actual Loss: 1.1260\n",
      "Baseline Loss: 4.0841 | Actual Loss: 0.8577\n",
      "Baseline Loss: 3.5289 | Actual Loss: 0.8753\n",
      "Baseline Loss: 3.5249 | Actual Loss: 1.2814\n",
      "Baseline Loss: 3.6092 | Actual Loss: 2.9517\n",
      "Baseline Loss: 3.8435 | Actual Loss: 2.6210\n",
      "Baseline Loss: 3.6365 | Actual Loss: 1.5660\n",
      "Baseline Loss: 3.4281 | Actual Loss: 2.5584\n",
      "Baseline Loss: 3.5207 | Actual Loss: 0.7597\n",
      "Baseline Loss: 3.4403 | Actual Loss: 1.2981\n",
      "Baseline Loss: 3.2219 | Actual Loss: 1.3118\n",
      "Baseline Loss: 3.5920 | Actual Loss: 0.8880\n",
      "Baseline Loss: 3.5128 | Actual Loss: 1.2986\n",
      "Baseline Loss: 3.6458 | Actual Loss: 1.0818\n",
      "Baseline Loss: 3.2734 | Actual Loss: 1.5318\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.2054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 18/1000 [00:11<10:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5623 | Actual Loss: 1.2541\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.3334\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.9650\n",
      "Epoch 18/1000: Train Loss: 1.4713, Val Loss: 1.1895\n",
      "Baseline Loss: 3.4997 | Actual Loss: 1.2089\n",
      "Baseline Loss: 3.4471 | Actual Loss: 0.8575\n",
      "Baseline Loss: 3.6138 | Actual Loss: 1.1458\n",
      "Baseline Loss: 3.6225 | Actual Loss: 0.6090\n",
      "Baseline Loss: 3.5745 | Actual Loss: 2.3632\n",
      "Baseline Loss: 3.7422 | Actual Loss: 0.6980\n",
      "Baseline Loss: 3.6184 | Actual Loss: 0.8912\n",
      "Baseline Loss: 3.5004 | Actual Loss: 0.6932\n",
      "Baseline Loss: 3.6636 | Actual Loss: 1.1934\n",
      "Baseline Loss: 3.2738 | Actual Loss: 1.4284\n",
      "Baseline Loss: 3.6980 | Actual Loss: 1.6882\n",
      "Baseline Loss: 3.6498 | Actual Loss: 1.1149\n",
      "Baseline Loss: 3.5045 | Actual Loss: 1.1120\n",
      "Baseline Loss: 3.4329 | Actual Loss: 1.1702\n",
      "Baseline Loss: 3.4434 | Actual Loss: 2.8713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 19/1000 [00:11<10:25,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.1380 | Actual Loss: 1.4250\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.1383\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.3279\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.2719\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.7961\n",
      "Epoch 19/1000: Train Loss: 1.2794, Val Loss: 1.1335\n",
      "New best validation loss: 1.1335\n",
      "Baseline Loss: 3.2640 | Actual Loss: 1.1226\n",
      "Baseline Loss: 3.4469 | Actual Loss: 0.8674\n",
      "Baseline Loss: 3.7222 | Actual Loss: 1.2613\n",
      "Baseline Loss: 3.6690 | Actual Loss: 0.8735\n",
      "Baseline Loss: 3.7627 | Actual Loss: 0.9225\n",
      "Baseline Loss: 3.6230 | Actual Loss: 1.7459\n",
      "Baseline Loss: 3.5248 | Actual Loss: 0.8738\n",
      "Baseline Loss: 3.3543 | Actual Loss: 0.8228\n",
      "Baseline Loss: 3.6689 | Actual Loss: 1.0567\n",
      "Baseline Loss: 3.8263 | Actual Loss: 0.6148\n",
      "Baseline Loss: 3.6467 | Actual Loss: 1.4580\n",
      "Baseline Loss: 3.3762 | Actual Loss: 1.0069\n",
      "Baseline Loss: 3.5167 | Actual Loss: 0.7599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 20/1000 [00:12<10:38,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7026 | Actual Loss: 1.2908\n",
      "Baseline Loss: 3.6410 | Actual Loss: 1.5452\n",
      "Baseline Loss: 3.2118 | Actual Loss: 2.6998\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.0109\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.4711\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.2352\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.8359\n",
      "Epoch 20/1000: Train Loss: 1.1826, Val Loss: 1.1382\n",
      "Baseline Loss: 3.5451 | Actual Loss: 1.1215\n",
      "Baseline Loss: 3.5120 | Actual Loss: 1.4061\n",
      "Baseline Loss: 3.5415 | Actual Loss: 1.2934\n",
      "Baseline Loss: 3.9760 | Actual Loss: 1.4973\n",
      "Baseline Loss: 3.5288 | Actual Loss: 1.0823\n",
      "Baseline Loss: 3.4883 | Actual Loss: 1.2844\n",
      "Baseline Loss: 3.5961 | Actual Loss: 1.0337\n",
      "Baseline Loss: 3.5742 | Actual Loss: 1.1363\n",
      "Baseline Loss: 3.4578 | Actual Loss: 1.0531\n",
      "Baseline Loss: 3.5299 | Actual Loss: 1.1665\n",
      "Baseline Loss: 3.6688 | Actual Loss: 0.7683\n",
      "Baseline Loss: 3.6272 | Actual Loss: 1.4629\n",
      "Baseline Loss: 3.6501 | Actual Loss: 2.1466\n",
      "Baseline Loss: 3.5870 | Actual Loss: 1.9489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 21/1000 [00:13<10:51,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3544 | Actual Loss: 0.8587\n",
      "Baseline Loss: 3.2498 | Actual Loss: 0.5561\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.1596\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.3592\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.2972\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.9253\n",
      "Epoch 21/1000: Train Loss: 1.2385, Val Loss: 1.1853\n",
      "Baseline Loss: 3.6462 | Actual Loss: 0.9136\n",
      "Baseline Loss: 3.2950 | Actual Loss: 1.1424\n",
      "Baseline Loss: 3.6686 | Actual Loss: 1.6814\n",
      "Baseline Loss: 3.4290 | Actual Loss: 1.0202\n",
      "Baseline Loss: 3.5620 | Actual Loss: 0.9041\n",
      "Baseline Loss: 3.4421 | Actual Loss: 1.0455\n",
      "Baseline Loss: 3.6099 | Actual Loss: 1.1792\n",
      "Baseline Loss: 3.5366 | Actual Loss: 0.9288\n",
      "Baseline Loss: 3.4884 | Actual Loss: 1.4456\n",
      "Baseline Loss: 3.5969 | Actual Loss: 1.1529\n",
      "Baseline Loss: 3.6181 | Actual Loss: 1.2671\n",
      "Baseline Loss: 3.7422 | Actual Loss: 1.3212\n",
      "Baseline Loss: 3.5128 | Actual Loss: 0.9212\n",
      "Baseline Loss: 3.4210 | Actual Loss: 0.6108\n",
      "Baseline Loss: 3.7026 | Actual Loss: 1.1427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 22/1000 [00:13<10:33,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4891 | Actual Loss: 1.1054\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.1255\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.3108\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.2465\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.8657\n",
      "Epoch 22/1000: Train Loss: 1.1114, Val Loss: 1.1371\n",
      "Baseline Loss: 3.6597 | Actual Loss: 1.3711\n",
      "Baseline Loss: 3.5326 | Actual Loss: 0.8908\n",
      "Baseline Loss: 3.6046 | Actual Loss: 1.2190\n",
      "Baseline Loss: 3.5368 | Actual Loss: 1.3119\n",
      "Baseline Loss: 3.6786 | Actual Loss: 1.3257\n",
      "Baseline Loss: 3.4374 | Actual Loss: 1.1287\n",
      "Baseline Loss: 3.6326 | Actual Loss: 0.6326\n",
      "Baseline Loss: 3.5920 | Actual Loss: 1.2231\n",
      "Baseline Loss: 3.4104 | Actual Loss: 0.7650\n",
      "Baseline Loss: 3.5248 | Actual Loss: 1.5437\n",
      "Baseline Loss: 3.8833 | Actual Loss: 1.2317\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.7187\n",
      "Baseline Loss: 3.6933 | Actual Loss: 1.0676\n",
      "Baseline Loss: 3.4740 | Actual Loss: 1.0564\n",
      "Baseline Loss: 3.5965 | Actual Loss: 1.1816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 23/1000 [00:14<10:27,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.2351 | Actual Loss: 0.6987\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.1388\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.3204\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.3263\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.9134\n",
      "Epoch 23/1000: Train Loss: 1.0854, Val Loss: 1.1747\n",
      "Baseline Loss: 3.7322 | Actual Loss: 0.4156\n",
      "Baseline Loss: 3.6047 | Actual Loss: 0.7461\n",
      "Baseline Loss: 3.5373 | Actual Loss: 1.2179\n",
      "Baseline Loss: 3.4277 | Actual Loss: 1.4374\n",
      "Baseline Loss: 3.5617 | Actual Loss: 1.0862\n",
      "Baseline Loss: 3.5255 | Actual Loss: 1.2085\n",
      "Baseline Loss: 3.5745 | Actual Loss: 1.2091\n",
      "Baseline Loss: 3.7025 | Actual Loss: 0.7895\n",
      "Baseline Loss: 3.6011 | Actual Loss: 0.8613\n",
      "Baseline Loss: 3.5045 | Actual Loss: 1.0307\n",
      "Baseline Loss: 3.4427 | Actual Loss: 0.9303\n",
      "Baseline Loss: 3.5743 | Actual Loss: 0.8325\n",
      "Baseline Loss: 3.4107 | Actual Loss: 1.0444\n",
      "Baseline Loss: 3.6412 | Actual Loss: 0.7585\n",
      "Baseline Loss: 3.4136 | Actual Loss: 1.5555\n",
      "Baseline Loss: 3.3412 | Actual Loss: 0.8553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 24/1000 [00:15<10:30,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3892 | Actual Loss: 1.0804\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.2575\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.2591\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.8701\n",
      "Epoch 24/1000: Train Loss: 0.9987, Val Loss: 1.1168\n",
      "New best validation loss: 1.1168\n",
      "Baseline Loss: 3.5288 | Actual Loss: 1.6527\n",
      "Baseline Loss: 3.5177 | Actual Loss: 1.3934\n",
      "Baseline Loss: 3.3967 | Actual Loss: 1.5531\n",
      "Baseline Loss: 3.4242 | Actual Loss: 1.4892\n",
      "Baseline Loss: 3.3787 | Actual Loss: 1.4446\n",
      "Baseline Loss: 3.6738 | Actual Loss: 0.9554\n",
      "Baseline Loss: 3.5574 | Actual Loss: 1.1548\n",
      "Baseline Loss: 3.7422 | Actual Loss: 0.5245\n",
      "Baseline Loss: 3.5652 | Actual Loss: 1.5583\n",
      "Baseline Loss: 3.5407 | Actual Loss: 1.0809\n",
      "Baseline Loss: 3.3949 | Actual Loss: 1.1878\n",
      "Baseline Loss: 3.5294 | Actual Loss: 0.8165\n",
      "Baseline Loss: 3.5538 | Actual Loss: 1.1176\n",
      "Baseline Loss: 3.5088 | Actual Loss: 1.2638\n",
      "Baseline Loss: 3.6975 | Actual Loss: 0.5744\n",
      "Baseline Loss: 3.4115 | Actual Loss: 0.3317\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.1051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▎         | 25/1000 [00:15<10:17,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5623 | Actual Loss: 1.5976\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.1253\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.7599\n",
      "Epoch 25/1000: Train Loss: 1.1312, Val Loss: 1.1470\n",
      "Baseline Loss: 3.4069 | Actual Loss: 1.7648\n",
      "Baseline Loss: 3.6882 | Actual Loss: 1.1202\n",
      "Baseline Loss: 3.7775 | Actual Loss: 1.3205\n",
      "Baseline Loss: 3.3983 | Actual Loss: 1.2987\n",
      "Baseline Loss: 3.4732 | Actual Loss: 0.8132\n",
      "Baseline Loss: 3.6593 | Actual Loss: 0.8101\n",
      "Baseline Loss: 3.4041 | Actual Loss: 1.0772\n",
      "Baseline Loss: 3.6738 | Actual Loss: 0.8693\n",
      "Baseline Loss: 3.5917 | Actual Loss: 0.8551\n",
      "Baseline Loss: 3.5043 | Actual Loss: 0.8202\n",
      "Baseline Loss: 3.5009 | Actual Loss: 1.2453\n",
      "Baseline Loss: 3.5368 | Actual Loss: 0.9119\n",
      "Baseline Loss: 3.6787 | Actual Loss: 0.7459\n",
      "Baseline Loss: 3.3206 | Actual Loss: 0.8947\n",
      "Baseline Loss: 3.8045 | Actual Loss: 2.3931\n",
      "Baseline Loss: 3.6175 | Actual Loss: 1.3773\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.1298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 26/1000 [00:16<10:16,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5623 | Actual Loss: 1.8011\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.2152\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.9012\n",
      "Epoch 26/1000: Train Loss: 1.1448, Val Loss: 1.2618\n",
      "Baseline Loss: 3.3233 | Actual Loss: 1.8656\n",
      "Baseline Loss: 3.4626 | Actual Loss: 1.1974\n",
      "Baseline Loss: 3.6407 | Actual Loss: 1.0895\n",
      "Baseline Loss: 3.8050 | Actual Loss: 0.9859\n",
      "Baseline Loss: 3.4808 | Actual Loss: 1.2165\n",
      "Baseline Loss: 3.6454 | Actual Loss: 1.4757\n",
      "Baseline Loss: 3.5042 | Actual Loss: 1.0061\n",
      "Baseline Loss: 3.7727 | Actual Loss: 0.8564\n",
      "Baseline Loss: 3.6223 | Actual Loss: 0.4593\n",
      "Baseline Loss: 3.5704 | Actual Loss: 0.8936\n",
      "Baseline Loss: 3.5825 | Actual Loss: 1.4250\n",
      "Baseline Loss: 3.6092 | Actual Loss: 0.9915\n",
      "Baseline Loss: 3.7317 | Actual Loss: 0.7540\n",
      "Baseline Loss: 3.3009 | Actual Loss: 3.7126\n",
      "Baseline Loss: 3.6146 | Actual Loss: 0.7418\n",
      "Baseline Loss: 3.3479 | Actual Loss: 0.4221\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.0659\n",
      "Baseline Loss: 3.5623 | Actual Loss: 2.6102\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.6807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 27/1000 [00:17<10:07,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3263 | Actual Loss: 1.2959\n",
      "Epoch 27/1000: Train Loss: 1.1933, Val Loss: 1.6632\n",
      "Baseline Loss: 3.5961 | Actual Loss: 0.7950\n",
      "Baseline Loss: 3.5803 | Actual Loss: 1.2774\n",
      "Baseline Loss: 3.3543 | Actual Loss: 0.7837\n",
      "Baseline Loss: 3.4805 | Actual Loss: 1.0700\n",
      "Baseline Loss: 3.4293 | Actual Loss: 0.9132\n",
      "Baseline Loss: 3.5786 | Actual Loss: 2.0891\n",
      "Baseline Loss: 3.6361 | Actual Loss: 0.9746\n",
      "Baseline Loss: 3.6555 | Actual Loss: 0.9583\n",
      "Baseline Loss: 3.5208 | Actual Loss: 1.2258\n",
      "Baseline Loss: 3.5489 | Actual Loss: 1.0821\n",
      "Baseline Loss: 3.4734 | Actual Loss: 0.8067\n",
      "Baseline Loss: 3.4329 | Actual Loss: 1.2567\n",
      "Baseline Loss: 3.7467 | Actual Loss: 0.8100\n",
      "Baseline Loss: 3.6775 | Actual Loss: 0.8679\n",
      "Baseline Loss: 3.5135 | Actual Loss: 1.7004\n",
      "Baseline Loss: 3.2804 | Actual Loss: 1.9200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 28/1000 [00:17<10:18,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3892 | Actual Loss: 1.1100\n",
      "Baseline Loss: 3.5623 | Actual Loss: 2.2531\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.3842\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.8109\n",
      "Epoch 28/1000: Train Loss: 1.1582, Val Loss: 1.3895\n",
      "Baseline Loss: 3.6980 | Actual Loss: 1.8423\n",
      "Baseline Loss: 3.3644 | Actual Loss: 1.0018\n",
      "Baseline Loss: 3.6182 | Actual Loss: 0.9047\n",
      "Baseline Loss: 3.4075 | Actual Loss: 1.2398\n",
      "Baseline Loss: 3.4174 | Actual Loss: 1.3758\n",
      "Baseline Loss: 3.6226 | Actual Loss: 1.2146\n",
      "Baseline Loss: 3.5332 | Actual Loss: 1.0277\n",
      "Baseline Loss: 3.5963 | Actual Loss: 0.9781\n",
      "Baseline Loss: 3.6825 | Actual Loss: 1.2756\n",
      "Baseline Loss: 3.4971 | Actual Loss: 1.5002\n",
      "Baseline Loss: 3.6549 | Actual Loss: 1.2109\n",
      "Baseline Loss: 3.5005 | Actual Loss: 2.0160\n",
      "Baseline Loss: 3.4765 | Actual Loss: 1.1926\n",
      "Baseline Loss: 3.6329 | Actual Loss: 1.1162\n",
      "Baseline Loss: 3.4469 | Actual Loss: 1.0891\n",
      "Baseline Loss: 3.1374 | Actual Loss: 0.7900\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.1298\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.3244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 29/1000 [00:18<10:17,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.2385 | Actual Loss: 1.1644\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.9453\n",
      "Epoch 29/1000: Train Loss: 1.2360, Val Loss: 1.1410\n",
      "Baseline Loss: 3.4878 | Actual Loss: 0.8246\n",
      "Baseline Loss: 3.4853 | Actual Loss: 0.8635\n",
      "Baseline Loss: 3.6732 | Actual Loss: 1.7391\n",
      "Baseline Loss: 3.6925 | Actual Loss: 1.7238\n",
      "Baseline Loss: 3.3440 | Actual Loss: 0.8833\n",
      "Baseline Loss: 3.4010 | Actual Loss: 0.9548\n",
      "Baseline Loss: 3.5411 | Actual Loss: 0.8468\n",
      "Baseline Loss: 3.4926 | Actual Loss: 1.9054\n",
      "Baseline Loss: 3.6147 | Actual Loss: 2.4927\n",
      "Baseline Loss: 3.4736 | Actual Loss: 0.5692\n",
      "Baseline Loss: 3.4810 | Actual Loss: 1.3132\n",
      "Baseline Loss: 3.5165 | Actual Loss: 2.3267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 30/1000 [00:18<10:08,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4773 | Actual Loss: 0.7979\n",
      "Baseline Loss: 3.4167 | Actual Loss: 2.9661\n",
      "Baseline Loss: 3.6973 | Actual Loss: 1.9947\n",
      "Baseline Loss: 3.3925 | Actual Loss: 0.4911\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.2619\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.4279\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.4628\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.9279\n",
      "Epoch 30/1000: Train Loss: 1.4183, Val Loss: 1.2701\n",
      "Baseline Loss: 3.4776 | Actual Loss: 0.9191\n",
      "Baseline Loss: 3.5413 | Actual Loss: 1.2869\n",
      "Baseline Loss: 3.6738 | Actual Loss: 1.0550\n",
      "Baseline Loss: 3.4693 | Actual Loss: 1.2876\n",
      "Baseline Loss: 3.8777 | Actual Loss: 1.4464\n",
      "Baseline Loss: 3.5039 | Actual Loss: 0.6683\n",
      "Baseline Loss: 3.3858 | Actual Loss: 0.8189\n",
      "Baseline Loss: 3.4286 | Actual Loss: 0.7937\n",
      "Baseline Loss: 3.5296 | Actual Loss: 1.1056\n",
      "Baseline Loss: 3.3892 | Actual Loss: 0.5435\n",
      "Baseline Loss: 3.7269 | Actual Loss: 1.2600\n",
      "Baseline Loss: 3.3891 | Actual Loss: 0.7364\n",
      "Baseline Loss: 3.6142 | Actual Loss: 1.0869\n",
      "Baseline Loss: 3.5168 | Actual Loss: 1.3947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 31/1000 [00:19<10:09,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5661 | Actual Loss: 0.9394\n",
      "Baseline Loss: 3.5835 | Actual Loss: 0.8635\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.0958\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.1758\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.2771\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.9695\n",
      "Epoch 31/1000: Train Loss: 1.0129, Val Loss: 1.1296\n",
      "Baseline Loss: 3.3709 | Actual Loss: 1.1643\n",
      "Baseline Loss: 3.4700 | Actual Loss: 0.6970\n",
      "Baseline Loss: 3.4620 | Actual Loss: 1.1709\n",
      "Baseline Loss: 3.5700 | Actual Loss: 0.8410\n",
      "Baseline Loss: 3.5920 | Actual Loss: 1.3841\n",
      "Baseline Loss: 3.6975 | Actual Loss: 1.8100\n",
      "Baseline Loss: 3.5448 | Actual Loss: 0.5265\n",
      "Baseline Loss: 3.7022 | Actual Loss: 0.9648\n",
      "Baseline Loss: 3.4278 | Actual Loss: 1.0427\n",
      "Baseline Loss: 3.8434 | Actual Loss: 1.0442\n",
      "Baseline Loss: 3.6972 | Actual Loss: 0.9927\n",
      "Baseline Loss: 3.4959 | Actual Loss: 1.0812\n",
      "Baseline Loss: 3.6731 | Actual Loss: 2.7107\n",
      "Baseline Loss: 3.7525 | Actual Loss: 1.1281\n",
      "Baseline Loss: 3.3051 | Actual Loss: 0.5648\n",
      "Baseline Loss: 3.3400 | Actual Loss: 3.0734\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.1168\n",
      "Baseline Loss: 3.5623 | Actual Loss: 2.7706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 32/1000 [00:20<09:44,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.2385 | Actual Loss: 2.0592\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.9745\n",
      "Epoch 32/1000: Train Loss: 1.2623, Val Loss: 1.7303\n",
      "Baseline Loss: 3.7121 | Actual Loss: 3.2501\n",
      "Baseline Loss: 3.8659 | Actual Loss: 2.5988\n",
      "Baseline Loss: 3.5204 | Actual Loss: 0.6580\n",
      "Baseline Loss: 3.6498 | Actual Loss: 2.5657\n",
      "Baseline Loss: 3.6927 | Actual Loss: 2.2732\n",
      "Baseline Loss: 3.5830 | Actual Loss: 1.6628\n",
      "Baseline Loss: 3.5494 | Actual Loss: 1.3228\n",
      "Baseline Loss: 3.4855 | Actual Loss: 2.3147\n",
      "Baseline Loss: 3.4656 | Actual Loss: 1.8503\n",
      "Baseline Loss: 3.5533 | Actual Loss: 1.6434\n",
      "Baseline Loss: 3.4735 | Actual Loss: 1.1362\n",
      "Baseline Loss: 3.5966 | Actual Loss: 1.1942\n",
      "Baseline Loss: 3.5331 | Actual Loss: 1.2306\n",
      "Baseline Loss: 3.3947 | Actual Loss: 1.2458\n",
      "Baseline Loss: 3.5657 | Actual Loss: 1.4587\n",
      "Baseline Loss: 3.2267 | Actual Loss: 1.2505\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.2460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 33/1000 [00:20<10:12,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5623 | Actual Loss: 1.6179\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.1281\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.8738\n",
      "Epoch 33/1000: Train Loss: 1.7285, Val Loss: 1.2165\n",
      "Baseline Loss: 3.5416 | Actual Loss: 1.2750\n",
      "Baseline Loss: 3.8597 | Actual Loss: 0.7046\n",
      "Baseline Loss: 3.5011 | Actual Loss: 0.9501\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.1712\n",
      "Baseline Loss: 3.5368 | Actual Loss: 0.5751\n",
      "Baseline Loss: 3.5997 | Actual Loss: 0.7303\n",
      "Baseline Loss: 3.7886 | Actual Loss: 1.2216\n",
      "Baseline Loss: 3.4579 | Actual Loss: 2.3501\n",
      "Baseline Loss: 3.3894 | Actual Loss: 1.4710\n",
      "Baseline Loss: 3.4432 | Actual Loss: 1.0921\n",
      "Baseline Loss: 3.3926 | Actual Loss: 1.1311\n",
      "Baseline Loss: 3.5367 | Actual Loss: 0.9691\n",
      "Baseline Loss: 3.5500 | Actual Loss: 0.9362\n",
      "Baseline Loss: 3.4972 | Actual Loss: 0.6741\n",
      "Baseline Loss: 3.4033 | Actual Loss: 1.0722\n",
      "Baseline Loss: 3.5845 | Actual Loss: 2.7717\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.0678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 34/1000 [00:21<10:11,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5623 | Actual Loss: 2.0315\n",
      "Baseline Loss: 3.2385 | Actual Loss: 2.0556\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.9184\n",
      "Epoch 34/1000: Train Loss: 1.1935, Val Loss: 1.5183\n",
      "Baseline Loss: 3.4733 | Actual Loss: 1.2125\n",
      "Baseline Loss: 3.3715 | Actual Loss: 0.7045\n",
      "Baseline Loss: 3.4354 | Actual Loss: 0.8341\n",
      "Baseline Loss: 3.4814 | Actual Loss: 0.7998\n",
      "Baseline Loss: 3.5874 | Actual Loss: 0.9064\n",
      "Baseline Loss: 3.7268 | Actual Loss: 2.1982\n",
      "Baseline Loss: 3.6738 | Actual Loss: 0.5262\n",
      "Baseline Loss: 3.6924 | Actual Loss: 1.0152\n",
      "Baseline Loss: 3.4696 | Actual Loss: 1.0716\n",
      "Baseline Loss: 3.6317 | Actual Loss: 1.1046\n",
      "Baseline Loss: 3.4701 | Actual Loss: 0.8545\n",
      "Baseline Loss: 3.3782 | Actual Loss: 1.2642\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.0475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 35/1000 [00:22<09:57,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7473 | Actual Loss: 0.9419\n",
      "Baseline Loss: 3.6093 | Actual Loss: 1.6381\n",
      "Baseline Loss: 3.1464 | Actual Loss: 0.7777\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.0239\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.5123\n",
      "Baseline Loss: 3.2385 | Actual Loss: 0.8770\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.8231\n",
      "Epoch 35/1000: Train Loss: 1.0561, Val Loss: 1.0591\n",
      "New best validation loss: 1.0591\n",
      "Baseline Loss: 3.7782 | Actual Loss: 0.7643\n",
      "Baseline Loss: 3.5453 | Actual Loss: 1.4170\n",
      "Baseline Loss: 3.5578 | Actual Loss: 1.1922\n",
      "Baseline Loss: 3.5752 | Actual Loss: 1.0295\n",
      "Baseline Loss: 3.4518 | Actual Loss: 1.1863\n",
      "Baseline Loss: 3.6004 | Actual Loss: 1.0028\n",
      "Baseline Loss: 3.6503 | Actual Loss: 0.9014\n",
      "Baseline Loss: 3.6057 | Actual Loss: 0.7906\n",
      "Baseline Loss: 3.3861 | Actual Loss: 1.3753\n",
      "Baseline Loss: 3.4511 | Actual Loss: 1.0263\n",
      "Baseline Loss: 3.7943 | Actual Loss: 0.6692\n",
      "Baseline Loss: 3.5364 | Actual Loss: 0.9928\n",
      "Baseline Loss: 3.5087 | Actual Loss: 0.7880\n",
      "Baseline Loss: 3.5455 | Actual Loss: 0.9937\n",
      "Baseline Loss: 3.5250 | Actual Loss: 0.7776\n",
      "Baseline Loss: 3.4500 | Actual Loss: 2.0588\n",
      "Baseline Loss: 3.3892 | Actual Loss: 0.8902\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.0664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 36/1000 [00:22<10:13,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.2385 | Actual Loss: 1.3938\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.8487\n",
      "Epoch 36/1000: Train Loss: 1.0604, Val Loss: 1.0498\n",
      "New best validation loss: 1.0498\n",
      "Baseline Loss: 3.4930 | Actual Loss: 1.9627\n",
      "Baseline Loss: 3.4931 | Actual Loss: 0.9573\n",
      "Baseline Loss: 3.6829 | Actual Loss: 0.7743\n",
      "Baseline Loss: 3.7171 | Actual Loss: 0.9219\n",
      "Baseline Loss: 3.4769 | Actual Loss: 1.0714\n",
      "Baseline Loss: 3.6050 | Actual Loss: 1.2433\n",
      "Baseline Loss: 3.6239 | Actual Loss: 1.2146\n",
      "Baseline Loss: 3.5288 | Actual Loss: 1.0643\n",
      "Baseline Loss: 3.4539 | Actual Loss: 1.1541\n",
      "Baseline Loss: 3.5884 | Actual Loss: 1.5654\n",
      "Baseline Loss: 3.4173 | Actual Loss: 0.8909\n",
      "Baseline Loss: 3.4734 | Actual Loss: 0.6020\n",
      "Baseline Loss: 3.5786 | Actual Loss: 0.9030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 37/1000 [00:23<09:58,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5704 | Actual Loss: 1.0088\n",
      "Baseline Loss: 3.6046 | Actual Loss: 0.7349\n",
      "Baseline Loss: 3.3748 | Actual Loss: 1.7830\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.1278\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.2086\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.4630\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.8730\n",
      "Epoch 37/1000: Train Loss: 1.1157, Val Loss: 1.1681\n",
      "Baseline Loss: 3.5748 | Actual Loss: 1.5814\n",
      "Baseline Loss: 3.7027 | Actual Loss: 1.2832\n",
      "Baseline Loss: 3.6546 | Actual Loss: 1.2690\n",
      "Baseline Loss: 3.4773 | Actual Loss: 1.0576\n",
      "Baseline Loss: 3.3281 | Actual Loss: 1.2562\n",
      "Baseline Loss: 3.3008 | Actual Loss: 1.3969\n",
      "Baseline Loss: 3.6265 | Actual Loss: 1.2184\n",
      "Baseline Loss: 3.6639 | Actual Loss: 1.2974\n",
      "Baseline Loss: 3.5086 | Actual Loss: 1.0387\n",
      "Baseline Loss: 3.5541 | Actual Loss: 1.3526\n",
      "Baseline Loss: 3.7218 | Actual Loss: 0.4521\n",
      "Baseline Loss: 3.5168 | Actual Loss: 0.6690\n",
      "Baseline Loss: 3.6833 | Actual Loss: 3.5728\n",
      "Baseline Loss: 3.6451 | Actual Loss: 1.0942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 38/1000 [00:23<10:09,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5320 | Actual Loss: 3.0317\n",
      "Baseline Loss: 3.4293 | Actual Loss: 1.0149\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.0816\n",
      "Baseline Loss: 3.5623 | Actual Loss: 2.4944\n",
      "Baseline Loss: 3.2385 | Actual Loss: 2.2166\n",
      "Baseline Loss: 3.3263 | Actual Loss: 1.1255\n",
      "Epoch 38/1000: Train Loss: 1.4116, Val Loss: 1.7295\n",
      "Baseline Loss: 3.7577 | Actual Loss: 1.0643\n",
      "Baseline Loss: 3.4738 | Actual Loss: 0.4306\n",
      "Baseline Loss: 3.9497 | Actual Loss: 2.9218\n",
      "Baseline Loss: 3.4470 | Actual Loss: 0.9251\n",
      "Baseline Loss: 3.7371 | Actual Loss: 1.5938\n",
      "Baseline Loss: 3.4512 | Actual Loss: 0.9942\n",
      "Baseline Loss: 3.8670 | Actual Loss: 0.9464\n",
      "Baseline Loss: 3.6226 | Actual Loss: 1.5832\n",
      "Baseline Loss: 3.3746 | Actual Loss: 1.3638\n",
      "Baseline Loss: 3.6007 | Actual Loss: 1.3745\n",
      "Baseline Loss: 3.4283 | Actual Loss: 1.3307\n",
      "Baseline Loss: 3.5198 | Actual Loss: 1.2883\n",
      "Baseline Loss: 3.7408 | Actual Loss: 1.0358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 39/1000 [00:24<10:14,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4390 | Actual Loss: 1.3969\n",
      "Baseline Loss: 3.4505 | Actual Loss: 1.0230\n",
      "Baseline Loss: 3.3568 | Actual Loss: 1.2098\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.0231\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.5640\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.3533\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.8901\n",
      "Epoch 39/1000: Train Loss: 1.2801, Val Loss: 1.2076\n",
      "Baseline Loss: 3.6735 | Actual Loss: 1.9281\n",
      "Baseline Loss: 3.5839 | Actual Loss: 0.5944\n",
      "Baseline Loss: 3.4143 | Actual Loss: 0.6327\n",
      "Baseline Loss: 3.5204 | Actual Loss: 0.6708\n",
      "Baseline Loss: 3.8374 | Actual Loss: 3.2248\n",
      "Baseline Loss: 3.3573 | Actual Loss: 0.9085\n",
      "Baseline Loss: 3.5053 | Actual Loss: 0.8045\n",
      "Baseline Loss: 3.5971 | Actual Loss: 0.6299\n",
      "Baseline Loss: 3.5409 | Actual Loss: 1.1760\n",
      "Baseline Loss: 3.5662 | Actual Loss: 3.2222\n",
      "Baseline Loss: 3.5459 | Actual Loss: 0.9381\n",
      "Baseline Loss: 3.5821 | Actual Loss: 0.9570\n",
      "Baseline Loss: 3.6044 | Actual Loss: 0.8421\n",
      "Baseline Loss: 3.5754 | Actual Loss: 1.0233\n",
      "Baseline Loss: 3.5590 | Actual Loss: 1.9960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 40/1000 [00:25<10:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.0451 | Actual Loss: 1.2696\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.0750\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.4572\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.4541\n",
      "Baseline Loss: 3.3263 | Actual Loss: 1.0076\n",
      "Epoch 40/1000: Train Loss: 1.3011, Val Loss: 1.2485\n",
      "Baseline Loss: 3.5753 | Actual Loss: 0.8916\n",
      "Baseline Loss: 3.7374 | Actual Loss: 1.5809\n",
      "Baseline Loss: 3.5625 | Actual Loss: 1.0082\n",
      "Baseline Loss: 3.8265 | Actual Loss: 0.8269\n",
      "Baseline Loss: 3.6096 | Actual Loss: 1.1796\n",
      "Baseline Loss: 3.5537 | Actual Loss: 1.2362\n",
      "Baseline Loss: 3.6980 | Actual Loss: 0.5118\n",
      "Baseline Loss: 3.3551 | Actual Loss: 0.9169\n",
      "Baseline Loss: 3.7074 | Actual Loss: 1.0866\n",
      "Baseline Loss: 3.5710 | Actual Loss: 2.8814\n",
      "Baseline Loss: 3.6278 | Actual Loss: 3.7993\n",
      "Baseline Loss: 3.6272 | Actual Loss: 1.9431\n",
      "Baseline Loss: 3.3270 | Actual Loss: 1.1068\n",
      "Baseline Loss: 3.4024 | Actual Loss: 1.1556\n",
      "Baseline Loss: 3.5795 | Actual Loss: 0.5090\n",
      "Baseline Loss: 3.2192 | Actual Loss: 2.9161\n",
      "Baseline Loss: 3.3892 | Actual Loss: 0.9506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 41/1000 [00:25<10:01,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5623 | Actual Loss: 1.8271\n",
      "Baseline Loss: 3.2385 | Actual Loss: 2.8512\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.8732\n",
      "Epoch 41/1000: Train Loss: 1.4719, Val Loss: 1.6255\n",
      "Baseline Loss: 3.6318 | Actual Loss: 1.2496\n",
      "Baseline Loss: 3.6274 | Actual Loss: 0.6766\n",
      "Baseline Loss: 3.5088 | Actual Loss: 0.5006\n",
      "Baseline Loss: 3.5537 | Actual Loss: 0.5302\n",
      "Baseline Loss: 3.6315 | Actual Loss: 1.2549\n",
      "Baseline Loss: 3.6142 | Actual Loss: 1.9579\n",
      "Baseline Loss: 3.7220 | Actual Loss: 0.8325\n",
      "Baseline Loss: 3.6596 | Actual Loss: 1.9696\n",
      "Baseline Loss: 3.6009 | Actual Loss: 1.4592\n",
      "Baseline Loss: 3.5049 | Actual Loss: 0.9161\n",
      "Baseline Loss: 3.6138 | Actual Loss: 1.7221\n",
      "Baseline Loss: 3.3168 | Actual Loss: 0.9970\n",
      "Baseline Loss: 3.3673 | Actual Loss: 1.5355\n",
      "Baseline Loss: 3.5048 | Actual Loss: 0.9211\n",
      "Baseline Loss: 3.3782 | Actual Loss: 1.4503\n",
      "Baseline Loss: 3.9569 | Actual Loss: 1.1903\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.2772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 42/1000 [00:26<10:20,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5623 | Actual Loss: 1.3308\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.3071\n",
      "Baseline Loss: 3.3263 | Actual Loss: 1.1543\n",
      "Epoch 42/1000: Train Loss: 1.1977, Val Loss: 1.2674\n",
      "Baseline Loss: 3.6137 | Actual Loss: 1.1105\n",
      "Baseline Loss: 3.8042 | Actual Loss: 0.7724\n",
      "Baseline Loss: 3.4934 | Actual Loss: 0.7039\n",
      "Baseline Loss: 3.6882 | Actual Loss: 1.6518\n",
      "Baseline Loss: 3.6733 | Actual Loss: 1.1313\n",
      "Baseline Loss: 3.4783 | Actual Loss: 1.0788\n",
      "Baseline Loss: 3.3141 | Actual Loss: 0.7242\n",
      "Baseline Loss: 3.7631 | Actual Loss: 0.7803\n",
      "Baseline Loss: 3.4175 | Actual Loss: 1.0713\n",
      "Baseline Loss: 3.6686 | Actual Loss: 1.0271\n",
      "Baseline Loss: 3.5092 | Actual Loss: 0.7711\n",
      "Baseline Loss: 3.6639 | Actual Loss: 0.7912\n",
      "Baseline Loss: 3.5580 | Actual Loss: 2.1357\n",
      "Baseline Loss: 3.4858 | Actual Loss: 0.6184\n",
      "Baseline Loss: 3.5789 | Actual Loss: 1.5432\n",
      "Baseline Loss: 3.1110 | Actual Loss: 0.8300\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.2421\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.1743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 43/1000 [00:27<10:08,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.2385 | Actual Loss: 1.1775\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.8748\n",
      "Epoch 43/1000: Train Loss: 1.0463, Val Loss: 1.1172\n",
      "Baseline Loss: 3.5539 | Actual Loss: 1.2732\n",
      "Baseline Loss: 3.6137 | Actual Loss: 1.3781\n",
      "Baseline Loss: 3.6098 | Actual Loss: 0.6665\n",
      "Baseline Loss: 3.6453 | Actual Loss: 1.0013\n",
      "Baseline Loss: 3.6598 | Actual Loss: 0.9975\n",
      "Baseline Loss: 3.5450 | Actual Loss: 1.4407\n",
      "Baseline Loss: 3.7368 | Actual Loss: 0.8685\n",
      "Baseline Loss: 3.5289 | Actual Loss: 0.7797\n",
      "Baseline Loss: 3.4217 | Actual Loss: 0.6374\n",
      "Baseline Loss: 3.4168 | Actual Loss: 0.7559\n",
      "Baseline Loss: 3.6180 | Actual Loss: 1.4773\n",
      "Baseline Loss: 3.7118 | Actual Loss: 0.8271\n",
      "Baseline Loss: 3.4502 | Actual Loss: 1.0096\n",
      "Baseline Loss: 3.5912 | Actual Loss: 0.8364\n",
      "Baseline Loss: 3.4550 | Actual Loss: 0.7165\n",
      "Baseline Loss: 3.2977 | Actual Loss: 0.6331\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 44/1000 [00:27<10:20,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5623 | Actual Loss: 1.4155\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.0853\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.8148\n",
      "Epoch 44/1000: Train Loss: 0.9562, Val Loss: 1.0795\n",
      "Baseline Loss: 3.4774 | Actual Loss: 0.9808\n",
      "Baseline Loss: 3.7219 | Actual Loss: 0.8764\n",
      "Baseline Loss: 3.3854 | Actual Loss: 0.9409\n",
      "Baseline Loss: 3.5089 | Actual Loss: 1.2345\n",
      "Baseline Loss: 3.5012 | Actual Loss: 1.1875\n",
      "Baseline Loss: 3.7022 | Actual Loss: 1.1840\n",
      "Baseline Loss: 3.4065 | Actual Loss: 1.0255\n",
      "Baseline Loss: 3.5087 | Actual Loss: 0.7247\n",
      "Baseline Loss: 3.3794 | Actual Loss: 0.9223\n",
      "Baseline Loss: 3.5166 | Actual Loss: 1.1095\n",
      "Baseline Loss: 3.5748 | Actual Loss: 0.9244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 45/1000 [00:28<09:56,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5249 | Actual Loss: 0.7180\n",
      "Baseline Loss: 3.6366 | Actual Loss: 1.1070\n",
      "Baseline Loss: 3.6414 | Actual Loss: 0.8226\n",
      "Baseline Loss: 3.6969 | Actual Loss: 1.1989\n",
      "Baseline Loss: 3.4024 | Actual Loss: 0.5424\n",
      "Baseline Loss: 3.3892 | Actual Loss: 0.9468\n",
      "Baseline Loss: 3.5623 | Actual Loss: 0.9627\n",
      "Baseline Loss: 3.2385 | Actual Loss: 0.8569\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.8594\n",
      "Epoch 45/1000: Train Loss: 0.9687, Val Loss: 0.9064\n",
      "New best validation loss: 0.9064\n",
      "Baseline Loss: 3.6092 | Actual Loss: 1.1737\n",
      "Baseline Loss: 3.7021 | Actual Loss: 0.7401\n",
      "Baseline Loss: 3.5534 | Actual Loss: 0.7471\n",
      "Baseline Loss: 3.5619 | Actual Loss: 0.6754\n",
      "Baseline Loss: 3.5920 | Actual Loss: 1.2002\n",
      "Baseline Loss: 3.3557 | Actual Loss: 1.2246\n",
      "Baseline Loss: 3.5749 | Actual Loss: 0.9698\n",
      "Baseline Loss: 3.6772 | Actual Loss: 0.9109\n",
      "Baseline Loss: 3.4424 | Actual Loss: 0.9292\n",
      "Baseline Loss: 3.4617 | Actual Loss: 1.1493\n",
      "Baseline Loss: 3.7216 | Actual Loss: 0.4496\n",
      "Baseline Loss: 3.4851 | Actual Loss: 0.8546\n",
      "Baseline Loss: 3.4656 | Actual Loss: 0.8012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 46/1000 [00:29<10:10,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5417 | Actual Loss: 0.9701\n",
      "Baseline Loss: 3.5004 | Actual Loss: 0.7059\n",
      "Baseline Loss: 3.4887 | Actual Loss: 3.4227\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.0807\n",
      "Baseline Loss: 3.5623 | Actual Loss: 2.0034\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.3434\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.8010\n",
      "Epoch 46/1000: Train Loss: 1.0578, Val Loss: 1.3071\n",
      "Baseline Loss: 3.5794 | Actual Loss: 2.3433\n",
      "Baseline Loss: 3.6370 | Actual Loss: 1.5837\n",
      "Baseline Loss: 3.4932 | Actual Loss: 1.3711\n",
      "Baseline Loss: 3.3816 | Actual Loss: 0.9110\n",
      "Baseline Loss: 3.8656 | Actual Loss: 0.4695\n",
      "Baseline Loss: 3.6317 | Actual Loss: 0.6303\n",
      "Baseline Loss: 3.3381 | Actual Loss: 0.4286\n",
      "Baseline Loss: 3.6095 | Actual Loss: 0.6008\n",
      "Baseline Loss: 3.5570 | Actual Loss: 1.3896\n",
      "Baseline Loss: 3.4685 | Actual Loss: 1.2035\n",
      "Baseline Loss: 3.3993 | Actual Loss: 0.7730\n",
      "Baseline Loss: 3.4896 | Actual Loss: 1.0251\n",
      "Baseline Loss: 3.3914 | Actual Loss: 1.3042\n",
      "Baseline Loss: 3.6832 | Actual Loss: 1.6283\n",
      "Baseline Loss: 3.7619 | Actual Loss: 0.7329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 47/1000 [00:29<10:11,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4689 | Actual Loss: 1.0934\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.0225\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.4136\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.0487\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.8064\n",
      "Epoch 47/1000: Train Loss: 1.0930, Val Loss: 1.0728\n",
      "Baseline Loss: 3.5414 | Actual Loss: 0.8295\n",
      "Baseline Loss: 3.5247 | Actual Loss: 0.6752\n",
      "Baseline Loss: 3.2914 | Actual Loss: 1.6154\n",
      "Baseline Loss: 3.6223 | Actual Loss: 0.4717\n",
      "Baseline Loss: 3.6591 | Actual Loss: 1.5727\n",
      "Baseline Loss: 3.5209 | Actual Loss: 1.3355\n",
      "Baseline Loss: 3.7315 | Actual Loss: 1.5939\n",
      "Baseline Loss: 3.4777 | Actual Loss: 0.6297\n",
      "Baseline Loss: 3.3982 | Actual Loss: 0.9336\n",
      "Baseline Loss: 3.6639 | Actual Loss: 1.0504\n",
      "Baseline Loss: 3.7218 | Actual Loss: 1.0358\n",
      "Baseline Loss: 3.5377 | Actual Loss: 0.7564\n",
      "Baseline Loss: 3.5043 | Actual Loss: 1.1692\n",
      "Baseline Loss: 3.5787 | Actual Loss: 1.0797\n",
      "Baseline Loss: 3.6056 | Actual Loss: 2.2699\n",
      "Baseline Loss: 3.5298 | Actual Loss: 3.1317\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.0349\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.0940\n",
      "Baseline Loss: 3.2385 | Actual Loss: 0.9798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 48/1000 [00:30<09:52,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3263 | Actual Loss: 0.9284\n",
      "Epoch 48/1000: Train Loss: 1.2594, Val Loss: 1.0093\n",
      "Baseline Loss: 3.3547 | Actual Loss: 1.0142\n",
      "Baseline Loss: 3.6232 | Actual Loss: 2.3929\n",
      "Baseline Loss: 3.4967 | Actual Loss: 0.8870\n",
      "Baseline Loss: 3.6049 | Actual Loss: 1.5525\n",
      "Baseline Loss: 3.5321 | Actual Loss: 1.1693\n",
      "Baseline Loss: 3.3674 | Actual Loss: 1.2784\n",
      "Baseline Loss: 3.6098 | Actual Loss: 0.9429\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.0766\n",
      "Baseline Loss: 3.5416 | Actual Loss: 0.5841\n",
      "Baseline Loss: 3.6873 | Actual Loss: 0.8849\n",
      "Baseline Loss: 3.4583 | Actual Loss: 1.9635\n",
      "Baseline Loss: 3.7574 | Actual Loss: 2.9777\n",
      "Baseline Loss: 3.4194 | Actual Loss: 0.7494\n",
      "Baseline Loss: 3.5051 | Actual Loss: 3.2656\n",
      "Baseline Loss: 3.4541 | Actual Loss: 2.4435\n",
      "Baseline Loss: 3.8495 | Actual Loss: 3.8656\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.2864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 49/1000 [00:30<10:03,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5623 | Actual Loss: 2.8327\n",
      "Baseline Loss: 3.2385 | Actual Loss: 2.7362\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.6786\n",
      "Epoch 49/1000: Train Loss: 1.6905, Val Loss: 1.8835\n",
      "Baseline Loss: 3.6045 | Actual Loss: 2.1841\n",
      "Baseline Loss: 3.6786 | Actual Loss: 2.5407\n",
      "Baseline Loss: 3.7886 | Actual Loss: 0.8030\n",
      "Baseline Loss: 3.5048 | Actual Loss: 1.2451\n",
      "Baseline Loss: 3.6733 | Actual Loss: 0.7905\n",
      "Baseline Loss: 3.4845 | Actual Loss: 0.5359\n",
      "Baseline Loss: 3.4508 | Actual Loss: 1.4994\n",
      "Baseline Loss: 3.3351 | Actual Loss: 2.3361\n",
      "Baseline Loss: 3.3719 | Actual Loss: 1.5893\n",
      "Baseline Loss: 3.5408 | Actual Loss: 1.0994\n",
      "Baseline Loss: 3.5003 | Actual Loss: 2.1807\n",
      "Baseline Loss: 3.6737 | Actual Loss: 1.4919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 50/1000 [00:31<10:01,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4686 | Actual Loss: 1.4754\n",
      "Baseline Loss: 3.4931 | Actual Loss: 1.3590\n",
      "Baseline Loss: 3.3082 | Actual Loss: 1.6398\n",
      "Baseline Loss: 3.8643 | Actual Loss: 1.0486\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.2418\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.5425\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.5802\n",
      "Baseline Loss: 3.3263 | Actual Loss: 1.2824\n",
      "Epoch 50/1000: Train Loss: 1.4887, Val Loss: 1.4117\n",
      "Baseline Loss: 3.6695 | Actual Loss: 1.6307\n",
      "Baseline Loss: 3.6639 | Actual Loss: 1.2104\n",
      "Baseline Loss: 3.3958 | Actual Loss: 1.9431\n",
      "Baseline Loss: 3.6407 | Actual Loss: 1.0670\n",
      "Baseline Loss: 3.5498 | Actual Loss: 1.8705\n",
      "Baseline Loss: 3.4367 | Actual Loss: 2.9410\n",
      "Baseline Loss: 3.4699 | Actual Loss: 0.9198\n",
      "Baseline Loss: 3.7571 | Actual Loss: 1.7700\n",
      "Baseline Loss: 3.3988 | Actual Loss: 1.3152\n",
      "Baseline Loss: 3.5657 | Actual Loss: 0.6681\n",
      "Baseline Loss: 3.7781 | Actual Loss: 1.0353\n",
      "Baseline Loss: 3.2490 | Actual Loss: 1.2789\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.9568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 51/1000 [00:32<09:39,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6317 | Actual Loss: 0.8543\n",
      "Baseline Loss: 3.5210 | Actual Loss: 0.9615\n",
      "Baseline Loss: 3.7659 | Actual Loss: 0.2407\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.0481\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.0383\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.0717\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.8728\n",
      "Epoch 51/1000: Train Loss: 1.3540, Val Loss: 1.0077\n",
      "Baseline Loss: 3.4800 | Actual Loss: 0.8372\n",
      "Baseline Loss: 3.5118 | Actual Loss: 0.6898\n",
      "Baseline Loss: 3.3616 | Actual Loss: 1.2586\n",
      "Baseline Loss: 3.6092 | Actual Loss: 0.7253\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.8345\n",
      "Baseline Loss: 3.5370 | Actual Loss: 0.7597\n",
      "Baseline Loss: 3.7993 | Actual Loss: 1.0220\n",
      "Baseline Loss: 3.5933 | Actual Loss: 0.6908\n",
      "Baseline Loss: 3.6230 | Actual Loss: 3.1631\n",
      "Baseline Loss: 3.5209 | Actual Loss: 0.7930\n",
      "Baseline Loss: 3.5494 | Actual Loss: 0.7064\n",
      "Baseline Loss: 3.6365 | Actual Loss: 0.6461\n",
      "Baseline Loss: 3.2803 | Actual Loss: 1.6975\n",
      "Baseline Loss: 3.5919 | Actual Loss: 1.0223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 52/1000 [00:32<09:56,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6327 | Actual Loss: 0.8032\n",
      "Baseline Loss: 3.9734 | Actual Loss: 1.8329\n",
      "Baseline Loss: 3.3892 | Actual Loss: 0.9936\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.1055\n",
      "Baseline Loss: 3.2385 | Actual Loss: 0.9756\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.7593\n",
      "Epoch 52/1000: Train Loss: 1.0927, Val Loss: 0.9585\n",
      "Baseline Loss: 3.4423 | Actual Loss: 0.6241\n",
      "Baseline Loss: 3.4626 | Actual Loss: 0.6738\n",
      "Baseline Loss: 3.5134 | Actual Loss: 1.2701\n",
      "Baseline Loss: 3.4278 | Actual Loss: 0.8516\n",
      "Baseline Loss: 3.4284 | Actual Loss: 0.9461\n",
      "Baseline Loss: 3.7375 | Actual Loss: 0.6667\n",
      "Baseline Loss: 3.7169 | Actual Loss: 0.9268\n",
      "Baseline Loss: 3.4782 | Actual Loss: 0.7628\n",
      "Baseline Loss: 3.6142 | Actual Loss: 1.4036\n",
      "Baseline Loss: 3.3349 | Actual Loss: 0.5627\n",
      "Baseline Loss: 3.8158 | Actual Loss: 0.8389\n",
      "Baseline Loss: 3.5863 | Actual Loss: 0.8132\n",
      "Baseline Loss: 3.7725 | Actual Loss: 3.2035\n",
      "Baseline Loss: 3.3997 | Actual Loss: 2.3658\n",
      "Baseline Loss: 3.5963 | Actual Loss: 0.5456\n",
      "Baseline Loss: 3.4399 | Actual Loss: 0.9329\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.0197\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.3047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 53/1000 [00:33<09:37,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.2385 | Actual Loss: 1.0020\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.8254\n",
      "Epoch 53/1000: Train Loss: 1.0868, Val Loss: 1.0379\n",
      "Baseline Loss: 3.7473 | Actual Loss: 0.5894\n",
      "Baseline Loss: 3.6317 | Actual Loss: 0.9352\n",
      "Baseline Loss: 3.4779 | Actual Loss: 0.4757\n",
      "Baseline Loss: 3.4346 | Actual Loss: 2.7094\n",
      "Baseline Loss: 3.7516 | Actual Loss: 1.1001\n",
      "Baseline Loss: 3.2893 | Actual Loss: 0.9124\n",
      "Baseline Loss: 3.6779 | Actual Loss: 0.7833\n",
      "Baseline Loss: 3.5568 | Actual Loss: 0.6586\n",
      "Baseline Loss: 3.5289 | Actual Loss: 0.6956\n",
      "Baseline Loss: 3.5673 | Actual Loss: 0.5511\n",
      "Baseline Loss: 3.4325 | Actual Loss: 0.9658\n",
      "Baseline Loss: 3.5829 | Actual Loss: 1.2802\n",
      "Baseline Loss: 3.6361 | Actual Loss: 1.3322\n",
      "Baseline Loss: 3.6885 | Actual Loss: 1.2108\n",
      "Baseline Loss: 3.3002 | Actual Loss: 1.2173\n",
      "Baseline Loss: 3.4695 | Actual Loss: 3.0683\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.0214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 54/1000 [00:34<09:54,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5623 | Actual Loss: 2.8176\n",
      "Baseline Loss: 3.2385 | Actual Loss: 2.4252\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.8673\n",
      "Epoch 54/1000: Train Loss: 1.1553, Val Loss: 1.7829\n",
      "Baseline Loss: 3.8780 | Actual Loss: 1.2604\n",
      "Baseline Loss: 3.7221 | Actual Loss: 0.6880\n",
      "Baseline Loss: 3.4292 | Actual Loss: 0.8165\n",
      "Baseline Loss: 3.4937 | Actual Loss: 0.9864\n",
      "Baseline Loss: 3.6364 | Actual Loss: 1.4349\n",
      "Baseline Loss: 3.5203 | Actual Loss: 0.7597\n",
      "Baseline Loss: 3.7882 | Actual Loss: 0.6439\n",
      "Baseline Loss: 3.5444 | Actual Loss: 2.2752\n",
      "Baseline Loss: 3.3304 | Actual Loss: 0.9042\n",
      "Baseline Loss: 3.4470 | Actual Loss: 1.5399\n",
      "Baseline Loss: 3.4174 | Actual Loss: 1.5370\n",
      "Baseline Loss: 3.4321 | Actual Loss: 1.3684\n",
      "Baseline Loss: 3.8321 | Actual Loss: 1.8460\n",
      "Baseline Loss: 3.4659 | Actual Loss: 1.0954\n",
      "Baseline Loss: 3.5833 | Actual Loss: 0.7738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 55/1000 [00:34<10:02,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.2575 | Actual Loss: 1.1056\n",
      "Baseline Loss: 3.3892 | Actual Loss: 0.9831\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.4128\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.5051\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.8710\n",
      "Epoch 55/1000: Train Loss: 1.1897, Val Loss: 1.1930\n",
      "Baseline Loss: 3.4025 | Actual Loss: 1.4088\n",
      "Baseline Loss: 3.7623 | Actual Loss: 0.8513\n",
      "Baseline Loss: 3.5094 | Actual Loss: 1.0810\n",
      "Baseline Loss: 3.5491 | Actual Loss: 0.8062\n",
      "Baseline Loss: 3.4035 | Actual Loss: 0.6447\n",
      "Baseline Loss: 3.4250 | Actual Loss: 1.0434\n",
      "Baseline Loss: 3.6130 | Actual Loss: 0.8945\n",
      "Baseline Loss: 3.6544 | Actual Loss: 1.6552\n",
      "Baseline Loss: 3.3717 | Actual Loss: 0.5935\n",
      "Baseline Loss: 3.6279 | Actual Loss: 0.8067\n",
      "Baseline Loss: 3.4667 | Actual Loss: 1.0668\n",
      "Baseline Loss: 3.3925 | Actual Loss: 0.9555\n",
      "Baseline Loss: 3.6409 | Actual Loss: 1.9790\n",
      "Baseline Loss: 3.7371 | Actual Loss: 1.4775\n",
      "Baseline Loss: 3.7321 | Actual Loss: 1.7112\n",
      "Baseline Loss: 3.0775 | Actual Loss: 0.3542\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.0279\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.2746\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.4799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 56/1000 [00:35<09:45,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3263 | Actual Loss: 0.9330\n",
      "Epoch 56/1000: Train Loss: 1.0831, Val Loss: 1.1789\n",
      "Baseline Loss: 3.6371 | Actual Loss: 1.1567\n",
      "Baseline Loss: 3.6631 | Actual Loss: 1.1685\n",
      "Baseline Loss: 3.3603 | Actual Loss: 1.0599\n",
      "Baseline Loss: 3.7988 | Actual Loss: 1.3283\n",
      "Baseline Loss: 3.8597 | Actual Loss: 0.8043\n",
      "Baseline Loss: 3.4959 | Actual Loss: 1.2271\n",
      "Baseline Loss: 3.4135 | Actual Loss: 0.7895\n",
      "Baseline Loss: 3.4893 | Actual Loss: 0.3799\n",
      "Baseline Loss: 3.5834 | Actual Loss: 1.0384\n",
      "Baseline Loss: 3.3444 | Actual Loss: 0.7679\n",
      "Baseline Loss: 3.5373 | Actual Loss: 0.8089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 57/1000 [00:35<09:41,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5832 | Actual Loss: 0.4299\n",
      "Baseline Loss: 3.5671 | Actual Loss: 0.6581\n",
      "Baseline Loss: 3.5500 | Actual Loss: 1.0793\n",
      "Baseline Loss: 3.3719 | Actual Loss: 1.0448\n",
      "Baseline Loss: 3.6059 | Actual Loss: 1.3214\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.0706\n",
      "Baseline Loss: 3.5623 | Actual Loss: 2.2560\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.3650\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.7863\n",
      "Epoch 57/1000: Train Loss: 0.9414, Val Loss: 1.3695\n",
      "Baseline Loss: 3.6831 | Actual Loss: 2.5572\n",
      "Baseline Loss: 3.5410 | Actual Loss: 0.7862\n",
      "Baseline Loss: 3.3752 | Actual Loss: 1.0033\n",
      "Baseline Loss: 3.6226 | Actual Loss: 0.9447\n",
      "Baseline Loss: 3.5629 | Actual Loss: 0.7505\n",
      "Baseline Loss: 3.6360 | Actual Loss: 0.9899\n",
      "Baseline Loss: 3.3643 | Actual Loss: 0.7794\n",
      "Baseline Loss: 3.4846 | Actual Loss: 0.9625\n",
      "Baseline Loss: 3.5743 | Actual Loss: 1.1021\n",
      "Baseline Loss: 3.5405 | Actual Loss: 0.6360\n",
      "Baseline Loss: 3.4626 | Actual Loss: 1.1394\n",
      "Baseline Loss: 3.5832 | Actual Loss: 1.0379\n",
      "Baseline Loss: 3.7998 | Actual Loss: 1.6757\n",
      "Baseline Loss: 3.4398 | Actual Loss: 1.1462\n",
      "Baseline Loss: 3.6226 | Actual Loss: 2.7288\n",
      "Baseline Loss: 3.5097 | Actual Loss: 3.3611\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.0184\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.6815\n",
      "Baseline Loss: 3.2385 | Actual Loss: 2.5758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 58/1000 [00:36<09:56,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3263 | Actual Loss: 0.7385\n",
      "Epoch 58/1000: Train Loss: 1.3500, Val Loss: 1.5036\n",
      "Baseline Loss: 3.6971 | Actual Loss: 0.9227\n",
      "Baseline Loss: 3.5400 | Actual Loss: 0.8656\n",
      "Baseline Loss: 3.5022 | Actual Loss: 0.5034\n",
      "Baseline Loss: 3.6143 | Actual Loss: 1.3335\n",
      "Baseline Loss: 3.4625 | Actual Loss: 0.6401\n",
      "Baseline Loss: 3.7267 | Actual Loss: 0.8101\n",
      "Baseline Loss: 3.5284 | Actual Loss: 0.5693\n",
      "Baseline Loss: 3.4663 | Actual Loss: 1.5466\n",
      "Baseline Loss: 3.6775 | Actual Loss: 1.4267\n",
      "Baseline Loss: 3.4354 | Actual Loss: 1.3645\n",
      "Baseline Loss: 3.3888 | Actual Loss: 0.7571\n",
      "Baseline Loss: 3.3925 | Actual Loss: 1.0889\n",
      "Baseline Loss: 3.7468 | Actual Loss: 1.1982\n",
      "Baseline Loss: 3.5062 | Actual Loss: 0.9727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 59/1000 [00:37<09:37,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6090 | Actual Loss: 0.9735\n",
      "Baseline Loss: 3.4789 | Actual Loss: 0.4982\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.0130\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.3700\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.5004\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.8217\n",
      "Epoch 59/1000: Train Loss: 0.9669, Val Loss: 1.1763\n",
      "Baseline Loss: 3.5367 | Actual Loss: 0.6306\n",
      "Baseline Loss: 3.4510 | Actual Loss: 0.8285\n",
      "Baseline Loss: 3.5045 | Actual Loss: 0.4074\n",
      "Baseline Loss: 3.6556 | Actual Loss: 1.0471\n",
      "Baseline Loss: 3.5285 | Actual Loss: 0.6201\n",
      "Baseline Loss: 3.5752 | Actual Loss: 2.4705\n",
      "Baseline Loss: 3.6184 | Actual Loss: 1.3802\n",
      "Baseline Loss: 3.6496 | Actual Loss: 0.6807\n",
      "Baseline Loss: 3.6315 | Actual Loss: 1.0664\n",
      "Baseline Loss: 3.6089 | Actual Loss: 0.9471\n",
      "Baseline Loss: 3.6232 | Actual Loss: 0.8114\n",
      "Baseline Loss: 3.2980 | Actual Loss: 0.9986\n",
      "Baseline Loss: 3.4462 | Actual Loss: 1.1232\n",
      "Baseline Loss: 3.5162 | Actual Loss: 0.6131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 60/1000 [00:37<09:47,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5656 | Actual Loss: 1.8186\n",
      "Baseline Loss: 3.5723 | Actual Loss: 3.0662\n",
      "Baseline Loss: 3.3892 | Actual Loss: 0.9366\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.0940\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.4924\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.8393\n",
      "Epoch 60/1000: Train Loss: 1.1569, Val Loss: 1.0905\n",
      "Baseline Loss: 3.4585 | Actual Loss: 0.8391\n",
      "Baseline Loss: 3.5321 | Actual Loss: 0.7770\n",
      "Baseline Loss: 3.3636 | Actual Loss: 0.4020\n",
      "Baseline Loss: 3.4659 | Actual Loss: 1.2115\n",
      "Baseline Loss: 3.3807 | Actual Loss: 0.4036\n",
      "Baseline Loss: 3.5748 | Actual Loss: 1.2487\n",
      "Baseline Loss: 3.4063 | Actual Loss: 1.0620\n",
      "Baseline Loss: 3.8492 | Actual Loss: 1.3720\n",
      "Baseline Loss: 3.6102 | Actual Loss: 2.3611\n",
      "Baseline Loss: 3.5074 | Actual Loss: 0.5749\n",
      "Baseline Loss: 3.8157 | Actual Loss: 1.1556\n",
      "Baseline Loss: 3.7473 | Actual Loss: 1.2585\n",
      "Baseline Loss: 3.4542 | Actual Loss: 0.3205\n",
      "Baseline Loss: 3.6004 | Actual Loss: 1.0625\n",
      "Baseline Loss: 3.7838 | Actual Loss: 1.2117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 61/1000 [00:38<09:42,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3925 | Actual Loss: 1.0446\n",
      "Baseline Loss: 3.3892 | Actual Loss: 0.9638\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.1129\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.6835\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.8234\n",
      "Epoch 61/1000: Train Loss: 1.0191, Val Loss: 1.1459\n",
      "Baseline Loss: 3.6318 | Actual Loss: 0.6911\n",
      "Baseline Loss: 3.4774 | Actual Loss: 0.7743\n",
      "Baseline Loss: 3.4738 | Actual Loss: 1.1237\n",
      "Baseline Loss: 3.7068 | Actual Loss: 0.6094\n",
      "Baseline Loss: 3.6406 | Actual Loss: 0.7987\n",
      "Baseline Loss: 3.6872 | Actual Loss: 1.1135\n",
      "Baseline Loss: 3.5129 | Actual Loss: 0.8959\n",
      "Baseline Loss: 3.5504 | Actual Loss: 0.8654\n",
      "Baseline Loss: 3.4504 | Actual Loss: 1.1420\n",
      "Baseline Loss: 3.4102 | Actual Loss: 0.6808\n",
      "Baseline Loss: 3.6455 | Actual Loss: 3.6599\n",
      "Baseline Loss: 3.4289 | Actual Loss: 0.2225\n",
      "Baseline Loss: 3.9377 | Actual Loss: 2.8793\n",
      "Baseline Loss: 3.3447 | Actual Loss: 3.1148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 62/1000 [00:39<09:59,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5534 | Actual Loss: 2.0600\n",
      "Baseline Loss: 3.0741 | Actual Loss: 0.9443\n",
      "Baseline Loss: 3.3892 | Actual Loss: 0.9395\n",
      "Baseline Loss: 3.5623 | Actual Loss: 2.5386\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.3791\n",
      "Baseline Loss: 3.3263 | Actual Loss: 1.2018\n",
      "Epoch 62/1000: Train Loss: 1.3485, Val Loss: 1.5148\n",
      "Baseline Loss: 3.6877 | Actual Loss: 0.7501\n",
      "Baseline Loss: 3.6186 | Actual Loss: 0.6314\n",
      "Baseline Loss: 3.4766 | Actual Loss: 0.7321\n",
      "Baseline Loss: 3.6507 | Actual Loss: 1.5075\n",
      "Baseline Loss: 3.5960 | Actual Loss: 0.9891\n",
      "Baseline Loss: 3.3776 | Actual Loss: 0.8348\n",
      "Baseline Loss: 3.6045 | Actual Loss: 2.0645\n",
      "Baseline Loss: 3.7727 | Actual Loss: 1.1686\n",
      "Baseline Loss: 3.5041 | Actual Loss: 1.1199\n",
      "Baseline Loss: 3.6770 | Actual Loss: 0.9043\n",
      "Baseline Loss: 3.6003 | Actual Loss: 0.6961\n",
      "Baseline Loss: 3.3747 | Actual Loss: 0.9436\n",
      "Baseline Loss: 3.8325 | Actual Loss: 0.4141\n",
      "Baseline Loss: 3.4905 | Actual Loss: 0.3501\n",
      "Baseline Loss: 3.4330 | Actual Loss: 1.4345\n",
      "Baseline Loss: 3.5516 | Actual Loss: 2.0963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 63/1000 [00:39<10:06,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3892 | Actual Loss: 0.9816\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.8591\n",
      "Baseline Loss: 3.2385 | Actual Loss: 2.1463\n",
      "Baseline Loss: 3.3263 | Actual Loss: 1.1892\n",
      "Epoch 63/1000: Train Loss: 1.0398, Val Loss: 1.5441\n",
      "Baseline Loss: 3.5244 | Actual Loss: 0.7897\n",
      "Baseline Loss: 3.6829 | Actual Loss: 3.5912\n",
      "Baseline Loss: 3.6057 | Actual Loss: 0.8256\n",
      "Baseline Loss: 3.4070 | Actual Loss: 0.5971\n",
      "Baseline Loss: 3.6272 | Actual Loss: 1.2033\n",
      "Baseline Loss: 3.4703 | Actual Loss: 0.7834\n",
      "Baseline Loss: 3.5656 | Actual Loss: 0.9153\n",
      "Baseline Loss: 3.4773 | Actual Loss: 0.8314\n",
      "Baseline Loss: 3.8549 | Actual Loss: 1.5991\n",
      "Baseline Loss: 3.6223 | Actual Loss: 0.5985\n",
      "Baseline Loss: 3.6972 | Actual Loss: 0.9532\n",
      "Baseline Loss: 3.5128 | Actual Loss: 0.6965\n",
      "Baseline Loss: 3.5925 | Actual Loss: 0.8890\n",
      "Baseline Loss: 3.5053 | Actual Loss: 1.2857\n",
      "Baseline Loss: 3.5209 | Actual Loss: 1.9162\n",
      "Baseline Loss: 3.2421 | Actual Loss: 0.5114\n",
      "Baseline Loss: 3.3892 | Actual Loss: 0.9745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 64/1000 [00:40<10:09,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5623 | Actual Loss: 1.4009\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.6981\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.8886\n",
      "Epoch 64/1000: Train Loss: 1.1242, Val Loss: 1.2405\n",
      "Baseline Loss: 3.5667 | Actual Loss: 2.8477\n",
      "Baseline Loss: 3.4772 | Actual Loss: 1.8446\n",
      "Baseline Loss: 3.5788 | Actual Loss: 0.4226\n",
      "Baseline Loss: 3.6687 | Actual Loss: 0.8110\n",
      "Baseline Loss: 3.6229 | Actual Loss: 2.6002\n",
      "Baseline Loss: 3.6271 | Actual Loss: 0.7189\n",
      "Baseline Loss: 3.5089 | Actual Loss: 1.2376\n",
      "Baseline Loss: 3.6591 | Actual Loss: 0.7283\n",
      "Baseline Loss: 3.3679 | Actual Loss: 1.3620\n",
      "Baseline Loss: 3.5085 | Actual Loss: 0.8895\n",
      "Baseline Loss: 3.4502 | Actual Loss: 0.8912\n",
      "Baseline Loss: 3.4059 | Actual Loss: 1.1145\n",
      "Baseline Loss: 3.5085 | Actual Loss: 1.6784\n",
      "Baseline Loss: 3.5922 | Actual Loss: 0.7923\n",
      "Baseline Loss: 3.5214 | Actual Loss: 2.5594\n",
      "Baseline Loss: 3.1962 | Actual Loss: 1.2543\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.3055\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.0162\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.4122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 65/1000 [00:40<09:53,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3263 | Actual Loss: 0.8070\n",
      "Epoch 65/1000: Train Loss: 1.3595, Val Loss: 1.1352\n",
      "Baseline Loss: 3.5004 | Actual Loss: 0.8303\n",
      "Baseline Loss: 3.3586 | Actual Loss: 0.9118\n",
      "Baseline Loss: 3.5324 | Actual Loss: 0.5573\n",
      "Baseline Loss: 3.2880 | Actual Loss: 1.1151\n",
      "Baseline Loss: 3.4888 | Actual Loss: 0.7912\n",
      "Baseline Loss: 3.7782 | Actual Loss: 2.0776\n",
      "Baseline Loss: 3.5408 | Actual Loss: 1.0753\n",
      "Baseline Loss: 3.4206 | Actual Loss: 0.9143\n",
      "Baseline Loss: 3.4277 | Actual Loss: 0.8215\n",
      "Baseline Loss: 3.7221 | Actual Loss: 1.5896\n",
      "Baseline Loss: 3.5620 | Actual Loss: 0.5700\n",
      "Baseline Loss: 3.7416 | Actual Loss: 0.7709\n",
      "Baseline Loss: 3.6597 | Actual Loss: 0.6634\n",
      "Baseline Loss: 3.6546 | Actual Loss: 1.9456\n",
      "Baseline Loss: 3.3758 | Actual Loss: 0.9388\n",
      "Baseline Loss: 3.6056 | Actual Loss: 0.8029\n",
      "Baseline Loss: 3.3892 | Actual Loss: 0.9460\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.1559\n",
      "Baseline Loss: 3.2385 | Actual Loss: 2.0583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 66/1000 [00:41<09:57,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3263 | Actual Loss: 0.7836\n",
      "Epoch 66/1000: Train Loss: 1.0235, Val Loss: 1.2360\n",
      "Baseline Loss: 3.5793 | Actual Loss: 1.2125\n",
      "Baseline Loss: 3.5745 | Actual Loss: 0.8880\n",
      "Baseline Loss: 3.5580 | Actual Loss: 0.4929\n",
      "Baseline Loss: 3.5873 | Actual Loss: 1.9938\n",
      "Baseline Loss: 3.6460 | Actual Loss: 0.4134\n",
      "Baseline Loss: 3.4512 | Actual Loss: 0.6879\n",
      "Baseline Loss: 3.4732 | Actual Loss: 1.4344\n",
      "Baseline Loss: 3.5835 | Actual Loss: 2.8311\n",
      "Baseline Loss: 3.4363 | Actual Loss: 1.1234\n",
      "Baseline Loss: 3.4102 | Actual Loss: 1.1693\n",
      "Baseline Loss: 3.5370 | Actual Loss: 0.8468\n",
      "Baseline Loss: 3.5534 | Actual Loss: 2.5361\n",
      "Baseline Loss: 3.3886 | Actual Loss: 1.2373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 67/1000 [00:42<09:47,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7224 | Actual Loss: 1.2118\n",
      "Baseline Loss: 3.4035 | Actual Loss: 0.8671\n",
      "Baseline Loss: 3.3931 | Actual Loss: 0.6410\n",
      "Baseline Loss: 3.3892 | Actual Loss: 0.9995\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.1845\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.4228\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.9611\n",
      "Epoch 67/1000: Train Loss: 1.2242, Val Loss: 1.1420\n",
      "Baseline Loss: 3.7167 | Actual Loss: 2.2269\n",
      "Baseline Loss: 3.5656 | Actual Loss: 0.6622\n",
      "Baseline Loss: 3.5716 | Actual Loss: 1.2117\n",
      "Baseline Loss: 3.3786 | Actual Loss: 0.8750\n",
      "Baseline Loss: 3.4262 | Actual Loss: 0.8712\n",
      "Baseline Loss: 3.5846 | Actual Loss: 0.6646\n",
      "Baseline Loss: 3.4545 | Actual Loss: 0.3447\n",
      "Baseline Loss: 3.4977 | Actual Loss: 0.4468\n",
      "Baseline Loss: 3.6263 | Actual Loss: 3.4831\n",
      "Baseline Loss: 3.8377 | Actual Loss: 1.3826\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.3587\n",
      "Baseline Loss: 3.5122 | Actual Loss: 1.1370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 68/1000 [00:42<09:50,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4771 | Actual Loss: 2.3518\n",
      "Baseline Loss: 3.5699 | Actual Loss: 0.9399\n",
      "Baseline Loss: 3.5051 | Actual Loss: 2.6341\n",
      "Baseline Loss: 3.2896 | Actual Loss: 0.6255\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.1688\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.2283\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.7583\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.8497\n",
      "Epoch 68/1000: Train Loss: 1.3260, Val Loss: 1.2513\n",
      "Baseline Loss: 3.3337 | Actual Loss: 1.1688\n",
      "Baseline Loss: 3.6925 | Actual Loss: 0.9418\n",
      "Baseline Loss: 3.5877 | Actual Loss: 2.8518\n",
      "Baseline Loss: 3.3503 | Actual Loss: 1.1015\n",
      "Baseline Loss: 3.5132 | Actual Loss: 0.7997\n",
      "Baseline Loss: 3.6011 | Actual Loss: 1.0187\n",
      "Baseline Loss: 3.4358 | Actual Loss: 1.1763\n",
      "Baseline Loss: 3.6180 | Actual Loss: 0.8052\n",
      "Baseline Loss: 3.6638 | Actual Loss: 1.4384\n",
      "Baseline Loss: 3.5010 | Actual Loss: 2.6548\n",
      "Baseline Loss: 3.6409 | Actual Loss: 1.0373\n",
      "Baseline Loss: 3.3601 | Actual Loss: 1.9546\n",
      "Baseline Loss: 3.5179 | Actual Loss: 1.3358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 69/1000 [00:43<09:49,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7993 | Actual Loss: 1.1005\n",
      "Baseline Loss: 3.6645 | Actual Loss: 0.5228\n",
      "Baseline Loss: 3.2653 | Actual Loss: 1.2120\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.0601\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.2441\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.4844\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.9809\n",
      "Epoch 69/1000: Train Loss: 1.3200, Val Loss: 1.1924\n",
      "Baseline Loss: 3.3537 | Actual Loss: 1.0235\n",
      "Baseline Loss: 3.4931 | Actual Loss: 0.5859\n",
      "Baseline Loss: 3.3511 | Actual Loss: 0.8463\n",
      "Baseline Loss: 3.6781 | Actual Loss: 0.7025\n",
      "Baseline Loss: 3.7891 | Actual Loss: 0.5910\n",
      "Baseline Loss: 3.6320 | Actual Loss: 0.5523\n",
      "Baseline Loss: 3.5301 | Actual Loss: 0.6141\n",
      "Baseline Loss: 3.6055 | Actual Loss: 0.9332\n",
      "Baseline Loss: 3.5579 | Actual Loss: 0.7890\n",
      "Baseline Loss: 3.6098 | Actual Loss: 0.7290\n",
      "Baseline Loss: 3.4106 | Actual Loss: 1.3994\n",
      "Baseline Loss: 3.4318 | Actual Loss: 1.0334\n",
      "Baseline Loss: 3.6147 | Actual Loss: 0.9087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 70/1000 [00:44<09:40,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5333 | Actual Loss: 1.2960\n",
      "Baseline Loss: 3.6453 | Actual Loss: 0.9161\n",
      "Baseline Loss: 3.3654 | Actual Loss: 0.8745\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.0852\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.3844\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.3316\n",
      "Baseline Loss: 3.3263 | Actual Loss: 1.2412\n",
      "Epoch 70/1000: Train Loss: 0.8622, Val Loss: 1.2606\n",
      "Baseline Loss: 3.4033 | Actual Loss: 1.0845\n",
      "Baseline Loss: 3.3577 | Actual Loss: 0.9530\n",
      "Baseline Loss: 3.4810 | Actual Loss: 1.0053\n",
      "Baseline Loss: 3.3997 | Actual Loss: 0.5926\n",
      "Baseline Loss: 3.7619 | Actual Loss: 0.8504\n",
      "Baseline Loss: 3.5664 | Actual Loss: 4.4674\n",
      "Baseline Loss: 3.7835 | Actual Loss: 2.3971\n",
      "Baseline Loss: 3.4689 | Actual Loss: 0.7050\n",
      "Baseline Loss: 3.5011 | Actual Loss: 0.7763\n",
      "Baseline Loss: 3.6180 | Actual Loss: 1.6301\n",
      "Baseline Loss: 3.6181 | Actual Loss: 1.2569\n",
      "Baseline Loss: 3.4589 | Actual Loss: 0.9158\n",
      "Baseline Loss: 3.6782 | Actual Loss: 0.7235\n",
      "Baseline Loss: 3.5709 | Actual Loss: 0.6437\n",
      "Baseline Loss: 3.3967 | Actual Loss: 0.7913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 71/1000 [00:44<09:41,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.2336 | Actual Loss: 0.4505\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.1861\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.2917\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.2661\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.9487\n",
      "Epoch 71/1000: Train Loss: 1.2027, Val Loss: 1.1732\n",
      "Baseline Loss: 3.7219 | Actual Loss: 1.1738\n",
      "Baseline Loss: 3.6406 | Actual Loss: 0.6433\n",
      "Baseline Loss: 3.7778 | Actual Loss: 0.5985\n",
      "Baseline Loss: 3.4180 | Actual Loss: 1.0612\n",
      "Baseline Loss: 3.5579 | Actual Loss: 0.3778\n",
      "Baseline Loss: 3.6416 | Actual Loss: 1.4830\n",
      "Baseline Loss: 3.5453 | Actual Loss: 0.7166\n",
      "Baseline Loss: 3.5253 | Actual Loss: 0.8775\n",
      "Baseline Loss: 3.6974 | Actual Loss: 1.1531\n",
      "Baseline Loss: 3.6052 | Actual Loss: 1.2515\n",
      "Baseline Loss: 3.5533 | Actual Loss: 0.8605\n",
      "Baseline Loss: 3.7882 | Actual Loss: 1.1989\n",
      "Baseline Loss: 3.3210 | Actual Loss: 0.8628\n",
      "Baseline Loss: 3.3214 | Actual Loss: 0.9491\n",
      "Baseline Loss: 3.3343 | Actual Loss: 0.8752\n",
      "Baseline Loss: 3.4497 | Actual Loss: 0.7002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 72/1000 [00:45<09:54,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3892 | Actual Loss: 1.0338\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.3770\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.2096\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.9016\n",
      "Epoch 72/1000: Train Loss: 0.9239, Val Loss: 1.1305\n",
      "Baseline Loss: 3.9073 | Actual Loss: 2.0609\n",
      "Baseline Loss: 3.5793 | Actual Loss: 0.6918\n",
      "Baseline Loss: 3.6315 | Actual Loss: 0.6570\n",
      "Baseline Loss: 3.5832 | Actual Loss: 0.4986\n",
      "Baseline Loss: 3.3608 | Actual Loss: 0.8076\n",
      "Baseline Loss: 3.5034 | Actual Loss: 1.6789\n",
      "Baseline Loss: 3.4136 | Actual Loss: 0.5540\n",
      "Baseline Loss: 3.6150 | Actual Loss: 0.7246\n",
      "Baseline Loss: 3.4959 | Actual Loss: 0.8086\n",
      "Baseline Loss: 3.7218 | Actual Loss: 0.8143\n",
      "Baseline Loss: 3.5574 | Actual Loss: 0.4625\n",
      "Baseline Loss: 3.5462 | Actual Loss: 0.6290\n",
      "Baseline Loss: 3.5965 | Actual Loss: 1.1902\n",
      "Baseline Loss: 3.5383 | Actual Loss: 0.8470\n",
      "Baseline Loss: 3.3782 | Actual Loss: 0.8656\n",
      "Baseline Loss: 3.1965 | Actual Loss: 1.1506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 73/1000 [00:46<09:40,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3892 | Actual Loss: 0.8939\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.1309\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.2987\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.9660\n",
      "Epoch 73/1000: Train Loss: 0.9026, Val Loss: 1.0724\n",
      "Baseline Loss: 3.9130 | Actual Loss: 1.9541\n",
      "Baseline Loss: 3.5162 | Actual Loss: 1.0245\n",
      "Baseline Loss: 3.4034 | Actual Loss: 1.0164\n",
      "Baseline Loss: 3.5039 | Actual Loss: 1.4439\n",
      "Baseline Loss: 3.5668 | Actual Loss: 1.4142\n",
      "Baseline Loss: 3.4665 | Actual Loss: 0.6970\n",
      "Baseline Loss: 3.3076 | Actual Loss: 0.5660\n",
      "Baseline Loss: 3.4815 | Actual Loss: 0.9883\n",
      "Baseline Loss: 3.4098 | Actual Loss: 0.6131\n",
      "Baseline Loss: 3.7830 | Actual Loss: 0.7556\n",
      "Baseline Loss: 3.6737 | Actual Loss: 0.6064\n",
      "Baseline Loss: 3.5100 | Actual Loss: 0.5904\n",
      "Baseline Loss: 3.7936 | Actual Loss: 0.9145\n",
      "Baseline Loss: 3.3816 | Actual Loss: 0.6839\n",
      "Baseline Loss: 3.8103 | Actual Loss: 1.1896\n",
      "Baseline Loss: 3.2896 | Actual Loss: 1.1702\n",
      "Baseline Loss: 3.3892 | Actual Loss: 0.9607\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.3909\n",
      "Baseline Loss: 3.2385 | Actual Loss: 2.1259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 74/1000 [00:46<09:41,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3263 | Actual Loss: 0.6969\n",
      "Epoch 74/1000: Train Loss: 0.9768, Val Loss: 1.2936\n",
      "Baseline Loss: 3.6557 | Actual Loss: 0.7971\n",
      "Baseline Loss: 3.5258 | Actual Loss: 0.5101\n",
      "Baseline Loss: 3.7423 | Actual Loss: 0.9424\n",
      "Baseline Loss: 3.6002 | Actual Loss: 0.7796\n",
      "Baseline Loss: 3.4247 | Actual Loss: 1.0832\n",
      "Baseline Loss: 3.6186 | Actual Loss: 0.5218\n",
      "Baseline Loss: 3.5833 | Actual Loss: 0.6709\n",
      "Baseline Loss: 3.4471 | Actual Loss: 0.8589\n",
      "Baseline Loss: 3.7994 | Actual Loss: 1.5750\n",
      "Baseline Loss: 3.3439 | Actual Loss: 0.8014\n",
      "Baseline Loss: 3.7020 | Actual Loss: 0.3809\n",
      "Baseline Loss: 3.6461 | Actual Loss: 1.6963\n",
      "Baseline Loss: 3.4620 | Actual Loss: 1.5434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 75/1000 [00:47<09:34,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4925 | Actual Loss: 0.4300\n",
      "Baseline Loss: 3.4318 | Actual Loss: 1.3753\n",
      "Baseline Loss: 3.6292 | Actual Loss: 2.3496\n",
      "Baseline Loss: 3.3892 | Actual Loss: 0.9360\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.2350\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.4918\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.7687\n",
      "Epoch 75/1000: Train Loss: 1.0197, Val Loss: 1.1079\n",
      "Baseline Loss: 3.6180 | Actual Loss: 0.3681\n",
      "Baseline Loss: 3.3997 | Actual Loss: 0.3137\n",
      "Baseline Loss: 3.6235 | Actual Loss: 1.3222\n",
      "Baseline Loss: 3.5378 | Actual Loss: 0.7812\n",
      "Baseline Loss: 3.5505 | Actual Loss: 0.6392\n",
      "Baseline Loss: 3.4130 | Actual Loss: 0.9784\n",
      "Baseline Loss: 3.4092 | Actual Loss: 0.8686\n",
      "Baseline Loss: 3.7577 | Actual Loss: 1.0345\n",
      "Baseline Loss: 3.5578 | Actual Loss: 0.6151\n",
      "Baseline Loss: 3.5166 | Actual Loss: 0.8468\n",
      "Baseline Loss: 3.4287 | Actual Loss: 0.9388\n",
      "Baseline Loss: 3.5495 | Actual Loss: 1.0864\n",
      "Baseline Loss: 3.6546 | Actual Loss: 2.2286\n",
      "Baseline Loss: 3.5742 | Actual Loss: 0.5714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 76/1000 [00:47<09:35,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5301 | Actual Loss: 0.6036\n",
      "Baseline Loss: 3.6892 | Actual Loss: 3.0428\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.0350\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.0841\n",
      "Baseline Loss: 3.2385 | Actual Loss: 2.0404\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.9124\n",
      "Epoch 76/1000: Train Loss: 1.0150, Val Loss: 1.2680\n",
      "Baseline Loss: 3.6689 | Actual Loss: 0.9901\n",
      "Baseline Loss: 3.9372 | Actual Loss: 1.0379\n",
      "Baseline Loss: 3.7574 | Actual Loss: 2.8698\n",
      "Baseline Loss: 3.7218 | Actual Loss: 0.7663\n",
      "Baseline Loss: 3.3350 | Actual Loss: 0.9270\n",
      "Baseline Loss: 3.4241 | Actual Loss: 1.0845\n",
      "Baseline Loss: 3.4436 | Actual Loss: 0.9102\n",
      "Baseline Loss: 3.4586 | Actual Loss: 0.7926\n",
      "Baseline Loss: 3.5324 | Actual Loss: 0.9409\n",
      "Baseline Loss: 3.8268 | Actual Loss: 0.4026\n",
      "Baseline Loss: 3.5332 | Actual Loss: 0.9711\n",
      "Baseline Loss: 3.5535 | Actual Loss: 1.1713\n",
      "Baseline Loss: 3.4779 | Actual Loss: 1.0520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 77/1000 [00:48<09:42,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5497 | Actual Loss: 0.6406\n",
      "Baseline Loss: 3.3808 | Actual Loss: 0.7101\n",
      "Baseline Loss: 3.2491 | Actual Loss: 2.6751\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.0523\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.3943\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.3854\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.8145\n",
      "Epoch 77/1000: Train Loss: 1.1214, Val Loss: 1.1616\n",
      "Baseline Loss: 3.5375 | Actual Loss: 0.9449\n",
      "Baseline Loss: 3.6320 | Actual Loss: 1.6707\n",
      "Baseline Loss: 3.5832 | Actual Loss: 0.6809\n",
      "Baseline Loss: 3.7218 | Actual Loss: 1.0146\n",
      "Baseline Loss: 3.4801 | Actual Loss: 0.5692\n",
      "Baseline Loss: 3.4585 | Actual Loss: 0.9722\n",
      "Baseline Loss: 3.5414 | Actual Loss: 0.8958\n",
      "Baseline Loss: 3.5966 | Actual Loss: 0.4724\n",
      "Baseline Loss: 3.6733 | Actual Loss: 2.7586\n",
      "Baseline Loss: 3.4097 | Actual Loss: 1.3958\n",
      "Baseline Loss: 3.4736 | Actual Loss: 0.4331\n",
      "Baseline Loss: 3.3824 | Actual Loss: 1.0030\n",
      "Baseline Loss: 3.5042 | Actual Loss: 1.0971\n",
      "Baseline Loss: 3.5959 | Actual Loss: 0.3765\n",
      "Baseline Loss: 3.9130 | Actual Loss: 0.8040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 78/1000 [00:49<09:29,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4115 | Actual Loss: 0.3077\n",
      "Baseline Loss: 3.3892 | Actual Loss: 0.9162\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.2253\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.6611\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.7994\n",
      "Epoch 78/1000: Train Loss: 0.9623, Val Loss: 1.1505\n",
      "Baseline Loss: 3.5287 | Actual Loss: 1.0965\n",
      "Baseline Loss: 3.6317 | Actual Loss: 1.4514\n",
      "Baseline Loss: 3.5036 | Actual Loss: 0.8040\n",
      "Baseline Loss: 3.5455 | Actual Loss: 0.4276\n",
      "Baseline Loss: 3.5124 | Actual Loss: 0.5374\n",
      "Baseline Loss: 3.7222 | Actual Loss: 0.3220\n",
      "Baseline Loss: 3.7121 | Actual Loss: 2.2633\n",
      "Baseline Loss: 3.5663 | Actual Loss: 0.7883\n",
      "Baseline Loss: 3.5373 | Actual Loss: 1.5084\n",
      "Baseline Loss: 3.4963 | Actual Loss: 0.5673\n",
      "Baseline Loss: 3.4437 | Actual Loss: 0.6129\n",
      "Baseline Loss: 3.4322 | Actual Loss: 0.9434\n",
      "Baseline Loss: 3.7731 | Actual Loss: 0.7242\n",
      "Baseline Loss: 3.5089 | Actual Loss: 0.5512\n",
      "Baseline Loss: 3.7023 | Actual Loss: 0.4947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 79/1000 [00:49<09:28,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4207 | Actual Loss: 0.6560\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.0028\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.1806\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.0940\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.7742\n",
      "Epoch 79/1000: Train Loss: 0.8593, Val Loss: 1.0129\n",
      "Baseline Loss: 3.5872 | Actual Loss: 0.9133\n",
      "Baseline Loss: 3.6596 | Actual Loss: 1.3339\n",
      "Baseline Loss: 3.4777 | Actual Loss: 0.8837\n",
      "Baseline Loss: 3.5544 | Actual Loss: 0.4509\n",
      "Baseline Loss: 3.5006 | Actual Loss: 1.0055\n",
      "Baseline Loss: 3.4542 | Actual Loss: 0.4605\n",
      "Baseline Loss: 3.8267 | Actual Loss: 0.9269\n",
      "Baseline Loss: 3.6184 | Actual Loss: 0.5903\n",
      "Baseline Loss: 3.9437 | Actual Loss: 1.0319\n",
      "Baseline Loss: 3.3749 | Actual Loss: 0.4517\n",
      "Baseline Loss: 3.4881 | Actual Loss: 0.5271\n",
      "Baseline Loss: 3.4041 | Actual Loss: 0.9212\n",
      "Baseline Loss: 3.4579 | Actual Loss: 1.9344\n",
      "Baseline Loss: 3.3782 | Actual Loss: 1.0135\n",
      "Baseline Loss: 3.6364 | Actual Loss: 3.4793\n",
      "Baseline Loss: 3.3670 | Actual Loss: 3.1016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 80/1000 [00:50<09:38,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3892 | Actual Loss: 0.9614\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.1872\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.3486\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.7714\n",
      "Epoch 80/1000: Train Loss: 1.1891, Val Loss: 1.0671\n",
      "Baseline Loss: 3.4762 | Actual Loss: 1.6558\n",
      "Baseline Loss: 3.5048 | Actual Loss: 1.1475\n",
      "Baseline Loss: 3.5704 | Actual Loss: 3.5144\n",
      "Baseline Loss: 3.3808 | Actual Loss: 0.5276\n",
      "Baseline Loss: 3.6052 | Actual Loss: 0.9898\n",
      "Baseline Loss: 3.5965 | Actual Loss: 1.4123\n",
      "Baseline Loss: 3.4895 | Actual Loss: 0.7959\n",
      "Baseline Loss: 3.4928 | Actual Loss: 1.1124\n",
      "Baseline Loss: 3.6051 | Actual Loss: 0.8016\n",
      "Baseline Loss: 3.7627 | Actual Loss: 0.6258\n",
      "Baseline Loss: 3.2983 | Actual Loss: 0.6768\n",
      "Baseline Loss: 3.8714 | Actual Loss: 0.6491\n",
      "Baseline Loss: 3.7773 | Actual Loss: 0.8994\n",
      "Baseline Loss: 3.5341 | Actual Loss: 0.5111\n",
      "Baseline Loss: 3.5874 | Actual Loss: 2.5925\n",
      "Baseline Loss: 3.4592 | Actual Loss: 0.4651\n",
      "Baseline Loss: 3.3892 | Actual Loss: 0.9776\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.2287\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.1003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 81/1000 [00:51<09:43,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3263 | Actual Loss: 0.8956\n",
      "Epoch 81/1000: Train Loss: 1.1486, Val Loss: 1.0505\n",
      "Baseline Loss: 3.5834 | Actual Loss: 0.8937\n",
      "Baseline Loss: 3.5541 | Actual Loss: 0.5599\n",
      "Baseline Loss: 3.4317 | Actual Loss: 0.5896\n",
      "Baseline Loss: 3.3073 | Actual Loss: 1.5193\n",
      "Baseline Loss: 3.4920 | Actual Loss: 0.8489\n",
      "Baseline Loss: 3.5258 | Actual Loss: 0.7514\n",
      "Baseline Loss: 3.5494 | Actual Loss: 0.4899\n",
      "Baseline Loss: 3.7836 | Actual Loss: 0.6929\n",
      "Baseline Loss: 3.5287 | Actual Loss: 0.7500\n",
      "Baseline Loss: 3.5747 | Actual Loss: 0.4995\n",
      "Baseline Loss: 3.7729 | Actual Loss: 1.0470\n",
      "Baseline Loss: 3.5874 | Actual Loss: 0.8429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 82/1000 [00:51<09:35,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5720 | Actual Loss: 1.7257\n",
      "Baseline Loss: 3.3956 | Actual Loss: 0.9434\n",
      "Baseline Loss: 3.4656 | Actual Loss: 0.9676\n",
      "Baseline Loss: 3.6175 | Actual Loss: 3.2257\n",
      "Baseline Loss: 3.3892 | Actual Loss: 0.9362\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.3767\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.7274\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.8271\n",
      "Epoch 82/1000: Train Loss: 1.0217, Val Loss: 1.2169\n",
      "Baseline Loss: 3.4549 | Actual Loss: 1.9145\n",
      "Baseline Loss: 3.4774 | Actual Loss: 0.8890\n",
      "Baseline Loss: 3.5045 | Actual Loss: 0.6206\n",
      "Baseline Loss: 3.4580 | Actual Loss: 0.3763\n",
      "Baseline Loss: 3.6501 | Actual Loss: 0.5638\n",
      "Baseline Loss: 3.7423 | Actual Loss: 0.5415\n",
      "Baseline Loss: 3.6277 | Actual Loss: 0.9304\n",
      "Baseline Loss: 3.5962 | Actual Loss: 0.6430\n",
      "Baseline Loss: 3.5339 | Actual Loss: 1.2871\n",
      "Baseline Loss: 3.4884 | Actual Loss: 0.6032\n",
      "Baseline Loss: 3.6639 | Actual Loss: 0.8572\n",
      "Baseline Loss: 3.3854 | Actual Loss: 1.3607\n",
      "Baseline Loss: 3.7792 | Actual Loss: 0.8045\n",
      "Baseline Loss: 3.5124 | Actual Loss: 0.8806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 83/1000 [00:52<09:35,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3849 | Actual Loss: 0.6094\n",
      "Baseline Loss: 3.6407 | Actual Loss: 0.9900\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.1276\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.1636\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.2427\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.8792\n",
      "Epoch 83/1000: Train Loss: 0.8670, Val Loss: 1.1033\n",
      "Baseline Loss: 3.4924 | Actual Loss: 2.1977\n",
      "Baseline Loss: 3.5130 | Actual Loss: 0.9461\n",
      "Baseline Loss: 3.5134 | Actual Loss: 0.4796\n",
      "Baseline Loss: 3.4898 | Actual Loss: 0.8085\n",
      "Baseline Loss: 3.9378 | Actual Loss: 1.4691\n",
      "Baseline Loss: 3.4615 | Actual Loss: 1.0581\n",
      "Baseline Loss: 3.4848 | Actual Loss: 0.6886\n",
      "Baseline Loss: 3.3405 | Actual Loss: 3.0446\n",
      "Baseline Loss: 3.4429 | Actual Loss: 0.9101\n",
      "Baseline Loss: 3.5413 | Actual Loss: 1.5551\n",
      "Baseline Loss: 3.5966 | Actual Loss: 1.1546\n",
      "Baseline Loss: 3.5162 | Actual Loss: 0.4356\n",
      "Baseline Loss: 3.6447 | Actual Loss: 0.3777\n",
      "Baseline Loss: 3.6684 | Actual Loss: 0.7542\n",
      "Baseline Loss: 3.6234 | Actual Loss: 1.7176\n",
      "Baseline Loss: 3.5298 | Actual Loss: 0.8697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 84/1000 [00:52<09:24,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3892 | Actual Loss: 1.0296\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.3970\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.4288\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.9001\n",
      "Epoch 84/1000: Train Loss: 1.1542, Val Loss: 1.1889\n",
      "Baseline Loss: 3.7519 | Actual Loss: 3.6835\n",
      "Baseline Loss: 3.5365 | Actual Loss: 0.7567\n",
      "Baseline Loss: 3.5051 | Actual Loss: 2.2291\n",
      "Baseline Loss: 3.3948 | Actual Loss: 0.6061\n",
      "Baseline Loss: 3.5568 | Actual Loss: 0.7108\n",
      "Baseline Loss: 3.5284 | Actual Loss: 0.5498\n",
      "Baseline Loss: 3.5494 | Actual Loss: 0.7773\n",
      "Baseline Loss: 3.8209 | Actual Loss: 0.2806\n",
      "Baseline Loss: 3.5566 | Actual Loss: 0.6135\n",
      "Baseline Loss: 3.5920 | Actual Loss: 0.1968\n",
      "Baseline Loss: 3.6642 | Actual Loss: 0.6330\n",
      "Baseline Loss: 3.8544 | Actual Loss: 0.3740\n",
      "Baseline Loss: 3.4852 | Actual Loss: 0.8349\n",
      "Baseline Loss: 3.4507 | Actual Loss: 1.5673\n",
      "Baseline Loss: 3.6141 | Actual Loss: 0.3796\n",
      "Baseline Loss: 3.2402 | Actual Loss: 1.2263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 85/1000 [00:53<09:36,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3892 | Actual Loss: 0.9506\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.4456\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.2518\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.8403\n",
      "Epoch 85/1000: Train Loss: 0.9637, Val Loss: 1.1221\n",
      "Baseline Loss: 3.5167 | Actual Loss: 0.6636\n",
      "Baseline Loss: 3.5626 | Actual Loss: 0.4892\n",
      "Baseline Loss: 3.7682 | Actual Loss: 2.2205\n",
      "Baseline Loss: 3.5373 | Actual Loss: 1.2471\n",
      "Baseline Loss: 3.4785 | Actual Loss: 1.1906\n",
      "Baseline Loss: 3.5834 | Actual Loss: 0.3240\n",
      "Baseline Loss: 3.5129 | Actual Loss: 0.3842\n",
      "Baseline Loss: 3.5833 | Actual Loss: 0.1856\n",
      "Baseline Loss: 3.4655 | Actual Loss: 0.5460\n",
      "Baseline Loss: 3.4849 | Actual Loss: 0.8314\n",
      "Baseline Loss: 3.6785 | Actual Loss: 0.6158\n",
      "Baseline Loss: 3.6092 | Actual Loss: 0.5566\n",
      "Baseline Loss: 3.6829 | Actual Loss: 3.0618\n",
      "Baseline Loss: 3.3009 | Actual Loss: 3.0702\n",
      "Baseline Loss: 3.6003 | Actual Loss: 0.9652\n",
      "Baseline Loss: 3.3931 | Actual Loss: 2.2333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▊         | 86/1000 [00:54<09:40,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3892 | Actual Loss: 0.8981\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.2190\n",
      "Baseline Loss: 3.2385 | Actual Loss: 2.3400\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.8482\n",
      "Epoch 86/1000: Train Loss: 1.1616, Val Loss: 1.3263\n",
      "Baseline Loss: 3.6271 | Actual Loss: 1.0958\n",
      "Baseline Loss: 3.8000 | Actual Loss: 0.3313\n",
      "Baseline Loss: 3.3408 | Actual Loss: 0.8739\n",
      "Baseline Loss: 3.6828 | Actual Loss: 2.1590\n",
      "Baseline Loss: 3.7023 | Actual Loss: 1.5936\n",
      "Baseline Loss: 3.5407 | Actual Loss: 0.8248\n",
      "Baseline Loss: 3.4214 | Actual Loss: 0.3666\n",
      "Baseline Loss: 3.5541 | Actual Loss: 0.7122\n",
      "Baseline Loss: 3.7116 | Actual Loss: 0.6790\n",
      "Baseline Loss: 3.4474 | Actual Loss: 0.6084\n",
      "Baseline Loss: 3.5832 | Actual Loss: 0.4769\n",
      "Baseline Loss: 3.3844 | Actual Loss: 0.8754\n",
      "Baseline Loss: 3.4581 | Actual Loss: 0.7792\n",
      "Baseline Loss: 3.6137 | Actual Loss: 0.6803\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.2613\n",
      "Baseline Loss: 3.0567 | Actual Loss: 0.6807\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.0842\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.2037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▊         | 87/1000 [00:54<09:24,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.2385 | Actual Loss: 1.8521\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.8345\n",
      "Epoch 87/1000: Train Loss: 0.8124, Val Loss: 1.2436\n",
      "Baseline Loss: 3.3572 | Actual Loss: 1.3113\n",
      "Baseline Loss: 3.5248 | Actual Loss: 0.6871\n",
      "Baseline Loss: 3.3781 | Actual Loss: 0.7983\n",
      "Baseline Loss: 3.7027 | Actual Loss: 1.9448\n",
      "Baseline Loss: 3.7623 | Actual Loss: 1.6512\n",
      "Baseline Loss: 3.6364 | Actual Loss: 0.6522\n",
      "Baseline Loss: 3.4069 | Actual Loss: 0.9225\n",
      "Baseline Loss: 3.5625 | Actual Loss: 0.7716\n",
      "Baseline Loss: 3.4071 | Actual Loss: 1.2046\n",
      "Baseline Loss: 3.6226 | Actual Loss: 1.3737\n",
      "Baseline Loss: 3.5574 | Actual Loss: 0.6769\n",
      "Baseline Loss: 3.6143 | Actual Loss: 0.4460\n",
      "Baseline Loss: 3.5414 | Actual Loss: 1.3470\n",
      "Baseline Loss: 3.4689 | Actual Loss: 0.4341\n",
      "Baseline Loss: 3.4853 | Actual Loss: 0.7458\n",
      "Baseline Loss: 3.8943 | Actual Loss: 4.0146\n",
      "Baseline Loss: 3.3892 | Actual Loss: 0.9413\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.1498\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.5520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 88/1000 [00:55<09:31,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3263 | Actual Loss: 0.7530\n",
      "Epoch 88/1000: Train Loss: 1.1864, Val Loss: 1.0990\n",
      "Baseline Loss: 3.4773 | Actual Loss: 3.1128\n",
      "Baseline Loss: 3.6365 | Actual Loss: 0.9443\n",
      "Baseline Loss: 3.5329 | Actual Loss: 0.8352\n",
      "Baseline Loss: 3.7831 | Actual Loss: 0.7787\n",
      "Baseline Loss: 3.3964 | Actual Loss: 3.9602\n",
      "Baseline Loss: 3.5203 | Actual Loss: 0.7058\n",
      "Baseline Loss: 3.4113 | Actual Loss: 0.9443\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.5109\n",
      "Baseline Loss: 3.4772 | Actual Loss: 1.0168\n",
      "Baseline Loss: 3.5529 | Actual Loss: 0.7887\n",
      "Baseline Loss: 3.6453 | Actual Loss: 0.5578\n",
      "Baseline Loss: 3.4166 | Actual Loss: 0.3842\n",
      "Baseline Loss: 3.6050 | Actual Loss: 0.6659\n",
      "Baseline Loss: 3.6234 | Actual Loss: 0.4718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 89/1000 [00:55<09:18,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4131 | Actual Loss: 0.5536\n",
      "Baseline Loss: 3.4118 | Actual Loss: 3.3933\n",
      "Baseline Loss: 3.3892 | Actual Loss: 0.9425\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.1487\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.3824\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.9045\n",
      "Epoch 89/1000: Train Loss: 1.2265, Val Loss: 1.0945\n",
      "Baseline Loss: 3.9694 | Actual Loss: 3.4106\n",
      "Baseline Loss: 3.5009 | Actual Loss: 0.4132\n",
      "Baseline Loss: 3.3846 | Actual Loss: 0.5830\n",
      "Baseline Loss: 3.6647 | Actual Loss: 1.0093\n",
      "Baseline Loss: 3.8150 | Actual Loss: 0.2889\n",
      "Baseline Loss: 3.5079 | Actual Loss: 1.8127\n",
      "Baseline Loss: 3.3073 | Actual Loss: 0.7664\n",
      "Baseline Loss: 3.4657 | Actual Loss: 0.6431\n",
      "Baseline Loss: 3.5579 | Actual Loss: 0.7508\n",
      "Baseline Loss: 3.6325 | Actual Loss: 0.9775\n",
      "Baseline Loss: 3.4810 | Actual Loss: 0.5511\n",
      "Baseline Loss: 3.5663 | Actual Loss: 0.5616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 90/1000 [00:56<09:28,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4887 | Actual Loss: 1.1396\n",
      "Baseline Loss: 3.6971 | Actual Loss: 0.9999\n",
      "Baseline Loss: 3.5720 | Actual Loss: 0.7975\n",
      "Baseline Loss: 3.2498 | Actual Loss: 0.3422\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.0549\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.3494\n",
      "Baseline Loss: 3.2385 | Actual Loss: 3.1565\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.8655\n",
      "Epoch 90/1000: Train Loss: 0.9404, Val Loss: 1.6066\n",
      "Baseline Loss: 3.6185 | Actual Loss: 0.6465\n",
      "Baseline Loss: 3.5174 | Actual Loss: 0.8125\n",
      "Baseline Loss: 3.5798 | Actual Loss: 1.0084\n",
      "Baseline Loss: 3.4970 | Actual Loss: 0.3163\n",
      "Baseline Loss: 3.6681 | Actual Loss: 1.0496\n",
      "Baseline Loss: 3.5136 | Actual Loss: 3.1214\n",
      "Baseline Loss: 3.5752 | Actual Loss: 0.4954\n",
      "Baseline Loss: 3.4702 | Actual Loss: 1.2267\n",
      "Baseline Loss: 3.5382 | Actual Loss: 1.0588\n",
      "Baseline Loss: 3.5368 | Actual Loss: 0.9474\n",
      "Baseline Loss: 3.5745 | Actual Loss: 0.7164\n",
      "Baseline Loss: 3.8782 | Actual Loss: 0.9290\n",
      "Baseline Loss: 3.5494 | Actual Loss: 0.9547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 91/1000 [00:57<09:33,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3993 | Actual Loss: 1.0883\n",
      "Baseline Loss: 3.5885 | Actual Loss: 0.8397\n",
      "Baseline Loss: 3.3491 | Actual Loss: 0.5039\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.0944\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.1421\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.3225\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.8230\n",
      "Epoch 91/1000: Train Loss: 0.9822, Val Loss: 1.0955\n",
      "Baseline Loss: 3.5292 | Actual Loss: 0.8649\n",
      "Baseline Loss: 3.8483 | Actual Loss: 3.3580\n",
      "Baseline Loss: 3.4768 | Actual Loss: 0.8388\n",
      "Baseline Loss: 3.8660 | Actual Loss: 0.4691\n",
      "Baseline Loss: 3.5579 | Actual Loss: 0.6216\n",
      "Baseline Loss: 3.6097 | Actual Loss: 0.6545\n",
      "Baseline Loss: 3.7372 | Actual Loss: 0.6664\n",
      "Baseline Loss: 3.5569 | Actual Loss: 1.6237\n",
      "Baseline Loss: 3.3147 | Actual Loss: 0.9468\n",
      "Baseline Loss: 3.4167 | Actual Loss: 1.0280\n",
      "Baseline Loss: 3.5539 | Actual Loss: 1.0001\n",
      "Baseline Loss: 3.6508 | Actual Loss: 0.8451\n",
      "Baseline Loss: 3.5628 | Actual Loss: 0.5807\n",
      "Baseline Loss: 3.5756 | Actual Loss: 0.5907\n",
      "Baseline Loss: 3.5295 | Actual Loss: 0.7730\n",
      "Baseline Loss: 3.2333 | Actual Loss: 0.5890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 92/1000 [00:57<09:20,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3892 | Actual Loss: 0.9718\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.4374\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.4626\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.8726\n",
      "Epoch 92/1000: Train Loss: 0.9656, Val Loss: 1.1861\n",
      "Baseline Loss: 3.4963 | Actual Loss: 0.7416\n",
      "Baseline Loss: 3.6266 | Actual Loss: 0.8287\n",
      "Baseline Loss: 3.6146 | Actual Loss: 1.0161\n",
      "Baseline Loss: 3.4928 | Actual Loss: 0.7395\n",
      "Baseline Loss: 3.6583 | Actual Loss: 0.4904\n",
      "Baseline Loss: 3.3646 | Actual Loss: 0.5148\n",
      "Baseline Loss: 3.5118 | Actual Loss: 1.0109\n",
      "Baseline Loss: 3.5788 | Actual Loss: 2.7829\n",
      "Baseline Loss: 3.5251 | Actual Loss: 1.3454\n",
      "Baseline Loss: 3.4073 | Actual Loss: 1.2136\n",
      "Baseline Loss: 3.6093 | Actual Loss: 0.5351\n",
      "Baseline Loss: 3.6504 | Actual Loss: 0.6658\n",
      "Baseline Loss: 3.5699 | Actual Loss: 0.9963\n",
      "Baseline Loss: 3.5126 | Actual Loss: 0.5208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 93/1000 [00:58<09:34,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4030 | Actual Loss: 0.6408\n",
      "Baseline Loss: 3.4009 | Actual Loss: 0.4076\n",
      "Baseline Loss: 3.3892 | Actual Loss: 0.9736\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.3253\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.3132\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.8286\n",
      "Epoch 93/1000: Train Loss: 0.9031, Val Loss: 1.1102\n",
      "Baseline Loss: 3.7023 | Actual Loss: 0.6896\n",
      "Baseline Loss: 3.8269 | Actual Loss: 0.6917\n",
      "Baseline Loss: 3.3210 | Actual Loss: 0.6560\n",
      "Baseline Loss: 3.5575 | Actual Loss: 0.6362\n",
      "Baseline Loss: 3.6497 | Actual Loss: 0.7426\n",
      "Baseline Loss: 3.4616 | Actual Loss: 1.2232\n",
      "Baseline Loss: 3.6459 | Actual Loss: 0.7800\n",
      "Baseline Loss: 3.8263 | Actual Loss: 0.9637\n",
      "Baseline Loss: 3.5783 | Actual Loss: 0.7191\n",
      "Baseline Loss: 3.4127 | Actual Loss: 0.6959\n",
      "Baseline Loss: 3.4511 | Actual Loss: 0.7653\n",
      "Baseline Loss: 3.4288 | Actual Loss: 0.7949\n",
      "Baseline Loss: 3.4245 | Actual Loss: 0.6165\n",
      "Baseline Loss: 3.7474 | Actual Loss: 0.9959\n",
      "Baseline Loss: 3.4357 | Actual Loss: 2.3013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 94/1000 [00:59<09:32,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.2587 | Actual Loss: 0.2907\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.0672\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.2617\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.5186\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.8506\n",
      "Epoch 94/1000: Train Loss: 0.8477, Val Loss: 1.1745\n",
      "Baseline Loss: 3.6369 | Actual Loss: 0.6725\n",
      "Baseline Loss: 3.7272 | Actual Loss: 0.8284\n",
      "Baseline Loss: 3.4095 | Actual Loss: 0.9567\n",
      "Baseline Loss: 3.4776 | Actual Loss: 0.8964\n",
      "Baseline Loss: 3.2695 | Actual Loss: 1.5297\n",
      "Baseline Loss: 3.3961 | Actual Loss: 1.3698\n",
      "Baseline Loss: 3.3640 | Actual Loss: 1.1657\n",
      "Baseline Loss: 3.7118 | Actual Loss: 0.6374\n",
      "Baseline Loss: 3.4283 | Actual Loss: 0.3738\n",
      "Baseline Loss: 3.6010 | Actual Loss: 1.2038\n",
      "Baseline Loss: 3.5917 | Actual Loss: 0.3258\n",
      "Baseline Loss: 3.6501 | Actual Loss: 0.8986\n",
      "Baseline Loss: 3.4923 | Actual Loss: 0.9601\n",
      "Baseline Loss: 3.5047 | Actual Loss: 0.6679\n",
      "Baseline Loss: 3.7827 | Actual Loss: 0.6288\n",
      "Baseline Loss: 3.5629 | Actual Loss: 0.6813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 94/1000 [00:59<09:35,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3892 | Actual Loss: 0.9865\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.0736\n",
      "Baseline Loss: 3.2385 | Actual Loss: 1.4653\n",
      "Baseline Loss: 3.3263 | Actual Loss: 0.7989\n",
      "Epoch 95/1000: Train Loss: 0.8623, Val Loss: 1.0811\n",
      "\n",
      "Early stopping at epoch 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.906435027718544"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devices = [\"cuda\" if torch.cuda.is_available() else \"cpu\"]\n",
    "model9 = GNNModelWithNewLoss(\n",
    "        num_node_features=data_list[0].x.shape[1],\n",
    "        num_edge_features=data_list[0].edge_attr.shape[1],\n",
    "        num_global_features=0,\n",
    "        cov_num= 9,\n",
    "        hidden_dim=512,\n",
    "        dropout_rate=0.1,\n",
    "        property_index= 2,\n",
    "        save_path= 'premodels_new_og/9/9' \n",
    "    ).to(devices[0])\n",
    "\n",
    "model9.train_model(\n",
    "    data_list,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
