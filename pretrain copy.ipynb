{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abe15dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.getdata import smiles2graph\n",
    "from model.CL_model_vas_info import GNNModelWithNewLoss\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fea3686",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/vsa.csv\")  \n",
    "smiles_list = df[\"SMILES\"].tolist()\n",
    "smr_vsa_list = [list(map(float, row.split())) for row in df[\"SMR_VSA\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "652499ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_vsa_data(vsa_file):\n",
    "    df = pd.read_csv(vsa_file)\n",
    "\n",
    "    def parse_vsa(s):\n",
    "        try:\n",
    "            return list(map(float, s.strip('[]').split()))\n",
    "        except:\n",
    "            return []\n",
    "\n",
    "    smr_arrays = df[\"SMR_VSA\"].apply(parse_vsa).tolist()          \n",
    "    slogp_arrays = df[\"SlogP_VSA\"].apply(parse_vsa).tolist()     \n",
    "    peoe_arrays = df[\"PEOE_VSA\"].apply(parse_vsa).tolist()       \n",
    "\n",
    "    properties = list(zip(smr_arrays, slogp_arrays, peoe_arrays))\n",
    "    \n",
    "    return df[\"SMILES\"].tolist(), properties\n",
    "\n",
    "x_smiles, properties = read_vsa_data(\"./data/vsa.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ead4c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = smiles2graph(\n",
    "    x_smiles,\n",
    "    properties=properties,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d56a71e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[21, 133], edge_index=[2, 44], edge_attr=[44, 14], global_features=[1, 8], smiles='Cc1cccc(C2=CCN(C(=O)NCCCC#N)CC2)c1', property_0=[1, 10], property_1=[1, 10], property_2=[1, 14])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffbfd7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133 14 8\n"
     ]
    }
   ],
   "source": [
    "print(data_list[0].x.shape[1],\n",
    "    data_list[0].edge_attr.shape[1],\n",
    "    data_list[0].global_features.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8f7538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import DataLoader\n",
    "devices = [\"cuda\" if torch.cuda.is_available() else \"cpu\"]\n",
    "model1 = GNNModelWithNewLoss(\n",
    "        num_node_features=data_list[0].x.shape[1],\n",
    "        num_edge_features=data_list[0].edge_attr.shape[1],\n",
    "        num_global_features=0,\n",
    "        hidden_dim=512,\n",
    "        dropout_rate=0.1,\n",
    "        property_index=0 ,\n",
    "        save_path= 'premodels_new_og/3/0' \n",
    "    ).to(devices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b1f8b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chenxinyi\\.conda\\envs\\torch\\lib\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training will be saved to: premodels_new/0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 5.3143 | Actual Loss: 5.2730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 1/300 [00:06<34:24,  6.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.9720 | Actual Loss: 3.9277\n",
      "Epoch 1/300: Train Loss: 5.2730, Val Loss: 3.9277\n",
      "New best validation loss: 3.9277\n",
      "Baseline Loss: 5.3143 | Actual Loss: 5.2710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 2/300 [00:10<24:54,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.9720 | Actual Loss: 3.9123\n",
      "Epoch 2/300: Train Loss: 5.2710, Val Loss: 3.9123\n",
      "New best validation loss: 3.9123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 2/300 [00:11<27:48,  5.60s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\chenxinyi\\Documents\\GitHub\\clean_multi_cl\\model\\CL_model_vas_info.py:266\u001b[0m, in \u001b[0;36mGNNModelWithNewLoss.train_model\u001b[1;34m(self, dataset, num_epochs, lr, weight_decay, patience, batch_size, best_val_loss_all)\u001b[0m\n\u001b[0;32m    263\u001b[0m batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    264\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 266\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;66;03m# Backpropagation with gradient clipping\u001b[39;00m\n\u001b[0;32m    269\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\chenxinyi\\Documents\\GitHub\\clean_multi_cl\\model\\CL_model_vas_info.py:199\u001b[0m, in \u001b[0;36mGNNModelWithNewLoss.get_loss\u001b[1;34m(self, batch, temperature, k, vsa_threshold)\u001b[0m\n\u001b[0;32m    196\u001b[0m     all_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(idx_i\u001b[38;5;241m.\u001b[39mtolist(), idx_j\u001b[38;5;241m.\u001b[39mtolist()))\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;66;03m# Negative pairs = all - positive\u001b[39;00m\n\u001b[1;32m--> 199\u001b[0m     neg_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mall_pairs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpos_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m    202\u001b[0m \u001b[38;5;66;03m# Compute projected graph embeddings\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model1.train_model(\n",
    "    data_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fe71e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = GNNModelWithNewLoss(\n",
    "        num_node_features=data_list[0].x.shape[1],\n",
    "        num_edge_features=data_list[0].edge_attr.shape[1],\n",
    "        num_global_features=0,\n",
    "        hidden_dim=512,\n",
    "        dropout_rate=0.1,\n",
    "        property_index=1 ,\n",
    "        save_path= 'premodels_new_og/3/1'\n",
    "    ).to(devices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48b63c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training will be saved to: premodels_new/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/300 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\chenxinyi\\Documents\\GitHub\\clean_multi_cl\\model\\CL_model_vas_info.py:266\u001b[0m, in \u001b[0;36mGNNModelWithNewLoss.train_model\u001b[1;34m(self, dataset, num_epochs, lr, weight_decay, patience, batch_size, best_val_loss_all)\u001b[0m\n\u001b[0;32m    263\u001b[0m batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    264\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 266\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;66;03m# Backpropagation with gradient clipping\u001b[39;00m\n\u001b[0;32m    269\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\chenxinyi\\Documents\\GitHub\\clean_multi_cl\\model\\CL_model_vas_info.py:203\u001b[0m, in \u001b[0;36mGNNModelWithNewLoss.get_loss\u001b[1;34m(self, batch, temperature, k, vsa_threshold)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m    202\u001b[0m \u001b[38;5;66;03m# Compute projected graph embeddings\u001b[39;00m\n\u001b[1;32m--> 203\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_project(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# shape: [n, dim]\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;66;03m# Compute cosine distances for positive pairs\u001b[39;00m\n\u001b[0;32m    206\u001b[0m pos_i, pos_j \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mpos_pairs)\n",
      "File \u001b[1;32mc:\\Users\\chenxinyi\\Documents\\GitHub\\clean_multi_cl\\model\\CL_model_vas_info.py:116\u001b[0m, in \u001b[0;36mGNNModelWithNewLoss.forward\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    113\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n\u001b[0;32m    115\u001b[0m \u001b[38;5;66;03m# Second GAT layer\u001b[39;00m\n\u001b[1;32m--> 116\u001b[0m x, attn2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mreturn_attention_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention_weights\u001b[38;5;241m.\u001b[39mappend(attn2)\n\u001b[0;32m    119\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(x))\n",
      "File \u001b[1;32mc:\\Users\\chenxinyi\\.conda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\chenxinyi\\.conda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\chenxinyi\\.conda\\envs\\torch\\lib\\site-packages\\torch_geometric\\nn\\conv\\gat_conv.py:347\u001b[0m, in \u001b[0;36mGATConv.forward\u001b[1;34m(self, x, edge_index, edge_attr, size, return_attention_weights)\u001b[0m\n\u001b[0;32m    345\u001b[0m         num_nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(num_nodes, x_dst\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m    346\u001b[0m     num_nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(size) \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m num_nodes\n\u001b[1;32m--> 347\u001b[0m     edge_index, edge_attr \u001b[38;5;241m=\u001b[39m \u001b[43mremove_self_loops\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    349\u001b[0m     edge_index, edge_attr \u001b[38;5;241m=\u001b[39m add_self_loops(\n\u001b[0;32m    350\u001b[0m         edge_index, edge_attr, fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill_value,\n\u001b[0;32m    351\u001b[0m         num_nodes\u001b[38;5;241m=\u001b[39mnum_nodes)\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(edge_index, SparseTensor):\n",
      "File \u001b[1;32mc:\\Users\\chenxinyi\\.conda\\envs\\torch\\lib\\site-packages\\torch_geometric\\utils\\loop.py:113\u001b[0m, in \u001b[0;36mremove_self_loops\u001b[1;34m(edge_index, edge_attr)\u001b[0m\n\u001b[0;32m    110\u001b[0m     is_undirected \u001b[38;5;241m=\u001b[39m edge_index\u001b[38;5;241m.\u001b[39mis_undirected\n\u001b[0;32m    112\u001b[0m mask \u001b[38;5;241m=\u001b[39m edge_index[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m edge_index[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m--> 113\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m \u001b[43medge_index\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(edge_index, EdgeIndex):\n\u001b[0;32m    116\u001b[0m     edge_index\u001b[38;5;241m.\u001b[39m_is_undirected \u001b[38;5;241m=\u001b[39m is_undirected\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model2.train_model(\n",
    "    data_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0fc12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = GNNModelWithNewLoss(\n",
    "        num_node_features=data_list[0].x.shape[1],\n",
    "        num_edge_features=data_list[0].edge_attr.shape[1],\n",
    "        num_global_features=0,\n",
    "        hidden_dim=512,\n",
    "        dropout_rate=0.1,\n",
    "        property_index=2,\n",
    "        save_path=\"premodels_new_og/3/2\"\n",
    "    ).to(devices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b665fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.train_model(\n",
    "    data_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2080382a",
   "metadata": {},
   "outputs": [],
   "source": [
    "devices = [\"cuda\" if torch.cuda.is_available() else \"cpu\"]\n",
    "model4 = GNNModelWithNewLoss(\n",
    "        num_node_features=data_list[0].x.shape[1],\n",
    "        num_edge_features=data_list[0].edge_attr.shape[1],\n",
    "        num_global_features=0,\n",
    "        cov_num= 6,\n",
    "        hidden_dim=512,\n",
    "        dropout_rate=0.1,\n",
    "        property_index=0 ,\n",
    "        save_path= 'premodels_new_og/6/0' \n",
    "    ).to(devices[0])\n",
    "\n",
    "model4.train_model(\n",
    "    data_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea51dc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "devices = [\"cuda\" if torch.cuda.is_available() else \"cpu\"]\n",
    "model5 = GNNModelWithNewLoss(\n",
    "        num_node_features=data_list[0].x.shape[1],\n",
    "        num_edge_features=data_list[0].edge_attr.shape[1],\n",
    "        num_global_features=0,\n",
    "        cov_num= 6,\n",
    "        hidden_dim=512,\n",
    "        dropout_rate=0.1,\n",
    "        property_index= 1,\n",
    "        save_path= 'premodels_new_og/6/1' \n",
    "    ).to(devices[0])\n",
    "\n",
    "model5.train_model(\n",
    "    data_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971916e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "devices = [\"cuda\" if torch.cuda.is_available() else \"cpu\"]\n",
    "model6 = GNNModelWithNewLoss(\n",
    "        num_node_features=data_list[0].x.shape[1],\n",
    "        num_edge_features=data_list[0].edge_attr.shape[1],\n",
    "        num_global_features=0,\n",
    "        cov_num= 6,\n",
    "        hidden_dim=512,\n",
    "        dropout_rate=0.1,\n",
    "        property_index= 2,\n",
    "        save_path= 'premodels_new_og/6/2' \n",
    "    ).to(devices[0])\n",
    "\n",
    "model6.train_model(\n",
    "    data_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01e3575",
   "metadata": {},
   "outputs": [],
   "source": [
    "devices = [\"cuda\" if torch.cuda.is_available() else \"cpu\"]\n",
    "model7 = GNNModelWithNewLoss(\n",
    "        num_node_features=data_list[0].x.shape[1],\n",
    "        num_edge_features=data_list[0].edge_attr.shape[1],\n",
    "        num_global_features=0,\n",
    "        cov_num= 9,\n",
    "        hidden_dim=512,\n",
    "        dropout_rate=0.1,\n",
    "        property_index= 0,\n",
    "        save_path= 'premodels_new_og/9/0' \n",
    "    ).to(devices[0])\n",
    "\n",
    "model7.train_model(\n",
    "    data_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc31e0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "devices = [\"cuda\" if torch.cuda.is_available() else \"cpu\"]\n",
    "model8 = GNNModelWithNewLoss(\n",
    "        num_node_features=data_list[0].x.shape[1],\n",
    "        num_edge_features=data_list[0].edge_attr.shape[1],\n",
    "        num_global_features=0,\n",
    "        cov_num= 9,\n",
    "        hidden_dim=512,\n",
    "        dropout_rate=0.1,\n",
    "        property_index= 1,\n",
    "        save_path= 'premodels_new_og/9/1' \n",
    "    ).to(devices[0])\n",
    "\n",
    "model8.train_model(\n",
    "    data_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364f6bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "devices = [\"cuda\" if torch.cuda.is_available() else \"cpu\"]\n",
    "model9 = GNNModelWithNewLoss(\n",
    "        num_node_features=data_list[0].x.shape[1],\n",
    "        num_edge_features=data_list[0].edge_attr.shape[1],\n",
    "        num_global_features=0,\n",
    "        cov_num= 9,\n",
    "        hidden_dim=512,\n",
    "        dropout_rate=0.1,\n",
    "        property_index= 2,\n",
    "        save_path= 'premodels_new_og/9/9' \n",
    "    ).to(devices[0])\n",
    "\n",
    "model9.train_model(\n",
    "    data_list,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
