{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abe15dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.getdata import smiles2graph\n",
    "from model.CL_model_vas_info import GNNModelWithNewLoss\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fea3686",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/vsa.csv\")  \n",
    "smiles_list = df[\"SMILES\"].tolist()\n",
    "smr_vsa_list = [list(map(float, row.split())) for row in df[\"SMR_VSA\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "652499ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_vsa_data(vsa_file):\n",
    "    df = pd.read_csv(vsa_file)\n",
    "\n",
    "    def parse_vsa(s):\n",
    "        try:\n",
    "            return list(map(float, s.strip('[]').split()))\n",
    "        except:\n",
    "            return []\n",
    "\n",
    "    smr_arrays = df[\"SMR_VSA\"].apply(parse_vsa).tolist()          \n",
    "    slogp_arrays = df[\"SlogP_VSA\"].apply(parse_vsa).tolist()     \n",
    "    peoe_arrays = df[\"PEOE_VSA\"].apply(parse_vsa).tolist()       \n",
    "\n",
    "    properties = list(zip(smr_arrays, slogp_arrays, peoe_arrays))\n",
    "    \n",
    "    return df[\"SMILES\"].tolist(), properties\n",
    "\n",
    "x_smiles, properties = read_vsa_data(\"./data/vsa.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ead4c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = smiles2graph(\n",
    "    x_smiles,\n",
    "    properties=properties,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d56a71e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[21, 133], edge_index=[2, 44], edge_attr=[44, 14], global_features=[1, 8], smiles='Cc1cccc(C2=CCN(C(=O)NCCCC#N)CC2)c1', property_0=[1, 10], property_1=[1, 10], property_2=[1, 14])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffbfd7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133 14 8\n"
     ]
    }
   ],
   "source": [
    "print(data_list[0].x.shape[1],\n",
    "    data_list[0].edge_attr.shape[1],\n",
    "    data_list[0].global_features.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe8f7538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import DataLoader\n",
    "devices = [\"cuda\" if torch.cuda.is_available() else \"cpu\"]\n",
    "model1 = GNNModelWithNewLoss(\n",
    "        num_node_features=data_list[0].x.shape[1],\n",
    "        num_edge_features=data_list[0].edge_attr.shape[1],\n",
    "        num_global_features=data_list[0].global_features.shape[1],\n",
    "        hidden_dim=512,\n",
    "        dropout_rate=0.1,\n",
    "        property_index=0 ,\n",
    "        save_path= 'premodels_new/3/0' \n",
    "    ).to(devices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b1f8b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/easter/.conda/envs/chemprop/lib/python3.11/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training will be saved to: premodels_new/3/0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8638 | Actual Loss: 2.8510\n",
      "Baseline Loss: 2.8378 | Actual Loss: 2.8075\n",
      "Baseline Loss: 2.7709 | Actual Loss: 2.7472\n",
      "Baseline Loss: 2.8248 | Actual Loss: 2.8307\n",
      "Baseline Loss: 2.8079 | Actual Loss: 2.7283\n",
      "Baseline Loss: 2.7979 | Actual Loss: 2.7711\n",
      "Baseline Loss: 2.8453 | Actual Loss: 2.7882\n",
      "Baseline Loss: 2.8137 | Actual Loss: 2.7661\n",
      "Baseline Loss: 2.7795 | Actual Loss: 2.6907\n",
      "Baseline Loss: 2.8416 | Actual Loss: 2.8699\n",
      "Baseline Loss: 2.8477 | Actual Loss: 2.8050\n",
      "Baseline Loss: 2.8586 | Actual Loss: 2.8407\n",
      "Baseline Loss: 2.8849 | Actual Loss: 2.8336\n",
      "Baseline Loss: 2.9245 | Actual Loss: 2.8176\n",
      "Baseline Loss: 2.8071 | Actual Loss: 2.7831\n",
      "Baseline Loss: 2.4892 | Actual Loss: 2.4923\n",
      "Baseline Loss: 2.8199 | Actual Loss: 2.7548\n",
      "Baseline Loss: 2.8180 | Actual Loss: 2.7747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 1/1000 [00:00<08:55,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7998 | Actual Loss: 2.7007\n",
      "Baseline Loss: 2.7254 | Actual Loss: 2.6678\n",
      "Epoch 1/1000: Train Loss: 2.7764, Val Loss: 2.7245\n",
      "New best validation loss: 2.7245\n",
      "Baseline Loss: 2.8948 | Actual Loss: 2.8426\n",
      "Baseline Loss: 2.8040 | Actual Loss: 2.7620\n",
      "Baseline Loss: 2.7760 | Actual Loss: 2.7269\n",
      "Baseline Loss: 2.7683 | Actual Loss: 2.7278\n",
      "Baseline Loss: 2.7865 | Actual Loss: 2.7326\n",
      "Baseline Loss: 2.8271 | Actual Loss: 2.7129\n",
      "Baseline Loss: 2.8611 | Actual Loss: 2.8271\n",
      "Baseline Loss: 2.8929 | Actual Loss: 2.8267\n",
      "Baseline Loss: 2.8331 | Actual Loss: 2.7301\n",
      "Baseline Loss: 2.8952 | Actual Loss: 2.8071\n",
      "Baseline Loss: 2.7430 | Actual Loss: 2.6331\n",
      "Baseline Loss: 2.8858 | Actual Loss: 2.8180\n",
      "Baseline Loss: 2.8068 | Actual Loss: 2.6744\n",
      "Baseline Loss: 2.8118 | Actual Loss: 2.7160\n",
      "Baseline Loss: 2.7978 | Actual Loss: 2.6931\n",
      "Baseline Loss: 2.6917 | Actual Loss: 2.6313\n",
      "Baseline Loss: 2.8199 | Actual Loss: 2.7298\n",
      "Baseline Loss: 2.8180 | Actual Loss: 2.8021\n",
      "Baseline Loss: 2.7998 | Actual Loss: 2.6811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 2/1000 [00:00<05:58,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7254 | Actual Loss: 2.6351\n",
      "Epoch 2/1000: Train Loss: 2.7414, Val Loss: 2.7120\n",
      "New best validation loss: 2.7120\n",
      "Baseline Loss: 2.8033 | Actual Loss: 2.7125\n",
      "Baseline Loss: 2.8136 | Actual Loss: 2.6538\n",
      "Baseline Loss: 2.8382 | Actual Loss: 2.7155\n",
      "Baseline Loss: 2.7907 | Actual Loss: 2.5927\n",
      "Baseline Loss: 2.8020 | Actual Loss: 2.7084\n",
      "Baseline Loss: 2.7493 | Actual Loss: 2.6992\n",
      "Baseline Loss: 2.7465 | Actual Loss: 2.6236\n",
      "Baseline Loss: 2.8471 | Actual Loss: 2.6948\n",
      "Baseline Loss: 2.8088 | Actual Loss: 2.7247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 3/1000 [00:01<05:38,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7893 | Actual Loss: 2.5815\n",
      "Baseline Loss: 2.8358 | Actual Loss: 2.7125\n",
      "Baseline Loss: 2.8657 | Actual Loss: 2.6372\n",
      "Baseline Loss: 2.9212 | Actual Loss: 2.7389\n",
      "Baseline Loss: 2.8710 | Actual Loss: 2.7114\n",
      "Baseline Loss: 2.8292 | Actual Loss: 2.6459\n",
      "Baseline Loss: 2.4714 | Actual Loss: 2.3581\n",
      "Baseline Loss: 2.8199 | Actual Loss: 2.6125\n",
      "Baseline Loss: 2.8180 | Actual Loss: 2.7137\n",
      "Baseline Loss: 2.7998 | Actual Loss: 2.6555\n",
      "Baseline Loss: 2.7254 | Actual Loss: 2.6011\n",
      "Epoch 3/1000: Train Loss: 2.6569, Val Loss: 2.6457\n",
      "New best validation loss: 2.6457\n",
      "Baseline Loss: 2.9108 | Actual Loss: 2.7885\n",
      "Baseline Loss: 2.8683 | Actual Loss: 2.6768\n",
      "Baseline Loss: 2.8800 | Actual Loss: 2.5132\n",
      "Baseline Loss: 2.7873 | Actual Loss: 2.5935\n",
      "Baseline Loss: 2.8658 | Actual Loss: 2.5733\n",
      "Baseline Loss: 2.8616 | Actual Loss: 2.7032\n",
      "Baseline Loss: 2.7824 | Actual Loss: 2.4404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 4/1000 [00:01<04:56,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8514 | Actual Loss: 2.5272\n",
      "Baseline Loss: 2.8788 | Actual Loss: 2.4868\n",
      "Baseline Loss: 2.7999 | Actual Loss: 2.3646\n",
      "Baseline Loss: 2.8185 | Actual Loss: 2.4359\n",
      "Baseline Loss: 2.7869 | Actual Loss: 2.5366\n",
      "Baseline Loss: 2.8119 | Actual Loss: 2.4717\n",
      "Baseline Loss: 2.7768 | Actual Loss: 2.4927\n",
      "Baseline Loss: 2.8402 | Actual Loss: 2.3726\n",
      "Baseline Loss: 2.5791 | Actual Loss: 2.2074\n",
      "Baseline Loss: 2.8199 | Actual Loss: 2.4009\n",
      "Baseline Loss: 2.8180 | Actual Loss: 2.3715\n",
      "Baseline Loss: 2.7998 | Actual Loss: 2.5557\n",
      "Baseline Loss: 2.7254 | Actual Loss: 2.2426\n",
      "Epoch 4/1000: Train Loss: 2.5115, Val Loss: 2.3927\n",
      "New best validation loss: 2.3927\n",
      "Baseline Loss: 2.9199 | Actual Loss: 2.4619\n",
      "Baseline Loss: 2.7974 | Actual Loss: 2.3896\n",
      "Baseline Loss: 2.7747 | Actual Loss: 2.5172\n",
      "Baseline Loss: 2.8315 | Actual Loss: 2.4477\n",
      "Baseline Loss: 2.8318 | Actual Loss: 2.5365\n",
      "Baseline Loss: 2.7882 | Actual Loss: 2.1801\n",
      "Baseline Loss: 2.8189 | Actual Loss: 2.3122\n",
      "Baseline Loss: 2.8539 | Actual Loss: 2.4511\n",
      "Baseline Loss: 2.7982 | Actual Loss: 2.2194\n",
      "Baseline Loss: 2.8790 | Actual Loss: 2.4289\n",
      "Baseline Loss: 2.8617 | Actual Loss: 2.2872\n",
      "Baseline Loss: 2.8813 | Actual Loss: 2.1908\n",
      "Baseline Loss: 2.8072 | Actual Loss: 2.0295\n",
      "Baseline Loss: 2.8857 | Actual Loss: 2.4154\n",
      "Baseline Loss: 2.7792 | Actual Loss: 2.1335\n",
      "Baseline Loss: 2.6510 | Actual Loss: 2.0345\n",
      "Baseline Loss: 2.8199 | Actual Loss: 2.5243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 5/1000 [00:01<05:03,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8180 | Actual Loss: 2.1707\n",
      "Baseline Loss: 2.7998 | Actual Loss: 2.0564\n",
      "Baseline Loss: 2.7254 | Actual Loss: 2.1682\n",
      "Epoch 5/1000: Train Loss: 2.3147, Val Loss: 2.2299\n",
      "New best validation loss: 2.2299\n",
      "Baseline Loss: 2.8622 | Actual Loss: 2.3820\n",
      "Baseline Loss: 2.8449 | Actual Loss: 2.0382\n",
      "Baseline Loss: 2.8360 | Actual Loss: 1.9628\n",
      "Baseline Loss: 2.7944 | Actual Loss: 2.0508\n",
      "Baseline Loss: 2.8726 | Actual Loss: 2.2285\n",
      "Baseline Loss: 2.8128 | Actual Loss: 2.5589\n",
      "Baseline Loss: 2.8098 | Actual Loss: 1.9421\n",
      "Baseline Loss: 2.8103 | Actual Loss: 2.3825\n",
      "Baseline Loss: 2.8403 | Actual Loss: 2.6264\n",
      "Baseline Loss: 2.8025 | Actual Loss: 2.1100\n",
      "Baseline Loss: 2.8427 | Actual Loss: 2.1178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 6/1000 [00:01<05:12,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8498 | Actual Loss: 1.8632\n",
      "Baseline Loss: 2.8205 | Actual Loss: 1.8135\n",
      "Baseline Loss: 2.7639 | Actual Loss: 2.0457\n",
      "Baseline Loss: 2.8803 | Actual Loss: 1.9241\n",
      "Baseline Loss: 2.4993 | Actual Loss: 2.1948\n",
      "Baseline Loss: 2.8199 | Actual Loss: 2.0015\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.9471\n",
      "Baseline Loss: 2.7998 | Actual Loss: 2.2384\n",
      "Baseline Loss: 2.7254 | Actual Loss: 1.8596\n",
      "Epoch 6/1000: Train Loss: 2.1401, Val Loss: 2.0117\n",
      "New best validation loss: 2.0117\n",
      "Baseline Loss: 2.7725 | Actual Loss: 2.0213\n",
      "Baseline Loss: 2.8936 | Actual Loss: 2.2504\n",
      "Baseline Loss: 2.8837 | Actual Loss: 2.0310\n",
      "Baseline Loss: 2.8210 | Actual Loss: 1.7879\n",
      "Baseline Loss: 2.8999 | Actual Loss: 1.7845\n",
      "Baseline Loss: 2.7674 | Actual Loss: 1.9072\n",
      "Baseline Loss: 2.9075 | Actual Loss: 1.8331\n",
      "Baseline Loss: 2.7938 | Actual Loss: 1.9813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 7/1000 [00:02<04:53,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8216 | Actual Loss: 1.6260\n",
      "Baseline Loss: 2.7616 | Actual Loss: 2.0868\n",
      "Baseline Loss: 2.8447 | Actual Loss: 1.7877\n",
      "Baseline Loss: 2.8149 | Actual Loss: 1.8585\n",
      "Baseline Loss: 2.8095 | Actual Loss: 2.2219\n",
      "Baseline Loss: 2.8881 | Actual Loss: 2.1351\n",
      "Baseline Loss: 2.8596 | Actual Loss: 2.0086\n",
      "Baseline Loss: 2.5760 | Actual Loss: 1.3445\n",
      "Baseline Loss: 2.8199 | Actual Loss: 1.5035\n",
      "Baseline Loss: 2.8180 | Actual Loss: 2.0732\n",
      "Baseline Loss: 2.7998 | Actual Loss: 1.6032\n",
      "Baseline Loss: 2.7254 | Actual Loss: 1.5385\n",
      "Epoch 7/1000: Train Loss: 1.9166, Val Loss: 1.6796\n",
      "New best validation loss: 1.6796\n",
      "Baseline Loss: 2.8052 | Actual Loss: 2.1769\n",
      "Baseline Loss: 2.9317 | Actual Loss: 2.1560\n",
      "Baseline Loss: 2.8276 | Actual Loss: 1.6795\n",
      "Baseline Loss: 2.8071 | Actual Loss: 1.5670\n",
      "Baseline Loss: 2.8425 | Actual Loss: 1.8881\n",
      "Baseline Loss: 2.8573 | Actual Loss: 2.1831\n",
      "Baseline Loss: 2.8705 | Actual Loss: 1.7581\n",
      "Baseline Loss: 2.8217 | Actual Loss: 2.1315\n",
      "Baseline Loss: 2.7776 | Actual Loss: 1.8329\n",
      "Baseline Loss: 2.8708 | Actual Loss: 1.8031\n",
      "Baseline Loss: 2.8115 | Actual Loss: 1.6845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 8/1000 [00:02<05:14,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8077 | Actual Loss: 1.8641\n",
      "Baseline Loss: 2.7608 | Actual Loss: 1.7931\n",
      "Baseline Loss: 2.8620 | Actual Loss: 1.6284\n",
      "Baseline Loss: 2.7480 | Actual Loss: 1.8285\n",
      "Baseline Loss: 2.6299 | Actual Loss: 1.8760\n",
      "Baseline Loss: 2.8199 | Actual Loss: 1.7441\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.8916\n",
      "Baseline Loss: 2.7998 | Actual Loss: 1.6470\n",
      "Baseline Loss: 2.7254 | Actual Loss: 1.7591\n",
      "Epoch 8/1000: Train Loss: 1.8657, Val Loss: 1.7604\n",
      "Baseline Loss: 2.7701 | Actual Loss: 1.6193\n",
      "Baseline Loss: 2.7648 | Actual Loss: 1.4619\n",
      "Baseline Loss: 2.7483 | Actual Loss: 1.5980\n",
      "Baseline Loss: 2.8470 | Actual Loss: 2.1709\n",
      "Baseline Loss: 2.8324 | Actual Loss: 2.0398\n",
      "Baseline Loss: 2.8671 | Actual Loss: 1.5378\n",
      "Baseline Loss: 2.8122 | Actual Loss: 1.8014\n",
      "Baseline Loss: 2.8372 | Actual Loss: 1.8510\n",
      "Baseline Loss: 2.7325 | Actual Loss: 1.6052\n",
      "Baseline Loss: 2.8839 | Actual Loss: 2.1695\n",
      "Baseline Loss: 2.8621 | Actual Loss: 1.9544\n",
      "Baseline Loss: 2.7970 | Actual Loss: 2.0644\n",
      "Baseline Loss: 2.8127 | Actual Loss: 1.6555\n",
      "Baseline Loss: 2.8584 | Actual Loss: 1.8308\n",
      "Baseline Loss: 2.8485 | Actual Loss: 1.2026\n",
      "Baseline Loss: 2.5921 | Actual Loss: 0.9437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 9/1000 [00:02<05:41,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8199 | Actual Loss: 1.6124\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.9246\n",
      "Baseline Loss: 2.7998 | Actual Loss: 1.6984\n",
      "Baseline Loss: 2.7254 | Actual Loss: 1.5553\n",
      "Epoch 9/1000: Train Loss: 1.7191, Val Loss: 1.6977\n",
      "Baseline Loss: 2.7882 | Actual Loss: 1.7442\n",
      "Baseline Loss: 2.7961 | Actual Loss: 1.6740\n",
      "Baseline Loss: 2.8873 | Actual Loss: 1.6253\n",
      "Baseline Loss: 2.8684 | Actual Loss: 1.6338\n",
      "Baseline Loss: 2.7683 | Actual Loss: 1.5394\n",
      "Baseline Loss: 2.7904 | Actual Loss: 1.8334\n",
      "Baseline Loss: 2.7771 | Actual Loss: 1.3687\n",
      "Baseline Loss: 2.8160 | Actual Loss: 1.6457\n",
      "Baseline Loss: 2.8154 | Actual Loss: 1.9701\n",
      "Baseline Loss: 2.7925 | Actual Loss: 1.7542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 10/1000 [00:03<05:22,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8642 | Actual Loss: 2.0650\n",
      "Baseline Loss: 2.7558 | Actual Loss: 1.4078\n",
      "Baseline Loss: 2.7454 | Actual Loss: 1.2414\n",
      "Baseline Loss: 2.8633 | Actual Loss: 1.8991\n",
      "Baseline Loss: 2.8635 | Actual Loss: 1.8779\n",
      "Baseline Loss: 2.5303 | Actual Loss: 2.0166\n",
      "Baseline Loss: 2.8199 | Actual Loss: 1.5049\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.6437\n",
      "Baseline Loss: 2.7998 | Actual Loss: 1.4300\n",
      "Baseline Loss: 2.7254 | Actual Loss: 1.2385\n",
      "Epoch 10/1000: Train Loss: 1.7060, Val Loss: 1.4543\n",
      "New best validation loss: 1.4543\n",
      "Baseline Loss: 2.8238 | Actual Loss: 1.2329\n",
      "Baseline Loss: 2.8380 | Actual Loss: 1.5286\n",
      "Baseline Loss: 2.8338 | Actual Loss: 1.6245\n",
      "Baseline Loss: 2.7807 | Actual Loss: 1.5745\n",
      "Baseline Loss: 2.7922 | Actual Loss: 1.8119\n",
      "Baseline Loss: 2.8435 | Actual Loss: 1.6643\n",
      "Baseline Loss: 2.8238 | Actual Loss: 1.7053\n",
      "Baseline Loss: 2.8433 | Actual Loss: 1.9121\n",
      "Baseline Loss: 2.8460 | Actual Loss: 1.6811\n",
      "Baseline Loss: 2.8856 | Actual Loss: 1.5563\n",
      "Baseline Loss: 2.7865 | Actual Loss: 1.2722\n",
      "Baseline Loss: 2.8391 | Actual Loss: 1.2491\n",
      "Baseline Loss: 2.8537 | Actual Loss: 1.8462\n",
      "Baseline Loss: 2.8092 | Actual Loss: 1.6645\n",
      "Baseline Loss: 2.7429 | Actual Loss: 1.4005\n",
      "Baseline Loss: 2.5522 | Actual Loss: 1.1463\n",
      "Baseline Loss: 2.8199 | Actual Loss: 1.5545\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.7921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 11/1000 [00:03<05:40,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7998 | Actual Loss: 1.4369\n",
      "Baseline Loss: 2.7254 | Actual Loss: 1.2763\n",
      "Epoch 11/1000: Train Loss: 1.5544, Val Loss: 1.5149\n",
      "Baseline Loss: 2.8726 | Actual Loss: 1.7027\n",
      "Baseline Loss: 2.8849 | Actual Loss: 1.5098\n",
      "Baseline Loss: 2.9244 | Actual Loss: 1.6064\n",
      "Baseline Loss: 2.8146 | Actual Loss: 1.6106\n",
      "Baseline Loss: 2.8372 | Actual Loss: 1.9398\n",
      "Baseline Loss: 2.8195 | Actual Loss: 1.2685\n",
      "Baseline Loss: 2.8797 | Actual Loss: 1.2228\n",
      "Baseline Loss: 2.8177 | Actual Loss: 1.3250\n",
      "Baseline Loss: 2.7680 | Actual Loss: 1.6853\n",
      "Baseline Loss: 2.7632 | Actual Loss: 1.3795\n",
      "Baseline Loss: 2.7750 | Actual Loss: 1.3608\n",
      "Baseline Loss: 2.8381 | Actual Loss: 1.5110\n",
      "Baseline Loss: 2.8363 | Actual Loss: 1.5376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 12/1000 [00:04<05:52,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8304 | Actual Loss: 1.1128\n",
      "Baseline Loss: 2.8295 | Actual Loss: 1.2902\n",
      "Baseline Loss: 2.5874 | Actual Loss: 1.3604\n",
      "Baseline Loss: 2.8199 | Actual Loss: 1.4002\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.6977\n",
      "Baseline Loss: 2.7998 | Actual Loss: 1.3451\n",
      "Baseline Loss: 2.7254 | Actual Loss: 1.0613\n",
      "Epoch 12/1000: Train Loss: 1.4640, Val Loss: 1.3761\n",
      "New best validation loss: 1.3761\n",
      "Baseline Loss: 2.7949 | Actual Loss: 1.5465\n",
      "Baseline Loss: 2.8423 | Actual Loss: 1.3683\n",
      "Baseline Loss: 2.7677 | Actual Loss: 1.3767\n",
      "Baseline Loss: 2.7594 | Actual Loss: 1.2406\n",
      "Baseline Loss: 2.8598 | Actual Loss: 1.3708\n",
      "Baseline Loss: 2.8616 | Actual Loss: 1.8352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏         | 13/1000 [00:04<05:27,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8312 | Actual Loss: 1.5889\n",
      "Baseline Loss: 2.8245 | Actual Loss: 1.4210\n",
      "Baseline Loss: 2.8005 | Actual Loss: 1.6160\n",
      "Baseline Loss: 2.8079 | Actual Loss: 1.1663\n",
      "Baseline Loss: 2.8367 | Actual Loss: 1.8263\n",
      "Baseline Loss: 2.8410 | Actual Loss: 1.5575\n",
      "Baseline Loss: 2.8090 | Actual Loss: 1.6027\n",
      "Baseline Loss: 2.8553 | Actual Loss: 1.0912\n",
      "Baseline Loss: 2.8486 | Actual Loss: 1.1406\n",
      "Baseline Loss: 2.5300 | Actual Loss: 0.7716\n",
      "Baseline Loss: 2.8199 | Actual Loss: 1.6135\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.4648\n",
      "Baseline Loss: 2.7998 | Actual Loss: 1.1631\n",
      "Baseline Loss: 2.7254 | Actual Loss: 1.0410\n",
      "Epoch 13/1000: Train Loss: 1.4075, Val Loss: 1.3206\n",
      "New best validation loss: 1.3206\n",
      "Baseline Loss: 2.8261 | Actual Loss: 1.7711\n",
      "Baseline Loss: 2.7971 | Actual Loss: 1.5544\n",
      "Baseline Loss: 2.8777 | Actual Loss: 1.1322\n",
      "Baseline Loss: 2.8690 | Actual Loss: 1.7538\n",
      "Baseline Loss: 2.8362 | Actual Loss: 1.6622\n",
      "Baseline Loss: 2.7789 | Actual Loss: 1.1482\n",
      "Baseline Loss: 2.8239 | Actual Loss: 0.9260\n",
      "Baseline Loss: 2.8018 | Actual Loss: 1.3138\n",
      "Baseline Loss: 2.7783 | Actual Loss: 1.2749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏         | 14/1000 [00:04<05:45,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8739 | Actual Loss: 1.3740\n",
      "Baseline Loss: 2.7898 | Actual Loss: 1.3580\n",
      "Baseline Loss: 2.8398 | Actual Loss: 1.3858\n",
      "Baseline Loss: 2.8534 | Actual Loss: 1.6696\n",
      "Baseline Loss: 2.8429 | Actual Loss: 1.5978\n",
      "Baseline Loss: 2.7880 | Actual Loss: 0.9334\n",
      "Baseline Loss: 2.5005 | Actual Loss: 1.0705\n",
      "Baseline Loss: 2.8199 | Actual Loss: 1.5893\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.7504\n",
      "Baseline Loss: 2.7998 | Actual Loss: 1.0835\n",
      "Baseline Loss: 2.7254 | Actual Loss: 1.0318\n",
      "Epoch 14/1000: Train Loss: 1.3703, Val Loss: 1.3637\n",
      "Baseline Loss: 2.7968 | Actual Loss: 1.2568\n",
      "Baseline Loss: 2.8567 | Actual Loss: 1.9733\n",
      "Baseline Loss: 2.8247 | Actual Loss: 1.1634\n",
      "Baseline Loss: 2.9462 | Actual Loss: 1.0439\n",
      "Baseline Loss: 2.8530 | Actual Loss: 1.2878\n",
      "Baseline Loss: 2.8519 | Actual Loss: 0.8771\n",
      "Baseline Loss: 2.7842 | Actual Loss: 1.6908\n",
      "Baseline Loss: 2.8581 | Actual Loss: 1.3703\n",
      "Baseline Loss: 2.7638 | Actual Loss: 0.9864\n",
      "Baseline Loss: 2.8231 | Actual Loss: 1.3357\n",
      "Baseline Loss: 2.7938 | Actual Loss: 1.3006\n",
      "Baseline Loss: 2.7489 | Actual Loss: 1.6289\n",
      "Baseline Loss: 2.8426 | Actual Loss: 1.0894\n",
      "Baseline Loss: 2.8335 | Actual Loss: 1.7186\n",
      "Baseline Loss: 2.7694 | Actual Loss: 1.1466\n",
      "Baseline Loss: 2.5532 | Actual Loss: 0.8995\n",
      "Baseline Loss: 2.8199 | Actual Loss: 1.5680\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.4498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 15/1000 [00:05<05:25,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7998 | Actual Loss: 1.2682\n",
      "Baseline Loss: 2.7254 | Actual Loss: 1.0275\n",
      "Epoch 15/1000: Train Loss: 1.2981, Val Loss: 1.3284\n",
      "Baseline Loss: 2.7634 | Actual Loss: 0.8677\n",
      "Baseline Loss: 2.8268 | Actual Loss: 0.8798\n",
      "Baseline Loss: 2.8331 | Actual Loss: 1.0410\n",
      "Baseline Loss: 2.7925 | Actual Loss: 1.6703\n",
      "Baseline Loss: 2.8171 | Actual Loss: 1.1911\n",
      "Baseline Loss: 2.8336 | Actual Loss: 1.0412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 16/1000 [00:05<05:39,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8724 | Actual Loss: 1.0552\n",
      "Baseline Loss: 2.7997 | Actual Loss: 1.8110\n",
      "Baseline Loss: 2.7836 | Actual Loss: 1.3800\n",
      "Baseline Loss: 2.7758 | Actual Loss: 1.3779\n",
      "Baseline Loss: 2.8432 | Actual Loss: 1.3919\n",
      "Baseline Loss: 2.8605 | Actual Loss: 1.3920\n",
      "Baseline Loss: 2.7578 | Actual Loss: 1.1702\n",
      "Baseline Loss: 2.8222 | Actual Loss: 1.3112\n",
      "Baseline Loss: 2.8446 | Actual Loss: 0.9494\n",
      "Baseline Loss: 2.5665 | Actual Loss: 1.2386\n",
      "Baseline Loss: 2.8199 | Actual Loss: 1.2262\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.3988\n",
      "Baseline Loss: 2.7998 | Actual Loss: 1.0321\n",
      "Baseline Loss: 2.7254 | Actual Loss: 1.0503\n",
      "Epoch 16/1000: Train Loss: 1.2355, Val Loss: 1.1769\n",
      "New best validation loss: 1.1769\n",
      "Baseline Loss: 2.7896 | Actual Loss: 1.9283\n",
      "Baseline Loss: 2.8651 | Actual Loss: 1.2036\n",
      "Baseline Loss: 2.8211 | Actual Loss: 1.5129\n",
      "Baseline Loss: 2.8650 | Actual Loss: 0.8133\n",
      "Baseline Loss: 2.8780 | Actual Loss: 1.1092\n",
      "Baseline Loss: 2.7651 | Actual Loss: 1.0104\n",
      "Baseline Loss: 2.8069 | Actual Loss: 1.0961\n",
      "Baseline Loss: 2.8937 | Actual Loss: 1.2291\n",
      "Baseline Loss: 2.8510 | Actual Loss: 1.1694\n",
      "Baseline Loss: 2.7571 | Actual Loss: 1.2648\n",
      "Baseline Loss: 2.8161 | Actual Loss: 1.3646\n",
      "Baseline Loss: 2.7865 | Actual Loss: 1.1473\n",
      "Baseline Loss: 2.8707 | Actual Loss: 1.2390\n",
      "Baseline Loss: 2.7662 | Actual Loss: 1.0055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 17/1000 [00:05<05:48,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7903 | Actual Loss: 1.1440\n",
      "Baseline Loss: 2.5394 | Actual Loss: 0.5879\n",
      "Baseline Loss: 2.8199 | Actual Loss: 1.5302\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.4084\n",
      "Baseline Loss: 2.7998 | Actual Loss: 1.0907\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.9528\n",
      "Epoch 17/1000: Train Loss: 1.1766, Val Loss: 1.2455\n",
      "Baseline Loss: 2.8032 | Actual Loss: 1.2516\n",
      "Baseline Loss: 2.8088 | Actual Loss: 1.6353\n",
      "Baseline Loss: 2.8327 | Actual Loss: 1.7960\n",
      "Baseline Loss: 2.8120 | Actual Loss: 1.3362\n",
      "Baseline Loss: 2.7983 | Actual Loss: 1.2115\n",
      "Baseline Loss: 2.9024 | Actual Loss: 1.0588\n",
      "Baseline Loss: 2.8667 | Actual Loss: 1.3174\n",
      "Baseline Loss: 2.7915 | Actual Loss: 1.1761\n",
      "Baseline Loss: 2.8287 | Actual Loss: 1.1724\n",
      "Baseline Loss: 2.8844 | Actual Loss: 1.0526\n",
      "Baseline Loss: 2.7869 | Actual Loss: 1.5342\n",
      "Baseline Loss: 2.7699 | Actual Loss: 1.1890\n",
      "Baseline Loss: 2.8317 | Actual Loss: 1.4403\n",
      "Baseline Loss: 2.8725 | Actual Loss: 0.9629\n",
      "Baseline Loss: 2.8685 | Actual Loss: 1.3817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 18/1000 [00:06<05:29,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5359 | Actual Loss: 0.8682\n",
      "Baseline Loss: 2.8199 | Actual Loss: 1.5009\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.4221\n",
      "Baseline Loss: 2.7998 | Actual Loss: 1.2245\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.9878\n",
      "Epoch 18/1000: Train Loss: 1.2740, Val Loss: 1.2838\n",
      "Baseline Loss: 2.7938 | Actual Loss: 1.1817\n",
      "Baseline Loss: 2.7720 | Actual Loss: 1.3151\n",
      "Baseline Loss: 2.8910 | Actual Loss: 1.4130\n",
      "Baseline Loss: 2.9264 | Actual Loss: 1.1111\n",
      "Baseline Loss: 2.8388 | Actual Loss: 1.0566\n",
      "Baseline Loss: 2.7550 | Actual Loss: 1.5097\n",
      "Baseline Loss: 2.7766 | Actual Loss: 1.0868\n",
      "Baseline Loss: 2.8486 | Actual Loss: 1.2594\n",
      "Baseline Loss: 2.7945 | Actual Loss: 1.7170\n",
      "Baseline Loss: 2.7523 | Actual Loss: 0.9551\n",
      "Baseline Loss: 2.7865 | Actual Loss: 0.9762\n",
      "Baseline Loss: 2.8504 | Actual Loss: 1.3583\n",
      "Baseline Loss: 2.7722 | Actual Loss: 1.3589\n",
      "Baseline Loss: 2.8425 | Actual Loss: 1.0362\n",
      "Baseline Loss: 2.8065 | Actual Loss: 1.1835\n",
      "Baseline Loss: 2.5114 | Actual Loss: 0.6510\n",
      "Baseline Loss: 2.8199 | Actual Loss: 1.5123\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.4868\n",
      "Baseline Loss: 2.7998 | Actual Loss: 1.1312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 19/1000 [00:06<05:43,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7254 | Actual Loss: 0.9504\n",
      "Epoch 19/1000: Train Loss: 1.1981, Val Loss: 1.2702\n",
      "Baseline Loss: 2.8232 | Actual Loss: 1.0602\n",
      "Baseline Loss: 2.8041 | Actual Loss: 1.2971\n",
      "Baseline Loss: 2.8477 | Actual Loss: 1.5904\n",
      "Baseline Loss: 2.8837 | Actual Loss: 0.7558\n",
      "Baseline Loss: 2.7433 | Actual Loss: 1.4341\n",
      "Baseline Loss: 2.8301 | Actual Loss: 1.2042\n",
      "Baseline Loss: 2.8367 | Actual Loss: 1.3536\n",
      "Baseline Loss: 2.8599 | Actual Loss: 1.6942\n",
      "Baseline Loss: 2.8102 | Actual Loss: 1.0308\n",
      "Baseline Loss: 2.8358 | Actual Loss: 1.0389\n",
      "Baseline Loss: 2.7998 | Actual Loss: 1.5318\n",
      "Baseline Loss: 2.8123 | Actual Loss: 1.1388\n",
      "Baseline Loss: 2.8706 | Actual Loss: 1.2058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 20/1000 [00:06<05:53,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8444 | Actual Loss: 1.1031\n",
      "Baseline Loss: 2.8330 | Actual Loss: 1.0388\n",
      "Baseline Loss: 2.5017 | Actual Loss: 1.1918\n",
      "Baseline Loss: 2.8199 | Actual Loss: 1.2585\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.2579\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.9628\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.9113\n",
      "Epoch 20/1000: Train Loss: 1.2293, Val Loss: 1.0977\n",
      "New best validation loss: 1.0977\n",
      "Baseline Loss: 2.8142 | Actual Loss: 0.9926\n",
      "Baseline Loss: 2.9198 | Actual Loss: 1.6397\n",
      "Baseline Loss: 2.8426 | Actual Loss: 1.1180\n",
      "Baseline Loss: 2.7761 | Actual Loss: 0.7516\n",
      "Baseline Loss: 2.8490 | Actual Loss: 2.0063\n",
      "Baseline Loss: 2.7781 | Actual Loss: 1.7912\n",
      "Baseline Loss: 2.9413 | Actual Loss: 1.0797\n",
      "Baseline Loss: 2.7994 | Actual Loss: 1.1769\n",
      "Baseline Loss: 2.7996 | Actual Loss: 1.0545\n",
      "Baseline Loss: 2.8182 | Actual Loss: 1.2129\n",
      "Baseline Loss: 2.8134 | Actual Loss: 0.8639\n",
      "Baseline Loss: 2.8563 | Actual Loss: 1.0614\n",
      "Baseline Loss: 2.9017 | Actual Loss: 0.9326\n",
      "Baseline Loss: 2.7739 | Actual Loss: 1.1870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 21/1000 [00:07<05:34,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7718 | Actual Loss: 0.9876\n",
      "Baseline Loss: 2.4786 | Actual Loss: 0.8988\n",
      "Baseline Loss: 2.8199 | Actual Loss: 1.4980\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.3554\n",
      "Baseline Loss: 2.7998 | Actual Loss: 1.0649\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.7727\n",
      "Epoch 21/1000: Train Loss: 1.1722, Val Loss: 1.1728\n",
      "Baseline Loss: 2.8269 | Actual Loss: 1.1720\n",
      "Baseline Loss: 2.8235 | Actual Loss: 0.9128\n",
      "Baseline Loss: 2.8274 | Actual Loss: 1.0673\n",
      "Baseline Loss: 2.7975 | Actual Loss: 1.2157\n",
      "Baseline Loss: 2.8660 | Actual Loss: 0.9526\n",
      "Baseline Loss: 2.7938 | Actual Loss: 1.1002\n",
      "Baseline Loss: 2.7830 | Actual Loss: 1.3552\n",
      "Baseline Loss: 2.8464 | Actual Loss: 1.4595\n",
      "Baseline Loss: 2.8879 | Actual Loss: 1.2944\n",
      "Baseline Loss: 2.8558 | Actual Loss: 1.4728\n",
      "Baseline Loss: 2.8005 | Actual Loss: 1.1681\n",
      "Baseline Loss: 2.8289 | Actual Loss: 1.1122\n",
      "Baseline Loss: 2.7687 | Actual Loss: 0.9657\n",
      "Baseline Loss: 2.8889 | Actual Loss: 1.1240\n",
      "Baseline Loss: 2.7691 | Actual Loss: 0.9199\n",
      "Baseline Loss: 2.6563 | Actual Loss: 1.6047\n",
      "Baseline Loss: 2.8199 | Actual Loss: 1.7207\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.2302\n",
      "Baseline Loss: 2.7998 | Actual Loss: 1.1409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 22/1000 [00:07<05:41,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7254 | Actual Loss: 0.8501\n",
      "Epoch 22/1000: Train Loss: 1.1811, Val Loss: 1.2355\n",
      "Baseline Loss: 2.8792 | Actual Loss: 1.1422\n",
      "Baseline Loss: 2.8116 | Actual Loss: 0.8003\n",
      "Baseline Loss: 2.7364 | Actual Loss: 1.1597\n",
      "Baseline Loss: 2.8421 | Actual Loss: 1.4387\n",
      "Baseline Loss: 2.9020 | Actual Loss: 1.0260\n",
      "Baseline Loss: 2.8186 | Actual Loss: 1.5995\n",
      "Baseline Loss: 2.8306 | Actual Loss: 0.9542\n",
      "Baseline Loss: 2.7982 | Actual Loss: 0.8586\n",
      "Baseline Loss: 2.9065 | Actual Loss: 1.0665\n",
      "Baseline Loss: 2.9249 | Actual Loss: 0.8402\n",
      "Baseline Loss: 2.8668 | Actual Loss: 1.1029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 23/1000 [00:07<05:50,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7514 | Actual Loss: 0.8939\n",
      "Baseline Loss: 2.8040 | Actual Loss: 1.0246\n",
      "Baseline Loss: 2.8228 | Actual Loss: 1.4512\n",
      "Baseline Loss: 2.8116 | Actual Loss: 1.0585\n",
      "Baseline Loss: 2.6131 | Actual Loss: 0.6114\n",
      "Baseline Loss: 2.8199 | Actual Loss: 1.2039\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.2926\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.8515\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.8963\n",
      "Epoch 23/1000: Train Loss: 1.0643, Val Loss: 1.0611\n",
      "New best validation loss: 1.0611\n",
      "Baseline Loss: 2.8098 | Actual Loss: 0.9675\n",
      "Baseline Loss: 2.8247 | Actual Loss: 0.9581\n",
      "Baseline Loss: 2.9287 | Actual Loss: 0.9074\n",
      "Baseline Loss: 2.8445 | Actual Loss: 1.1267\n",
      "Baseline Loss: 2.8816 | Actual Loss: 0.9799\n",
      "Baseline Loss: 2.7564 | Actual Loss: 1.3396\n",
      "Baseline Loss: 2.9059 | Actual Loss: 1.0741\n",
      "Baseline Loss: 2.7886 | Actual Loss: 1.1165\n",
      "Baseline Loss: 2.8803 | Actual Loss: 1.0657\n",
      "Baseline Loss: 2.8287 | Actual Loss: 0.9132\n",
      "Baseline Loss: 2.8647 | Actual Loss: 1.1640\n",
      "Baseline Loss: 2.8148 | Actual Loss: 1.0484\n",
      "Baseline Loss: 2.8287 | Actual Loss: 1.3925\n",
      "Baseline Loss: 2.7747 | Actual Loss: 0.9524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 24/1000 [00:08<05:30,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8531 | Actual Loss: 1.3546\n",
      "Baseline Loss: 2.5763 | Actual Loss: 1.0710\n",
      "Baseline Loss: 2.8199 | Actual Loss: 1.1876\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.4315\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.9653\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.8466\n",
      "Epoch 24/1000: Train Loss: 1.0895, Val Loss: 1.1077\n",
      "Baseline Loss: 2.8271 | Actual Loss: 1.0352\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.9872\n",
      "Baseline Loss: 2.8330 | Actual Loss: 1.2838\n",
      "Baseline Loss: 2.7889 | Actual Loss: 0.9873\n",
      "Baseline Loss: 2.7848 | Actual Loss: 0.8763\n",
      "Baseline Loss: 2.8104 | Actual Loss: 1.0803\n",
      "Baseline Loss: 2.8406 | Actual Loss: 1.4275\n",
      "Baseline Loss: 2.7263 | Actual Loss: 0.8488\n",
      "Baseline Loss: 2.8713 | Actual Loss: 0.8339\n",
      "Baseline Loss: 2.8517 | Actual Loss: 0.9416\n",
      "Baseline Loss: 2.8415 | Actual Loss: 0.9108\n",
      "Baseline Loss: 2.8824 | Actual Loss: 1.5145\n",
      "Baseline Loss: 2.8363 | Actual Loss: 1.0003\n",
      "Baseline Loss: 2.8489 | Actual Loss: 1.1929\n",
      "Baseline Loss: 2.8954 | Actual Loss: 1.2840\n",
      "Baseline Loss: 2.4962 | Actual Loss: 0.9118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▎         | 25/1000 [00:08<05:50,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8199 | Actual Loss: 1.1028\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.1904\n",
      "Baseline Loss: 2.7998 | Actual Loss: 1.0067\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.9353\n",
      "Epoch 25/1000: Train Loss: 1.0698, Val Loss: 1.0588\n",
      "New best validation loss: 1.0588\n",
      "Baseline Loss: 2.8212 | Actual Loss: 1.0013\n",
      "Baseline Loss: 2.8339 | Actual Loss: 1.5315\n",
      "Baseline Loss: 2.7682 | Actual Loss: 0.9168\n",
      "Baseline Loss: 2.9039 | Actual Loss: 0.9362\n",
      "Baseline Loss: 2.7699 | Actual Loss: 1.1823\n",
      "Baseline Loss: 2.9319 | Actual Loss: 1.0884\n",
      "Baseline Loss: 2.7505 | Actual Loss: 0.9929\n",
      "Baseline Loss: 2.8732 | Actual Loss: 1.5789\n",
      "Baseline Loss: 2.8428 | Actual Loss: 0.9928\n",
      "Baseline Loss: 2.8170 | Actual Loss: 1.7017\n",
      "Baseline Loss: 2.8653 | Actual Loss: 0.9173\n",
      "Baseline Loss: 2.8733 | Actual Loss: 1.0740\n",
      "Baseline Loss: 2.8100 | Actual Loss: 0.8402\n",
      "Baseline Loss: 2.8335 | Actual Loss: 1.1143\n",
      "Baseline Loss: 2.7958 | Actual Loss: 1.0916\n",
      "Baseline Loss: 2.4953 | Actual Loss: 1.1994\n",
      "Baseline Loss: 2.8199 | Actual Loss: 1.1796\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.3114\n",
      "Baseline Loss: 2.7998 | Actual Loss: 1.0158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 26/1000 [00:08<06:01,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7254 | Actual Loss: 0.7235\n",
      "Epoch 26/1000: Train Loss: 1.1350, Val Loss: 1.0575\n",
      "New best validation loss: 1.0575\n",
      "Baseline Loss: 2.7968 | Actual Loss: 1.1275\n",
      "Baseline Loss: 2.8215 | Actual Loss: 0.8433\n",
      "Baseline Loss: 2.7689 | Actual Loss: 0.6816\n",
      "Baseline Loss: 2.8196 | Actual Loss: 0.6813\n",
      "Baseline Loss: 2.7640 | Actual Loss: 1.2012\n",
      "Baseline Loss: 2.7947 | Actual Loss: 1.2249\n",
      "Baseline Loss: 2.8624 | Actual Loss: 1.3425\n",
      "Baseline Loss: 2.8308 | Actual Loss: 1.2267\n",
      "Baseline Loss: 2.7964 | Actual Loss: 1.0500\n",
      "Baseline Loss: 2.7410 | Actual Loss: 1.0253\n",
      "Baseline Loss: 2.7968 | Actual Loss: 1.1266\n",
      "Baseline Loss: 2.8542 | Actual Loss: 1.3842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 27/1000 [00:09<05:43,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8205 | Actual Loss: 0.8996\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.6834\n",
      "Baseline Loss: 2.8346 | Actual Loss: 0.6980\n",
      "Baseline Loss: 2.6348 | Actual Loss: 0.9795\n",
      "Baseline Loss: 2.8199 | Actual Loss: 1.1382\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.2991\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.9605\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.7262\n",
      "Epoch 27/1000: Train Loss: 1.0110, Val Loss: 1.0310\n",
      "New best validation loss: 1.0310\n",
      "Baseline Loss: 2.8308 | Actual Loss: 0.9496\n",
      "Baseline Loss: 2.7798 | Actual Loss: 1.2619\n",
      "Baseline Loss: 2.8710 | Actual Loss: 1.0033\n",
      "Baseline Loss: 2.8824 | Actual Loss: 0.9772\n",
      "Baseline Loss: 2.8738 | Actual Loss: 1.1954\n",
      "Baseline Loss: 2.8523 | Actual Loss: 1.1170\n",
      "Baseline Loss: 2.8490 | Actual Loss: 0.9655\n",
      "Baseline Loss: 2.8708 | Actual Loss: 1.1132\n",
      "Baseline Loss: 2.7521 | Actual Loss: 0.9689\n",
      "Baseline Loss: 2.7938 | Actual Loss: 1.3765\n",
      "Baseline Loss: 2.7885 | Actual Loss: 0.8090\n",
      "Baseline Loss: 2.7911 | Actual Loss: 0.9591\n",
      "Baseline Loss: 2.8327 | Actual Loss: 0.9983\n",
      "Baseline Loss: 2.8253 | Actual Loss: 0.6413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 28/1000 [00:09<05:47,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8202 | Actual Loss: 0.8290\n",
      "Baseline Loss: 2.5392 | Actual Loss: 1.4058\n",
      "Baseline Loss: 2.8199 | Actual Loss: 1.1470\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.2770\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.9656\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.8025\n",
      "Epoch 28/1000: Train Loss: 1.0357, Val Loss: 1.0480\n",
      "Baseline Loss: 2.8501 | Actual Loss: 1.0434\n",
      "Baseline Loss: 2.8394 | Actual Loss: 1.0812\n",
      "Baseline Loss: 2.8425 | Actual Loss: 1.0772\n",
      "Baseline Loss: 2.8414 | Actual Loss: 1.0669\n",
      "Baseline Loss: 2.8376 | Actual Loss: 1.0035\n",
      "Baseline Loss: 2.8681 | Actual Loss: 0.8405\n",
      "Baseline Loss: 2.8664 | Actual Loss: 0.6702\n",
      "Baseline Loss: 2.8037 | Actual Loss: 1.2634\n",
      "Baseline Loss: 2.8370 | Actual Loss: 0.8447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 29/1000 [00:09<05:20,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7570 | Actual Loss: 1.1462\n",
      "Baseline Loss: 2.7607 | Actual Loss: 1.1929\n",
      "Baseline Loss: 2.7938 | Actual Loss: 0.8931\n",
      "Baseline Loss: 2.8856 | Actual Loss: 0.9665\n",
      "Baseline Loss: 2.7974 | Actual Loss: 0.6190\n",
      "Baseline Loss: 2.8448 | Actual Loss: 1.0465\n",
      "Baseline Loss: 2.5890 | Actual Loss: 1.2769\n",
      "Baseline Loss: 2.8199 | Actual Loss: 1.0432\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.3245\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.8287\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.7966\n",
      "Epoch 29/1000: Train Loss: 1.0020, Val Loss: 0.9983\n",
      "New best validation loss: 0.9983\n",
      "Baseline Loss: 2.8956 | Actual Loss: 0.9641\n",
      "Baseline Loss: 2.8807 | Actual Loss: 0.8785\n",
      "Baseline Loss: 2.7996 | Actual Loss: 1.3919\n",
      "Baseline Loss: 2.8460 | Actual Loss: 1.0690\n",
      "Baseline Loss: 2.8504 | Actual Loss: 0.7693\n",
      "Baseline Loss: 2.8596 | Actual Loss: 1.2955\n",
      "Baseline Loss: 2.7987 | Actual Loss: 0.7682\n",
      "Baseline Loss: 2.8313 | Actual Loss: 0.8763\n",
      "Baseline Loss: 2.8561 | Actual Loss: 0.9151\n",
      "Baseline Loss: 2.8481 | Actual Loss: 1.1288\n",
      "Baseline Loss: 2.8202 | Actual Loss: 1.2884\n",
      "Baseline Loss: 2.7633 | Actual Loss: 0.8172\n",
      "Baseline Loss: 2.8788 | Actual Loss: 0.7061\n",
      "Baseline Loss: 2.8338 | Actual Loss: 0.7961\n",
      "Baseline Loss: 2.8282 | Actual Loss: 0.4943\n",
      "Baseline Loss: 2.4033 | Actual Loss: 1.5080\n",
      "Baseline Loss: 2.8199 | Actual Loss: 1.4068\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.4474\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.9929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 30/1000 [00:10<05:21,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7254 | Actual Loss: 0.8534\n",
      "Epoch 30/1000: Train Loss: 0.9792, Val Loss: 1.1751\n",
      "Baseline Loss: 2.8408 | Actual Loss: 0.6371\n",
      "Baseline Loss: 2.8144 | Actual Loss: 1.2400\n",
      "Baseline Loss: 2.8100 | Actual Loss: 1.1062\n",
      "Baseline Loss: 2.8485 | Actual Loss: 1.2538\n",
      "Baseline Loss: 2.8330 | Actual Loss: 0.7583\n",
      "Baseline Loss: 2.8358 | Actual Loss: 0.8097\n",
      "Baseline Loss: 2.7554 | Actual Loss: 1.0504\n",
      "Baseline Loss: 2.8306 | Actual Loss: 0.9604\n",
      "Baseline Loss: 2.8167 | Actual Loss: 0.9352\n",
      "Baseline Loss: 2.8411 | Actual Loss: 0.6568\n",
      "Baseline Loss: 2.9023 | Actual Loss: 0.9033\n",
      "Baseline Loss: 2.8947 | Actual Loss: 1.2678\n",
      "Baseline Loss: 2.8205 | Actual Loss: 1.2701\n",
      "Baseline Loss: 2.8068 | Actual Loss: 0.8233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 31/1000 [00:10<05:21,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8487 | Actual Loss: 0.8878\n",
      "Baseline Loss: 2.5174 | Actual Loss: 0.4804\n",
      "Baseline Loss: 2.8199 | Actual Loss: 1.1668\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.3497\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.8037\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.5463\n",
      "Epoch 31/1000: Train Loss: 0.9400, Val Loss: 0.9666\n",
      "New best validation loss: 0.9666\n",
      "Baseline Loss: 2.8874 | Actual Loss: 0.6714\n",
      "Baseline Loss: 2.8270 | Actual Loss: 0.9298\n",
      "Baseline Loss: 2.8146 | Actual Loss: 1.4427\n",
      "Baseline Loss: 2.7515 | Actual Loss: 1.0606\n",
      "Baseline Loss: 2.8039 | Actual Loss: 0.8754\n",
      "Baseline Loss: 2.7863 | Actual Loss: 1.3601\n",
      "Baseline Loss: 2.8987 | Actual Loss: 0.7200\n",
      "Baseline Loss: 2.7497 | Actual Loss: 0.8317\n",
      "Baseline Loss: 2.8288 | Actual Loss: 1.3922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 32/1000 [00:10<05:06,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8180 | Actual Loss: 0.9038\n",
      "Baseline Loss: 2.7776 | Actual Loss: 0.9118\n",
      "Baseline Loss: 2.7991 | Actual Loss: 1.2794\n",
      "Baseline Loss: 2.8678 | Actual Loss: 0.6613\n",
      "Baseline Loss: 2.8553 | Actual Loss: 0.9707\n",
      "Baseline Loss: 2.7890 | Actual Loss: 0.9425\n",
      "Baseline Loss: 2.4402 | Actual Loss: 0.8157\n",
      "Baseline Loss: 2.8199 | Actual Loss: 1.1124\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.3279\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.8001\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.6238\n",
      "Epoch 32/1000: Train Loss: 0.9856, Val Loss: 0.9661\n",
      "New best validation loss: 0.9661\n",
      "Baseline Loss: 2.7489 | Actual Loss: 0.8176\n",
      "Baseline Loss: 2.8486 | Actual Loss: 1.0599\n",
      "Baseline Loss: 2.8857 | Actual Loss: 0.6352\n",
      "Baseline Loss: 2.8618 | Actual Loss: 0.7252\n",
      "Baseline Loss: 2.7775 | Actual Loss: 0.8596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 33/1000 [00:11<05:12,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8004 | Actual Loss: 0.7251\n",
      "Baseline Loss: 2.7907 | Actual Loss: 1.1768\n",
      "Baseline Loss: 2.8727 | Actual Loss: 1.0681\n",
      "Baseline Loss: 2.7894 | Actual Loss: 0.9155\n",
      "Baseline Loss: 2.7670 | Actual Loss: 0.7156\n",
      "Baseline Loss: 2.7994 | Actual Loss: 0.5362\n",
      "Baseline Loss: 2.8320 | Actual Loss: 1.0820\n",
      "Baseline Loss: 2.8357 | Actual Loss: 1.8862\n",
      "Baseline Loss: 2.8587 | Actual Loss: 1.0787\n",
      "Baseline Loss: 2.8750 | Actual Loss: 0.9635\n",
      "Baseline Loss: 2.4889 | Actual Loss: 0.8236\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.9535\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.1551\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.7071\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.6349\n",
      "Epoch 33/1000: Train Loss: 0.9418, Val Loss: 0.8627\n",
      "New best validation loss: 0.8627\n",
      "Baseline Loss: 2.8315 | Actual Loss: 0.7865\n",
      "Baseline Loss: 2.8270 | Actual Loss: 0.6012\n",
      "Baseline Loss: 2.8325 | Actual Loss: 0.6945\n",
      "Baseline Loss: 2.8314 | Actual Loss: 1.0871\n",
      "Baseline Loss: 2.8533 | Actual Loss: 0.9054\n",
      "Baseline Loss: 2.8558 | Actual Loss: 1.1882\n",
      "Baseline Loss: 2.8520 | Actual Loss: 0.9129\n",
      "Baseline Loss: 2.8326 | Actual Loss: 0.9422\n",
      "Baseline Loss: 2.7971 | Actual Loss: 0.6092\n",
      "Baseline Loss: 2.8344 | Actual Loss: 0.8288\n",
      "Baseline Loss: 2.8286 | Actual Loss: 0.8760\n",
      "Baseline Loss: 2.8153 | Actual Loss: 0.6822\n",
      "Baseline Loss: 2.8687 | Actual Loss: 1.0401\n",
      "Baseline Loss: 2.8296 | Actual Loss: 0.4766\n",
      "Baseline Loss: 2.8447 | Actual Loss: 0.6769\n",
      "Baseline Loss: 2.3817 | Actual Loss: 0.4163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 34/1000 [00:11<05:14,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8199 | Actual Loss: 1.1753\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.2870\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.8668\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.7392\n",
      "Epoch 34/1000: Train Loss: 0.7953, Val Loss: 1.0171\n",
      "Baseline Loss: 2.7790 | Actual Loss: 0.8486\n",
      "Baseline Loss: 2.8518 | Actual Loss: 0.7283\n",
      "Baseline Loss: 2.8030 | Actual Loss: 0.6448\n",
      "Baseline Loss: 2.8368 | Actual Loss: 1.7044\n",
      "Baseline Loss: 2.7613 | Actual Loss: 0.5830\n",
      "Baseline Loss: 2.7731 | Actual Loss: 0.7596\n",
      "Baseline Loss: 2.8734 | Actual Loss: 0.7033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 35/1000 [00:11<05:00,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9014 | Actual Loss: 1.0811\n",
      "Baseline Loss: 2.7832 | Actual Loss: 1.1068\n",
      "Baseline Loss: 2.7852 | Actual Loss: 0.6946\n",
      "Baseline Loss: 2.8373 | Actual Loss: 1.5669\n",
      "Baseline Loss: 2.7245 | Actual Loss: 1.0479\n",
      "Baseline Loss: 2.8362 | Actual Loss: 0.7875\n",
      "Baseline Loss: 2.7653 | Actual Loss: 0.8432\n",
      "Baseline Loss: 2.8282 | Actual Loss: 1.1252\n",
      "Baseline Loss: 2.6682 | Actual Loss: 2.1829\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.9612\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.2759\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.8350\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.6546\n",
      "Epoch 35/1000: Train Loss: 1.0255, Val Loss: 0.9317\n",
      "Baseline Loss: 2.8803 | Actual Loss: 0.8883\n",
      "Baseline Loss: 2.7913 | Actual Loss: 0.8518\n",
      "Baseline Loss: 2.8325 | Actual Loss: 0.8674\n",
      "Baseline Loss: 2.7798 | Actual Loss: 1.1985\n",
      "Baseline Loss: 2.7960 | Actual Loss: 0.6977\n",
      "Baseline Loss: 2.8178 | Actual Loss: 0.6436\n",
      "Baseline Loss: 2.8171 | Actual Loss: 0.8539\n",
      "Baseline Loss: 2.8153 | Actual Loss: 0.7252\n",
      "Baseline Loss: 2.8964 | Actual Loss: 0.8706\n",
      "Baseline Loss: 2.8372 | Actual Loss: 0.8035\n",
      "Baseline Loss: 2.8078 | Actual Loss: 0.7571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 36/1000 [00:12<05:11,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8177 | Actual Loss: 0.8957\n",
      "Baseline Loss: 2.7828 | Actual Loss: 1.6379\n",
      "Baseline Loss: 2.7762 | Actual Loss: 0.7492\n",
      "Baseline Loss: 2.8736 | Actual Loss: 0.6803\n",
      "Baseline Loss: 2.6227 | Actual Loss: 1.1246\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.8599\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.4193\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.7655\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.6163\n",
      "Epoch 36/1000: Train Loss: 0.8903, Val Loss: 0.9152\n",
      "Baseline Loss: 2.8257 | Actual Loss: 0.9633\n",
      "Baseline Loss: 2.8768 | Actual Loss: 0.7126\n",
      "Baseline Loss: 2.8552 | Actual Loss: 1.3269\n",
      "Baseline Loss: 2.8313 | Actual Loss: 2.4510\n",
      "Baseline Loss: 2.7784 | Actual Loss: 0.6569\n",
      "Baseline Loss: 2.8052 | Actual Loss: 1.3498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 37/1000 [00:12<04:57,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7702 | Actual Loss: 0.7826\n",
      "Baseline Loss: 2.9332 | Actual Loss: 0.9626\n",
      "Baseline Loss: 2.8548 | Actual Loss: 1.5730\n",
      "Baseline Loss: 2.7981 | Actual Loss: 1.1931\n",
      "Baseline Loss: 2.8142 | Actual Loss: 1.1376\n",
      "Baseline Loss: 2.8439 | Actual Loss: 0.9193\n",
      "Baseline Loss: 2.8342 | Actual Loss: 0.9283\n",
      "Baseline Loss: 2.8958 | Actual Loss: 0.7051\n",
      "Baseline Loss: 2.7819 | Actual Loss: 0.6818\n",
      "Baseline Loss: 2.5403 | Actual Loss: 0.6649\n",
      "Baseline Loss: 2.8199 | Actual Loss: 1.3447\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.2240\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.8654\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.6878\n",
      "Epoch 37/1000: Train Loss: 1.0630, Val Loss: 1.0305\n",
      "Baseline Loss: 2.7958 | Actual Loss: 1.3936\n",
      "Baseline Loss: 2.7863 | Actual Loss: 0.8171\n",
      "Baseline Loss: 2.8595 | Actual Loss: 1.1482\n",
      "Baseline Loss: 2.7909 | Actual Loss: 0.7233\n",
      "Baseline Loss: 2.8247 | Actual Loss: 0.5897\n",
      "Baseline Loss: 2.7690 | Actual Loss: 0.7121\n",
      "Baseline Loss: 2.7862 | Actual Loss: 0.7273\n",
      "Baseline Loss: 2.8299 | Actual Loss: 1.2200\n",
      "Baseline Loss: 2.7948 | Actual Loss: 0.5779\n",
      "Baseline Loss: 2.7847 | Actual Loss: 1.5308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 38/1000 [00:12<05:10,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8585 | Actual Loss: 0.9959\n",
      "Baseline Loss: 2.8373 | Actual Loss: 0.5823\n",
      "Baseline Loss: 2.9231 | Actual Loss: 0.5627\n",
      "Baseline Loss: 2.9277 | Actual Loss: 0.8705\n",
      "Baseline Loss: 2.8071 | Actual Loss: 1.1847\n",
      "Baseline Loss: 2.5840 | Actual Loss: 1.3893\n",
      "Baseline Loss: 2.8199 | Actual Loss: 1.1593\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.1384\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.9261\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.7774\n",
      "Epoch 38/1000: Train Loss: 0.9391, Val Loss: 1.0003\n",
      "Baseline Loss: 2.8745 | Actual Loss: 1.4563\n",
      "Baseline Loss: 2.8754 | Actual Loss: 0.6528\n",
      "Baseline Loss: 2.7956 | Actual Loss: 0.8821\n",
      "Baseline Loss: 2.8166 | Actual Loss: 0.8032\n",
      "Baseline Loss: 2.8351 | Actual Loss: 0.8072\n",
      "Baseline Loss: 2.8591 | Actual Loss: 0.7466\n",
      "Baseline Loss: 2.8109 | Actual Loss: 0.9343\n",
      "Baseline Loss: 2.7725 | Actual Loss: 0.9911\n",
      "Baseline Loss: 2.8146 | Actual Loss: 1.4456\n",
      "Baseline Loss: 2.8167 | Actual Loss: 1.5515\n",
      "Baseline Loss: 2.8020 | Actual Loss: 0.5553\n",
      "Baseline Loss: 2.8283 | Actual Loss: 0.9248\n",
      "Baseline Loss: 2.8111 | Actual Loss: 0.4949\n",
      "Baseline Loss: 2.8248 | Actual Loss: 0.5236\n",
      "Baseline Loss: 2.8137 | Actual Loss: 0.8565\n",
      "Baseline Loss: 2.6812 | Actual Loss: 1.2865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 39/1000 [00:13<05:16,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8199 | Actual Loss: 1.0762\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.1191\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.7372\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.6288\n",
      "Epoch 39/1000: Train Loss: 0.9320, Val Loss: 0.8904\n",
      "Baseline Loss: 2.8237 | Actual Loss: 1.1247\n",
      "Baseline Loss: 2.8370 | Actual Loss: 0.8346\n",
      "Baseline Loss: 2.8019 | Actual Loss: 1.0399\n",
      "Baseline Loss: 2.8378 | Actual Loss: 1.0259\n",
      "Baseline Loss: 2.8402 | Actual Loss: 0.6198\n",
      "Baseline Loss: 2.8219 | Actual Loss: 0.7822\n",
      "Baseline Loss: 2.8168 | Actual Loss: 0.7284\n",
      "Baseline Loss: 2.8650 | Actual Loss: 0.9662\n",
      "Baseline Loss: 2.7907 | Actual Loss: 0.7986\n",
      "Baseline Loss: 2.8466 | Actual Loss: 0.8333\n",
      "Baseline Loss: 2.8726 | Actual Loss: 0.7562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 40/1000 [00:13<05:00,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8203 | Actual Loss: 1.5603\n",
      "Baseline Loss: 2.7722 | Actual Loss: 0.5223\n",
      "Baseline Loss: 2.7812 | Actual Loss: 0.7864\n",
      "Baseline Loss: 2.7771 | Actual Loss: 0.6706\n",
      "Baseline Loss: 2.5123 | Actual Loss: 0.4566\n",
      "Baseline Loss: 2.8199 | Actual Loss: 1.1412\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.2822\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.7599\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.5507\n",
      "Epoch 40/1000: Train Loss: 0.8441, Val Loss: 0.9335\n",
      "Baseline Loss: 2.7987 | Actual Loss: 0.6617\n",
      "Baseline Loss: 2.8792 | Actual Loss: 0.6507\n",
      "Baseline Loss: 2.7910 | Actual Loss: 0.8697\n",
      "Baseline Loss: 2.8207 | Actual Loss: 0.6681\n",
      "Baseline Loss: 2.8043 | Actual Loss: 0.8979\n",
      "Baseline Loss: 2.8662 | Actual Loss: 1.3845\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4123\n",
      "Baseline Loss: 2.8590 | Actual Loss: 0.7046\n",
      "Baseline Loss: 2.8479 | Actual Loss: 1.0499\n",
      "Baseline Loss: 2.7817 | Actual Loss: 0.7852\n",
      "Baseline Loss: 2.8440 | Actual Loss: 0.8801\n",
      "Baseline Loss: 2.7757 | Actual Loss: 0.5114\n",
      "Baseline Loss: 2.8591 | Actual Loss: 0.2408\n",
      "Baseline Loss: 2.8601 | Actual Loss: 0.9977\n",
      "Baseline Loss: 2.8513 | Actual Loss: 0.9465\n",
      "Baseline Loss: 2.5329 | Actual Loss: 0.5986\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.9689\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.2670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 41/1000 [00:13<05:14,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7998 | Actual Loss: 0.6615\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.5786\n",
      "Epoch 41/1000: Train Loss: 0.7662, Val Loss: 0.8690\n",
      "Baseline Loss: 2.8410 | Actual Loss: 0.9994\n",
      "Baseline Loss: 2.7621 | Actual Loss: 0.8563\n",
      "Baseline Loss: 2.8029 | Actual Loss: 2.0496\n",
      "Baseline Loss: 2.8604 | Actual Loss: 0.6427\n",
      "Baseline Loss: 2.8483 | Actual Loss: 1.4532\n",
      "Baseline Loss: 2.7743 | Actual Loss: 0.5972\n",
      "Baseline Loss: 2.8498 | Actual Loss: 0.5568\n",
      "Baseline Loss: 2.7981 | Actual Loss: 1.0642\n",
      "Baseline Loss: 2.8797 | Actual Loss: 0.7786\n",
      "Baseline Loss: 2.8182 | Actual Loss: 1.1413\n",
      "Baseline Loss: 2.8338 | Actual Loss: 0.6533\n",
      "Baseline Loss: 2.8020 | Actual Loss: 0.5839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 42/1000 [00:14<05:02,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8529 | Actual Loss: 0.5686\n",
      "Baseline Loss: 2.8323 | Actual Loss: 0.7045\n",
      "Baseline Loss: 2.8101 | Actual Loss: 0.7130\n",
      "Baseline Loss: 2.3910 | Actual Loss: 0.4577\n",
      "Baseline Loss: 2.8199 | Actual Loss: 1.0415\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.7640\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.8499\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.5088\n",
      "Epoch 42/1000: Train Loss: 0.8638, Val Loss: 1.0411\n",
      "Baseline Loss: 2.8126 | Actual Loss: 0.7248\n",
      "Baseline Loss: 2.7780 | Actual Loss: 0.8158\n",
      "Baseline Loss: 2.8385 | Actual Loss: 0.7244\n",
      "Baseline Loss: 2.9014 | Actual Loss: 0.5864\n",
      "Baseline Loss: 2.8642 | Actual Loss: 1.0102\n",
      "Baseline Loss: 2.8697 | Actual Loss: 0.6351\n",
      "Baseline Loss: 2.7735 | Actual Loss: 0.7934\n",
      "Baseline Loss: 2.7715 | Actual Loss: 0.6880\n",
      "Baseline Loss: 2.7767 | Actual Loss: 1.0106\n",
      "Baseline Loss: 2.8247 | Actual Loss: 0.5163\n",
      "Baseline Loss: 2.9134 | Actual Loss: 0.7343\n",
      "Baseline Loss: 2.8211 | Actual Loss: 0.7050\n",
      "Baseline Loss: 2.7977 | Actual Loss: 1.2773\n",
      "Baseline Loss: 2.8469 | Actual Loss: 1.7953\n",
      "Baseline Loss: 2.8056 | Actual Loss: 0.9573\n",
      "Baseline Loss: 2.4919 | Actual Loss: 0.5375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 43/1000 [00:14<05:16,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8199 | Actual Loss: 1.0764\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.1521\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.8233\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.5259\n",
      "Epoch 43/1000: Train Loss: 0.8445, Val Loss: 0.8944\n",
      "Baseline Loss: 2.8557 | Actual Loss: 0.6591\n",
      "Baseline Loss: 2.8167 | Actual Loss: 0.8879\n",
      "Baseline Loss: 2.8040 | Actual Loss: 0.6222\n",
      "Baseline Loss: 2.8565 | Actual Loss: 0.5206\n",
      "Baseline Loss: 2.8195 | Actual Loss: 0.5568\n",
      "Baseline Loss: 2.8398 | Actual Loss: 0.5997\n",
      "Baseline Loss: 2.8472 | Actual Loss: 0.6468\n",
      "Baseline Loss: 2.7662 | Actual Loss: 0.4263\n",
      "Baseline Loss: 2.7813 | Actual Loss: 0.8937\n",
      "Baseline Loss: 2.8530 | Actual Loss: 0.9240\n",
      "Baseline Loss: 2.8018 | Actual Loss: 0.6365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 44/1000 [00:14<05:23,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8041 | Actual Loss: 0.4637\n",
      "Baseline Loss: 2.7865 | Actual Loss: 0.8207\n",
      "Baseline Loss: 2.7813 | Actual Loss: 0.8686\n",
      "Baseline Loss: 2.8618 | Actual Loss: 0.7923\n",
      "Baseline Loss: 2.6035 | Actual Loss: 0.5641\n",
      "Baseline Loss: 2.8199 | Actual Loss: 1.1925\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.4553\n",
      "Baseline Loss: 2.7998 | Actual Loss: 1.0582\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.4003\n",
      "Epoch 44/1000: Train Loss: 0.6802, Val Loss: 1.0266\n",
      "Baseline Loss: 2.8087 | Actual Loss: 1.0674\n",
      "Baseline Loss: 2.8806 | Actual Loss: 0.8077\n",
      "Baseline Loss: 2.9018 | Actual Loss: 0.6668\n",
      "Baseline Loss: 2.8598 | Actual Loss: 2.5765\n",
      "Baseline Loss: 2.7712 | Actual Loss: 1.3909\n",
      "Baseline Loss: 2.7988 | Actual Loss: 0.5393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 45/1000 [00:15<05:09,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7873 | Actual Loss: 0.5058\n",
      "Baseline Loss: 2.8446 | Actual Loss: 0.7909\n",
      "Baseline Loss: 2.7801 | Actual Loss: 0.6008\n",
      "Baseline Loss: 2.8039 | Actual Loss: 1.7117\n",
      "Baseline Loss: 2.8268 | Actual Loss: 0.6901\n",
      "Baseline Loss: 2.8500 | Actual Loss: 0.2423\n",
      "Baseline Loss: 2.7555 | Actual Loss: 0.4775\n",
      "Baseline Loss: 2.8770 | Actual Loss: 0.6120\n",
      "Baseline Loss: 2.8214 | Actual Loss: 1.4215\n",
      "Baseline Loss: 2.5729 | Actual Loss: 0.3371\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.9801\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.2059\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5927\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.5806\n",
      "Epoch 45/1000: Train Loss: 0.9024, Val Loss: 0.8398\n",
      "New best validation loss: 0.8398\n",
      "Baseline Loss: 2.8288 | Actual Loss: 0.8616\n",
      "Baseline Loss: 2.7640 | Actual Loss: 0.5403\n",
      "Baseline Loss: 2.8427 | Actual Loss: 0.6594\n",
      "Baseline Loss: 2.7980 | Actual Loss: 0.7677\n",
      "Baseline Loss: 2.8452 | Actual Loss: 0.6305\n",
      "Baseline Loss: 2.9343 | Actual Loss: 0.8001\n",
      "Baseline Loss: 2.8289 | Actual Loss: 1.1602\n",
      "Baseline Loss: 2.8549 | Actual Loss: 0.7262\n",
      "Baseline Loss: 2.8144 | Actual Loss: 0.6244\n",
      "Baseline Loss: 2.8585 | Actual Loss: 0.6044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 46/1000 [00:15<05:14,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8510 | Actual Loss: 0.9680\n",
      "Baseline Loss: 2.8002 | Actual Loss: 1.0063\n",
      "Baseline Loss: 2.9037 | Actual Loss: 2.8261\n",
      "Baseline Loss: 2.7922 | Actual Loss: 0.8476\n",
      "Baseline Loss: 2.8508 | Actual Loss: 0.5954\n",
      "Baseline Loss: 2.6357 | Actual Loss: 1.1667\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.9796\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.1448\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.7327\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.5574\n",
      "Epoch 46/1000: Train Loss: 0.9240, Val Loss: 0.8536\n",
      "Baseline Loss: 2.8397 | Actual Loss: 0.7327\n",
      "Baseline Loss: 2.8420 | Actual Loss: 1.4941\n",
      "Baseline Loss: 2.8102 | Actual Loss: 0.7906\n",
      "Baseline Loss: 2.8412 | Actual Loss: 0.6578\n",
      "Baseline Loss: 2.7496 | Actual Loss: 0.7149\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.1592\n",
      "Baseline Loss: 2.8084 | Actual Loss: 0.4382\n",
      "Baseline Loss: 2.8433 | Actual Loss: 0.7791\n",
      "Baseline Loss: 2.8258 | Actual Loss: 1.3165\n",
      "Baseline Loss: 2.8235 | Actual Loss: 0.8732\n",
      "Baseline Loss: 2.7543 | Actual Loss: 0.7181\n",
      "Baseline Loss: 2.9282 | Actual Loss: 0.5102\n",
      "Baseline Loss: 2.7956 | Actual Loss: 1.5815\n",
      "Baseline Loss: 2.7792 | Actual Loss: 0.9258\n",
      "Baseline Loss: 2.8154 | Actual Loss: 0.3236\n",
      "Baseline Loss: 2.5686 | Actual Loss: 0.9367\n",
      "Baseline Loss: 2.8199 | Actual Loss: 1.1524\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.1699\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.8151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 47/1000 [00:15<05:00,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7254 | Actual Loss: 0.5077\n",
      "Epoch 47/1000: Train Loss: 0.8720, Val Loss: 0.9113\n",
      "Baseline Loss: 2.8432 | Actual Loss: 1.1525\n",
      "Baseline Loss: 2.8892 | Actual Loss: 0.3722\n",
      "Baseline Loss: 2.8780 | Actual Loss: 0.7273\n",
      "Baseline Loss: 2.8059 | Actual Loss: 0.4443\n",
      "Baseline Loss: 2.9157 | Actual Loss: 0.6767\n",
      "Baseline Loss: 2.7715 | Actual Loss: 1.6765\n",
      "Baseline Loss: 2.7907 | Actual Loss: 1.8063\n",
      "Baseline Loss: 2.8771 | Actual Loss: 0.8856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 48/1000 [00:16<05:13,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9343 | Actual Loss: 0.7439\n",
      "Baseline Loss: 2.7762 | Actual Loss: 0.5796\n",
      "Baseline Loss: 2.7735 | Actual Loss: 0.7545\n",
      "Baseline Loss: 2.8011 | Actual Loss: 0.9809\n",
      "Baseline Loss: 2.8058 | Actual Loss: 0.5240\n",
      "Baseline Loss: 2.7818 | Actual Loss: 0.5908\n",
      "Baseline Loss: 2.8373 | Actual Loss: 0.5057\n",
      "Baseline Loss: 2.3838 | Actual Loss: 0.8352\n",
      "Baseline Loss: 2.8199 | Actual Loss: 1.0145\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.0215\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.7962\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.5376\n",
      "Epoch 48/1000: Train Loss: 0.8285, Val Loss: 0.8424\n",
      "Baseline Loss: 2.8000 | Actual Loss: 0.9777\n",
      "Baseline Loss: 2.8731 | Actual Loss: 0.6236\n",
      "Baseline Loss: 2.8495 | Actual Loss: 1.0682\n",
      "Baseline Loss: 2.7822 | Actual Loss: 0.5589\n",
      "Baseline Loss: 2.7755 | Actual Loss: 1.0868\n",
      "Baseline Loss: 2.8168 | Actual Loss: 0.7916\n",
      "Baseline Loss: 2.8172 | Actual Loss: 0.3861\n",
      "Baseline Loss: 2.7939 | Actual Loss: 0.7002\n",
      "Baseline Loss: 2.8343 | Actual Loss: 0.6038\n",
      "Baseline Loss: 2.7778 | Actual Loss: 0.7498\n",
      "Baseline Loss: 2.8200 | Actual Loss: 2.4396\n",
      "Baseline Loss: 2.8443 | Actual Loss: 0.3827\n",
      "Baseline Loss: 2.8586 | Actual Loss: 0.5740\n",
      "Baseline Loss: 2.8953 | Actual Loss: 0.6631\n",
      "Baseline Loss: 2.8979 | Actual Loss: 0.8614\n",
      "Baseline Loss: 2.5589 | Actual Loss: 0.7703\n",
      "Baseline Loss: 2.8199 | Actual Loss: 1.3120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 49/1000 [00:16<05:26,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8180 | Actual Loss: 1.1902\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.9052\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.5397\n",
      "Epoch 49/1000: Train Loss: 0.8273, Val Loss: 0.9868\n",
      "Baseline Loss: 2.9084 | Actual Loss: 0.7815\n",
      "Baseline Loss: 2.8308 | Actual Loss: 1.2628\n",
      "Baseline Loss: 2.8768 | Actual Loss: 0.9325\n",
      "Baseline Loss: 2.8461 | Actual Loss: 0.4860\n",
      "Baseline Loss: 2.8336 | Actual Loss: 0.4941\n",
      "Baseline Loss: 2.8616 | Actual Loss: 1.4366\n",
      "Baseline Loss: 2.8611 | Actual Loss: 1.2277\n",
      "Baseline Loss: 2.7832 | Actual Loss: 0.7507\n",
      "Baseline Loss: 2.8289 | Actual Loss: 0.7720\n",
      "Baseline Loss: 2.8069 | Actual Loss: 0.6934\n",
      "Baseline Loss: 2.7868 | Actual Loss: 0.6658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 50/1000 [00:16<05:12,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8141 | Actual Loss: 0.7454\n",
      "Baseline Loss: 2.7864 | Actual Loss: 0.9969\n",
      "Baseline Loss: 2.7795 | Actual Loss: 0.5880\n",
      "Baseline Loss: 2.8651 | Actual Loss: 0.5420\n",
      "Baseline Loss: 2.4786 | Actual Loss: 2.0817\n",
      "Baseline Loss: 2.8199 | Actual Loss: 1.5484\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.2595\n",
      "Baseline Loss: 2.7998 | Actual Loss: 1.1467\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.4979\n",
      "Epoch 50/1000: Train Loss: 0.9036, Val Loss: 1.1131\n",
      "Baseline Loss: 2.8364 | Actual Loss: 0.4857\n",
      "Baseline Loss: 2.8668 | Actual Loss: 0.8551\n",
      "Baseline Loss: 2.7613 | Actual Loss: 0.7459\n",
      "Baseline Loss: 2.8717 | Actual Loss: 0.4154\n",
      "Baseline Loss: 2.7684 | Actual Loss: 0.8695\n",
      "Baseline Loss: 2.9069 | Actual Loss: 1.2587\n",
      "Baseline Loss: 2.8512 | Actual Loss: 0.5223\n",
      "Baseline Loss: 2.7944 | Actual Loss: 0.8431\n",
      "Baseline Loss: 2.8105 | Actual Loss: 0.7253\n",
      "Baseline Loss: 2.8206 | Actual Loss: 1.0298\n",
      "Baseline Loss: 2.7642 | Actual Loss: 0.5589\n",
      "Baseline Loss: 2.9052 | Actual Loss: 0.5274\n",
      "Baseline Loss: 2.8358 | Actual Loss: 0.7958\n",
      "Baseline Loss: 2.9215 | Actual Loss: 1.2849\n",
      "Baseline Loss: 2.7812 | Actual Loss: 0.7608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 51/1000 [00:17<05:17,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5496 | Actual Loss: 0.3706\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.7796\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.0707\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5910\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.4715\n",
      "Epoch 51/1000: Train Loss: 0.7531, Val Loss: 0.7282\n",
      "New best validation loss: 0.7282\n",
      "Baseline Loss: 2.8439 | Actual Loss: 0.3282\n",
      "Baseline Loss: 2.8508 | Actual Loss: 0.4933\n",
      "Baseline Loss: 2.8818 | Actual Loss: 1.4599\n",
      "Baseline Loss: 2.8399 | Actual Loss: 0.9327\n",
      "Baseline Loss: 2.8356 | Actual Loss: 0.4385\n",
      "Baseline Loss: 2.7806 | Actual Loss: 1.2602\n",
      "Baseline Loss: 2.8127 | Actual Loss: 1.5343\n",
      "Baseline Loss: 2.8248 | Actual Loss: 0.5445\n",
      "Baseline Loss: 2.7990 | Actual Loss: 1.3138\n",
      "Baseline Loss: 2.8133 | Actual Loss: 2.0180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 52/1000 [00:17<05:22,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8633 | Actual Loss: 1.1546\n",
      "Baseline Loss: 2.8242 | Actual Loss: 0.6685\n",
      "Baseline Loss: 2.8388 | Actual Loss: 1.3394\n",
      "Baseline Loss: 2.7869 | Actual Loss: 0.5139\n",
      "Baseline Loss: 2.7629 | Actual Loss: 0.8300\n",
      "Baseline Loss: 2.6572 | Actual Loss: 0.6122\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.9235\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.1373\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.8130\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.6964\n",
      "Epoch 52/1000: Train Loss: 0.9651, Val Loss: 0.8926\n",
      "Baseline Loss: 2.8150 | Actual Loss: 0.8308\n",
      "Baseline Loss: 2.8376 | Actual Loss: 0.7298\n",
      "Baseline Loss: 2.8031 | Actual Loss: 0.9978\n",
      "Baseline Loss: 2.8813 | Actual Loss: 0.7102\n",
      "Baseline Loss: 2.8568 | Actual Loss: 0.4725\n",
      "Baseline Loss: 2.8754 | Actual Loss: 0.7596\n",
      "Baseline Loss: 2.7684 | Actual Loss: 0.6081\n",
      "Baseline Loss: 2.8904 | Actual Loss: 0.7059\n",
      "Baseline Loss: 2.8284 | Actual Loss: 0.8567\n",
      "Baseline Loss: 2.8516 | Actual Loss: 0.7716\n",
      "Baseline Loss: 2.7629 | Actual Loss: 0.8760\n",
      "Baseline Loss: 2.8549 | Actual Loss: 1.7883\n",
      "Baseline Loss: 2.9008 | Actual Loss: 0.3307\n",
      "Baseline Loss: 2.8393 | Actual Loss: 0.8658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 53/1000 [00:17<05:04,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8348 | Actual Loss: 1.1981\n",
      "Baseline Loss: 2.3609 | Actual Loss: 0.1837\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.7019\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.3572\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.7224\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.6221\n",
      "Epoch 53/1000: Train Loss: 0.7929, Val Loss: 0.8509\n",
      "Baseline Loss: 2.8573 | Actual Loss: 1.0472\n",
      "Baseline Loss: 2.7945 | Actual Loss: 0.6993\n",
      "Baseline Loss: 2.7803 | Actual Loss: 0.8791\n",
      "Baseline Loss: 2.8509 | Actual Loss: 0.7931\n",
      "Baseline Loss: 2.8431 | Actual Loss: 0.5597\n",
      "Baseline Loss: 2.7328 | Actual Loss: 0.4555\n",
      "Baseline Loss: 2.8617 | Actual Loss: 0.3568\n",
      "Baseline Loss: 2.8203 | Actual Loss: 0.8573\n",
      "Baseline Loss: 2.7757 | Actual Loss: 1.0601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 54/1000 [00:18<05:17,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8232 | Actual Loss: 0.8056\n",
      "Baseline Loss: 2.7816 | Actual Loss: 0.5837\n",
      "Baseline Loss: 2.9348 | Actual Loss: 0.4115\n",
      "Baseline Loss: 2.9173 | Actual Loss: 0.8248\n",
      "Baseline Loss: 2.8277 | Actual Loss: 0.7938\n",
      "Baseline Loss: 2.7959 | Actual Loss: 1.3323\n",
      "Baseline Loss: 2.6566 | Actual Loss: 0.3854\n",
      "Baseline Loss: 2.8199 | Actual Loss: 1.0388\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.3446\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.7283\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.4588\n",
      "Epoch 54/1000: Train Loss: 0.7403, Val Loss: 0.8926\n",
      "Baseline Loss: 2.7610 | Actual Loss: 1.4569\n",
      "Baseline Loss: 2.7866 | Actual Loss: 1.0227\n",
      "Baseline Loss: 2.8214 | Actual Loss: 1.0794\n",
      "Baseline Loss: 2.7968 | Actual Loss: 0.4784\n",
      "Baseline Loss: 2.7329 | Actual Loss: 1.0506\n",
      "Baseline Loss: 2.8721 | Actual Loss: 0.6215\n",
      "Baseline Loss: 2.8615 | Actual Loss: 0.5341\n",
      "Baseline Loss: 2.9039 | Actual Loss: 0.4081\n",
      "Baseline Loss: 2.8557 | Actual Loss: 0.9149\n",
      "Baseline Loss: 2.8529 | Actual Loss: 0.4823\n",
      "Baseline Loss: 2.7695 | Actual Loss: 0.6588\n",
      "Baseline Loss: 2.7925 | Actual Loss: 0.2823\n",
      "Baseline Loss: 2.8762 | Actual Loss: 0.6323\n",
      "Baseline Loss: 2.8198 | Actual Loss: 0.4190\n",
      "Baseline Loss: 2.7876 | Actual Loss: 1.1414\n",
      "Baseline Loss: 2.5940 | Actual Loss: 1.7668\n",
      "Baseline Loss: 2.8199 | Actual Loss: 1.2405\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.4387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 55/1000 [00:18<04:56,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7998 | Actual Loss: 0.7420\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3892\n",
      "Epoch 55/1000: Train Loss: 0.8094, Val Loss: 0.9526\n",
      "Baseline Loss: 2.8716 | Actual Loss: 0.8536\n",
      "Baseline Loss: 2.8553 | Actual Loss: 1.6578\n",
      "Baseline Loss: 2.8722 | Actual Loss: 0.9006\n",
      "Baseline Loss: 2.7573 | Actual Loss: 0.6162\n",
      "Baseline Loss: 2.8615 | Actual Loss: 0.7198\n",
      "Baseline Loss: 2.8040 | Actual Loss: 0.8358\n",
      "Baseline Loss: 2.8086 | Actual Loss: 0.6872\n",
      "Baseline Loss: 2.8172 | Actual Loss: 0.7411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 56/1000 [00:18<05:07,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7971 | Actual Loss: 0.3039\n",
      "Baseline Loss: 2.8628 | Actual Loss: 1.5397\n",
      "Baseline Loss: 2.7613 | Actual Loss: 1.0415\n",
      "Baseline Loss: 2.8144 | Actual Loss: 0.8835\n",
      "Baseline Loss: 2.7860 | Actual Loss: 0.6127\n",
      "Baseline Loss: 2.9098 | Actual Loss: 0.3545\n",
      "Baseline Loss: 2.7872 | Actual Loss: 0.6644\n",
      "Baseline Loss: 2.6551 | Actual Loss: 0.6751\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.7399\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.2395\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.7340\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.5656\n",
      "Epoch 56/1000: Train Loss: 0.8180, Val Loss: 0.8198\n",
      "Baseline Loss: 2.9018 | Actual Loss: 0.2833\n",
      "Baseline Loss: 2.8824 | Actual Loss: 0.4989\n",
      "Baseline Loss: 2.7958 | Actual Loss: 0.6062\n",
      "Baseline Loss: 2.8376 | Actual Loss: 0.3622\n",
      "Baseline Loss: 2.9147 | Actual Loss: 0.8621\n",
      "Baseline Loss: 2.8455 | Actual Loss: 0.5404\n",
      "Baseline Loss: 2.8242 | Actual Loss: 1.6309\n",
      "Baseline Loss: 2.7649 | Actual Loss: 0.5073\n",
      "Baseline Loss: 2.8898 | Actual Loss: 1.7636\n",
      "Baseline Loss: 2.8451 | Actual Loss: 1.7300\n",
      "Baseline Loss: 2.8044 | Actual Loss: 0.6410\n",
      "Baseline Loss: 2.7500 | Actual Loss: 1.0531\n",
      "Baseline Loss: 2.7956 | Actual Loss: 0.9935\n",
      "Baseline Loss: 2.8034 | Actual Loss: 0.7646\n",
      "Baseline Loss: 2.7518 | Actual Loss: 0.8714\n",
      "Baseline Loss: 2.4492 | Actual Loss: 0.7145\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.9809\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.1847\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.7139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 57/1000 [00:18<04:46,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7254 | Actual Loss: 0.7340\n",
      "Epoch 57/1000: Train Loss: 0.8639, Val Loss: 0.9034\n",
      "Baseline Loss: 2.8628 | Actual Loss: 0.6905\n",
      "Baseline Loss: 2.7780 | Actual Loss: 1.3428\n",
      "Baseline Loss: 2.8856 | Actual Loss: 1.3398\n",
      "Baseline Loss: 2.8658 | Actual Loss: 0.7247\n",
      "Baseline Loss: 2.8313 | Actual Loss: 0.8263\n",
      "Baseline Loss: 2.8585 | Actual Loss: 0.7156\n",
      "Baseline Loss: 2.7907 | Actual Loss: 0.4789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 58/1000 [00:19<04:59,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8366 | Actual Loss: 0.4244\n",
      "Baseline Loss: 2.7683 | Actual Loss: 1.0479\n",
      "Baseline Loss: 2.8364 | Actual Loss: 0.4497\n",
      "Baseline Loss: 2.8021 | Actual Loss: 0.4695\n",
      "Baseline Loss: 2.7783 | Actual Loss: 1.7871\n",
      "Baseline Loss: 2.8111 | Actual Loss: 0.2094\n",
      "Baseline Loss: 2.8765 | Actual Loss: 0.5465\n",
      "Baseline Loss: 2.8606 | Actual Loss: 0.8287\n",
      "Baseline Loss: 2.5182 | Actual Loss: 1.2698\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.9883\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.0361\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.6333\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.5326\n",
      "Epoch 58/1000: Train Loss: 0.8220, Val Loss: 0.7976\n",
      "Baseline Loss: 2.8600 | Actual Loss: 1.0414\n",
      "Baseline Loss: 2.7670 | Actual Loss: 0.3924\n",
      "Baseline Loss: 2.7793 | Actual Loss: 0.7728\n",
      "Baseline Loss: 2.8031 | Actual Loss: 0.7538\n",
      "Baseline Loss: 2.8532 | Actual Loss: 0.6024\n",
      "Baseline Loss: 2.8926 | Actual Loss: 0.9114\n",
      "Baseline Loss: 2.8012 | Actual Loss: 0.4559\n",
      "Baseline Loss: 2.8414 | Actual Loss: 0.4335\n",
      "Baseline Loss: 2.8318 | Actual Loss: 0.6045\n",
      "Baseline Loss: 2.8684 | Actual Loss: 1.0017\n",
      "Baseline Loss: 2.8318 | Actual Loss: 0.8297\n",
      "Baseline Loss: 2.7733 | Actual Loss: 0.5812\n",
      "Baseline Loss: 2.7733 | Actual Loss: 0.4305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 59/1000 [00:19<05:12,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8146 | Actual Loss: 0.8711\n",
      "Baseline Loss: 2.8739 | Actual Loss: 0.4746\n",
      "Baseline Loss: 2.5912 | Actual Loss: 0.6138\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.9978\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.0129\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.6423\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.5237\n",
      "Epoch 59/1000: Train Loss: 0.6732, Val Loss: 0.7942\n",
      "Baseline Loss: 2.8052 | Actual Loss: 0.4597\n",
      "Baseline Loss: 2.8396 | Actual Loss: 1.1555\n",
      "Baseline Loss: 2.7741 | Actual Loss: 0.4197\n",
      "Baseline Loss: 2.8257 | Actual Loss: 0.3823\n",
      "Baseline Loss: 2.7905 | Actual Loss: 0.6853\n",
      "Baseline Loss: 2.7930 | Actual Loss: 0.6385\n",
      "Baseline Loss: 2.8267 | Actual Loss: 1.0363\n",
      "Baseline Loss: 2.8686 | Actual Loss: 0.4127\n",
      "Baseline Loss: 2.8402 | Actual Loss: 0.2763\n",
      "Baseline Loss: 2.9011 | Actual Loss: 2.5508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 60/1000 [00:19<04:52,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8461 | Actual Loss: 1.9752\n",
      "Baseline Loss: 2.8539 | Actual Loss: 0.6093\n",
      "Baseline Loss: 2.7611 | Actual Loss: 0.2042\n",
      "Baseline Loss: 2.7732 | Actual Loss: 0.5659\n",
      "Baseline Loss: 2.8491 | Actual Loss: 0.5115\n",
      "Baseline Loss: 2.4819 | Actual Loss: 0.2991\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.9291\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.9528\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.6015\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.4168\n",
      "Epoch 60/1000: Train Loss: 0.7614, Val Loss: 0.7251\n",
      "New best validation loss: 0.7251\n",
      "Baseline Loss: 2.9214 | Actual Loss: 0.5958\n",
      "Baseline Loss: 2.7791 | Actual Loss: 0.3617\n",
      "Baseline Loss: 2.8609 | Actual Loss: 1.8491\n",
      "Baseline Loss: 2.8726 | Actual Loss: 0.3489\n",
      "Baseline Loss: 2.8553 | Actual Loss: 0.5459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 61/1000 [00:20<05:00,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7836 | Actual Loss: 0.4232\n",
      "Baseline Loss: 2.8354 | Actual Loss: 0.3633\n",
      "Baseline Loss: 2.7832 | Actual Loss: 0.8775\n",
      "Baseline Loss: 2.8176 | Actual Loss: 1.4263\n",
      "Baseline Loss: 2.8261 | Actual Loss: 0.3340\n",
      "Baseline Loss: 2.7684 | Actual Loss: 0.5954\n",
      "Baseline Loss: 2.8092 | Actual Loss: 0.2691\n",
      "Baseline Loss: 2.7676 | Actual Loss: 0.8108\n",
      "Baseline Loss: 2.8044 | Actual Loss: 0.5790\n",
      "Baseline Loss: 2.8051 | Actual Loss: 1.9950\n",
      "Baseline Loss: 2.5104 | Actual Loss: 0.4965\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.8726\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.1423\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.6986\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.5880\n",
      "Epoch 61/1000: Train Loss: 0.7420, Val Loss: 0.8254\n",
      "Baseline Loss: 2.8540 | Actual Loss: 0.8634\n",
      "Baseline Loss: 2.8388 | Actual Loss: 0.8461\n",
      "Baseline Loss: 2.8590 | Actual Loss: 0.6366\n",
      "Baseline Loss: 2.8426 | Actual Loss: 0.8654\n",
      "Baseline Loss: 2.7915 | Actual Loss: 0.6026\n",
      "Baseline Loss: 2.8879 | Actual Loss: 0.8399\n",
      "Baseline Loss: 2.8129 | Actual Loss: 0.7321\n",
      "Baseline Loss: 2.8021 | Actual Loss: 1.0794\n",
      "Baseline Loss: 2.8443 | Actual Loss: 0.4435\n",
      "Baseline Loss: 2.8007 | Actual Loss: 1.2496\n",
      "Baseline Loss: 2.8356 | Actual Loss: 0.5412\n",
      "Baseline Loss: 2.8202 | Actual Loss: 1.0043\n",
      "Baseline Loss: 2.8286 | Actual Loss: 0.1764\n",
      "Baseline Loss: 2.7869 | Actual Loss: 0.5604\n",
      "Baseline Loss: 2.8231 | Actual Loss: 1.3687\n",
      "Baseline Loss: 2.4916 | Actual Loss: 0.1515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 62/1000 [00:20<05:12,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8199 | Actual Loss: 0.8871\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.1233\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.6902\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3328\n",
      "Epoch 62/1000: Train Loss: 0.7476, Val Loss: 0.7583\n",
      "Baseline Loss: 2.7707 | Actual Loss: 0.6622\n",
      "Baseline Loss: 2.8596 | Actual Loss: 1.0005\n",
      "Baseline Loss: 2.8203 | Actual Loss: 0.7019\n",
      "Baseline Loss: 2.8274 | Actual Loss: 0.6463\n",
      "Baseline Loss: 2.7989 | Actual Loss: 0.8168\n",
      "Baseline Loss: 2.8911 | Actual Loss: 0.5601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 63/1000 [00:20<04:55,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8659 | Actual Loss: 0.6047\n",
      "Baseline Loss: 2.7568 | Actual Loss: 0.5319\n",
      "Baseline Loss: 2.8432 | Actual Loss: 0.8166\n",
      "Baseline Loss: 2.8880 | Actual Loss: 0.4640\n",
      "Baseline Loss: 2.8508 | Actual Loss: 1.4908\n",
      "Baseline Loss: 2.7862 | Actual Loss: 0.4554\n",
      "Baseline Loss: 2.8193 | Actual Loss: 0.9630\n",
      "Baseline Loss: 2.8798 | Actual Loss: 0.3026\n",
      "Baseline Loss: 2.8479 | Actual Loss: 0.7913\n",
      "Baseline Loss: 2.5262 | Actual Loss: 1.0701\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.6602\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8761\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.6156\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.4535\n",
      "Epoch 63/1000: Train Loss: 0.7424, Val Loss: 0.6514\n",
      "New best validation loss: 0.6514\n",
      "Baseline Loss: 2.8056 | Actual Loss: 0.6341\n",
      "Baseline Loss: 2.7824 | Actual Loss: 0.8017\n",
      "Baseline Loss: 2.8137 | Actual Loss: 0.8548\n",
      "Baseline Loss: 2.8720 | Actual Loss: 0.5729\n",
      "Baseline Loss: 2.8400 | Actual Loss: 0.3806\n",
      "Baseline Loss: 2.7944 | Actual Loss: 0.7399\n",
      "Baseline Loss: 2.8719 | Actual Loss: 0.9290\n",
      "Baseline Loss: 2.8798 | Actual Loss: 1.0203\n",
      "Baseline Loss: 2.7865 | Actual Loss: 0.4167\n",
      "Baseline Loss: 2.8493 | Actual Loss: 0.5268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 64/1000 [00:21<04:56,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8472 | Actual Loss: 1.2276\n",
      "Baseline Loss: 2.7724 | Actual Loss: 0.6982\n",
      "Baseline Loss: 2.8973 | Actual Loss: 0.5738\n",
      "Baseline Loss: 2.7832 | Actual Loss: 0.6733\n",
      "Baseline Loss: 2.7868 | Actual Loss: 1.5374\n",
      "Baseline Loss: 2.5176 | Actual Loss: 0.8560\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.7684\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.1948\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.7951\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3923\n",
      "Epoch 64/1000: Train Loss: 0.7777, Val Loss: 0.7876\n",
      "Baseline Loss: 2.8570 | Actual Loss: 0.7538\n",
      "Baseline Loss: 2.8912 | Actual Loss: 1.1194\n",
      "Baseline Loss: 2.8352 | Actual Loss: 0.4882\n",
      "Baseline Loss: 2.8208 | Actual Loss: 0.6465\n",
      "Baseline Loss: 2.8144 | Actual Loss: 0.5855\n",
      "Baseline Loss: 2.7629 | Actual Loss: 0.6386\n",
      "Baseline Loss: 2.7848 | Actual Loss: 0.7405\n",
      "Baseline Loss: 2.7762 | Actual Loss: 0.4424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 65/1000 [00:21<04:44,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7993 | Actual Loss: 0.6822\n",
      "Baseline Loss: 2.8284 | Actual Loss: 0.6227\n",
      "Baseline Loss: 2.7832 | Actual Loss: 0.7958\n",
      "Baseline Loss: 2.8768 | Actual Loss: 0.3186\n",
      "Baseline Loss: 2.8662 | Actual Loss: 0.3212\n",
      "Baseline Loss: 2.9047 | Actual Loss: 0.9945\n",
      "Baseline Loss: 2.8421 | Actual Loss: 0.7212\n",
      "Baseline Loss: 2.4530 | Actual Loss: 0.3888\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.7770\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.0561\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.6344\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.5683\n",
      "Epoch 65/1000: Train Loss: 0.6412, Val Loss: 0.7589\n",
      "Baseline Loss: 2.8423 | Actual Loss: 0.3367\n",
      "Baseline Loss: 2.7919 | Actual Loss: 1.3594\n",
      "Baseline Loss: 2.8779 | Actual Loss: 0.8625\n",
      "Baseline Loss: 2.7949 | Actual Loss: 0.4071\n",
      "Baseline Loss: 2.8837 | Actual Loss: 0.8235\n",
      "Baseline Loss: 2.7992 | Actual Loss: 0.5504\n",
      "Baseline Loss: 2.7365 | Actual Loss: 0.2958\n",
      "Baseline Loss: 2.8277 | Actual Loss: 1.4942\n",
      "Baseline Loss: 2.8117 | Actual Loss: 0.3137\n",
      "Baseline Loss: 2.7876 | Actual Loss: 0.8798\n",
      "Baseline Loss: 2.7932 | Actual Loss: 0.5901\n",
      "Baseline Loss: 2.8006 | Actual Loss: 0.2890\n",
      "Baseline Loss: 2.8601 | Actual Loss: 0.2527\n",
      "Baseline Loss: 2.8051 | Actual Loss: 0.4847\n",
      "Baseline Loss: 2.8598 | Actual Loss: 1.3542\n",
      "Baseline Loss: 2.5294 | Actual Loss: 0.3888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 66/1000 [00:21<04:55,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8199 | Actual Loss: 0.5017\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.9317\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.6848\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.4712\n",
      "Epoch 66/1000: Train Loss: 0.6677, Val Loss: 0.6474\n",
      "New best validation loss: 0.6474\n",
      "Baseline Loss: 2.8425 | Actual Loss: 0.5810\n",
      "Baseline Loss: 2.8726 | Actual Loss: 0.7650\n",
      "Baseline Loss: 2.8617 | Actual Loss: 0.9170\n",
      "Baseline Loss: 2.8375 | Actual Loss: 0.5035\n",
      "Baseline Loss: 2.7846 | Actual Loss: 0.5683\n",
      "Baseline Loss: 2.9038 | Actual Loss: 0.3782\n",
      "Baseline Loss: 2.8483 | Actual Loss: 0.7798\n",
      "Baseline Loss: 2.8289 | Actual Loss: 0.5384\n",
      "Baseline Loss: 2.7615 | Actual Loss: 0.4428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 67/1000 [00:22<04:57,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8081 | Actual Loss: 0.9981\n",
      "Baseline Loss: 2.8137 | Actual Loss: 1.4650\n",
      "Baseline Loss: 2.7959 | Actual Loss: 1.7091\n",
      "Baseline Loss: 2.8472 | Actual Loss: 0.5032\n",
      "Baseline Loss: 2.7732 | Actual Loss: 0.5097\n",
      "Baseline Loss: 2.8953 | Actual Loss: 0.8929\n",
      "Baseline Loss: 2.3970 | Actual Loss: 0.3701\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.7954\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.1233\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.6278\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.5395\n",
      "Epoch 67/1000: Train Loss: 0.7451, Val Loss: 0.7715\n",
      "Baseline Loss: 2.8074 | Actual Loss: 0.4397\n",
      "Baseline Loss: 2.8419 | Actual Loss: 0.5819\n",
      "Baseline Loss: 2.8558 | Actual Loss: 0.6641\n",
      "Baseline Loss: 2.8386 | Actual Loss: 0.5612\n",
      "Baseline Loss: 2.8462 | Actual Loss: 0.4807\n",
      "Baseline Loss: 2.7645 | Actual Loss: 0.4517\n",
      "Baseline Loss: 2.8403 | Actual Loss: 0.8488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 68/1000 [00:22<04:45,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8886 | Actual Loss: 0.4245\n",
      "Baseline Loss: 2.7577 | Actual Loss: 2.2699\n",
      "Baseline Loss: 2.7993 | Actual Loss: 0.9564\n",
      "Baseline Loss: 2.8150 | Actual Loss: 0.3977\n",
      "Baseline Loss: 2.8441 | Actual Loss: 0.4466\n",
      "Baseline Loss: 2.8370 | Actual Loss: 0.5442\n",
      "Baseline Loss: 2.8065 | Actual Loss: 0.8270\n",
      "Baseline Loss: 2.7831 | Actual Loss: 0.5365\n",
      "Baseline Loss: 2.5089 | Actual Loss: 1.7408\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.7077\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.0552\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.6202\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.4923\n",
      "Epoch 68/1000: Train Loss: 0.7607, Val Loss: 0.7188\n",
      "Baseline Loss: 2.8485 | Actual Loss: 0.4217\n",
      "Baseline Loss: 2.7996 | Actual Loss: 0.5807\n",
      "Baseline Loss: 2.8125 | Actual Loss: 0.5317\n",
      "Baseline Loss: 2.8504 | Actual Loss: 0.4868\n",
      "Baseline Loss: 2.8819 | Actual Loss: 0.3538\n",
      "Baseline Loss: 2.7900 | Actual Loss: 0.7880\n",
      "Baseline Loss: 2.8818 | Actual Loss: 0.9056\n",
      "Baseline Loss: 2.8651 | Actual Loss: 0.4780\n",
      "Baseline Loss: 2.8210 | Actual Loss: 1.0931\n",
      "Baseline Loss: 2.8525 | Actual Loss: 0.5055\n",
      "Baseline Loss: 2.8570 | Actual Loss: 0.5073\n",
      "Baseline Loss: 2.8089 | Actual Loss: 0.6804\n",
      "Baseline Loss: 2.9022 | Actual Loss: 0.3548\n",
      "Baseline Loss: 2.7697 | Actual Loss: 0.7013\n",
      "Baseline Loss: 2.8081 | Actual Loss: 0.3822\n",
      "Baseline Loss: 2.5571 | Actual Loss: 0.4544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 69/1000 [00:22<04:53,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8199 | Actual Loss: 0.6570\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.0273\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.6888\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3828\n",
      "Epoch 69/1000: Train Loss: 0.5766, Val Loss: 0.6890\n",
      "Baseline Loss: 2.8784 | Actual Loss: 0.9146\n",
      "Baseline Loss: 2.8561 | Actual Loss: 1.5992\n",
      "Baseline Loss: 2.8519 | Actual Loss: 0.3486\n",
      "Baseline Loss: 2.9628 | Actual Loss: 0.5474\n",
      "Baseline Loss: 2.8675 | Actual Loss: 0.7166\n",
      "Baseline Loss: 2.7356 | Actual Loss: 0.2875\n",
      "Baseline Loss: 2.9299 | Actual Loss: 0.7022\n",
      "Baseline Loss: 2.8015 | Actual Loss: 0.4009\n",
      "Baseline Loss: 2.8081 | Actual Loss: 0.2044\n",
      "Baseline Loss: 2.9001 | Actual Loss: 0.2893\n",
      "Baseline Loss: 2.8133 | Actual Loss: 0.5300\n",
      "Baseline Loss: 2.8584 | Actual Loss: 0.4695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 70/1000 [00:23<04:58,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7800 | Actual Loss: 0.9680\n",
      "Baseline Loss: 2.7562 | Actual Loss: 0.6565\n",
      "Baseline Loss: 2.7695 | Actual Loss: 2.0872\n",
      "Baseline Loss: 2.6391 | Actual Loss: 0.5212\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.8191\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.0311\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5730\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2810\n",
      "Epoch 70/1000: Train Loss: 0.7027, Val Loss: 0.6761\n",
      "Baseline Loss: 2.8497 | Actual Loss: 0.6839\n",
      "Baseline Loss: 2.8256 | Actual Loss: 0.7216\n",
      "Baseline Loss: 2.7848 | Actual Loss: 0.5384\n",
      "Baseline Loss: 2.8281 | Actual Loss: 0.4849\n",
      "Baseline Loss: 2.7735 | Actual Loss: 0.3069\n",
      "Baseline Loss: 2.8157 | Actual Loss: 0.9282\n",
      "Baseline Loss: 2.8435 | Actual Loss: 0.4178\n",
      "Baseline Loss: 2.9017 | Actual Loss: 0.7097\n",
      "Baseline Loss: 2.9020 | Actual Loss: 1.7819\n",
      "Baseline Loss: 2.8063 | Actual Loss: 0.6305\n",
      "Baseline Loss: 2.8234 | Actual Loss: 1.2808\n",
      "Baseline Loss: 2.8125 | Actual Loss: 0.6121\n",
      "Baseline Loss: 2.7945 | Actual Loss: 0.6098\n",
      "Baseline Loss: 2.8063 | Actual Loss: 0.2834\n",
      "Baseline Loss: 2.8636 | Actual Loss: 0.3187\n",
      "Baseline Loss: 2.5380 | Actual Loss: 1.9851\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.9086\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.9710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 71/1000 [00:23<04:45,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7998 | Actual Loss: 0.6811\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3729\n",
      "Epoch 71/1000: Train Loss: 0.7684, Val Loss: 0.7334\n",
      "Baseline Loss: 2.8857 | Actual Loss: 0.4292\n",
      "Baseline Loss: 2.7837 | Actual Loss: 0.5218\n",
      "Baseline Loss: 2.8268 | Actual Loss: 0.7406\n",
      "Baseline Loss: 2.8695 | Actual Loss: 0.4882\n",
      "Baseline Loss: 2.8163 | Actual Loss: 0.4567\n",
      "Baseline Loss: 2.8243 | Actual Loss: 0.5474\n",
      "Baseline Loss: 2.8014 | Actual Loss: 0.3783\n",
      "Baseline Loss: 2.8059 | Actual Loss: 0.3992\n",
      "Baseline Loss: 2.8508 | Actual Loss: 1.2358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 72/1000 [00:23<04:52,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8618 | Actual Loss: 0.6846\n",
      "Baseline Loss: 2.8346 | Actual Loss: 0.3037\n",
      "Baseline Loss: 2.8561 | Actual Loss: 2.0777\n",
      "Baseline Loss: 2.7831 | Actual Loss: 0.4188\n",
      "Baseline Loss: 2.8392 | Actual Loss: 0.6509\n",
      "Baseline Loss: 2.7851 | Actual Loss: 0.2581\n",
      "Baseline Loss: 2.6989 | Actual Loss: 1.9487\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4795\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.1391\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5086\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.4579\n",
      "Epoch 72/1000: Train Loss: 0.7212, Val Loss: 0.6463\n",
      "New best validation loss: 0.6463\n",
      "Baseline Loss: 2.8495 | Actual Loss: 1.4517\n",
      "Baseline Loss: 2.8485 | Actual Loss: 2.4764\n",
      "Baseline Loss: 2.8406 | Actual Loss: 0.6146\n",
      "Baseline Loss: 2.8282 | Actual Loss: 0.3614\n",
      "Baseline Loss: 2.8187 | Actual Loss: 0.3080\n",
      "Baseline Loss: 2.8099 | Actual Loss: 0.4553\n",
      "Baseline Loss: 2.8385 | Actual Loss: 2.2824\n",
      "Baseline Loss: 2.7948 | Actual Loss: 0.6889\n",
      "Baseline Loss: 2.8551 | Actual Loss: 2.3718\n",
      "Baseline Loss: 2.8656 | Actual Loss: 0.5805\n",
      "Baseline Loss: 2.8364 | Actual Loss: 0.3006\n",
      "Baseline Loss: 2.8864 | Actual Loss: 0.5272\n",
      "Baseline Loss: 2.7415 | Actual Loss: 0.3537\n",
      "Baseline Loss: 2.7993 | Actual Loss: 0.6259\n",
      "Baseline Loss: 2.8177 | Actual Loss: 0.4737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 73/1000 [00:24<05:01,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5463 | Actual Loss: 0.4443\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.8341\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8981\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.6332\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.5056\n",
      "Epoch 73/1000: Train Loss: 0.8948, Val Loss: 0.7177\n",
      "Baseline Loss: 2.8290 | Actual Loss: 0.4516\n",
      "Baseline Loss: 2.8234 | Actual Loss: 0.7621\n",
      "Baseline Loss: 2.7744 | Actual Loss: 0.6315\n",
      "Baseline Loss: 2.9380 | Actual Loss: 0.3439\n",
      "Baseline Loss: 2.8495 | Actual Loss: 0.1588\n",
      "Baseline Loss: 2.8031 | Actual Loss: 0.4291\n",
      "Baseline Loss: 2.7800 | Actual Loss: 0.5300\n",
      "Baseline Loss: 2.7959 | Actual Loss: 2.2860\n",
      "Baseline Loss: 2.9006 | Actual Loss: 1.1623\n",
      "Baseline Loss: 2.8161 | Actual Loss: 0.5021\n",
      "Baseline Loss: 2.7860 | Actual Loss: 0.3114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 74/1000 [00:24<04:46,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8645 | Actual Loss: 0.2620\n",
      "Baseline Loss: 2.8446 | Actual Loss: 0.4376\n",
      "Baseline Loss: 2.8118 | Actual Loss: 0.1848\n",
      "Baseline Loss: 2.8168 | Actual Loss: 0.5892\n",
      "Baseline Loss: 2.4556 | Actual Loss: 0.3798\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.7074\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7892\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.6256\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3807\n",
      "Epoch 74/1000: Train Loss: 0.5889, Val Loss: 0.6257\n",
      "New best validation loss: 0.6257\n",
      "Baseline Loss: 2.7413 | Actual Loss: 0.5554\n",
      "Baseline Loss: 2.8197 | Actual Loss: 0.8689\n",
      "Baseline Loss: 2.8152 | Actual Loss: 1.0738\n",
      "Baseline Loss: 2.8922 | Actual Loss: 0.3838\n",
      "Baseline Loss: 2.8409 | Actual Loss: 0.3340\n",
      "Baseline Loss: 2.7993 | Actual Loss: 0.3336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 75/1000 [00:24<04:51,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8981 | Actual Loss: 0.6586\n",
      "Baseline Loss: 2.8255 | Actual Loss: 2.2430\n",
      "Baseline Loss: 2.8223 | Actual Loss: 0.5548\n",
      "Baseline Loss: 2.8314 | Actual Loss: 0.3061\n",
      "Baseline Loss: 2.8523 | Actual Loss: 0.6438\n",
      "Baseline Loss: 2.8457 | Actual Loss: 0.1553\n",
      "Baseline Loss: 2.8378 | Actual Loss: 0.5068\n",
      "Baseline Loss: 2.8489 | Actual Loss: 0.4110\n",
      "Baseline Loss: 2.8150 | Actual Loss: 0.6051\n",
      "Baseline Loss: 2.4261 | Actual Loss: 0.3339\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.7810\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.9470\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5693\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.5278\n",
      "Epoch 75/1000: Train Loss: 0.6230, Val Loss: 0.7063\n",
      "Baseline Loss: 2.8222 | Actual Loss: 0.3315\n",
      "Baseline Loss: 2.8434 | Actual Loss: 0.4951\n",
      "Baseline Loss: 2.8228 | Actual Loss: 0.5443\n",
      "Baseline Loss: 2.8867 | Actual Loss: 0.3048\n",
      "Baseline Loss: 2.7720 | Actual Loss: 0.2417\n",
      "Baseline Loss: 2.7949 | Actual Loss: 1.3755\n",
      "Baseline Loss: 2.8077 | Actual Loss: 0.5868\n",
      "Baseline Loss: 2.8326 | Actual Loss: 0.6775\n",
      "Baseline Loss: 2.8123 | Actual Loss: 2.3620\n",
      "Baseline Loss: 2.7933 | Actual Loss: 0.5435\n",
      "Baseline Loss: 2.7898 | Actual Loss: 0.3840\n",
      "Baseline Loss: 2.7822 | Actual Loss: 0.2431\n",
      "Baseline Loss: 2.9075 | Actual Loss: 0.3995\n",
      "Baseline Loss: 2.8498 | Actual Loss: 0.2947\n",
      "Baseline Loss: 2.7638 | Actual Loss: 0.6737\n",
      "Baseline Loss: 2.5619 | Actual Loss: 0.6200\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.7387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 76/1000 [00:24<04:40,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8180 | Actual Loss: 0.7726\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5493\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.5490\n",
      "Epoch 76/1000: Train Loss: 0.6299, Val Loss: 0.6524\n",
      "Baseline Loss: 2.7832 | Actual Loss: 0.7033\n",
      "Baseline Loss: 2.7880 | Actual Loss: 0.4368\n",
      "Baseline Loss: 2.8223 | Actual Loss: 0.3799\n",
      "Baseline Loss: 2.7761 | Actual Loss: 0.3407\n",
      "Baseline Loss: 2.7936 | Actual Loss: 0.3650\n",
      "Baseline Loss: 2.8247 | Actual Loss: 0.2705\n",
      "Baseline Loss: 2.9265 | Actual Loss: 1.4400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 77/1000 [00:25<04:54,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7875 | Actual Loss: 0.3381\n",
      "Baseline Loss: 2.8197 | Actual Loss: 0.3132\n",
      "Baseline Loss: 2.8698 | Actual Loss: 1.0032\n",
      "Baseline Loss: 2.7812 | Actual Loss: 0.2805\n",
      "Baseline Loss: 2.8215 | Actual Loss: 0.4635\n",
      "Baseline Loss: 2.8638 | Actual Loss: 0.2113\n",
      "Baseline Loss: 2.8565 | Actual Loss: 0.6022\n",
      "Baseline Loss: 2.8171 | Actual Loss: 1.0036\n",
      "Baseline Loss: 2.5766 | Actual Loss: 0.3239\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.9904\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.9372\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.6864\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.5629\n",
      "Epoch 77/1000: Train Loss: 0.5297, Val Loss: 0.7942\n",
      "Baseline Loss: 2.8177 | Actual Loss: 1.7921\n",
      "Baseline Loss: 2.8531 | Actual Loss: 1.5072\n",
      "Baseline Loss: 2.8137 | Actual Loss: 0.4523\n",
      "Baseline Loss: 2.7907 | Actual Loss: 0.4320\n",
      "Baseline Loss: 2.8897 | Actual Loss: 0.6993\n",
      "Baseline Loss: 2.7978 | Actual Loss: 0.5824\n",
      "Baseline Loss: 2.7984 | Actual Loss: 2.0492\n",
      "Baseline Loss: 2.8646 | Actual Loss: 0.3717\n",
      "Baseline Loss: 2.8935 | Actual Loss: 0.3036\n",
      "Baseline Loss: 2.8032 | Actual Loss: 0.4416\n",
      "Baseline Loss: 2.8320 | Actual Loss: 0.3079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 78/1000 [00:25<04:57,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8454 | Actual Loss: 0.1068\n",
      "Baseline Loss: 2.7913 | Actual Loss: 0.4014\n",
      "Baseline Loss: 2.7629 | Actual Loss: 0.8132\n",
      "Baseline Loss: 2.8558 | Actual Loss: 0.3904\n",
      "Baseline Loss: 2.5135 | Actual Loss: 1.0613\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.6847\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.1174\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4372\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.4213\n",
      "Epoch 78/1000: Train Loss: 0.7320, Val Loss: 0.6652\n",
      "Baseline Loss: 2.7647 | Actual Loss: 1.7387\n",
      "Baseline Loss: 2.7933 | Actual Loss: 0.2436\n",
      "Baseline Loss: 2.8192 | Actual Loss: 0.9583\n",
      "Baseline Loss: 2.7661 | Actual Loss: 0.3748\n",
      "Baseline Loss: 2.8575 | Actual Loss: 0.2417\n",
      "Baseline Loss: 2.8013 | Actual Loss: 0.5011\n",
      "Baseline Loss: 2.8268 | Actual Loss: 0.3988\n",
      "Baseline Loss: 2.8666 | Actual Loss: 0.3051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 79/1000 [00:25<04:44,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8617 | Actual Loss: 0.4294\n",
      "Baseline Loss: 2.7793 | Actual Loss: 0.6898\n",
      "Baseline Loss: 2.8247 | Actual Loss: 0.5449\n",
      "Baseline Loss: 2.7744 | Actual Loss: 0.2537\n",
      "Baseline Loss: 2.8154 | Actual Loss: 0.6141\n",
      "Baseline Loss: 2.7972 | Actual Loss: 0.4243\n",
      "Baseline Loss: 2.8047 | Actual Loss: 0.2742\n",
      "Baseline Loss: 2.7204 | Actual Loss: 0.3106\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.6381\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7601\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4445\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.4871\n",
      "Epoch 79/1000: Train Loss: 0.5189, Val Loss: 0.5825\n",
      "New best validation loss: 0.5825\n",
      "Baseline Loss: 2.8116 | Actual Loss: 0.5262\n",
      "Baseline Loss: 2.8387 | Actual Loss: 0.8851\n",
      "Baseline Loss: 2.7960 | Actual Loss: 0.5990\n",
      "Baseline Loss: 2.8165 | Actual Loss: 0.3763\n",
      "Baseline Loss: 2.8510 | Actual Loss: 0.5358\n",
      "Baseline Loss: 2.7853 | Actual Loss: 0.3863\n",
      "Baseline Loss: 2.8044 | Actual Loss: 0.2855\n",
      "Baseline Loss: 2.8741 | Actual Loss: 0.3517\n",
      "Baseline Loss: 2.8486 | Actual Loss: 0.9478\n",
      "Baseline Loss: 2.8337 | Actual Loss: 0.6711\n",
      "Baseline Loss: 2.9119 | Actual Loss: 1.3661\n",
      "Baseline Loss: 2.8772 | Actual Loss: 0.7770\n",
      "Baseline Loss: 2.8237 | Actual Loss: 0.1402\n",
      "Baseline Loss: 2.7560 | Actual Loss: 0.3480\n",
      "Baseline Loss: 2.7762 | Actual Loss: 0.4432\n",
      "Baseline Loss: 2.5880 | Actual Loss: 1.3789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 80/1000 [00:26<04:49,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8199 | Actual Loss: 0.9801\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8082\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5346\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.5303\n",
      "Epoch 80/1000: Train Loss: 0.6261, Val Loss: 0.7133\n",
      "Baseline Loss: 2.8434 | Actual Loss: 0.5775\n",
      "Baseline Loss: 2.7982 | Actual Loss: 0.5450\n",
      "Baseline Loss: 2.8218 | Actual Loss: 1.1285\n",
      "Baseline Loss: 2.7744 | Actual Loss: 0.2437\n",
      "Baseline Loss: 2.8252 | Actual Loss: 0.6237\n",
      "Baseline Loss: 2.8326 | Actual Loss: 0.4548\n",
      "Baseline Loss: 2.8823 | Actual Loss: 0.4697\n",
      "Baseline Loss: 2.8628 | Actual Loss: 0.5860\n",
      "Baseline Loss: 2.8020 | Actual Loss: 1.0436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 81/1000 [00:26<04:55,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8731 | Actual Loss: 1.2559\n",
      "Baseline Loss: 2.8016 | Actual Loss: 0.1982\n",
      "Baseline Loss: 2.7550 | Actual Loss: 0.4041\n",
      "Baseline Loss: 2.7817 | Actual Loss: 2.1183\n",
      "Baseline Loss: 2.8931 | Actual Loss: 0.3576\n",
      "Baseline Loss: 2.8568 | Actual Loss: 0.3108\n",
      "Baseline Loss: 2.6604 | Actual Loss: 2.7823\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.8188\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.0624\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.6734\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2655\n",
      "Epoch 81/1000: Train Loss: 0.8187, Val Loss: 0.7050\n",
      "Baseline Loss: 2.7744 | Actual Loss: 0.2191\n",
      "Baseline Loss: 2.7803 | Actual Loss: 0.2876\n",
      "Baseline Loss: 2.7801 | Actual Loss: 0.5110\n",
      "Baseline Loss: 2.8455 | Actual Loss: 0.3018\n",
      "Baseline Loss: 2.8435 | Actual Loss: 0.2720\n",
      "Baseline Loss: 2.8487 | Actual Loss: 2.5290\n",
      "Baseline Loss: 2.7800 | Actual Loss: 0.3365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 82/1000 [00:26<04:39,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8409 | Actual Loss: 1.7567\n",
      "Baseline Loss: 2.7364 | Actual Loss: 0.3441\n",
      "Baseline Loss: 2.8496 | Actual Loss: 0.3881\n",
      "Baseline Loss: 2.8140 | Actual Loss: 2.1110\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.5921\n",
      "Baseline Loss: 2.8396 | Actual Loss: 0.5177\n",
      "Baseline Loss: 2.8265 | Actual Loss: 0.6447\n",
      "Baseline Loss: 2.8003 | Actual Loss: 0.3449\n",
      "Baseline Loss: 2.7338 | Actual Loss: 0.2798\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.6567\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7981\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5687\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.5172\n",
      "Epoch 82/1000: Train Loss: 0.7148, Val Loss: 0.6352\n",
      "Baseline Loss: 2.8548 | Actual Loss: 0.6047\n",
      "Baseline Loss: 2.8348 | Actual Loss: 0.4293\n",
      "Baseline Loss: 2.8659 | Actual Loss: 0.7992\n",
      "Baseline Loss: 2.7869 | Actual Loss: 0.4950\n",
      "Baseline Loss: 2.7830 | Actual Loss: 0.3506\n",
      "Baseline Loss: 2.8414 | Actual Loss: 2.3442\n",
      "Baseline Loss: 2.8427 | Actual Loss: 0.2319\n",
      "Baseline Loss: 2.7590 | Actual Loss: 2.3154\n",
      "Baseline Loss: 2.8508 | Actual Loss: 0.6946\n",
      "Baseline Loss: 2.8533 | Actual Loss: 0.3246\n",
      "Baseline Loss: 2.8092 | Actual Loss: 0.2088\n",
      "Baseline Loss: 2.8038 | Actual Loss: 0.7182\n",
      "Baseline Loss: 2.8784 | Actual Loss: 0.5983\n",
      "Baseline Loss: 2.8009 | Actual Loss: 0.6785\n",
      "Baseline Loss: 2.8439 | Actual Loss: 0.7175\n",
      "Baseline Loss: 2.5457 | Actual Loss: 1.6928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 83/1000 [00:27<04:45,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8199 | Actual Loss: 0.6387\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.9975\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5876\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.5848\n",
      "Epoch 83/1000: Train Loss: 0.8252, Val Loss: 0.7022\n",
      "Baseline Loss: 2.8580 | Actual Loss: 0.4061\n",
      "Baseline Loss: 2.8135 | Actual Loss: 0.4112\n",
      "Baseline Loss: 2.8722 | Actual Loss: 0.8336\n",
      "Baseline Loss: 2.7980 | Actual Loss: 0.5453\n",
      "Baseline Loss: 2.8326 | Actual Loss: 0.4784\n",
      "Baseline Loss: 2.8600 | Actual Loss: 0.3110\n",
      "Baseline Loss: 2.8831 | Actual Loss: 0.7167\n",
      "Baseline Loss: 2.8043 | Actual Loss: 0.9684\n",
      "Baseline Loss: 2.8349 | Actual Loss: 0.1912\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.2103\n",
      "Baseline Loss: 2.8548 | Actual Loss: 2.4597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 84/1000 [00:27<04:53,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8080 | Actual Loss: 0.4859\n",
      "Baseline Loss: 2.8780 | Actual Loss: 2.2255\n",
      "Baseline Loss: 2.7050 | Actual Loss: 1.5684\n",
      "Baseline Loss: 2.7724 | Actual Loss: 0.8470\n",
      "Baseline Loss: 2.5189 | Actual Loss: 0.4986\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.6789\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8128\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.6175\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.5347\n",
      "Epoch 84/1000: Train Loss: 0.8223, Val Loss: 0.6610\n",
      "Baseline Loss: 2.8188 | Actual Loss: 0.2732\n",
      "Baseline Loss: 2.7446 | Actual Loss: 0.8962\n",
      "Baseline Loss: 2.8704 | Actual Loss: 0.3271\n",
      "Baseline Loss: 2.7591 | Actual Loss: 0.4207\n",
      "Baseline Loss: 2.8003 | Actual Loss: 0.4795\n",
      "Baseline Loss: 2.8664 | Actual Loss: 0.6429\n",
      "Baseline Loss: 2.7989 | Actual Loss: 0.6583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 85/1000 [00:27<04:35,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8155 | Actual Loss: 0.4893\n",
      "Baseline Loss: 2.7544 | Actual Loss: 0.2032\n",
      "Baseline Loss: 2.8387 | Actual Loss: 0.2113\n",
      "Baseline Loss: 2.8784 | Actual Loss: 0.4431\n",
      "Baseline Loss: 2.8123 | Actual Loss: 0.3971\n",
      "Baseline Loss: 2.9194 | Actual Loss: 0.3195\n",
      "Baseline Loss: 2.8088 | Actual Loss: 1.8754\n",
      "Baseline Loss: 2.8536 | Actual Loss: 1.3172\n",
      "Baseline Loss: 2.6517 | Actual Loss: 0.3376\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.3991\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6815\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.6485\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.4487\n",
      "Epoch 85/1000: Train Loss: 0.5807, Val Loss: 0.5445\n",
      "New best validation loss: 0.5445\n",
      "Baseline Loss: 2.8306 | Actual Loss: 0.5016\n",
      "Baseline Loss: 2.8551 | Actual Loss: 0.5497\n",
      "Baseline Loss: 2.8483 | Actual Loss: 0.5884\n",
      "Baseline Loss: 2.7830 | Actual Loss: 0.3613\n",
      "Baseline Loss: 2.8497 | Actual Loss: 0.3765\n",
      "Baseline Loss: 2.8455 | Actual Loss: 0.2964\n",
      "Baseline Loss: 2.8230 | Actual Loss: 0.4016\n",
      "Baseline Loss: 2.7808 | Actual Loss: 0.5011\n",
      "Baseline Loss: 2.8366 | Actual Loss: 0.3347\n",
      "Baseline Loss: 2.7670 | Actual Loss: 0.1442\n",
      "Baseline Loss: 2.8658 | Actual Loss: 0.4787\n",
      "Baseline Loss: 2.7979 | Actual Loss: 0.6397\n",
      "Baseline Loss: 2.8472 | Actual Loss: 0.6919\n",
      "Baseline Loss: 2.8523 | Actual Loss: 1.1236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▊         | 86/1000 [00:28<04:45,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8160 | Actual Loss: 0.3134\n",
      "Baseline Loss: 2.5646 | Actual Loss: 0.2894\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.6252\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8006\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5404\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.5010\n",
      "Epoch 86/1000: Train Loss: 0.4745, Val Loss: 0.6168\n",
      "Baseline Loss: 2.8301 | Actual Loss: 0.7263\n",
      "Baseline Loss: 2.8524 | Actual Loss: 0.4796\n",
      "Baseline Loss: 2.8271 | Actual Loss: 0.3370\n",
      "Baseline Loss: 2.8513 | Actual Loss: 0.4423\n",
      "Baseline Loss: 2.7831 | Actual Loss: 0.6256\n",
      "Baseline Loss: 2.7829 | Actual Loss: 0.5041\n",
      "Baseline Loss: 2.8001 | Actual Loss: 0.8458\n",
      "Baseline Loss: 2.8601 | Actual Loss: 0.3802\n",
      "Baseline Loss: 2.8659 | Actual Loss: 0.9499\n",
      "Baseline Loss: 2.8706 | Actual Loss: 0.4009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▊         | 87/1000 [00:28<04:50,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7854 | Actual Loss: 0.3558\n",
      "Baseline Loss: 2.7506 | Actual Loss: 1.4313\n",
      "Baseline Loss: 2.7825 | Actual Loss: 1.4107\n",
      "Baseline Loss: 2.9012 | Actual Loss: 0.3238\n",
      "Baseline Loss: 2.8314 | Actual Loss: 0.3090\n",
      "Baseline Loss: 2.5978 | Actual Loss: 0.1019\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5000\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8424\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.6270\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.4738\n",
      "Epoch 87/1000: Train Loss: 0.6015, Val Loss: 0.6108\n",
      "Baseline Loss: 2.8354 | Actual Loss: 0.5909\n",
      "Baseline Loss: 2.7783 | Actual Loss: 0.6489\n",
      "Baseline Loss: 2.7974 | Actual Loss: 0.9853\n",
      "Baseline Loss: 2.7749 | Actual Loss: 1.2504\n",
      "Baseline Loss: 2.8633 | Actual Loss: 1.0759\n",
      "Baseline Loss: 2.8167 | Actual Loss: 1.2294\n",
      "Baseline Loss: 2.8807 | Actual Loss: 0.2868\n",
      "Baseline Loss: 2.8346 | Actual Loss: 0.2316\n",
      "Baseline Loss: 2.8842 | Actual Loss: 0.4430\n",
      "Baseline Loss: 2.8543 | Actual Loss: 0.3877\n",
      "Baseline Loss: 2.8628 | Actual Loss: 0.3881\n",
      "Baseline Loss: 2.8332 | Actual Loss: 0.5690\n",
      "Baseline Loss: 2.8277 | Actual Loss: 0.8175\n",
      "Baseline Loss: 2.8475 | Actual Loss: 0.7128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 88/1000 [00:28<04:40,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8045 | Actual Loss: 0.2933\n",
      "Baseline Loss: 2.4705 | Actual Loss: 1.1499\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.7188\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.9741\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.6657\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.4935\n",
      "Epoch 88/1000: Train Loss: 0.6913, Val Loss: 0.7130\n",
      "Baseline Loss: 2.7690 | Actual Loss: 0.5064\n",
      "Baseline Loss: 2.7835 | Actual Loss: 0.4742\n",
      "Baseline Loss: 2.7852 | Actual Loss: 0.4987\n",
      "Baseline Loss: 2.7528 | Actual Loss: 0.7262\n",
      "Baseline Loss: 2.8304 | Actual Loss: 0.3399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 89/1000 [00:29<04:50,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8242 | Actual Loss: 0.4591\n",
      "Baseline Loss: 2.8568 | Actual Loss: 0.4973\n",
      "Baseline Loss: 2.8485 | Actual Loss: 0.4806\n",
      "Baseline Loss: 2.7959 | Actual Loss: 0.4608\n",
      "Baseline Loss: 2.8294 | Actual Loss: 0.2350\n",
      "Baseline Loss: 2.7875 | Actual Loss: 0.1430\n",
      "Baseline Loss: 2.8707 | Actual Loss: 0.4859\n",
      "Baseline Loss: 2.9103 | Actual Loss: 0.6442\n",
      "Baseline Loss: 2.8514 | Actual Loss: 1.8837\n",
      "Baseline Loss: 2.8587 | Actual Loss: 0.5426\n",
      "Baseline Loss: 2.4536 | Actual Loss: 2.1285\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.8349\n",
      "Baseline Loss: 2.8180 | Actual Loss: 2.5834\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.7742\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2968\n",
      "Epoch 89/1000: Train Loss: 0.6566, Val Loss: 1.1223\n",
      "Baseline Loss: 2.8286 | Actual Loss: 0.1949\n",
      "Baseline Loss: 2.8431 | Actual Loss: 0.3550\n",
      "Baseline Loss: 2.8618 | Actual Loss: 0.8589\n",
      "Baseline Loss: 2.7545 | Actual Loss: 1.6001\n",
      "Baseline Loss: 2.7890 | Actual Loss: 0.6148\n",
      "Baseline Loss: 2.8108 | Actual Loss: 0.2077\n",
      "Baseline Loss: 2.7970 | Actual Loss: 1.8476\n",
      "Baseline Loss: 2.7651 | Actual Loss: 0.8815\n",
      "Baseline Loss: 2.9014 | Actual Loss: 0.1798\n",
      "Baseline Loss: 2.8415 | Actual Loss: 0.4047\n",
      "Baseline Loss: 2.9082 | Actual Loss: 0.4191\n",
      "Baseline Loss: 2.7591 | Actual Loss: 0.3651\n",
      "Baseline Loss: 2.8565 | Actual Loss: 0.4275\n",
      "Baseline Loss: 2.7451 | Actual Loss: 0.3146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 90/1000 [00:29<05:02,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8335 | Actual Loss: 2.0745\n",
      "Baseline Loss: 2.6230 | Actual Loss: 0.2812\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5386\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8932\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5743\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.4518\n",
      "Epoch 90/1000: Train Loss: 0.6892, Val Loss: 0.6145\n",
      "Baseline Loss: 2.8130 | Actual Loss: 0.8314\n",
      "Baseline Loss: 2.7558 | Actual Loss: 0.4624\n",
      "Baseline Loss: 2.8339 | Actual Loss: 0.6557\n",
      "Baseline Loss: 2.8364 | Actual Loss: 0.5906\n",
      "Baseline Loss: 2.8350 | Actual Loss: 0.2938\n",
      "Baseline Loss: 2.8913 | Actual Loss: 0.3437\n",
      "Baseline Loss: 2.8557 | Actual Loss: 0.3331\n",
      "Baseline Loss: 2.8492 | Actual Loss: 0.2988\n",
      "Baseline Loss: 2.8091 | Actual Loss: 0.6257\n",
      "Baseline Loss: 2.9169 | Actual Loss: 0.4533\n",
      "Baseline Loss: 2.8095 | Actual Loss: 0.5173\n",
      "Baseline Loss: 2.7743 | Actual Loss: 0.3049\n",
      "Baseline Loss: 2.7613 | Actual Loss: 0.2501\n",
      "Baseline Loss: 2.8552 | Actual Loss: 0.4266\n",
      "Baseline Loss: 2.8831 | Actual Loss: 0.2370\n",
      "Baseline Loss: 2.6290 | Actual Loss: 0.3195\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.6089\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 91/1000 [00:29<04:45,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7998 | Actual Loss: 0.4927\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.4136\n",
      "Epoch 91/1000: Train Loss: 0.4340, Val Loss: 0.5911\n",
      "Baseline Loss: 2.7905 | Actual Loss: 2.6709\n",
      "Baseline Loss: 2.7792 | Actual Loss: 0.4074\n",
      "Baseline Loss: 2.7798 | Actual Loss: 0.1449\n",
      "Baseline Loss: 2.8188 | Actual Loss: 0.5568\n",
      "Baseline Loss: 2.8568 | Actual Loss: 0.3097\n",
      "Baseline Loss: 2.8659 | Actual Loss: 0.4233\n",
      "Baseline Loss: 2.7960 | Actual Loss: 0.2301\n",
      "Baseline Loss: 2.8524 | Actual Loss: 0.1923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 92/1000 [00:30<04:51,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7611 | Actual Loss: 0.4880\n",
      "Baseline Loss: 2.8997 | Actual Loss: 0.2182\n",
      "Baseline Loss: 2.8185 | Actual Loss: 0.2733\n",
      "Baseline Loss: 2.8553 | Actual Loss: 2.0357\n",
      "Baseline Loss: 2.8620 | Actual Loss: 0.1899\n",
      "Baseline Loss: 2.7999 | Actual Loss: 2.2581\n",
      "Baseline Loss: 2.7691 | Actual Loss: 0.4774\n",
      "Baseline Loss: 2.7433 | Actual Loss: 0.4373\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.7102\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8234\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5458\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3340\n",
      "Epoch 92/1000: Train Loss: 0.7071, Val Loss: 0.6034\n",
      "Baseline Loss: 2.8477 | Actual Loss: 0.4324\n",
      "Baseline Loss: 2.8880 | Actual Loss: 1.1860\n",
      "Baseline Loss: 2.8010 | Actual Loss: 0.2938\n",
      "Baseline Loss: 2.8296 | Actual Loss: 0.2799\n",
      "Baseline Loss: 2.8354 | Actual Loss: 0.1817\n",
      "Baseline Loss: 2.8386 | Actual Loss: 1.3209\n",
      "Baseline Loss: 2.8805 | Actual Loss: 0.5515\n",
      "Baseline Loss: 2.8640 | Actual Loss: 0.5551\n",
      "Baseline Loss: 2.7908 | Actual Loss: 0.7753\n",
      "Baseline Loss: 2.8096 | Actual Loss: 0.6477\n",
      "Baseline Loss: 2.8699 | Actual Loss: 0.4307\n",
      "Baseline Loss: 2.8105 | Actual Loss: 0.3165\n",
      "Baseline Loss: 2.7819 | Actual Loss: 0.2218\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3548\n",
      "Baseline Loss: 2.7988 | Actual Loss: 0.2742\n",
      "Baseline Loss: 2.5092 | Actual Loss: 2.2036\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.6137\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 93/1000 [00:30<04:56,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7998 | Actual Loss: 0.5711\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3489\n",
      "Epoch 93/1000: Train Loss: 0.6266, Val Loss: 0.5551\n",
      "Baseline Loss: 2.9084 | Actual Loss: 0.2056\n",
      "Baseline Loss: 2.8440 | Actual Loss: 0.3196\n",
      "Baseline Loss: 2.8189 | Actual Loss: 0.3868\n",
      "Baseline Loss: 2.8168 | Actual Loss: 1.1378\n",
      "Baseline Loss: 2.8468 | Actual Loss: 0.7490\n",
      "Baseline Loss: 2.9003 | Actual Loss: 0.4931\n",
      "Baseline Loss: 2.8223 | Actual Loss: 0.2172\n",
      "Baseline Loss: 2.7722 | Actual Loss: 0.2725\n",
      "Baseline Loss: 2.7780 | Actual Loss: 0.1673\n",
      "Baseline Loss: 2.8690 | Actual Loss: 0.5917\n",
      "Baseline Loss: 2.7477 | Actual Loss: 0.6858\n",
      "Baseline Loss: 2.8339 | Actual Loss: 0.4129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 94/1000 [00:30<04:41,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8038 | Actual Loss: 0.2229\n",
      "Baseline Loss: 2.8053 | Actual Loss: 0.3142\n",
      "Baseline Loss: 2.8116 | Actual Loss: 0.3294\n",
      "Baseline Loss: 2.4487 | Actual Loss: 0.7748\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.9624\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.9659\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5217\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.5356\n",
      "Epoch 94/1000: Train Loss: 0.4550, Val Loss: 0.7464\n",
      "Baseline Loss: 2.8622 | Actual Loss: 0.4328\n",
      "Baseline Loss: 2.8973 | Actual Loss: 0.5567\n",
      "Baseline Loss: 2.8693 | Actual Loss: 0.4773\n",
      "Baseline Loss: 2.8895 | Actual Loss: 0.2929\n",
      "Baseline Loss: 2.8253 | Actual Loss: 0.3980\n",
      "Baseline Loss: 2.8216 | Actual Loss: 0.7054\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.6172\n",
      "Baseline Loss: 2.8217 | Actual Loss: 0.1639\n",
      "Baseline Loss: 2.8731 | Actual Loss: 0.5301\n",
      "Baseline Loss: 2.7701 | Actual Loss: 2.1669\n",
      "Baseline Loss: 2.7939 | Actual Loss: 1.4972\n",
      "Baseline Loss: 2.8557 | Actual Loss: 1.9075\n",
      "Baseline Loss: 2.8547 | Actual Loss: 0.4046\n",
      "Baseline Loss: 2.7813 | Actual Loss: 2.3641\n",
      "Baseline Loss: 2.8551 | Actual Loss: 0.3055\n",
      "Baseline Loss: 2.4519 | Actual Loss: 0.2449\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.7777\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.9010\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 95/1000 [00:30<04:45,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7254 | Actual Loss: 0.3459\n",
      "Epoch 95/1000: Train Loss: 0.8166, Val Loss: 0.6533\n",
      "Baseline Loss: 2.7881 | Actual Loss: 0.4545\n",
      "Baseline Loss: 2.8218 | Actual Loss: 1.0695\n",
      "Baseline Loss: 2.8644 | Actual Loss: 0.2168\n",
      "Baseline Loss: 2.9033 | Actual Loss: 0.2940\n",
      "Baseline Loss: 2.8346 | Actual Loss: 0.3107\n",
      "Baseline Loss: 2.8319 | Actual Loss: 0.4408\n",
      "Baseline Loss: 2.9064 | Actual Loss: 0.1926\n",
      "Baseline Loss: 2.8665 | Actual Loss: 0.5340\n",
      "Baseline Loss: 2.7888 | Actual Loss: 0.2187\n",
      "Baseline Loss: 2.8009 | Actual Loss: 0.4221\n",
      "Baseline Loss: 2.7593 | Actual Loss: 0.2755\n",
      "Baseline Loss: 2.8190 | Actual Loss: 0.5552\n",
      "Baseline Loss: 2.8079 | Actual Loss: 0.8513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 96/1000 [00:31<04:31,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8068 | Actual Loss: 0.1744\n",
      "Baseline Loss: 2.8362 | Actual Loss: 0.2993\n",
      "Baseline Loss: 2.5894 | Actual Loss: 0.8914\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.6054\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8059\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.6097\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.4130\n",
      "Epoch 96/1000: Train Loss: 0.4500, Val Loss: 0.6085\n",
      "Baseline Loss: 2.7932 | Actual Loss: 2.2925\n",
      "Baseline Loss: 2.7942 | Actual Loss: 0.3166\n",
      "Baseline Loss: 2.8616 | Actual Loss: 0.2290\n",
      "Baseline Loss: 2.9022 | Actual Loss: 0.2286\n",
      "Baseline Loss: 2.8457 | Actual Loss: 0.3339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 97/1000 [00:31<04:43,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8345 | Actual Loss: 0.4948\n",
      "Baseline Loss: 2.8409 | Actual Loss: 0.4288\n",
      "Baseline Loss: 2.8593 | Actual Loss: 0.2849\n",
      "Baseline Loss: 2.9069 | Actual Loss: 0.2992\n",
      "Baseline Loss: 2.7948 | Actual Loss: 1.3607\n",
      "Baseline Loss: 2.8098 | Actual Loss: 0.8033\n",
      "Baseline Loss: 2.7721 | Actual Loss: 0.2486\n",
      "Baseline Loss: 2.8056 | Actual Loss: 0.3609\n",
      "Baseline Loss: 2.8087 | Actual Loss: 0.5615\n",
      "Baseline Loss: 2.8233 | Actual Loss: 0.4857\n",
      "Baseline Loss: 2.5852 | Actual Loss: 2.8857\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4894\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8198\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5866\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3890\n",
      "Epoch 97/1000: Train Loss: 0.7259, Val Loss: 0.5712\n",
      "Baseline Loss: 2.7828 | Actual Loss: 0.2663\n",
      "Baseline Loss: 2.8428 | Actual Loss: 0.6955\n",
      "Baseline Loss: 2.8790 | Actual Loss: 0.2629\n",
      "Baseline Loss: 2.8624 | Actual Loss: 0.7623\n",
      "Baseline Loss: 2.7411 | Actual Loss: 0.7395\n",
      "Baseline Loss: 2.7702 | Actual Loss: 0.3261\n",
      "Baseline Loss: 2.7854 | Actual Loss: 0.3370\n",
      "Baseline Loss: 2.9125 | Actual Loss: 0.7827\n",
      "Baseline Loss: 2.7830 | Actual Loss: 0.2533\n",
      "Baseline Loss: 2.8029 | Actual Loss: 0.2752\n",
      "Baseline Loss: 2.8498 | Actual Loss: 0.3747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 98/1000 [00:31<04:53,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8443 | Actual Loss: 0.8109\n",
      "Baseline Loss: 2.7945 | Actual Loss: 2.4394\n",
      "Baseline Loss: 2.9101 | Actual Loss: 0.3776\n",
      "Baseline Loss: 2.8627 | Actual Loss: 0.2355\n",
      "Baseline Loss: 2.4822 | Actual Loss: 0.3609\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.6197\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.9702\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5261\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.4507\n",
      "Epoch 98/1000: Train Loss: 0.5812, Val Loss: 0.6417\n",
      "Baseline Loss: 2.7529 | Actual Loss: 0.6016\n",
      "Baseline Loss: 2.8747 | Actual Loss: 0.4729\n",
      "Baseline Loss: 2.8358 | Actual Loss: 0.3855\n",
      "Baseline Loss: 2.8059 | Actual Loss: 0.3583\n",
      "Baseline Loss: 2.8761 | Actual Loss: 0.2430\n",
      "Baseline Loss: 2.9030 | Actual Loss: 0.3780\n",
      "Baseline Loss: 2.8244 | Actual Loss: 0.6232\n",
      "Baseline Loss: 2.8234 | Actual Loss: 0.2879\n",
      "Baseline Loss: 2.8922 | Actual Loss: 0.6226\n",
      "Baseline Loss: 2.8055 | Actual Loss: 0.4613\n",
      "Baseline Loss: 2.8403 | Actual Loss: 0.4358\n",
      "Baseline Loss: 2.8804 | Actual Loss: 0.5090\n",
      "Baseline Loss: 2.7945 | Actual Loss: 0.3111\n",
      "Baseline Loss: 2.7990 | Actual Loss: 0.7654\n",
      "Baseline Loss: 2.8506 | Actual Loss: 0.3562\n",
      "Baseline Loss: 2.3797 | Actual Loss: 1.8486\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5596\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8509\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 99/1000 [00:32<05:04,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7254 | Actual Loss: 0.4594\n",
      "Epoch 99/1000: Train Loss: 0.5413, Val Loss: 0.5766\n",
      "Baseline Loss: 2.7645 | Actual Loss: 0.5869\n",
      "Baseline Loss: 2.8894 | Actual Loss: 0.3197\n",
      "Baseline Loss: 2.7618 | Actual Loss: 0.2509\n",
      "Baseline Loss: 2.8679 | Actual Loss: 0.6381\n",
      "Baseline Loss: 2.8439 | Actual Loss: 0.1305\n",
      "Baseline Loss: 2.8535 | Actual Loss: 0.1548\n",
      "Baseline Loss: 2.8398 | Actual Loss: 0.2672\n",
      "Baseline Loss: 2.8134 | Actual Loss: 0.8433\n",
      "Baseline Loss: 2.8766 | Actual Loss: 0.4646\n",
      "Baseline Loss: 2.7662 | Actual Loss: 0.3320\n",
      "Baseline Loss: 2.7059 | Actual Loss: 0.6382\n",
      "Baseline Loss: 2.8451 | Actual Loss: 0.2813\n",
      "Baseline Loss: 2.8917 | Actual Loss: 0.3927\n",
      "Baseline Loss: 2.8439 | Actual Loss: 0.4851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 100/1000 [00:32<04:44,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7691 | Actual Loss: 0.7599\n",
      "Baseline Loss: 2.6563 | Actual Loss: 0.3332\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5181\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7167\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5520\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3809\n",
      "Epoch 100/1000: Train Loss: 0.4299, Val Loss: 0.5419\n",
      "New best validation loss: 0.5419\n",
      "Baseline Loss: 2.8286 | Actual Loss: 0.4048\n",
      "Baseline Loss: 2.8656 | Actual Loss: 0.2804\n",
      "Baseline Loss: 2.8434 | Actual Loss: 0.4739\n",
      "Baseline Loss: 2.8028 | Actual Loss: 0.6975\n",
      "Baseline Loss: 2.9488 | Actual Loss: 0.3194\n",
      "Baseline Loss: 2.8075 | Actual Loss: 1.8500\n",
      "Baseline Loss: 2.8366 | Actual Loss: 0.4434\n",
      "Baseline Loss: 2.7180 | Actual Loss: 2.0457\n",
      "Baseline Loss: 2.8419 | Actual Loss: 0.4852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 101/1000 [00:32<04:48,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7998 | Actual Loss: 0.2391\n",
      "Baseline Loss: 2.8133 | Actual Loss: 0.1715\n",
      "Baseline Loss: 2.8732 | Actual Loss: 0.4876\n",
      "Baseline Loss: 2.8924 | Actual Loss: 0.4608\n",
      "Baseline Loss: 2.8098 | Actual Loss: 0.2957\n",
      "Baseline Loss: 2.7688 | Actual Loss: 0.5537\n",
      "Baseline Loss: 2.7404 | Actual Loss: 2.0716\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.6465\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7725\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4980\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.4435\n",
      "Epoch 101/1000: Train Loss: 0.7050, Val Loss: 0.5901\n",
      "Baseline Loss: 2.9352 | Actual Loss: 0.3595\n",
      "Baseline Loss: 2.8178 | Actual Loss: 0.5100\n",
      "Baseline Loss: 2.8216 | Actual Loss: 0.4946\n",
      "Baseline Loss: 2.7684 | Actual Loss: 0.5175\n",
      "Baseline Loss: 2.8473 | Actual Loss: 0.1349\n",
      "Baseline Loss: 2.8273 | Actual Loss: 0.2747\n",
      "Baseline Loss: 2.7801 | Actual Loss: 0.2907\n",
      "Baseline Loss: 2.8667 | Actual Loss: 0.4230\n",
      "Baseline Loss: 2.7594 | Actual Loss: 0.3107\n",
      "Baseline Loss: 2.7819 | Actual Loss: 2.4413\n",
      "Baseline Loss: 2.8277 | Actual Loss: 1.0995\n",
      "Baseline Loss: 2.8243 | Actual Loss: 0.3411\n",
      "Baseline Loss: 2.8731 | Actual Loss: 0.1900\n",
      "Baseline Loss: 2.8589 | Actual Loss: 0.5939\n",
      "Baseline Loss: 2.8386 | Actual Loss: 0.4812\n",
      "Baseline Loss: 2.6514 | Actual Loss: 2.5595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 102/1000 [00:33<04:35,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8199 | Actual Loss: 0.5863\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8551\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5605\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2752\n",
      "Epoch 102/1000: Train Loss: 0.6889, Val Loss: 0.5693\n",
      "Baseline Loss: 2.7902 | Actual Loss: 0.3580\n",
      "Baseline Loss: 2.8490 | Actual Loss: 0.8070\n",
      "Baseline Loss: 2.7886 | Actual Loss: 0.2634\n",
      "Baseline Loss: 2.8487 | Actual Loss: 0.3704\n",
      "Baseline Loss: 2.8975 | Actual Loss: 2.4509\n",
      "Baseline Loss: 2.8431 | Actual Loss: 0.1275\n",
      "Baseline Loss: 2.8997 | Actual Loss: 1.7835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 103/1000 [00:33<04:45,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8218 | Actual Loss: 0.6764\n",
      "Baseline Loss: 2.8187 | Actual Loss: 0.6465\n",
      "Baseline Loss: 2.8440 | Actual Loss: 0.6770\n",
      "Baseline Loss: 2.8653 | Actual Loss: 0.9315\n",
      "Baseline Loss: 2.7941 | Actual Loss: 0.3478\n",
      "Baseline Loss: 2.8084 | Actual Loss: 0.4171\n",
      "Baseline Loss: 2.8262 | Actual Loss: 0.2980\n",
      "Baseline Loss: 2.8286 | Actual Loss: 0.4662\n",
      "Baseline Loss: 2.4371 | Actual Loss: 0.0511\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.7349\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8036\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5027\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3500\n",
      "Epoch 103/1000: Train Loss: 0.6670, Val Loss: 0.5978\n",
      "Baseline Loss: 2.7948 | Actual Loss: 0.4736\n",
      "Baseline Loss: 2.9046 | Actual Loss: 0.3757\n",
      "Baseline Loss: 2.8286 | Actual Loss: 0.5398\n",
      "Baseline Loss: 2.7953 | Actual Loss: 0.4747\n",
      "Baseline Loss: 2.7734 | Actual Loss: 0.5273\n",
      "Baseline Loss: 2.8388 | Actual Loss: 0.4526\n",
      "Baseline Loss: 2.9315 | Actual Loss: 0.6788\n",
      "Baseline Loss: 2.7909 | Actual Loss: 0.4350\n",
      "Baseline Loss: 2.8668 | Actual Loss: 0.2014\n",
      "Baseline Loss: 2.8276 | Actual Loss: 1.2422\n",
      "Baseline Loss: 2.7962 | Actual Loss: 1.0734\n",
      "Baseline Loss: 2.8031 | Actual Loss: 0.9218\n",
      "Baseline Loss: 2.8399 | Actual Loss: 0.2232\n",
      "Baseline Loss: 2.8618 | Actual Loss: 0.5319\n",
      "Baseline Loss: 2.8832 | Actual Loss: 2.0787\n",
      "Baseline Loss: 2.5643 | Actual Loss: 0.4154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 104/1000 [00:33<04:58,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8199 | Actual Loss: 0.4652\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7681\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5403\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3746\n",
      "Epoch 104/1000: Train Loss: 0.6653, Val Loss: 0.5370\n",
      "New best validation loss: 0.5370\n",
      "Baseline Loss: 2.7693 | Actual Loss: 2.0308\n",
      "Baseline Loss: 2.8140 | Actual Loss: 0.2984\n",
      "Baseline Loss: 2.8649 | Actual Loss: 0.1389\n",
      "Baseline Loss: 2.7715 | Actual Loss: 0.2277\n",
      "Baseline Loss: 2.7922 | Actual Loss: 0.4218\n",
      "Baseline Loss: 2.9075 | Actual Loss: 0.6585\n",
      "Baseline Loss: 2.8720 | Actual Loss: 0.5371\n",
      "Baseline Loss: 2.7666 | Actual Loss: 0.3707\n",
      "Baseline Loss: 2.8219 | Actual Loss: 0.8227\n",
      "Baseline Loss: 2.8550 | Actual Loss: 0.4501\n",
      "Baseline Loss: 2.8439 | Actual Loss: 0.2978\n",
      "Baseline Loss: 2.8102 | Actual Loss: 0.2501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 105/1000 [00:34<04:37,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8130 | Actual Loss: 0.6553\n",
      "Baseline Loss: 2.8284 | Actual Loss: 0.6107\n",
      "Baseline Loss: 2.8339 | Actual Loss: 0.4587\n",
      "Baseline Loss: 2.4091 | Actual Loss: 0.9221\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.6113\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7252\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5429\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2509\n",
      "Epoch 105/1000: Train Loss: 0.5720, Val Loss: 0.5326\n",
      "New best validation loss: 0.5326\n",
      "Baseline Loss: 2.8607 | Actual Loss: 0.1216\n",
      "Baseline Loss: 2.7919 | Actual Loss: 0.2920\n",
      "Baseline Loss: 2.8545 | Actual Loss: 0.1238\n",
      "Baseline Loss: 2.8898 | Actual Loss: 0.4075\n",
      "Baseline Loss: 2.8018 | Actual Loss: 0.2998\n",
      "Baseline Loss: 2.8689 | Actual Loss: 0.2556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 106/1000 [00:34<04:45,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7834 | Actual Loss: 0.2522\n",
      "Baseline Loss: 2.8746 | Actual Loss: 0.2745\n",
      "Baseline Loss: 2.8358 | Actual Loss: 0.3402\n",
      "Baseline Loss: 2.8403 | Actual Loss: 1.8094\n",
      "Baseline Loss: 2.7913 | Actual Loss: 0.5275\n",
      "Baseline Loss: 2.7739 | Actual Loss: 0.3148\n",
      "Baseline Loss: 2.7444 | Actual Loss: 0.7465\n",
      "Baseline Loss: 2.8250 | Actual Loss: 0.3442\n",
      "Baseline Loss: 2.8642 | Actual Loss: 0.7129\n",
      "Baseline Loss: 2.4009 | Actual Loss: 2.1188\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.8886\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.0493\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5360\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.4485\n",
      "Epoch 106/1000: Train Loss: 0.5588, Val Loss: 0.7306\n",
      "Baseline Loss: 2.7899 | Actual Loss: 1.6371\n",
      "Baseline Loss: 2.7813 | Actual Loss: 0.8883\n",
      "Baseline Loss: 2.8404 | Actual Loss: 0.6333\n",
      "Baseline Loss: 2.7816 | Actual Loss: 0.2516\n",
      "Baseline Loss: 2.8662 | Actual Loss: 0.8503\n",
      "Baseline Loss: 2.8400 | Actual Loss: 0.3926\n",
      "Baseline Loss: 2.7675 | Actual Loss: 0.4027\n",
      "Baseline Loss: 2.8568 | Actual Loss: 0.3414\n",
      "Baseline Loss: 2.7865 | Actual Loss: 0.3651\n",
      "Baseline Loss: 2.7786 | Actual Loss: 0.4129\n",
      "Baseline Loss: 2.9051 | Actual Loss: 1.6157\n",
      "Baseline Loss: 2.8055 | Actual Loss: 0.1660\n",
      "Baseline Loss: 2.7763 | Actual Loss: 1.4252\n",
      "Baseline Loss: 2.8046 | Actual Loss: 1.6118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 107/1000 [00:34<05:05,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8755 | Actual Loss: 1.1984\n",
      "Baseline Loss: 2.7462 | Actual Loss: 0.0853\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.6156\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.5031\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5040\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.5812\n",
      "Epoch 107/1000: Train Loss: 0.7674, Val Loss: 0.8010\n",
      "Baseline Loss: 2.8007 | Actual Loss: 2.1031\n",
      "Baseline Loss: 2.8477 | Actual Loss: 0.5299\n",
      "Baseline Loss: 2.7690 | Actual Loss: 2.2711\n",
      "Baseline Loss: 2.8522 | Actual Loss: 0.1221\n",
      "Baseline Loss: 2.8105 | Actual Loss: 0.2897\n",
      "Baseline Loss: 2.7978 | Actual Loss: 0.6952\n",
      "Baseline Loss: 2.7952 | Actual Loss: 0.5060\n",
      "Baseline Loss: 2.8770 | Actual Loss: 0.2474\n",
      "Baseline Loss: 2.8833 | Actual Loss: 0.4936\n",
      "Baseline Loss: 2.8288 | Actual Loss: 1.5205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 108/1000 [00:35<04:41,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7954 | Actual Loss: 0.7281\n",
      "Baseline Loss: 2.8169 | Actual Loss: 0.5565\n",
      "Baseline Loss: 2.8548 | Actual Loss: 0.8055\n",
      "Baseline Loss: 2.8125 | Actual Loss: 0.3281\n",
      "Baseline Loss: 2.8008 | Actual Loss: 0.2883\n",
      "Baseline Loss: 2.6354 | Actual Loss: 2.3352\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.6976\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.9604\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5557\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.4640\n",
      "Epoch 108/1000: Train Loss: 0.8638, Val Loss: 0.6694\n",
      "Baseline Loss: 2.8607 | Actual Loss: 0.2008\n",
      "Baseline Loss: 2.7296 | Actual Loss: 0.3127\n",
      "Baseline Loss: 2.8966 | Actual Loss: 0.8834\n",
      "Baseline Loss: 2.8071 | Actual Loss: 0.1403\n",
      "Baseline Loss: 2.7851 | Actual Loss: 0.3187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 109/1000 [00:35<04:54,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9510 | Actual Loss: 1.4208\n",
      "Baseline Loss: 2.8015 | Actual Loss: 0.3595\n",
      "Baseline Loss: 2.8011 | Actual Loss: 2.1397\n",
      "Baseline Loss: 2.8206 | Actual Loss: 1.0850\n",
      "Baseline Loss: 2.8677 | Actual Loss: 0.1784\n",
      "Baseline Loss: 2.8485 | Actual Loss: 0.2873\n",
      "Baseline Loss: 2.7948 | Actual Loss: 0.3440\n",
      "Baseline Loss: 2.7902 | Actual Loss: 0.2835\n",
      "Baseline Loss: 2.7881 | Actual Loss: 0.1802\n",
      "Baseline Loss: 2.8584 | Actual Loss: 0.7095\n",
      "Baseline Loss: 2.4670 | Actual Loss: 0.1097\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.9547\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8246\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5045\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.4414\n",
      "Epoch 109/1000: Train Loss: 0.5596, Val Loss: 0.6813\n",
      "Baseline Loss: 2.8270 | Actual Loss: 1.2899\n",
      "Baseline Loss: 2.8162 | Actual Loss: 0.2858\n",
      "Baseline Loss: 2.7868 | Actual Loss: 0.2612\n",
      "Baseline Loss: 2.8573 | Actual Loss: 0.3867\n",
      "Baseline Loss: 2.8320 | Actual Loss: 0.2469\n",
      "Baseline Loss: 2.7618 | Actual Loss: 1.6768\n",
      "Baseline Loss: 2.8704 | Actual Loss: 1.0576\n",
      "Baseline Loss: 2.8224 | Actual Loss: 0.4804\n",
      "Baseline Loss: 2.8402 | Actual Loss: 0.5877\n",
      "Baseline Loss: 2.8108 | Actual Loss: 0.7520\n",
      "Baseline Loss: 2.8066 | Actual Loss: 0.4111\n",
      "Baseline Loss: 2.7875 | Actual Loss: 0.5993\n",
      "Baseline Loss: 2.9058 | Actual Loss: 1.0215\n",
      "Baseline Loss: 2.8026 | Actual Loss: 0.5477\n",
      "Baseline Loss: 2.7813 | Actual Loss: 0.5288\n",
      "Baseline Loss: 2.5204 | Actual Loss: 0.2485\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.6181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 110/1000 [00:35<04:55,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8180 | Actual Loss: 0.8074\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4566\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.4403\n",
      "Epoch 110/1000: Train Loss: 0.6489, Val Loss: 0.5806\n",
      "Baseline Loss: 2.8765 | Actual Loss: 0.5178\n",
      "Baseline Loss: 2.8009 | Actual Loss: 0.3658\n",
      "Baseline Loss: 2.8332 | Actual Loss: 0.7638\n",
      "Baseline Loss: 2.9019 | Actual Loss: 0.1934\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2851\n",
      "Baseline Loss: 2.8061 | Actual Loss: 0.2783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 111/1000 [00:36<04:35,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7781 | Actual Loss: 0.1838\n",
      "Baseline Loss: 2.7346 | Actual Loss: 0.2793\n",
      "Baseline Loss: 2.8214 | Actual Loss: 0.2863\n",
      "Baseline Loss: 2.8191 | Actual Loss: 0.6487\n",
      "Baseline Loss: 2.7844 | Actual Loss: 1.1494\n",
      "Baseline Loss: 2.7936 | Actual Loss: 0.4309\n",
      "Baseline Loss: 2.8586 | Actual Loss: 0.2960\n",
      "Baseline Loss: 2.8018 | Actual Loss: 0.2245\n",
      "Baseline Loss: 2.8206 | Actual Loss: 0.2817\n",
      "Baseline Loss: 2.6321 | Actual Loss: 0.4269\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.6428\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8095\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5582\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3178\n",
      "Epoch 111/1000: Train Loss: 0.4132, Val Loss: 0.5821\n",
      "Baseline Loss: 2.7812 | Actual Loss: 0.5260\n",
      "Baseline Loss: 2.7456 | Actual Loss: 0.4397\n",
      "Baseline Loss: 2.8524 | Actual Loss: 0.4379\n",
      "Baseline Loss: 2.8329 | Actual Loss: 2.6237\n",
      "Baseline Loss: 2.7838 | Actual Loss: 0.3592\n",
      "Baseline Loss: 2.8095 | Actual Loss: 0.5047\n",
      "Baseline Loss: 2.8496 | Actual Loss: 0.7437\n",
      "Baseline Loss: 2.7992 | Actual Loss: 0.3345\n",
      "Baseline Loss: 2.8156 | Actual Loss: 0.3285\n",
      "Baseline Loss: 2.9399 | Actual Loss: 2.1850\n",
      "Baseline Loss: 2.7536 | Actual Loss: 0.8337\n",
      "Baseline Loss: 2.8699 | Actual Loss: 0.4052\n",
      "Baseline Loss: 2.8375 | Actual Loss: 0.4843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 112/1000 [00:36<04:43,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7771 | Actual Loss: 0.7613\n",
      "Baseline Loss: 2.9007 | Actual Loss: 0.3965\n",
      "Baseline Loss: 2.5377 | Actual Loss: 0.1052\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.7020\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8836\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4738\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3938\n",
      "Epoch 112/1000: Train Loss: 0.7168, Val Loss: 0.6133\n",
      "Baseline Loss: 2.8007 | Actual Loss: 0.4146\n",
      "Baseline Loss: 2.8592 | Actual Loss: 0.4677\n",
      "Baseline Loss: 2.8356 | Actual Loss: 0.4050\n",
      "Baseline Loss: 2.8238 | Actual Loss: 0.2477\n",
      "Baseline Loss: 2.8144 | Actual Loss: 0.1825\n",
      "Baseline Loss: 2.8391 | Actual Loss: 0.2589\n",
      "Baseline Loss: 2.8280 | Actual Loss: 2.0198\n",
      "Baseline Loss: 2.8176 | Actual Loss: 0.3805\n",
      "Baseline Loss: 2.8245 | Actual Loss: 0.5275\n",
      "Baseline Loss: 2.7622 | Actual Loss: 0.3851\n",
      "Baseline Loss: 2.7941 | Actual Loss: 2.6454\n",
      "Baseline Loss: 2.8050 | Actual Loss: 2.9933\n",
      "Baseline Loss: 2.7928 | Actual Loss: 0.3150\n",
      "Baseline Loss: 2.8399 | Actual Loss: 0.3083\n",
      "Baseline Loss: 2.8186 | Actual Loss: 0.4618\n",
      "Baseline Loss: 2.5101 | Actual Loss: 0.1680\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5934\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.9054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█▏        | 113/1000 [00:36<04:51,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7998 | Actual Loss: 0.5244\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2363\n",
      "Epoch 113/1000: Train Loss: 0.7613, Val Loss: 0.5649\n",
      "Baseline Loss: 2.7875 | Actual Loss: 0.3098\n",
      "Baseline Loss: 2.7600 | Actual Loss: 0.5085\n",
      "Baseline Loss: 2.7988 | Actual Loss: 0.2507\n",
      "Baseline Loss: 2.8292 | Actual Loss: 0.4300\n",
      "Baseline Loss: 2.8396 | Actual Loss: 0.4687\n",
      "Baseline Loss: 2.8449 | Actual Loss: 0.9074\n",
      "Baseline Loss: 2.8375 | Actual Loss: 0.9276\n",
      "Baseline Loss: 2.8438 | Actual Loss: 0.1740\n",
      "Baseline Loss: 2.8415 | Actual Loss: 0.2568\n",
      "Baseline Loss: 2.8146 | Actual Loss: 0.7483\n",
      "Baseline Loss: 2.8826 | Actual Loss: 0.1643\n",
      "Baseline Loss: 2.7458 | Actual Loss: 0.1816\n",
      "Baseline Loss: 2.8431 | Actual Loss: 0.5756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█▏        | 114/1000 [00:37<04:39,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8528 | Actual Loss: 0.2441\n",
      "Baseline Loss: 2.8368 | Actual Loss: 0.5476\n",
      "Baseline Loss: 2.5064 | Actual Loss: 0.2193\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5686\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6718\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4054\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2365\n",
      "Epoch 114/1000: Train Loss: 0.4321, Val Loss: 0.4706\n",
      "New best validation loss: 0.4706\n",
      "Baseline Loss: 2.8189 | Actual Loss: 0.2196\n",
      "Baseline Loss: 2.8657 | Actual Loss: 0.5849\n",
      "Baseline Loss: 2.7992 | Actual Loss: 0.3093\n",
      "Baseline Loss: 2.8336 | Actual Loss: 0.4744\n",
      "Baseline Loss: 2.8020 | Actual Loss: 0.2266\n",
      "Baseline Loss: 2.7763 | Actual Loss: 0.2000\n",
      "Baseline Loss: 2.8132 | Actual Loss: 2.7916\n",
      "Baseline Loss: 2.8560 | Actual Loss: 0.9947\n",
      "Baseline Loss: 2.8508 | Actual Loss: 0.7909\n",
      "Baseline Loss: 2.8081 | Actual Loss: 0.4925\n",
      "Baseline Loss: 2.8139 | Actual Loss: 2.6759\n",
      "Baseline Loss: 2.9002 | Actual Loss: 0.3773\n",
      "Baseline Loss: 2.7865 | Actual Loss: 0.4531\n",
      "Baseline Loss: 2.7938 | Actual Loss: 0.3117\n",
      "Baseline Loss: 2.8218 | Actual Loss: 2.2337\n",
      "Baseline Loss: 2.6995 | Actual Loss: 0.1356\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4440\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8593\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 115/1000 [00:37<04:44,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7254 | Actual Loss: 0.4319\n",
      "Epoch 115/1000: Train Loss: 0.8295, Val Loss: 0.5558\n",
      "Baseline Loss: 2.8460 | Actual Loss: 0.1645\n",
      "Baseline Loss: 2.7858 | Actual Loss: 0.1792\n",
      "Baseline Loss: 2.8497 | Actual Loss: 0.4976\n",
      "Baseline Loss: 2.8905 | Actual Loss: 0.1964\n",
      "Baseline Loss: 2.7761 | Actual Loss: 0.6751\n",
      "Baseline Loss: 2.8388 | Actual Loss: 0.3365\n",
      "Baseline Loss: 2.8135 | Actual Loss: 2.3717\n",
      "Baseline Loss: 2.8185 | Actual Loss: 0.4305\n",
      "Baseline Loss: 2.8750 | Actual Loss: 0.3207\n",
      "Baseline Loss: 2.8913 | Actual Loss: 0.1932\n",
      "Baseline Loss: 2.8440 | Actual Loss: 0.5452\n",
      "Baseline Loss: 2.7559 | Actual Loss: 1.5715\n",
      "Baseline Loss: 2.8880 | Actual Loss: 0.4374\n",
      "Baseline Loss: 2.7394 | Actual Loss: 0.3296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 116/1000 [00:37<04:25,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7712 | Actual Loss: 0.1445\n",
      "Baseline Loss: 2.6650 | Actual Loss: 1.2016\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5630\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.1601\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4751\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3840\n",
      "Epoch 116/1000: Train Loss: 0.5997, Val Loss: 0.6456\n",
      "Baseline Loss: 2.8798 | Actual Loss: 0.7502\n",
      "Baseline Loss: 2.8446 | Actual Loss: 0.4106\n",
      "Baseline Loss: 2.8579 | Actual Loss: 0.6068\n",
      "Baseline Loss: 2.7529 | Actual Loss: 0.2708\n",
      "Baseline Loss: 2.8635 | Actual Loss: 0.4261\n",
      "Baseline Loss: 2.7982 | Actual Loss: 0.4691\n",
      "Baseline Loss: 2.8412 | Actual Loss: 0.4335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 117/1000 [00:38<04:38,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7974 | Actual Loss: 0.2553\n",
      "Baseline Loss: 2.8441 | Actual Loss: 0.6525\n",
      "Baseline Loss: 2.8171 | Actual Loss: 0.4708\n",
      "Baseline Loss: 2.8050 | Actual Loss: 0.2418\n",
      "Baseline Loss: 2.8062 | Actual Loss: 0.1973\n",
      "Baseline Loss: 2.7939 | Actual Loss: 0.4138\n",
      "Baseline Loss: 2.8236 | Actual Loss: 0.7051\n",
      "Baseline Loss: 2.7825 | Actual Loss: 0.4321\n",
      "Baseline Loss: 2.5953 | Actual Loss: 2.0479\n",
      "Baseline Loss: 2.8199 | Actual Loss: 1.0525\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8946\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4406\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.5840\n",
      "Epoch 117/1000: Train Loss: 0.5490, Val Loss: 0.7429\n",
      "Baseline Loss: 2.8269 | Actual Loss: 1.3699\n",
      "Baseline Loss: 2.7865 | Actual Loss: 0.5050\n",
      "Baseline Loss: 2.7743 | Actual Loss: 0.4394\n",
      "Baseline Loss: 2.8549 | Actual Loss: 0.7666\n",
      "Baseline Loss: 2.8978 | Actual Loss: 0.4711\n",
      "Baseline Loss: 2.8169 | Actual Loss: 0.2242\n",
      "Baseline Loss: 2.8249 | Actual Loss: 1.0690\n",
      "Baseline Loss: 2.7954 | Actual Loss: 0.1824\n",
      "Baseline Loss: 2.7933 | Actual Loss: 0.2676\n",
      "Baseline Loss: 2.7712 | Actual Loss: 0.2172\n",
      "Baseline Loss: 2.7902 | Actual Loss: 0.1398\n",
      "Baseline Loss: 2.8244 | Actual Loss: 0.3970\n",
      "Baseline Loss: 2.8375 | Actual Loss: 0.5971\n",
      "Baseline Loss: 2.8718 | Actual Loss: 0.2838\n",
      "Baseline Loss: 2.8152 | Actual Loss: 2.3068\n",
      "Baseline Loss: 2.4807 | Actual Loss: 0.3384\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.9165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 118/1000 [00:38<04:45,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8180 | Actual Loss: 0.7852\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5686\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2340\n",
      "Epoch 118/1000: Train Loss: 0.5984, Val Loss: 0.6261\n",
      "Baseline Loss: 2.8212 | Actual Loss: 0.2781\n",
      "Baseline Loss: 2.7436 | Actual Loss: 0.7697\n",
      "Baseline Loss: 2.8497 | Actual Loss: 0.3421\n",
      "Baseline Loss: 2.8149 | Actual Loss: 0.1729\n",
      "Baseline Loss: 2.8367 | Actual Loss: 2.7285\n",
      "Baseline Loss: 2.7962 | Actual Loss: 0.6757\n",
      "Baseline Loss: 2.8212 | Actual Loss: 0.3793\n",
      "Baseline Loss: 2.8374 | Actual Loss: 0.4009\n",
      "Baseline Loss: 2.7630 | Actual Loss: 0.3297\n",
      "Baseline Loss: 2.8029 | Actual Loss: 0.2619\n",
      "Baseline Loss: 2.8636 | Actual Loss: 0.6164\n",
      "Baseline Loss: 2.8105 | Actual Loss: 0.4374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 119/1000 [00:38<04:28,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8800 | Actual Loss: 0.2013\n",
      "Baseline Loss: 2.8910 | Actual Loss: 2.2192\n",
      "Baseline Loss: 2.8231 | Actual Loss: 0.4659\n",
      "Baseline Loss: 2.6656 | Actual Loss: 0.1493\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.6644\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7309\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4712\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2123\n",
      "Epoch 119/1000: Train Loss: 0.6518, Val Loss: 0.5197\n",
      "Baseline Loss: 2.7507 | Actual Loss: 0.5195\n",
      "Baseline Loss: 2.8355 | Actual Loss: 0.2442\n",
      "Baseline Loss: 2.8639 | Actual Loss: 0.1380\n",
      "Baseline Loss: 2.8452 | Actual Loss: 0.4223\n",
      "Baseline Loss: 2.7801 | Actual Loss: 0.3769\n",
      "Baseline Loss: 2.7992 | Actual Loss: 0.4574\n",
      "Baseline Loss: 2.8074 | Actual Loss: 0.4062\n",
      "Baseline Loss: 2.8038 | Actual Loss: 0.1540\n",
      "Baseline Loss: 2.8497 | Actual Loss: 1.3314\n",
      "Baseline Loss: 2.8870 | Actual Loss: 0.3046\n",
      "Baseline Loss: 2.9299 | Actual Loss: 0.3149\n",
      "Baseline Loss: 2.8047 | Actual Loss: 0.3442\n",
      "Baseline Loss: 2.8562 | Actual Loss: 0.3322\n",
      "Baseline Loss: 2.8543 | Actual Loss: 0.2584\n",
      "Baseline Loss: 2.8324 | Actual Loss: 1.1727\n",
      "Baseline Loss: 2.4996 | Actual Loss: 1.2130\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.8934\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 120/1000 [00:38<04:40,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7998 | Actual Loss: 0.5379\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3944\n",
      "Epoch 120/1000: Train Loss: 0.4994, Val Loss: 0.6377\n",
      "Baseline Loss: 2.7724 | Actual Loss: 0.3169\n",
      "Baseline Loss: 2.8714 | Actual Loss: 0.2707\n",
      "Baseline Loss: 2.7851 | Actual Loss: 0.5027\n",
      "Baseline Loss: 2.8111 | Actual Loss: 0.3574\n",
      "Baseline Loss: 2.8615 | Actual Loss: 2.5306\n",
      "Baseline Loss: 2.8502 | Actual Loss: 0.3834\n",
      "Baseline Loss: 2.8257 | Actual Loss: 0.3296\n",
      "Baseline Loss: 2.8198 | Actual Loss: 0.6315\n",
      "Baseline Loss: 2.8652 | Actual Loss: 0.2495\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.1471\n",
      "Baseline Loss: 2.8327 | Actual Loss: 0.8924\n",
      "Baseline Loss: 2.8386 | Actual Loss: 1.4665\n",
      "Baseline Loss: 2.8197 | Actual Loss: 0.2506\n",
      "Baseline Loss: 2.7755 | Actual Loss: 0.5449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 121/1000 [00:39<04:22,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7573 | Actual Loss: 0.3574\n",
      "Baseline Loss: 2.5598 | Actual Loss: 0.0890\n",
      "Baseline Loss: 2.8199 | Actual Loss: 1.0914\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6515\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5979\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3804\n",
      "Epoch 121/1000: Train Loss: 0.5825, Val Loss: 0.6803\n",
      "Baseline Loss: 2.8031 | Actual Loss: 0.3515\n",
      "Baseline Loss: 2.7832 | Actual Loss: 0.4977\n",
      "Baseline Loss: 2.8077 | Actual Loss: 0.2577\n",
      "Baseline Loss: 2.7869 | Actual Loss: 0.6289\n",
      "Baseline Loss: 2.8144 | Actual Loss: 2.4015\n",
      "Baseline Loss: 2.7783 | Actual Loss: 0.8055\n",
      "Baseline Loss: 2.8358 | Actual Loss: 0.3888\n",
      "Baseline Loss: 2.8336 | Actual Loss: 0.9131\n",
      "Baseline Loss: 2.8964 | Actual Loss: 1.0700\n",
      "Baseline Loss: 2.8622 | Actual Loss: 0.3775\n",
      "Baseline Loss: 2.7776 | Actual Loss: 0.5401\n",
      "Baseline Loss: 2.8432 | Actual Loss: 0.3129\n",
      "Baseline Loss: 2.8508 | Actual Loss: 0.4509\n",
      "Baseline Loss: 2.8076 | Actual Loss: 0.3458\n",
      "Baseline Loss: 2.8463 | Actual Loss: 0.5822\n",
      "Baseline Loss: 2.5846 | Actual Loss: 0.0956\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.7057\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 122/1000 [00:39<04:40,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7998 | Actual Loss: 0.6192\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2959\n",
      "Epoch 122/1000: Train Loss: 0.6262, Val Loss: 0.5876\n",
      "Baseline Loss: 2.8387 | Actual Loss: 0.3387\n",
      "Baseline Loss: 2.7561 | Actual Loss: 1.3636\n",
      "Baseline Loss: 2.7912 | Actual Loss: 0.2603\n",
      "Baseline Loss: 2.8926 | Actual Loss: 0.3563\n",
      "Baseline Loss: 2.7603 | Actual Loss: 0.5989\n",
      "Baseline Loss: 2.8476 | Actual Loss: 0.3438\n",
      "Baseline Loss: 2.8655 | Actual Loss: 0.1716\n",
      "Baseline Loss: 2.8228 | Actual Loss: 0.1154\n",
      "Baseline Loss: 2.8158 | Actual Loss: 1.9529\n",
      "Baseline Loss: 2.8410 | Actual Loss: 0.2043\n",
      "Baseline Loss: 2.7986 | Actual Loss: 0.2877\n",
      "Baseline Loss: 2.8282 | Actual Loss: 0.2291\n",
      "Baseline Loss: 2.8475 | Actual Loss: 0.1337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 123/1000 [00:39<04:49,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8189 | Actual Loss: 0.4482\n",
      "Baseline Loss: 2.8496 | Actual Loss: 0.5415\n",
      "Baseline Loss: 2.5005 | Actual Loss: 1.5609\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.6122\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6935\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5784\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2110\n",
      "Epoch 123/1000: Train Loss: 0.5567, Val Loss: 0.5238\n",
      "Baseline Loss: 2.7925 | Actual Loss: 0.4221\n",
      "Baseline Loss: 2.8025 | Actual Loss: 0.2709\n",
      "Baseline Loss: 2.7825 | Actual Loss: 0.5042\n",
      "Baseline Loss: 2.8309 | Actual Loss: 0.4717\n",
      "Baseline Loss: 2.7828 | Actual Loss: 0.4394\n",
      "Baseline Loss: 2.8804 | Actual Loss: 0.2660\n",
      "Baseline Loss: 2.8388 | Actual Loss: 0.4227\n",
      "Baseline Loss: 2.7975 | Actual Loss: 0.5798\n",
      "Baseline Loss: 2.8361 | Actual Loss: 2.1384\n",
      "Baseline Loss: 2.8522 | Actual Loss: 0.2237\n",
      "Baseline Loss: 2.8692 | Actual Loss: 0.7139\n",
      "Baseline Loss: 2.8427 | Actual Loss: 0.4740\n",
      "Baseline Loss: 2.8283 | Actual Loss: 0.2392\n",
      "Baseline Loss: 2.7897 | Actual Loss: 0.2542\n",
      "Baseline Loss: 2.8114 | Actual Loss: 0.4905\n",
      "Baseline Loss: 2.6054 | Actual Loss: 0.3025\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 124/1000 [00:40<04:37,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8180 | Actual Loss: 0.8045\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5055\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3875\n",
      "Epoch 124/1000: Train Loss: 0.5133, Val Loss: 0.5577\n",
      "Baseline Loss: 2.7482 | Actual Loss: 0.4112\n",
      "Baseline Loss: 2.8936 | Actual Loss: 0.3725\n",
      "Baseline Loss: 2.8413 | Actual Loss: 0.7097\n",
      "Baseline Loss: 2.7636 | Actual Loss: 0.0952\n",
      "Baseline Loss: 2.7775 | Actual Loss: 1.7588\n",
      "Baseline Loss: 2.9039 | Actual Loss: 0.4889\n",
      "Baseline Loss: 2.8438 | Actual Loss: 0.3116\n",
      "Baseline Loss: 2.7836 | Actual Loss: 0.1425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▎        | 125/1000 [00:40<04:42,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8392 | Actual Loss: 0.5841\n",
      "Baseline Loss: 2.7874 | Actual Loss: 0.7015\n",
      "Baseline Loss: 2.8352 | Actual Loss: 0.2846\n",
      "Baseline Loss: 2.7915 | Actual Loss: 0.5381\n",
      "Baseline Loss: 2.9228 | Actual Loss: 0.5696\n",
      "Baseline Loss: 2.8360 | Actual Loss: 0.4383\n",
      "Baseline Loss: 2.8427 | Actual Loss: 0.6434\n",
      "Baseline Loss: 2.6764 | Actual Loss: 0.3777\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.6411\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8473\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5937\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.4095\n",
      "Epoch 125/1000: Train Loss: 0.5267, Val Loss: 0.6229\n",
      "Baseline Loss: 2.7570 | Actual Loss: 0.1374\n",
      "Baseline Loss: 2.7690 | Actual Loss: 0.3616\n",
      "Baseline Loss: 2.8093 | Actual Loss: 0.6360\n",
      "Baseline Loss: 2.8218 | Actual Loss: 0.5142\n",
      "Baseline Loss: 2.8687 | Actual Loss: 0.6310\n",
      "Baseline Loss: 2.8284 | Actual Loss: 0.3525\n",
      "Baseline Loss: 2.9221 | Actual Loss: 2.0678\n",
      "Baseline Loss: 2.7840 | Actual Loss: 0.5010\n",
      "Baseline Loss: 2.8116 | Actual Loss: 0.1804\n",
      "Baseline Loss: 2.7226 | Actual Loss: 0.3657\n",
      "Baseline Loss: 2.9011 | Actual Loss: 0.2558\n",
      "Baseline Loss: 2.7929 | Actual Loss: 0.2882\n",
      "Baseline Loss: 2.8288 | Actual Loss: 0.1286\n",
      "Baseline Loss: 2.7618 | Actual Loss: 0.1217\n",
      "Baseline Loss: 2.7642 | Actual Loss: 0.4481\n",
      "Baseline Loss: 2.5751 | Actual Loss: 0.1389\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 126/1000 [00:40<04:48,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8180 | Actual Loss: 1.0232\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5255\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.1627\n",
      "Epoch 126/1000: Train Loss: 0.4456, Val Loss: 0.5727\n",
      "Baseline Loss: 2.9276 | Actual Loss: 1.0945\n",
      "Baseline Loss: 2.8355 | Actual Loss: 0.3894\n",
      "Baseline Loss: 2.9039 | Actual Loss: 0.2269\n",
      "Baseline Loss: 2.8107 | Actual Loss: 0.2772\n",
      "Baseline Loss: 2.8571 | Actual Loss: 0.3240\n",
      "Baseline Loss: 2.8031 | Actual Loss: 0.7024\n",
      "Baseline Loss: 2.8484 | Actual Loss: 0.5683\n",
      "Baseline Loss: 2.7386 | Actual Loss: 0.2436\n",
      "Baseline Loss: 2.8051 | Actual Loss: 1.7811\n",
      "Baseline Loss: 2.8162 | Actual Loss: 0.1266\n",
      "Baseline Loss: 2.8314 | Actual Loss: 2.2002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 127/1000 [00:41<04:35,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8139 | Actual Loss: 0.9927\n",
      "Baseline Loss: 2.8340 | Actual Loss: 0.3033\n",
      "Baseline Loss: 2.8111 | Actual Loss: 0.4211\n",
      "Baseline Loss: 2.8592 | Actual Loss: 0.5146\n",
      "Baseline Loss: 2.4956 | Actual Loss: 0.1596\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4689\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8833\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.6054\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3327\n",
      "Epoch 127/1000: Train Loss: 0.6453, Val Loss: 0.5726\n",
      "Baseline Loss: 2.7550 | Actual Loss: 0.3923\n",
      "Baseline Loss: 2.8296 | Actual Loss: 0.4033\n",
      "Baseline Loss: 2.8518 | Actual Loss: 0.5617\n",
      "Baseline Loss: 2.8287 | Actual Loss: 0.3773\n",
      "Baseline Loss: 2.8413 | Actual Loss: 0.9885\n",
      "Baseline Loss: 2.8370 | Actual Loss: 0.1389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 128/1000 [00:41<04:45,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8607 | Actual Loss: 0.4382\n",
      "Baseline Loss: 2.7746 | Actual Loss: 0.4480\n",
      "Baseline Loss: 2.8390 | Actual Loss: 0.1492\n",
      "Baseline Loss: 2.8480 | Actual Loss: 0.2252\n",
      "Baseline Loss: 2.8279 | Actual Loss: 0.4060\n",
      "Baseline Loss: 2.8251 | Actual Loss: 0.0869\n",
      "Baseline Loss: 2.8088 | Actual Loss: 0.5902\n",
      "Baseline Loss: 2.8450 | Actual Loss: 0.3635\n",
      "Baseline Loss: 2.8260 | Actual Loss: 0.6169\n",
      "Baseline Loss: 2.5726 | Actual Loss: 0.0991\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.6158\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8745\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5733\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2057\n",
      "Epoch 128/1000: Train Loss: 0.3928, Val Loss: 0.5673\n",
      "Baseline Loss: 2.8588 | Actual Loss: 0.5423\n",
      "Baseline Loss: 2.8657 | Actual Loss: 0.3832\n",
      "Baseline Loss: 2.7827 | Actual Loss: 0.7489\n",
      "Baseline Loss: 2.9303 | Actual Loss: 0.5902\n",
      "Baseline Loss: 2.8299 | Actual Loss: 0.5274\n",
      "Baseline Loss: 2.7677 | Actual Loss: 0.3947\n",
      "Baseline Loss: 2.8860 | Actual Loss: 0.1994\n",
      "Baseline Loss: 2.8013 | Actual Loss: 0.2909\n",
      "Baseline Loss: 2.8255 | Actual Loss: 0.1267\n",
      "Baseline Loss: 2.8689 | Actual Loss: 0.2122\n",
      "Baseline Loss: 2.8369 | Actual Loss: 0.2323\n",
      "Baseline Loss: 2.9210 | Actual Loss: 2.8045\n",
      "Baseline Loss: 2.8146 | Actual Loss: 0.3299\n",
      "Baseline Loss: 2.7710 | Actual Loss: 0.6834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 129/1000 [00:41<04:51,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8185 | Actual Loss: 0.3045\n",
      "Baseline Loss: 2.5499 | Actual Loss: 0.0602\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.6630\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8658\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4812\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.4453\n",
      "Epoch 129/1000: Train Loss: 0.5269, Val Loss: 0.6138\n",
      "Baseline Loss: 2.7798 | Actual Loss: 0.2328\n",
      "Baseline Loss: 2.8409 | Actual Loss: 0.4475\n",
      "Baseline Loss: 2.8073 | Actual Loss: 0.3693\n",
      "Baseline Loss: 2.9081 | Actual Loss: 0.2676\n",
      "Baseline Loss: 2.8051 | Actual Loss: 0.1872\n",
      "Baseline Loss: 2.8319 | Actual Loss: 0.4060\n",
      "Baseline Loss: 2.7612 | Actual Loss: 0.6371\n",
      "Baseline Loss: 2.8060 | Actual Loss: 0.6963\n",
      "Baseline Loss: 2.9039 | Actual Loss: 0.5337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 130/1000 [00:42<04:35,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8949 | Actual Loss: 0.4975\n",
      "Baseline Loss: 2.8881 | Actual Loss: 0.4756\n",
      "Baseline Loss: 2.7595 | Actual Loss: 0.7779\n",
      "Baseline Loss: 2.8404 | Actual Loss: 0.5078\n",
      "Baseline Loss: 2.7794 | Actual Loss: 0.3042\n",
      "Baseline Loss: 2.7708 | Actual Loss: 0.4386\n",
      "Baseline Loss: 2.5778 | Actual Loss: 0.3808\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5785\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6667\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5036\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2583\n",
      "Epoch 130/1000: Train Loss: 0.4475, Val Loss: 0.5018\n",
      "Baseline Loss: 2.8065 | Actual Loss: 0.5977\n",
      "Baseline Loss: 2.8323 | Actual Loss: 0.2375\n",
      "Baseline Loss: 2.9166 | Actual Loss: 0.2425\n",
      "Baseline Loss: 2.7534 | Actual Loss: 0.2745\n",
      "Baseline Loss: 2.8176 | Actual Loss: 0.2558\n",
      "Baseline Loss: 2.8887 | Actual Loss: 0.3171\n",
      "Baseline Loss: 2.8058 | Actual Loss: 0.9491\n",
      "Baseline Loss: 2.8269 | Actual Loss: 1.0363\n",
      "Baseline Loss: 2.8088 | Actual Loss: 0.3878\n",
      "Baseline Loss: 2.8165 | Actual Loss: 0.2046\n",
      "Baseline Loss: 2.8086 | Actual Loss: 0.2933\n",
      "Baseline Loss: 2.7833 | Actual Loss: 0.9845\n",
      "Baseline Loss: 2.8229 | Actual Loss: 0.8242\n",
      "Baseline Loss: 2.8185 | Actual Loss: 0.2245\n",
      "Baseline Loss: 2.8578 | Actual Loss: 1.1699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 131/1000 [00:42<04:42,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5380 | Actual Loss: 0.3382\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.3130\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.9371\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5757\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.5014\n",
      "Epoch 131/1000: Train Loss: 0.5211, Val Loss: 0.5818\n",
      "Baseline Loss: 2.7704 | Actual Loss: 1.8555\n",
      "Baseline Loss: 2.8270 | Actual Loss: 0.3432\n",
      "Baseline Loss: 2.8323 | Actual Loss: 0.3261\n",
      "Baseline Loss: 2.8196 | Actual Loss: 0.1901\n",
      "Baseline Loss: 2.8018 | Actual Loss: 0.4380\n",
      "Baseline Loss: 2.9243 | Actual Loss: 0.4398\n",
      "Baseline Loss: 2.8965 | Actual Loss: 0.3967\n",
      "Baseline Loss: 2.7985 | Actual Loss: 0.5885\n",
      "Baseline Loss: 2.8676 | Actual Loss: 0.2232\n",
      "Baseline Loss: 2.7825 | Actual Loss: 1.2124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 132/1000 [00:42<04:22,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7783 | Actual Loss: 0.2149\n",
      "Baseline Loss: 2.8953 | Actual Loss: 0.3281\n",
      "Baseline Loss: 2.7788 | Actual Loss: 0.4886\n",
      "Baseline Loss: 2.8532 | Actual Loss: 0.1693\n",
      "Baseline Loss: 2.7971 | Actual Loss: 0.6585\n",
      "Baseline Loss: 2.5412 | Actual Loss: 0.1510\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5246\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8141\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5117\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3598\n",
      "Epoch 132/1000: Train Loss: 0.5015, Val Loss: 0.5526\n",
      "Baseline Loss: 2.7991 | Actual Loss: 0.5306\n",
      "Baseline Loss: 2.8899 | Actual Loss: 0.4455\n",
      "Baseline Loss: 2.7954 | Actual Loss: 0.2088\n",
      "Baseline Loss: 2.8283 | Actual Loss: 0.7747\n",
      "Baseline Loss: 2.8462 | Actual Loss: 0.2233\n",
      "Baseline Loss: 2.7615 | Actual Loss: 0.4364\n",
      "Baseline Loss: 2.8917 | Actual Loss: 1.1020\n",
      "Baseline Loss: 2.8306 | Actual Loss: 0.2225\n",
      "Baseline Loss: 2.8333 | Actual Loss: 0.5145\n",
      "Baseline Loss: 2.8393 | Actual Loss: 0.2645\n",
      "Baseline Loss: 2.8355 | Actual Loss: 0.9984\n",
      "Baseline Loss: 2.7571 | Actual Loss: 0.4078\n",
      "Baseline Loss: 2.7650 | Actual Loss: 0.1970\n",
      "Baseline Loss: 2.8738 | Actual Loss: 0.2151\n",
      "Baseline Loss: 2.8484 | Actual Loss: 0.3364\n",
      "Baseline Loss: 2.5268 | Actual Loss: 0.2712\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.3052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 133/1000 [00:43<04:36,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8180 | Actual Loss: 0.6718\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.6300\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.4366\n",
      "Epoch 133/1000: Train Loss: 0.4468, Val Loss: 0.5109\n",
      "Baseline Loss: 2.8799 | Actual Loss: 1.1990\n",
      "Baseline Loss: 2.8006 | Actual Loss: 0.7175\n",
      "Baseline Loss: 2.8263 | Actual Loss: 2.4075\n",
      "Baseline Loss: 2.8093 | Actual Loss: 0.2313\n",
      "Baseline Loss: 2.7797 | Actual Loss: 0.1369\n",
      "Baseline Loss: 2.7955 | Actual Loss: 0.1376\n",
      "Baseline Loss: 2.8099 | Actual Loss: 0.2233\n",
      "Baseline Loss: 2.8513 | Actual Loss: 0.2388\n",
      "Baseline Loss: 2.8071 | Actual Loss: 2.6611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 134/1000 [00:43<04:39,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8111 | Actual Loss: 0.9108\n",
      "Baseline Loss: 2.8869 | Actual Loss: 0.2732\n",
      "Baseline Loss: 2.8701 | Actual Loss: 0.3712\n",
      "Baseline Loss: 2.8650 | Actual Loss: 2.0523\n",
      "Baseline Loss: 2.7417 | Actual Loss: 1.8482\n",
      "Baseline Loss: 2.8592 | Actual Loss: 0.4903\n",
      "Baseline Loss: 2.4840 | Actual Loss: 0.0617\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4970\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.9255\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4800\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3243\n",
      "Epoch 134/1000: Train Loss: 0.8725, Val Loss: 0.8067\n",
      "Baseline Loss: 2.7857 | Actual Loss: 2.4324\n",
      "Baseline Loss: 2.7968 | Actual Loss: 0.2019\n",
      "Baseline Loss: 2.9128 | Actual Loss: 2.2962\n",
      "Baseline Loss: 2.7611 | Actual Loss: 0.4184\n",
      "Baseline Loss: 2.8413 | Actual Loss: 0.2482\n",
      "Baseline Loss: 2.7937 | Actual Loss: 0.7966\n",
      "Baseline Loss: 2.8399 | Actual Loss: 0.5505\n",
      "Baseline Loss: 2.8569 | Actual Loss: 0.0920\n",
      "Baseline Loss: 2.8025 | Actual Loss: 0.1787\n",
      "Baseline Loss: 2.8076 | Actual Loss: 0.6206\n",
      "Baseline Loss: 2.8021 | Actual Loss: 0.6281\n",
      "Baseline Loss: 2.7888 | Actual Loss: 0.4435\n",
      "Baseline Loss: 2.7865 | Actual Loss: 0.4418\n",
      "Baseline Loss: 2.8940 | Actual Loss: 0.4623\n",
      "Baseline Loss: 2.8617 | Actual Loss: 0.2102\n",
      "Baseline Loss: 2.6117 | Actual Loss: 2.0045\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5617\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8661\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.6113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▎        | 135/1000 [00:43<04:39,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7254 | Actual Loss: 0.4346\n",
      "Epoch 135/1000: Train Loss: 0.7516, Val Loss: 0.6184\n",
      "Baseline Loss: 2.8035 | Actual Loss: 0.4894\n",
      "Baseline Loss: 2.8502 | Actual Loss: 0.3279\n",
      "Baseline Loss: 2.8372 | Actual Loss: 0.3879\n",
      "Baseline Loss: 2.8087 | Actual Loss: 0.9063\n",
      "Baseline Loss: 2.9074 | Actual Loss: 0.2214\n",
      "Baseline Loss: 2.8651 | Actual Loss: 0.5858\n",
      "Baseline Loss: 2.9150 | Actual Loss: 0.0894\n",
      "Baseline Loss: 2.9295 | Actual Loss: 0.2294\n",
      "Baseline Loss: 2.8466 | Actual Loss: 1.2209\n",
      "Baseline Loss: 2.8026 | Actual Loss: 0.8519\n",
      "Baseline Loss: 2.8475 | Actual Loss: 0.3511\n",
      "Baseline Loss: 2.7335 | Actual Loss: 0.0916\n",
      "Baseline Loss: 2.7637 | Actual Loss: 0.3867\n",
      "Baseline Loss: 2.7693 | Actual Loss: 0.4029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▎        | 136/1000 [00:44<04:25,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8034 | Actual Loss: 0.5537\n",
      "Baseline Loss: 2.5809 | Actual Loss: 2.0525\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5975\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7901\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5148\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3582\n",
      "Epoch 136/1000: Train Loss: 0.5718, Val Loss: 0.5652\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.1493\n",
      "Baseline Loss: 2.8197 | Actual Loss: 0.4761\n",
      "Baseline Loss: 2.8079 | Actual Loss: 0.1994\n",
      "Baseline Loss: 2.8338 | Actual Loss: 2.1987\n",
      "Baseline Loss: 2.8849 | Actual Loss: 0.3638\n",
      "Baseline Loss: 2.8313 | Actual Loss: 1.6289\n",
      "Baseline Loss: 2.7920 | Actual Loss: 0.4066\n",
      "Baseline Loss: 2.8220 | Actual Loss: 0.6579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▎        | 137/1000 [00:44<04:30,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9214 | Actual Loss: 0.2558\n",
      "Baseline Loss: 2.7805 | Actual Loss: 1.1907\n",
      "Baseline Loss: 2.8232 | Actual Loss: 0.2182\n",
      "Baseline Loss: 2.8362 | Actual Loss: 2.4155\n",
      "Baseline Loss: 2.7858 | Actual Loss: 0.2203\n",
      "Baseline Loss: 2.7709 | Actual Loss: 0.4685\n",
      "Baseline Loss: 2.8081 | Actual Loss: 0.5239\n",
      "Baseline Loss: 2.5257 | Actual Loss: 0.1392\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.8130\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8193\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4923\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3466\n",
      "Epoch 137/1000: Train Loss: 0.7195, Val Loss: 0.6178\n",
      "Baseline Loss: 2.8489 | Actual Loss: 0.2402\n",
      "Baseline Loss: 2.8202 | Actual Loss: 0.3323\n",
      "Baseline Loss: 2.8861 | Actual Loss: 0.3703\n",
      "Baseline Loss: 2.8513 | Actual Loss: 0.3367\n",
      "Baseline Loss: 2.8462 | Actual Loss: 0.3529\n",
      "Baseline Loss: 2.7515 | Actual Loss: 0.3403\n",
      "Baseline Loss: 2.9277 | Actual Loss: 0.6910\n",
      "Baseline Loss: 2.8084 | Actual Loss: 0.4472\n",
      "Baseline Loss: 2.7212 | Actual Loss: 0.5903\n",
      "Baseline Loss: 2.7983 | Actual Loss: 0.2382\n",
      "Baseline Loss: 2.8419 | Actual Loss: 0.1330\n",
      "Baseline Loss: 2.8413 | Actual Loss: 0.8052\n",
      "Baseline Loss: 2.8422 | Actual Loss: 0.2532\n",
      "Baseline Loss: 2.8654 | Actual Loss: 2.8003\n",
      "Baseline Loss: 2.7751 | Actual Loss: 0.8013\n",
      "Baseline Loss: 2.4810 | Actual Loss: 2.1193\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.6016\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.8230\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 138/1000 [00:44<04:38,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7254 | Actual Loss: 0.2799\n",
      "Epoch 138/1000: Train Loss: 0.6782, Val Loss: 0.7926\n",
      "Baseline Loss: 2.8226 | Actual Loss: 0.2291\n",
      "Baseline Loss: 2.9195 | Actual Loss: 2.2207\n",
      "Baseline Loss: 2.8525 | Actual Loss: 0.5483\n",
      "Baseline Loss: 2.8103 | Actual Loss: 0.2652\n",
      "Baseline Loss: 2.7940 | Actual Loss: 0.3796\n",
      "Baseline Loss: 2.8163 | Actual Loss: 0.4431\n",
      "Baseline Loss: 2.8164 | Actual Loss: 0.2202\n",
      "Baseline Loss: 2.8254 | Actual Loss: 0.1659\n",
      "Baseline Loss: 2.8592 | Actual Loss: 0.6039\n",
      "Baseline Loss: 2.8086 | Actual Loss: 0.2295\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.1540\n",
      "Baseline Loss: 2.8279 | Actual Loss: 0.2910\n",
      "Baseline Loss: 2.7729 | Actual Loss: 0.4205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 139/1000 [00:45<04:27,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7630 | Actual Loss: 0.7145\n",
      "Baseline Loss: 2.8053 | Actual Loss: 0.4599\n",
      "Baseline Loss: 2.5797 | Actual Loss: 0.3025\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.8854\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7911\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.6046\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2601\n",
      "Epoch 139/1000: Train Loss: 0.4780, Val Loss: 0.6353\n",
      "Baseline Loss: 2.8350 | Actual Loss: 2.0746\n",
      "Baseline Loss: 2.7682 | Actual Loss: 0.2494\n",
      "Baseline Loss: 2.7656 | Actual Loss: 0.2528\n",
      "Baseline Loss: 2.8429 | Actual Loss: 0.3744\n",
      "Baseline Loss: 2.9118 | Actual Loss: 0.7105\n",
      "Baseline Loss: 2.7906 | Actual Loss: 0.3489\n",
      "Baseline Loss: 2.8741 | Actual Loss: 2.3027\n",
      "Baseline Loss: 2.8778 | Actual Loss: 0.2286\n",
      "Baseline Loss: 2.8148 | Actual Loss: 0.1183\n",
      "Baseline Loss: 2.8803 | Actual Loss: 0.2088\n",
      "Baseline Loss: 2.8300 | Actual Loss: 0.1283\n",
      "Baseline Loss: 2.8744 | Actual Loss: 0.3255\n",
      "Baseline Loss: 2.7966 | Actual Loss: 0.2866\n",
      "Baseline Loss: 2.8351 | Actual Loss: 0.2426\n",
      "Baseline Loss: 2.8368 | Actual Loss: 0.3843\n",
      "Baseline Loss: 2.5207 | Actual Loss: 0.1219\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5676\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8667\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 140/1000 [00:45<04:35,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7254 | Actual Loss: 0.1656\n",
      "Epoch 140/1000: Train Loss: 0.5224, Val Loss: 0.5223\n",
      "Baseline Loss: 2.8349 | Actual Loss: 0.3582\n",
      "Baseline Loss: 2.7721 | Actual Loss: 0.6608\n",
      "Baseline Loss: 2.8133 | Actual Loss: 0.3419\n",
      "Baseline Loss: 2.8230 | Actual Loss: 0.4000\n",
      "Baseline Loss: 2.7575 | Actual Loss: 0.2289\n",
      "Baseline Loss: 2.8323 | Actual Loss: 0.1340\n",
      "Baseline Loss: 2.8008 | Actual Loss: 0.9845\n",
      "Baseline Loss: 2.7383 | Actual Loss: 0.3285\n",
      "Baseline Loss: 2.8573 | Actual Loss: 0.4088\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.2470\n",
      "Baseline Loss: 2.8497 | Actual Loss: 0.1430\n",
      "Baseline Loss: 2.7824 | Actual Loss: 0.1749\n",
      "Baseline Loss: 2.9183 | Actual Loss: 0.2170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 141/1000 [00:45<04:24,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8041 | Actual Loss: 0.2211\n",
      "Baseline Loss: 2.8040 | Actual Loss: 0.5190\n",
      "Baseline Loss: 2.4484 | Actual Loss: 1.3029\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4321\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7254\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5085\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.1855\n",
      "Epoch 141/1000: Train Loss: 0.4169, Val Loss: 0.4629\n",
      "New best validation loss: 0.4629\n",
      "Baseline Loss: 2.8090 | Actual Loss: 0.2658\n",
      "Baseline Loss: 2.8741 | Actual Loss: 0.4984\n",
      "Baseline Loss: 2.7890 | Actual Loss: 0.4222\n",
      "Baseline Loss: 2.7975 | Actual Loss: 0.2280\n",
      "Baseline Loss: 2.8736 | Actual Loss: 0.6605\n",
      "Baseline Loss: 2.8288 | Actual Loss: 0.2161\n",
      "Baseline Loss: 2.8595 | Actual Loss: 0.3970\n",
      "Baseline Loss: 2.7583 | Actual Loss: 1.7222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 142/1000 [00:45<04:28,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7978 | Actual Loss: 0.2203\n",
      "Baseline Loss: 2.8788 | Actual Loss: 0.3831\n",
      "Baseline Loss: 2.8176 | Actual Loss: 0.1494\n",
      "Baseline Loss: 2.8257 | Actual Loss: 0.3749\n",
      "Baseline Loss: 2.8970 | Actual Loss: 0.2338\n",
      "Baseline Loss: 2.8165 | Actual Loss: 0.4577\n",
      "Baseline Loss: 2.7975 | Actual Loss: 0.3449\n",
      "Baseline Loss: 2.4636 | Actual Loss: 0.6538\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5114\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6806\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.6074\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3521\n",
      "Epoch 142/1000: Train Loss: 0.4518, Val Loss: 0.5379\n",
      "Baseline Loss: 2.7469 | Actual Loss: 0.4048\n",
      "Baseline Loss: 2.8645 | Actual Loss: 0.6055\n",
      "Baseline Loss: 2.7837 | Actual Loss: 0.4605\n",
      "Baseline Loss: 2.8159 | Actual Loss: 0.4248\n",
      "Baseline Loss: 2.8498 | Actual Loss: 2.2222\n",
      "Baseline Loss: 2.7902 | Actual Loss: 0.3539\n",
      "Baseline Loss: 2.8084 | Actual Loss: 0.3154\n",
      "Baseline Loss: 2.7819 | Actual Loss: 0.2211\n",
      "Baseline Loss: 2.8009 | Actual Loss: 2.2904\n",
      "Baseline Loss: 2.8698 | Actual Loss: 0.3515\n",
      "Baseline Loss: 2.8391 | Actual Loss: 0.5198\n",
      "Baseline Loss: 2.8599 | Actual Loss: 0.5054\n",
      "Baseline Loss: 2.8382 | Actual Loss: 2.3110\n",
      "Baseline Loss: 2.9363 | Actual Loss: 0.4737\n",
      "Baseline Loss: 2.7671 | Actual Loss: 0.2575\n",
      "Baseline Loss: 2.7087 | Actual Loss: 0.0625\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4045\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8565\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 143/1000 [00:46<04:14,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7254 | Actual Loss: 0.2429\n",
      "Epoch 143/1000: Train Loss: 0.7363, Val Loss: 0.5192\n",
      "Baseline Loss: 2.8263 | Actual Loss: 0.4449\n",
      "Baseline Loss: 2.7988 | Actual Loss: 0.1977\n",
      "Baseline Loss: 2.8189 | Actual Loss: 0.8234\n",
      "Baseline Loss: 2.8558 | Actual Loss: 0.2359\n",
      "Baseline Loss: 2.8361 | Actual Loss: 0.2727\n",
      "Baseline Loss: 2.7837 | Actual Loss: 0.6321\n",
      "Baseline Loss: 2.8100 | Actual Loss: 0.3637\n",
      "Baseline Loss: 2.8257 | Actual Loss: 0.2600\n",
      "Baseline Loss: 2.7800 | Actual Loss: 0.3767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 144/1000 [00:46<04:25,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8184 | Actual Loss: 0.3064\n",
      "Baseline Loss: 2.8905 | Actual Loss: 0.4792\n",
      "Baseline Loss: 2.8155 | Actual Loss: 0.2225\n",
      "Baseline Loss: 2.7720 | Actual Loss: 0.2835\n",
      "Baseline Loss: 2.7981 | Actual Loss: 0.6567\n",
      "Baseline Loss: 2.8006 | Actual Loss: 0.3698\n",
      "Baseline Loss: 2.5772 | Actual Loss: 0.3249\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5072\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7672\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5316\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.1869\n",
      "Epoch 144/1000: Train Loss: 0.3906, Val Loss: 0.4982\n",
      "Baseline Loss: 2.8475 | Actual Loss: 2.2811\n",
      "Baseline Loss: 2.7649 | Actual Loss: 0.1259\n",
      "Baseline Loss: 2.8183 | Actual Loss: 0.3776\n",
      "Baseline Loss: 2.8673 | Actual Loss: 0.5253\n",
      "Baseline Loss: 2.7903 | Actual Loss: 0.6048\n",
      "Baseline Loss: 2.8381 | Actual Loss: 0.9290\n",
      "Baseline Loss: 2.7999 | Actual Loss: 0.1563\n",
      "Baseline Loss: 2.7847 | Actual Loss: 1.1515\n",
      "Baseline Loss: 2.8013 | Actual Loss: 0.3327\n",
      "Baseline Loss: 2.8483 | Actual Loss: 0.4849\n",
      "Baseline Loss: 2.9055 | Actual Loss: 2.3874\n",
      "Baseline Loss: 2.8394 | Actual Loss: 0.0952\n",
      "Baseline Loss: 2.9298 | Actual Loss: 0.4841\n",
      "Baseline Loss: 2.7632 | Actual Loss: 0.1741\n",
      "Baseline Loss: 2.8746 | Actual Loss: 0.2314\n",
      "Baseline Loss: 2.4755 | Actual Loss: 0.0610\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4953\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.9126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 145/1000 [00:46<04:30,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7998 | Actual Loss: 0.4676\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3660\n",
      "Epoch 145/1000: Train Loss: 0.6501, Val Loss: 0.5604\n",
      "Baseline Loss: 2.8206 | Actual Loss: 0.6198\n",
      "Baseline Loss: 2.8864 | Actual Loss: 2.8413\n",
      "Baseline Loss: 2.8115 | Actual Loss: 1.1553\n",
      "Baseline Loss: 2.8586 | Actual Loss: 0.1234\n",
      "Baseline Loss: 2.8720 | Actual Loss: 0.0751\n",
      "Baseline Loss: 2.8025 | Actual Loss: 0.1114\n",
      "Baseline Loss: 2.8183 | Actual Loss: 0.2779\n",
      "Baseline Loss: 2.8129 | Actual Loss: 0.3655\n",
      "Baseline Loss: 2.8065 | Actual Loss: 0.2703\n",
      "Baseline Loss: 2.7881 | Actual Loss: 0.3118\n",
      "Baseline Loss: 2.8149 | Actual Loss: 0.3940\n",
      "Baseline Loss: 2.8006 | Actual Loss: 0.0828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 146/1000 [00:47<04:17,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8187 | Actual Loss: 1.9551\n",
      "Baseline Loss: 2.8354 | Actual Loss: 0.5355\n",
      "Baseline Loss: 2.8270 | Actual Loss: 0.4829\n",
      "Baseline Loss: 2.5680 | Actual Loss: 0.1048\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5001\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7021\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5352\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.1788\n",
      "Epoch 146/1000: Train Loss: 0.6067, Val Loss: 0.4791\n",
      "Baseline Loss: 2.9109 | Actual Loss: 2.2379\n",
      "Baseline Loss: 2.8449 | Actual Loss: 0.3790\n",
      "Baseline Loss: 2.8935 | Actual Loss: 0.5535\n",
      "Baseline Loss: 2.7919 | Actual Loss: 0.1116\n",
      "Baseline Loss: 2.8528 | Actual Loss: 0.1180\n",
      "Baseline Loss: 2.8802 | Actual Loss: 0.6544\n",
      "Baseline Loss: 2.7794 | Actual Loss: 0.4662\n",
      "Baseline Loss: 2.8336 | Actual Loss: 0.2116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 147/1000 [00:47<04:22,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8982 | Actual Loss: 0.2932\n",
      "Baseline Loss: 2.8423 | Actual Loss: 0.9378\n",
      "Baseline Loss: 2.7782 | Actual Loss: 0.2206\n",
      "Baseline Loss: 2.7909 | Actual Loss: 0.3215\n",
      "Baseline Loss: 2.7923 | Actual Loss: 0.2244\n",
      "Baseline Loss: 2.8676 | Actual Loss: 0.0860\n",
      "Baseline Loss: 2.8440 | Actual Loss: 0.2141\n",
      "Baseline Loss: 2.5806 | Actual Loss: 0.3205\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.3356\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8889\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5332\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.1783\n",
      "Epoch 147/1000: Train Loss: 0.4594, Val Loss: 0.4840\n",
      "Baseline Loss: 2.8270 | Actual Loss: 0.2468\n",
      "Baseline Loss: 2.7690 | Actual Loss: 1.7887\n",
      "Baseline Loss: 2.8489 | Actual Loss: 0.1791\n",
      "Baseline Loss: 2.8164 | Actual Loss: 0.2098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 148/1000 [00:47<04:07,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8179 | Actual Loss: 0.1951\n",
      "Baseline Loss: 2.8331 | Actual Loss: 0.3739\n",
      "Baseline Loss: 2.8006 | Actual Loss: 0.5698\n",
      "Baseline Loss: 2.8484 | Actual Loss: 0.5046\n",
      "Baseline Loss: 2.8177 | Actual Loss: 0.1821\n",
      "Baseline Loss: 2.8222 | Actual Loss: 0.8028\n",
      "Baseline Loss: 2.7991 | Actual Loss: 1.2998\n",
      "Baseline Loss: 2.8282 | Actual Loss: 0.5596\n",
      "Baseline Loss: 2.8168 | Actual Loss: 0.4932\n",
      "Baseline Loss: 2.8830 | Actual Loss: 0.1167\n",
      "Baseline Loss: 2.8224 | Actual Loss: 0.1287\n",
      "Baseline Loss: 2.5039 | Actual Loss: 0.2327\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.3617\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.1166\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5925\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3561\n",
      "Epoch 148/1000: Train Loss: 0.4927, Val Loss: 0.6067\n",
      "Baseline Loss: 2.9190 | Actual Loss: 0.3303\n",
      "Baseline Loss: 2.7787 | Actual Loss: 0.1860\n",
      "Baseline Loss: 2.8605 | Actual Loss: 0.4230\n",
      "Baseline Loss: 2.8276 | Actual Loss: 0.2537\n",
      "Baseline Loss: 2.9303 | Actual Loss: 0.2760\n",
      "Baseline Loss: 2.7858 | Actual Loss: 1.5314\n",
      "Baseline Loss: 2.8009 | Actual Loss: 0.2774\n",
      "Baseline Loss: 2.7911 | Actual Loss: 0.2244\n",
      "Baseline Loss: 2.7799 | Actual Loss: 0.3970\n",
      "Baseline Loss: 2.9106 | Actual Loss: 0.2077\n",
      "Baseline Loss: 2.8374 | Actual Loss: 0.2256\n",
      "Baseline Loss: 2.8327 | Actual Loss: 0.3232\n",
      "Baseline Loss: 2.7761 | Actual Loss: 0.2279\n",
      "Baseline Loss: 2.8101 | Actual Loss: 0.4541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 149/1000 [00:48<04:23,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8171 | Actual Loss: 0.5631\n",
      "Baseline Loss: 2.6022 | Actual Loss: 2.0657\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5048\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7576\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4493\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.1405\n",
      "Epoch 149/1000: Train Loss: 0.4979, Val Loss: 0.4630\n",
      "Baseline Loss: 2.7870 | Actual Loss: 0.3197\n",
      "Baseline Loss: 2.8555 | Actual Loss: 0.4044\n",
      "Baseline Loss: 2.7725 | Actual Loss: 0.2005\n",
      "Baseline Loss: 2.8899 | Actual Loss: 0.2792\n",
      "Baseline Loss: 2.9153 | Actual Loss: 0.4229\n",
      "Baseline Loss: 2.8151 | Actual Loss: 0.1958\n",
      "Baseline Loss: 2.8019 | Actual Loss: 0.5298\n",
      "Baseline Loss: 2.8307 | Actual Loss: 0.2187\n",
      "Baseline Loss: 2.8086 | Actual Loss: 0.4207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 150/1000 [00:48<04:28,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8823 | Actual Loss: 0.5060\n",
      "Baseline Loss: 2.8745 | Actual Loss: 0.5521\n",
      "Baseline Loss: 2.7902 | Actual Loss: 2.3057\n",
      "Baseline Loss: 2.8323 | Actual Loss: 2.2757\n",
      "Baseline Loss: 2.8239 | Actual Loss: 0.1921\n",
      "Baseline Loss: 2.8124 | Actual Loss: 0.3757\n",
      "Baseline Loss: 2.5227 | Actual Loss: 0.3242\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5080\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6952\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.6069\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.4416\n",
      "Epoch 150/1000: Train Loss: 0.5952, Val Loss: 0.5629\n",
      "Baseline Loss: 2.8426 | Actual Loss: 0.2261\n",
      "Baseline Loss: 2.8901 | Actual Loss: 0.2823\n",
      "Baseline Loss: 2.8229 | Actual Loss: 0.0780\n",
      "Baseline Loss: 2.7661 | Actual Loss: 0.1887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 151/1000 [00:48<04:15,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7871 | Actual Loss: 2.2187\n",
      "Baseline Loss: 2.8416 | Actual Loss: 0.2234\n",
      "Baseline Loss: 2.8511 | Actual Loss: 0.5933\n",
      "Baseline Loss: 2.8455 | Actual Loss: 0.6232\n",
      "Baseline Loss: 2.7966 | Actual Loss: 0.0650\n",
      "Baseline Loss: 2.7937 | Actual Loss: 0.2714\n",
      "Baseline Loss: 2.8580 | Actual Loss: 0.1658\n",
      "Baseline Loss: 2.8515 | Actual Loss: 2.1724\n",
      "Baseline Loss: 2.8875 | Actual Loss: 0.3763\n",
      "Baseline Loss: 2.8093 | Actual Loss: 0.2746\n",
      "Baseline Loss: 2.8295 | Actual Loss: 0.5280\n",
      "Baseline Loss: 2.5005 | Actual Loss: 0.0852\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5952\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7156\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5195\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3446\n",
      "Epoch 151/1000: Train Loss: 0.5233, Val Loss: 0.5437\n",
      "Baseline Loss: 2.8228 | Actual Loss: 0.4572\n",
      "Baseline Loss: 2.7982 | Actual Loss: 0.3180\n",
      "Baseline Loss: 2.8367 | Actual Loss: 0.4596\n",
      "Baseline Loss: 2.8164 | Actual Loss: 0.3194\n",
      "Baseline Loss: 2.8528 | Actual Loss: 0.2450\n",
      "Baseline Loss: 2.8531 | Actual Loss: 0.2117\n",
      "Baseline Loss: 2.7997 | Actual Loss: 0.2324\n",
      "Baseline Loss: 2.7826 | Actual Loss: 0.2270\n",
      "Baseline Loss: 2.8150 | Actual Loss: 0.2521\n",
      "Baseline Loss: 2.8350 | Actual Loss: 0.6490\n",
      "Baseline Loss: 2.7846 | Actual Loss: 0.1251\n",
      "Baseline Loss: 2.8279 | Actual Loss: 0.5878\n",
      "Baseline Loss: 2.8626 | Actual Loss: 0.1356\n",
      "Baseline Loss: 2.7846 | Actual Loss: 0.4709\n",
      "Baseline Loss: 2.7790 | Actual Loss: 0.3090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 152/1000 [00:49<04:26,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7029 | Actual Loss: 0.3067\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4387\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6891\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5563\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3750\n",
      "Epoch 152/1000: Train Loss: 0.3317, Val Loss: 0.5148\n",
      "Baseline Loss: 2.8512 | Actual Loss: 0.2446\n",
      "Baseline Loss: 2.8072 | Actual Loss: 1.3135\n",
      "Baseline Loss: 2.8026 | Actual Loss: 0.5402\n",
      "Baseline Loss: 2.8954 | Actual Loss: 0.1893\n",
      "Baseline Loss: 2.8413 | Actual Loss: 0.1568\n",
      "Baseline Loss: 2.7921 | Actual Loss: 2.2921\n",
      "Baseline Loss: 2.8886 | Actual Loss: 0.2446\n",
      "Baseline Loss: 2.7868 | Actual Loss: 0.4959\n",
      "Baseline Loss: 2.8249 | Actual Loss: 0.4926\n",
      "Baseline Loss: 2.8654 | Actual Loss: 0.8897\n",
      "Baseline Loss: 2.7643 | Actual Loss: 0.1990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 153/1000 [00:49<04:35,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7953 | Actual Loss: 0.3193\n",
      "Baseline Loss: 2.7893 | Actual Loss: 0.2804\n",
      "Baseline Loss: 2.7701 | Actual Loss: 0.3205\n",
      "Baseline Loss: 2.8563 | Actual Loss: 2.5528\n",
      "Baseline Loss: 2.5928 | Actual Loss: 0.2414\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4958\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8223\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.6164\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.1546\n",
      "Epoch 153/1000: Train Loss: 0.6733, Val Loss: 0.5222\n",
      "Baseline Loss: 2.7917 | Actual Loss: 1.3634\n",
      "Baseline Loss: 2.8494 | Actual Loss: 0.3008\n",
      "Baseline Loss: 2.8338 | Actual Loss: 0.3303\n",
      "Baseline Loss: 2.7799 | Actual Loss: 2.2936\n",
      "Baseline Loss: 2.8314 | Actual Loss: 0.1641\n",
      "Baseline Loss: 2.7927 | Actual Loss: 0.1518\n",
      "Baseline Loss: 2.8137 | Actual Loss: 0.1431\n",
      "Baseline Loss: 2.8449 | Actual Loss: 2.6730\n",
      "Baseline Loss: 2.8752 | Actual Loss: 2.4749\n",
      "Baseline Loss: 2.8333 | Actual Loss: 0.3823\n",
      "Baseline Loss: 2.8784 | Actual Loss: 0.3210\n",
      "Baseline Loss: 2.8026 | Actual Loss: 0.4480\n",
      "Baseline Loss: 2.8810 | Actual Loss: 0.2796\n",
      "Baseline Loss: 2.7942 | Actual Loss: 0.3447\n",
      "Baseline Loss: 2.8607 | Actual Loss: 0.4773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 154/1000 [00:49<04:21,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5886 | Actual Loss: 0.4389\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4861\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8420\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4965\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.1623\n",
      "Epoch 154/1000: Train Loss: 0.7867, Val Loss: 0.4967\n",
      "Baseline Loss: 2.8734 | Actual Loss: 0.3738\n",
      "Baseline Loss: 2.8318 | Actual Loss: 2.2315\n",
      "Baseline Loss: 2.8995 | Actual Loss: 0.2607\n",
      "Baseline Loss: 2.8101 | Actual Loss: 0.4158\n",
      "Baseline Loss: 2.7860 | Actual Loss: 0.1348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 155/1000 [00:49<04:33,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8264 | Actual Loss: 0.4420\n",
      "Baseline Loss: 2.7881 | Actual Loss: 0.5859\n",
      "Baseline Loss: 2.7771 | Actual Loss: 0.2353\n",
      "Baseline Loss: 2.8561 | Actual Loss: 0.5101\n",
      "Baseline Loss: 2.7774 | Actual Loss: 0.5356\n",
      "Baseline Loss: 2.8563 | Actual Loss: 2.1920\n",
      "Baseline Loss: 2.7727 | Actual Loss: 0.4358\n",
      "Baseline Loss: 2.8706 | Actual Loss: 0.3422\n",
      "Baseline Loss: 2.8382 | Actual Loss: 0.1726\n",
      "Baseline Loss: 2.8109 | Actual Loss: 0.2485\n",
      "Baseline Loss: 2.5129 | Actual Loss: 0.1258\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.6117\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7569\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5973\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.1815\n",
      "Epoch 155/1000: Train Loss: 0.5776, Val Loss: 0.5368\n",
      "Baseline Loss: 2.7398 | Actual Loss: 0.2129\n",
      "Baseline Loss: 2.8483 | Actual Loss: 0.2778\n",
      "Baseline Loss: 2.7539 | Actual Loss: 0.2378\n",
      "Baseline Loss: 2.8124 | Actual Loss: 0.2485\n",
      "Baseline Loss: 2.8601 | Actual Loss: 0.1301\n",
      "Baseline Loss: 2.8215 | Actual Loss: 0.4610\n",
      "Baseline Loss: 2.8918 | Actual Loss: 0.1872\n",
      "Baseline Loss: 2.7873 | Actual Loss: 0.5773\n",
      "Baseline Loss: 2.7710 | Actual Loss: 0.3852\n",
      "Baseline Loss: 2.8830 | Actual Loss: 0.6903\n",
      "Baseline Loss: 2.8062 | Actual Loss: 0.1957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 156/1000 [00:50<04:38,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8214 | Actual Loss: 0.9239\n",
      "Baseline Loss: 2.8803 | Actual Loss: 0.3015\n",
      "Baseline Loss: 2.7938 | Actual Loss: 0.7186\n",
      "Baseline Loss: 2.7837 | Actual Loss: 0.2521\n",
      "Baseline Loss: 2.5937 | Actual Loss: 0.0700\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5414\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7782\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5030\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.4783\n",
      "Epoch 156/1000: Train Loss: 0.3668, Val Loss: 0.5752\n",
      "Baseline Loss: 2.8893 | Actual Loss: 0.6687\n",
      "Baseline Loss: 2.8461 | Actual Loss: 0.2392\n",
      "Baseline Loss: 2.8785 | Actual Loss: 0.5672\n",
      "Baseline Loss: 2.7675 | Actual Loss: 0.4552\n",
      "Baseline Loss: 2.8342 | Actual Loss: 0.3164\n",
      "Baseline Loss: 2.8021 | Actual Loss: 0.1959\n",
      "Baseline Loss: 2.8034 | Actual Loss: 0.6903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 157/1000 [00:50<04:24,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8253 | Actual Loss: 0.2087\n",
      "Baseline Loss: 2.8498 | Actual Loss: 0.3789\n",
      "Baseline Loss: 2.8039 | Actual Loss: 0.2368\n",
      "Baseline Loss: 2.8528 | Actual Loss: 0.3350\n",
      "Baseline Loss: 2.8621 | Actual Loss: 0.3455\n",
      "Baseline Loss: 2.8072 | Actual Loss: 0.3939\n",
      "Baseline Loss: 2.8848 | Actual Loss: 0.9799\n",
      "Baseline Loss: 2.8044 | Actual Loss: 0.1269\n",
      "Baseline Loss: 2.3934 | Actual Loss: 0.2765\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4696\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7050\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5102\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2378\n",
      "Epoch 157/1000: Train Loss: 0.4009, Val Loss: 0.4807\n",
      "Baseline Loss: 2.7331 | Actual Loss: 0.2010\n",
      "Baseline Loss: 2.7639 | Actual Loss: 2.3868\n",
      "Baseline Loss: 2.8262 | Actual Loss: 0.0719\n",
      "Baseline Loss: 2.8026 | Actual Loss: 2.1985\n",
      "Baseline Loss: 2.9310 | Actual Loss: 0.2502\n",
      "Baseline Loss: 2.9052 | Actual Loss: 0.2180\n",
      "Baseline Loss: 2.8239 | Actual Loss: 0.6027\n",
      "Baseline Loss: 2.7652 | Actual Loss: 0.1126\n",
      "Baseline Loss: 2.8778 | Actual Loss: 0.2239\n",
      "Baseline Loss: 2.8793 | Actual Loss: 0.4823\n",
      "Baseline Loss: 2.8474 | Actual Loss: 0.5205\n",
      "Baseline Loss: 2.8574 | Actual Loss: 0.2280\n",
      "Baseline Loss: 2.7782 | Actual Loss: 0.2411\n",
      "Baseline Loss: 2.8031 | Actual Loss: 0.2589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 158/1000 [00:50<04:35,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8090 | Actual Loss: 0.1154\n",
      "Baseline Loss: 2.5574 | Actual Loss: 0.2388\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5368\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6846\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5104\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.4022\n",
      "Epoch 158/1000: Train Loss: 0.5219, Val Loss: 0.5335\n",
      "Baseline Loss: 2.8591 | Actual Loss: 0.1363\n",
      "Baseline Loss: 2.8601 | Actual Loss: 0.3678\n",
      "Baseline Loss: 2.7640 | Actual Loss: 0.3674\n",
      "Baseline Loss: 2.8380 | Actual Loss: 0.4364\n",
      "Baseline Loss: 2.7860 | Actual Loss: 0.1151\n",
      "Baseline Loss: 2.8549 | Actual Loss: 0.2044\n",
      "Baseline Loss: 2.8103 | Actual Loss: 2.2778\n",
      "Baseline Loss: 2.8425 | Actual Loss: 1.8861\n",
      "Baseline Loss: 2.8410 | Actual Loss: 0.3474\n",
      "Baseline Loss: 2.8718 | Actual Loss: 0.2143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 159/1000 [00:51<04:41,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8271 | Actual Loss: 0.2136\n",
      "Baseline Loss: 2.8384 | Actual Loss: 0.3254\n",
      "Baseline Loss: 2.8119 | Actual Loss: 0.1256\n",
      "Baseline Loss: 2.8381 | Actual Loss: 0.4450\n",
      "Baseline Loss: 2.9011 | Actual Loss: 0.3476\n",
      "Baseline Loss: 2.4801 | Actual Loss: 2.2048\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5175\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6713\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4874\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2678\n",
      "Epoch 159/1000: Train Loss: 0.6259, Val Loss: 0.4860\n",
      "Baseline Loss: 2.8165 | Actual Loss: 2.2842\n",
      "Baseline Loss: 2.8587 | Actual Loss: 0.3927\n",
      "Baseline Loss: 2.7946 | Actual Loss: 0.7077\n",
      "Baseline Loss: 2.7820 | Actual Loss: 2.4771\n",
      "Baseline Loss: 2.8229 | Actual Loss: 0.5051\n",
      "Baseline Loss: 2.8119 | Actual Loss: 0.1899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 160/1000 [00:51<04:25,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7754 | Actual Loss: 0.1212\n",
      "Baseline Loss: 2.7905 | Actual Loss: 0.4596\n",
      "Baseline Loss: 2.8710 | Actual Loss: 0.2583\n",
      "Baseline Loss: 2.8426 | Actual Loss: 0.4603\n",
      "Baseline Loss: 2.7898 | Actual Loss: 0.0736\n",
      "Baseline Loss: 2.9297 | Actual Loss: 0.2214\n",
      "Baseline Loss: 2.8375 | Actual Loss: 0.3480\n",
      "Baseline Loss: 2.8584 | Actual Loss: 0.1162\n",
      "Baseline Loss: 2.8705 | Actual Loss: 0.2394\n",
      "Baseline Loss: 2.4693 | Actual Loss: 0.3226\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4834\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6229\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5812\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.1630\n",
      "Epoch 160/1000: Train Loss: 0.5736, Val Loss: 0.4626\n",
      "New best validation loss: 0.4626\n",
      "Baseline Loss: 2.8307 | Actual Loss: 0.2889\n",
      "Baseline Loss: 2.7923 | Actual Loss: 0.8111\n",
      "Baseline Loss: 2.9367 | Actual Loss: 0.2125\n",
      "Baseline Loss: 2.8116 | Actual Loss: 0.1285\n",
      "Baseline Loss: 2.8051 | Actual Loss: 0.4057\n",
      "Baseline Loss: 2.7618 | Actual Loss: 0.5405\n",
      "Baseline Loss: 2.8642 | Actual Loss: 0.5635\n",
      "Baseline Loss: 2.8721 | Actual Loss: 2.1670\n",
      "Baseline Loss: 2.8203 | Actual Loss: 2.2715\n",
      "Baseline Loss: 2.8364 | Actual Loss: 0.2337\n",
      "Baseline Loss: 2.8034 | Actual Loss: 0.2767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 161/1000 [00:51<04:33,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7592 | Actual Loss: 1.3100\n",
      "Baseline Loss: 2.8218 | Actual Loss: 0.2704\n",
      "Baseline Loss: 2.8052 | Actual Loss: 0.2661\n",
      "Baseline Loss: 2.8292 | Actual Loss: 0.3696\n",
      "Baseline Loss: 2.4639 | Actual Loss: 0.2210\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5280\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6984\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5465\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.1289\n",
      "Epoch 161/1000: Train Loss: 0.6460, Val Loss: 0.4755\n",
      "Baseline Loss: 2.8396 | Actual Loss: 0.5110\n",
      "Baseline Loss: 2.8393 | Actual Loss: 0.1952\n",
      "Baseline Loss: 2.8581 | Actual Loss: 0.5173\n",
      "Baseline Loss: 2.7783 | Actual Loss: 0.2690\n",
      "Baseline Loss: 2.7490 | Actual Loss: 0.4972\n",
      "Baseline Loss: 2.8666 | Actual Loss: 0.1738\n",
      "Baseline Loss: 2.7981 | Actual Loss: 0.1992\n",
      "Baseline Loss: 2.8233 | Actual Loss: 0.7732\n",
      "Baseline Loss: 2.8644 | Actual Loss: 0.2201\n",
      "Baseline Loss: 2.8751 | Actual Loss: 0.5506\n",
      "Baseline Loss: 2.8541 | Actual Loss: 0.5498\n",
      "Baseline Loss: 2.8023 | Actual Loss: 0.3086\n",
      "Baseline Loss: 2.7781 | Actual Loss: 0.5834\n",
      "Baseline Loss: 2.8077 | Actual Loss: 0.0830\n",
      "Baseline Loss: 2.8245 | Actual Loss: 0.2820\n",
      "Baseline Loss: 2.5619 | Actual Loss: 0.4052\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 162/1000 [00:52<04:40,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8180 | Actual Loss: 0.6713\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4727\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2796\n",
      "Epoch 162/1000: Train Loss: 0.3824, Val Loss: 0.4816\n",
      "Baseline Loss: 2.8650 | Actual Loss: 0.4557\n",
      "Baseline Loss: 2.8707 | Actual Loss: 0.3620\n",
      "Baseline Loss: 2.8503 | Actual Loss: 1.0798\n",
      "Baseline Loss: 2.7728 | Actual Loss: 0.2791\n",
      "Baseline Loss: 2.8068 | Actual Loss: 0.1255\n",
      "Baseline Loss: 2.8705 | Actual Loss: 0.1925\n",
      "Baseline Loss: 2.8336 | Actual Loss: 0.1040\n",
      "Baseline Loss: 2.7649 | Actual Loss: 0.1863\n",
      "Baseline Loss: 2.8649 | Actual Loss: 2.3080\n",
      "Baseline Loss: 2.8143 | Actual Loss: 0.1146\n",
      "Baseline Loss: 2.8182 | Actual Loss: 0.1254\n",
      "Baseline Loss: 2.8174 | Actual Loss: 1.1233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▋        | 163/1000 [00:52<04:24,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8404 | Actual Loss: 0.2437\n",
      "Baseline Loss: 2.8159 | Actual Loss: 0.2062\n",
      "Baseline Loss: 2.8275 | Actual Loss: 0.2301\n",
      "Baseline Loss: 2.4873 | Actual Loss: 0.2522\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.6047\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6050\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4635\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.1595\n",
      "Epoch 163/1000: Train Loss: 0.4618, Val Loss: 0.4582\n",
      "New best validation loss: 0.4582\n",
      "Baseline Loss: 2.8693 | Actual Loss: 0.3813\n",
      "Baseline Loss: 2.7936 | Actual Loss: 0.1327\n",
      "Baseline Loss: 2.8206 | Actual Loss: 0.6454\n",
      "Baseline Loss: 2.7724 | Actual Loss: 0.1199\n",
      "Baseline Loss: 2.8367 | Actual Loss: 0.1190\n",
      "Baseline Loss: 2.8214 | Actual Loss: 0.1947\n",
      "Baseline Loss: 2.8352 | Actual Loss: 0.6968\n",
      "Baseline Loss: 2.9318 | Actual Loss: 0.2986\n",
      "Baseline Loss: 2.7778 | Actual Loss: 0.2461\n",
      "Baseline Loss: 2.8838 | Actual Loss: 0.2381\n",
      "Baseline Loss: 2.8231 | Actual Loss: 0.3084\n",
      "Baseline Loss: 2.8344 | Actual Loss: 0.3494\n",
      "Baseline Loss: 2.8764 | Actual Loss: 1.5873\n",
      "Baseline Loss: 2.7557 | Actual Loss: 0.2180\n",
      "Baseline Loss: 2.8248 | Actual Loss: 2.9417\n",
      "Baseline Loss: 2.4944 | Actual Loss: 0.2095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▋        | 164/1000 [00:52<04:31,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8199 | Actual Loss: 0.4920\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8299\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5213\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.1629\n",
      "Epoch 164/1000: Train Loss: 0.5429, Val Loss: 0.5015\n",
      "Baseline Loss: 2.8413 | Actual Loss: 0.3815\n",
      "Baseline Loss: 2.8791 | Actual Loss: 0.1197\n",
      "Baseline Loss: 2.7731 | Actual Loss: 0.0942\n",
      "Baseline Loss: 2.8271 | Actual Loss: 0.6316\n",
      "Baseline Loss: 2.7706 | Actual Loss: 0.9794\n",
      "Baseline Loss: 2.8472 | Actual Loss: 0.3082\n",
      "Baseline Loss: 2.8512 | Actual Loss: 0.2360\n",
      "Baseline Loss: 2.8423 | Actual Loss: 0.3736\n",
      "Baseline Loss: 2.8135 | Actual Loss: 0.1842\n",
      "Baseline Loss: 2.7750 | Actual Loss: 0.8154\n",
      "Baseline Loss: 2.8082 | Actual Loss: 0.7320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▋        | 165/1000 [00:53<04:37,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8460 | Actual Loss: 0.4765\n",
      "Baseline Loss: 2.8184 | Actual Loss: 0.2880\n",
      "Baseline Loss: 2.8392 | Actual Loss: 0.2093\n",
      "Baseline Loss: 2.7289 | Actual Loss: 0.2193\n",
      "Baseline Loss: 2.7316 | Actual Loss: 1.7866\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.7223\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6996\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5012\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.4007\n",
      "Epoch 165/1000: Train Loss: 0.4897, Val Loss: 0.5809\n",
      "Baseline Loss: 2.7572 | Actual Loss: 0.3187\n",
      "Baseline Loss: 2.8533 | Actual Loss: 0.1179\n",
      "Baseline Loss: 2.8253 | Actual Loss: 0.2252\n",
      "Baseline Loss: 2.8040 | Actual Loss: 0.1108\n",
      "Baseline Loss: 2.9048 | Actual Loss: 0.3919\n",
      "Baseline Loss: 2.8338 | Actual Loss: 0.1940\n",
      "Baseline Loss: 2.8726 | Actual Loss: 0.7533\n",
      "Baseline Loss: 2.7918 | Actual Loss: 1.7495\n",
      "Baseline Loss: 2.8539 | Actual Loss: 0.5597\n",
      "Baseline Loss: 2.8512 | Actual Loss: 1.9005\n",
      "Baseline Loss: 2.7663 | Actual Loss: 0.1553\n",
      "Baseline Loss: 2.8135 | Actual Loss: 0.2000\n",
      "Baseline Loss: 2.8993 | Actual Loss: 0.1238\n",
      "Baseline Loss: 2.7650 | Actual Loss: 0.3569\n",
      "Baseline Loss: 2.7822 | Actual Loss: 0.3165\n",
      "Baseline Loss: 2.4758 | Actual Loss: 2.2017\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.6571\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 166/1000 [00:53<04:17,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7998 | Actual Loss: 0.4880\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2812\n",
      "Epoch 166/1000: Train Loss: 0.6047, Val Loss: 0.5576\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.4018\n",
      "Baseline Loss: 2.7984 | Actual Loss: 0.2689\n",
      "Baseline Loss: 2.8165 | Actual Loss: 0.4820\n",
      "Baseline Loss: 2.8741 | Actual Loss: 2.4474\n",
      "Baseline Loss: 2.7797 | Actual Loss: 2.2434\n",
      "Baseline Loss: 2.8591 | Actual Loss: 0.4669\n",
      "Baseline Loss: 2.8209 | Actual Loss: 0.2882\n",
      "Baseline Loss: 2.7835 | Actual Loss: 0.1252\n",
      "Baseline Loss: 2.8241 | Actual Loss: 0.3817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 167/1000 [00:53<04:21,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8450 | Actual Loss: 0.2576\n",
      "Baseline Loss: 2.8542 | Actual Loss: 0.6708\n",
      "Baseline Loss: 2.8117 | Actual Loss: 0.3647\n",
      "Baseline Loss: 2.8114 | Actual Loss: 0.2221\n",
      "Baseline Loss: 2.8144 | Actual Loss: 0.2182\n",
      "Baseline Loss: 2.8852 | Actual Loss: 0.3454\n",
      "Baseline Loss: 2.4876 | Actual Loss: 0.2118\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4725\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6068\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.6138\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.1918\n",
      "Epoch 167/1000: Train Loss: 0.5872, Val Loss: 0.4712\n",
      "Baseline Loss: 2.8575 | Actual Loss: 0.1457\n",
      "Baseline Loss: 2.8609 | Actual Loss: 0.1270\n",
      "Baseline Loss: 2.7212 | Actual Loss: 2.0794\n",
      "Baseline Loss: 2.7816 | Actual Loss: 0.1869\n",
      "Baseline Loss: 2.7921 | Actual Loss: 0.1501\n",
      "Baseline Loss: 2.8510 | Actual Loss: 0.3237\n",
      "Baseline Loss: 2.8160 | Actual Loss: 0.2275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 168/1000 [00:54<04:11,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9249 | Actual Loss: 0.1203\n",
      "Baseline Loss: 2.8784 | Actual Loss: 2.3464\n",
      "Baseline Loss: 2.8064 | Actual Loss: 0.1363\n",
      "Baseline Loss: 2.8398 | Actual Loss: 0.4479\n",
      "Baseline Loss: 2.7404 | Actual Loss: 0.2847\n",
      "Baseline Loss: 2.7903 | Actual Loss: 2.2072\n",
      "Baseline Loss: 2.7725 | Actual Loss: 0.4664\n",
      "Baseline Loss: 2.7910 | Actual Loss: 2.9262\n",
      "Baseline Loss: 2.6778 | Actual Loss: 0.1712\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5480\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7299\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4854\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.1553\n",
      "Epoch 168/1000: Train Loss: 0.7717, Val Loss: 0.4797\n",
      "Baseline Loss: 2.8375 | Actual Loss: 0.7227\n",
      "Baseline Loss: 2.8182 | Actual Loss: 0.0729\n",
      "Baseline Loss: 2.8399 | Actual Loss: 0.5289\n",
      "Baseline Loss: 2.8148 | Actual Loss: 0.2151\n",
      "Baseline Loss: 2.8370 | Actual Loss: 0.2019\n",
      "Baseline Loss: 2.7832 | Actual Loss: 2.3902\n",
      "Baseline Loss: 2.7952 | Actual Loss: 0.2330\n",
      "Baseline Loss: 2.7562 | Actual Loss: 0.6199\n",
      "Baseline Loss: 2.7988 | Actual Loss: 0.2180\n",
      "Baseline Loss: 2.8486 | Actual Loss: 0.2825\n",
      "Baseline Loss: 2.8602 | Actual Loss: 0.3175\n",
      "Baseline Loss: 2.8855 | Actual Loss: 0.0721\n",
      "Baseline Loss: 2.7862 | Actual Loss: 0.1106\n",
      "Baseline Loss: 2.7762 | Actual Loss: 0.2520\n",
      "Baseline Loss: 2.8225 | Actual Loss: 0.8055\n",
      "Baseline Loss: 2.5880 | Actual Loss: 0.6357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 169/1000 [00:54<04:17,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8199 | Actual Loss: 0.4857\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7174\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5029\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2700\n",
      "Epoch 169/1000: Train Loss: 0.4799, Val Loss: 0.4940\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.1941\n",
      "Baseline Loss: 2.8241 | Actual Loss: 0.5266\n",
      "Baseline Loss: 2.8918 | Actual Loss: 0.2559\n",
      "Baseline Loss: 2.8121 | Actual Loss: 0.1695\n",
      "Baseline Loss: 2.8305 | Actual Loss: 2.0757\n",
      "Baseline Loss: 2.7605 | Actual Loss: 0.3342\n",
      "Baseline Loss: 2.7803 | Actual Loss: 0.2805\n",
      "Baseline Loss: 2.7732 | Actual Loss: 0.2679\n",
      "Baseline Loss: 2.7676 | Actual Loss: 0.3992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 170/1000 [00:54<04:22,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8300 | Actual Loss: 0.5820\n",
      "Baseline Loss: 2.7875 | Actual Loss: 0.3224\n",
      "Baseline Loss: 2.8211 | Actual Loss: 0.2890\n",
      "Baseline Loss: 2.7778 | Actual Loss: 0.5456\n",
      "Baseline Loss: 2.8468 | Actual Loss: 0.1807\n",
      "Baseline Loss: 2.8012 | Actual Loss: 2.1167\n",
      "Baseline Loss: 2.5165 | Actual Loss: 0.0636\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5042\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8335\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5391\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.1684\n",
      "Epoch 170/1000: Train Loss: 0.5377, Val Loss: 0.5113\n",
      "Baseline Loss: 2.8120 | Actual Loss: 0.1307\n",
      "Baseline Loss: 2.8133 | Actual Loss: 0.1774\n",
      "Baseline Loss: 2.8146 | Actual Loss: 0.3843\n",
      "Baseline Loss: 2.8007 | Actual Loss: 1.1134\n",
      "Baseline Loss: 2.8632 | Actual Loss: 2.2893\n",
      "Baseline Loss: 2.7737 | Actual Loss: 2.3711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 171/1000 [00:55<04:12,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7474 | Actual Loss: 0.3134\n",
      "Baseline Loss: 2.8326 | Actual Loss: 0.2385\n",
      "Baseline Loss: 2.8497 | Actual Loss: 0.2649\n",
      "Baseline Loss: 2.8626 | Actual Loss: 0.2115\n",
      "Baseline Loss: 2.8592 | Actual Loss: 0.0804\n",
      "Baseline Loss: 2.7762 | Actual Loss: 0.5039\n",
      "Baseline Loss: 2.8602 | Actual Loss: 0.3918\n",
      "Baseline Loss: 2.8629 | Actual Loss: 0.2523\n",
      "Baseline Loss: 2.8429 | Actual Loss: 0.4843\n",
      "Baseline Loss: 2.5312 | Actual Loss: 0.2044\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5083\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8584\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4993\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3296\n",
      "Epoch 171/1000: Train Loss: 0.5882, Val Loss: 0.5489\n",
      "Baseline Loss: 2.8657 | Actual Loss: 0.2330\n",
      "Baseline Loss: 2.8947 | Actual Loss: 0.2208\n",
      "Baseline Loss: 2.8862 | Actual Loss: 0.1971\n",
      "Baseline Loss: 2.8959 | Actual Loss: 0.1346\n",
      "Baseline Loss: 2.8005 | Actual Loss: 0.2178\n",
      "Baseline Loss: 2.7888 | Actual Loss: 0.3900\n",
      "Baseline Loss: 2.8374 | Actual Loss: 0.6764\n",
      "Baseline Loss: 2.7713 | Actual Loss: 0.8331\n",
      "Baseline Loss: 2.7480 | Actual Loss: 0.5364\n",
      "Baseline Loss: 2.8131 | Actual Loss: 0.3237\n",
      "Baseline Loss: 2.7929 | Actual Loss: 0.3411\n",
      "Baseline Loss: 2.8148 | Actual Loss: 0.3932\n",
      "Baseline Loss: 2.8778 | Actual Loss: 0.2266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 172/1000 [00:55<04:16,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8156 | Actual Loss: 0.4463\n",
      "Baseline Loss: 2.8319 | Actual Loss: 0.2961\n",
      "Baseline Loss: 2.5918 | Actual Loss: 0.0915\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5127\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8866\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5488\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2940\n",
      "Epoch 172/1000: Train Loss: 0.3474, Val Loss: 0.5605\n",
      "Baseline Loss: 2.8216 | Actual Loss: 0.6252\n",
      "Baseline Loss: 2.7966 | Actual Loss: 0.2476\n",
      "Baseline Loss: 2.8243 | Actual Loss: 0.1636\n",
      "Baseline Loss: 2.8069 | Actual Loss: 0.2197\n",
      "Baseline Loss: 2.7966 | Actual Loss: 0.4238\n",
      "Baseline Loss: 2.8157 | Actual Loss: 0.3484\n",
      "Baseline Loss: 2.9168 | Actual Loss: 0.1829\n",
      "Baseline Loss: 2.9013 | Actual Loss: 0.2349\n",
      "Baseline Loss: 2.8088 | Actual Loss: 0.3693\n",
      "Baseline Loss: 2.8201 | Actual Loss: 0.1516\n",
      "Baseline Loss: 2.8269 | Actual Loss: 2.6120\n",
      "Baseline Loss: 2.8289 | Actual Loss: 1.3089\n",
      "Baseline Loss: 2.7829 | Actual Loss: 0.3309\n",
      "Baseline Loss: 2.7834 | Actual Loss: 0.2094\n",
      "Baseline Loss: 2.7627 | Actual Loss: 0.3009\n",
      "Baseline Loss: 2.6156 | Actual Loss: 2.3810\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.7622\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7790\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 173/1000 [00:55<04:26,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7254 | Actual Loss: 0.3822\n",
      "Epoch 173/1000: Train Loss: 0.6319, Val Loss: 0.6030\n",
      "Baseline Loss: 2.8243 | Actual Loss: 0.2524\n",
      "Baseline Loss: 2.7394 | Actual Loss: 0.4893\n",
      "Baseline Loss: 2.8036 | Actual Loss: 0.2183\n",
      "Baseline Loss: 2.8604 | Actual Loss: 0.3682\n",
      "Baseline Loss: 2.8040 | Actual Loss: 0.3505\n",
      "Baseline Loss: 2.7562 | Actual Loss: 0.3314\n",
      "Baseline Loss: 2.8158 | Actual Loss: 0.2075\n",
      "Baseline Loss: 2.7514 | Actual Loss: 1.0685\n",
      "Baseline Loss: 2.9625 | Actual Loss: 0.2457\n",
      "Baseline Loss: 2.8457 | Actual Loss: 0.6682\n",
      "Baseline Loss: 2.8102 | Actual Loss: 0.4063\n",
      "Baseline Loss: 2.8208 | Actual Loss: 0.3403\n",
      "Baseline Loss: 2.8761 | Actual Loss: 0.2239\n",
      "Baseline Loss: 2.7899 | Actual Loss: 0.4609\n",
      "Baseline Loss: 2.8009 | Actual Loss: 0.1960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 174/1000 [00:55<04:08,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5751 | Actual Loss: 0.0963\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5053\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6767\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5689\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.1888\n",
      "Epoch 174/1000: Train Loss: 0.3702, Val Loss: 0.4849\n",
      "Baseline Loss: 2.8342 | Actual Loss: 0.6944\n",
      "Baseline Loss: 2.8904 | Actual Loss: 0.2974\n",
      "Baseline Loss: 2.8269 | Actual Loss: 0.2199\n",
      "Baseline Loss: 2.8052 | Actual Loss: 0.6051\n",
      "Baseline Loss: 2.8041 | Actual Loss: 0.4203\n",
      "Baseline Loss: 2.8519 | Actual Loss: 0.5487\n",
      "Baseline Loss: 2.7840 | Actual Loss: 0.4133\n",
      "Baseline Loss: 2.8581 | Actual Loss: 0.1809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 175/1000 [00:56<04:16,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7751 | Actual Loss: 0.3819\n",
      "Baseline Loss: 2.7746 | Actual Loss: 0.2679\n",
      "Baseline Loss: 2.7832 | Actual Loss: 0.2523\n",
      "Baseline Loss: 2.8205 | Actual Loss: 0.2157\n",
      "Baseline Loss: 2.7916 | Actual Loss: 0.2643\n",
      "Baseline Loss: 2.8143 | Actual Loss: 0.2931\n",
      "Baseline Loss: 2.9444 | Actual Loss: 0.1163\n",
      "Baseline Loss: 2.4873 | Actual Loss: 2.3592\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5153\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6780\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4405\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2518\n",
      "Epoch 175/1000: Train Loss: 0.4707, Val Loss: 0.4714\n",
      "Baseline Loss: 2.8169 | Actual Loss: 0.2750\n",
      "Baseline Loss: 2.7782 | Actual Loss: 0.3293\n",
      "Baseline Loss: 2.8423 | Actual Loss: 0.2192\n",
      "Baseline Loss: 2.8179 | Actual Loss: 0.5397\n",
      "Baseline Loss: 2.8035 | Actual Loss: 0.0659\n",
      "Baseline Loss: 2.8506 | Actual Loss: 0.1985\n",
      "Baseline Loss: 2.8169 | Actual Loss: 0.2325\n",
      "Baseline Loss: 2.8215 | Actual Loss: 0.6543\n",
      "Baseline Loss: 2.9212 | Actual Loss: 0.1233\n",
      "Baseline Loss: 2.7678 | Actual Loss: 0.5269\n",
      "Baseline Loss: 2.8607 | Actual Loss: 0.1863\n",
      "Baseline Loss: 2.8806 | Actual Loss: 2.1800\n",
      "Baseline Loss: 2.8455 | Actual Loss: 0.5208\n",
      "Baseline Loss: 2.7664 | Actual Loss: 0.4065\n",
      "Baseline Loss: 2.8364 | Actual Loss: 0.5039\n",
      "Baseline Loss: 2.4027 | Actual Loss: 0.0968\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4642\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8380\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 176/1000 [00:56<04:26,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7254 | Actual Loss: 0.2214\n",
      "Epoch 176/1000: Train Loss: 0.4412, Val Loss: 0.5135\n",
      "Baseline Loss: 2.7372 | Actual Loss: 0.1475\n",
      "Baseline Loss: 2.9303 | Actual Loss: 0.1202\n",
      "Baseline Loss: 2.8435 | Actual Loss: 0.3536\n",
      "Baseline Loss: 2.7719 | Actual Loss: 2.4174\n",
      "Baseline Loss: 2.8102 | Actual Loss: 0.1615\n",
      "Baseline Loss: 2.8637 | Actual Loss: 0.1465\n",
      "Baseline Loss: 2.9319 | Actual Loss: 0.9705\n",
      "Baseline Loss: 2.7702 | Actual Loss: 0.2827\n",
      "Baseline Loss: 2.8434 | Actual Loss: 2.0977\n",
      "Baseline Loss: 2.8994 | Actual Loss: 2.6615\n",
      "Baseline Loss: 2.8089 | Actual Loss: 0.5477\n",
      "Baseline Loss: 2.8546 | Actual Loss: 1.2752\n",
      "Baseline Loss: 2.7818 | Actual Loss: 0.1625\n",
      "Baseline Loss: 2.8563 | Actual Loss: 1.0401\n",
      "Baseline Loss: 2.8460 | Actual Loss: 0.2955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 177/1000 [00:56<04:08,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.4974 | Actual Loss: 0.0510\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5256\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7393\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5235\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3298\n",
      "Epoch 177/1000: Train Loss: 0.7957, Val Loss: 0.5295\n",
      "Baseline Loss: 2.7638 | Actual Loss: 0.2002\n",
      "Baseline Loss: 2.8495 | Actual Loss: 0.4534\n",
      "Baseline Loss: 2.8067 | Actual Loss: 0.1964\n",
      "Baseline Loss: 2.8580 | Actual Loss: 0.1258\n",
      "Baseline Loss: 2.8327 | Actual Loss: 0.5011\n",
      "Baseline Loss: 2.8333 | Actual Loss: 0.1044\n",
      "Baseline Loss: 2.8213 | Actual Loss: 0.5010\n",
      "Baseline Loss: 2.8081 | Actual Loss: 1.4115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 178/1000 [00:57<04:13,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8426 | Actual Loss: 2.3202\n",
      "Baseline Loss: 2.8300 | Actual Loss: 0.5671\n",
      "Baseline Loss: 2.8483 | Actual Loss: 0.5237\n",
      "Baseline Loss: 2.7810 | Actual Loss: 0.2020\n",
      "Baseline Loss: 2.8840 | Actual Loss: 0.7551\n",
      "Baseline Loss: 2.8179 | Actual Loss: 0.2460\n",
      "Baseline Loss: 2.8289 | Actual Loss: 1.9259\n",
      "Baseline Loss: 2.4795 | Actual Loss: 0.2345\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5231\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6595\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4355\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2544\n",
      "Epoch 178/1000: Train Loss: 0.6418, Val Loss: 0.4681\n",
      "Baseline Loss: 2.8261 | Actual Loss: 0.3113\n",
      "Baseline Loss: 2.7169 | Actual Loss: 0.6552\n",
      "Baseline Loss: 2.8370 | Actual Loss: 0.2486\n",
      "Baseline Loss: 2.8108 | Actual Loss: 0.2255\n",
      "Baseline Loss: 2.7725 | Actual Loss: 0.5601\n",
      "Baseline Loss: 2.8255 | Actual Loss: 0.1413\n",
      "Baseline Loss: 2.8059 | Actual Loss: 1.9546\n",
      "Baseline Loss: 2.8189 | Actual Loss: 0.7067\n",
      "Baseline Loss: 2.8053 | Actual Loss: 0.6048\n",
      "Baseline Loss: 2.8782 | Actual Loss: 0.2313\n",
      "Baseline Loss: 2.8183 | Actual Loss: 0.3957\n",
      "Baseline Loss: 2.9159 | Actual Loss: 0.2506\n",
      "Baseline Loss: 2.8178 | Actual Loss: 0.1321\n",
      "Baseline Loss: 2.7384 | Actual Loss: 0.1855\n",
      "Baseline Loss: 2.8900 | Actual Loss: 0.2145\n",
      "Baseline Loss: 2.6713 | Actual Loss: 0.2554\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.7488\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 179/1000 [00:57<04:24,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7998 | Actual Loss: 0.4363\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3641\n",
      "Epoch 179/1000: Train Loss: 0.4421, Val Loss: 0.5694\n",
      "Baseline Loss: 2.8250 | Actual Loss: 0.2922\n",
      "Baseline Loss: 2.8684 | Actual Loss: 2.2515\n",
      "Baseline Loss: 2.8349 | Actual Loss: 0.4531\n",
      "Baseline Loss: 2.7817 | Actual Loss: 0.3456\n",
      "Baseline Loss: 2.8054 | Actual Loss: 1.6913\n",
      "Baseline Loss: 2.7695 | Actual Loss: 0.1156\n",
      "Baseline Loss: 2.8085 | Actual Loss: 0.2574\n",
      "Baseline Loss: 2.8728 | Actual Loss: 0.1646\n",
      "Baseline Loss: 2.7889 | Actual Loss: 0.0920\n",
      "Baseline Loss: 2.7693 | Actual Loss: 0.2736\n",
      "Baseline Loss: 2.7990 | Actual Loss: 1.0083\n",
      "Baseline Loss: 2.8618 | Actual Loss: 0.3007\n",
      "Baseline Loss: 2.8551 | Actual Loss: 0.5063\n",
      "Baseline Loss: 2.8315 | Actual Loss: 0.1744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 180/1000 [00:57<04:07,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8046 | Actual Loss: 0.2361\n",
      "Baseline Loss: 2.4928 | Actual Loss: 0.0416\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5365\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6322\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5537\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.4210\n",
      "Epoch 180/1000: Train Loss: 0.5128, Val Loss: 0.5358\n",
      "Baseline Loss: 2.7210 | Actual Loss: 0.2012\n",
      "Baseline Loss: 2.8122 | Actual Loss: 0.2142\n",
      "Baseline Loss: 2.9302 | Actual Loss: 2.1652\n",
      "Baseline Loss: 2.8446 | Actual Loss: 0.2581\n",
      "Baseline Loss: 2.8222 | Actual Loss: 1.1412\n",
      "Baseline Loss: 2.8058 | Actual Loss: 0.4871\n",
      "Baseline Loss: 2.7740 | Actual Loss: 0.1404\n",
      "Baseline Loss: 2.7786 | Actual Loss: 0.1830\n",
      "Baseline Loss: 2.8194 | Actual Loss: 0.4928\n",
      "Baseline Loss: 2.8696 | Actual Loss: 2.2493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 181/1000 [00:58<04:12,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7979 | Actual Loss: 1.0205\n",
      "Baseline Loss: 2.8178 | Actual Loss: 0.0686\n",
      "Baseline Loss: 2.8706 | Actual Loss: 0.1294\n",
      "Baseline Loss: 2.7871 | Actual Loss: 0.3361\n",
      "Baseline Loss: 2.8256 | Actual Loss: 0.2612\n",
      "Baseline Loss: 2.7392 | Actual Loss: 0.0461\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4985\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6637\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5076\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3361\n",
      "Epoch 181/1000: Train Loss: 0.5871, Val Loss: 0.5015\n",
      "Baseline Loss: 2.8642 | Actual Loss: 0.3825\n",
      "Baseline Loss: 2.8417 | Actual Loss: 0.2542\n",
      "Baseline Loss: 2.8117 | Actual Loss: 0.1023\n",
      "Baseline Loss: 2.7852 | Actual Loss: 0.6813\n",
      "Baseline Loss: 2.8050 | Actual Loss: 0.1008\n",
      "Baseline Loss: 2.8734 | Actual Loss: 0.5073\n",
      "Baseline Loss: 2.8117 | Actual Loss: 0.3914\n",
      "Baseline Loss: 2.8224 | Actual Loss: 2.3945\n",
      "Baseline Loss: 2.7341 | Actual Loss: 0.2172\n",
      "Baseline Loss: 2.8758 | Actual Loss: 0.3512\n",
      "Baseline Loss: 2.8605 | Actual Loss: 0.5002\n",
      "Baseline Loss: 2.8151 | Actual Loss: 0.3408\n",
      "Baseline Loss: 2.7714 | Actual Loss: 0.2008\n",
      "Baseline Loss: 2.8399 | Actual Loss: 0.0781\n",
      "Baseline Loss: 2.8326 | Actual Loss: 1.0458\n",
      "Baseline Loss: 2.6035 | Actual Loss: 0.2315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 182/1000 [00:58<04:04,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8199 | Actual Loss: 0.4923\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6801\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5301\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.1578\n",
      "Epoch 182/1000: Train Loss: 0.4862, Val Loss: 0.4651\n",
      "Baseline Loss: 2.9612 | Actual Loss: 0.4532\n",
      "Baseline Loss: 2.8542 | Actual Loss: 0.2274\n",
      "Baseline Loss: 2.8276 | Actual Loss: 1.0559\n",
      "Baseline Loss: 2.8506 | Actual Loss: 0.3734\n",
      "Baseline Loss: 2.8718 | Actual Loss: 1.3281\n",
      "Baseline Loss: 2.8163 | Actual Loss: 0.5475\n",
      "Baseline Loss: 2.8135 | Actual Loss: 0.3211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 183/1000 [00:58<04:15,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7643 | Actual Loss: 0.2810\n",
      "Baseline Loss: 2.7937 | Actual Loss: 0.5048\n",
      "Baseline Loss: 2.8642 | Actual Loss: 0.0513\n",
      "Baseline Loss: 2.7650 | Actual Loss: 0.2334\n",
      "Baseline Loss: 2.8121 | Actual Loss: 0.7259\n",
      "Baseline Loss: 2.7706 | Actual Loss: 0.3180\n",
      "Baseline Loss: 2.8772 | Actual Loss: 0.6587\n",
      "Baseline Loss: 2.7958 | Actual Loss: 0.4968\n",
      "Baseline Loss: 2.5468 | Actual Loss: 0.2342\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4979\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6510\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4772\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2521\n",
      "Epoch 183/1000: Train Loss: 0.4882, Val Loss: 0.4696\n",
      "Baseline Loss: 2.9090 | Actual Loss: 0.4881\n",
      "Baseline Loss: 2.8602 | Actual Loss: 0.2259\n",
      "Baseline Loss: 2.8390 | Actual Loss: 0.5862\n",
      "Baseline Loss: 2.8601 | Actual Loss: 0.2144\n",
      "Baseline Loss: 2.8296 | Actual Loss: 0.2023\n",
      "Baseline Loss: 2.8376 | Actual Loss: 0.2931\n",
      "Baseline Loss: 2.9718 | Actual Loss: 0.6559\n",
      "Baseline Loss: 2.8408 | Actual Loss: 0.5588\n",
      "Baseline Loss: 2.8149 | Actual Loss: 0.3688\n",
      "Baseline Loss: 2.8079 | Actual Loss: 0.4932\n",
      "Baseline Loss: 2.8453 | Actual Loss: 0.4194\n",
      "Baseline Loss: 2.7995 | Actual Loss: 0.7039\n",
      "Baseline Loss: 2.7997 | Actual Loss: 0.0930\n",
      "Baseline Loss: 2.7738 | Actual Loss: 0.1705\n",
      "Baseline Loss: 2.7578 | Actual Loss: 0.3446\n",
      "Baseline Loss: 2.4273 | Actual Loss: 2.1768\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.6549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 184/1000 [00:59<04:24,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8180 | Actual Loss: 0.7163\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4671\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2073\n",
      "Epoch 184/1000: Train Loss: 0.4997, Val Loss: 0.5114\n",
      "Baseline Loss: 2.7834 | Actual Loss: 2.0169\n",
      "Baseline Loss: 2.7804 | Actual Loss: 0.4108\n",
      "Baseline Loss: 2.8343 | Actual Loss: 0.4708\n",
      "Baseline Loss: 2.7656 | Actual Loss: 0.2137\n",
      "Baseline Loss: 2.8360 | Actual Loss: 0.2950\n",
      "Baseline Loss: 2.8166 | Actual Loss: 0.1280\n",
      "Baseline Loss: 2.7952 | Actual Loss: 0.2199\n",
      "Baseline Loss: 2.8372 | Actual Loss: 0.7800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 185/1000 [00:59<04:10,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8239 | Actual Loss: 0.2412\n",
      "Baseline Loss: 2.8513 | Actual Loss: 0.2591\n",
      "Baseline Loss: 2.8440 | Actual Loss: 0.2331\n",
      "Baseline Loss: 2.8518 | Actual Loss: 0.4199\n",
      "Baseline Loss: 2.8306 | Actual Loss: 0.4087\n",
      "Baseline Loss: 2.8386 | Actual Loss: 0.1044\n",
      "Baseline Loss: 2.8224 | Actual Loss: 0.3476\n",
      "Baseline Loss: 2.6147 | Actual Loss: 0.2577\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4772\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7322\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4899\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2073\n",
      "Epoch 185/1000: Train Loss: 0.4254, Val Loss: 0.4767\n",
      "Baseline Loss: 2.7695 | Actual Loss: 2.0597\n",
      "Baseline Loss: 2.8264 | Actual Loss: 0.1490\n",
      "Baseline Loss: 2.8751 | Actual Loss: 0.2227\n",
      "Baseline Loss: 2.8350 | Actual Loss: 0.3625\n",
      "Baseline Loss: 2.7663 | Actual Loss: 0.3718\n",
      "Baseline Loss: 2.9051 | Actual Loss: 0.3483\n",
      "Baseline Loss: 2.8357 | Actual Loss: 0.6658\n",
      "Baseline Loss: 2.8805 | Actual Loss: 0.2259\n",
      "Baseline Loss: 2.7978 | Actual Loss: 0.2505\n",
      "Baseline Loss: 2.8091 | Actual Loss: 0.1417\n",
      "Baseline Loss: 2.8198 | Actual Loss: 0.1236\n",
      "Baseline Loss: 2.8225 | Actual Loss: 0.4472\n",
      "Baseline Loss: 2.9132 | Actual Loss: 0.3642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▊        | 186/1000 [00:59<04:15,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8802 | Actual Loss: 0.7079\n",
      "Baseline Loss: 2.8231 | Actual Loss: 0.2870\n",
      "Baseline Loss: 2.4510 | Actual Loss: 0.0789\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4613\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7015\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5969\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.1575\n",
      "Epoch 186/1000: Train Loss: 0.4254, Val Loss: 0.4793\n",
      "Baseline Loss: 2.8451 | Actual Loss: 0.1317\n",
      "Baseline Loss: 2.8599 | Actual Loss: 0.5701\n",
      "Baseline Loss: 2.8318 | Actual Loss: 0.8416\n",
      "Baseline Loss: 2.8595 | Actual Loss: 2.3389\n",
      "Baseline Loss: 2.8184 | Actual Loss: 2.2184\n",
      "Baseline Loss: 2.7987 | Actual Loss: 0.5047\n",
      "Baseline Loss: 2.7655 | Actual Loss: 0.5977\n",
      "Baseline Loss: 2.7793 | Actual Loss: 0.6601\n",
      "Baseline Loss: 2.8556 | Actual Loss: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▊        | 187/1000 [01:00<04:06,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7771 | Actual Loss: 0.1933\n",
      "Baseline Loss: 2.7492 | Actual Loss: 0.4264\n",
      "Baseline Loss: 2.8991 | Actual Loss: 0.1297\n",
      "Baseline Loss: 2.9205 | Actual Loss: 2.9362\n",
      "Baseline Loss: 2.8163 | Actual Loss: 0.3385\n",
      "Baseline Loss: 2.9335 | Actual Loss: 0.4652\n",
      "Baseline Loss: 2.5017 | Actual Loss: 0.2600\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5213\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6085\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4334\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2014\n",
      "Epoch 187/1000: Train Loss: 0.8158, Val Loss: 0.4411\n",
      "New best validation loss: 0.4411\n",
      "Baseline Loss: 2.7967 | Actual Loss: 0.3022\n",
      "Baseline Loss: 2.8035 | Actual Loss: 0.3727\n",
      "Baseline Loss: 2.8231 | Actual Loss: 1.5004\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.7584\n",
      "Baseline Loss: 2.7668 | Actual Loss: 0.0900\n",
      "Baseline Loss: 2.8571 | Actual Loss: 0.5047\n",
      "Baseline Loss: 2.7866 | Actual Loss: 0.4813\n",
      "Baseline Loss: 2.8224 | Actual Loss: 0.1292\n",
      "Baseline Loss: 2.8563 | Actual Loss: 0.1011\n",
      "Baseline Loss: 2.8940 | Actual Loss: 0.2270\n",
      "Baseline Loss: 2.7613 | Actual Loss: 0.4173\n",
      "Baseline Loss: 2.8216 | Actual Loss: 0.5073\n",
      "Baseline Loss: 2.9166 | Actual Loss: 0.1439\n",
      "Baseline Loss: 2.7886 | Actual Loss: 0.5181\n",
      "Baseline Loss: 2.8711 | Actual Loss: 0.2910\n",
      "Baseline Loss: 2.5236 | Actual Loss: 0.2736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 188/1000 [01:00<04:13,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8199 | Actual Loss: 0.2992\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8126\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5293\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.4853\n",
      "Epoch 188/1000: Train Loss: 0.4761, Val Loss: 0.5316\n",
      "Baseline Loss: 2.8804 | Actual Loss: 0.5165\n",
      "Baseline Loss: 2.8583 | Actual Loss: 0.4707\n",
      "Baseline Loss: 2.8807 | Actual Loss: 0.1352\n",
      "Baseline Loss: 2.8568 | Actual Loss: 1.7946\n",
      "Baseline Loss: 2.8792 | Actual Loss: 0.5536\n",
      "Baseline Loss: 2.7605 | Actual Loss: 0.3142\n",
      "Baseline Loss: 2.8479 | Actual Loss: 0.6934\n",
      "Baseline Loss: 2.7583 | Actual Loss: 0.1758\n",
      "Baseline Loss: 2.8381 | Actual Loss: 0.3103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 189/1000 [01:00<04:15,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8024 | Actual Loss: 2.1013\n",
      "Baseline Loss: 2.8637 | Actual Loss: 0.2771\n",
      "Baseline Loss: 2.8575 | Actual Loss: 0.1348\n",
      "Baseline Loss: 2.8302 | Actual Loss: 0.2200\n",
      "Baseline Loss: 2.8081 | Actual Loss: 0.3964\n",
      "Baseline Loss: 2.7983 | Actual Loss: 0.2065\n",
      "Baseline Loss: 2.4708 | Actual Loss: 1.7652\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5995\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7344\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4131\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.1786\n",
      "Epoch 189/1000: Train Loss: 0.6291, Val Loss: 0.4814\n",
      "Baseline Loss: 2.8225 | Actual Loss: 0.2418\n",
      "Baseline Loss: 2.7719 | Actual Loss: 2.2129\n",
      "Baseline Loss: 2.8468 | Actual Loss: 0.2269\n",
      "Baseline Loss: 2.8225 | Actual Loss: 0.2284\n",
      "Baseline Loss: 2.9037 | Actual Loss: 2.3634\n",
      "Baseline Loss: 2.9014 | Actual Loss: 1.6087\n",
      "Baseline Loss: 2.7831 | Actual Loss: 0.9883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 190/1000 [01:00<04:04,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8107 | Actual Loss: 0.3912\n",
      "Baseline Loss: 2.8100 | Actual Loss: 0.2664\n",
      "Baseline Loss: 2.7720 | Actual Loss: 0.1844\n",
      "Baseline Loss: 2.8217 | Actual Loss: 0.4175\n",
      "Baseline Loss: 2.8556 | Actual Loss: 0.4215\n",
      "Baseline Loss: 2.7688 | Actual Loss: 0.4710\n",
      "Baseline Loss: 2.7796 | Actual Loss: 0.4752\n",
      "Baseline Loss: 2.8157 | Actual Loss: 0.1198\n",
      "Baseline Loss: 2.6682 | Actual Loss: 0.1031\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.6460\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.0148\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5241\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2396\n",
      "Epoch 190/1000: Train Loss: 0.6700, Val Loss: 0.6061\n",
      "Baseline Loss: 2.8435 | Actual Loss: 2.2241\n",
      "Baseline Loss: 2.8084 | Actual Loss: 0.1146\n",
      "Baseline Loss: 2.8067 | Actual Loss: 0.2623\n",
      "Baseline Loss: 2.9019 | Actual Loss: 0.1281\n",
      "Baseline Loss: 2.7899 | Actual Loss: 0.2727\n",
      "Baseline Loss: 2.7804 | Actual Loss: 0.5938\n",
      "Baseline Loss: 2.7659 | Actual Loss: 0.1078\n",
      "Baseline Loss: 2.8391 | Actual Loss: 0.4159\n",
      "Baseline Loss: 2.8881 | Actual Loss: 0.5381\n",
      "Baseline Loss: 2.7882 | Actual Loss: 0.4312\n",
      "Baseline Loss: 2.9197 | Actual Loss: 0.3048\n",
      "Baseline Loss: 2.8795 | Actual Loss: 0.5503\n",
      "Baseline Loss: 2.7405 | Actual Loss: 0.5199\n",
      "Baseline Loss: 2.8802 | Actual Loss: 0.2457\n",
      "Baseline Loss: 2.8037 | Actual Loss: 0.2116\n",
      "Baseline Loss: 2.3967 | Actual Loss: 0.3102\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 191/1000 [01:01<04:10,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8180 | Actual Loss: 0.7415\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4915\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.1414\n",
      "Epoch 191/1000: Train Loss: 0.4519, Val Loss: 0.4825\n",
      "Baseline Loss: 2.7966 | Actual Loss: 0.3013\n",
      "Baseline Loss: 2.8158 | Actual Loss: 0.7666\n",
      "Baseline Loss: 2.8283 | Actual Loss: 0.2588\n",
      "Baseline Loss: 2.7881 | Actual Loss: 0.5010\n",
      "Baseline Loss: 2.8105 | Actual Loss: 0.2365\n",
      "Baseline Loss: 2.7725 | Actual Loss: 0.2206\n",
      "Baseline Loss: 2.8363 | Actual Loss: 2.1058\n",
      "Baseline Loss: 2.8224 | Actual Loss: 2.6198\n",
      "Baseline Loss: 2.9013 | Actual Loss: 2.4927\n",
      "Baseline Loss: 2.8733 | Actual Loss: 0.2840\n",
      "Baseline Loss: 2.8827 | Actual Loss: 0.2088\n",
      "Baseline Loss: 2.7533 | Actual Loss: 0.3834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 192/1000 [01:01<04:15,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8004 | Actual Loss: 0.3765\n",
      "Baseline Loss: 2.8870 | Actual Loss: 0.6768\n",
      "Baseline Loss: 2.8251 | Actual Loss: 0.5148\n",
      "Baseline Loss: 2.5355 | Actual Loss: 0.2805\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4806\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7052\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.3731\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3146\n",
      "Epoch 192/1000: Train Loss: 0.7642, Val Loss: 0.4684\n",
      "Baseline Loss: 2.7728 | Actual Loss: 0.1529\n",
      "Baseline Loss: 2.8944 | Actual Loss: 0.1680\n",
      "Baseline Loss: 2.8388 | Actual Loss: 2.6141\n",
      "Baseline Loss: 2.8885 | Actual Loss: 0.1156\n",
      "Baseline Loss: 2.7904 | Actual Loss: 0.2485\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.3958\n",
      "Baseline Loss: 2.8290 | Actual Loss: 2.5751\n",
      "Baseline Loss: 2.7842 | Actual Loss: 0.5740\n",
      "Baseline Loss: 2.9035 | Actual Loss: 2.1080\n",
      "Baseline Loss: 2.8143 | Actual Loss: 0.1974\n",
      "Baseline Loss: 2.8638 | Actual Loss: 1.9773\n",
      "Baseline Loss: 2.8921 | Actual Loss: 2.3882\n",
      "Baseline Loss: 2.7602 | Actual Loss: 0.1629\n",
      "Baseline Loss: 2.8084 | Actual Loss: 0.0852\n",
      "Baseline Loss: 2.8269 | Actual Loss: 0.6651\n",
      "Baseline Loss: 2.6860 | Actual Loss: 0.2971\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5361\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 193/1000 [01:01<04:04,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7998 | Actual Loss: 0.4143\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3240\n",
      "Epoch 193/1000: Train Loss: 0.9203, Val Loss: 0.4993\n",
      "Baseline Loss: 2.7780 | Actual Loss: 0.3301\n",
      "Baseline Loss: 2.8477 | Actual Loss: 0.1710\n",
      "Baseline Loss: 2.8588 | Actual Loss: 0.5157\n",
      "Baseline Loss: 2.9002 | Actual Loss: 0.4904\n",
      "Baseline Loss: 2.8492 | Actual Loss: 0.7656\n",
      "Baseline Loss: 2.8627 | Actual Loss: 0.5608\n",
      "Baseline Loss: 2.8714 | Actual Loss: 0.3842\n",
      "Baseline Loss: 2.7435 | Actual Loss: 0.2473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 194/1000 [01:02<04:10,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8346 | Actual Loss: 0.1718\n",
      "Baseline Loss: 2.7824 | Actual Loss: 0.5018\n",
      "Baseline Loss: 2.8575 | Actual Loss: 0.2634\n",
      "Baseline Loss: 2.8351 | Actual Loss: 0.2676\n",
      "Baseline Loss: 2.8403 | Actual Loss: 0.3024\n",
      "Baseline Loss: 2.8307 | Actual Loss: 0.3851\n",
      "Baseline Loss: 2.7712 | Actual Loss: 0.1035\n",
      "Baseline Loss: 2.4786 | Actual Loss: 0.0247\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5197\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7274\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5330\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.1252\n",
      "Epoch 194/1000: Train Loss: 0.3428, Val Loss: 0.4763\n",
      "Baseline Loss: 2.8955 | Actual Loss: 0.2391\n",
      "Baseline Loss: 2.8026 | Actual Loss: 0.2421\n",
      "Baseline Loss: 2.8188 | Actual Loss: 0.2098\n",
      "Baseline Loss: 2.8586 | Actual Loss: 0.5078\n",
      "Baseline Loss: 2.7986 | Actual Loss: 0.7922\n",
      "Baseline Loss: 2.8299 | Actual Loss: 0.1132\n",
      "Baseline Loss: 2.7665 | Actual Loss: 0.5670\n",
      "Baseline Loss: 2.8261 | Actual Loss: 0.2200\n",
      "Baseline Loss: 2.8299 | Actual Loss: 0.4494\n",
      "Baseline Loss: 2.8298 | Actual Loss: 1.3977\n",
      "Baseline Loss: 2.7649 | Actual Loss: 0.3573\n",
      "Baseline Loss: 2.8618 | Actual Loss: 0.3202\n",
      "Baseline Loss: 2.8532 | Actual Loss: 0.7630\n",
      "Baseline Loss: 2.8298 | Actual Loss: 0.1199\n",
      "Baseline Loss: 2.7949 | Actual Loss: 0.2094\n",
      "Baseline Loss: 2.6129 | Actual Loss: 0.0498\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.6392\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6928\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 195/1000 [01:02<04:21,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7254 | Actual Loss: 0.3314\n",
      "Epoch 195/1000: Train Loss: 0.4099, Val Loss: 0.5169\n",
      "Baseline Loss: 2.8265 | Actual Loss: 0.6752\n",
      "Baseline Loss: 2.7774 | Actual Loss: 0.1308\n",
      "Baseline Loss: 2.7542 | Actual Loss: 0.2308\n",
      "Baseline Loss: 2.7968 | Actual Loss: 0.2131\n",
      "Baseline Loss: 2.9010 | Actual Loss: 0.4983\n",
      "Baseline Loss: 2.7720 | Actual Loss: 0.2111\n",
      "Baseline Loss: 2.7955 | Actual Loss: 0.1231\n",
      "Baseline Loss: 2.9652 | Actual Loss: 0.3108\n",
      "Baseline Loss: 2.7722 | Actual Loss: 0.2437\n",
      "Baseline Loss: 2.8124 | Actual Loss: 0.2740\n",
      "Baseline Loss: 2.7916 | Actual Loss: 0.2556\n",
      "Baseline Loss: 2.8445 | Actual Loss: 0.1236\n",
      "Baseline Loss: 2.8335 | Actual Loss: 0.1461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 196/1000 [01:02<04:09,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8509 | Actual Loss: 0.5175\n",
      "Baseline Loss: 2.8860 | Actual Loss: 0.1711\n",
      "Baseline Loss: 2.5794 | Actual Loss: 0.2160\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5586\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6220\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4947\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.4336\n",
      "Epoch 196/1000: Train Loss: 0.2713, Val Loss: 0.5272\n",
      "Baseline Loss: 2.8580 | Actual Loss: 0.2017\n",
      "Baseline Loss: 2.8148 | Actual Loss: 0.1302\n",
      "Baseline Loss: 2.7725 | Actual Loss: 2.1994\n",
      "Baseline Loss: 2.9138 | Actual Loss: 0.2522\n",
      "Baseline Loss: 2.8574 | Actual Loss: 0.8274\n",
      "Baseline Loss: 2.8032 | Actual Loss: 0.4691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 197/1000 [01:03<04:13,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8929 | Actual Loss: 0.2050\n",
      "Baseline Loss: 2.8689 | Actual Loss: 0.4018\n",
      "Baseline Loss: 2.7893 | Actual Loss: 0.2271\n",
      "Baseline Loss: 2.8075 | Actual Loss: 0.1744\n",
      "Baseline Loss: 2.8261 | Actual Loss: 0.1334\n",
      "Baseline Loss: 2.8150 | Actual Loss: 0.2205\n",
      "Baseline Loss: 2.8005 | Actual Loss: 0.2895\n",
      "Baseline Loss: 2.7649 | Actual Loss: 0.1038\n",
      "Baseline Loss: 2.7721 | Actual Loss: 0.4332\n",
      "Baseline Loss: 2.4720 | Actual Loss: 0.1005\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5331\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6942\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4983\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.1399\n",
      "Epoch 197/1000: Train Loss: 0.3981, Val Loss: 0.4664\n",
      "Baseline Loss: 2.8247 | Actual Loss: 0.2724\n",
      "Baseline Loss: 2.8136 | Actual Loss: 0.4099\n",
      "Baseline Loss: 2.8552 | Actual Loss: 0.4902\n",
      "Baseline Loss: 2.8542 | Actual Loss: 0.3083\n",
      "Baseline Loss: 2.8782 | Actual Loss: 0.2634\n",
      "Baseline Loss: 2.8525 | Actual Loss: 0.1869\n",
      "Baseline Loss: 2.8779 | Actual Loss: 2.3508\n",
      "Baseline Loss: 2.7616 | Actual Loss: 2.3925\n",
      "Baseline Loss: 2.8257 | Actual Loss: 0.4227\n",
      "Baseline Loss: 2.8308 | Actual Loss: 0.2590\n",
      "Baseline Loss: 2.8618 | Actual Loss: 0.3644\n",
      "Baseline Loss: 2.8489 | Actual Loss: 0.3709\n",
      "Baseline Loss: 2.8269 | Actual Loss: 0.1028\n",
      "Baseline Loss: 2.8485 | Actual Loss: 0.4097\n",
      "Baseline Loss: 2.8093 | Actual Loss: 1.6701\n",
      "Baseline Loss: 2.4771 | Actual Loss: 0.2130\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 198/1000 [01:03<04:21,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8180 | Actual Loss: 0.8705\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4924\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.1602\n",
      "Epoch 198/1000: Train Loss: 0.6554, Val Loss: 0.4974\n",
      "Baseline Loss: 2.8262 | Actual Loss: 0.2104\n",
      "Baseline Loss: 2.8497 | Actual Loss: 2.0555\n",
      "Baseline Loss: 2.7812 | Actual Loss: 2.6105\n",
      "Baseline Loss: 2.8138 | Actual Loss: 0.3347\n",
      "Baseline Loss: 2.9122 | Actual Loss: 0.5432\n",
      "Baseline Loss: 2.8776 | Actual Loss: 1.9523\n",
      "Baseline Loss: 2.7626 | Actual Loss: 0.1905\n",
      "Baseline Loss: 2.7801 | Actual Loss: 0.2545\n",
      "Baseline Loss: 2.9167 | Actual Loss: 0.3569\n",
      "Baseline Loss: 2.7580 | Actual Loss: 0.2814\n",
      "Baseline Loss: 2.8367 | Actual Loss: 0.2548\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.8527\n",
      "Baseline Loss: 2.7587 | Actual Loss: 0.2858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 199/1000 [01:03<04:04,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8438 | Actual Loss: 0.6649\n",
      "Baseline Loss: 2.8624 | Actual Loss: 0.2582\n",
      "Baseline Loss: 2.4472 | Actual Loss: 0.3191\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5564\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6391\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4310\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.4078\n",
      "Epoch 199/1000: Train Loss: 0.7141, Val Loss: 0.5086\n",
      "Baseline Loss: 2.8225 | Actual Loss: 0.1813\n",
      "Baseline Loss: 2.8343 | Actual Loss: 0.3378\n",
      "Baseline Loss: 2.7716 | Actual Loss: 0.8171\n",
      "Baseline Loss: 2.8257 | Actual Loss: 0.1474\n",
      "Baseline Loss: 2.8644 | Actual Loss: 2.4355\n",
      "Baseline Loss: 2.8263 | Actual Loss: 2.4098\n",
      "Baseline Loss: 2.8730 | Actual Loss: 1.9419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 200/1000 [01:04<04:10,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9632 | Actual Loss: 0.4305\n",
      "Baseline Loss: 2.8068 | Actual Loss: 1.7968\n",
      "Baseline Loss: 2.8110 | Actual Loss: 0.1511\n",
      "Baseline Loss: 2.8190 | Actual Loss: 0.3566\n",
      "Baseline Loss: 2.8051 | Actual Loss: 0.1835\n",
      "Baseline Loss: 2.8056 | Actual Loss: 0.2583\n",
      "Baseline Loss: 2.8121 | Actual Loss: 0.3949\n",
      "Baseline Loss: 2.8558 | Actual Loss: 0.2003\n",
      "Baseline Loss: 2.4486 | Actual Loss: 0.4072\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5513\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7639\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4935\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2525\n",
      "Epoch 200/1000: Train Loss: 0.7781, Val Loss: 0.5153\n",
      "Baseline Loss: 2.7800 | Actual Loss: 0.4499\n",
      "Baseline Loss: 2.7670 | Actual Loss: 1.5658\n",
      "Baseline Loss: 2.7981 | Actual Loss: 0.5466\n",
      "Baseline Loss: 2.7961 | Actual Loss: 0.3794\n",
      "Baseline Loss: 2.9719 | Actual Loss: 0.4861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 201/1000 [01:04<03:59,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8562 | Actual Loss: 0.2869\n",
      "Baseline Loss: 2.8387 | Actual Loss: 0.1112\n",
      "Baseline Loss: 2.8342 | Actual Loss: 0.1820\n",
      "Baseline Loss: 2.7926 | Actual Loss: 0.5060\n",
      "Baseline Loss: 2.8856 | Actual Loss: 0.2818\n",
      "Baseline Loss: 2.8361 | Actual Loss: 0.2910\n",
      "Baseline Loss: 2.7767 | Actual Loss: 0.2046\n",
      "Baseline Loss: 2.7596 | Actual Loss: 0.3721\n",
      "Baseline Loss: 2.8387 | Actual Loss: 0.2085\n",
      "Baseline Loss: 2.8606 | Actual Loss: 0.2233\n",
      "Baseline Loss: 2.6215 | Actual Loss: 0.0592\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.6180\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7036\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4394\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.4299\n",
      "Epoch 201/1000: Train Loss: 0.3847, Val Loss: 0.5477\n",
      "Baseline Loss: 2.7913 | Actual Loss: 0.6170\n",
      "Baseline Loss: 2.8463 | Actual Loss: 0.1115\n",
      "Baseline Loss: 2.8868 | Actual Loss: 0.2042\n",
      "Baseline Loss: 2.8089 | Actual Loss: 0.3964\n",
      "Baseline Loss: 2.7897 | Actual Loss: 0.3525\n",
      "Baseline Loss: 2.7612 | Actual Loss: 0.1953\n",
      "Baseline Loss: 2.8231 | Actual Loss: 0.2390\n",
      "Baseline Loss: 2.8417 | Actual Loss: 0.2213\n",
      "Baseline Loss: 2.8850 | Actual Loss: 0.2159\n",
      "Baseline Loss: 2.8725 | Actual Loss: 0.1225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 202/1000 [01:04<04:05,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8519 | Actual Loss: 0.5375\n",
      "Baseline Loss: 2.8754 | Actual Loss: 0.1225\n",
      "Baseline Loss: 2.8450 | Actual Loss: 0.7608\n",
      "Baseline Loss: 2.7903 | Actual Loss: 0.2452\n",
      "Baseline Loss: 2.8843 | Actual Loss: 0.2629\n",
      "Baseline Loss: 2.5538 | Actual Loss: 0.3711\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4554\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7540\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5747\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.1967\n",
      "Epoch 202/1000: Train Loss: 0.3110, Val Loss: 0.4952\n",
      "Baseline Loss: 2.8063 | Actual Loss: 0.1430\n",
      "Baseline Loss: 2.8290 | Actual Loss: 0.4242\n",
      "Baseline Loss: 2.7480 | Actual Loss: 0.1350\n",
      "Baseline Loss: 2.7690 | Actual Loss: 0.2144\n",
      "Baseline Loss: 2.7587 | Actual Loss: 0.1937\n",
      "Baseline Loss: 2.8206 | Actual Loss: 0.3902\n",
      "Baseline Loss: 2.8794 | Actual Loss: 0.5935\n",
      "Baseline Loss: 2.8796 | Actual Loss: 0.1950\n",
      "Baseline Loss: 2.8131 | Actual Loss: 0.3847\n",
      "Baseline Loss: 2.8352 | Actual Loss: 0.2515\n",
      "Baseline Loss: 2.8053 | Actual Loss: 0.8320\n",
      "Baseline Loss: 2.8177 | Actual Loss: 2.4229\n",
      "Baseline Loss: 2.8018 | Actual Loss: 0.0722\n",
      "Baseline Loss: 2.8580 | Actual Loss: 0.2236\n",
      "Baseline Loss: 2.8889 | Actual Loss: 0.1605\n",
      "Baseline Loss: 2.5451 | Actual Loss: 2.2967\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4897\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 203/1000 [01:05<04:18,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7998 | Actual Loss: 0.5078\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.4202\n",
      "Epoch 203/1000: Train Loss: 0.5583, Val Loss: 0.5381\n",
      "Baseline Loss: 2.8237 | Actual Loss: 1.8022\n",
      "Baseline Loss: 2.8645 | Actual Loss: 0.1193\n",
      "Baseline Loss: 2.8604 | Actual Loss: 0.8826\n",
      "Baseline Loss: 2.7426 | Actual Loss: 0.2789\n",
      "Baseline Loss: 2.9234 | Actual Loss: 2.3936\n",
      "Baseline Loss: 2.8225 | Actual Loss: 0.2604\n",
      "Baseline Loss: 2.8540 | Actual Loss: 0.1949\n",
      "Baseline Loss: 2.7751 | Actual Loss: 0.0839\n",
      "Baseline Loss: 2.8193 | Actual Loss: 0.4905\n",
      "Baseline Loss: 2.7620 | Actual Loss: 0.2962\n",
      "Baseline Loss: 2.9098 | Actual Loss: 0.3929\n",
      "Baseline Loss: 2.8051 | Actual Loss: 0.2365\n",
      "Baseline Loss: 2.8433 | Actual Loss: 0.2394\n",
      "Baseline Loss: 2.8249 | Actual Loss: 0.0920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 204/1000 [01:05<04:01,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8026 | Actual Loss: 0.1611\n",
      "Baseline Loss: 2.5791 | Actual Loss: 1.6742\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.7025\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6855\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4978\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3469\n",
      "Epoch 204/1000: Train Loss: 0.5999, Val Loss: 0.5582\n",
      "Baseline Loss: 2.9050 | Actual Loss: 0.4910\n",
      "Baseline Loss: 2.7652 | Actual Loss: 0.2332\n",
      "Baseline Loss: 2.7476 | Actual Loss: 0.2190\n",
      "Baseline Loss: 2.8262 | Actual Loss: 0.4383\n",
      "Baseline Loss: 2.9163 | Actual Loss: 2.0304\n",
      "Baseline Loss: 2.9035 | Actual Loss: 0.2545\n",
      "Baseline Loss: 2.8210 | Actual Loss: 0.7514\n",
      "Baseline Loss: 2.8472 | Actual Loss: 2.3792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 205/1000 [01:05<04:06,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7856 | Actual Loss: 0.8636\n",
      "Baseline Loss: 2.8263 | Actual Loss: 0.4626\n",
      "Baseline Loss: 2.8427 | Actual Loss: 0.1280\n",
      "Baseline Loss: 2.8400 | Actual Loss: 0.2379\n",
      "Baseline Loss: 2.7439 | Actual Loss: 0.2789\n",
      "Baseline Loss: 2.7629 | Actual Loss: 0.1201\n",
      "Baseline Loss: 2.8820 | Actual Loss: 0.1107\n",
      "Baseline Loss: 2.5207 | Actual Loss: 0.1437\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5067\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7504\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.3798\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.1990\n",
      "Epoch 205/1000: Train Loss: 0.5714, Val Loss: 0.4590\n",
      "Baseline Loss: 2.8327 | Actual Loss: 0.7612\n",
      "Baseline Loss: 2.8966 | Actual Loss: 0.3099\n",
      "Baseline Loss: 2.8131 | Actual Loss: 0.1982\n",
      "Baseline Loss: 2.8689 | Actual Loss: 0.1462\n",
      "Baseline Loss: 2.8086 | Actual Loss: 1.0831\n",
      "Baseline Loss: 2.8495 | Actual Loss: 0.3423\n",
      "Baseline Loss: 2.8719 | Actual Loss: 0.2942\n",
      "Baseline Loss: 2.7955 | Actual Loss: 0.3815\n",
      "Baseline Loss: 2.8226 | Actual Loss: 0.1229\n",
      "Baseline Loss: 2.8479 | Actual Loss: 0.4203\n",
      "Baseline Loss: 2.7906 | Actual Loss: 0.2057\n",
      "Baseline Loss: 2.8366 | Actual Loss: 0.2584\n",
      "Baseline Loss: 2.7787 | Actual Loss: 0.5238\n",
      "Baseline Loss: 2.8548 | Actual Loss: 0.1981\n",
      "Baseline Loss: 2.7264 | Actual Loss: 0.4140\n",
      "Baseline Loss: 2.4931 | Actual Loss: 0.2323\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 206/1000 [01:06<04:18,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8180 | Actual Loss: 0.6494\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4966\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3604\n",
      "Epoch 206/1000: Train Loss: 0.3682, Val Loss: 0.5266\n",
      "Baseline Loss: 2.7833 | Actual Loss: 0.3568\n",
      "Baseline Loss: 2.8746 | Actual Loss: 0.1904\n",
      "Baseline Loss: 2.8596 | Actual Loss: 0.3776\n",
      "Baseline Loss: 2.7819 | Actual Loss: 2.3323\n",
      "Baseline Loss: 2.8265 | Actual Loss: 2.3111\n",
      "Baseline Loss: 2.9032 | Actual Loss: 1.3056\n",
      "Baseline Loss: 2.8242 | Actual Loss: 0.3792\n",
      "Baseline Loss: 2.8143 | Actual Loss: 0.3112\n",
      "Baseline Loss: 2.7871 | Actual Loss: 0.3679\n",
      "Baseline Loss: 2.8559 | Actual Loss: 1.4422\n",
      "Baseline Loss: 2.7993 | Actual Loss: 2.2117\n",
      "Baseline Loss: 2.7806 | Actual Loss: 0.3435\n",
      "Baseline Loss: 2.8108 | Actual Loss: 0.1243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 207/1000 [01:06<03:59,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8421 | Actual Loss: 2.3335\n",
      "Baseline Loss: 2.8457 | Actual Loss: 0.2450\n",
      "Baseline Loss: 2.4568 | Actual Loss: 0.3078\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.7030\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6460\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4257\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2434\n",
      "Epoch 207/1000: Train Loss: 0.9338, Val Loss: 0.5045\n",
      "Baseline Loss: 2.8094 | Actual Loss: 0.2229\n",
      "Baseline Loss: 2.9197 | Actual Loss: 0.1941\n",
      "Baseline Loss: 2.7576 | Actual Loss: 0.5709\n",
      "Baseline Loss: 2.8258 | Actual Loss: 0.3330\n",
      "Baseline Loss: 2.7465 | Actual Loss: 0.4161\n",
      "Baseline Loss: 2.8408 | Actual Loss: 0.2979\n",
      "Baseline Loss: 2.8446 | Actual Loss: 0.2126\n",
      "Baseline Loss: 2.7701 | Actual Loss: 0.2048\n",
      "Baseline Loss: 2.8169 | Actual Loss: 0.3522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 208/1000 [01:06<04:11,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7840 | Actual Loss: 0.4762\n",
      "Baseline Loss: 2.8460 | Actual Loss: 0.2908\n",
      "Baseline Loss: 2.9039 | Actual Loss: 0.5917\n",
      "Baseline Loss: 2.7879 | Actual Loss: 2.1089\n",
      "Baseline Loss: 2.7352 | Actual Loss: 0.4858\n",
      "Baseline Loss: 2.8893 | Actual Loss: 0.2013\n",
      "Baseline Loss: 2.4977 | Actual Loss: 0.7932\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4827\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7077\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4865\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.1542\n",
      "Epoch 208/1000: Train Loss: 0.4845, Val Loss: 0.4578\n",
      "Baseline Loss: 2.8730 | Actual Loss: 0.1933\n",
      "Baseline Loss: 2.7767 | Actual Loss: 0.1265\n",
      "Baseline Loss: 2.7537 | Actual Loss: 0.5390\n",
      "Baseline Loss: 2.8048 | Actual Loss: 0.1882\n",
      "Baseline Loss: 2.8658 | Actual Loss: 0.4253\n",
      "Baseline Loss: 2.7939 | Actual Loss: 0.1798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 209/1000 [01:06<03:55,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8501 | Actual Loss: 0.3348\n",
      "Baseline Loss: 2.8088 | Actual Loss: 0.2203\n",
      "Baseline Loss: 2.8635 | Actual Loss: 0.2832\n",
      "Baseline Loss: 2.8778 | Actual Loss: 0.0473\n",
      "Baseline Loss: 2.7738 | Actual Loss: 0.3696\n",
      "Baseline Loss: 2.8337 | Actual Loss: 2.3849\n",
      "Baseline Loss: 2.8540 | Actual Loss: 0.2417\n",
      "Baseline Loss: 2.7899 | Actual Loss: 0.6161\n",
      "Baseline Loss: 2.8402 | Actual Loss: 2.3312\n",
      "Baseline Loss: 2.6688 | Actual Loss: 0.2238\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5052\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6751\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4987\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3652\n",
      "Epoch 209/1000: Train Loss: 0.5441, Val Loss: 0.5110\n",
      "Baseline Loss: 2.7691 | Actual Loss: 0.1264\n",
      "Baseline Loss: 2.7990 | Actual Loss: 0.2236\n",
      "Baseline Loss: 2.8519 | Actual Loss: 0.2306\n",
      "Baseline Loss: 2.8162 | Actual Loss: 0.3535\n",
      "Baseline Loss: 2.8330 | Actual Loss: 0.1124\n",
      "Baseline Loss: 2.8626 | Actual Loss: 0.1555\n",
      "Baseline Loss: 2.7651 | Actual Loss: 0.3167\n",
      "Baseline Loss: 2.8064 | Actual Loss: 0.1246\n",
      "Baseline Loss: 2.8079 | Actual Loss: 0.2919\n",
      "Baseline Loss: 2.7795 | Actual Loss: 0.3600\n",
      "Baseline Loss: 2.8738 | Actual Loss: 0.1382\n",
      "Baseline Loss: 2.8082 | Actual Loss: 0.4352\n",
      "Baseline Loss: 2.8380 | Actual Loss: 0.4555\n",
      "Baseline Loss: 2.8275 | Actual Loss: 0.8709\n",
      "Baseline Loss: 2.8684 | Actual Loss: 0.4848\n",
      "Baseline Loss: 2.4630 | Actual Loss: 1.9183\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5277\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6259\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4946\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 210/1000 [01:07<04:00,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 210/1000: Train Loss: 0.4124, Val Loss: 0.4907\n",
      "Baseline Loss: 2.8286 | Actual Loss: 0.4878\n",
      "Baseline Loss: 2.8711 | Actual Loss: 0.4790\n",
      "Baseline Loss: 2.7930 | Actual Loss: 0.2173\n",
      "Baseline Loss: 2.8169 | Actual Loss: 0.5163\n",
      "Baseline Loss: 2.7864 | Actual Loss: 1.3382\n",
      "Baseline Loss: 2.9028 | Actual Loss: 2.8146\n",
      "Baseline Loss: 2.8001 | Actual Loss: 0.2529\n",
      "Baseline Loss: 2.8885 | Actual Loss: 0.2102\n",
      "Baseline Loss: 2.8188 | Actual Loss: 0.2958\n",
      "Baseline Loss: 2.8396 | Actual Loss: 1.2795\n",
      "Baseline Loss: 2.7916 | Actual Loss: 0.2431\n",
      "Baseline Loss: 2.8567 | Actual Loss: 0.6050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 211/1000 [01:07<04:10,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8218 | Actual Loss: 0.4641\n",
      "Baseline Loss: 2.8690 | Actual Loss: 0.1302\n",
      "Baseline Loss: 2.8029 | Actual Loss: 0.7332\n",
      "Baseline Loss: 2.5487 | Actual Loss: 0.0954\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5858\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7201\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4621\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3568\n",
      "Epoch 211/1000: Train Loss: 0.6352, Val Loss: 0.5312\n",
      "Baseline Loss: 2.8041 | Actual Loss: 0.2649\n",
      "Baseline Loss: 2.8012 | Actual Loss: 0.1839\n",
      "Baseline Loss: 2.8128 | Actual Loss: 0.2148\n",
      "Baseline Loss: 2.8035 | Actual Loss: 0.5137\n",
      "Baseline Loss: 2.8054 | Actual Loss: 0.5198\n",
      "Baseline Loss: 2.8581 | Actual Loss: 0.5334\n",
      "Baseline Loss: 2.8496 | Actual Loss: 0.1990\n",
      "Baseline Loss: 2.8314 | Actual Loss: 0.1732\n",
      "Baseline Loss: 2.8561 | Actual Loss: 0.3009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 212/1000 [01:07<03:54,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7858 | Actual Loss: 0.3218\n",
      "Baseline Loss: 2.8084 | Actual Loss: 0.2732\n",
      "Baseline Loss: 2.8119 | Actual Loss: 0.0728\n",
      "Baseline Loss: 2.8237 | Actual Loss: 0.1884\n",
      "Baseline Loss: 2.8366 | Actual Loss: 0.2017\n",
      "Baseline Loss: 2.7268 | Actual Loss: 2.3474\n",
      "Baseline Loss: 2.6745 | Actual Loss: 0.0902\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5115\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.9530\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4094\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3414\n",
      "Epoch 212/1000: Train Loss: 0.3999, Val Loss: 0.5538\n",
      "Baseline Loss: 2.8148 | Actual Loss: 0.3530\n",
      "Baseline Loss: 2.8707 | Actual Loss: 0.2789\n",
      "Baseline Loss: 2.8294 | Actual Loss: 0.3845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██▏       | 213/1000 [01:08<03:59,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8441 | Actual Loss: 1.9350\n",
      "Baseline Loss: 2.7575 | Actual Loss: 0.3393\n",
      "Baseline Loss: 2.8092 | Actual Loss: 0.5321\n",
      "Baseline Loss: 2.7746 | Actual Loss: 0.1921\n",
      "Baseline Loss: 2.8157 | Actual Loss: 0.4157\n",
      "Baseline Loss: 2.8073 | Actual Loss: 0.4224\n",
      "Baseline Loss: 2.7984 | Actual Loss: 0.1805\n",
      "Baseline Loss: 2.7889 | Actual Loss: 0.3280\n",
      "Baseline Loss: 2.8528 | Actual Loss: 0.4259\n",
      "Baseline Loss: 2.8496 | Actual Loss: 0.2319\n",
      "Baseline Loss: 2.8572 | Actual Loss: 0.1338\n",
      "Baseline Loss: 2.9094 | Actual Loss: 0.2353\n",
      "Baseline Loss: 2.3916 | Actual Loss: 2.0966\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4171\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7366\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4317\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3609\n",
      "Epoch 213/1000: Train Loss: 0.5303, Val Loss: 0.4865\n",
      "Baseline Loss: 2.8730 | Actual Loss: 0.5644\n",
      "Baseline Loss: 2.8336 | Actual Loss: 0.2219\n",
      "Baseline Loss: 2.8461 | Actual Loss: 2.2446\n",
      "Baseline Loss: 2.9119 | Actual Loss: 0.3889\n",
      "Baseline Loss: 2.8175 | Actual Loss: 0.3851\n",
      "Baseline Loss: 2.8711 | Actual Loss: 0.2259\n",
      "Baseline Loss: 2.8396 | Actual Loss: 0.2240\n",
      "Baseline Loss: 2.8114 | Actual Loss: 0.2204\n",
      "Baseline Loss: 2.7356 | Actual Loss: 0.5032\n",
      "Baseline Loss: 2.8090 | Actual Loss: 0.2077\n",
      "Baseline Loss: 2.7840 | Actual Loss: 0.1158\n",
      "Baseline Loss: 2.8308 | Actual Loss: 0.2107\n",
      "Baseline Loss: 2.8068 | Actual Loss: 0.1314\n",
      "Baseline Loss: 2.7942 | Actual Loss: 0.2818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██▏       | 214/1000 [01:08<04:12,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8421 | Actual Loss: 0.3583\n",
      "Baseline Loss: 2.5705 | Actual Loss: 0.2473\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5538\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6788\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5487\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2010\n",
      "Epoch 214/1000: Train Loss: 0.4082, Val Loss: 0.4956\n",
      "Baseline Loss: 2.8330 | Actual Loss: 0.3941\n",
      "Baseline Loss: 2.8350 | Actual Loss: 0.4663\n",
      "Baseline Loss: 2.8201 | Actual Loss: 2.2720\n",
      "Baseline Loss: 2.7448 | Actual Loss: 0.3002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 215/1000 [01:08<03:54,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8190 | Actual Loss: 0.3720\n",
      "Baseline Loss: 2.8863 | Actual Loss: 0.1058\n",
      "Baseline Loss: 2.8848 | Actual Loss: 0.2420\n",
      "Baseline Loss: 2.8740 | Actual Loss: 0.2289\n",
      "Baseline Loss: 2.8253 | Actual Loss: 0.3418\n",
      "Baseline Loss: 2.7889 | Actual Loss: 0.2769\n",
      "Baseline Loss: 2.8779 | Actual Loss: 0.2550\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.3017\n",
      "Baseline Loss: 2.8128 | Actual Loss: 1.9960\n",
      "Baseline Loss: 2.8386 | Actual Loss: 0.4382\n",
      "Baseline Loss: 2.8152 | Actual Loss: 0.3617\n",
      "Baseline Loss: 2.6197 | Actual Loss: 0.2496\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4470\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6566\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5519\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2011\n",
      "Epoch 215/1000: Train Loss: 0.5376, Val Loss: 0.4642\n",
      "Baseline Loss: 2.7802 | Actual Loss: 0.1856\n",
      "Baseline Loss: 2.8695 | Actual Loss: 0.2528\n",
      "Baseline Loss: 2.8099 | Actual Loss: 0.2513\n",
      "Baseline Loss: 2.8627 | Actual Loss: 0.1827\n",
      "Baseline Loss: 2.8107 | Actual Loss: 1.8471\n",
      "Baseline Loss: 2.8510 | Actual Loss: 1.2020\n",
      "Baseline Loss: 2.7587 | Actual Loss: 0.2202\n",
      "Baseline Loss: 2.8108 | Actual Loss: 0.3014\n",
      "Baseline Loss: 2.8379 | Actual Loss: 0.2825\n",
      "Baseline Loss: 2.8426 | Actual Loss: 0.6899\n",
      "Baseline Loss: 2.8190 | Actual Loss: 0.1108\n",
      "Baseline Loss: 2.8621 | Actual Loss: 0.2183\n",
      "Baseline Loss: 2.8340 | Actual Loss: 0.2186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 216/1000 [01:09<04:07,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8077 | Actual Loss: 0.4842\n",
      "Baseline Loss: 2.8354 | Actual Loss: 0.5322\n",
      "Baseline Loss: 2.4663 | Actual Loss: 0.2391\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4966\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6776\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5100\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3069\n",
      "Epoch 216/1000: Train Loss: 0.4512, Val Loss: 0.4978\n",
      "Baseline Loss: 2.8485 | Actual Loss: 0.2574\n",
      "Baseline Loss: 2.8696 | Actual Loss: 0.2625\n",
      "Baseline Loss: 2.8960 | Actual Loss: 0.3919\n",
      "Baseline Loss: 2.9076 | Actual Loss: 0.1909\n",
      "Baseline Loss: 2.7603 | Actual Loss: 0.4216\n",
      "Baseline Loss: 2.7770 | Actual Loss: 0.6029\n",
      "Baseline Loss: 2.8537 | Actual Loss: 2.2431\n",
      "Baseline Loss: 2.8095 | Actual Loss: 0.2126\n",
      "Baseline Loss: 2.8069 | Actual Loss: 0.0696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 217/1000 [01:09<03:51,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8013 | Actual Loss: 0.2284\n",
      "Baseline Loss: 2.8608 | Actual Loss: 0.2723\n",
      "Baseline Loss: 2.7305 | Actual Loss: 0.6733\n",
      "Baseline Loss: 2.7892 | Actual Loss: 0.2226\n",
      "Baseline Loss: 2.8089 | Actual Loss: 0.5325\n",
      "Baseline Loss: 2.8782 | Actual Loss: 0.2209\n",
      "Baseline Loss: 2.4864 | Actual Loss: 0.2630\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4932\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6295\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5062\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2998\n",
      "Epoch 217/1000: Train Loss: 0.4416, Val Loss: 0.4822\n",
      "Baseline Loss: 2.8178 | Actual Loss: 0.2063\n",
      "Baseline Loss: 2.7777 | Actual Loss: 0.0592\n",
      "Baseline Loss: 2.8235 | Actual Loss: 2.3239\n",
      "Baseline Loss: 2.8981 | Actual Loss: 0.2834\n",
      "Baseline Loss: 2.7974 | Actual Loss: 0.1928\n",
      "Baseline Loss: 2.7611 | Actual Loss: 0.3859\n",
      "Baseline Loss: 2.8456 | Actual Loss: 0.2383\n",
      "Baseline Loss: 2.8307 | Actual Loss: 0.4498\n",
      "Baseline Loss: 2.8247 | Actual Loss: 0.1402\n",
      "Baseline Loss: 2.8560 | Actual Loss: 0.2242\n",
      "Baseline Loss: 2.8914 | Actual Loss: 0.3098\n",
      "Baseline Loss: 2.7864 | Actual Loss: 0.4639\n",
      "Baseline Loss: 2.7591 | Actual Loss: 0.3693\n",
      "Baseline Loss: 2.8912 | Actual Loss: 0.4501\n",
      "Baseline Loss: 2.8019 | Actual Loss: 0.1997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 218/1000 [01:09<03:59,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5358 | Actual Loss: 0.2449\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.6518\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7125\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5361\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.1645\n",
      "Epoch 218/1000: Train Loss: 0.4088, Val Loss: 0.5162\n",
      "Baseline Loss: 2.9156 | Actual Loss: 0.2673\n",
      "Baseline Loss: 2.8444 | Actual Loss: 0.3604\n",
      "Baseline Loss: 2.8234 | Actual Loss: 0.2111\n",
      "Baseline Loss: 2.8342 | Actual Loss: 0.1055\n",
      "Baseline Loss: 2.8372 | Actual Loss: 0.1744\n",
      "Baseline Loss: 2.7564 | Actual Loss: 0.4857\n",
      "Baseline Loss: 2.7619 | Actual Loss: 0.2107\n",
      "Baseline Loss: 2.8244 | Actual Loss: 2.1638\n",
      "Baseline Loss: 2.8132 | Actual Loss: 0.3066\n",
      "Baseline Loss: 2.8634 | Actual Loss: 0.8728\n",
      "Baseline Loss: 2.8216 | Actual Loss: 0.2618\n",
      "Baseline Loss: 2.8543 | Actual Loss: 0.1695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 219/1000 [01:09<04:08,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7528 | Actual Loss: 0.2648\n",
      "Baseline Loss: 2.8026 | Actual Loss: 0.5534\n",
      "Baseline Loss: 2.8470 | Actual Loss: 0.1119\n",
      "Baseline Loss: 2.5946 | Actual Loss: 0.3022\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4866\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6769\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4407\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2892\n",
      "Epoch 219/1000: Train Loss: 0.4264, Val Loss: 0.4734\n",
      "Baseline Loss: 2.8133 | Actual Loss: 0.2089\n",
      "Baseline Loss: 2.8223 | Actual Loss: 0.2421\n",
      "Baseline Loss: 2.8304 | Actual Loss: 0.4770\n",
      "Baseline Loss: 2.8615 | Actual Loss: 0.1867\n",
      "Baseline Loss: 2.8725 | Actual Loss: 0.4789\n",
      "Baseline Loss: 2.8020 | Actual Loss: 0.6983\n",
      "Baseline Loss: 2.8041 | Actual Loss: 0.4272\n",
      "Baseline Loss: 2.8037 | Actual Loss: 0.1746\n",
      "Baseline Loss: 2.8684 | Actual Loss: 0.1936\n",
      "Baseline Loss: 2.8332 | Actual Loss: 2.2922\n",
      "Baseline Loss: 2.8557 | Actual Loss: 0.3348\n",
      "Baseline Loss: 2.8518 | Actual Loss: 0.2565\n",
      "Baseline Loss: 2.7412 | Actual Loss: 0.4316\n",
      "Baseline Loss: 2.8562 | Actual Loss: 0.0695\n",
      "Baseline Loss: 2.7926 | Actual Loss: 0.5016\n",
      "Baseline Loss: 2.5406 | Actual Loss: 0.3598\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.7351\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 220/1000 [01:10<03:54,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7998 | Actual Loss: 0.4802\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3484\n",
      "Epoch 220/1000: Train Loss: 0.4583, Val Loss: 0.5764\n",
      "Baseline Loss: 2.8440 | Actual Loss: 0.1783\n",
      "Baseline Loss: 2.7939 | Actual Loss: 2.0446\n",
      "Baseline Loss: 2.8152 | Actual Loss: 0.1205\n",
      "Baseline Loss: 2.8512 | Actual Loss: 0.0788\n",
      "Baseline Loss: 2.8100 | Actual Loss: 0.4002\n",
      "Baseline Loss: 2.7974 | Actual Loss: 0.3932\n",
      "Baseline Loss: 2.8549 | Actual Loss: 0.6288\n",
      "Baseline Loss: 2.8687 | Actual Loss: 0.3775\n",
      "Baseline Loss: 2.8384 | Actual Loss: 0.4566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 221/1000 [01:10<03:59,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8041 | Actual Loss: 0.5773\n",
      "Baseline Loss: 2.8286 | Actual Loss: 0.6175\n",
      "Baseline Loss: 2.8169 | Actual Loss: 0.5310\n",
      "Baseline Loss: 2.9098 | Actual Loss: 0.4890\n",
      "Baseline Loss: 2.8586 | Actual Loss: 0.2089\n",
      "Baseline Loss: 2.7310 | Actual Loss: 0.1783\n",
      "Baseline Loss: 2.5265 | Actual Loss: 1.8713\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5729\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6729\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.3550\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.1969\n",
      "Epoch 221/1000: Train Loss: 0.5720, Val Loss: 0.4494\n",
      "Baseline Loss: 2.8369 | Actual Loss: 0.3782\n",
      "Baseline Loss: 2.8429 | Actual Loss: 0.7342\n",
      "Baseline Loss: 2.8298 | Actual Loss: 0.8251\n",
      "Baseline Loss: 2.8504 | Actual Loss: 0.4437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 222/1000 [01:10<03:46,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8271 | Actual Loss: 0.2768\n",
      "Baseline Loss: 2.8191 | Actual Loss: 0.4170\n",
      "Baseline Loss: 2.8327 | Actual Loss: 0.4435\n",
      "Baseline Loss: 2.8473 | Actual Loss: 0.7676\n",
      "Baseline Loss: 2.8366 | Actual Loss: 0.1485\n",
      "Baseline Loss: 2.8302 | Actual Loss: 0.2546\n",
      "Baseline Loss: 2.8318 | Actual Loss: 0.2158\n",
      "Baseline Loss: 2.8339 | Actual Loss: 0.2288\n",
      "Baseline Loss: 2.8055 | Actual Loss: 0.0755\n",
      "Baseline Loss: 2.8060 | Actual Loss: 0.1371\n",
      "Baseline Loss: 2.7902 | Actual Loss: 0.3735\n",
      "Baseline Loss: 2.4879 | Actual Loss: 1.6189\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5007\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6989\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5340\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3040\n",
      "Epoch 222/1000: Train Loss: 0.4587, Val Loss: 0.5094\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.3051\n",
      "Baseline Loss: 2.8460 | Actual Loss: 0.2362\n",
      "Baseline Loss: 2.8092 | Actual Loss: 0.1944\n",
      "Baseline Loss: 2.8668 | Actual Loss: 0.5893\n",
      "Baseline Loss: 2.9085 | Actual Loss: 0.2142\n",
      "Baseline Loss: 2.8656 | Actual Loss: 2.3460\n",
      "Baseline Loss: 2.7675 | Actual Loss: 0.4827\n",
      "Baseline Loss: 2.8409 | Actual Loss: 0.2524\n",
      "Baseline Loss: 2.8212 | Actual Loss: 0.2120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 223/1000 [01:11<04:03,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8576 | Actual Loss: 0.2139\n",
      "Baseline Loss: 2.7313 | Actual Loss: 0.2385\n",
      "Baseline Loss: 2.8124 | Actual Loss: 2.3765\n",
      "Baseline Loss: 2.8077 | Actual Loss: 0.4432\n",
      "Baseline Loss: 2.8373 | Actual Loss: 0.2582\n",
      "Baseline Loss: 2.7779 | Actual Loss: 0.1787\n",
      "Baseline Loss: 2.4577 | Actual Loss: 0.8734\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5191\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7117\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5251\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3918\n",
      "Epoch 223/1000: Train Loss: 0.5884, Val Loss: 0.5369\n",
      "Baseline Loss: 2.8184 | Actual Loss: 0.2048\n",
      "Baseline Loss: 2.7715 | Actual Loss: 0.3128\n",
      "Baseline Loss: 2.8485 | Actual Loss: 0.5323\n",
      "Baseline Loss: 2.7870 | Actual Loss: 0.3822\n",
      "Baseline Loss: 2.7668 | Actual Loss: 1.3133\n",
      "Baseline Loss: 2.7940 | Actual Loss: 0.2586\n",
      "Baseline Loss: 2.8623 | Actual Loss: 1.5516\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.2202\n",
      "Baseline Loss: 2.7646 | Actual Loss: 0.5432\n",
      "Baseline Loss: 2.9440 | Actual Loss: 0.1971\n",
      "Baseline Loss: 2.8346 | Actual Loss: 0.2404\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2175\n",
      "Baseline Loss: 2.8103 | Actual Loss: 0.8993\n",
      "Baseline Loss: 2.8392 | Actual Loss: 0.1938\n",
      "Baseline Loss: 2.7755 | Actual Loss: 0.4484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 224/1000 [01:11<04:06,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5900 | Actual Loss: 1.6132\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4708\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6868\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5388\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3630\n",
      "Epoch 224/1000: Train Loss: 0.5705, Val Loss: 0.5148\n",
      "Baseline Loss: 2.8744 | Actual Loss: 0.2315\n",
      "Baseline Loss: 2.8651 | Actual Loss: 1.6576\n",
      "Baseline Loss: 2.8612 | Actual Loss: 0.5151\n",
      "Baseline Loss: 2.8267 | Actual Loss: 0.1235\n",
      "Baseline Loss: 2.7522 | Actual Loss: 0.1098\n",
      "Baseline Loss: 2.8311 | Actual Loss: 0.3611\n",
      "Baseline Loss: 2.8683 | Actual Loss: 0.2610\n",
      "Baseline Loss: 2.7880 | Actual Loss: 0.1248\n",
      "Baseline Loss: 2.8449 | Actual Loss: 0.3680\n",
      "Baseline Loss: 2.7817 | Actual Loss: 0.3486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▎       | 225/1000 [01:11<03:51,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7694 | Actual Loss: 0.6489\n",
      "Baseline Loss: 2.8830 | Actual Loss: 0.3827\n",
      "Baseline Loss: 2.8183 | Actual Loss: 0.1140\n",
      "Baseline Loss: 2.8461 | Actual Loss: 0.3324\n",
      "Baseline Loss: 2.8370 | Actual Loss: 0.6562\n",
      "Baseline Loss: 2.5451 | Actual Loss: 2.0991\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5666\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7863\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4334\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.1583\n",
      "Epoch 225/1000: Train Loss: 0.5209, Val Loss: 0.4862\n",
      "Baseline Loss: 2.7716 | Actual Loss: 0.2926\n",
      "Baseline Loss: 2.7981 | Actual Loss: 1.2313\n",
      "Baseline Loss: 2.8648 | Actual Loss: 0.4201\n",
      "Baseline Loss: 2.7592 | Actual Loss: 0.4184\n",
      "Baseline Loss: 2.7940 | Actual Loss: 0.3089\n",
      "Baseline Loss: 2.7664 | Actual Loss: 0.1597\n",
      "Baseline Loss: 2.8674 | Actual Loss: 0.2961\n",
      "Baseline Loss: 2.8800 | Actual Loss: 0.2216\n",
      "Baseline Loss: 2.8487 | Actual Loss: 0.5168\n",
      "Baseline Loss: 2.8338 | Actual Loss: 0.1641\n",
      "Baseline Loss: 2.8649 | Actual Loss: 0.2856\n",
      "Baseline Loss: 2.7939 | Actual Loss: 0.2015\n",
      "Baseline Loss: 2.8122 | Actual Loss: 0.2250\n",
      "Baseline Loss: 2.7842 | Actual Loss: 0.2081\n",
      "Baseline Loss: 2.8422 | Actual Loss: 0.2115\n",
      "Baseline Loss: 2.4756 | Actual Loss: 2.0810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 226/1000 [01:12<04:04,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8199 | Actual Loss: 0.5179\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8252\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.3921\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2345\n",
      "Epoch 226/1000: Train Loss: 0.4526, Val Loss: 0.4924\n",
      "Baseline Loss: 2.8696 | Actual Loss: 0.1282\n",
      "Baseline Loss: 2.8064 | Actual Loss: 0.0761\n",
      "Baseline Loss: 2.8277 | Actual Loss: 0.2134\n",
      "Baseline Loss: 2.7788 | Actual Loss: 0.3433\n",
      "Baseline Loss: 2.7857 | Actual Loss: 0.2231\n",
      "Baseline Loss: 2.7805 | Actual Loss: 0.4415\n",
      "Baseline Loss: 2.8169 | Actual Loss: 0.1959\n",
      "Baseline Loss: 2.7509 | Actual Loss: 0.3098\n",
      "Baseline Loss: 2.8780 | Actual Loss: 3.0596\n",
      "Baseline Loss: 2.9387 | Actual Loss: 0.5698\n",
      "Baseline Loss: 2.8786 | Actual Loss: 0.2102\n",
      "Baseline Loss: 2.7485 | Actual Loss: 1.6901\n",
      "Baseline Loss: 2.8805 | Actual Loss: 0.1189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 227/1000 [01:12<04:08,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8439 | Actual Loss: 0.1319\n",
      "Baseline Loss: 2.7610 | Actual Loss: 0.3852\n",
      "Baseline Loss: 2.4879 | Actual Loss: 1.6461\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4488\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6910\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4425\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.1678\n",
      "Epoch 227/1000: Train Loss: 0.6090, Val Loss: 0.4375\n",
      "New best validation loss: 0.4375\n",
      "Baseline Loss: 2.8833 | Actual Loss: 0.2953\n",
      "Baseline Loss: 2.7930 | Actual Loss: 0.5684\n",
      "Baseline Loss: 2.8318 | Actual Loss: 0.5364\n",
      "Baseline Loss: 2.8157 | Actual Loss: 2.1798\n",
      "Baseline Loss: 2.8388 | Actual Loss: 0.1894\n",
      "Baseline Loss: 2.8304 | Actual Loss: 0.2699\n",
      "Baseline Loss: 2.7907 | Actual Loss: 0.2394\n",
      "Baseline Loss: 2.7531 | Actual Loss: 0.2714\n",
      "Baseline Loss: 2.7609 | Actual Loss: 0.2859\n",
      "Baseline Loss: 2.8501 | Actual Loss: 0.2391\n",
      "Baseline Loss: 2.9092 | Actual Loss: 2.1778\n",
      "Baseline Loss: 2.7558 | Actual Loss: 0.5369\n",
      "Baseline Loss: 2.8742 | Actual Loss: 0.2609\n",
      "Baseline Loss: 2.7972 | Actual Loss: 0.2494\n",
      "Baseline Loss: 2.8612 | Actual Loss: 0.4871\n",
      "Baseline Loss: 2.5288 | Actual Loss: 2.2055\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5160\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6756\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 228/1000 [01:12<03:53,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7254 | Actual Loss: 0.3993\n",
      "Epoch 228/1000: Train Loss: 0.6870, Val Loss: 0.5257\n",
      "Baseline Loss: 2.7872 | Actual Loss: 0.0694\n",
      "Baseline Loss: 2.8045 | Actual Loss: 0.2548\n",
      "Baseline Loss: 2.8324 | Actual Loss: 0.5037\n",
      "Baseline Loss: 2.8426 | Actual Loss: 0.2194\n",
      "Baseline Loss: 2.8672 | Actual Loss: 0.8914\n",
      "Baseline Loss: 2.8018 | Actual Loss: 0.7979\n",
      "Baseline Loss: 2.7870 | Actual Loss: 0.1259\n",
      "Baseline Loss: 2.8127 | Actual Loss: 0.1484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 229/1000 [01:13<04:02,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8023 | Actual Loss: 2.4083\n",
      "Baseline Loss: 2.9684 | Actual Loss: 0.8607\n",
      "Baseline Loss: 2.8457 | Actual Loss: 0.1247\n",
      "Baseline Loss: 2.8895 | Actual Loss: 0.6513\n",
      "Baseline Loss: 2.7978 | Actual Loss: 0.2075\n",
      "Baseline Loss: 2.7979 | Actual Loss: 0.4912\n",
      "Baseline Loss: 2.8174 | Actual Loss: 0.2603\n",
      "Baseline Loss: 2.5244 | Actual Loss: 0.2813\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4944\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7821\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4929\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2899\n",
      "Epoch 229/1000: Train Loss: 0.5185, Val Loss: 0.5148\n",
      "Baseline Loss: 2.8411 | Actual Loss: 0.1915\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.3923\n",
      "Baseline Loss: 2.8491 | Actual Loss: 0.2187\n",
      "Baseline Loss: 2.7706 | Actual Loss: 0.2410\n",
      "Baseline Loss: 2.7922 | Actual Loss: 0.2252\n",
      "Baseline Loss: 2.7696 | Actual Loss: 0.1843\n",
      "Baseline Loss: 2.7841 | Actual Loss: 0.3478\n",
      "Baseline Loss: 2.7622 | Actual Loss: 0.3537\n",
      "Baseline Loss: 2.8496 | Actual Loss: 0.6997\n",
      "Baseline Loss: 2.7982 | Actual Loss: 0.5609\n",
      "Baseline Loss: 2.8604 | Actual Loss: 2.1223\n",
      "Baseline Loss: 2.7879 | Actual Loss: 0.2010\n",
      "Baseline Loss: 2.7873 | Actual Loss: 0.3226\n",
      "Baseline Loss: 2.8444 | Actual Loss: 0.3510\n",
      "Baseline Loss: 2.8526 | Actual Loss: 0.1099\n",
      "Baseline Loss: 2.5729 | Actual Loss: 0.0602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 230/1000 [01:13<04:08,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8199 | Actual Loss: 0.5916\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7461\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4042\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2780\n",
      "Epoch 230/1000: Train Loss: 0.4114, Val Loss: 0.5050\n",
      "Baseline Loss: 2.8614 | Actual Loss: 0.5627\n",
      "Baseline Loss: 2.8116 | Actual Loss: 0.4527\n",
      "Baseline Loss: 2.7978 | Actual Loss: 0.6000\n",
      "Baseline Loss: 2.7791 | Actual Loss: 0.3507\n",
      "Baseline Loss: 2.8458 | Actual Loss: 0.2633\n",
      "Baseline Loss: 2.7934 | Actual Loss: 0.3717\n",
      "Baseline Loss: 2.8018 | Actual Loss: 0.7119\n",
      "Baseline Loss: 2.8871 | Actual Loss: 0.4756\n",
      "Baseline Loss: 2.8523 | Actual Loss: 0.1994\n",
      "Baseline Loss: 2.8630 | Actual Loss: 0.5855\n",
      "Baseline Loss: 2.8116 | Actual Loss: 0.3345\n",
      "Baseline Loss: 2.8382 | Actual Loss: 0.2010\n",
      "Baseline Loss: 2.8155 | Actual Loss: 2.5637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 231/1000 [01:13<03:52,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8160 | Actual Loss: 2.1807\n",
      "Baseline Loss: 2.8109 | Actual Loss: 0.1904\n",
      "Baseline Loss: 2.6351 | Actual Loss: 0.1400\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4912\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6904\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.3918\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.4090\n",
      "Epoch 231/1000: Train Loss: 0.6365, Val Loss: 0.4956\n",
      "Baseline Loss: 2.8146 | Actual Loss: 0.6053\n",
      "Baseline Loss: 2.8035 | Actual Loss: 0.6022\n",
      "Baseline Loss: 2.8358 | Actual Loss: 0.2940\n",
      "Baseline Loss: 2.9008 | Actual Loss: 0.3276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 232/1000 [01:14<04:00,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8421 | Actual Loss: 0.2322\n",
      "Baseline Loss: 2.8785 | Actual Loss: 0.2394\n",
      "Baseline Loss: 2.8038 | Actual Loss: 0.4630\n",
      "Baseline Loss: 2.7706 | Actual Loss: 0.3533\n",
      "Baseline Loss: 2.8931 | Actual Loss: 0.2194\n",
      "Baseline Loss: 2.8242 | Actual Loss: 0.5455\n",
      "Baseline Loss: 2.8931 | Actual Loss: 0.3143\n",
      "Baseline Loss: 2.8722 | Actual Loss: 0.0725\n",
      "Baseline Loss: 2.7950 | Actual Loss: 0.2095\n",
      "Baseline Loss: 2.8467 | Actual Loss: 0.4900\n",
      "Baseline Loss: 2.8133 | Actual Loss: 0.3133\n",
      "Baseline Loss: 2.6641 | Actual Loss: 2.8366\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.7756\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7485\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4914\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2954\n",
      "Epoch 232/1000: Train Loss: 0.5074, Val Loss: 0.5777\n",
      "Baseline Loss: 2.9290 | Actual Loss: 0.2102\n",
      "Baseline Loss: 2.8553 | Actual Loss: 0.4874\n",
      "Baseline Loss: 2.8484 | Actual Loss: 0.0768\n",
      "Baseline Loss: 2.7886 | Actual Loss: 0.5004\n",
      "Baseline Loss: 2.8433 | Actual Loss: 0.5897\n",
      "Baseline Loss: 2.7092 | Actual Loss: 0.2468\n",
      "Baseline Loss: 2.7976 | Actual Loss: 0.5001\n",
      "Baseline Loss: 2.8107 | Actual Loss: 0.2620\n",
      "Baseline Loss: 2.9138 | Actual Loss: 0.2454\n",
      "Baseline Loss: 2.7862 | Actual Loss: 0.2975\n",
      "Baseline Loss: 2.8087 | Actual Loss: 0.5488\n",
      "Baseline Loss: 2.8392 | Actual Loss: 2.6718\n",
      "Baseline Loss: 2.8158 | Actual Loss: 0.2411\n",
      "Baseline Loss: 2.8601 | Actual Loss: 0.1078\n",
      "Baseline Loss: 2.9622 | Actual Loss: 2.5942\n",
      "Baseline Loss: 2.5389 | Actual Loss: 1.4537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 233/1000 [01:14<04:07,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8199 | Actual Loss: 0.4951\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7202\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.3822\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2718\n",
      "Epoch 233/1000: Train Loss: 0.6896, Val Loss: 0.4673\n",
      "Baseline Loss: 2.8199 | Actual Loss: 3.0161\n",
      "Baseline Loss: 2.8732 | Actual Loss: 0.3480\n",
      "Baseline Loss: 2.8848 | Actual Loss: 2.6798\n",
      "Baseline Loss: 2.8012 | Actual Loss: 2.2812\n",
      "Baseline Loss: 2.9223 | Actual Loss: 0.0956\n",
      "Baseline Loss: 2.7929 | Actual Loss: 0.3388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 234/1000 [01:14<03:48,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7778 | Actual Loss: 0.6995\n",
      "Baseline Loss: 2.8623 | Actual Loss: 0.3507\n",
      "Baseline Loss: 2.7712 | Actual Loss: 0.0835\n",
      "Baseline Loss: 2.7591 | Actual Loss: 0.2373\n",
      "Baseline Loss: 2.8078 | Actual Loss: 0.2926\n",
      "Baseline Loss: 2.8205 | Actual Loss: 0.1994\n",
      "Baseline Loss: 2.8091 | Actual Loss: 0.4209\n",
      "Baseline Loss: 2.8281 | Actual Loss: 0.1493\n",
      "Baseline Loss: 2.8339 | Actual Loss: 0.6219\n",
      "Baseline Loss: 2.5350 | Actual Loss: 0.4904\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4927\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6581\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.3617\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2737\n",
      "Epoch 234/1000: Train Loss: 0.7691, Val Loss: 0.4465\n",
      "Baseline Loss: 2.8480 | Actual Loss: 0.5498\n",
      "Baseline Loss: 2.7792 | Actual Loss: 0.4654\n",
      "Baseline Loss: 2.8154 | Actual Loss: 0.3408\n",
      "Baseline Loss: 2.7862 | Actual Loss: 0.4952\n",
      "Baseline Loss: 2.7993 | Actual Loss: 0.1548\n",
      "Baseline Loss: 2.8084 | Actual Loss: 0.1949\n",
      "Baseline Loss: 2.8408 | Actual Loss: 0.4734\n",
      "Baseline Loss: 2.8659 | Actual Loss: 0.3255\n",
      "Baseline Loss: 2.9045 | Actual Loss: 0.4711\n",
      "Baseline Loss: 2.8449 | Actual Loss: 0.5301\n",
      "Baseline Loss: 2.7787 | Actual Loss: 0.4373\n",
      "Baseline Loss: 2.8462 | Actual Loss: 0.1934\n",
      "Baseline Loss: 2.8284 | Actual Loss: 0.3597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██▎       | 235/1000 [01:14<04:02,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7933 | Actual Loss: 0.1487\n",
      "Baseline Loss: 2.8083 | Actual Loss: 0.4366\n",
      "Baseline Loss: 2.5586 | Actual Loss: 0.4509\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4639\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.1308\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4085\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2312\n",
      "Epoch 235/1000: Train Loss: 0.3767, Val Loss: 0.5586\n",
      "Baseline Loss: 2.8237 | Actual Loss: 0.6026\n",
      "Baseline Loss: 2.8864 | Actual Loss: 0.7338\n",
      "Baseline Loss: 2.8124 | Actual Loss: 0.2946\n",
      "Baseline Loss: 2.7640 | Actual Loss: 0.4596\n",
      "Baseline Loss: 2.8019 | Actual Loss: 0.3878\n",
      "Baseline Loss: 2.8505 | Actual Loss: 0.2474\n",
      "Baseline Loss: 2.8879 | Actual Loss: 2.0640\n",
      "Baseline Loss: 2.8705 | Actual Loss: 0.1321\n",
      "Baseline Loss: 2.8518 | Actual Loss: 0.1260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██▎       | 236/1000 [01:15<03:46,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8457 | Actual Loss: 0.2404\n",
      "Baseline Loss: 2.8584 | Actual Loss: 0.2890\n",
      "Baseline Loss: 2.8704 | Actual Loss: 2.2734\n",
      "Baseline Loss: 2.8113 | Actual Loss: 0.1183\n",
      "Baseline Loss: 2.7794 | Actual Loss: 0.4565\n",
      "Baseline Loss: 2.7030 | Actual Loss: 0.1382\n",
      "Baseline Loss: 2.5834 | Actual Loss: 0.1569\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5253\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7217\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4859\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.1332\n",
      "Epoch 236/1000: Train Loss: 0.5450, Val Loss: 0.4665\n",
      "Baseline Loss: 2.8389 | Actual Loss: 0.2633\n",
      "Baseline Loss: 2.8926 | Actual Loss: 2.3883\n",
      "Baseline Loss: 2.9308 | Actual Loss: 0.3828\n",
      "Baseline Loss: 2.8050 | Actual Loss: 0.4566\n",
      "Baseline Loss: 2.8081 | Actual Loss: 0.4904\n",
      "Baseline Loss: 2.8467 | Actual Loss: 0.2406\n",
      "Baseline Loss: 2.8182 | Actual Loss: 0.9551\n",
      "Baseline Loss: 2.8007 | Actual Loss: 0.4294\n",
      "Baseline Loss: 2.7783 | Actual Loss: 0.3888\n",
      "Baseline Loss: 2.7590 | Actual Loss: 0.1079\n",
      "Baseline Loss: 2.7983 | Actual Loss: 1.1670\n",
      "Baseline Loss: 2.7600 | Actual Loss: 0.3892\n",
      "Baseline Loss: 2.8273 | Actual Loss: 0.2416\n",
      "Baseline Loss: 2.8733 | Actual Loss: 0.7186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██▎       | 237/1000 [01:15<03:56,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8818 | Actual Loss: 0.3802\n",
      "Baseline Loss: 2.4273 | Actual Loss: 0.2429\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4986\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6350\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4113\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2780\n",
      "Epoch 237/1000: Train Loss: 0.5777, Val Loss: 0.4557\n",
      "Baseline Loss: 2.8752 | Actual Loss: 0.5545\n",
      "Baseline Loss: 2.8552 | Actual Loss: 2.0667\n",
      "Baseline Loss: 2.8325 | Actual Loss: 0.1764\n",
      "Baseline Loss: 2.8132 | Actual Loss: 0.2702\n",
      "Baseline Loss: 2.7793 | Actual Loss: 0.5719\n",
      "Baseline Loss: 2.8570 | Actual Loss: 0.3719\n",
      "Baseline Loss: 2.8551 | Actual Loss: 0.1223\n",
      "Baseline Loss: 2.9313 | Actual Loss: 0.3287\n",
      "Baseline Loss: 2.7890 | Actual Loss: 0.2604\n",
      "Baseline Loss: 2.8449 | Actual Loss: 0.2149\n",
      "Baseline Loss: 2.8006 | Actual Loss: 0.4783\n",
      "Baseline Loss: 2.7750 | Actual Loss: 0.4029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██▍       | 238/1000 [01:15<03:44,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7903 | Actual Loss: 0.1827\n",
      "Baseline Loss: 2.8019 | Actual Loss: 0.4705\n",
      "Baseline Loss: 2.7970 | Actual Loss: 0.1180\n",
      "Baseline Loss: 2.5359 | Actual Loss: 0.3392\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.6220\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8903\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4688\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3167\n",
      "Epoch 238/1000: Train Loss: 0.4331, Val Loss: 0.5745\n",
      "Baseline Loss: 2.7907 | Actual Loss: 0.3684\n",
      "Baseline Loss: 2.7939 | Actual Loss: 0.2780\n",
      "Baseline Loss: 2.8262 | Actual Loss: 1.9713\n",
      "Baseline Loss: 2.7821 | Actual Loss: 0.4888\n",
      "Baseline Loss: 2.8512 | Actual Loss: 0.3116\n",
      "Baseline Loss: 2.8154 | Actual Loss: 0.1937\n",
      "Baseline Loss: 2.8816 | Actual Loss: 0.2473\n",
      "Baseline Loss: 2.8005 | Actual Loss: 0.5650\n",
      "Baseline Loss: 2.8594 | Actual Loss: 0.2985\n",
      "Baseline Loss: 2.8305 | Actual Loss: 0.1189\n",
      "Baseline Loss: 2.8562 | Actual Loss: 0.3992\n",
      "Baseline Loss: 2.8667 | Actual Loss: 0.4840\n",
      "Baseline Loss: 2.8485 | Actual Loss: 0.2819\n",
      "Baseline Loss: 2.8243 | Actual Loss: 0.1918\n",
      "Baseline Loss: 2.7911 | Actual Loss: 0.2852\n",
      "Baseline Loss: 2.5427 | Actual Loss: 0.2204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██▍       | 239/1000 [01:16<03:55,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8199 | Actual Loss: 0.7037\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8784\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4537\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2392\n",
      "Epoch 239/1000: Train Loss: 0.4190, Val Loss: 0.5687\n",
      "Baseline Loss: 2.7965 | Actual Loss: 0.5207\n",
      "Baseline Loss: 2.7506 | Actual Loss: 0.1971\n",
      "Baseline Loss: 2.8047 | Actual Loss: 1.4380\n",
      "Baseline Loss: 2.8236 | Actual Loss: 0.3642\n",
      "Baseline Loss: 2.8624 | Actual Loss: 0.5243\n",
      "Baseline Loss: 2.8306 | Actual Loss: 0.2745\n",
      "Baseline Loss: 2.8549 | Actual Loss: 0.9646\n",
      "Baseline Loss: 2.8158 | Actual Loss: 0.3986\n",
      "Baseline Loss: 2.8375 | Actual Loss: 0.5396\n",
      "Baseline Loss: 2.7665 | Actual Loss: 0.2077\n",
      "Baseline Loss: 2.8360 | Actual Loss: 0.3242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██▍       | 240/1000 [01:16<04:05,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8501 | Actual Loss: 0.2534\n",
      "Baseline Loss: 2.8724 | Actual Loss: 0.4282\n",
      "Baseline Loss: 2.8578 | Actual Loss: 0.5600\n",
      "Baseline Loss: 2.7878 | Actual Loss: 0.1115\n",
      "Baseline Loss: 2.5244 | Actual Loss: 0.2377\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5270\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6745\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.3330\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2302\n",
      "Epoch 240/1000: Train Loss: 0.4590, Val Loss: 0.4412\n",
      "Baseline Loss: 2.8432 | Actual Loss: 0.2451\n",
      "Baseline Loss: 2.8556 | Actual Loss: 0.2492\n",
      "Baseline Loss: 2.7811 | Actual Loss: 0.2430\n",
      "Baseline Loss: 2.8427 | Actual Loss: 0.4495\n",
      "Baseline Loss: 2.8115 | Actual Loss: 0.5361\n",
      "Baseline Loss: 2.8420 | Actual Loss: 2.3244\n",
      "Baseline Loss: 2.7355 | Actual Loss: 0.4199\n",
      "Baseline Loss: 2.8989 | Actual Loss: 0.4997\n",
      "Baseline Loss: 2.8533 | Actual Loss: 0.5039\n",
      "Baseline Loss: 2.8010 | Actual Loss: 0.5535\n",
      "Baseline Loss: 2.7765 | Actual Loss: 0.1511\n",
      "Baseline Loss: 2.8092 | Actual Loss: 0.2153\n",
      "Baseline Loss: 2.8781 | Actual Loss: 0.2264\n",
      "Baseline Loss: 2.7922 | Actual Loss: 0.0672\n",
      "Baseline Loss: 2.9154 | Actual Loss: 0.2136\n",
      "Baseline Loss: 2.5421 | Actual Loss: 0.0837\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.2905\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██▍       | 241/1000 [01:16<04:06,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7998 | Actual Loss: 0.4309\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.1182\n",
      "Epoch 241/1000: Train Loss: 0.4363, Val Loss: 0.3897\n",
      "New best validation loss: 0.3897\n",
      "Baseline Loss: 2.8120 | Actual Loss: 0.5792\n",
      "Baseline Loss: 2.8374 | Actual Loss: 0.5361\n",
      "Baseline Loss: 2.7737 | Actual Loss: 0.2019\n",
      "Baseline Loss: 2.8812 | Actual Loss: 0.5489\n",
      "Baseline Loss: 2.8449 | Actual Loss: 0.4911\n",
      "Baseline Loss: 2.7882 | Actual Loss: 0.5136\n",
      "Baseline Loss: 2.8286 | Actual Loss: 0.0857\n",
      "Baseline Loss: 2.8179 | Actual Loss: 0.2982\n",
      "Baseline Loss: 2.8380 | Actual Loss: 0.4581\n",
      "Baseline Loss: 2.8854 | Actual Loss: 0.0823\n",
      "Baseline Loss: 2.8416 | Actual Loss: 0.1895\n",
      "Baseline Loss: 2.7776 | Actual Loss: 0.4852\n",
      "Baseline Loss: 2.8396 | Actual Loss: 0.2517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██▍       | 242/1000 [01:17<03:54,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8225 | Actual Loss: 0.2183\n",
      "Baseline Loss: 2.8746 | Actual Loss: 0.6527\n",
      "Baseline Loss: 2.5971 | Actual Loss: 0.3310\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.6598\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6424\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5557\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.1465\n",
      "Epoch 242/1000: Train Loss: 0.3702, Val Loss: 0.5011\n",
      "Baseline Loss: 2.8411 | Actual Loss: 0.5502\n",
      "Baseline Loss: 2.8247 | Actual Loss: 0.4143\n",
      "Baseline Loss: 2.8587 | Actual Loss: 2.4304\n",
      "Baseline Loss: 2.8894 | Actual Loss: 0.2594\n",
      "Baseline Loss: 2.7898 | Actual Loss: 0.1267\n",
      "Baseline Loss: 2.7976 | Actual Loss: 0.3865\n",
      "Baseline Loss: 2.8384 | Actual Loss: 0.3525\n",
      "Baseline Loss: 2.7814 | Actual Loss: 0.2292\n",
      "Baseline Loss: 2.7990 | Actual Loss: 0.3892\n",
      "Baseline Loss: 2.7732 | Actual Loss: 0.1935\n",
      "Baseline Loss: 2.7860 | Actual Loss: 0.2632\n",
      "Baseline Loss: 2.7964 | Actual Loss: 0.3007\n",
      "Baseline Loss: 2.8031 | Actual Loss: 0.2143\n",
      "Baseline Loss: 2.8058 | Actual Loss: 0.2120\n",
      "Baseline Loss: 2.8404 | Actual Loss: 0.2092\n",
      "Baseline Loss: 2.6806 | Actual Loss: 0.0963\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5649\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6996\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██▍       | 243/1000 [01:17<03:59,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7254 | Actual Loss: 0.1206\n",
      "Epoch 243/1000: Train Loss: 0.4142, Val Loss: 0.4790\n",
      "Baseline Loss: 2.8223 | Actual Loss: 0.2167\n",
      "Baseline Loss: 2.7835 | Actual Loss: 0.6155\n",
      "Baseline Loss: 2.8565 | Actual Loss: 0.1430\n",
      "Baseline Loss: 2.8312 | Actual Loss: 0.2339\n",
      "Baseline Loss: 2.7944 | Actual Loss: 0.2602\n",
      "Baseline Loss: 2.8321 | Actual Loss: 0.5263\n",
      "Baseline Loss: 2.7646 | Actual Loss: 0.5152\n",
      "Baseline Loss: 2.8155 | Actual Loss: 2.0568\n",
      "Baseline Loss: 2.8592 | Actual Loss: 0.2919\n",
      "Baseline Loss: 2.8832 | Actual Loss: 0.3927\n",
      "Baseline Loss: 2.8090 | Actual Loss: 0.4415\n",
      "Baseline Loss: 2.8658 | Actual Loss: 0.4966\n",
      "Baseline Loss: 2.7952 | Actual Loss: 0.6113\n",
      "Baseline Loss: 2.7724 | Actual Loss: 0.0670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██▍       | 244/1000 [01:17<03:49,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8146 | Actual Loss: 0.1999\n",
      "Baseline Loss: 2.6597 | Actual Loss: 0.0444\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4853\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.9012\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.3666\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.1676\n",
      "Epoch 244/1000: Train Loss: 0.4446, Val Loss: 0.4802\n",
      "Baseline Loss: 2.7771 | Actual Loss: 0.2241\n",
      "Baseline Loss: 2.8264 | Actual Loss: 0.9549\n",
      "Baseline Loss: 2.8296 | Actual Loss: 0.1273\n",
      "Baseline Loss: 2.8725 | Actual Loss: 0.1987\n",
      "Baseline Loss: 2.8081 | Actual Loss: 2.0472\n",
      "Baseline Loss: 2.8032 | Actual Loss: 0.5504\n",
      "Baseline Loss: 2.8012 | Actual Loss: 0.1051\n",
      "Baseline Loss: 2.8171 | Actual Loss: 0.3164\n",
      "Baseline Loss: 2.8409 | Actual Loss: 0.2529\n",
      "Baseline Loss: 2.8047 | Actual Loss: 0.6418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██▍       | 245/1000 [01:18<03:57,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8973 | Actual Loss: 0.5148\n",
      "Baseline Loss: 2.8236 | Actual Loss: 0.4611\n",
      "Baseline Loss: 2.8651 | Actual Loss: 0.2752\n",
      "Baseline Loss: 2.8114 | Actual Loss: 0.3314\n",
      "Baseline Loss: 2.8405 | Actual Loss: 0.2267\n",
      "Baseline Loss: 2.4351 | Actual Loss: 0.7492\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4588\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8177\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.3427\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3134\n",
      "Epoch 245/1000: Train Loss: 0.4986, Val Loss: 0.4832\n",
      "Baseline Loss: 2.8195 | Actual Loss: 0.5021\n",
      "Baseline Loss: 2.8402 | Actual Loss: 1.3270\n",
      "Baseline Loss: 2.8499 | Actual Loss: 0.3843\n",
      "Baseline Loss: 2.8101 | Actual Loss: 0.1083\n",
      "Baseline Loss: 2.8228 | Actual Loss: 1.8862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▍       | 246/1000 [01:18<03:42,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9162 | Actual Loss: 2.0206\n",
      "Baseline Loss: 2.8539 | Actual Loss: 0.0827\n",
      "Baseline Loss: 2.7596 | Actual Loss: 0.0912\n",
      "Baseline Loss: 2.8461 | Actual Loss: 0.2309\n",
      "Baseline Loss: 2.8241 | Actual Loss: 0.4113\n",
      "Baseline Loss: 2.8891 | Actual Loss: 0.7729\n",
      "Baseline Loss: 2.8830 | Actual Loss: 0.1154\n",
      "Baseline Loss: 2.8020 | Actual Loss: 0.2621\n",
      "Baseline Loss: 2.8058 | Actual Loss: 0.2177\n",
      "Baseline Loss: 2.8350 | Actual Loss: 0.5468\n",
      "Baseline Loss: 2.4267 | Actual Loss: 0.2516\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.3948\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8525\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.3559\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.1312\n",
      "Epoch 246/1000: Train Loss: 0.5757, Val Loss: 0.4336\n",
      "Baseline Loss: 2.8370 | Actual Loss: 0.2131\n",
      "Baseline Loss: 2.8098 | Actual Loss: 0.2763\n",
      "Baseline Loss: 2.7482 | Actual Loss: 0.2518\n",
      "Baseline Loss: 2.8699 | Actual Loss: 0.4754\n",
      "Baseline Loss: 2.8080 | Actual Loss: 0.5263\n",
      "Baseline Loss: 2.8069 | Actual Loss: 0.5643\n",
      "Baseline Loss: 2.8010 | Actual Loss: 0.9510\n",
      "Baseline Loss: 2.9263 | Actual Loss: 2.5261\n",
      "Baseline Loss: 2.7611 | Actual Loss: 0.2901\n",
      "Baseline Loss: 2.8004 | Actual Loss: 0.3427\n",
      "Baseline Loss: 2.8780 | Actual Loss: 0.2302\n",
      "Baseline Loss: 2.8554 | Actual Loss: 0.1127\n",
      "Baseline Loss: 2.8642 | Actual Loss: 0.2674\n",
      "Baseline Loss: 2.8683 | Actual Loss: 0.4733\n",
      "Baseline Loss: 2.8182 | Actual Loss: 0.3457\n",
      "Baseline Loss: 2.6102 | Actual Loss: 0.1003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▍       | 247/1000 [01:18<03:55,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8199 | Actual Loss: 0.5506\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6435\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5198\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.1944\n",
      "Epoch 247/1000: Train Loss: 0.4967, Val Loss: 0.4771\n",
      "Baseline Loss: 2.7840 | Actual Loss: 0.2100\n",
      "Baseline Loss: 2.8421 | Actual Loss: 0.3578\n",
      "Baseline Loss: 2.8762 | Actual Loss: 0.9534\n",
      "Baseline Loss: 2.7259 | Actual Loss: 0.1957\n",
      "Baseline Loss: 2.8016 | Actual Loss: 0.2606\n",
      "Baseline Loss: 2.8812 | Actual Loss: 0.4238\n",
      "Baseline Loss: 2.8868 | Actual Loss: 0.4164\n",
      "Baseline Loss: 2.8129 | Actual Loss: 0.4620\n",
      "Baseline Loss: 2.7953 | Actual Loss: 2.7094\n",
      "Baseline Loss: 2.7975 | Actual Loss: 0.2751\n",
      "Baseline Loss: 2.7958 | Actual Loss: 0.2250\n",
      "Baseline Loss: 2.8168 | Actual Loss: 0.4636\n",
      "Baseline Loss: 2.8529 | Actual Loss: 1.9322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▍       | 248/1000 [01:18<04:01,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8302 | Actual Loss: 0.1171\n",
      "Baseline Loss: 2.8506 | Actual Loss: 2.4301\n",
      "Baseline Loss: 2.4442 | Actual Loss: 0.0856\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4737\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6334\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4882\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3843\n",
      "Epoch 248/1000: Train Loss: 0.7199, Val Loss: 0.4949\n",
      "Baseline Loss: 2.8385 | Actual Loss: 0.2247\n",
      "Baseline Loss: 2.8406 | Actual Loss: 0.3259\n",
      "Baseline Loss: 2.8111 | Actual Loss: 0.5355\n",
      "Baseline Loss: 2.8231 | Actual Loss: 0.3463\n",
      "Baseline Loss: 2.7529 | Actual Loss: 0.1147\n",
      "Baseline Loss: 2.8905 | Actual Loss: 0.1955\n",
      "Baseline Loss: 2.8541 | Actual Loss: 0.5272\n",
      "Baseline Loss: 2.8485 | Actual Loss: 0.2595\n",
      "Baseline Loss: 2.8286 | Actual Loss: 0.8782\n",
      "Baseline Loss: 2.7987 | Actual Loss: 0.1384\n",
      "Baseline Loss: 2.8144 | Actual Loss: 1.8269\n",
      "Baseline Loss: 2.8609 | Actual Loss: 0.1877\n",
      "Baseline Loss: 2.7637 | Actual Loss: 0.1283\n",
      "Baseline Loss: 2.7955 | Actual Loss: 1.8608\n",
      "Baseline Loss: 2.8024 | Actual Loss: 0.1454\n",
      "Baseline Loss: 2.5418 | Actual Loss: 1.2129\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4959\n",
      "Baseline Loss: 2.8180 | Actual Loss: 1.1323\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.3888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▍       | 249/1000 [01:19<03:45,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7254 | Actual Loss: 0.4225\n",
      "Epoch 249/1000: Train Loss: 0.5567, Val Loss: 0.6099\n",
      "Baseline Loss: 2.8594 | Actual Loss: 0.2438\n",
      "Baseline Loss: 2.8526 | Actual Loss: 0.3038\n",
      "Baseline Loss: 2.8432 | Actual Loss: 0.4018\n",
      "Baseline Loss: 2.8209 | Actual Loss: 0.1245\n",
      "Baseline Loss: 2.8698 | Actual Loss: 0.2248\n",
      "Baseline Loss: 2.8411 | Actual Loss: 0.2635\n",
      "Baseline Loss: 2.8360 | Actual Loss: 0.4893\n",
      "Baseline Loss: 2.7776 | Actual Loss: 0.2509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▌       | 250/1000 [01:19<03:51,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6874 | Actual Loss: 0.2121\n",
      "Baseline Loss: 2.8306 | Actual Loss: 0.6269\n",
      "Baseline Loss: 2.8382 | Actual Loss: 0.2792\n",
      "Baseline Loss: 2.8195 | Actual Loss: 0.2253\n",
      "Baseline Loss: 2.8496 | Actual Loss: 0.1166\n",
      "Baseline Loss: 2.8264 | Actual Loss: 1.8257\n",
      "Baseline Loss: 2.8728 | Actual Loss: 0.4763\n",
      "Baseline Loss: 2.4986 | Actual Loss: 0.0857\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4495\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7170\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.3356\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2789\n",
      "Epoch 250/1000: Train Loss: 0.3844, Val Loss: 0.4453\n",
      "Baseline Loss: 2.8057 | Actual Loss: 0.3290\n",
      "Baseline Loss: 2.8218 | Actual Loss: 0.1834\n",
      "Baseline Loss: 2.9218 | Actual Loss: 0.2167\n",
      "Baseline Loss: 2.8148 | Actual Loss: 0.0695\n",
      "Baseline Loss: 2.7171 | Actual Loss: 0.4562\n",
      "Baseline Loss: 2.8007 | Actual Loss: 0.2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▌       | 251/1000 [01:19<03:42,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7682 | Actual Loss: 0.1998\n",
      "Baseline Loss: 2.8402 | Actual Loss: 0.3798\n",
      "Baseline Loss: 2.8500 | Actual Loss: 0.2365\n",
      "Baseline Loss: 2.8127 | Actual Loss: 0.1104\n",
      "Baseline Loss: 2.7871 | Actual Loss: 0.2932\n",
      "Baseline Loss: 2.8626 | Actual Loss: 0.2243\n",
      "Baseline Loss: 2.8616 | Actual Loss: 1.6510\n",
      "Baseline Loss: 2.8121 | Actual Loss: 0.3596\n",
      "Baseline Loss: 2.8771 | Actual Loss: 1.7288\n",
      "Baseline Loss: 2.5877 | Actual Loss: 2.0722\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4897\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7522\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4650\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2495\n",
      "Epoch 251/1000: Train Loss: 0.5445, Val Loss: 0.4891\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.4644\n",
      "Baseline Loss: 2.8117 | Actual Loss: 0.2776\n",
      "Baseline Loss: 2.8653 | Actual Loss: 0.3176\n",
      "Baseline Loss: 2.7652 | Actual Loss: 0.2658\n",
      "Baseline Loss: 2.8197 | Actual Loss: 0.1851\n",
      "Baseline Loss: 2.8312 | Actual Loss: 0.1099\n",
      "Baseline Loss: 2.8551 | Actual Loss: 0.2642\n",
      "Baseline Loss: 2.8372 | Actual Loss: 0.5025\n",
      "Baseline Loss: 2.7820 | Actual Loss: 2.0001\n",
      "Baseline Loss: 2.8708 | Actual Loss: 2.2310\n",
      "Baseline Loss: 2.7905 | Actual Loss: 0.1831\n",
      "Baseline Loss: 2.8101 | Actual Loss: 0.3363\n",
      "Baseline Loss: 2.8035 | Actual Loss: 0.5060\n",
      "Baseline Loss: 2.8765 | Actual Loss: 0.5866\n",
      "Baseline Loss: 2.8276 | Actual Loss: 0.3655\n",
      "Baseline Loss: 2.6925 | Actual Loss: 0.2614\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4982\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▌       | 252/1000 [01:20<03:48,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7998 | Actual Loss: 0.3284\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2109\n",
      "Epoch 252/1000: Train Loss: 0.5536, Val Loss: 0.4436\n",
      "Baseline Loss: 2.7336 | Actual Loss: 0.2233\n",
      "Baseline Loss: 2.8094 | Actual Loss: 2.3677\n",
      "Baseline Loss: 2.8760 | Actual Loss: 0.2370\n",
      "Baseline Loss: 2.8731 | Actual Loss: 0.1202\n",
      "Baseline Loss: 2.7770 | Actual Loss: 0.2555\n",
      "Baseline Loss: 2.7758 | Actual Loss: 0.4552\n",
      "Baseline Loss: 2.8109 | Actual Loss: 0.4407\n",
      "Baseline Loss: 2.8755 | Actual Loss: 0.1979\n",
      "Baseline Loss: 2.7945 | Actual Loss: 1.8870\n",
      "Baseline Loss: 2.8644 | Actual Loss: 0.1190\n",
      "Baseline Loss: 2.7528 | Actual Loss: 0.3261\n",
      "Baseline Loss: 2.8716 | Actual Loss: 0.5521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▌       | 253/1000 [01:20<03:53,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8480 | Actual Loss: 0.6474\n",
      "Baseline Loss: 2.7638 | Actual Loss: 0.2858\n",
      "Baseline Loss: 2.8477 | Actual Loss: 0.2857\n",
      "Baseline Loss: 2.5410 | Actual Loss: 2.0144\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4860\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7042\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4802\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2635\n",
      "Epoch 253/1000: Train Loss: 0.6509, Val Loss: 0.4835\n",
      "Baseline Loss: 2.7562 | Actual Loss: 2.4710\n",
      "Baseline Loss: 2.8109 | Actual Loss: 0.2972\n",
      "Baseline Loss: 2.8191 | Actual Loss: 0.3981\n",
      "Baseline Loss: 2.7956 | Actual Loss: 0.3909\n",
      "Baseline Loss: 2.8269 | Actual Loss: 1.9373\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.1094\n",
      "Baseline Loss: 2.7977 | Actual Loss: 0.2941\n",
      "Baseline Loss: 2.8731 | Actual Loss: 0.3686\n",
      "Baseline Loss: 2.8145 | Actual Loss: 0.4348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▌       | 254/1000 [01:20<03:43,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7799 | Actual Loss: 0.7981\n",
      "Baseline Loss: 2.8125 | Actual Loss: 0.1363\n",
      "Baseline Loss: 2.8874 | Actual Loss: 0.2632\n",
      "Baseline Loss: 2.9195 | Actual Loss: 0.4775\n",
      "Baseline Loss: 2.8194 | Actual Loss: 0.4826\n",
      "Baseline Loss: 2.8358 | Actual Loss: 0.9955\n",
      "Baseline Loss: 2.6357 | Actual Loss: 1.6981\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5118\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8598\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5143\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3833\n",
      "Epoch 254/1000: Train Loss: 0.7220, Val Loss: 0.5673\n",
      "Baseline Loss: 2.7766 | Actual Loss: 0.6116\n",
      "Baseline Loss: 2.8628 | Actual Loss: 0.4409\n",
      "Baseline Loss: 2.8537 | Actual Loss: 0.7101\n",
      "Baseline Loss: 2.9125 | Actual Loss: 0.2797\n",
      "Baseline Loss: 2.8632 | Actual Loss: 1.4945\n",
      "Baseline Loss: 2.8208 | Actual Loss: 0.1554\n",
      "Baseline Loss: 2.8157 | Actual Loss: 0.2655\n",
      "Baseline Loss: 2.8226 | Actual Loss: 0.1656\n",
      "Baseline Loss: 2.8276 | Actual Loss: 0.2630\n",
      "Baseline Loss: 2.8647 | Actual Loss: 2.4512\n",
      "Baseline Loss: 2.8352 | Actual Loss: 0.1862\n",
      "Baseline Loss: 2.8344 | Actual Loss: 0.2579\n",
      "Baseline Loss: 2.7693 | Actual Loss: 0.1333\n",
      "Baseline Loss: 2.7659 | Actual Loss: 0.4036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▌       | 255/1000 [01:21<03:56,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8307 | Actual Loss: 0.3175\n",
      "Baseline Loss: 2.5110 | Actual Loss: 0.2968\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5064\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8172\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4924\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.1543\n",
      "Epoch 255/1000: Train Loss: 0.5271, Val Loss: 0.4926\n",
      "Baseline Loss: 2.7638 | Actual Loss: 0.3484\n",
      "Baseline Loss: 2.7966 | Actual Loss: 0.4469\n",
      "Baseline Loss: 2.8408 | Actual Loss: 0.3663\n",
      "Baseline Loss: 2.8308 | Actual Loss: 0.2662\n",
      "Baseline Loss: 2.8381 | Actual Loss: 0.3858\n",
      "Baseline Loss: 2.8620 | Actual Loss: 0.2411\n",
      "Baseline Loss: 2.7778 | Actual Loss: 0.0884\n",
      "Baseline Loss: 2.8240 | Actual Loss: 1.9797\n",
      "Baseline Loss: 2.8124 | Actual Loss: 0.5027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▌       | 256/1000 [01:21<04:02,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7818 | Actual Loss: 0.2563\n",
      "Baseline Loss: 2.7804 | Actual Loss: 0.4898\n",
      "Baseline Loss: 2.8169 | Actual Loss: 0.4276\n",
      "Baseline Loss: 2.9024 | Actual Loss: 1.9324\n",
      "Baseline Loss: 2.8518 | Actual Loss: 0.4427\n",
      "Baseline Loss: 2.9217 | Actual Loss: 0.4605\n",
      "Baseline Loss: 2.5656 | Actual Loss: 0.1332\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5039\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6587\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.3849\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3464\n",
      "Epoch 256/1000: Train Loss: 0.5480, Val Loss: 0.4735\n",
      "Baseline Loss: 2.7320 | Actual Loss: 0.2013\n",
      "Baseline Loss: 2.8325 | Actual Loss: 0.1341\n",
      "Baseline Loss: 2.8054 | Actual Loss: 0.1284\n",
      "Baseline Loss: 2.7857 | Actual Loss: 0.5588\n",
      "Baseline Loss: 2.7839 | Actual Loss: 0.2303\n",
      "Baseline Loss: 2.8086 | Actual Loss: 0.1347\n",
      "Baseline Loss: 2.8124 | Actual Loss: 0.1999\n",
      "Baseline Loss: 2.8520 | Actual Loss: 0.9313\n",
      "Baseline Loss: 2.8868 | Actual Loss: 0.3166\n",
      "Baseline Loss: 2.7718 | Actual Loss: 0.3730\n",
      "Baseline Loss: 2.8032 | Actual Loss: 0.2028\n",
      "Baseline Loss: 2.8041 | Actual Loss: 0.5300\n",
      "Baseline Loss: 2.7771 | Actual Loss: 0.3019\n",
      "Baseline Loss: 2.7876 | Actual Loss: 0.9936\n",
      "Baseline Loss: 2.8496 | Actual Loss: 0.1439\n",
      "Baseline Loss: 2.6854 | Actual Loss: 0.8719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▌       | 257/1000 [01:21<03:44,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8199 | Actual Loss: 0.5268\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6724\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4579\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.1954\n",
      "Epoch 257/1000: Train Loss: 0.3908, Val Loss: 0.4631\n",
      "Baseline Loss: 2.7925 | Actual Loss: 0.6206\n",
      "Baseline Loss: 2.8265 | Actual Loss: 0.1721\n",
      "Baseline Loss: 2.8587 | Actual Loss: 0.3000\n",
      "Baseline Loss: 2.7997 | Actual Loss: 0.1394\n",
      "Baseline Loss: 2.8300 | Actual Loss: 2.1836\n",
      "Baseline Loss: 2.8855 | Actual Loss: 0.1027\n",
      "Baseline Loss: 2.8592 | Actual Loss: 0.5336\n",
      "Baseline Loss: 2.8304 | Actual Loss: 0.8638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▌       | 258/1000 [01:22<03:51,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7922 | Actual Loss: 0.5445\n",
      "Baseline Loss: 2.7276 | Actual Loss: 0.1834\n",
      "Baseline Loss: 2.8059 | Actual Loss: 0.3101\n",
      "Baseline Loss: 2.7052 | Actual Loss: 0.3920\n",
      "Baseline Loss: 2.9337 | Actual Loss: 2.4599\n",
      "Baseline Loss: 2.8131 | Actual Loss: 0.5120\n",
      "Baseline Loss: 2.7948 | Actual Loss: 0.0783\n",
      "Baseline Loss: 2.5822 | Actual Loss: 1.0639\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4861\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7587\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4226\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2866\n",
      "Epoch 258/1000: Train Loss: 0.6537, Val Loss: 0.4885\n",
      "Baseline Loss: 2.7981 | Actual Loss: 0.1192\n",
      "Baseline Loss: 2.8931 | Actual Loss: 0.2211\n",
      "Baseline Loss: 2.8877 | Actual Loss: 0.2486\n",
      "Baseline Loss: 2.8256 | Actual Loss: 0.4300\n",
      "Baseline Loss: 2.7886 | Actual Loss: 0.5710\n",
      "Baseline Loss: 2.7466 | Actual Loss: 0.5200\n",
      "Baseline Loss: 2.8669 | Actual Loss: 0.1357\n",
      "Baseline Loss: 2.8090 | Actual Loss: 0.2892\n",
      "Baseline Loss: 2.8188 | Actual Loss: 0.5492\n",
      "Baseline Loss: 2.8850 | Actual Loss: 0.5832\n",
      "Baseline Loss: 2.8276 | Actual Loss: 0.2156\n",
      "Baseline Loss: 2.8067 | Actual Loss: 0.5034\n",
      "Baseline Loss: 2.8725 | Actual Loss: 0.2190\n",
      "Baseline Loss: 2.8773 | Actual Loss: 0.2661\n",
      "Baseline Loss: 2.7532 | Actual Loss: 0.4743\n",
      "Baseline Loss: 2.4645 | Actual Loss: 0.0482\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5356\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▌       | 259/1000 [01:22<03:55,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7998 | Actual Loss: 0.4654\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2864\n",
      "Epoch 259/1000: Train Loss: 0.3371, Val Loss: 0.5221\n",
      "Baseline Loss: 2.8592 | Actual Loss: 0.1912\n",
      "Baseline Loss: 2.8274 | Actual Loss: 0.2718\n",
      "Baseline Loss: 2.8463 | Actual Loss: 0.3198\n",
      "Baseline Loss: 2.8485 | Actual Loss: 0.0673\n",
      "Baseline Loss: 2.7713 | Actual Loss: 0.2440\n",
      "Baseline Loss: 2.8904 | Actual Loss: 0.7113\n",
      "Baseline Loss: 2.9134 | Actual Loss: 0.1139\n",
      "Baseline Loss: 2.8416 | Actual Loss: 2.3786\n",
      "Baseline Loss: 2.8151 | Actual Loss: 0.2555\n",
      "Baseline Loss: 2.7990 | Actual Loss: 0.1593\n",
      "Baseline Loss: 2.8127 | Actual Loss: 0.2007\n",
      "Baseline Loss: 2.8362 | Actual Loss: 0.3283\n",
      "Baseline Loss: 2.8708 | Actual Loss: 2.2597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▌       | 260/1000 [01:22<03:41,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7670 | Actual Loss: 0.4425\n",
      "Baseline Loss: 2.8198 | Actual Loss: 0.3962\n",
      "Baseline Loss: 2.4798 | Actual Loss: 2.1015\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5067\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8040\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5416\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2485\n",
      "Epoch 260/1000: Train Loss: 0.6526, Val Loss: 0.5252\n",
      "Baseline Loss: 2.8232 | Actual Loss: 0.3043\n",
      "Baseline Loss: 2.7808 | Actual Loss: 0.1858\n",
      "Baseline Loss: 2.7676 | Actual Loss: 0.5097\n",
      "Baseline Loss: 2.9122 | Actual Loss: 0.5343\n",
      "Baseline Loss: 2.8379 | Actual Loss: 0.3161\n",
      "Baseline Loss: 2.7581 | Actual Loss: 0.1140\n",
      "Baseline Loss: 2.8672 | Actual Loss: 0.1375\n",
      "Baseline Loss: 2.8577 | Actual Loss: 0.2010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▌       | 261/1000 [01:22<03:50,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8469 | Actual Loss: 0.3183\n",
      "Baseline Loss: 2.7868 | Actual Loss: 0.2426\n",
      "Baseline Loss: 2.8696 | Actual Loss: 0.2234\n",
      "Baseline Loss: 2.8606 | Actual Loss: 1.3509\n",
      "Baseline Loss: 2.7823 | Actual Loss: 0.2740\n",
      "Baseline Loss: 2.8229 | Actual Loss: 0.2869\n",
      "Baseline Loss: 2.8567 | Actual Loss: 0.3831\n",
      "Baseline Loss: 2.5364 | Actual Loss: 2.0395\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4962\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6931\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.3460\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2071\n",
      "Epoch 261/1000: Train Loss: 0.4638, Val Loss: 0.4356\n",
      "Baseline Loss: 2.7655 | Actual Loss: 0.4277\n",
      "Baseline Loss: 2.8577 | Actual Loss: 0.2055\n",
      "Baseline Loss: 2.8924 | Actual Loss: 0.5477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▌       | 262/1000 [01:23<03:37,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7900 | Actual Loss: 0.2124\n",
      "Baseline Loss: 2.8333 | Actual Loss: 0.8908\n",
      "Baseline Loss: 2.8432 | Actual Loss: 0.1263\n",
      "Baseline Loss: 2.8687 | Actual Loss: 0.2896\n",
      "Baseline Loss: 2.8093 | Actual Loss: 0.3883\n",
      "Baseline Loss: 2.8812 | Actual Loss: 0.6029\n",
      "Baseline Loss: 2.7823 | Actual Loss: 0.2069\n",
      "Baseline Loss: 2.8107 | Actual Loss: 0.2382\n",
      "Baseline Loss: 2.8279 | Actual Loss: 0.1496\n",
      "Baseline Loss: 2.8504 | Actual Loss: 0.3375\n",
      "Baseline Loss: 2.8741 | Actual Loss: 0.3261\n",
      "Baseline Loss: 2.8378 | Actual Loss: 1.1964\n",
      "Baseline Loss: 2.5526 | Actual Loss: 0.5146\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4738\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7423\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4852\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2130\n",
      "Epoch 262/1000: Train Loss: 0.4163, Val Loss: 0.4786\n",
      "Baseline Loss: 2.8319 | Actual Loss: 1.5916\n",
      "Baseline Loss: 2.8302 | Actual Loss: 0.3790\n",
      "Baseline Loss: 2.8231 | Actual Loss: 0.9027\n",
      "Baseline Loss: 2.8171 | Actual Loss: 0.1074\n",
      "Baseline Loss: 2.8193 | Actual Loss: 2.1489\n",
      "Baseline Loss: 2.7774 | Actual Loss: 0.2314\n",
      "Baseline Loss: 2.8816 | Actual Loss: 2.2376\n",
      "Baseline Loss: 2.9452 | Actual Loss: 0.2665\n",
      "Baseline Loss: 2.8159 | Actual Loss: 0.5018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▋       | 263/1000 [01:23<03:45,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8249 | Actual Loss: 0.2594\n",
      "Baseline Loss: 2.7697 | Actual Loss: 0.1833\n",
      "Baseline Loss: 2.7987 | Actual Loss: 0.2417\n",
      "Baseline Loss: 2.7938 | Actual Loss: 0.5028\n",
      "Baseline Loss: 2.8222 | Actual Loss: 0.3200\n",
      "Baseline Loss: 2.8162 | Actual Loss: 0.3232\n",
      "Baseline Loss: 2.5766 | Actual Loss: 0.4088\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5199\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7064\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5109\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.1370\n",
      "Epoch 263/1000: Train Loss: 0.6629, Val Loss: 0.4685\n",
      "Baseline Loss: 2.8077 | Actual Loss: 0.1274\n",
      "Baseline Loss: 2.7322 | Actual Loss: 0.2503\n",
      "Baseline Loss: 2.7952 | Actual Loss: 0.5711\n",
      "Baseline Loss: 2.8009 | Actual Loss: 0.2032\n",
      "Baseline Loss: 2.7994 | Actual Loss: 0.5500\n",
      "Baseline Loss: 2.8294 | Actual Loss: 0.1755\n",
      "Baseline Loss: 2.8152 | Actual Loss: 0.3895\n",
      "Baseline Loss: 2.8420 | Actual Loss: 2.0875\n",
      "Baseline Loss: 2.8177 | Actual Loss: 0.0658\n",
      "Baseline Loss: 2.8373 | Actual Loss: 0.4345\n",
      "Baseline Loss: 2.8315 | Actual Loss: 0.5217\n",
      "Baseline Loss: 2.8115 | Actual Loss: 0.3321\n",
      "Baseline Loss: 2.8392 | Actual Loss: 0.4570\n",
      "Baseline Loss: 2.9063 | Actual Loss: 0.2625\n",
      "Baseline Loss: 2.8736 | Actual Loss: 0.9516\n",
      "Baseline Loss: 2.5800 | Actual Loss: 0.1350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▋       | 264/1000 [01:23<03:52,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8199 | Actual Loss: 0.4962\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6991\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5026\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3852\n",
      "Epoch 264/1000: Train Loss: 0.4697, Val Loss: 0.5208\n",
      "Baseline Loss: 2.8186 | Actual Loss: 0.3274\n",
      "Baseline Loss: 2.8156 | Actual Loss: 2.5116\n",
      "Baseline Loss: 2.8617 | Actual Loss: 0.4896\n",
      "Baseline Loss: 2.8238 | Actual Loss: 0.2235\n",
      "Baseline Loss: 2.9119 | Actual Loss: 0.3582\n",
      "Baseline Loss: 2.8099 | Actual Loss: 0.2641\n",
      "Baseline Loss: 2.8133 | Actual Loss: 1.8595\n",
      "Baseline Loss: 2.7926 | Actual Loss: 0.4080\n",
      "Baseline Loss: 2.8346 | Actual Loss: 2.1977\n",
      "Baseline Loss: 2.8332 | Actual Loss: 0.2641\n",
      "Baseline Loss: 2.8425 | Actual Loss: 0.4464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▋       | 265/1000 [01:24<03:38,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7971 | Actual Loss: 0.1539\n",
      "Baseline Loss: 2.7812 | Actual Loss: 0.6066\n",
      "Baseline Loss: 2.9037 | Actual Loss: 0.4331\n",
      "Baseline Loss: 2.8636 | Actual Loss: 0.1274\n",
      "Baseline Loss: 2.4855 | Actual Loss: 1.6171\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5315\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6647\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4834\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2663\n",
      "Epoch 265/1000: Train Loss: 0.7680, Val Loss: 0.4865\n",
      "Baseline Loss: 2.8269 | Actual Loss: 0.4807\n",
      "Baseline Loss: 2.8479 | Actual Loss: 0.2688\n",
      "Baseline Loss: 2.7847 | Actual Loss: 0.4422\n",
      "Baseline Loss: 2.7840 | Actual Loss: 0.2052\n",
      "Baseline Loss: 2.8298 | Actual Loss: 0.2442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  27%|██▋       | 266/1000 [01:24<03:47,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8624 | Actual Loss: 0.5215\n",
      "Baseline Loss: 2.8102 | Actual Loss: 1.1381\n",
      "Baseline Loss: 2.8245 | Actual Loss: 0.1186\n",
      "Baseline Loss: 2.7456 | Actual Loss: 0.2086\n",
      "Baseline Loss: 2.8665 | Actual Loss: 0.1539\n",
      "Baseline Loss: 2.8129 | Actual Loss: 0.3645\n",
      "Baseline Loss: 2.8458 | Actual Loss: 0.1458\n",
      "Baseline Loss: 2.8438 | Actual Loss: 0.2824\n",
      "Baseline Loss: 2.8308 | Actual Loss: 0.6179\n",
      "Baseline Loss: 2.8352 | Actual Loss: 0.3334\n",
      "Baseline Loss: 2.5760 | Actual Loss: 0.2147\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5906\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8745\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4874\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3954\n",
      "Epoch 266/1000: Train Loss: 0.3588, Val Loss: 0.5869\n",
      "Baseline Loss: 2.7622 | Actual Loss: 0.1178\n",
      "Baseline Loss: 2.7579 | Actual Loss: 2.3562\n",
      "Baseline Loss: 2.8448 | Actual Loss: 0.4752\n",
      "Baseline Loss: 2.7811 | Actual Loss: 0.2922\n",
      "Baseline Loss: 2.8432 | Actual Loss: 0.3404\n",
      "Baseline Loss: 2.7984 | Actual Loss: 1.0055\n",
      "Baseline Loss: 2.8781 | Actual Loss: 0.1699\n",
      "Baseline Loss: 2.8239 | Actual Loss: 0.2624\n",
      "Baseline Loss: 2.8016 | Actual Loss: 0.1252\n",
      "Baseline Loss: 2.8216 | Actual Loss: 0.2649\n",
      "Baseline Loss: 2.8242 | Actual Loss: 0.2434\n",
      "Baseline Loss: 2.9220 | Actual Loss: 0.2087\n",
      "Baseline Loss: 2.8093 | Actual Loss: 0.4140\n",
      "Baseline Loss: 2.8570 | Actual Loss: 0.2516\n",
      "Baseline Loss: 2.8318 | Actual Loss: 0.1697\n",
      "Baseline Loss: 2.6729 | Actual Loss: 2.5995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  27%|██▋       | 267/1000 [01:24<03:54,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8199 | Actual Loss: 0.6012\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7484\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5101\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3807\n",
      "Epoch 267/1000: Train Loss: 0.5810, Val Loss: 0.5601\n",
      "Baseline Loss: 2.7847 | Actual Loss: 0.4926\n",
      "Baseline Loss: 2.7926 | Actual Loss: 0.6202\n",
      "Baseline Loss: 2.8058 | Actual Loss: 0.3006\n",
      "Baseline Loss: 2.9068 | Actual Loss: 0.3165\n",
      "Baseline Loss: 2.8457 | Actual Loss: 0.1751\n",
      "Baseline Loss: 2.9245 | Actual Loss: 0.2016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  27%|██▋       | 268/1000 [01:25<03:39,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7890 | Actual Loss: 0.5062\n",
      "Baseline Loss: 2.7851 | Actual Loss: 0.7990\n",
      "Baseline Loss: 2.8456 | Actual Loss: 0.2199\n",
      "Baseline Loss: 2.8835 | Actual Loss: 0.1929\n",
      "Baseline Loss: 2.8295 | Actual Loss: 0.1928\n",
      "Baseline Loss: 2.7981 | Actual Loss: 0.3330\n",
      "Baseline Loss: 2.8397 | Actual Loss: 0.4928\n",
      "Baseline Loss: 2.8512 | Actual Loss: 0.7109\n",
      "Baseline Loss: 2.7940 | Actual Loss: 0.2138\n",
      "Baseline Loss: 2.6064 | Actual Loss: 0.2807\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4943\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7023\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.3512\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2672\n",
      "Epoch 268/1000: Train Loss: 0.3780, Val Loss: 0.4538\n",
      "Baseline Loss: 2.8842 | Actual Loss: 0.2139\n",
      "Baseline Loss: 2.7917 | Actual Loss: 0.3180\n",
      "Baseline Loss: 2.8360 | Actual Loss: 0.3664\n",
      "Baseline Loss: 2.8802 | Actual Loss: 0.1113\n",
      "Baseline Loss: 2.8277 | Actual Loss: 0.2265\n",
      "Baseline Loss: 2.8573 | Actual Loss: 0.1947\n",
      "Baseline Loss: 2.7882 | Actual Loss: 0.2401\n",
      "Baseline Loss: 2.8577 | Actual Loss: 0.2409\n",
      "Baseline Loss: 2.8351 | Actual Loss: 0.4567\n",
      "Baseline Loss: 2.8421 | Actual Loss: 0.3361\n",
      "Baseline Loss: 2.8238 | Actual Loss: 0.2120\n",
      "Baseline Loss: 2.8208 | Actual Loss: 0.1667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  27%|██▋       | 269/1000 [01:25<03:44,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8243 | Actual Loss: 0.2540\n",
      "Baseline Loss: 2.7941 | Actual Loss: 0.3378\n",
      "Baseline Loss: 2.8136 | Actual Loss: 0.3958\n",
      "Baseline Loss: 2.6818 | Actual Loss: 2.3686\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5725\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6474\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4927\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2989\n",
      "Epoch 269/1000: Train Loss: 0.4025, Val Loss: 0.5029\n",
      "Baseline Loss: 2.8876 | Actual Loss: 0.2733\n",
      "Baseline Loss: 2.8573 | Actual Loss: 0.3122\n",
      "Baseline Loss: 2.9010 | Actual Loss: 0.6851\n",
      "Baseline Loss: 2.8695 | Actual Loss: 0.3495\n",
      "Baseline Loss: 2.7890 | Actual Loss: 0.3772\n",
      "Baseline Loss: 2.8364 | Actual Loss: 0.1230\n",
      "Baseline Loss: 2.8349 | Actual Loss: 0.1030\n",
      "Baseline Loss: 2.8592 | Actual Loss: 0.1144\n",
      "Baseline Loss: 2.7721 | Actual Loss: 0.4535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  27%|██▋       | 270/1000 [01:25<03:38,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8358 | Actual Loss: 0.2964\n",
      "Baseline Loss: 2.7566 | Actual Loss: 2.3438\n",
      "Baseline Loss: 2.7813 | Actual Loss: 0.3895\n",
      "Baseline Loss: 2.8764 | Actual Loss: 2.4762\n",
      "Baseline Loss: 2.7892 | Actual Loss: 0.3939\n",
      "Baseline Loss: 2.7925 | Actual Loss: 0.4250\n",
      "Baseline Loss: 2.4931 | Actual Loss: 0.0875\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.3231\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8547\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4527\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.4410\n",
      "Epoch 270/1000: Train Loss: 0.5752, Val Loss: 0.5179\n",
      "Baseline Loss: 2.7657 | Actual Loss: 0.2124\n",
      "Baseline Loss: 2.8462 | Actual Loss: 0.1291\n",
      "Baseline Loss: 2.9861 | Actual Loss: 0.4581\n",
      "Baseline Loss: 2.8771 | Actual Loss: 0.1872\n",
      "Baseline Loss: 2.7798 | Actual Loss: 0.3571\n",
      "Baseline Loss: 2.8586 | Actual Loss: 0.2434\n",
      "Baseline Loss: 2.8361 | Actual Loss: 0.3467\n",
      "Baseline Loss: 2.8104 | Actual Loss: 0.1323\n",
      "Baseline Loss: 2.7783 | Actual Loss: 2.2240\n",
      "Baseline Loss: 2.7825 | Actual Loss: 0.4589\n",
      "Baseline Loss: 2.8295 | Actual Loss: 0.2391\n",
      "Baseline Loss: 2.8053 | Actual Loss: 0.9390\n",
      "Baseline Loss: 2.8641 | Actual Loss: 0.3838\n",
      "Baseline Loss: 2.8307 | Actual Loss: 0.2481\n",
      "Baseline Loss: 2.7869 | Actual Loss: 0.2171\n",
      "Baseline Loss: 2.4761 | Actual Loss: 0.1961\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  27%|██▋       | 271/1000 [01:26<03:45,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8180 | Actual Loss: 0.6947\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4614\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3012\n",
      "Epoch 271/1000: Train Loss: 0.4358, Val Loss: 0.4787\n",
      "Baseline Loss: 2.9193 | Actual Loss: 0.2108\n",
      "Baseline Loss: 2.8388 | Actual Loss: 0.1531\n",
      "Baseline Loss: 2.8077 | Actual Loss: 0.0699\n",
      "Baseline Loss: 2.8013 | Actual Loss: 0.1262\n",
      "Baseline Loss: 2.8251 | Actual Loss: 2.0566\n",
      "Baseline Loss: 2.8361 | Actual Loss: 0.2324\n",
      "Baseline Loss: 2.8226 | Actual Loss: 0.2953\n",
      "Baseline Loss: 2.7755 | Actual Loss: 0.5373\n",
      "Baseline Loss: 2.7763 | Actual Loss: 0.2748\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.1363\n",
      "Baseline Loss: 2.7795 | Actual Loss: 0.3641\n",
      "Baseline Loss: 2.8690 | Actual Loss: 0.1985\n",
      "Baseline Loss: 2.8513 | Actual Loss: 0.4002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  27%|██▋       | 272/1000 [01:26<03:49,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8608 | Actual Loss: 2.4926\n",
      "Baseline Loss: 2.8504 | Actual Loss: 0.1411\n",
      "Baseline Loss: 2.5111 | Actual Loss: 0.2177\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4428\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7120\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.3625\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3196\n",
      "Epoch 272/1000: Train Loss: 0.4942, Val Loss: 0.4592\n",
      "Baseline Loss: 2.8858 | Actual Loss: 0.1237\n",
      "Baseline Loss: 2.8332 | Actual Loss: 2.0151\n",
      "Baseline Loss: 2.7202 | Actual Loss: 0.9362\n",
      "Baseline Loss: 2.8350 | Actual Loss: 0.3644\n",
      "Baseline Loss: 2.8031 | Actual Loss: 0.1098\n",
      "Baseline Loss: 2.8445 | Actual Loss: 0.2927\n",
      "Baseline Loss: 2.7922 | Actual Loss: 0.1635\n",
      "Baseline Loss: 2.8577 | Actual Loss: 2.4095\n",
      "Baseline Loss: 2.8034 | Actual Loss: 0.3909\n",
      "Baseline Loss: 2.8318 | Actual Loss: 0.1286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  27%|██▋       | 273/1000 [01:26<03:39,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8302 | Actual Loss: 0.3758\n",
      "Baseline Loss: 2.9090 | Actual Loss: 0.5163\n",
      "Baseline Loss: 2.8623 | Actual Loss: 0.7311\n",
      "Baseline Loss: 2.8220 | Actual Loss: 0.9086\n",
      "Baseline Loss: 2.9139 | Actual Loss: 0.3449\n",
      "Baseline Loss: 2.5089 | Actual Loss: 0.0790\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4564\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6929\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4955\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.1586\n",
      "Epoch 273/1000: Train Loss: 0.6181, Val Loss: 0.4508\n",
      "Baseline Loss: 2.8312 | Actual Loss: 0.3260\n",
      "Baseline Loss: 2.8166 | Actual Loss: 0.3776\n",
      "Baseline Loss: 2.8609 | Actual Loss: 0.1492\n",
      "Baseline Loss: 2.7590 | Actual Loss: 0.1852\n",
      "Baseline Loss: 2.8057 | Actual Loss: 1.2113\n",
      "Baseline Loss: 2.8257 | Actual Loss: 0.2840\n",
      "Baseline Loss: 2.8056 | Actual Loss: 2.1663\n",
      "Baseline Loss: 2.8131 | Actual Loss: 0.2765\n",
      "Baseline Loss: 2.7361 | Actual Loss: 0.2013\n",
      "Baseline Loss: 2.7554 | Actual Loss: 2.3460\n",
      "Baseline Loss: 2.8695 | Actual Loss: 2.0229\n",
      "Baseline Loss: 2.8543 | Actual Loss: 0.6491\n",
      "Baseline Loss: 2.7901 | Actual Loss: 0.2868\n",
      "Baseline Loss: 2.8739 | Actual Loss: 0.2607\n",
      "Baseline Loss: 2.8533 | Actual Loss: 0.7032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  27%|██▋       | 274/1000 [01:26<03:49,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6305 | Actual Loss: 0.3091\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5538\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6320\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4332\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.1571\n",
      "Epoch 274/1000: Train Loss: 0.7347, Val Loss: 0.4440\n",
      "Baseline Loss: 2.8446 | Actual Loss: 2.3659\n",
      "Baseline Loss: 2.8801 | Actual Loss: 2.1486\n",
      "Baseline Loss: 2.7496 | Actual Loss: 0.4544\n",
      "Baseline Loss: 2.8643 | Actual Loss: 0.2109\n",
      "Baseline Loss: 2.8286 | Actual Loss: 0.5849\n",
      "Baseline Loss: 2.8734 | Actual Loss: 0.2211\n",
      "Baseline Loss: 2.7710 | Actual Loss: 0.4572\n",
      "Baseline Loss: 2.8088 | Actual Loss: 0.3089\n",
      "Baseline Loss: 2.8719 | Actual Loss: 0.5988\n",
      "Baseline Loss: 2.8376 | Actual Loss: 0.0841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 275/1000 [01:27<03:39,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8304 | Actual Loss: 0.2391\n",
      "Baseline Loss: 2.8594 | Actual Loss: 0.4439\n",
      "Baseline Loss: 2.8001 | Actual Loss: 0.2955\n",
      "Baseline Loss: 2.8441 | Actual Loss: 0.1516\n",
      "Baseline Loss: 2.7780 | Actual Loss: 0.1166\n",
      "Baseline Loss: 2.3868 | Actual Loss: 0.7015\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4851\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7157\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5052\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.1490\n",
      "Epoch 275/1000: Train Loss: 0.5864, Val Loss: 0.4638\n",
      "Baseline Loss: 2.9764 | Actual Loss: 0.7785\n",
      "Baseline Loss: 2.8378 | Actual Loss: 0.3759\n",
      "Baseline Loss: 2.8288 | Actual Loss: 0.1913\n",
      "Baseline Loss: 2.7800 | Actual Loss: 0.0821\n",
      "Baseline Loss: 2.8264 | Actual Loss: 2.5020\n",
      "Baseline Loss: 2.8416 | Actual Loss: 0.4029\n",
      "Baseline Loss: 2.8224 | Actual Loss: 0.1901\n",
      "Baseline Loss: 2.7769 | Actual Loss: 0.1360\n",
      "Baseline Loss: 2.7801 | Actual Loss: 0.7724\n",
      "Baseline Loss: 2.7937 | Actual Loss: 0.7829\n",
      "Baseline Loss: 2.9006 | Actual Loss: 0.0999\n",
      "Baseline Loss: 2.8766 | Actual Loss: 0.1417\n",
      "Baseline Loss: 2.7922 | Actual Loss: 0.5032\n",
      "Baseline Loss: 2.8120 | Actual Loss: 0.4687\n",
      "Baseline Loss: 2.8746 | Actual Loss: 0.5808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 276/1000 [01:27<03:49,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.4968 | Actual Loss: 1.9788\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.6254\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6268\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.3181\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.1215\n",
      "Epoch 276/1000: Train Loss: 0.6242, Val Loss: 0.4230\n",
      "Baseline Loss: 2.8061 | Actual Loss: 2.5963\n",
      "Baseline Loss: 2.8191 | Actual Loss: 0.2768\n",
      "Baseline Loss: 2.9184 | Actual Loss: 0.1517\n",
      "Baseline Loss: 2.8131 | Actual Loss: 0.3547\n",
      "Baseline Loss: 2.7558 | Actual Loss: 0.2499\n",
      "Baseline Loss: 2.8879 | Actual Loss: 2.0143\n",
      "Baseline Loss: 2.8568 | Actual Loss: 0.4005\n",
      "Baseline Loss: 2.8220 | Actual Loss: 0.3505\n",
      "Baseline Loss: 2.7835 | Actual Loss: 0.1706\n",
      "Baseline Loss: 2.8255 | Actual Loss: 0.3479\n",
      "Baseline Loss: 2.7442 | Actual Loss: 0.2634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 277/1000 [01:27<03:55,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8143 | Actual Loss: 0.2505\n",
      "Baseline Loss: 2.8536 | Actual Loss: 0.7538\n",
      "Baseline Loss: 2.7868 | Actual Loss: 0.3676\n",
      "Baseline Loss: 2.8793 | Actual Loss: 0.1627\n",
      "Baseline Loss: 2.4993 | Actual Loss: 0.0795\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5227\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6836\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4340\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3970\n",
      "Epoch 277/1000: Train Loss: 0.5494, Val Loss: 0.5093\n",
      "Baseline Loss: 2.8776 | Actual Loss: 0.1386\n",
      "Baseline Loss: 2.8792 | Actual Loss: 0.3403\n",
      "Baseline Loss: 2.8314 | Actual Loss: 0.4275\n",
      "Baseline Loss: 2.9043 | Actual Loss: 0.3212\n",
      "Baseline Loss: 2.7824 | Actual Loss: 0.1956\n",
      "Baseline Loss: 2.8160 | Actual Loss: 0.7820\n",
      "Baseline Loss: 2.8079 | Actual Loss: 0.5251\n",
      "Baseline Loss: 2.7739 | Actual Loss: 0.2209\n",
      "Baseline Loss: 2.8362 | Actual Loss: 0.4729\n",
      "Baseline Loss: 2.8374 | Actual Loss: 0.1222\n",
      "Baseline Loss: 2.7994 | Actual Loss: 0.3927\n",
      "Baseline Loss: 2.8317 | Actual Loss: 0.4812\n",
      "Baseline Loss: 2.8238 | Actual Loss: 0.5802\n",
      "Baseline Loss: 2.8325 | Actual Loss: 0.1743\n",
      "Baseline Loss: 2.7383 | Actual Loss: 0.5318\n",
      "Baseline Loss: 2.5978 | Actual Loss: 0.1007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 278/1000 [01:28<04:01,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8199 | Actual Loss: 0.4665\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7397\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4918\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2971\n",
      "Epoch 278/1000: Train Loss: 0.3630, Val Loss: 0.4988\n",
      "Baseline Loss: 2.7675 | Actual Loss: 0.3376\n",
      "Baseline Loss: 2.7768 | Actual Loss: 0.3912\n",
      "Baseline Loss: 2.8580 | Actual Loss: 0.2725\n",
      "Baseline Loss: 2.8108 | Actual Loss: 0.1938\n",
      "Baseline Loss: 2.9215 | Actual Loss: 0.1809\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.2394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 279/1000 [01:28<03:43,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7746 | Actual Loss: 0.5743\n",
      "Baseline Loss: 2.7969 | Actual Loss: 0.2321\n",
      "Baseline Loss: 2.8606 | Actual Loss: 0.4904\n",
      "Baseline Loss: 2.8480 | Actual Loss: 0.3168\n",
      "Baseline Loss: 2.8252 | Actual Loss: 0.7051\n",
      "Baseline Loss: 2.8242 | Actual Loss: 0.2906\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2103\n",
      "Baseline Loss: 2.8784 | Actual Loss: 0.5526\n",
      "Baseline Loss: 2.8462 | Actual Loss: 0.1843\n",
      "Baseline Loss: 2.5883 | Actual Loss: 2.4233\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4818\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8038\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4871\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2572\n",
      "Epoch 279/1000: Train Loss: 0.4747, Val Loss: 0.5075\n",
      "Baseline Loss: 2.7576 | Actual Loss: 0.4589\n",
      "Baseline Loss: 2.8308 | Actual Loss: 1.6891\n",
      "Baseline Loss: 2.8381 | Actual Loss: 0.2048\n",
      "Baseline Loss: 2.8352 | Actual Loss: 0.2139\n",
      "Baseline Loss: 2.8388 | Actual Loss: 0.5227\n",
      "Baseline Loss: 2.8354 | Actual Loss: 0.1844\n",
      "Baseline Loss: 2.8870 | Actual Loss: 0.5261\n",
      "Baseline Loss: 2.7550 | Actual Loss: 0.3891\n",
      "Baseline Loss: 2.8298 | Actual Loss: 0.2909\n",
      "Baseline Loss: 2.8573 | Actual Loss: 0.2042\n",
      "Baseline Loss: 2.7953 | Actual Loss: 0.6049\n",
      "Baseline Loss: 2.7828 | Actual Loss: 0.4735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 280/1000 [01:28<03:52,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8659 | Actual Loss: 0.1196\n",
      "Baseline Loss: 2.8969 | Actual Loss: 2.5337\n",
      "Baseline Loss: 2.8015 | Actual Loss: 0.4134\n",
      "Baseline Loss: 2.4904 | Actual Loss: 0.5375\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5242\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7840\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4230\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3361\n",
      "Epoch 280/1000: Train Loss: 0.5854, Val Loss: 0.5168\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.4000\n",
      "Baseline Loss: 2.8098 | Actual Loss: 2.2782\n",
      "Baseline Loss: 2.7670 | Actual Loss: 0.2282\n",
      "Baseline Loss: 2.8346 | Actual Loss: 0.4380\n",
      "Baseline Loss: 2.8301 | Actual Loss: 2.1781\n",
      "Baseline Loss: 2.7426 | Actual Loss: 0.4876\n",
      "Baseline Loss: 2.7919 | Actual Loss: 0.3641\n",
      "Baseline Loss: 2.8692 | Actual Loss: 0.2223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 281/1000 [01:29<03:37,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8456 | Actual Loss: 0.1213\n",
      "Baseline Loss: 2.7946 | Actual Loss: 0.2121\n",
      "Baseline Loss: 2.8880 | Actual Loss: 1.4904\n",
      "Baseline Loss: 2.8273 | Actual Loss: 0.1739\n",
      "Baseline Loss: 2.7783 | Actual Loss: 0.2188\n",
      "Baseline Loss: 2.8400 | Actual Loss: 0.1212\n",
      "Baseline Loss: 2.8323 | Actual Loss: 0.2182\n",
      "Baseline Loss: 2.4934 | Actual Loss: 1.1117\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4975\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6307\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4212\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3810\n",
      "Epoch 281/1000: Train Loss: 0.6415, Val Loss: 0.4826\n",
      "Baseline Loss: 2.7444 | Actual Loss: 2.5464\n",
      "Baseline Loss: 2.8454 | Actual Loss: 0.7299\n",
      "Baseline Loss: 2.8343 | Actual Loss: 0.7564\n",
      "Baseline Loss: 2.8010 | Actual Loss: 0.2478\n",
      "Baseline Loss: 2.8040 | Actual Loss: 0.9218\n",
      "Baseline Loss: 2.8689 | Actual Loss: 0.3294\n",
      "Baseline Loss: 2.7827 | Actual Loss: 2.5282\n",
      "Baseline Loss: 2.8739 | Actual Loss: 0.1719\n",
      "Baseline Loss: 2.8390 | Actual Loss: 0.2190\n",
      "Baseline Loss: 2.8491 | Actual Loss: 0.1992\n",
      "Baseline Loss: 2.7933 | Actual Loss: 0.1943\n",
      "Baseline Loss: 2.8628 | Actual Loss: 0.4302\n",
      "Baseline Loss: 2.8585 | Actual Loss: 0.0646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 282/1000 [01:29<03:44,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7531 | Actual Loss: 2.3425\n",
      "Baseline Loss: 2.8001 | Actual Loss: 0.1691\n",
      "Baseline Loss: 2.5726 | Actual Loss: 0.1455\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4323\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6763\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4465\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2588\n",
      "Epoch 282/1000: Train Loss: 0.7498, Val Loss: 0.4535\n",
      "Baseline Loss: 2.8535 | Actual Loss: 0.2062\n",
      "Baseline Loss: 2.8543 | Actual Loss: 0.2299\n",
      "Baseline Loss: 2.8502 | Actual Loss: 0.8753\n",
      "Baseline Loss: 2.7544 | Actual Loss: 0.2737\n",
      "Baseline Loss: 2.8318 | Actual Loss: 0.2130\n",
      "Baseline Loss: 2.8454 | Actual Loss: 0.1911\n",
      "Baseline Loss: 2.8287 | Actual Loss: 0.5531\n",
      "Baseline Loss: 2.7930 | Actual Loss: 0.1206\n",
      "Baseline Loss: 2.8202 | Actual Loss: 1.0905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 283/1000 [01:29<03:35,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8391 | Actual Loss: 0.4006\n",
      "Baseline Loss: 2.8543 | Actual Loss: 0.1849\n",
      "Baseline Loss: 2.8223 | Actual Loss: 0.4844\n",
      "Baseline Loss: 2.8168 | Actual Loss: 0.1339\n",
      "Baseline Loss: 2.7661 | Actual Loss: 0.1898\n",
      "Baseline Loss: 2.8656 | Actual Loss: 2.5696\n",
      "Baseline Loss: 2.6723 | Actual Loss: 0.2392\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4769\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7410\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5841\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3625\n",
      "Epoch 283/1000: Train Loss: 0.4972, Val Loss: 0.5411\n",
      "Baseline Loss: 2.8317 | Actual Loss: 0.1372\n",
      "Baseline Loss: 2.7568 | Actual Loss: 0.3127\n",
      "Baseline Loss: 2.8779 | Actual Loss: 0.2944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 284/1000 [01:30<03:39,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8238 | Actual Loss: 2.1353\n",
      "Baseline Loss: 2.7634 | Actual Loss: 0.2620\n",
      "Baseline Loss: 2.8244 | Actual Loss: 0.2793\n",
      "Baseline Loss: 2.8492 | Actual Loss: 2.3551\n",
      "Baseline Loss: 2.8850 | Actual Loss: 0.5065\n",
      "Baseline Loss: 2.9234 | Actual Loss: 0.2566\n",
      "Baseline Loss: 2.7337 | Actual Loss: 0.2483\n",
      "Baseline Loss: 2.8468 | Actual Loss: 0.2467\n",
      "Baseline Loss: 2.8747 | Actual Loss: 0.4133\n",
      "Baseline Loss: 2.7948 | Actual Loss: 0.4998\n",
      "Baseline Loss: 2.7816 | Actual Loss: 0.1060\n",
      "Baseline Loss: 2.8400 | Actual Loss: 0.2215\n",
      "Baseline Loss: 2.5640 | Actual Loss: 1.7194\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4616\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6979\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4638\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.4147\n",
      "Epoch 284/1000: Train Loss: 0.6246, Val Loss: 0.5095\n",
      "Baseline Loss: 2.7835 | Actual Loss: 0.2732\n",
      "Baseline Loss: 2.8260 | Actual Loss: 0.5004\n",
      "Baseline Loss: 2.8169 | Actual Loss: 2.0867\n",
      "Baseline Loss: 2.7934 | Actual Loss: 0.6853\n",
      "Baseline Loss: 2.7844 | Actual Loss: 0.4312\n",
      "Baseline Loss: 2.8648 | Actual Loss: 0.4983\n",
      "Baseline Loss: 2.8350 | Actual Loss: 0.0698\n",
      "Baseline Loss: 2.8695 | Actual Loss: 1.7705\n",
      "Baseline Loss: 2.8178 | Actual Loss: 0.1775\n",
      "Baseline Loss: 2.7994 | Actual Loss: 0.2037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 285/1000 [01:30<03:43,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7714 | Actual Loss: 0.2226\n",
      "Baseline Loss: 2.8676 | Actual Loss: 2.5673\n",
      "Baseline Loss: 2.7827 | Actual Loss: 1.7803\n",
      "Baseline Loss: 2.8257 | Actual Loss: 0.1753\n",
      "Baseline Loss: 2.8387 | Actual Loss: 0.5176\n",
      "Baseline Loss: 2.5890 | Actual Loss: 0.1084\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4825\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7122\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4641\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3642\n",
      "Epoch 285/1000: Train Loss: 0.7543, Val Loss: 0.5058\n",
      "Baseline Loss: 2.8364 | Actual Loss: 0.2310\n",
      "Baseline Loss: 2.7968 | Actual Loss: 0.1975\n",
      "Baseline Loss: 2.8182 | Actual Loss: 0.2285\n",
      "Baseline Loss: 2.9103 | Actual Loss: 0.3252\n",
      "Baseline Loss: 2.8115 | Actual Loss: 0.5569\n",
      "Baseline Loss: 2.8038 | Actual Loss: 2.4061\n",
      "Baseline Loss: 2.8346 | Actual Loss: 0.4836\n",
      "Baseline Loss: 2.8725 | Actual Loss: 0.4190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  29%|██▊       | 286/1000 [01:30<03:33,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8616 | Actual Loss: 0.1925\n",
      "Baseline Loss: 2.8023 | Actual Loss: 1.5688\n",
      "Baseline Loss: 2.7724 | Actual Loss: 0.1767\n",
      "Baseline Loss: 2.8645 | Actual Loss: 0.1598\n",
      "Baseline Loss: 2.8397 | Actual Loss: 0.1243\n",
      "Baseline Loss: 2.7898 | Actual Loss: 0.5240\n",
      "Baseline Loss: 2.8457 | Actual Loss: 0.3835\n",
      "Baseline Loss: 2.5571 | Actual Loss: 0.1826\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5154\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6732\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4281\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3853\n",
      "Epoch 286/1000: Train Loss: 0.5100, Val Loss: 0.5005\n",
      "Baseline Loss: 2.7718 | Actual Loss: 0.3255\n",
      "Baseline Loss: 2.8722 | Actual Loss: 0.1085\n",
      "Baseline Loss: 2.8837 | Actual Loss: 0.2450\n",
      "Baseline Loss: 2.8444 | Actual Loss: 0.2055\n",
      "Baseline Loss: 2.8546 | Actual Loss: 0.4191\n",
      "Baseline Loss: 2.8781 | Actual Loss: 0.5856\n",
      "Baseline Loss: 2.8507 | Actual Loss: 0.4380\n",
      "Baseline Loss: 2.7905 | Actual Loss: 0.3487\n",
      "Baseline Loss: 2.8364 | Actual Loss: 0.1076\n",
      "Baseline Loss: 2.8051 | Actual Loss: 0.3058\n",
      "Baseline Loss: 2.7927 | Actual Loss: 1.9982\n",
      "Baseline Loss: 2.8245 | Actual Loss: 0.5656\n",
      "Baseline Loss: 2.8286 | Actual Loss: 0.3542\n",
      "Baseline Loss: 2.8264 | Actual Loss: 0.5103\n",
      "Baseline Loss: 2.8622 | Actual Loss: 0.1288\n",
      "Baseline Loss: 2.5008 | Actual Loss: 0.0397\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5055\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  29%|██▊       | 287/1000 [01:31<03:39,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7998 | Actual Loss: 0.4277\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.2061\n",
      "Epoch 287/1000: Train Loss: 0.4179, Val Loss: 0.4494\n",
      "Baseline Loss: 2.8740 | Actual Loss: 0.1313\n",
      "Baseline Loss: 2.8243 | Actual Loss: 0.2243\n",
      "Baseline Loss: 2.7662 | Actual Loss: 0.3146\n",
      "Baseline Loss: 2.8622 | Actual Loss: 0.2117\n",
      "Baseline Loss: 2.8509 | Actual Loss: 0.2125\n",
      "Baseline Loss: 2.8799 | Actual Loss: 0.2315\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.4071\n",
      "Baseline Loss: 2.8636 | Actual Loss: 0.8079\n",
      "Baseline Loss: 2.8048 | Actual Loss: 0.1934\n",
      "Baseline Loss: 2.8055 | Actual Loss: 0.2692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  29%|██▉       | 288/1000 [01:31<03:41,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8075 | Actual Loss: 0.5371\n",
      "Baseline Loss: 2.7657 | Actual Loss: 0.3888\n",
      "Baseline Loss: 2.8287 | Actual Loss: 0.1605\n",
      "Baseline Loss: 2.7693 | Actual Loss: 0.2279\n",
      "Baseline Loss: 2.8656 | Actual Loss: 0.1486\n",
      "Baseline Loss: 2.5484 | Actual Loss: 0.0557\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.6445\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6616\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4256\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.1802\n",
      "Epoch 288/1000: Train Loss: 0.2826, Val Loss: 0.4780\n",
      "Baseline Loss: 2.7825 | Actual Loss: 1.1164\n",
      "Baseline Loss: 2.9638 | Actual Loss: 0.6000\n",
      "Baseline Loss: 2.7880 | Actual Loss: 0.4723\n",
      "Baseline Loss: 2.8160 | Actual Loss: 0.2819\n",
      "Baseline Loss: 2.8607 | Actual Loss: 0.3177\n",
      "Baseline Loss: 2.8308 | Actual Loss: 0.1288\n",
      "Baseline Loss: 2.9340 | Actual Loss: 2.1963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  29%|██▉       | 289/1000 [01:31<03:35,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7790 | Actual Loss: 0.1539\n",
      "Baseline Loss: 2.8288 | Actual Loss: 0.4746\n",
      "Baseline Loss: 2.8350 | Actual Loss: 0.2407\n",
      "Baseline Loss: 2.7819 | Actual Loss: 0.5103\n",
      "Baseline Loss: 2.7580 | Actual Loss: 0.0990\n",
      "Baseline Loss: 2.7892 | Actual Loss: 0.2852\n",
      "Baseline Loss: 2.8862 | Actual Loss: 0.4692\n",
      "Baseline Loss: 2.8608 | Actual Loss: 0.1554\n",
      "Baseline Loss: 2.6711 | Actual Loss: 0.1116\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4743\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.6909\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.5476\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3051\n",
      "Epoch 289/1000: Train Loss: 0.4758, Val Loss: 0.5045\n",
      "Baseline Loss: 2.7536 | Actual Loss: 0.1519\n",
      "Baseline Loss: 2.8611 | Actual Loss: 1.1524\n",
      "Baseline Loss: 2.8398 | Actual Loss: 1.0668\n",
      "Baseline Loss: 2.8307 | Actual Loss: 0.1281\n",
      "Baseline Loss: 2.8146 | Actual Loss: 0.2695\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.4054\n",
      "Baseline Loss: 2.8755 | Actual Loss: 0.1173\n",
      "Baseline Loss: 2.8762 | Actual Loss: 0.3889\n",
      "Baseline Loss: 2.7889 | Actual Loss: 0.2731\n",
      "Baseline Loss: 2.7962 | Actual Loss: 0.1764\n",
      "Baseline Loss: 2.8260 | Actual Loss: 0.1286\n",
      "Baseline Loss: 2.8605 | Actual Loss: 2.4543\n",
      "Baseline Loss: 2.7677 | Actual Loss: 0.2106\n",
      "Baseline Loss: 2.8639 | Actual Loss: 0.4453\n",
      "Baseline Loss: 2.7759 | Actual Loss: 2.1055\n",
      "Baseline Loss: 2.6312 | Actual Loss: 0.0566\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5761\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.7130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  29%|██▉       | 290/1000 [01:31<03:41,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7998 | Actual Loss: 0.5000\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.1310\n",
      "Epoch 290/1000: Train Loss: 0.5957, Val Loss: 0.4800\n",
      "Baseline Loss: 2.7888 | Actual Loss: 0.2110\n",
      "Baseline Loss: 2.9081 | Actual Loss: 0.3743\n",
      "Baseline Loss: 2.8064 | Actual Loss: 0.3463\n",
      "Baseline Loss: 2.8519 | Actual Loss: 0.2327\n",
      "Baseline Loss: 2.8195 | Actual Loss: 0.2169\n",
      "Baseline Loss: 2.7729 | Actual Loss: 1.0418\n",
      "Baseline Loss: 2.8238 | Actual Loss: 0.3157\n",
      "Baseline Loss: 2.8332 | Actual Loss: 0.2299\n",
      "Baseline Loss: 2.8683 | Actual Loss: 0.5073\n",
      "Baseline Loss: 2.8463 | Actual Loss: 0.5232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  29%|██▉       | 290/1000 [01:32<03:45,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8217 | Actual Loss: 0.6348\n",
      "Baseline Loss: 2.7782 | Actual Loss: 0.0851\n",
      "Baseline Loss: 2.7851 | Actual Loss: 0.2295\n",
      "Baseline Loss: 2.7780 | Actual Loss: 0.2425\n",
      "Baseline Loss: 2.8923 | Actual Loss: 0.1179\n",
      "Baseline Loss: 2.5353 | Actual Loss: 0.1355\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5362\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.8782\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.4417\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3127\n",
      "Epoch 291/1000: Train Loss: 0.3403, Val Loss: 0.5422\n",
      "\n",
      "Early stopping at epoch 291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.38972920924425125"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.train_model(\n",
    "    data_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35fe71e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = GNNModelWithNewLoss(\n",
    "        num_node_features=data_list[0].x.shape[1],\n",
    "        num_edge_features=data_list[0].edge_attr.shape[1],\n",
    "        num_global_features=data_list[0].global_features.shape[1],\n",
    "        hidden_dim=512,\n",
    "        dropout_rate=0.1,\n",
    "        property_index=1 ,\n",
    "        save_path= 'premodels_new/3/1'\n",
    "    ).to(devices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48b63c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training will be saved to: premodels_new/3/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7151 | Actual Loss: 2.6712\n",
      "Baseline Loss: 2.7067 | Actual Loss: 2.6770\n",
      "Baseline Loss: 2.6591 | Actual Loss: 2.6410\n",
      "Baseline Loss: 2.6534 | Actual Loss: 2.6127\n",
      "Baseline Loss: 2.6895 | Actual Loss: 2.6639\n",
      "Baseline Loss: 2.7035 | Actual Loss: 2.6885\n",
      "Baseline Loss: 2.6749 | Actual Loss: 2.6179\n",
      "Baseline Loss: 2.6621 | Actual Loss: 2.6071\n",
      "Baseline Loss: 2.6678 | Actual Loss: 2.6389\n",
      "Baseline Loss: 2.6641 | Actual Loss: 2.6349\n",
      "Baseline Loss: 2.6866 | Actual Loss: 2.6708\n",
      "Baseline Loss: 2.6412 | Actual Loss: 2.5849\n",
      "Baseline Loss: 2.6940 | Actual Loss: 2.6186\n",
      "Baseline Loss: 2.6731 | Actual Loss: 2.6128\n",
      "Baseline Loss: 2.6698 | Actual Loss: 2.6491\n",
      "Baseline Loss: 2.2060 | Actual Loss: 2.1880\n",
      "Baseline Loss: 2.6907 | Actual Loss: 2.6403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 1/1000 [00:00<04:38,  3.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6644 | Actual Loss: 2.6058\n",
      "Baseline Loss: 2.6840 | Actual Loss: 2.6185\n",
      "Baseline Loss: 2.6117 | Actual Loss: 2.5763\n",
      "Epoch 1/1000: Train Loss: 2.6111, Val Loss: 2.6102\n",
      "New best validation loss: 2.6102\n",
      "Baseline Loss: 2.6860 | Actual Loss: 2.6464\n",
      "Baseline Loss: 2.7203 | Actual Loss: 2.6887\n",
      "Baseline Loss: 2.6689 | Actual Loss: 2.5720\n",
      "Baseline Loss: 2.6636 | Actual Loss: 2.5985\n",
      "Baseline Loss: 2.6570 | Actual Loss: 2.5865\n",
      "Baseline Loss: 2.6309 | Actual Loss: 2.5922\n",
      "Baseline Loss: 2.6548 | Actual Loss: 2.5866\n",
      "Baseline Loss: 2.6993 | Actual Loss: 2.6473\n",
      "Baseline Loss: 2.6469 | Actual Loss: 2.5963\n",
      "Baseline Loss: 2.7216 | Actual Loss: 2.6122\n",
      "Baseline Loss: 2.6307 | Actual Loss: 2.5324\n",
      "Baseline Loss: 2.6895 | Actual Loss: 2.5695\n",
      "Baseline Loss: 2.6897 | Actual Loss: 2.5624\n",
      "Baseline Loss: 2.7139 | Actual Loss: 2.6407\n",
      "Baseline Loss: 2.6745 | Actual Loss: 2.6804\n",
      "Baseline Loss: 2.2809 | Actual Loss: 2.1752\n",
      "Baseline Loss: 2.6907 | Actual Loss: 2.5803\n",
      "Baseline Loss: 2.6644 | Actual Loss: 2.5598\n",
      "Baseline Loss: 2.6840 | Actual Loss: 2.5404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 2/1000 [00:00<05:24,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6117 | Actual Loss: 2.5257\n",
      "Epoch 2/1000: Train Loss: 2.5805, Val Loss: 2.5515\n",
      "New best validation loss: 2.5515\n",
      "Baseline Loss: 2.7052 | Actual Loss: 2.5325\n",
      "Baseline Loss: 2.6878 | Actual Loss: 2.6738\n",
      "Baseline Loss: 2.6475 | Actual Loss: 2.5608\n",
      "Baseline Loss: 2.7100 | Actual Loss: 2.6985\n",
      "Baseline Loss: 2.6900 | Actual Loss: 2.5604\n",
      "Baseline Loss: 2.6629 | Actual Loss: 2.5097\n",
      "Baseline Loss: 2.6782 | Actual Loss: 2.6305\n",
      "Baseline Loss: 2.6556 | Actual Loss: 2.4832\n",
      "Baseline Loss: 2.6481 | Actual Loss: 2.6124\n",
      "Baseline Loss: 2.6662 | Actual Loss: 2.4697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 3/1000 [00:00<05:40,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6625 | Actual Loss: 2.5339\n",
      "Baseline Loss: 2.6637 | Actual Loss: 2.4912\n",
      "Baseline Loss: 2.6918 | Actual Loss: 2.5823\n",
      "Baseline Loss: 2.6546 | Actual Loss: 2.5424\n",
      "Baseline Loss: 2.7069 | Actual Loss: 2.6364\n",
      "Baseline Loss: 2.2773 | Actual Loss: 2.0824\n",
      "Baseline Loss: 2.6907 | Actual Loss: 2.5139\n",
      "Baseline Loss: 2.6644 | Actual Loss: 2.4150\n",
      "Baseline Loss: 2.6840 | Actual Loss: 2.4607\n",
      "Baseline Loss: 2.6117 | Actual Loss: 2.3725\n",
      "Epoch 3/1000: Train Loss: 2.5375, Val Loss: 2.4405\n",
      "New best validation loss: 2.4405\n",
      "Baseline Loss: 2.6798 | Actual Loss: 2.4313\n",
      "Baseline Loss: 2.6785 | Actual Loss: 2.3983\n",
      "Baseline Loss: 2.6911 | Actual Loss: 2.4295\n",
      "Baseline Loss: 2.6376 | Actual Loss: 2.4006\n",
      "Baseline Loss: 2.6581 | Actual Loss: 2.4079\n",
      "Baseline Loss: 2.6511 | Actual Loss: 2.3914\n",
      "Baseline Loss: 2.7134 | Actual Loss: 2.5387\n",
      "Baseline Loss: 2.6575 | Actual Loss: 2.4870\n",
      "Baseline Loss: 2.6907 | Actual Loss: 2.4749\n",
      "Baseline Loss: 2.6438 | Actual Loss: 2.4056\n",
      "Baseline Loss: 2.6907 | Actual Loss: 2.3691\n",
      "Baseline Loss: 2.7192 | Actual Loss: 2.2731\n",
      "Baseline Loss: 2.6885 | Actual Loss: 2.2387\n",
      "Baseline Loss: 2.7033 | Actual Loss: 2.3093\n",
      "Baseline Loss: 2.6665 | Actual Loss: 2.2279\n",
      "Baseline Loss: 2.2411 | Actual Loss: 1.7383\n",
      "Baseline Loss: 2.6907 | Actual Loss: 2.1574\n",
      "Baseline Loss: 2.6644 | Actual Loss: 2.2088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 4/1000 [00:01<05:44,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6840 | Actual Loss: 2.1590\n",
      "Baseline Loss: 2.6117 | Actual Loss: 2.1623\n",
      "Epoch 4/1000: Train Loss: 2.3451, Val Loss: 2.1719\n",
      "New best validation loss: 2.1719\n",
      "Baseline Loss: 2.6919 | Actual Loss: 2.4326\n",
      "Baseline Loss: 2.6897 | Actual Loss: 2.0977\n",
      "Baseline Loss: 2.6777 | Actual Loss: 2.2430\n",
      "Baseline Loss: 2.6547 | Actual Loss: 2.2152\n",
      "Baseline Loss: 2.6863 | Actual Loss: 2.2919\n",
      "Baseline Loss: 2.6769 | Actual Loss: 2.0955\n",
      "Baseline Loss: 2.6636 | Actual Loss: 2.2330\n",
      "Baseline Loss: 2.6954 | Actual Loss: 2.1853\n",
      "Baseline Loss: 2.6808 | Actual Loss: 1.8438\n",
      "Baseline Loss: 2.6493 | Actual Loss: 1.9726\n",
      "Baseline Loss: 2.6565 | Actual Loss: 2.1259\n",
      "Baseline Loss: 2.6913 | Actual Loss: 1.7877\n",
      "Baseline Loss: 2.6680 | Actual Loss: 1.7854\n",
      "Baseline Loss: 2.6550 | Actual Loss: 1.8648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 5/1000 [00:01<05:13,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6373 | Actual Loss: 1.7065\n",
      "Baseline Loss: 2.2489 | Actual Loss: 1.5065\n",
      "Baseline Loss: 2.6907 | Actual Loss: 1.9402\n",
      "Baseline Loss: 2.6644 | Actual Loss: 1.9754\n",
      "Baseline Loss: 2.6840 | Actual Loss: 1.7461\n",
      "Baseline Loss: 2.6117 | Actual Loss: 1.6066\n",
      "Epoch 5/1000: Train Loss: 2.0242, Val Loss: 1.8171\n",
      "New best validation loss: 1.8171\n",
      "Baseline Loss: 2.7296 | Actual Loss: 1.8131\n",
      "Baseline Loss: 2.6723 | Actual Loss: 1.6171\n",
      "Baseline Loss: 2.6416 | Actual Loss: 1.7120\n",
      "Baseline Loss: 2.6391 | Actual Loss: 1.8588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 6/1000 [00:01<05:17,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7122 | Actual Loss: 1.8018\n",
      "Baseline Loss: 2.6410 | Actual Loss: 1.8507\n",
      "Baseline Loss: 2.7248 | Actual Loss: 1.8419\n",
      "Baseline Loss: 2.6666 | Actual Loss: 1.5059\n",
      "Baseline Loss: 2.6398 | Actual Loss: 1.8023\n",
      "Baseline Loss: 2.6949 | Actual Loss: 1.8518\n",
      "Baseline Loss: 2.6584 | Actual Loss: 1.7956\n",
      "Baseline Loss: 2.6500 | Actual Loss: 2.0458\n",
      "Baseline Loss: 2.6688 | Actual Loss: 1.5238\n",
      "Baseline Loss: 2.6640 | Actual Loss: 1.7949\n",
      "Baseline Loss: 2.7034 | Actual Loss: 2.0205\n",
      "Baseline Loss: 2.2698 | Actual Loss: 1.3863\n",
      "Baseline Loss: 2.6907 | Actual Loss: 1.7434\n",
      "Baseline Loss: 2.6644 | Actual Loss: 1.6826\n",
      "Baseline Loss: 2.6840 | Actual Loss: 1.5148\n",
      "Baseline Loss: 2.6117 | Actual Loss: 1.5174\n",
      "Epoch 6/1000: Train Loss: 1.7639, Val Loss: 1.6145\n",
      "New best validation loss: 1.6145\n",
      "Baseline Loss: 2.6588 | Actual Loss: 1.5069\n",
      "Baseline Loss: 2.6406 | Actual Loss: 1.8727\n",
      "Baseline Loss: 2.6728 | Actual Loss: 1.6149\n",
      "Baseline Loss: 2.6478 | Actual Loss: 1.6842\n",
      "Baseline Loss: 2.6550 | Actual Loss: 2.0308\n",
      "Baseline Loss: 2.6878 | Actual Loss: 1.6399\n",
      "Baseline Loss: 2.6796 | Actual Loss: 1.6428\n",
      "Baseline Loss: 2.6925 | Actual Loss: 1.7598\n",
      "Baseline Loss: 2.6631 | Actual Loss: 1.3530\n",
      "Baseline Loss: 2.6621 | Actual Loss: 1.4377\n",
      "Baseline Loss: 2.7038 | Actual Loss: 1.9053\n",
      "Baseline Loss: 2.6876 | Actual Loss: 1.7002\n",
      "Baseline Loss: 2.6942 | Actual Loss: 1.6332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 7/1000 [00:02<05:31,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6933 | Actual Loss: 1.8392\n",
      "Baseline Loss: 2.6656 | Actual Loss: 1.6444\n",
      "Baseline Loss: 2.2732 | Actual Loss: 1.8336\n",
      "Baseline Loss: 2.6907 | Actual Loss: 2.0359\n",
      "Baseline Loss: 2.6644 | Actual Loss: 1.6596\n",
      "Baseline Loss: 2.6840 | Actual Loss: 2.0994\n",
      "Baseline Loss: 2.6117 | Actual Loss: 1.5709\n",
      "Epoch 7/1000: Train Loss: 1.6937, Val Loss: 1.8414\n",
      "Baseline Loss: 2.6697 | Actual Loss: 1.9003\n",
      "Baseline Loss: 2.6620 | Actual Loss: 1.5922\n",
      "Baseline Loss: 2.6669 | Actual Loss: 1.7846\n",
      "Baseline Loss: 2.6858 | Actual Loss: 1.6108\n",
      "Baseline Loss: 2.6687 | Actual Loss: 1.7407\n",
      "Baseline Loss: 2.6374 | Actual Loss: 1.4555\n",
      "Baseline Loss: 2.6771 | Actual Loss: 1.8122\n",
      "Baseline Loss: 2.6859 | Actual Loss: 1.8703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 8/1000 [00:02<05:04,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6983 | Actual Loss: 1.7256\n",
      "Baseline Loss: 2.6862 | Actual Loss: 2.0659\n",
      "Baseline Loss: 2.7472 | Actual Loss: 1.6014\n",
      "Baseline Loss: 2.7110 | Actual Loss: 1.9257\n",
      "Baseline Loss: 2.6717 | Actual Loss: 1.7475\n",
      "Baseline Loss: 2.6429 | Actual Loss: 1.5405\n",
      "Baseline Loss: 2.6790 | Actual Loss: 1.5751\n",
      "Baseline Loss: 2.2516 | Actual Loss: 1.1942\n",
      "Baseline Loss: 2.6907 | Actual Loss: 1.5799\n",
      "Baseline Loss: 2.6644 | Actual Loss: 1.6887\n",
      "Baseline Loss: 2.6840 | Actual Loss: 1.9003\n",
      "Baseline Loss: 2.6117 | Actual Loss: 1.3712\n",
      "Epoch 8/1000: Train Loss: 1.6964, Val Loss: 1.6350\n",
      "Baseline Loss: 2.6627 | Actual Loss: 1.6256\n",
      "Baseline Loss: 2.6567 | Actual Loss: 1.5743\n",
      "Baseline Loss: 2.6884 | Actual Loss: 1.8665\n",
      "Baseline Loss: 2.6520 | Actual Loss: 1.7605\n",
      "Baseline Loss: 2.6633 | Actual Loss: 1.3783\n",
      "Baseline Loss: 2.6752 | Actual Loss: 1.8234\n",
      "Baseline Loss: 2.6933 | Actual Loss: 1.7124\n",
      "Baseline Loss: 2.6778 | Actual Loss: 1.0981\n",
      "Baseline Loss: 2.6804 | Actual Loss: 1.6618\n",
      "Baseline Loss: 2.7021 | Actual Loss: 1.4250\n",
      "Baseline Loss: 2.6634 | Actual Loss: 1.4422\n",
      "Baseline Loss: 2.6848 | Actual Loss: 1.6293\n",
      "Baseline Loss: 2.6385 | Actual Loss: 1.4413\n",
      "Baseline Loss: 2.7335 | Actual Loss: 1.6286\n",
      "Baseline Loss: 2.7027 | Actual Loss: 1.3702\n",
      "Baseline Loss: 2.3116 | Actual Loss: 1.0185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 9/1000 [00:02<05:20,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6907 | Actual Loss: 1.6725\n",
      "Baseline Loss: 2.6644 | Actual Loss: 1.6433\n",
      "Baseline Loss: 2.6840 | Actual Loss: 1.4959\n",
      "Baseline Loss: 2.6117 | Actual Loss: 1.4443\n",
      "Epoch 9/1000: Train Loss: 1.5285, Val Loss: 1.5640\n",
      "New best validation loss: 1.5640\n",
      "Baseline Loss: 2.6702 | Actual Loss: 1.7487\n",
      "Baseline Loss: 2.6789 | Actual Loss: 1.5363\n",
      "Baseline Loss: 2.6535 | Actual Loss: 1.4051\n",
      "Baseline Loss: 2.7111 | Actual Loss: 1.5981\n",
      "Baseline Loss: 2.6992 | Actual Loss: 1.5325\n",
      "Baseline Loss: 2.6689 | Actual Loss: 1.8240\n",
      "Baseline Loss: 2.6196 | Actual Loss: 1.2895\n",
      "Baseline Loss: 2.6909 | Actual Loss: 1.4418\n",
      "Baseline Loss: 2.6357 | Actual Loss: 1.6305\n",
      "Baseline Loss: 2.6982 | Actual Loss: 1.8477\n",
      "Baseline Loss: 2.6786 | Actual Loss: 1.4455\n",
      "Baseline Loss: 2.6534 | Actual Loss: 1.5097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 10/1000 [00:03<05:27,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6697 | Actual Loss: 1.5414\n",
      "Baseline Loss: 2.6756 | Actual Loss: 1.5199\n",
      "Baseline Loss: 2.6799 | Actual Loss: 1.4559\n",
      "Baseline Loss: 2.3419 | Actual Loss: 1.2321\n",
      "Baseline Loss: 2.6907 | Actual Loss: 1.5118\n",
      "Baseline Loss: 2.6644 | Actual Loss: 1.5005\n",
      "Baseline Loss: 2.6840 | Actual Loss: 1.5262\n",
      "Baseline Loss: 2.6117 | Actual Loss: 1.6268\n",
      "Epoch 10/1000: Train Loss: 1.5349, Val Loss: 1.5413\n",
      "New best validation loss: 1.5413\n",
      "Baseline Loss: 2.6956 | Actual Loss: 1.5816\n",
      "Baseline Loss: 2.6754 | Actual Loss: 1.3394\n",
      "Baseline Loss: 2.6891 | Actual Loss: 1.3581\n",
      "Baseline Loss: 2.6796 | Actual Loss: 1.4921\n",
      "Baseline Loss: 2.6908 | Actual Loss: 1.4052\n",
      "Baseline Loss: 2.6448 | Actual Loss: 1.7720\n",
      "Baseline Loss: 2.7086 | Actual Loss: 1.7151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 11/1000 [00:03<04:57,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6734 | Actual Loss: 1.3639\n",
      "Baseline Loss: 2.7022 | Actual Loss: 1.5609\n",
      "Baseline Loss: 2.6791 | Actual Loss: 2.0031\n",
      "Baseline Loss: 2.6573 | Actual Loss: 1.4297\n",
      "Baseline Loss: 2.7011 | Actual Loss: 1.4426\n",
      "Baseline Loss: 2.6564 | Actual Loss: 1.3417\n",
      "Baseline Loss: 2.6746 | Actual Loss: 1.6215\n",
      "Baseline Loss: 2.6393 | Actual Loss: 1.6307\n",
      "Baseline Loss: 2.2540 | Actual Loss: 1.1969\n",
      "Baseline Loss: 2.6907 | Actual Loss: 1.5077\n",
      "Baseline Loss: 2.6644 | Actual Loss: 1.5802\n",
      "Baseline Loss: 2.6840 | Actual Loss: 1.6523\n",
      "Baseline Loss: 2.6117 | Actual Loss: 1.4285\n",
      "Epoch 11/1000: Train Loss: 1.5159, Val Loss: 1.5422\n",
      "Baseline Loss: 2.7191 | Actual Loss: 1.4778\n",
      "Baseline Loss: 2.7088 | Actual Loss: 1.5338\n",
      "Baseline Loss: 2.6907 | Actual Loss: 1.5181\n",
      "Baseline Loss: 2.6715 | Actual Loss: 1.7039\n",
      "Baseline Loss: 2.6781 | Actual Loss: 1.2126\n",
      "Baseline Loss: 2.6535 | Actual Loss: 1.3263\n",
      "Baseline Loss: 2.6654 | Actual Loss: 1.4454\n",
      "Baseline Loss: 2.6814 | Actual Loss: 1.4564\n",
      "Baseline Loss: 2.6282 | Actual Loss: 1.7525\n",
      "Baseline Loss: 2.6811 | Actual Loss: 1.5711\n",
      "Baseline Loss: 2.6851 | Actual Loss: 1.6371\n",
      "Baseline Loss: 2.6805 | Actual Loss: 1.1467\n",
      "Baseline Loss: 2.6521 | Actual Loss: 1.4823\n",
      "Baseline Loss: 2.7330 | Actual Loss: 1.5417\n",
      "Baseline Loss: 2.6452 | Actual Loss: 1.3937\n",
      "Baseline Loss: 2.2728 | Actual Loss: 1.0505\n",
      "Baseline Loss: 2.6907 | Actual Loss: 1.5225\n",
      "Baseline Loss: 2.6644 | Actual Loss: 1.6031\n",
      "Baseline Loss: 2.6840 | Actual Loss: 1.6646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 12/1000 [00:03<05:18,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6117 | Actual Loss: 1.3185\n",
      "Epoch 12/1000: Train Loss: 1.4531, Val Loss: 1.5272\n",
      "New best validation loss: 1.5272\n",
      "Baseline Loss: 2.6750 | Actual Loss: 1.4050\n",
      "Baseline Loss: 2.6597 | Actual Loss: 1.7403\n",
      "Baseline Loss: 2.7110 | Actual Loss: 1.2715\n",
      "Baseline Loss: 2.6656 | Actual Loss: 1.3322\n",
      "Baseline Loss: 2.7084 | Actual Loss: 1.2388\n",
      "Baseline Loss: 2.6804 | Actual Loss: 1.5112\n",
      "Baseline Loss: 2.6681 | Actual Loss: 1.3236\n",
      "Baseline Loss: 2.6593 | Actual Loss: 1.5384\n",
      "Baseline Loss: 2.6623 | Actual Loss: 1.6710\n",
      "Baseline Loss: 2.6643 | Actual Loss: 1.1458\n",
      "Baseline Loss: 2.6346 | Actual Loss: 1.1112\n",
      "Baseline Loss: 2.6898 | Actual Loss: 1.3980\n",
      "Baseline Loss: 2.7057 | Actual Loss: 1.4559\n",
      "Baseline Loss: 2.6711 | Actual Loss: 1.3796\n",
      "Baseline Loss: 2.6854 | Actual Loss: 1.6250\n",
      "Baseline Loss: 2.2286 | Actual Loss: 1.1910\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏         | 13/1000 [00:04<05:21,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6907 | Actual Loss: 1.4005\n",
      "Baseline Loss: 2.6644 | Actual Loss: 1.2477\n",
      "Baseline Loss: 2.6840 | Actual Loss: 1.4839\n",
      "Baseline Loss: 2.6117 | Actual Loss: 1.2203\n",
      "Epoch 13/1000: Train Loss: 1.3961, Val Loss: 1.3381\n",
      "New best validation loss: 1.3381\n",
      "Baseline Loss: 2.6341 | Actual Loss: 1.2616\n",
      "Baseline Loss: 2.6431 | Actual Loss: 1.2794\n",
      "Baseline Loss: 2.6698 | Actual Loss: 1.4080\n",
      "Baseline Loss: 2.7193 | Actual Loss: 1.7232\n",
      "Baseline Loss: 2.6774 | Actual Loss: 1.1067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏         | 14/1000 [00:04<04:57,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6731 | Actual Loss: 1.5945\n",
      "Baseline Loss: 2.6851 | Actual Loss: 1.5936\n",
      "Baseline Loss: 2.6388 | Actual Loss: 1.0400\n",
      "Baseline Loss: 2.6759 | Actual Loss: 1.5189\n",
      "Baseline Loss: 2.6778 | Actual Loss: 1.1158\n",
      "Baseline Loss: 2.6649 | Actual Loss: 1.2232\n",
      "Baseline Loss: 2.6872 | Actual Loss: 1.4518\n",
      "Baseline Loss: 2.7299 | Actual Loss: 1.4741\n",
      "Baseline Loss: 2.7057 | Actual Loss: 1.1645\n",
      "Baseline Loss: 2.6597 | Actual Loss: 1.3983\n",
      "Baseline Loss: 2.3229 | Actual Loss: 1.0715\n",
      "Baseline Loss: 2.6907 | Actual Loss: 1.4200\n",
      "Baseline Loss: 2.6644 | Actual Loss: 1.1849\n",
      "Baseline Loss: 2.6840 | Actual Loss: 1.3083\n",
      "Baseline Loss: 2.6117 | Actual Loss: 1.2481\n",
      "Epoch 14/1000: Train Loss: 1.3391, Val Loss: 1.2903\n",
      "New best validation loss: 1.2903\n",
      "Baseline Loss: 2.6437 | Actual Loss: 1.3370\n",
      "Baseline Loss: 2.6610 | Actual Loss: 1.2068\n",
      "Baseline Loss: 2.6840 | Actual Loss: 1.4166\n",
      "Baseline Loss: 2.6644 | Actual Loss: 1.0496\n",
      "Baseline Loss: 2.6832 | Actual Loss: 1.3972\n",
      "Baseline Loss: 2.6736 | Actual Loss: 1.3150\n",
      "Baseline Loss: 2.6931 | Actual Loss: 1.4026\n",
      "Baseline Loss: 2.7227 | Actual Loss: 1.6152\n",
      "Baseline Loss: 2.6370 | Actual Loss: 1.0918\n",
      "Baseline Loss: 2.6783 | Actual Loss: 1.2413\n",
      "Baseline Loss: 2.6852 | Actual Loss: 1.2667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 15/1000 [00:04<05:09,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6341 | Actual Loss: 1.2039\n",
      "Baseline Loss: 2.6538 | Actual Loss: 1.2692\n",
      "Baseline Loss: 2.6834 | Actual Loss: 1.5663\n",
      "Baseline Loss: 2.6939 | Actual Loss: 1.4494\n",
      "Baseline Loss: 2.2526 | Actual Loss: 0.9596\n",
      "Baseline Loss: 2.6907 | Actual Loss: 1.5089\n",
      "Baseline Loss: 2.6644 | Actual Loss: 1.2321\n",
      "Baseline Loss: 2.6840 | Actual Loss: 1.3436\n",
      "Baseline Loss: 2.6117 | Actual Loss: 1.3856\n",
      "Epoch 15/1000: Train Loss: 1.2993, Val Loss: 1.3675\n",
      "Baseline Loss: 2.6707 | Actual Loss: 1.6926\n",
      "Baseline Loss: 2.7348 | Actual Loss: 1.2220\n",
      "Baseline Loss: 2.7101 | Actual Loss: 1.2580\n",
      "Baseline Loss: 2.6872 | Actual Loss: 1.2888\n",
      "Baseline Loss: 2.6367 | Actual Loss: 1.2794\n",
      "Baseline Loss: 2.6541 | Actual Loss: 1.4666\n",
      "Baseline Loss: 2.6620 | Actual Loss: 1.5270\n",
      "Baseline Loss: 2.7069 | Actual Loss: 1.4297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 16/1000 [00:05<04:52,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6862 | Actual Loss: 1.0300\n",
      "Baseline Loss: 2.6700 | Actual Loss: 0.9270\n",
      "Baseline Loss: 2.6497 | Actual Loss: 1.3873\n",
      "Baseline Loss: 2.6887 | Actual Loss: 1.7213\n",
      "Baseline Loss: 2.6733 | Actual Loss: 1.5570\n",
      "Baseline Loss: 2.6373 | Actual Loss: 1.2908\n",
      "Baseline Loss: 2.6861 | Actual Loss: 1.0182\n",
      "Baseline Loss: 2.3029 | Actual Loss: 1.0928\n",
      "Baseline Loss: 2.6907 | Actual Loss: 1.1502\n",
      "Baseline Loss: 2.6644 | Actual Loss: 1.4425\n",
      "Baseline Loss: 2.6840 | Actual Loss: 1.3019\n",
      "Baseline Loss: 2.6117 | Actual Loss: 1.2120\n",
      "Epoch 16/1000: Train Loss: 1.3243, Val Loss: 1.2766\n",
      "New best validation loss: 1.2766\n",
      "Baseline Loss: 2.6622 | Actual Loss: 1.4516\n",
      "Baseline Loss: 2.6590 | Actual Loss: 1.0797\n",
      "Baseline Loss: 2.6804 | Actual Loss: 1.1637\n",
      "Baseline Loss: 2.7266 | Actual Loss: 1.1112\n",
      "Baseline Loss: 2.6980 | Actual Loss: 1.4271\n",
      "Baseline Loss: 2.6724 | Actual Loss: 1.4617\n",
      "Baseline Loss: 2.6501 | Actual Loss: 1.4019\n",
      "Baseline Loss: 2.6715 | Actual Loss: 1.2186\n",
      "Baseline Loss: 2.6550 | Actual Loss: 1.5028\n",
      "Baseline Loss: 2.6378 | Actual Loss: 1.3834\n",
      "Baseline Loss: 2.6970 | Actual Loss: 1.0711\n",
      "Baseline Loss: 2.6834 | Actual Loss: 0.9413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 17/1000 [00:05<05:12,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7162 | Actual Loss: 1.1526\n",
      "Baseline Loss: 2.6749 | Actual Loss: 1.0414\n",
      "Baseline Loss: 2.6888 | Actual Loss: 1.5885\n",
      "Baseline Loss: 2.2593 | Actual Loss: 1.2382\n",
      "Baseline Loss: 2.6907 | Actual Loss: 1.5219\n",
      "Baseline Loss: 2.6644 | Actual Loss: 1.3374\n",
      "Baseline Loss: 2.6840 | Actual Loss: 1.2670\n",
      "Baseline Loss: 2.6117 | Actual Loss: 1.2365\n",
      "Epoch 17/1000: Train Loss: 1.2647, Val Loss: 1.3407\n",
      "Baseline Loss: 2.6894 | Actual Loss: 1.3627\n",
      "Baseline Loss: 2.6951 | Actual Loss: 1.7709\n",
      "Baseline Loss: 2.6406 | Actual Loss: 1.5317\n",
      "Baseline Loss: 2.6433 | Actual Loss: 0.9160\n",
      "Baseline Loss: 2.6698 | Actual Loss: 1.2080\n",
      "Baseline Loss: 2.6965 | Actual Loss: 1.0352\n",
      "Baseline Loss: 2.6569 | Actual Loss: 1.1532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 18/1000 [00:05<05:00,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6486 | Actual Loss: 1.2997\n",
      "Baseline Loss: 2.7086 | Actual Loss: 1.0824\n",
      "Baseline Loss: 2.6398 | Actual Loss: 1.0775\n",
      "Baseline Loss: 2.6757 | Actual Loss: 1.2030\n",
      "Baseline Loss: 2.6864 | Actual Loss: 1.3791\n",
      "Baseline Loss: 2.7071 | Actual Loss: 1.3778\n",
      "Baseline Loss: 2.6737 | Actual Loss: 1.2198\n",
      "Baseline Loss: 2.6364 | Actual Loss: 1.5077\n",
      "Baseline Loss: 2.2975 | Actual Loss: 0.8027\n",
      "Baseline Loss: 2.6907 | Actual Loss: 1.1646\n",
      "Baseline Loss: 2.6644 | Actual Loss: 1.1530\n",
      "Baseline Loss: 2.6840 | Actual Loss: 1.2215\n",
      "Baseline Loss: 2.6117 | Actual Loss: 1.1589\n",
      "Epoch 18/1000: Train Loss: 1.2455, Val Loss: 1.1745\n",
      "New best validation loss: 1.1745\n",
      "Baseline Loss: 2.6635 | Actual Loss: 1.1003\n",
      "Baseline Loss: 2.6714 | Actual Loss: 1.0729\n",
      "Baseline Loss: 2.6892 | Actual Loss: 1.1467\n",
      "Baseline Loss: 2.6576 | Actual Loss: 1.3617\n",
      "Baseline Loss: 2.6499 | Actual Loss: 1.2331\n",
      "Baseline Loss: 2.6882 | Actual Loss: 1.2891\n",
      "Baseline Loss: 2.6942 | Actual Loss: 1.0737\n",
      "Baseline Loss: 2.6618 | Actual Loss: 1.1190\n",
      "Baseline Loss: 2.6734 | Actual Loss: 1.5749\n",
      "Baseline Loss: 2.6719 | Actual Loss: 0.9382\n",
      "Baseline Loss: 2.6645 | Actual Loss: 1.0865\n",
      "Baseline Loss: 2.7032 | Actual Loss: 1.2672\n",
      "Baseline Loss: 2.6437 | Actual Loss: 1.2401\n",
      "Baseline Loss: 2.6889 | Actual Loss: 1.3286\n",
      "Baseline Loss: 2.6896 | Actual Loss: 1.1408\n",
      "Baseline Loss: 2.2909 | Actual Loss: 0.5950\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.9759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 19/1000 [00:06<05:12,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6644 | Actual Loss: 1.3195\n",
      "Baseline Loss: 2.6840 | Actual Loss: 1.5178\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.9932\n",
      "Epoch 19/1000: Train Loss: 1.1605, Val Loss: 1.2016\n",
      "Baseline Loss: 2.7020 | Actual Loss: 1.1862\n",
      "Baseline Loss: 2.6887 | Actual Loss: 1.2118\n",
      "Baseline Loss: 2.6503 | Actual Loss: 1.1344\n",
      "Baseline Loss: 2.6716 | Actual Loss: 1.3786\n",
      "Baseline Loss: 2.6701 | Actual Loss: 1.1246\n",
      "Baseline Loss: 2.6218 | Actual Loss: 1.2459\n",
      "Baseline Loss: 2.6855 | Actual Loss: 1.2581\n",
      "Baseline Loss: 2.6580 | Actual Loss: 1.0500\n",
      "Baseline Loss: 2.6609 | Actual Loss: 1.1454\n",
      "Baseline Loss: 2.7006 | Actual Loss: 1.3687\n",
      "Baseline Loss: 2.6688 | Actual Loss: 1.2347\n",
      "Baseline Loss: 2.6920 | Actual Loss: 1.0851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 20/1000 [00:06<05:17,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6614 | Actual Loss: 1.0523\n",
      "Baseline Loss: 2.6916 | Actual Loss: 1.0571\n",
      "Baseline Loss: 2.6955 | Actual Loss: 1.5116\n",
      "Baseline Loss: 2.2621 | Actual Loss: 0.9170\n",
      "Baseline Loss: 2.6907 | Actual Loss: 1.1277\n",
      "Baseline Loss: 2.6644 | Actual Loss: 1.1781\n",
      "Baseline Loss: 2.6840 | Actual Loss: 1.1223\n",
      "Baseline Loss: 2.6117 | Actual Loss: 1.1917\n",
      "Epoch 20/1000: Train Loss: 1.1851, Val Loss: 1.1549\n",
      "New best validation loss: 1.1549\n",
      "Baseline Loss: 2.6780 | Actual Loss: 1.2709\n",
      "Baseline Loss: 2.6482 | Actual Loss: 1.0632\n",
      "Baseline Loss: 2.6823 | Actual Loss: 1.2299\n",
      "Baseline Loss: 2.6861 | Actual Loss: 1.2683\n",
      "Baseline Loss: 2.6502 | Actual Loss: 1.4668\n",
      "Baseline Loss: 2.6725 | Actual Loss: 1.1602\n",
      "Baseline Loss: 2.7033 | Actual Loss: 1.2010\n",
      "Baseline Loss: 2.6913 | Actual Loss: 1.0443\n",
      "Baseline Loss: 2.6900 | Actual Loss: 0.9216\n",
      "Baseline Loss: 2.6594 | Actual Loss: 1.1904\n",
      "Baseline Loss: 2.6679 | Actual Loss: 1.4721\n",
      "Baseline Loss: 2.6772 | Actual Loss: 1.3961\n",
      "Baseline Loss: 2.6836 | Actual Loss: 1.2288\n",
      "Baseline Loss: 2.7053 | Actual Loss: 1.5385\n",
      "Baseline Loss: 2.6568 | Actual Loss: 0.9666\n",
      "Baseline Loss: 2.2748 | Actual Loss: 0.6897\n",
      "Baseline Loss: 2.6907 | Actual Loss: 1.3849\n",
      "Baseline Loss: 2.6644 | Actual Loss: 1.3223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 21/1000 [00:06<05:03,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6840 | Actual Loss: 1.0304\n",
      "Baseline Loss: 2.6117 | Actual Loss: 1.2951\n",
      "Epoch 21/1000: Train Loss: 1.1943, Val Loss: 1.2582\n",
      "Baseline Loss: 2.6724 | Actual Loss: 1.2790\n",
      "Baseline Loss: 2.6494 | Actual Loss: 1.1435\n",
      "Baseline Loss: 2.6460 | Actual Loss: 1.2203\n",
      "Baseline Loss: 2.6626 | Actual Loss: 1.2357\n",
      "Baseline Loss: 2.6635 | Actual Loss: 1.4102\n",
      "Baseline Loss: 2.6540 | Actual Loss: 1.4859\n",
      "Baseline Loss: 2.6733 | Actual Loss: 1.1378\n",
      "Baseline Loss: 2.6690 | Actual Loss: 1.1783\n",
      "Baseline Loss: 2.7082 | Actual Loss: 1.1824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 22/1000 [00:06<05:09,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6524 | Actual Loss: 1.2511\n",
      "Baseline Loss: 2.6579 | Actual Loss: 1.2941\n",
      "Baseline Loss: 2.6743 | Actual Loss: 0.9587\n",
      "Baseline Loss: 2.6813 | Actual Loss: 1.1964\n",
      "Baseline Loss: 2.6962 | Actual Loss: 0.9017\n",
      "Baseline Loss: 2.7311 | Actual Loss: 0.9648\n",
      "Baseline Loss: 2.3381 | Actual Loss: 0.5853\n",
      "Baseline Loss: 2.6907 | Actual Loss: 1.2381\n",
      "Baseline Loss: 2.6644 | Actual Loss: 1.0722\n",
      "Baseline Loss: 2.6840 | Actual Loss: 1.1680\n",
      "Baseline Loss: 2.6117 | Actual Loss: 1.2156\n",
      "Epoch 22/1000: Train Loss: 1.1516, Val Loss: 1.1735\n",
      "Baseline Loss: 2.6613 | Actual Loss: 1.3577\n",
      "Baseline Loss: 2.6812 | Actual Loss: 1.1050\n",
      "Baseline Loss: 2.6667 | Actual Loss: 1.0981\n",
      "Baseline Loss: 2.6730 | Actual Loss: 1.0976\n",
      "Baseline Loss: 2.6720 | Actual Loss: 1.1727\n",
      "Baseline Loss: 2.6479 | Actual Loss: 0.8744\n",
      "Baseline Loss: 2.7187 | Actual Loss: 0.9873\n",
      "Baseline Loss: 2.6755 | Actual Loss: 1.3672\n",
      "Baseline Loss: 2.6943 | Actual Loss: 1.2414\n",
      "Baseline Loss: 2.6815 | Actual Loss: 1.2185\n",
      "Baseline Loss: 2.6661 | Actual Loss: 0.8543\n",
      "Baseline Loss: 2.6814 | Actual Loss: 1.1281\n",
      "Baseline Loss: 2.6565 | Actual Loss: 0.9168\n",
      "Baseline Loss: 2.6802 | Actual Loss: 0.8937\n",
      "Baseline Loss: 2.6483 | Actual Loss: 0.8973\n",
      "Baseline Loss: 2.3319 | Actual Loss: 1.1706\n",
      "Baseline Loss: 2.6907 | Actual Loss: 1.1927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 23/1000 [00:07<05:20,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6644 | Actual Loss: 1.3093\n",
      "Baseline Loss: 2.6840 | Actual Loss: 1.2443\n",
      "Baseline Loss: 2.6117 | Actual Loss: 1.1821\n",
      "Epoch 23/1000: Train Loss: 1.0863, Val Loss: 1.2321\n",
      "Baseline Loss: 2.6781 | Actual Loss: 1.3968\n",
      "Baseline Loss: 2.6720 | Actual Loss: 1.0542\n",
      "Baseline Loss: 2.6653 | Actual Loss: 1.6881\n",
      "Baseline Loss: 2.6907 | Actual Loss: 1.1599\n",
      "Baseline Loss: 2.6887 | Actual Loss: 1.0406\n",
      "Baseline Loss: 2.7060 | Actual Loss: 0.9715\n",
      "Baseline Loss: 2.6766 | Actual Loss: 0.8511\n",
      "Baseline Loss: 2.6778 | Actual Loss: 1.2130\n",
      "Baseline Loss: 2.6444 | Actual Loss: 1.2372\n",
      "Baseline Loss: 2.6604 | Actual Loss: 1.3370\n",
      "Baseline Loss: 2.6480 | Actual Loss: 0.9984\n",
      "Baseline Loss: 2.6557 | Actual Loss: 0.9473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 24/1000 [00:07<05:06,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7071 | Actual Loss: 0.9459\n",
      "Baseline Loss: 2.7220 | Actual Loss: 1.1320\n",
      "Baseline Loss: 2.6624 | Actual Loss: 1.2051\n",
      "Baseline Loss: 2.2643 | Actual Loss: 0.4452\n",
      "Baseline Loss: 2.6907 | Actual Loss: 1.1677\n",
      "Baseline Loss: 2.6644 | Actual Loss: 1.0549\n",
      "Baseline Loss: 2.6840 | Actual Loss: 1.0202\n",
      "Baseline Loss: 2.6117 | Actual Loss: 1.0903\n",
      "Epoch 24/1000: Train Loss: 1.1015, Val Loss: 1.0833\n",
      "New best validation loss: 1.0833\n",
      "Baseline Loss: 2.6968 | Actual Loss: 0.9263\n",
      "Baseline Loss: 2.6703 | Actual Loss: 1.1887\n",
      "Baseline Loss: 2.6643 | Actual Loss: 1.0720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▎         | 25/1000 [00:07<05:11,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6414 | Actual Loss: 1.1614\n",
      "Baseline Loss: 2.6860 | Actual Loss: 1.0266\n",
      "Baseline Loss: 2.6838 | Actual Loss: 1.4990\n",
      "Baseline Loss: 2.6548 | Actual Loss: 1.2303\n",
      "Baseline Loss: 2.6528 | Actual Loss: 1.1965\n",
      "Baseline Loss: 2.6223 | Actual Loss: 1.3208\n",
      "Baseline Loss: 2.6828 | Actual Loss: 1.4781\n",
      "Baseline Loss: 2.7103 | Actual Loss: 1.0469\n",
      "Baseline Loss: 2.6870 | Actual Loss: 1.2067\n",
      "Baseline Loss: 2.6614 | Actual Loss: 0.9874\n",
      "Baseline Loss: 2.6934 | Actual Loss: 1.2077\n",
      "Baseline Loss: 2.6861 | Actual Loss: 1.3788\n",
      "Baseline Loss: 2.2684 | Actual Loss: 0.9292\n",
      "Baseline Loss: 2.6907 | Actual Loss: 1.3339\n",
      "Baseline Loss: 2.6644 | Actual Loss: 1.1337\n",
      "Baseline Loss: 2.6840 | Actual Loss: 1.1110\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.9565\n",
      "Epoch 25/1000: Train Loss: 1.1785, Val Loss: 1.1338\n",
      "Baseline Loss: 2.6516 | Actual Loss: 1.0652\n",
      "Baseline Loss: 2.6744 | Actual Loss: 1.3570\n",
      "Baseline Loss: 2.6296 | Actual Loss: 0.9353\n",
      "Baseline Loss: 2.6587 | Actual Loss: 1.5914\n",
      "Baseline Loss: 2.7228 | Actual Loss: 1.2414\n",
      "Baseline Loss: 2.6627 | Actual Loss: 1.1582\n",
      "Baseline Loss: 2.7470 | Actual Loss: 0.9545\n",
      "Baseline Loss: 2.6676 | Actual Loss: 0.8594\n",
      "Baseline Loss: 2.6769 | Actual Loss: 1.0231\n",
      "Baseline Loss: 2.6637 | Actual Loss: 1.1669\n",
      "Baseline Loss: 2.6563 | Actual Loss: 0.9763\n",
      "Baseline Loss: 2.6809 | Actual Loss: 1.0845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 26/1000 [00:08<05:22,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6603 | Actual Loss: 0.8628\n",
      "Baseline Loss: 2.6823 | Actual Loss: 1.1059\n",
      "Baseline Loss: 2.6814 | Actual Loss: 1.1943\n",
      "Baseline Loss: 2.3664 | Actual Loss: 1.4546\n",
      "Baseline Loss: 2.6907 | Actual Loss: 1.1130\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.9866\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.9763\n",
      "Baseline Loss: 2.6117 | Actual Loss: 1.0362\n",
      "Epoch 26/1000: Train Loss: 1.1269, Val Loss: 1.0280\n",
      "New best validation loss: 1.0280\n",
      "Baseline Loss: 2.6557 | Actual Loss: 1.0486\n",
      "Baseline Loss: 2.6662 | Actual Loss: 1.1519\n",
      "Baseline Loss: 2.6865 | Actual Loss: 1.2640\n",
      "Baseline Loss: 2.6553 | Actual Loss: 1.0885\n",
      "Baseline Loss: 2.6776 | Actual Loss: 1.5463\n",
      "Baseline Loss: 2.6575 | Actual Loss: 1.3984\n",
      "Baseline Loss: 2.6512 | Actual Loss: 0.9587\n",
      "Baseline Loss: 2.6803 | Actual Loss: 1.1211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 27/1000 [00:08<05:00,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6620 | Actual Loss: 0.7703\n",
      "Baseline Loss: 2.6731 | Actual Loss: 0.9598\n",
      "Baseline Loss: 2.7462 | Actual Loss: 0.7570\n",
      "Baseline Loss: 2.6562 | Actual Loss: 1.0305\n",
      "Baseline Loss: 2.6508 | Actual Loss: 0.8610\n",
      "Baseline Loss: 2.6653 | Actual Loss: 1.1929\n",
      "Baseline Loss: 2.6878 | Actual Loss: 2.1354\n",
      "Baseline Loss: 2.2369 | Actual Loss: 1.4145\n",
      "Baseline Loss: 2.6907 | Actual Loss: 1.0420\n",
      "Baseline Loss: 2.6644 | Actual Loss: 1.1668\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.8805\n",
      "Baseline Loss: 2.6117 | Actual Loss: 1.1573\n",
      "Epoch 27/1000: Train Loss: 1.1687, Val Loss: 1.0617\n",
      "Baseline Loss: 2.6946 | Actual Loss: 1.0764\n",
      "Baseline Loss: 2.6948 | Actual Loss: 1.0145\n",
      "Baseline Loss: 2.6736 | Actual Loss: 0.8366\n",
      "Baseline Loss: 2.6558 | Actual Loss: 0.8631\n",
      "Baseline Loss: 2.6856 | Actual Loss: 0.8817\n",
      "Baseline Loss: 2.6743 | Actual Loss: 1.4316\n",
      "Baseline Loss: 2.6821 | Actual Loss: 1.0549\n",
      "Baseline Loss: 2.6768 | Actual Loss: 1.2232\n",
      "Baseline Loss: 2.6648 | Actual Loss: 1.2247\n",
      "Baseline Loss: 2.6307 | Actual Loss: 1.0606\n",
      "Baseline Loss: 2.6760 | Actual Loss: 1.0367\n",
      "Baseline Loss: 2.6595 | Actual Loss: 1.1039\n",
      "Baseline Loss: 2.6607 | Actual Loss: 1.0434\n",
      "Baseline Loss: 2.6689 | Actual Loss: 1.4827\n",
      "Baseline Loss: 2.7120 | Actual Loss: 0.7888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 28/1000 [00:08<05:04,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2584 | Actual Loss: 1.0471\n",
      "Baseline Loss: 2.6907 | Actual Loss: 1.3142\n",
      "Baseline Loss: 2.6644 | Actual Loss: 1.0767\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.9578\n",
      "Baseline Loss: 2.6117 | Actual Loss: 1.4056\n",
      "Epoch 28/1000: Train Loss: 1.0731, Val Loss: 1.1886\n",
      "Baseline Loss: 2.6974 | Actual Loss: 1.3201\n",
      "Baseline Loss: 2.6688 | Actual Loss: 1.0790\n",
      "Baseline Loss: 2.6633 | Actual Loss: 1.1065\n",
      "Baseline Loss: 2.7307 | Actual Loss: 1.3569\n",
      "Baseline Loss: 2.6884 | Actual Loss: 0.9024\n",
      "Baseline Loss: 2.6650 | Actual Loss: 1.1475\n",
      "Baseline Loss: 2.6760 | Actual Loss: 0.8821\n",
      "Baseline Loss: 2.6999 | Actual Loss: 0.9290\n",
      "Baseline Loss: 2.6687 | Actual Loss: 0.8186\n",
      "Baseline Loss: 2.6905 | Actual Loss: 0.7348\n",
      "Baseline Loss: 2.6565 | Actual Loss: 1.1391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 29/1000 [00:09<05:18,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6555 | Actual Loss: 1.0271\n",
      "Baseline Loss: 2.6839 | Actual Loss: 1.1871\n",
      "Baseline Loss: 2.6824 | Actual Loss: 0.8067\n",
      "Baseline Loss: 2.6399 | Actual Loss: 1.3109\n",
      "Baseline Loss: 2.2450 | Actual Loss: 0.6093\n",
      "Baseline Loss: 2.6907 | Actual Loss: 1.1220\n",
      "Baseline Loss: 2.6644 | Actual Loss: 1.0180\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.8981\n",
      "Baseline Loss: 2.6117 | Actual Loss: 1.1563\n",
      "Epoch 29/1000: Train Loss: 1.0223, Val Loss: 1.0486\n",
      "Baseline Loss: 2.6604 | Actual Loss: 1.3305\n",
      "Baseline Loss: 2.6778 | Actual Loss: 1.2466\n",
      "Baseline Loss: 2.6597 | Actual Loss: 0.9272\n",
      "Baseline Loss: 2.6438 | Actual Loss: 1.2520\n",
      "Baseline Loss: 2.6673 | Actual Loss: 1.0303\n",
      "Baseline Loss: 2.7559 | Actual Loss: 0.9872\n",
      "Baseline Loss: 2.6911 | Actual Loss: 1.4338\n",
      "Baseline Loss: 2.6643 | Actual Loss: 0.9231\n",
      "Baseline Loss: 2.6520 | Actual Loss: 1.1769\n",
      "Baseline Loss: 2.7035 | Actual Loss: 0.8712\n",
      "Baseline Loss: 2.6769 | Actual Loss: 0.6449\n",
      "Baseline Loss: 2.6353 | Actual Loss: 1.0316\n",
      "Baseline Loss: 2.6392 | Actual Loss: 1.0219\n",
      "Baseline Loss: 2.6756 | Actual Loss: 1.2261\n",
      "Baseline Loss: 2.6952 | Actual Loss: 1.1036\n",
      "Baseline Loss: 2.2768 | Actual Loss: 1.6434\n",
      "Baseline Loss: 2.6907 | Actual Loss: 1.4035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 30/1000 [00:09<04:55,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6644 | Actual Loss: 1.0550\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.8699\n",
      "Baseline Loss: 2.6117 | Actual Loss: 1.0304\n",
      "Epoch 30/1000: Train Loss: 1.1156, Val Loss: 1.0897\n",
      "Baseline Loss: 2.6543 | Actual Loss: 0.7805\n",
      "Baseline Loss: 2.6632 | Actual Loss: 0.8344\n",
      "Baseline Loss: 2.6368 | Actual Loss: 1.0402\n",
      "Baseline Loss: 2.7019 | Actual Loss: 0.7803\n",
      "Baseline Loss: 2.6645 | Actual Loss: 0.8307\n",
      "Baseline Loss: 2.6988 | Actual Loss: 0.9768\n",
      "Baseline Loss: 2.6859 | Actual Loss: 1.1682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 31/1000 [00:09<05:10,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6701 | Actual Loss: 0.9564\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.9620\n",
      "Baseline Loss: 2.7269 | Actual Loss: 1.1591\n",
      "Baseline Loss: 2.6607 | Actual Loss: 0.9054\n",
      "Baseline Loss: 2.6582 | Actual Loss: 1.3857\n",
      "Baseline Loss: 2.6817 | Actual Loss: 1.3179\n",
      "Baseline Loss: 2.6668 | Actual Loss: 0.8676\n",
      "Baseline Loss: 2.6970 | Actual Loss: 0.7507\n",
      "Baseline Loss: 2.3056 | Actual Loss: 0.7814\n",
      "Baseline Loss: 2.6907 | Actual Loss: 1.0795\n",
      "Baseline Loss: 2.6644 | Actual Loss: 1.2613\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.8245\n",
      "Baseline Loss: 2.6117 | Actual Loss: 1.0337\n",
      "Epoch 31/1000: Train Loss: 0.9686, Val Loss: 1.0498\n",
      "Baseline Loss: 2.7000 | Actual Loss: 1.1879\n",
      "Baseline Loss: 2.6425 | Actual Loss: 0.9659\n",
      "Baseline Loss: 2.6799 | Actual Loss: 0.7924\n",
      "Baseline Loss: 2.6211 | Actual Loss: 1.3462\n",
      "Baseline Loss: 2.7197 | Actual Loss: 0.7443\n",
      "Baseline Loss: 2.6417 | Actual Loss: 1.3004\n",
      "Baseline Loss: 2.6681 | Actual Loss: 1.3927\n",
      "Baseline Loss: 2.6573 | Actual Loss: 0.9452\n",
      "Baseline Loss: 2.6789 | Actual Loss: 0.7706\n",
      "Baseline Loss: 2.6546 | Actual Loss: 1.3257\n",
      "Baseline Loss: 2.6951 | Actual Loss: 1.3125\n",
      "Baseline Loss: 2.6626 | Actual Loss: 0.8802\n",
      "Baseline Loss: 2.6975 | Actual Loss: 1.1716\n",
      "Baseline Loss: 2.6749 | Actual Loss: 1.0222\n",
      "Baseline Loss: 2.6967 | Actual Loss: 1.1485\n",
      "Baseline Loss: 2.3252 | Actual Loss: 0.6441\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.9692\n",
      "Baseline Loss: 2.6644 | Actual Loss: 1.1184\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.8166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 32/1000 [00:10<05:14,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6117 | Actual Loss: 0.8024\n",
      "Epoch 32/1000: Train Loss: 1.0594, Val Loss: 0.9267\n",
      "New best validation loss: 0.9267\n",
      "Baseline Loss: 2.6625 | Actual Loss: 1.0160\n",
      "Baseline Loss: 2.6632 | Actual Loss: 1.0185\n",
      "Baseline Loss: 2.6828 | Actual Loss: 0.9596\n",
      "Baseline Loss: 2.7063 | Actual Loss: 1.1782\n",
      "Baseline Loss: 2.6336 | Actual Loss: 1.4099\n",
      "Baseline Loss: 2.6908 | Actual Loss: 1.0706\n",
      "Baseline Loss: 2.7025 | Actual Loss: 1.4836\n",
      "Baseline Loss: 2.6818 | Actual Loss: 0.8965\n",
      "Baseline Loss: 2.6593 | Actual Loss: 0.9851\n",
      "Baseline Loss: 2.6660 | Actual Loss: 0.7122\n",
      "Baseline Loss: 2.6612 | Actual Loss: 0.9002\n",
      "Baseline Loss: 2.7052 | Actual Loss: 0.8029\n",
      "Baseline Loss: 2.6397 | Actual Loss: 0.8669\n",
      "Baseline Loss: 2.7146 | Actual Loss: 1.0490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 33/1000 [00:10<04:50,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6849 | Actual Loss: 1.2182\n",
      "Baseline Loss: 2.3791 | Actual Loss: 0.7796\n",
      "Baseline Loss: 2.6907 | Actual Loss: 1.1457\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.9582\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.6904\n",
      "Baseline Loss: 2.6117 | Actual Loss: 1.1018\n",
      "Epoch 33/1000: Train Loss: 1.0217, Val Loss: 0.9740\n",
      "Baseline Loss: 2.6941 | Actual Loss: 0.9008\n",
      "Baseline Loss: 2.6810 | Actual Loss: 1.1167\n",
      "Baseline Loss: 2.6976 | Actual Loss: 0.8137\n",
      "Baseline Loss: 2.6842 | Actual Loss: 1.1883\n",
      "Baseline Loss: 2.6619 | Actual Loss: 0.7257\n",
      "Baseline Loss: 2.6669 | Actual Loss: 1.3100\n",
      "Baseline Loss: 2.6757 | Actual Loss: 0.7372\n",
      "Baseline Loss: 2.6837 | Actual Loss: 1.0486\n",
      "Baseline Loss: 2.6573 | Actual Loss: 0.8218\n",
      "Baseline Loss: 2.6537 | Actual Loss: 0.9204\n",
      "Baseline Loss: 2.6454 | Actual Loss: 0.8336\n",
      "Baseline Loss: 2.6518 | Actual Loss: 0.8614\n",
      "Baseline Loss: 2.6827 | Actual Loss: 1.1864\n",
      "Baseline Loss: 2.7152 | Actual Loss: 0.8361\n",
      "Baseline Loss: 2.6562 | Actual Loss: 1.0388\n",
      "Baseline Loss: 2.3329 | Actual Loss: 0.7546\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.9588\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.8980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 34/1000 [00:10<05:10,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6840 | Actual Loss: 0.8400\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.9119\n",
      "Epoch 34/1000: Train Loss: 0.9434, Val Loss: 0.9022\n",
      "New best validation loss: 0.9022\n",
      "Baseline Loss: 2.6842 | Actual Loss: 1.0831\n",
      "Baseline Loss: 2.6461 | Actual Loss: 0.8995\n",
      "Baseline Loss: 2.6642 | Actual Loss: 0.8666\n",
      "Baseline Loss: 2.6731 | Actual Loss: 0.7803\n",
      "Baseline Loss: 2.7048 | Actual Loss: 1.1966\n",
      "Baseline Loss: 2.6697 | Actual Loss: 1.3445\n",
      "Baseline Loss: 2.6853 | Actual Loss: 1.0727\n",
      "Baseline Loss: 2.6423 | Actual Loss: 0.9614\n",
      "Baseline Loss: 2.6629 | Actual Loss: 1.1693\n",
      "Baseline Loss: 2.6776 | Actual Loss: 0.7208\n",
      "Baseline Loss: 2.6948 | Actual Loss: 1.4552\n",
      "Baseline Loss: 2.6847 | Actual Loss: 0.8722\n",
      "Baseline Loss: 2.6942 | Actual Loss: 0.8906\n",
      "Baseline Loss: 2.6956 | Actual Loss: 0.9387\n",
      "Baseline Loss: 2.6780 | Actual Loss: 1.0196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 35/1000 [00:11<04:51,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2223 | Actual Loss: 0.8303\n",
      "Baseline Loss: 2.6907 | Actual Loss: 1.0698\n",
      "Baseline Loss: 2.6644 | Actual Loss: 1.0747\n",
      "Baseline Loss: 2.6840 | Actual Loss: 1.0825\n",
      "Baseline Loss: 2.6117 | Actual Loss: 1.0116\n",
      "Epoch 35/1000: Train Loss: 1.0063, Val Loss: 1.0597\n",
      "Baseline Loss: 2.6616 | Actual Loss: 1.1925\n",
      "Baseline Loss: 2.6634 | Actual Loss: 1.1867\n",
      "Baseline Loss: 2.6579 | Actual Loss: 0.9842\n",
      "Baseline Loss: 2.6627 | Actual Loss: 0.6653\n",
      "Baseline Loss: 2.7016 | Actual Loss: 0.5461\n",
      "Baseline Loss: 2.6607 | Actual Loss: 1.3181\n",
      "Baseline Loss: 2.6747 | Actual Loss: 0.9664\n",
      "Baseline Loss: 2.7082 | Actual Loss: 1.0488\n",
      "Baseline Loss: 2.7139 | Actual Loss: 0.7904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 36/1000 [00:11<05:08,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6439 | Actual Loss: 1.1418\n",
      "Baseline Loss: 2.6464 | Actual Loss: 1.1151\n",
      "Baseline Loss: 2.6757 | Actual Loss: 1.1623\n",
      "Baseline Loss: 2.6522 | Actual Loss: 0.7930\n",
      "Baseline Loss: 2.6705 | Actual Loss: 0.8334\n",
      "Baseline Loss: 2.6297 | Actual Loss: 0.8638\n",
      "Baseline Loss: 2.2924 | Actual Loss: 0.5524\n",
      "Baseline Loss: 2.6907 | Actual Loss: 1.0214\n",
      "Baseline Loss: 2.6644 | Actual Loss: 1.0497\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.7379\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.9372\n",
      "Epoch 36/1000: Train Loss: 0.9475, Val Loss: 0.9366\n",
      "Baseline Loss: 2.6634 | Actual Loss: 0.7378\n",
      "Baseline Loss: 2.6746 | Actual Loss: 0.6427\n",
      "Baseline Loss: 2.6720 | Actual Loss: 0.6624\n",
      "Baseline Loss: 2.6496 | Actual Loss: 0.5708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 37/1000 [00:11<04:54,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6487 | Actual Loss: 1.2776\n",
      "Baseline Loss: 2.6502 | Actual Loss: 0.8771\n",
      "Baseline Loss: 2.6607 | Actual Loss: 1.6029\n",
      "Baseline Loss: 2.6973 | Actual Loss: 0.8794\n",
      "Baseline Loss: 2.6899 | Actual Loss: 1.5050\n",
      "Baseline Loss: 2.6637 | Actual Loss: 1.2445\n",
      "Baseline Loss: 2.6817 | Actual Loss: 1.4029\n",
      "Baseline Loss: 2.6824 | Actual Loss: 1.0940\n",
      "Baseline Loss: 2.6700 | Actual Loss: 0.9800\n",
      "Baseline Loss: 2.6976 | Actual Loss: 1.1089\n",
      "Baseline Loss: 2.6693 | Actual Loss: 1.3083\n",
      "Baseline Loss: 2.2673 | Actual Loss: 1.0041\n",
      "Baseline Loss: 2.6907 | Actual Loss: 1.1561\n",
      "Baseline Loss: 2.6644 | Actual Loss: 1.1009\n",
      "Baseline Loss: 2.6840 | Actual Loss: 1.0068\n",
      "Baseline Loss: 2.6117 | Actual Loss: 1.1747\n",
      "Epoch 37/1000: Train Loss: 1.0561, Val Loss: 1.1096\n",
      "Baseline Loss: 2.6882 | Actual Loss: 1.1405\n",
      "Baseline Loss: 2.7176 | Actual Loss: 0.7932\n",
      "Baseline Loss: 2.7067 | Actual Loss: 1.0089\n",
      "Baseline Loss: 2.6709 | Actual Loss: 1.2192\n",
      "Baseline Loss: 2.6649 | Actual Loss: 0.8594\n",
      "Baseline Loss: 2.6533 | Actual Loss: 0.8977\n",
      "Baseline Loss: 2.6464 | Actual Loss: 1.1007\n",
      "Baseline Loss: 2.6712 | Actual Loss: 0.8761\n",
      "Baseline Loss: 2.6535 | Actual Loss: 1.1022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 38/1000 [00:12<05:05,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6433 | Actual Loss: 1.1889\n",
      "Baseline Loss: 2.6534 | Actual Loss: 1.4112\n",
      "Baseline Loss: 2.6660 | Actual Loss: 1.1528\n",
      "Baseline Loss: 2.6496 | Actual Loss: 0.7267\n",
      "Baseline Loss: 2.7067 | Actual Loss: 0.8943\n",
      "Baseline Loss: 2.6835 | Actual Loss: 0.8391\n",
      "Baseline Loss: 2.2936 | Actual Loss: 0.8915\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.9617\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.8456\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.6859\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.7926\n",
      "Epoch 38/1000: Train Loss: 1.0064, Val Loss: 0.8214\n",
      "New best validation loss: 0.8214\n",
      "Baseline Loss: 2.6725 | Actual Loss: 1.1191\n",
      "Baseline Loss: 2.6633 | Actual Loss: 0.6402\n",
      "Baseline Loss: 2.6999 | Actual Loss: 0.9889\n",
      "Baseline Loss: 2.6594 | Actual Loss: 1.0276\n",
      "Baseline Loss: 2.6517 | Actual Loss: 0.7531\n",
      "Baseline Loss: 2.6923 | Actual Loss: 0.8530\n",
      "Baseline Loss: 2.6962 | Actual Loss: 0.8532\n",
      "Baseline Loss: 2.7062 | Actual Loss: 0.6222\n",
      "Baseline Loss: 2.6762 | Actual Loss: 1.0147\n",
      "Baseline Loss: 2.6816 | Actual Loss: 1.0131\n",
      "Baseline Loss: 2.6782 | Actual Loss: 1.0620\n",
      "Baseline Loss: 2.6969 | Actual Loss: 0.8071\n",
      "Baseline Loss: 2.6576 | Actual Loss: 0.6088\n",
      "Baseline Loss: 2.6682 | Actual Loss: 0.8737\n",
      "Baseline Loss: 2.6783 | Actual Loss: 0.6236\n",
      "Baseline Loss: 2.3062 | Actual Loss: 0.7795\n",
      "Baseline Loss: 2.6907 | Actual Loss: 1.1165\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.8853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 39/1000 [00:12<05:10,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6840 | Actual Loss: 0.5256\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.8815\n",
      "Epoch 39/1000: Train Loss: 0.8525, Val Loss: 0.8522\n",
      "Baseline Loss: 2.6855 | Actual Loss: 0.7640\n",
      "Baseline Loss: 2.6383 | Actual Loss: 0.8236\n",
      "Baseline Loss: 2.6885 | Actual Loss: 1.1826\n",
      "Baseline Loss: 2.6585 | Actual Loss: 0.7810\n",
      "Baseline Loss: 2.6621 | Actual Loss: 0.7810\n",
      "Baseline Loss: 2.6610 | Actual Loss: 0.8153\n",
      "Baseline Loss: 2.6562 | Actual Loss: 1.1743\n",
      "Baseline Loss: 2.7088 | Actual Loss: 0.9882\n",
      "Baseline Loss: 2.6949 | Actual Loss: 0.9883\n",
      "Baseline Loss: 2.7109 | Actual Loss: 0.6940\n",
      "Baseline Loss: 2.6701 | Actual Loss: 0.7986\n",
      "Baseline Loss: 2.6923 | Actual Loss: 1.3551\n",
      "Baseline Loss: 2.6900 | Actual Loss: 1.0044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 40/1000 [00:12<04:57,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6688 | Actual Loss: 0.7955\n",
      "Baseline Loss: 2.6811 | Actual Loss: 0.5179\n",
      "Baseline Loss: 2.2650 | Actual Loss: 1.2822\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7263\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.8473\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.5312\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.9870\n",
      "Epoch 40/1000: Train Loss: 0.9216, Val Loss: 0.7730\n",
      "New best validation loss: 0.7730\n",
      "Baseline Loss: 2.6591 | Actual Loss: 0.5561\n",
      "Baseline Loss: 2.6540 | Actual Loss: 1.1786\n",
      "Baseline Loss: 2.6726 | Actual Loss: 0.6746\n",
      "Baseline Loss: 2.6629 | Actual Loss: 0.7428\n",
      "Baseline Loss: 2.7207 | Actual Loss: 1.3485\n",
      "Baseline Loss: 2.6763 | Actual Loss: 0.9044\n",
      "Baseline Loss: 2.6828 | Actual Loss: 1.2054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 41/1000 [00:12<05:04,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6615 | Actual Loss: 0.9314\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.9361\n",
      "Baseline Loss: 2.6885 | Actual Loss: 0.9275\n",
      "Baseline Loss: 2.6516 | Actual Loss: 0.7180\n",
      "Baseline Loss: 2.6506 | Actual Loss: 0.9587\n",
      "Baseline Loss: 2.6185 | Actual Loss: 0.9467\n",
      "Baseline Loss: 2.7106 | Actual Loss: 0.7946\n",
      "Baseline Loss: 2.6473 | Actual Loss: 0.8113\n",
      "Baseline Loss: 2.3181 | Actual Loss: 0.2573\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7545\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.7814\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.8087\n",
      "Baseline Loss: 2.6117 | Actual Loss: 1.1575\n",
      "Epoch 41/1000: Train Loss: 0.8682, Val Loss: 0.8755\n",
      "Baseline Loss: 2.6979 | Actual Loss: 0.7817\n",
      "Baseline Loss: 2.6525 | Actual Loss: 0.8931\n",
      "Baseline Loss: 2.6628 | Actual Loss: 2.0151\n",
      "Baseline Loss: 2.7069 | Actual Loss: 0.7654\n",
      "Baseline Loss: 2.6666 | Actual Loss: 0.4187\n",
      "Baseline Loss: 2.6985 | Actual Loss: 1.0979\n",
      "Baseline Loss: 2.6774 | Actual Loss: 1.4227\n",
      "Baseline Loss: 2.6960 | Actual Loss: 0.7444\n",
      "Baseline Loss: 2.6597 | Actual Loss: 0.8687\n",
      "Baseline Loss: 2.6407 | Actual Loss: 0.9601\n",
      "Baseline Loss: 2.6827 | Actual Loss: 0.8788\n",
      "Baseline Loss: 2.6821 | Actual Loss: 1.4605\n",
      "Baseline Loss: 2.6670 | Actual Loss: 0.7941\n",
      "Baseline Loss: 2.6707 | Actual Loss: 0.8523\n",
      "Baseline Loss: 2.6433 | Actual Loss: 0.9501\n",
      "Baseline Loss: 2.2693 | Actual Loss: 0.7076\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.9034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 42/1000 [00:13<05:05,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6644 | Actual Loss: 0.8876\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.8305\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.9298\n",
      "Epoch 42/1000: Train Loss: 0.9757, Val Loss: 0.8878\n",
      "Baseline Loss: 2.6672 | Actual Loss: 0.9655\n",
      "Baseline Loss: 2.6641 | Actual Loss: 1.0727\n",
      "Baseline Loss: 2.6696 | Actual Loss: 0.8040\n",
      "Baseline Loss: 2.6965 | Actual Loss: 0.9839\n",
      "Baseline Loss: 2.6943 | Actual Loss: 0.7876\n",
      "Baseline Loss: 2.7026 | Actual Loss: 0.7567\n",
      "Baseline Loss: 2.6820 | Actual Loss: 0.7846\n",
      "Baseline Loss: 2.6893 | Actual Loss: 0.7742\n",
      "Baseline Loss: 2.6764 | Actual Loss: 2.0622\n",
      "Baseline Loss: 2.6781 | Actual Loss: 0.8727\n",
      "Baseline Loss: 2.6471 | Actual Loss: 0.6565\n",
      "Baseline Loss: 2.6523 | Actual Loss: 1.3555\n",
      "Baseline Loss: 2.6829 | Actual Loss: 1.0052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 43/1000 [00:13<04:52,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6610 | Actual Loss: 0.7984\n",
      "Baseline Loss: 2.6385 | Actual Loss: 0.6406\n",
      "Baseline Loss: 2.2373 | Actual Loss: 0.5346\n",
      "Baseline Loss: 2.6907 | Actual Loss: 1.0338\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.8760\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.7021\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.7510\n",
      "Epoch 43/1000: Train Loss: 0.9284, Val Loss: 0.8407\n",
      "Baseline Loss: 2.6753 | Actual Loss: 0.9583\n",
      "Baseline Loss: 2.6634 | Actual Loss: 0.9294\n",
      "Baseline Loss: 2.6714 | Actual Loss: 0.8675\n",
      "Baseline Loss: 2.7044 | Actual Loss: 1.0766\n",
      "Baseline Loss: 2.6631 | Actual Loss: 0.9968\n",
      "Baseline Loss: 2.6568 | Actual Loss: 0.8881\n",
      "Baseline Loss: 2.6517 | Actual Loss: 0.8261\n",
      "Baseline Loss: 2.6466 | Actual Loss: 0.9331\n",
      "Baseline Loss: 2.6573 | Actual Loss: 0.9291\n",
      "Baseline Loss: 2.7004 | Actual Loss: 0.5987\n",
      "Baseline Loss: 2.6800 | Actual Loss: 0.7701\n",
      "Baseline Loss: 2.6725 | Actual Loss: 1.1672\n",
      "Baseline Loss: 2.7011 | Actual Loss: 0.7759\n",
      "Baseline Loss: 2.6888 | Actual Loss: 0.7849\n",
      "Baseline Loss: 2.6689 | Actual Loss: 0.7985\n",
      "Baseline Loss: 2.4119 | Actual Loss: 1.0786\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.9852\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.7930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 44/1000 [00:13<05:05,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6840 | Actual Loss: 0.8052\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.8248\n",
      "Epoch 44/1000: Train Loss: 0.8987, Val Loss: 0.8520\n",
      "Baseline Loss: 2.6475 | Actual Loss: 1.0378\n",
      "Baseline Loss: 2.6565 | Actual Loss: 0.9820\n",
      "Baseline Loss: 2.6602 | Actual Loss: 0.9800\n",
      "Baseline Loss: 2.6950 | Actual Loss: 0.7001\n",
      "Baseline Loss: 2.7075 | Actual Loss: 0.7828\n",
      "Baseline Loss: 2.6430 | Actual Loss: 1.0785\n",
      "Baseline Loss: 2.6737 | Actual Loss: 0.5414\n",
      "Baseline Loss: 2.6437 | Actual Loss: 0.7928\n",
      "Baseline Loss: 2.6668 | Actual Loss: 0.8903\n",
      "Baseline Loss: 2.7034 | Actual Loss: 0.9126\n",
      "Baseline Loss: 2.6960 | Actual Loss: 0.7930\n",
      "Baseline Loss: 2.6508 | Actual Loss: 0.6900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 45/1000 [00:14<05:11,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6473 | Actual Loss: 0.6425\n",
      "Baseline Loss: 2.6738 | Actual Loss: 0.8030\n",
      "Baseline Loss: 2.6611 | Actual Loss: 0.5467\n",
      "Baseline Loss: 2.2993 | Actual Loss: 0.5682\n",
      "Baseline Loss: 2.6907 | Actual Loss: 1.0535\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.8317\n",
      "Baseline Loss: 2.6840 | Actual Loss: 1.1578\n",
      "Baseline Loss: 2.6117 | Actual Loss: 1.1761\n",
      "Epoch 45/1000: Train Loss: 0.7963, Val Loss: 1.0547\n",
      "Baseline Loss: 2.6540 | Actual Loss: 1.4523\n",
      "Baseline Loss: 2.6714 | Actual Loss: 0.8079\n",
      "Baseline Loss: 2.6722 | Actual Loss: 1.2610\n",
      "Baseline Loss: 2.6561 | Actual Loss: 1.0795\n",
      "Baseline Loss: 2.6625 | Actual Loss: 0.4289\n",
      "Baseline Loss: 2.6799 | Actual Loss: 0.8781\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.8058\n",
      "Baseline Loss: 2.6932 | Actual Loss: 0.8583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 46/1000 [00:14<04:56,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7224 | Actual Loss: 0.9865\n",
      "Baseline Loss: 2.6867 | Actual Loss: 0.9760\n",
      "Baseline Loss: 2.6583 | Actual Loss: 1.0064\n",
      "Baseline Loss: 2.6569 | Actual Loss: 1.0133\n",
      "Baseline Loss: 2.6595 | Actual Loss: 0.6738\n",
      "Baseline Loss: 2.6915 | Actual Loss: 1.0571\n",
      "Baseline Loss: 2.6608 | Actual Loss: 0.7319\n",
      "Baseline Loss: 2.3074 | Actual Loss: 1.4462\n",
      "Baseline Loss: 2.6907 | Actual Loss: 1.0731\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.7992\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.7386\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.7386\n",
      "Epoch 46/1000: Train Loss: 0.9664, Val Loss: 0.8374\n",
      "Baseline Loss: 2.6357 | Actual Loss: 1.2215\n",
      "Baseline Loss: 2.6430 | Actual Loss: 0.7342\n",
      "Baseline Loss: 2.7109 | Actual Loss: 0.9224\n",
      "Baseline Loss: 2.6928 | Actual Loss: 1.0716\n",
      "Baseline Loss: 2.6619 | Actual Loss: 0.5473\n",
      "Baseline Loss: 2.6705 | Actual Loss: 1.0512\n",
      "Baseline Loss: 2.6473 | Actual Loss: 1.2037\n",
      "Baseline Loss: 2.6972 | Actual Loss: 0.9262\n",
      "Baseline Loss: 2.6714 | Actual Loss: 1.0007\n",
      "Baseline Loss: 2.6815 | Actual Loss: 0.7670\n",
      "Baseline Loss: 2.6664 | Actual Loss: 0.6468\n",
      "Baseline Loss: 2.6813 | Actual Loss: 0.6743\n",
      "Baseline Loss: 2.6663 | Actual Loss: 0.8465\n",
      "Baseline Loss: 2.6863 | Actual Loss: 0.5993\n",
      "Baseline Loss: 2.6962 | Actual Loss: 0.8381\n",
      "Baseline Loss: 2.2187 | Actual Loss: 1.5427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 47/1000 [00:14<05:03,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6907 | Actual Loss: 1.3765\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.7098\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.7291\n",
      "Baseline Loss: 2.6117 | Actual Loss: 1.1188\n",
      "Epoch 47/1000: Train Loss: 0.9121, Val Loss: 0.9836\n",
      "Baseline Loss: 2.6752 | Actual Loss: 0.7040\n",
      "Baseline Loss: 2.6766 | Actual Loss: 1.5433\n",
      "Baseline Loss: 2.6897 | Actual Loss: 0.8764\n",
      "Baseline Loss: 2.6632 | Actual Loss: 0.7229\n",
      "Baseline Loss: 2.6454 | Actual Loss: 0.8456\n",
      "Baseline Loss: 2.6760 | Actual Loss: 0.7332\n",
      "Baseline Loss: 2.6757 | Actual Loss: 0.7634\n",
      "Baseline Loss: 2.7015 | Actual Loss: 1.0795\n",
      "Baseline Loss: 2.6980 | Actual Loss: 0.6331\n",
      "Baseline Loss: 2.6505 | Actual Loss: 0.8954\n",
      "Baseline Loss: 2.6820 | Actual Loss: 0.8299\n",
      "Baseline Loss: 2.6730 | Actual Loss: 0.8711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 48/1000 [00:15<05:07,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6600 | Actual Loss: 1.0209\n",
      "Baseline Loss: 2.6536 | Actual Loss: 0.7991\n",
      "Baseline Loss: 2.7215 | Actual Loss: 0.4419\n",
      "Baseline Loss: 2.2549 | Actual Loss: 0.8061\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.8667\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.7571\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.7290\n",
      "Baseline Loss: 2.6117 | Actual Loss: 1.0102\n",
      "Epoch 48/1000: Train Loss: 0.8479, Val Loss: 0.8408\n",
      "Baseline Loss: 2.6835 | Actual Loss: 0.9842\n",
      "Baseline Loss: 2.6802 | Actual Loss: 0.8069\n",
      "Baseline Loss: 2.6643 | Actual Loss: 0.9481\n",
      "Baseline Loss: 2.6951 | Actual Loss: 1.3397\n",
      "Baseline Loss: 2.6845 | Actual Loss: 1.0527\n",
      "Baseline Loss: 2.6451 | Actual Loss: 0.7819\n",
      "Baseline Loss: 2.6781 | Actual Loss: 0.9529\n",
      "Baseline Loss: 2.6811 | Actual Loss: 0.5481\n",
      "Baseline Loss: 2.6894 | Actual Loss: 0.8649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 49/1000 [00:15<04:47,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6847 | Actual Loss: 0.7253\n",
      "Baseline Loss: 2.6596 | Actual Loss: 0.8888\n",
      "Baseline Loss: 2.6627 | Actual Loss: 0.8000\n",
      "Baseline Loss: 2.6877 | Actual Loss: 1.0685\n",
      "Baseline Loss: 2.6959 | Actual Loss: 0.9338\n",
      "Baseline Loss: 2.6737 | Actual Loss: 0.8540\n",
      "Baseline Loss: 2.2395 | Actual Loss: 0.9953\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7889\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.7527\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.7020\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.9419\n",
      "Epoch 49/1000: Train Loss: 0.9091, Val Loss: 0.7964\n",
      "Baseline Loss: 2.6557 | Actual Loss: 0.7859\n",
      "Baseline Loss: 2.6774 | Actual Loss: 1.3720\n",
      "Baseline Loss: 2.6724 | Actual Loss: 0.8017\n",
      "Baseline Loss: 2.6729 | Actual Loss: 0.7514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 50/1000 [00:15<04:59,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6699 | Actual Loss: 0.7837\n",
      "Baseline Loss: 2.6608 | Actual Loss: 0.6203\n",
      "Baseline Loss: 2.6901 | Actual Loss: 0.5202\n",
      "Baseline Loss: 2.6745 | Actual Loss: 0.7621\n",
      "Baseline Loss: 2.6986 | Actual Loss: 0.7207\n",
      "Baseline Loss: 2.6613 | Actual Loss: 0.8425\n",
      "Baseline Loss: 2.6787 | Actual Loss: 0.4668\n",
      "Baseline Loss: 2.6987 | Actual Loss: 0.8260\n",
      "Baseline Loss: 2.6536 | Actual Loss: 1.0272\n",
      "Baseline Loss: 2.6858 | Actual Loss: 0.5352\n",
      "Baseline Loss: 2.6356 | Actual Loss: 0.9065\n",
      "Baseline Loss: 2.2809 | Actual Loss: 0.4531\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.9441\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.7098\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.6873\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.7573\n",
      "Epoch 50/1000: Train Loss: 0.7610, Val Loss: 0.7746\n",
      "Baseline Loss: 2.7230 | Actual Loss: 1.0298\n",
      "Baseline Loss: 2.6769 | Actual Loss: 0.6465\n",
      "Baseline Loss: 2.6397 | Actual Loss: 0.6997\n",
      "Baseline Loss: 2.6642 | Actual Loss: 0.8785\n",
      "Baseline Loss: 2.6759 | Actual Loss: 0.5469\n",
      "Baseline Loss: 2.6904 | Actual Loss: 0.6242\n",
      "Baseline Loss: 2.6731 | Actual Loss: 0.9914\n",
      "Baseline Loss: 2.6772 | Actual Loss: 0.6011\n",
      "Baseline Loss: 2.6866 | Actual Loss: 0.7911\n",
      "Baseline Loss: 2.6805 | Actual Loss: 0.8824\n",
      "Baseline Loss: 2.6294 | Actual Loss: 0.3322\n",
      "Baseline Loss: 2.6824 | Actual Loss: 0.5537\n",
      "Baseline Loss: 2.6662 | Actual Loss: 0.6942\n",
      "Baseline Loss: 2.6999 | Actual Loss: 0.8018\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.8685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 51/1000 [00:16<05:11,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2202 | Actual Loss: 0.5281\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.9377\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.7640\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.5152\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.7163\n",
      "Epoch 51/1000: Train Loss: 0.7169, Val Loss: 0.7333\n",
      "New best validation loss: 0.7333\n",
      "Baseline Loss: 2.7014 | Actual Loss: 0.9180\n",
      "Baseline Loss: 2.6456 | Actual Loss: 0.7670\n",
      "Baseline Loss: 2.6759 | Actual Loss: 0.8365\n",
      "Baseline Loss: 2.6776 | Actual Loss: 0.8859\n",
      "Baseline Loss: 2.6603 | Actual Loss: 0.8705\n",
      "Baseline Loss: 2.6820 | Actual Loss: 0.8060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 52/1000 [00:16<04:48,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6951 | Actual Loss: 0.4710\n",
      "Baseline Loss: 2.6930 | Actual Loss: 0.7124\n",
      "Baseline Loss: 2.6584 | Actual Loss: 0.6351\n",
      "Baseline Loss: 2.6686 | Actual Loss: 1.3017\n",
      "Baseline Loss: 2.7026 | Actual Loss: 1.2464\n",
      "Baseline Loss: 2.6903 | Actual Loss: 0.9524\n",
      "Baseline Loss: 2.6581 | Actual Loss: 0.8108\n",
      "Baseline Loss: 2.6914 | Actual Loss: 0.6240\n",
      "Baseline Loss: 2.6751 | Actual Loss: 1.1171\n",
      "Baseline Loss: 2.2942 | Actual Loss: 0.6106\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.9131\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.7321\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.7024\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.7910\n",
      "Epoch 52/1000: Train Loss: 0.8478, Val Loss: 0.7847\n",
      "Baseline Loss: 2.6556 | Actual Loss: 0.8198\n",
      "Baseline Loss: 2.6999 | Actual Loss: 0.7435\n",
      "Baseline Loss: 2.6597 | Actual Loss: 1.0806\n",
      "Baseline Loss: 2.6659 | Actual Loss: 0.6458\n",
      "Baseline Loss: 2.6528 | Actual Loss: 0.7747\n",
      "Baseline Loss: 2.6621 | Actual Loss: 0.9670\n",
      "Baseline Loss: 2.6941 | Actual Loss: 0.7218\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.2418\n",
      "Baseline Loss: 2.6824 | Actual Loss: 0.7226\n",
      "Baseline Loss: 2.6991 | Actual Loss: 0.7919\n",
      "Baseline Loss: 2.6852 | Actual Loss: 0.5174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 53/1000 [00:16<05:01,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6427 | Actual Loss: 0.5932\n",
      "Baseline Loss: 2.6321 | Actual Loss: 0.7951\n",
      "Baseline Loss: 2.6759 | Actual Loss: 0.8822\n",
      "Baseline Loss: 2.6393 | Actual Loss: 0.3255\n",
      "Baseline Loss: 2.3644 | Actual Loss: 0.2306\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.9430\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.8341\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.6273\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.6738\n",
      "Epoch 53/1000: Train Loss: 0.7408, Val Loss: 0.7696\n",
      "Baseline Loss: 2.6583 | Actual Loss: 0.9191\n",
      "Baseline Loss: 2.6700 | Actual Loss: 0.9773\n",
      "Baseline Loss: 2.6691 | Actual Loss: 0.7155\n",
      "Baseline Loss: 2.7195 | Actual Loss: 0.8645\n",
      "Baseline Loss: 2.6553 | Actual Loss: 0.3162\n",
      "Baseline Loss: 2.6413 | Actual Loss: 0.9849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 54/1000 [00:17<04:48,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7238 | Actual Loss: 0.5677\n",
      "Baseline Loss: 2.6823 | Actual Loss: 0.8960\n",
      "Baseline Loss: 2.6760 | Actual Loss: 0.5413\n",
      "Baseline Loss: 2.7038 | Actual Loss: 0.4993\n",
      "Baseline Loss: 2.6943 | Actual Loss: 0.9136\n",
      "Baseline Loss: 2.6533 | Actual Loss: 0.6545\n",
      "Baseline Loss: 2.6453 | Actual Loss: 0.8796\n",
      "Baseline Loss: 2.6670 | Actual Loss: 0.8275\n",
      "Baseline Loss: 2.6847 | Actual Loss: 0.9487\n",
      "Baseline Loss: 2.2120 | Actual Loss: 0.1530\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.8534\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.8110\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.6672\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.7276\n",
      "Epoch 54/1000: Train Loss: 0.7287, Val Loss: 0.7648\n",
      "Baseline Loss: 2.6725 | Actual Loss: 0.5076\n",
      "Baseline Loss: 2.6761 | Actual Loss: 0.9600\n",
      "Baseline Loss: 2.7081 | Actual Loss: 0.8327\n",
      "Baseline Loss: 2.6682 | Actual Loss: 0.6368\n",
      "Baseline Loss: 2.7001 | Actual Loss: 0.5478\n",
      "Baseline Loss: 2.6368 | Actual Loss: 0.8116\n",
      "Baseline Loss: 2.6710 | Actual Loss: 0.5336\n",
      "Baseline Loss: 2.6747 | Actual Loss: 0.6543\n",
      "Baseline Loss: 2.6576 | Actual Loss: 0.6755\n",
      "Baseline Loss: 2.6524 | Actual Loss: 0.5328\n",
      "Baseline Loss: 2.6574 | Actual Loss: 0.5444\n",
      "Baseline Loss: 2.7025 | Actual Loss: 1.5605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 55/1000 [00:17<04:57,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6416 | Actual Loss: 2.2229\n",
      "Baseline Loss: 2.6668 | Actual Loss: 1.1118\n",
      "Baseline Loss: 2.6770 | Actual Loss: 0.6368\n",
      "Baseline Loss: 2.2608 | Actual Loss: 0.8281\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.9359\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.6104\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.7042\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.8277\n",
      "Epoch 55/1000: Train Loss: 0.8498, Val Loss: 0.7695\n",
      "Baseline Loss: 2.6925 | Actual Loss: 0.6715\n",
      "Baseline Loss: 2.6851 | Actual Loss: 0.8485\n",
      "Baseline Loss: 2.6868 | Actual Loss: 0.8876\n",
      "Baseline Loss: 2.6616 | Actual Loss: 0.9785\n",
      "Baseline Loss: 2.7010 | Actual Loss: 0.8134\n",
      "Baseline Loss: 2.6698 | Actual Loss: 0.4571\n",
      "Baseline Loss: 2.6817 | Actual Loss: 0.6585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 56/1000 [00:17<04:37,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6864 | Actual Loss: 0.6852\n",
      "Baseline Loss: 2.6868 | Actual Loss: 0.4751\n",
      "Baseline Loss: 2.6631 | Actual Loss: 1.0947\n",
      "Baseline Loss: 2.6716 | Actual Loss: 0.7130\n",
      "Baseline Loss: 2.6633 | Actual Loss: 0.6602\n",
      "Baseline Loss: 2.6650 | Actual Loss: 0.7698\n",
      "Baseline Loss: 2.6797 | Actual Loss: 0.7880\n",
      "Baseline Loss: 2.6619 | Actual Loss: 0.4505\n",
      "Baseline Loss: 2.2399 | Actual Loss: 0.1512\n",
      "Baseline Loss: 2.6907 | Actual Loss: 1.0486\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.6230\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.6654\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.9190\n",
      "Epoch 56/1000: Train Loss: 0.6939, Val Loss: 0.8140\n",
      "Baseline Loss: 2.6768 | Actual Loss: 0.7504\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.6815\n",
      "Baseline Loss: 2.6590 | Actual Loss: 0.6509\n",
      "Baseline Loss: 2.7044 | Actual Loss: 1.7321\n",
      "Baseline Loss: 2.6511 | Actual Loss: 0.5203\n",
      "Baseline Loss: 2.6614 | Actual Loss: 0.8759\n",
      "Baseline Loss: 2.6885 | Actual Loss: 0.3676\n",
      "Baseline Loss: 2.6495 | Actual Loss: 1.0279\n",
      "Baseline Loss: 2.6549 | Actual Loss: 0.8867\n",
      "Baseline Loss: 2.6490 | Actual Loss: 0.7212\n",
      "Baseline Loss: 2.6725 | Actual Loss: 0.7926\n",
      "Baseline Loss: 2.6523 | Actual Loss: 0.8993\n",
      "Baseline Loss: 2.6803 | Actual Loss: 0.7860\n",
      "Baseline Loss: 2.6768 | Actual Loss: 0.7535\n",
      "Baseline Loss: 2.6850 | Actual Loss: 0.6591\n",
      "Baseline Loss: 2.2368 | Actual Loss: 0.4557\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.8063\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.6262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 57/1000 [00:17<04:51,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6840 | Actual Loss: 0.6706\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.8670\n",
      "Epoch 57/1000: Train Loss: 0.7850, Val Loss: 0.7425\n",
      "Baseline Loss: 2.6959 | Actual Loss: 0.6304\n",
      "Baseline Loss: 2.6479 | Actual Loss: 1.1477\n",
      "Baseline Loss: 2.6607 | Actual Loss: 0.7971\n",
      "Baseline Loss: 2.6885 | Actual Loss: 0.3575\n",
      "Baseline Loss: 2.6670 | Actual Loss: 0.5777\n",
      "Baseline Loss: 2.6980 | Actual Loss: 0.7523\n",
      "Baseline Loss: 2.6653 | Actual Loss: 0.8217\n",
      "Baseline Loss: 2.6969 | Actual Loss: 0.7594\n",
      "Baseline Loss: 2.6727 | Actual Loss: 0.8818\n",
      "Baseline Loss: 2.6520 | Actual Loss: 1.3707\n",
      "Baseline Loss: 2.6515 | Actual Loss: 0.7353\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.6603\n",
      "Baseline Loss: 2.7011 | Actual Loss: 0.7673\n",
      "Baseline Loss: 2.6823 | Actual Loss: 0.8538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 58/1000 [00:18<04:57,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6652 | Actual Loss: 0.7825\n",
      "Baseline Loss: 2.2638 | Actual Loss: 0.2179\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7058\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.5367\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4787\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.6995\n",
      "Epoch 58/1000: Train Loss: 0.7571, Val Loss: 0.6052\n",
      "New best validation loss: 0.6052\n",
      "Baseline Loss: 2.6639 | Actual Loss: 0.6077\n",
      "Baseline Loss: 2.6972 | Actual Loss: 0.8951\n",
      "Baseline Loss: 2.6730 | Actual Loss: 0.7126\n",
      "Baseline Loss: 2.6984 | Actual Loss: 1.1210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 59/1000 [00:18<04:35,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6479 | Actual Loss: 0.7534\n",
      "Baseline Loss: 2.6811 | Actual Loss: 0.7543\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.6850\n",
      "Baseline Loss: 2.6967 | Actual Loss: 0.7789\n",
      "Baseline Loss: 2.6703 | Actual Loss: 0.6652\n",
      "Baseline Loss: 2.7174 | Actual Loss: 0.7795\n",
      "Baseline Loss: 2.6663 | Actual Loss: 1.8061\n",
      "Baseline Loss: 2.7014 | Actual Loss: 0.3634\n",
      "Baseline Loss: 2.6682 | Actual Loss: 0.5106\n",
      "Baseline Loss: 2.6531 | Actual Loss: 0.4605\n",
      "Baseline Loss: 2.6566 | Actual Loss: 0.7390\n",
      "Baseline Loss: 2.2217 | Actual Loss: 0.5214\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.8217\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.7009\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.5934\n",
      "Baseline Loss: 2.6117 | Actual Loss: 1.0679\n",
      "Epoch 59/1000: Train Loss: 0.7596, Val Loss: 0.7960\n",
      "Baseline Loss: 2.6523 | Actual Loss: 0.9690\n",
      "Baseline Loss: 2.6858 | Actual Loss: 0.3596\n",
      "Baseline Loss: 2.6721 | Actual Loss: 0.3627\n",
      "Baseline Loss: 2.6608 | Actual Loss: 0.6354\n",
      "Baseline Loss: 2.6330 | Actual Loss: 0.8919\n",
      "Baseline Loss: 2.7065 | Actual Loss: 0.3873\n",
      "Baseline Loss: 2.6571 | Actual Loss: 0.7443\n",
      "Baseline Loss: 2.6517 | Actual Loss: 0.8344\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.8585\n",
      "Baseline Loss: 2.6621 | Actual Loss: 0.9294\n",
      "Baseline Loss: 2.6627 | Actual Loss: 0.7647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 60/1000 [00:18<04:51,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7128 | Actual Loss: 0.4946\n",
      "Baseline Loss: 2.6850 | Actual Loss: 0.7141\n",
      "Baseline Loss: 2.7213 | Actual Loss: 0.5040\n",
      "Baseline Loss: 2.7075 | Actual Loss: 1.8631\n",
      "Baseline Loss: 2.2156 | Actual Loss: 0.6034\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.8113\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.6348\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.7554\n",
      "Baseline Loss: 2.6117 | Actual Loss: 1.0690\n",
      "Epoch 60/1000: Train Loss: 0.7448, Val Loss: 0.8176\n",
      "Baseline Loss: 2.6673 | Actual Loss: 0.5673\n",
      "Baseline Loss: 2.7073 | Actual Loss: 0.8594\n",
      "Baseline Loss: 2.6918 | Actual Loss: 0.5160\n",
      "Baseline Loss: 2.6552 | Actual Loss: 0.6938\n",
      "Baseline Loss: 2.6588 | Actual Loss: 0.8916\n",
      "Baseline Loss: 2.6516 | Actual Loss: 0.6686\n",
      "Baseline Loss: 2.6249 | Actual Loss: 0.8454\n",
      "Baseline Loss: 2.6782 | Actual Loss: 0.7664\n",
      "Baseline Loss: 2.7058 | Actual Loss: 0.7978\n",
      "Baseline Loss: 2.6781 | Actual Loss: 0.7912\n",
      "Baseline Loss: 2.6766 | Actual Loss: 0.8939\n",
      "Baseline Loss: 2.6991 | Actual Loss: 0.9282\n",
      "Baseline Loss: 2.6869 | Actual Loss: 1.1353\n",
      "Baseline Loss: 2.6707 | Actual Loss: 0.5759\n",
      "Baseline Loss: 2.7104 | Actual Loss: 0.7561\n",
      "Baseline Loss: 2.2871 | Actual Loss: 0.4016\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.8648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 61/1000 [00:19<04:58,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6644 | Actual Loss: 0.5736\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.5161\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.6562\n",
      "Epoch 61/1000: Train Loss: 0.7555, Val Loss: 0.6527\n",
      "Baseline Loss: 2.6818 | Actual Loss: 0.6397\n",
      "Baseline Loss: 2.6889 | Actual Loss: 1.2042\n",
      "Baseline Loss: 2.6784 | Actual Loss: 0.6135\n",
      "Baseline Loss: 2.6915 | Actual Loss: 0.5051\n",
      "Baseline Loss: 2.6505 | Actual Loss: 0.5388\n",
      "Baseline Loss: 2.7081 | Actual Loss: 0.4251\n",
      "Baseline Loss: 2.7020 | Actual Loss: 0.7513\n",
      "Baseline Loss: 2.6769 | Actual Loss: 0.2282\n",
      "Baseline Loss: 2.7161 | Actual Loss: 0.9682\n",
      "Baseline Loss: 2.6498 | Actual Loss: 0.7629\n",
      "Baseline Loss: 2.6955 | Actual Loss: 0.4636\n",
      "Baseline Loss: 2.6695 | Actual Loss: 0.5537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 62/1000 [00:19<04:41,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6417 | Actual Loss: 0.6355\n",
      "Baseline Loss: 2.6576 | Actual Loss: 1.0130\n",
      "Baseline Loss: 2.6774 | Actual Loss: 0.9236\n",
      "Baseline Loss: 2.2850 | Actual Loss: 0.2878\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.8299\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.7678\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.7016\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.7223\n",
      "Epoch 62/1000: Train Loss: 0.6572, Val Loss: 0.7554\n",
      "Baseline Loss: 2.6771 | Actual Loss: 0.5836\n",
      "Baseline Loss: 2.6484 | Actual Loss: 0.6996\n",
      "Baseline Loss: 2.6717 | Actual Loss: 0.3570\n",
      "Baseline Loss: 2.6824 | Actual Loss: 0.6169\n",
      "Baseline Loss: 2.6747 | Actual Loss: 0.4564\n",
      "Baseline Loss: 2.6640 | Actual Loss: 1.5358\n",
      "Baseline Loss: 2.6841 | Actual Loss: 0.6597\n",
      "Baseline Loss: 2.6901 | Actual Loss: 0.8638\n",
      "Baseline Loss: 2.6964 | Actual Loss: 0.7298\n",
      "Baseline Loss: 2.6872 | Actual Loss: 0.7741\n",
      "Baseline Loss: 2.6666 | Actual Loss: 0.8697\n",
      "Baseline Loss: 2.6359 | Actual Loss: 0.3494\n",
      "Baseline Loss: 2.6560 | Actual Loss: 1.5393\n",
      "Baseline Loss: 2.6456 | Actual Loss: 0.7198\n",
      "Baseline Loss: 2.6851 | Actual Loss: 0.6420\n",
      "Baseline Loss: 2.2963 | Actual Loss: 0.3323\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.8245\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.6527\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.5611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 63/1000 [00:19<04:52,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6117 | Actual Loss: 0.6433\n",
      "Epoch 63/1000: Train Loss: 0.7331, Val Loss: 0.6704\n",
      "Baseline Loss: 2.6427 | Actual Loss: 0.9806\n",
      "Baseline Loss: 2.6934 | Actual Loss: 0.7984\n",
      "Baseline Loss: 2.6976 | Actual Loss: 0.5978\n",
      "Baseline Loss: 2.7215 | Actual Loss: 0.6759\n",
      "Baseline Loss: 2.6821 | Actual Loss: 0.4491\n",
      "Baseline Loss: 2.7062 | Actual Loss: 1.1431\n",
      "Baseline Loss: 2.6177 | Actual Loss: 0.2296\n",
      "Baseline Loss: 2.6865 | Actual Loss: 0.7752\n",
      "Baseline Loss: 2.6667 | Actual Loss: 1.2541\n",
      "Baseline Loss: 2.7084 | Actual Loss: 0.6181\n",
      "Baseline Loss: 2.6616 | Actual Loss: 0.6532\n",
      "Baseline Loss: 2.6938 | Actual Loss: 0.4363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 64/1000 [00:20<05:02,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7175 | Actual Loss: 0.3134\n",
      "Baseline Loss: 2.6478 | Actual Loss: 0.4809\n",
      "Baseline Loss: 2.6821 | Actual Loss: 0.9577\n",
      "Baseline Loss: 2.2853 | Actual Loss: 1.9995\n",
      "Baseline Loss: 2.6907 | Actual Loss: 1.0479\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.8294\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.7534\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.7701\n",
      "Epoch 64/1000: Train Loss: 0.7727, Val Loss: 0.8502\n",
      "Baseline Loss: 2.6565 | Actual Loss: 0.7206\n",
      "Baseline Loss: 2.6877 | Actual Loss: 0.6810\n",
      "Baseline Loss: 2.6978 | Actual Loss: 0.7389\n",
      "Baseline Loss: 2.6540 | Actual Loss: 0.7174\n",
      "Baseline Loss: 2.6874 | Actual Loss: 0.7507\n",
      "Baseline Loss: 2.6930 | Actual Loss: 0.5863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 65/1000 [00:20<04:51,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7223 | Actual Loss: 0.3427\n",
      "Baseline Loss: 2.6545 | Actual Loss: 0.9044\n",
      "Baseline Loss: 2.6454 | Actual Loss: 0.6994\n",
      "Baseline Loss: 2.7046 | Actual Loss: 0.5157\n",
      "Baseline Loss: 2.6913 | Actual Loss: 0.7347\n",
      "Baseline Loss: 2.6542 | Actual Loss: 0.7084\n",
      "Baseline Loss: 2.6294 | Actual Loss: 0.5455\n",
      "Baseline Loss: 2.6827 | Actual Loss: 0.5548\n",
      "Baseline Loss: 2.6841 | Actual Loss: 0.6088\n",
      "Baseline Loss: 2.2120 | Actual Loss: 0.8189\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.8335\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.6305\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3567\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.6929\n",
      "Epoch 65/1000: Train Loss: 0.6643, Val Loss: 0.6284\n",
      "Baseline Loss: 2.6664 | Actual Loss: 0.6574\n",
      "Baseline Loss: 2.6599 | Actual Loss: 0.5424\n",
      "Baseline Loss: 2.6515 | Actual Loss: 0.5677\n",
      "Baseline Loss: 2.6762 | Actual Loss: 0.3846\n",
      "Baseline Loss: 2.6719 | Actual Loss: 0.8529\n",
      "Baseline Loss: 2.6627 | Actual Loss: 0.3156\n",
      "Baseline Loss: 2.6625 | Actual Loss: 0.8272\n",
      "Baseline Loss: 2.6579 | Actual Loss: 0.6648\n",
      "Baseline Loss: 2.6909 | Actual Loss: 0.5513\n",
      "Baseline Loss: 2.6803 | Actual Loss: 0.7860\n",
      "Baseline Loss: 2.6787 | Actual Loss: 1.1858\n",
      "Baseline Loss: 2.6695 | Actual Loss: 0.5468\n",
      "Baseline Loss: 2.6653 | Actual Loss: 0.7163\n",
      "Baseline Loss: 2.6749 | Actual Loss: 0.8910\n",
      "Baseline Loss: 2.6608 | Actual Loss: 1.3123\n",
      "Baseline Loss: 2.3038 | Actual Loss: 0.3465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 66/1000 [00:20<05:01,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6907 | Actual Loss: 0.8472\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.5967\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.6428\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5823\n",
      "Epoch 66/1000: Train Loss: 0.6968, Val Loss: 0.6672\n",
      "Baseline Loss: 2.6309 | Actual Loss: 0.7337\n",
      "Baseline Loss: 2.6530 | Actual Loss: 0.9182\n",
      "Baseline Loss: 2.6682 | Actual Loss: 0.6314\n",
      "Baseline Loss: 2.6844 | Actual Loss: 0.3879\n",
      "Baseline Loss: 2.6915 | Actual Loss: 0.6292\n",
      "Baseline Loss: 2.6911 | Actual Loss: 0.9435\n",
      "Baseline Loss: 2.6707 | Actual Loss: 0.6914\n",
      "Baseline Loss: 2.6717 | Actual Loss: 0.6912\n",
      "Baseline Loss: 2.6540 | Actual Loss: 0.4335\n",
      "Baseline Loss: 2.6825 | Actual Loss: 0.5407\n",
      "Baseline Loss: 2.6871 | Actual Loss: 0.6918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 67/1000 [00:21<05:02,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6748 | Actual Loss: 0.6073\n",
      "Baseline Loss: 2.6864 | Actual Loss: 0.8996\n",
      "Baseline Loss: 2.6674 | Actual Loss: 0.4196\n",
      "Baseline Loss: 2.6745 | Actual Loss: 0.8096\n",
      "Baseline Loss: 2.2248 | Actual Loss: 0.3249\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.8136\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.6993\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.6660\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.7130\n",
      "Epoch 67/1000: Train Loss: 0.6471, Val Loss: 0.7230\n",
      "Baseline Loss: 2.6892 | Actual Loss: 0.7017\n",
      "Baseline Loss: 2.6787 | Actual Loss: 0.4413\n",
      "Baseline Loss: 2.6626 | Actual Loss: 0.5985\n",
      "Baseline Loss: 2.6762 | Actual Loss: 0.5233\n",
      "Baseline Loss: 2.7313 | Actual Loss: 1.1179\n",
      "Baseline Loss: 2.6436 | Actual Loss: 0.5249\n",
      "Baseline Loss: 2.7128 | Actual Loss: 0.5244\n",
      "Baseline Loss: 2.6665 | Actual Loss: 0.6300\n",
      "Baseline Loss: 2.6449 | Actual Loss: 0.8384\n",
      "Baseline Loss: 2.6771 | Actual Loss: 0.5712\n",
      "Baseline Loss: 2.6825 | Actual Loss: 0.5813\n",
      "Baseline Loss: 2.6531 | Actual Loss: 0.5873\n",
      "Baseline Loss: 2.7231 | Actual Loss: 0.5645\n",
      "Baseline Loss: 2.6790 | Actual Loss: 0.7389\n",
      "Baseline Loss: 2.7240 | Actual Loss: 0.7426\n",
      "Baseline Loss: 2.2888 | Actual Loss: 1.1472\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7617\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.6709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 68/1000 [00:21<04:49,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6840 | Actual Loss: 0.6458\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.7001\n",
      "Epoch 68/1000: Train Loss: 0.6771, Val Loss: 0.6946\n",
      "Baseline Loss: 2.6771 | Actual Loss: 0.6203\n",
      "Baseline Loss: 2.6726 | Actual Loss: 0.5624\n",
      "Baseline Loss: 2.6846 | Actual Loss: 0.5519\n",
      "Baseline Loss: 2.6524 | Actual Loss: 0.5513\n",
      "Baseline Loss: 2.7081 | Actual Loss: 1.1922\n",
      "Baseline Loss: 2.6609 | Actual Loss: 1.1215\n",
      "Baseline Loss: 2.6901 | Actual Loss: 0.5748\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.6826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 69/1000 [00:21<04:55,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6627 | Actual Loss: 0.7578\n",
      "Baseline Loss: 2.6832 | Actual Loss: 0.7512\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5038\n",
      "Baseline Loss: 2.6526 | Actual Loss: 0.4158\n",
      "Baseline Loss: 2.6739 | Actual Loss: 0.3731\n",
      "Baseline Loss: 2.6624 | Actual Loss: 0.5278\n",
      "Baseline Loss: 2.6689 | Actual Loss: 1.0334\n",
      "Baseline Loss: 2.2251 | Actual Loss: 1.0425\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7725\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.5608\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.5221\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.6124\n",
      "Epoch 69/1000: Train Loss: 0.7039, Val Loss: 0.6170\n",
      "Baseline Loss: 2.6563 | Actual Loss: 0.4001\n",
      "Baseline Loss: 2.6744 | Actual Loss: 0.6723\n",
      "Baseline Loss: 2.6800 | Actual Loss: 0.7594\n",
      "Baseline Loss: 2.6785 | Actual Loss: 0.5827\n",
      "Baseline Loss: 2.7180 | Actual Loss: 0.9922\n",
      "Baseline Loss: 2.6999 | Actual Loss: 0.5034\n",
      "Baseline Loss: 2.6625 | Actual Loss: 0.7377\n",
      "Baseline Loss: 2.6915 | Actual Loss: 1.8837\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.6661\n",
      "Baseline Loss: 2.6974 | Actual Loss: 0.4428\n",
      "Baseline Loss: 2.6819 | Actual Loss: 0.7914\n",
      "Baseline Loss: 2.6975 | Actual Loss: 0.5562\n",
      "Baseline Loss: 2.6925 | Actual Loss: 0.6991\n",
      "Baseline Loss: 2.6370 | Actual Loss: 0.3741\n",
      "Baseline Loss: 2.7163 | Actual Loss: 0.1996\n",
      "Baseline Loss: 2.2178 | Actual Loss: 0.2983\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7937\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.5190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 70/1000 [00:22<05:07,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6840 | Actual Loss: 0.9142\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5761\n",
      "Epoch 70/1000: Train Loss: 0.6600, Val Loss: 0.7008\n",
      "Baseline Loss: 2.6554 | Actual Loss: 1.3690\n",
      "Baseline Loss: 2.6681 | Actual Loss: 0.7774\n",
      "Baseline Loss: 2.6805 | Actual Loss: 0.6697\n",
      "Baseline Loss: 2.6949 | Actual Loss: 0.5156\n",
      "Baseline Loss: 2.6782 | Actual Loss: 0.4234\n",
      "Baseline Loss: 2.6802 | Actual Loss: 0.5871\n",
      "Baseline Loss: 2.6473 | Actual Loss: 0.4110\n",
      "Baseline Loss: 2.6958 | Actual Loss: 0.8594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 71/1000 [00:22<04:46,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6598 | Actual Loss: 0.6959\n",
      "Baseline Loss: 2.6783 | Actual Loss: 1.0583\n",
      "Baseline Loss: 2.6550 | Actual Loss: 0.7454\n",
      "Baseline Loss: 2.6856 | Actual Loss: 0.7915\n",
      "Baseline Loss: 2.7012 | Actual Loss: 0.8050\n",
      "Baseline Loss: 2.7005 | Actual Loss: 0.6284\n",
      "Baseline Loss: 2.7276 | Actual Loss: 0.6780\n",
      "Baseline Loss: 2.2523 | Actual Loss: 0.2106\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7100\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.5748\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.6476\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.6469\n",
      "Epoch 71/1000: Train Loss: 0.7016, Val Loss: 0.6448\n",
      "Baseline Loss: 2.7152 | Actual Loss: 0.7731\n",
      "Baseline Loss: 2.6576 | Actual Loss: 0.4998\n",
      "Baseline Loss: 2.6642 | Actual Loss: 1.0277\n",
      "Baseline Loss: 2.6763 | Actual Loss: 1.0353\n",
      "Baseline Loss: 2.6597 | Actual Loss: 0.3729\n",
      "Baseline Loss: 2.6871 | Actual Loss: 0.9182\n",
      "Baseline Loss: 2.6744 | Actual Loss: 0.4964\n",
      "Baseline Loss: 2.6433 | Actual Loss: 0.6130\n",
      "Baseline Loss: 2.6624 | Actual Loss: 0.7364\n",
      "Baseline Loss: 2.6468 | Actual Loss: 0.5148\n",
      "Baseline Loss: 2.6816 | Actual Loss: 0.8628\n",
      "Baseline Loss: 2.6654 | Actual Loss: 0.4210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 72/1000 [00:22<05:00,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6560 | Actual Loss: 0.7814\n",
      "Baseline Loss: 2.6471 | Actual Loss: 0.5867\n",
      "Baseline Loss: 2.7273 | Actual Loss: 0.5142\n",
      "Baseline Loss: 2.3172 | Actual Loss: 0.8444\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7823\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.5336\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.5783\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.7382\n",
      "Epoch 72/1000: Train Loss: 0.6874, Val Loss: 0.6581\n",
      "Baseline Loss: 2.6821 | Actual Loss: 0.6067\n",
      "Baseline Loss: 2.7111 | Actual Loss: 1.6708\n",
      "Baseline Loss: 2.7026 | Actual Loss: 0.7490\n",
      "Baseline Loss: 2.6457 | Actual Loss: 0.4725\n",
      "Baseline Loss: 2.6580 | Actual Loss: 0.3929\n",
      "Baseline Loss: 2.6955 | Actual Loss: 0.4837\n",
      "Baseline Loss: 2.6401 | Actual Loss: 0.8352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 73/1000 [00:23<04:46,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6756 | Actual Loss: 1.3028\n",
      "Baseline Loss: 2.6836 | Actual Loss: 0.8023\n",
      "Baseline Loss: 2.6533 | Actual Loss: 0.5486\n",
      "Baseline Loss: 2.6782 | Actual Loss: 0.6828\n",
      "Baseline Loss: 2.6598 | Actual Loss: 1.0170\n",
      "Baseline Loss: 2.6509 | Actual Loss: 0.8039\n",
      "Baseline Loss: 2.7082 | Actual Loss: 0.3567\n",
      "Baseline Loss: 2.6270 | Actual Loss: 0.3715\n",
      "Baseline Loss: 2.3092 | Actual Loss: 0.2196\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.8612\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.5856\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.5286\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.6395\n",
      "Epoch 73/1000: Train Loss: 0.7072, Val Loss: 0.6537\n",
      "Baseline Loss: 2.6700 | Actual Loss: 0.6696\n",
      "Baseline Loss: 2.6466 | Actual Loss: 0.3694\n",
      "Baseline Loss: 2.6880 | Actual Loss: 0.5867\n",
      "Baseline Loss: 2.7070 | Actual Loss: 1.9988\n",
      "Baseline Loss: 2.6806 | Actual Loss: 0.9472\n",
      "Baseline Loss: 2.6864 | Actual Loss: 0.9265\n",
      "Baseline Loss: 2.6454 | Actual Loss: 0.6830\n",
      "Baseline Loss: 2.6373 | Actual Loss: 0.8009\n",
      "Baseline Loss: 2.7004 | Actual Loss: 0.8747\n",
      "Baseline Loss: 2.7092 | Actual Loss: 0.5095\n",
      "Baseline Loss: 2.6581 | Actual Loss: 0.4741\n",
      "Baseline Loss: 2.7046 | Actual Loss: 0.5911\n",
      "Baseline Loss: 2.7011 | Actual Loss: 0.5621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 74/1000 [00:23<04:55,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6388 | Actual Loss: 0.4416\n",
      "Baseline Loss: 2.6887 | Actual Loss: 0.6364\n",
      "Baseline Loss: 2.2701 | Actual Loss: 0.4554\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7869\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.6187\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.5726\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5918\n",
      "Epoch 74/1000: Train Loss: 0.7204, Val Loss: 0.6425\n",
      "Baseline Loss: 2.6940 | Actual Loss: 0.4324\n",
      "Baseline Loss: 2.6928 | Actual Loss: 0.4086\n",
      "Baseline Loss: 2.6575 | Actual Loss: 0.5609\n",
      "Baseline Loss: 2.6856 | Actual Loss: 0.6558\n",
      "Baseline Loss: 2.6594 | Actual Loss: 0.6268\n",
      "Baseline Loss: 2.6742 | Actual Loss: 0.6592\n",
      "Baseline Loss: 2.6662 | Actual Loss: 0.8173\n",
      "Baseline Loss: 2.6801 | Actual Loss: 0.4968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 75/1000 [00:23<04:33,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6688 | Actual Loss: 0.5555\n",
      "Baseline Loss: 2.7070 | Actual Loss: 0.5991\n",
      "Baseline Loss: 2.6484 | Actual Loss: 1.7140\n",
      "Baseline Loss: 2.6540 | Actual Loss: 0.9493\n",
      "Baseline Loss: 2.6620 | Actual Loss: 0.6854\n",
      "Baseline Loss: 2.7073 | Actual Loss: 0.3510\n",
      "Baseline Loss: 2.6347 | Actual Loss: 0.8078\n",
      "Baseline Loss: 2.3479 | Actual Loss: 0.2853\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.8009\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.6043\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4425\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5937\n",
      "Epoch 75/1000: Train Loss: 0.6628, Val Loss: 0.6104\n",
      "Baseline Loss: 2.6593 | Actual Loss: 0.7191\n",
      "Baseline Loss: 2.7066 | Actual Loss: 0.5484\n",
      "Baseline Loss: 2.6530 | Actual Loss: 0.7857\n",
      "Baseline Loss: 2.7054 | Actual Loss: 0.3591\n",
      "Baseline Loss: 2.6978 | Actual Loss: 0.5454\n",
      "Baseline Loss: 2.6721 | Actual Loss: 0.4936\n",
      "Baseline Loss: 2.7077 | Actual Loss: 0.3968\n",
      "Baseline Loss: 2.6694 | Actual Loss: 0.3576\n",
      "Baseline Loss: 2.6635 | Actual Loss: 0.5128\n",
      "Baseline Loss: 2.6701 | Actual Loss: 2.1282\n",
      "Baseline Loss: 2.6423 | Actual Loss: 0.3772\n",
      "Baseline Loss: 2.6736 | Actual Loss: 0.9571\n",
      "Baseline Loss: 2.6524 | Actual Loss: 0.4913\n",
      "Baseline Loss: 2.6959 | Actual Loss: 0.5269\n",
      "Baseline Loss: 2.6800 | Actual Loss: 0.7340\n",
      "Baseline Loss: 2.3165 | Actual Loss: 0.4137\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7890\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.5541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 76/1000 [00:23<04:48,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6840 | Actual Loss: 0.5203\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.6079\n",
      "Epoch 76/1000: Train Loss: 0.6467, Val Loss: 0.6178\n",
      "Baseline Loss: 2.6527 | Actual Loss: 0.7248\n",
      "Baseline Loss: 2.6530 | Actual Loss: 0.8613\n",
      "Baseline Loss: 2.7179 | Actual Loss: 0.2680\n",
      "Baseline Loss: 2.6620 | Actual Loss: 0.5821\n",
      "Baseline Loss: 2.6629 | Actual Loss: 0.8224\n",
      "Baseline Loss: 2.6439 | Actual Loss: 0.7164\n",
      "Baseline Loss: 2.6689 | Actual Loss: 0.5680\n",
      "Baseline Loss: 2.6885 | Actual Loss: 1.3185\n",
      "Baseline Loss: 2.6863 | Actual Loss: 0.9807\n",
      "Baseline Loss: 2.6948 | Actual Loss: 0.1734\n",
      "Baseline Loss: 2.7038 | Actual Loss: 0.4461\n",
      "Baseline Loss: 2.7066 | Actual Loss: 0.2930\n",
      "Baseline Loss: 2.6521 | Actual Loss: 0.5144\n",
      "Baseline Loss: 2.7025 | Actual Loss: 0.8572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 77/1000 [00:24<04:53,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6666 | Actual Loss: 0.4390\n",
      "Baseline Loss: 2.2570 | Actual Loss: 0.1383\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7280\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.5682\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4956\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5401\n",
      "Epoch 77/1000: Train Loss: 0.6065, Val Loss: 0.5830\n",
      "New best validation loss: 0.5830\n",
      "Baseline Loss: 2.6959 | Actual Loss: 0.8041\n",
      "Baseline Loss: 2.6716 | Actual Loss: 0.8078\n",
      "Baseline Loss: 2.6906 | Actual Loss: 0.5483\n",
      "Baseline Loss: 2.7047 | Actual Loss: 0.4176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 78/1000 [00:24<04:32,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6280 | Actual Loss: 0.5274\n",
      "Baseline Loss: 2.6425 | Actual Loss: 0.4210\n",
      "Baseline Loss: 2.6752 | Actual Loss: 0.5501\n",
      "Baseline Loss: 2.6531 | Actual Loss: 0.5170\n",
      "Baseline Loss: 2.7191 | Actual Loss: 1.1270\n",
      "Baseline Loss: 2.6429 | Actual Loss: 0.7242\n",
      "Baseline Loss: 2.6476 | Actual Loss: 0.5869\n",
      "Baseline Loss: 2.6769 | Actual Loss: 0.5426\n",
      "Baseline Loss: 2.6737 | Actual Loss: 0.4960\n",
      "Baseline Loss: 2.6624 | Actual Loss: 1.7408\n",
      "Baseline Loss: 2.6701 | Actual Loss: 1.2046\n",
      "Baseline Loss: 2.2440 | Actual Loss: 0.2483\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7762\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.5667\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4794\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5970\n",
      "Epoch 78/1000: Train Loss: 0.7040, Val Loss: 0.6048\n",
      "Baseline Loss: 2.7211 | Actual Loss: 0.7968\n",
      "Baseline Loss: 2.6799 | Actual Loss: 0.4766\n",
      "Baseline Loss: 2.6698 | Actual Loss: 0.4288\n",
      "Baseline Loss: 2.6828 | Actual Loss: 0.3216\n",
      "Baseline Loss: 2.6663 | Actual Loss: 0.5292\n",
      "Baseline Loss: 2.6602 | Actual Loss: 0.5468\n",
      "Baseline Loss: 2.6529 | Actual Loss: 1.0395\n",
      "Baseline Loss: 2.6573 | Actual Loss: 0.8105\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.7323\n",
      "Baseline Loss: 2.6360 | Actual Loss: 0.6175\n",
      "Baseline Loss: 2.7291 | Actual Loss: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 79/1000 [00:24<04:47,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6690 | Actual Loss: 0.6354\n",
      "Baseline Loss: 2.7159 | Actual Loss: 0.6283\n",
      "Baseline Loss: 2.6739 | Actual Loss: 0.6135\n",
      "Baseline Loss: 2.6614 | Actual Loss: 0.3279\n",
      "Baseline Loss: 2.2276 | Actual Loss: 0.7941\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7559\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.6094\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4867\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5508\n",
      "Epoch 79/1000: Train Loss: 0.6124, Val Loss: 0.6007\n",
      "Baseline Loss: 2.6973 | Actual Loss: 0.6712\n",
      "Baseline Loss: 2.6417 | Actual Loss: 0.6768\n",
      "Baseline Loss: 2.6586 | Actual Loss: 0.7528\n",
      "Baseline Loss: 2.6968 | Actual Loss: 0.7493\n",
      "Baseline Loss: 2.6928 | Actual Loss: 0.4148\n",
      "Baseline Loss: 2.6782 | Actual Loss: 0.6279\n",
      "Baseline Loss: 2.6686 | Actual Loss: 0.5726\n",
      "Baseline Loss: 2.6782 | Actual Loss: 0.3024\n",
      "Baseline Loss: 2.6470 | Actual Loss: 0.3014\n",
      "Baseline Loss: 2.6842 | Actual Loss: 0.9232\n",
      "Baseline Loss: 2.6937 | Actual Loss: 0.5247\n",
      "Baseline Loss: 2.6675 | Actual Loss: 0.5975\n",
      "Baseline Loss: 2.6845 | Actual Loss: 1.0134\n",
      "Baseline Loss: 2.6663 | Actual Loss: 0.9915\n",
      "Baseline Loss: 2.6947 | Actual Loss: 0.5997\n",
      "Baseline Loss: 2.3248 | Actual Loss: 0.5806\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 80/1000 [00:25<04:53,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6644 | Actual Loss: 0.5266\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.5379\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.6309\n",
      "Epoch 80/1000: Train Loss: 0.6437, Val Loss: 0.5938\n",
      "Baseline Loss: 2.6603 | Actual Loss: 0.5478\n",
      "Baseline Loss: 2.6413 | Actual Loss: 0.1971\n",
      "Baseline Loss: 2.6986 | Actual Loss: 0.5509\n",
      "Baseline Loss: 2.7085 | Actual Loss: 0.3818\n",
      "Baseline Loss: 2.6616 | Actual Loss: 0.6334\n",
      "Baseline Loss: 2.6834 | Actual Loss: 0.5888\n",
      "Baseline Loss: 2.6570 | Actual Loss: 0.2188\n",
      "Baseline Loss: 2.6674 | Actual Loss: 0.2630\n",
      "Baseline Loss: 2.6728 | Actual Loss: 0.7365\n",
      "Baseline Loss: 2.6683 | Actual Loss: 0.8135\n",
      "Baseline Loss: 2.6615 | Actual Loss: 0.6300\n",
      "Baseline Loss: 2.6633 | Actual Loss: 0.3670\n",
      "Baseline Loss: 2.6810 | Actual Loss: 0.3250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 81/1000 [00:25<04:32,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6832 | Actual Loss: 0.9555\n",
      "Baseline Loss: 2.6707 | Actual Loss: 0.4898\n",
      "Baseline Loss: 2.3138 | Actual Loss: 0.3445\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7796\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.6115\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.5227\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5957\n",
      "Epoch 81/1000: Train Loss: 0.5027, Val Loss: 0.6274\n",
      "Baseline Loss: 2.6670 | Actual Loss: 0.3830\n",
      "Baseline Loss: 2.6628 | Actual Loss: 1.9174\n",
      "Baseline Loss: 2.6336 | Actual Loss: 0.7063\n",
      "Baseline Loss: 2.6368 | Actual Loss: 0.6920\n",
      "Baseline Loss: 2.6765 | Actual Loss: 0.7428\n",
      "Baseline Loss: 2.7396 | Actual Loss: 0.3876\n",
      "Baseline Loss: 2.6820 | Actual Loss: 0.5085\n",
      "Baseline Loss: 2.6851 | Actual Loss: 0.4452\n",
      "Baseline Loss: 2.6753 | Actual Loss: 1.0941\n",
      "Baseline Loss: 2.6753 | Actual Loss: 0.5453\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4531\n",
      "Baseline Loss: 2.6996 | Actual Loss: 0.4216\n",
      "Baseline Loss: 2.6895 | Actual Loss: 0.7581\n",
      "Baseline Loss: 2.6360 | Actual Loss: 1.1155\n",
      "Baseline Loss: 2.6921 | Actual Loss: 0.5876\n",
      "Baseline Loss: 2.2618 | Actual Loss: 1.3885\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7695\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.7043\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.5192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 82/1000 [00:25<04:48,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6117 | Actual Loss: 0.7035\n",
      "Epoch 82/1000: Train Loss: 0.7592, Val Loss: 0.6741\n",
      "Baseline Loss: 2.6877 | Actual Loss: 0.4269\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.6783\n",
      "Baseline Loss: 2.6751 | Actual Loss: 0.4477\n",
      "Baseline Loss: 2.6787 | Actual Loss: 0.4693\n",
      "Baseline Loss: 2.6499 | Actual Loss: 0.6778\n",
      "Baseline Loss: 2.6579 | Actual Loss: 0.5696\n",
      "Baseline Loss: 2.6762 | Actual Loss: 0.5042\n",
      "Baseline Loss: 2.6913 | Actual Loss: 0.6717\n",
      "Baseline Loss: 2.6787 | Actual Loss: 0.3452\n",
      "Baseline Loss: 2.6962 | Actual Loss: 1.1268\n",
      "Baseline Loss: 2.6854 | Actual Loss: 0.9888\n",
      "Baseline Loss: 2.6700 | Actual Loss: 0.5967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 83/1000 [00:26<04:55,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7123 | Actual Loss: 0.3754\n",
      "Baseline Loss: 2.6718 | Actual Loss: 0.5175\n",
      "Baseline Loss: 2.6703 | Actual Loss: 0.4555\n",
      "Baseline Loss: 2.2416 | Actual Loss: 0.7310\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.8009\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.5285\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.5115\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.7071\n",
      "Epoch 83/1000: Train Loss: 0.5989, Val Loss: 0.6370\n",
      "Baseline Loss: 2.6530 | Actual Loss: 0.3772\n",
      "Baseline Loss: 2.6658 | Actual Loss: 0.3561\n",
      "Baseline Loss: 2.6472 | Actual Loss: 0.3958\n",
      "Baseline Loss: 2.6618 | Actual Loss: 0.5586\n",
      "Baseline Loss: 2.6749 | Actual Loss: 1.1441\n",
      "Baseline Loss: 2.6655 | Actual Loss: 0.3005\n",
      "Baseline Loss: 2.6862 | Actual Loss: 0.7756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 84/1000 [00:26<04:35,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6772 | Actual Loss: 0.4630\n",
      "Baseline Loss: 2.6747 | Actual Loss: 0.9439\n",
      "Baseline Loss: 2.6551 | Actual Loss: 0.6285\n",
      "Baseline Loss: 2.6796 | Actual Loss: 0.6356\n",
      "Baseline Loss: 2.6648 | Actual Loss: 0.5918\n",
      "Baseline Loss: 2.6851 | Actual Loss: 1.7610\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.3729\n",
      "Baseline Loss: 2.6958 | Actual Loss: 0.4951\n",
      "Baseline Loss: 2.2717 | Actual Loss: 0.4588\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7880\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.6437\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4633\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5666\n",
      "Epoch 84/1000: Train Loss: 0.6412, Val Loss: 0.6154\n",
      "Baseline Loss: 2.7163 | Actual Loss: 0.9985\n",
      "Baseline Loss: 2.6687 | Actual Loss: 0.5331\n",
      "Baseline Loss: 2.7038 | Actual Loss: 0.3396\n",
      "Baseline Loss: 2.6849 | Actual Loss: 0.6035\n",
      "Baseline Loss: 2.6706 | Actual Loss: 0.4924\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4199\n",
      "Baseline Loss: 2.6817 | Actual Loss: 0.5041\n",
      "Baseline Loss: 2.6456 | Actual Loss: 1.1218\n",
      "Baseline Loss: 2.6344 | Actual Loss: 0.8491\n",
      "Baseline Loss: 2.6868 | Actual Loss: 0.7707\n",
      "Baseline Loss: 2.6406 | Actual Loss: 0.4766\n",
      "Baseline Loss: 2.6805 | Actual Loss: 0.2447\n",
      "Baseline Loss: 2.6964 | Actual Loss: 0.5912\n",
      "Baseline Loss: 2.6824 | Actual Loss: 0.5552\n",
      "Baseline Loss: 2.6963 | Actual Loss: 0.4367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 85/1000 [00:26<04:49,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.3542 | Actual Loss: 0.3088\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7893\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.6699\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.5215\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5925\n",
      "Epoch 85/1000: Train Loss: 0.5779, Val Loss: 0.6433\n",
      "Baseline Loss: 2.6971 | Actual Loss: 0.4070\n",
      "Baseline Loss: 2.6508 | Actual Loss: 0.6116\n",
      "Baseline Loss: 2.6453 | Actual Loss: 0.3248\n",
      "Baseline Loss: 2.6626 | Actual Loss: 0.6848\n",
      "Baseline Loss: 2.6744 | Actual Loss: 0.3958\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5589\n",
      "Baseline Loss: 2.6882 | Actual Loss: 0.3566\n",
      "Baseline Loss: 2.6836 | Actual Loss: 0.6373\n",
      "Baseline Loss: 2.6728 | Actual Loss: 0.3647\n",
      "Baseline Loss: 2.6749 | Actual Loss: 0.1693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▊         | 86/1000 [00:27<04:59,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6923 | Actual Loss: 0.5351\n",
      "Baseline Loss: 2.6942 | Actual Loss: 0.1585\n",
      "Baseline Loss: 2.6590 | Actual Loss: 0.4461\n",
      "Baseline Loss: 2.6668 | Actual Loss: 2.1995\n",
      "Baseline Loss: 2.6687 | Actual Loss: 1.8612\n",
      "Baseline Loss: 2.3308 | Actual Loss: 1.4887\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.8289\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.5443\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.7886\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.9624\n",
      "Epoch 86/1000: Train Loss: 0.7000, Val Loss: 0.7811\n",
      "Baseline Loss: 2.6401 | Actual Loss: 1.7433\n",
      "Baseline Loss: 2.6946 | Actual Loss: 0.4439\n",
      "Baseline Loss: 2.6631 | Actual Loss: 0.6443\n",
      "Baseline Loss: 2.6660 | Actual Loss: 0.3848\n",
      "Baseline Loss: 2.7052 | Actual Loss: 0.3957\n",
      "Baseline Loss: 2.6728 | Actual Loss: 0.4831\n",
      "Baseline Loss: 2.6777 | Actual Loss: 0.8968\n",
      "Baseline Loss: 2.6668 | Actual Loss: 0.3220\n",
      "Baseline Loss: 2.7205 | Actual Loss: 0.3516\n",
      "Baseline Loss: 2.6782 | Actual Loss: 0.5449\n",
      "Baseline Loss: 2.6689 | Actual Loss: 0.8489\n",
      "Baseline Loss: 2.6704 | Actual Loss: 0.5268\n",
      "Baseline Loss: 2.7237 | Actual Loss: 0.3684\n",
      "Baseline Loss: 2.6802 | Actual Loss: 0.6600\n",
      "Baseline Loss: 2.6609 | Actual Loss: 0.5740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▊         | 87/1000 [00:27<04:46,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2422 | Actual Loss: 0.3646\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7128\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.5620\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4253\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5707\n",
      "Epoch 87/1000: Train Loss: 0.5971, Val Loss: 0.5677\n",
      "New best validation loss: 0.5677\n",
      "Baseline Loss: 2.6575 | Actual Loss: 0.4770\n",
      "Baseline Loss: 2.6575 | Actual Loss: 0.3252\n",
      "Baseline Loss: 2.6806 | Actual Loss: 0.6794\n",
      "Baseline Loss: 2.6454 | Actual Loss: 0.4166\n",
      "Baseline Loss: 2.6656 | Actual Loss: 0.6113\n",
      "Baseline Loss: 2.7117 | Actual Loss: 0.9500\n",
      "Baseline Loss: 2.6685 | Actual Loss: 0.3270\n",
      "Baseline Loss: 2.6994 | Actual Loss: 0.3536\n",
      "Baseline Loss: 2.6813 | Actual Loss: 0.3628\n",
      "Baseline Loss: 2.6875 | Actual Loss: 1.0750\n",
      "Baseline Loss: 2.6540 | Actual Loss: 0.5073\n",
      "Baseline Loss: 2.6560 | Actual Loss: 0.4835\n",
      "Baseline Loss: 2.7245 | Actual Loss: 0.4492\n",
      "Baseline Loss: 2.6515 | Actual Loss: 0.8179\n",
      "Baseline Loss: 2.7339 | Actual Loss: 0.4130\n",
      "Baseline Loss: 2.2597 | Actual Loss: 0.1900\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7543\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.6356\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 88/1000 [00:27<04:57,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6117 | Actual Loss: 0.5459\n",
      "Epoch 88/1000: Train Loss: 0.5274, Val Loss: 0.5943\n",
      "Baseline Loss: 2.6842 | Actual Loss: 0.5236\n",
      "Baseline Loss: 2.6485 | Actual Loss: 0.4110\n",
      "Baseline Loss: 2.6424 | Actual Loss: 1.1360\n",
      "Baseline Loss: 2.6950 | Actual Loss: 0.4972\n",
      "Baseline Loss: 2.7025 | Actual Loss: 0.8419\n",
      "Baseline Loss: 2.6646 | Actual Loss: 0.8136\n",
      "Baseline Loss: 2.6680 | Actual Loss: 0.1823\n",
      "Baseline Loss: 2.7222 | Actual Loss: 0.7554\n",
      "Baseline Loss: 2.6794 | Actual Loss: 0.5197\n",
      "Baseline Loss: 2.6768 | Actual Loss: 0.4908\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.4852\n",
      "Baseline Loss: 2.6478 | Actual Loss: 0.6953\n",
      "Baseline Loss: 2.6616 | Actual Loss: 0.5887\n",
      "Baseline Loss: 2.6655 | Actual Loss: 0.5821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 89/1000 [00:28<04:59,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7008 | Actual Loss: 0.3423\n",
      "Baseline Loss: 2.2686 | Actual Loss: 0.5429\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.8730\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.6754\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3566\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.6295\n",
      "Epoch 89/1000: Train Loss: 0.5880, Val Loss: 0.6336\n",
      "Baseline Loss: 2.6492 | Actual Loss: 0.6710\n",
      "Baseline Loss: 2.6767 | Actual Loss: 0.5730\n",
      "Baseline Loss: 2.6930 | Actual Loss: 0.7418\n",
      "Baseline Loss: 2.6790 | Actual Loss: 0.4210\n",
      "Baseline Loss: 2.6649 | Actual Loss: 0.4831\n",
      "Baseline Loss: 2.6903 | Actual Loss: 0.6194\n",
      "Baseline Loss: 2.6656 | Actual Loss: 0.2438\n",
      "Baseline Loss: 2.7192 | Actual Loss: 0.6563\n",
      "Baseline Loss: 2.6330 | Actual Loss: 0.7950\n",
      "Baseline Loss: 2.7014 | Actual Loss: 0.8720\n",
      "Baseline Loss: 2.6504 | Actual Loss: 0.5936\n",
      "Baseline Loss: 2.7239 | Actual Loss: 0.3388\n",
      "Baseline Loss: 2.6529 | Actual Loss: 0.7765\n",
      "Baseline Loss: 2.6818 | Actual Loss: 0.8115\n",
      "Baseline Loss: 2.6814 | Actual Loss: 0.5853\n",
      "Baseline Loss: 2.2734 | Actual Loss: 0.2633\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6473\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4675\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 90/1000 [00:28<04:46,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6117 | Actual Loss: 0.5684\n",
      "Epoch 90/1000: Train Loss: 0.5903, Val Loss: 0.5254\n",
      "New best validation loss: 0.5254\n",
      "Baseline Loss: 2.6463 | Actual Loss: 0.3400\n",
      "Baseline Loss: 2.6769 | Actual Loss: 0.5369\n",
      "Baseline Loss: 2.6549 | Actual Loss: 0.5935\n",
      "Baseline Loss: 2.6597 | Actual Loss: 0.3297\n",
      "Baseline Loss: 2.6448 | Actual Loss: 1.4564\n",
      "Baseline Loss: 2.6976 | Actual Loss: 0.5975\n",
      "Baseline Loss: 2.6948 | Actual Loss: 0.3622\n",
      "Baseline Loss: 2.6880 | Actual Loss: 1.7198\n",
      "Baseline Loss: 2.7194 | Actual Loss: 2.1081\n",
      "Baseline Loss: 2.6510 | Actual Loss: 0.9546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 91/1000 [00:28<04:56,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6772 | Actual Loss: 1.1892\n",
      "Baseline Loss: 2.6342 | Actual Loss: 0.4776\n",
      "Baseline Loss: 2.6448 | Actual Loss: 0.3792\n",
      "Baseline Loss: 2.7327 | Actual Loss: 0.3829\n",
      "Baseline Loss: 2.6927 | Actual Loss: 0.9313\n",
      "Baseline Loss: 2.3425 | Actual Loss: 0.3220\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7420\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.7331\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4412\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5704\n",
      "Epoch 91/1000: Train Loss: 0.7926, Val Loss: 0.6217\n",
      "Baseline Loss: 2.6819 | Actual Loss: 1.2178\n",
      "Baseline Loss: 2.6569 | Actual Loss: 0.6690\n",
      "Baseline Loss: 2.6756 | Actual Loss: 0.5058\n",
      "Baseline Loss: 2.6659 | Actual Loss: 0.2850\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 92/1000 [00:28<04:38,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6860 | Actual Loss: 0.6108\n",
      "Baseline Loss: 2.7205 | Actual Loss: 0.5575\n",
      "Baseline Loss: 2.6865 | Actual Loss: 0.5557\n",
      "Baseline Loss: 2.7001 | Actual Loss: 0.9567\n",
      "Baseline Loss: 2.6726 | Actual Loss: 0.5478\n",
      "Baseline Loss: 2.6445 | Actual Loss: 0.4337\n",
      "Baseline Loss: 2.6705 | Actual Loss: 0.9333\n",
      "Baseline Loss: 2.6747 | Actual Loss: 0.2705\n",
      "Baseline Loss: 2.6540 | Actual Loss: 0.6970\n",
      "Baseline Loss: 2.7229 | Actual Loss: 0.3398\n",
      "Baseline Loss: 2.2742 | Actual Loss: 1.3949\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6773\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.7529\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.6001\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5865\n",
      "Epoch 92/1000: Train Loss: 0.6514, Val Loss: 0.6542\n",
      "Baseline Loss: 2.6952 | Actual Loss: 0.7253\n",
      "Baseline Loss: 2.6444 | Actual Loss: 0.4329\n",
      "Baseline Loss: 2.6668 | Actual Loss: 0.4666\n",
      "Baseline Loss: 2.6893 | Actual Loss: 0.7122\n",
      "Baseline Loss: 2.6655 | Actual Loss: 0.3709\n",
      "Baseline Loss: 2.6533 | Actual Loss: 0.7757\n",
      "Baseline Loss: 2.6442 | Actual Loss: 0.5039\n",
      "Baseline Loss: 2.6740 | Actual Loss: 0.5182\n",
      "Baseline Loss: 2.6745 | Actual Loss: 0.2453\n",
      "Baseline Loss: 2.7078 | Actual Loss: 0.2846\n",
      "Baseline Loss: 2.6425 | Actual Loss: 1.8039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 93/1000 [00:29<04:46,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6810 | Actual Loss: 0.7439\n",
      "Baseline Loss: 2.6439 | Actual Loss: 0.2167\n",
      "Baseline Loss: 2.7071 | Actual Loss: 1.0872\n",
      "Baseline Loss: 2.6718 | Actual Loss: 0.4299\n",
      "Baseline Loss: 2.3005 | Actual Loss: 0.3182\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6878\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.6736\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4235\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5509\n",
      "Epoch 93/1000: Train Loss: 0.6022, Val Loss: 0.5840\n",
      "Baseline Loss: 2.6513 | Actual Loss: 0.3060\n",
      "Baseline Loss: 2.6885 | Actual Loss: 0.6731\n",
      "Baseline Loss: 2.6889 | Actual Loss: 0.7957\n",
      "Baseline Loss: 2.6398 | Actual Loss: 0.5083\n",
      "Baseline Loss: 2.6842 | Actual Loss: 0.4410\n",
      "Baseline Loss: 2.6795 | Actual Loss: 0.5593\n",
      "Baseline Loss: 2.6777 | Actual Loss: 0.2846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 94/1000 [00:29<04:30,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6833 | Actual Loss: 0.1854\n",
      "Baseline Loss: 2.6536 | Actual Loss: 0.4357\n",
      "Baseline Loss: 2.6683 | Actual Loss: 0.6564\n",
      "Baseline Loss: 2.6688 | Actual Loss: 0.3336\n",
      "Baseline Loss: 2.6515 | Actual Loss: 0.3527\n",
      "Baseline Loss: 2.6973 | Actual Loss: 0.2668\n",
      "Baseline Loss: 2.6441 | Actual Loss: 0.8788\n",
      "Baseline Loss: 2.6581 | Actual Loss: 0.5835\n",
      "Baseline Loss: 2.2654 | Actual Loss: 0.3364\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.8078\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.6765\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4810\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5494\n",
      "Epoch 94/1000: Train Loss: 0.4748, Val Loss: 0.6287\n",
      "Baseline Loss: 2.6771 | Actual Loss: 0.7148\n",
      "Baseline Loss: 2.6948 | Actual Loss: 0.6979\n",
      "Baseline Loss: 2.6378 | Actual Loss: 0.4299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 95/1000 [00:29<04:36,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6927 | Actual Loss: 0.4451\n",
      "Baseline Loss: 2.6880 | Actual Loss: 0.5433\n",
      "Baseline Loss: 2.6543 | Actual Loss: 0.6009\n",
      "Baseline Loss: 2.6712 | Actual Loss: 0.2638\n",
      "Baseline Loss: 2.6479 | Actual Loss: 0.4079\n",
      "Baseline Loss: 2.6890 | Actual Loss: 0.3965\n",
      "Baseline Loss: 2.6749 | Actual Loss: 0.2472\n",
      "Baseline Loss: 2.6610 | Actual Loss: 0.6126\n",
      "Baseline Loss: 2.6736 | Actual Loss: 0.7294\n",
      "Baseline Loss: 2.6607 | Actual Loss: 0.5213\n",
      "Baseline Loss: 2.6940 | Actual Loss: 0.6536\n",
      "Baseline Loss: 2.6802 | Actual Loss: 0.5369\n",
      "Baseline Loss: 2.2945 | Actual Loss: 0.3813\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7660\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.7319\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4021\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.6607\n",
      "Epoch 95/1000: Train Loss: 0.5114, Val Loss: 0.6402\n",
      "Baseline Loss: 2.6647 | Actual Loss: 0.4394\n",
      "Baseline Loss: 2.6528 | Actual Loss: 0.3657\n",
      "Baseline Loss: 2.6842 | Actual Loss: 0.6948\n",
      "Baseline Loss: 2.6859 | Actual Loss: 0.1809\n",
      "Baseline Loss: 2.6844 | Actual Loss: 0.5513\n",
      "Baseline Loss: 2.6808 | Actual Loss: 0.6355\n",
      "Baseline Loss: 2.6789 | Actual Loss: 0.3660\n",
      "Baseline Loss: 2.6780 | Actual Loss: 0.9681\n",
      "Baseline Loss: 2.6708 | Actual Loss: 0.3769\n",
      "Baseline Loss: 2.6760 | Actual Loss: 0.5303\n",
      "Baseline Loss: 2.6743 | Actual Loss: 0.3488\n",
      "Baseline Loss: 2.7083 | Actual Loss: 0.4406\n",
      "Baseline Loss: 2.6367 | Actual Loss: 0.7714\n",
      "Baseline Loss: 2.6448 | Actual Loss: 0.6731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 96/1000 [00:30<04:50,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6750 | Actual Loss: 0.7183\n",
      "Baseline Loss: 2.2721 | Actual Loss: 0.4705\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7070\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.5772\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4066\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5030\n",
      "Epoch 96/1000: Train Loss: 0.5332, Val Loss: 0.5485\n",
      "Baseline Loss: 2.6779 | Actual Loss: 0.1348\n",
      "Baseline Loss: 2.6869 | Actual Loss: 0.4671\n",
      "Baseline Loss: 2.6823 | Actual Loss: 0.5670\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.6128\n",
      "Baseline Loss: 2.6540 | Actual Loss: 0.5103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 97/1000 [00:30<04:33,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7022 | Actual Loss: 0.5230\n",
      "Baseline Loss: 2.6811 | Actual Loss: 0.7571\n",
      "Baseline Loss: 2.6789 | Actual Loss: 0.2743\n",
      "Baseline Loss: 2.6916 | Actual Loss: 0.5780\n",
      "Baseline Loss: 2.6742 | Actual Loss: 0.5447\n",
      "Baseline Loss: 2.6722 | Actual Loss: 0.5403\n",
      "Baseline Loss: 2.6418 | Actual Loss: 0.4345\n",
      "Baseline Loss: 2.6646 | Actual Loss: 1.0253\n",
      "Baseline Loss: 2.6721 | Actual Loss: 0.5539\n",
      "Baseline Loss: 2.6976 | Actual Loss: 0.2053\n",
      "Baseline Loss: 2.2478 | Actual Loss: 0.3539\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7120\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4930\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3076\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5804\n",
      "Epoch 97/1000: Train Loss: 0.5052, Val Loss: 0.5233\n",
      "New best validation loss: 0.5233\n",
      "Baseline Loss: 2.6774 | Actual Loss: 0.6913\n",
      "Baseline Loss: 2.6927 | Actual Loss: 0.3606\n",
      "Baseline Loss: 2.6658 | Actual Loss: 0.5181\n",
      "Baseline Loss: 2.6242 | Actual Loss: 0.4167\n",
      "Baseline Loss: 2.6627 | Actual Loss: 2.2359\n",
      "Baseline Loss: 2.6773 | Actual Loss: 1.1178\n",
      "Baseline Loss: 2.6926 | Actual Loss: 0.3811\n",
      "Baseline Loss: 2.6576 | Actual Loss: 0.6640\n",
      "Baseline Loss: 2.7104 | Actual Loss: 0.6102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 98/1000 [00:30<04:40,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6591 | Actual Loss: 0.5569\n",
      "Baseline Loss: 2.6703 | Actual Loss: 0.5374\n",
      "Baseline Loss: 2.6533 | Actual Loss: 0.3650\n",
      "Baseline Loss: 2.6749 | Actual Loss: 0.5527\n",
      "Baseline Loss: 2.6773 | Actual Loss: 1.0585\n",
      "Baseline Loss: 2.6622 | Actual Loss: 1.8624\n",
      "Baseline Loss: 2.2326 | Actual Loss: 0.9280\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7843\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.6147\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4626\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5128\n",
      "Epoch 98/1000: Train Loss: 0.8035, Val Loss: 0.5936\n",
      "Baseline Loss: 2.6927 | Actual Loss: 1.5029\n",
      "Baseline Loss: 2.6607 | Actual Loss: 0.4931\n",
      "Baseline Loss: 2.6874 | Actual Loss: 0.6386\n",
      "Baseline Loss: 2.6854 | Actual Loss: 0.5198\n",
      "Baseline Loss: 2.6704 | Actual Loss: 0.5699\n",
      "Baseline Loss: 2.6762 | Actual Loss: 0.7057\n",
      "Baseline Loss: 2.6687 | Actual Loss: 0.4564\n",
      "Baseline Loss: 2.7108 | Actual Loss: 0.5022\n",
      "Baseline Loss: 2.6559 | Actual Loss: 0.5421\n",
      "Baseline Loss: 2.6529 | Actual Loss: 1.9739\n",
      "Baseline Loss: 2.7042 | Actual Loss: 0.5175\n",
      "Baseline Loss: 2.6958 | Actual Loss: 0.1989\n",
      "Baseline Loss: 2.6923 | Actual Loss: 0.5376\n",
      "Baseline Loss: 2.6533 | Actual Loss: 1.3842\n",
      "Baseline Loss: 2.6572 | Actual Loss: 0.6268\n",
      "Baseline Loss: 2.2546 | Actual Loss: 0.1317\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.9105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 99/1000 [00:31<04:53,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6644 | Actual Loss: 0.5235\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4082\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.9657\n",
      "Epoch 99/1000: Train Loss: 0.7063, Val Loss: 0.7020\n",
      "Baseline Loss: 2.6961 | Actual Loss: 2.2815\n",
      "Baseline Loss: 2.6684 | Actual Loss: 0.7091\n",
      "Baseline Loss: 2.6894 | Actual Loss: 0.4807\n",
      "Baseline Loss: 2.6961 | Actual Loss: 0.5375\n",
      "Baseline Loss: 2.6955 | Actual Loss: 0.6470\n",
      "Baseline Loss: 2.6234 | Actual Loss: 0.5006\n",
      "Baseline Loss: 2.7232 | Actual Loss: 0.4063\n",
      "Baseline Loss: 2.6509 | Actual Loss: 0.3931\n",
      "Baseline Loss: 2.6837 | Actual Loss: 0.7369\n",
      "Baseline Loss: 2.6633 | Actual Loss: 0.7134\n",
      "Baseline Loss: 2.6444 | Actual Loss: 0.1480\n",
      "Baseline Loss: 2.6513 | Actual Loss: 0.3248\n",
      "Baseline Loss: 2.6397 | Actual Loss: 0.5347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 100/1000 [00:31<04:34,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6741 | Actual Loss: 0.4725\n",
      "Baseline Loss: 2.6653 | Actual Loss: 0.6647\n",
      "Baseline Loss: 2.2649 | Actual Loss: 0.2543\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7693\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.7385\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.5131\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5387\n",
      "Epoch 100/1000: Train Loss: 0.6128, Val Loss: 0.6399\n",
      "Baseline Loss: 2.6851 | Actual Loss: 0.4682\n",
      "Baseline Loss: 2.6720 | Actual Loss: 0.4242\n",
      "Baseline Loss: 2.6936 | Actual Loss: 0.4815\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.7242\n",
      "Baseline Loss: 2.6954 | Actual Loss: 0.5744\n",
      "Baseline Loss: 2.6586 | Actual Loss: 0.5356\n",
      "Baseline Loss: 2.6635 | Actual Loss: 0.4534\n",
      "Baseline Loss: 2.6768 | Actual Loss: 0.2932\n",
      "Baseline Loss: 2.6654 | Actual Loss: 0.3530\n",
      "Baseline Loss: 2.6552 | Actual Loss: 1.6097\n",
      "Baseline Loss: 2.7267 | Actual Loss: 0.5877\n",
      "Baseline Loss: 2.6684 | Actual Loss: 0.2619\n",
      "Baseline Loss: 2.6660 | Actual Loss: 0.5502\n",
      "Baseline Loss: 2.6716 | Actual Loss: 0.3987\n",
      "Baseline Loss: 2.6776 | Actual Loss: 0.5950\n",
      "Baseline Loss: 2.2820 | Actual Loss: 0.4710\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7021\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.5068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 101/1000 [00:31<04:44,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6840 | Actual Loss: 0.4658\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5169\n",
      "Epoch 101/1000: Train Loss: 0.5489, Val Loss: 0.5479\n",
      "Baseline Loss: 2.6326 | Actual Loss: 0.5527\n",
      "Baseline Loss: 2.6608 | Actual Loss: 0.6759\n",
      "Baseline Loss: 2.6452 | Actual Loss: 0.4953\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.3088\n",
      "Baseline Loss: 2.6361 | Actual Loss: 0.5923\n",
      "Baseline Loss: 2.7156 | Actual Loss: 0.5557\n",
      "Baseline Loss: 2.6885 | Actual Loss: 0.4994\n",
      "Baseline Loss: 2.7144 | Actual Loss: 0.1881\n",
      "Baseline Loss: 2.6593 | Actual Loss: 0.4384\n",
      "Baseline Loss: 2.6814 | Actual Loss: 0.6369\n",
      "Baseline Loss: 2.6741 | Actual Loss: 0.3186\n",
      "Baseline Loss: 2.6605 | Actual Loss: 0.4359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 102/1000 [00:32<04:47,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6569 | Actual Loss: 0.4693\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.2852\n",
      "Baseline Loss: 2.7140 | Actual Loss: 2.0725\n",
      "Baseline Loss: 2.3404 | Actual Loss: 0.6282\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6957\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.5149\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.6006\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5231\n",
      "Epoch 102/1000: Train Loss: 0.5721, Val Loss: 0.5836\n",
      "Baseline Loss: 2.6743 | Actual Loss: 0.4782\n",
      "Baseline Loss: 2.6863 | Actual Loss: 0.6492\n",
      "Baseline Loss: 2.6919 | Actual Loss: 0.6524\n",
      "Baseline Loss: 2.6682 | Actual Loss: 0.3214\n",
      "Baseline Loss: 2.6460 | Actual Loss: 0.4659\n",
      "Baseline Loss: 2.6945 | Actual Loss: 0.2177\n",
      "Baseline Loss: 2.6407 | Actual Loss: 0.2353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 103/1000 [00:32<04:30,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6563 | Actual Loss: 0.7218\n",
      "Baseline Loss: 2.7048 | Actual Loss: 0.3172\n",
      "Baseline Loss: 2.6442 | Actual Loss: 0.1598\n",
      "Baseline Loss: 2.6778 | Actual Loss: 0.7001\n",
      "Baseline Loss: 2.6800 | Actual Loss: 0.4095\n",
      "Baseline Loss: 2.6871 | Actual Loss: 0.6719\n",
      "Baseline Loss: 2.6654 | Actual Loss: 0.2436\n",
      "Baseline Loss: 2.6777 | Actual Loss: 1.3555\n",
      "Baseline Loss: 2.2549 | Actual Loss: 0.3894\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7880\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.6519\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.5046\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.6070\n",
      "Epoch 103/1000: Train Loss: 0.4993, Val Loss: 0.6379\n",
      "Baseline Loss: 2.6528 | Actual Loss: 0.4056\n",
      "Baseline Loss: 2.6869 | Actual Loss: 0.5205\n",
      "Baseline Loss: 2.6592 | Actual Loss: 0.8191\n",
      "Baseline Loss: 2.6797 | Actual Loss: 0.5900\n",
      "Baseline Loss: 2.6373 | Actual Loss: 0.5569\n",
      "Baseline Loss: 2.6998 | Actual Loss: 1.6118\n",
      "Baseline Loss: 2.6976 | Actual Loss: 0.3463\n",
      "Baseline Loss: 2.6763 | Actual Loss: 0.3566\n",
      "Baseline Loss: 2.6926 | Actual Loss: 0.4140\n",
      "Baseline Loss: 2.6736 | Actual Loss: 0.3518\n",
      "Baseline Loss: 2.6502 | Actual Loss: 0.8699\n",
      "Baseline Loss: 2.7169 | Actual Loss: 0.4677\n",
      "Baseline Loss: 2.6540 | Actual Loss: 0.4529\n",
      "Baseline Loss: 2.7011 | Actual Loss: 0.3182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 104/1000 [00:32<04:44,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6757 | Actual Loss: 1.1036\n",
      "Baseline Loss: 2.3260 | Actual Loss: 0.2039\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6909\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.5417\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3573\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5009\n",
      "Epoch 104/1000: Train Loss: 0.5868, Val Loss: 0.5227\n",
      "New best validation loss: 0.5227\n",
      "Baseline Loss: 2.6149 | Actual Loss: 0.3842\n",
      "Baseline Loss: 2.6324 | Actual Loss: 0.4859\n",
      "Baseline Loss: 2.6736 | Actual Loss: 0.3556\n",
      "Baseline Loss: 2.6599 | Actual Loss: 0.5476\n",
      "Baseline Loss: 2.7062 | Actual Loss: 0.8768\n",
      "Baseline Loss: 2.6826 | Actual Loss: 0.3823\n",
      "Baseline Loss: 2.6595 | Actual Loss: 0.6064\n",
      "Baseline Loss: 2.6726 | Actual Loss: 0.9571\n",
      "Baseline Loss: 2.6666 | Actual Loss: 0.2566\n",
      "Baseline Loss: 2.7025 | Actual Loss: 0.4791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 105/1000 [00:33<04:47,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6883 | Actual Loss: 0.5443\n",
      "Baseline Loss: 2.7192 | Actual Loss: 0.4769\n",
      "Baseline Loss: 2.6699 | Actual Loss: 0.3236\n",
      "Baseline Loss: 2.6762 | Actual Loss: 0.3136\n",
      "Baseline Loss: 2.7166 | Actual Loss: 0.5002\n",
      "Baseline Loss: 2.2894 | Actual Loss: 0.2822\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7554\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4841\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4871\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.4970\n",
      "Epoch 105/1000: Train Loss: 0.4858, Val Loss: 0.5559\n",
      "Baseline Loss: 2.6656 | Actual Loss: 0.1673\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.6841\n",
      "Baseline Loss: 2.6817 | Actual Loss: 0.3701\n",
      "Baseline Loss: 2.6433 | Actual Loss: 0.3780\n",
      "Baseline Loss: 2.7031 | Actual Loss: 0.3678\n",
      "Baseline Loss: 2.6784 | Actual Loss: 0.4611\n",
      "Baseline Loss: 2.6986 | Actual Loss: 0.6556\n",
      "Baseline Loss: 2.6700 | Actual Loss: 0.5766\n",
      "Baseline Loss: 2.6368 | Actual Loss: 0.3431\n",
      "Baseline Loss: 2.6635 | Actual Loss: 0.1767\n",
      "Baseline Loss: 2.6658 | Actual Loss: 0.6761\n",
      "Baseline Loss: 2.6939 | Actual Loss: 0.2491\n",
      "Baseline Loss: 2.6688 | Actual Loss: 0.3152\n",
      "Baseline Loss: 2.6721 | Actual Loss: 1.1433\n",
      "Baseline Loss: 2.6712 | Actual Loss: 0.2881\n",
      "Baseline Loss: 2.2948 | Actual Loss: 0.2136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 106/1000 [00:33<04:36,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6907 | Actual Loss: 0.6836\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4903\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3715\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5264\n",
      "Epoch 106/1000: Train Loss: 0.4416, Val Loss: 0.5179\n",
      "New best validation loss: 0.5179\n",
      "Baseline Loss: 2.6773 | Actual Loss: 0.4268\n",
      "Baseline Loss: 2.6682 | Actual Loss: 0.2299\n",
      "Baseline Loss: 2.7179 | Actual Loss: 0.8285\n",
      "Baseline Loss: 2.6526 | Actual Loss: 0.2958\n",
      "Baseline Loss: 2.7043 | Actual Loss: 0.3701\n",
      "Baseline Loss: 2.6486 | Actual Loss: 0.6588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 107/1000 [00:33<04:45,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6672 | Actual Loss: 0.7011\n",
      "Baseline Loss: 2.7134 | Actual Loss: 0.1924\n",
      "Baseline Loss: 2.6464 | Actual Loss: 0.4609\n",
      "Baseline Loss: 2.6890 | Actual Loss: 0.3862\n",
      "Baseline Loss: 2.6902 | Actual Loss: 0.5764\n",
      "Baseline Loss: 2.6821 | Actual Loss: 0.3989\n",
      "Baseline Loss: 2.6898 | Actual Loss: 0.2561\n",
      "Baseline Loss: 2.6564 | Actual Loss: 0.5388\n",
      "Baseline Loss: 2.6526 | Actual Loss: 0.3835\n",
      "Baseline Loss: 2.2449 | Actual Loss: 0.2495\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7813\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4873\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3816\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.4513\n",
      "Epoch 107/1000: Train Loss: 0.4346, Val Loss: 0.5254\n",
      "Baseline Loss: 2.6444 | Actual Loss: 0.4675\n",
      "Baseline Loss: 2.6502 | Actual Loss: 0.3571\n",
      "Baseline Loss: 2.6783 | Actual Loss: 0.3177\n",
      "Baseline Loss: 2.6540 | Actual Loss: 0.8020\n",
      "Baseline Loss: 2.6771 | Actual Loss: 0.9077\n",
      "Baseline Loss: 2.7262 | Actual Loss: 0.3532\n",
      "Baseline Loss: 2.7075 | Actual Loss: 0.4633\n",
      "Baseline Loss: 2.6584 | Actual Loss: 0.2911\n",
      "Baseline Loss: 2.6624 | Actual Loss: 0.7009\n",
      "Baseline Loss: 2.6711 | Actual Loss: 0.3204\n",
      "Baseline Loss: 2.6671 | Actual Loss: 0.2935\n",
      "Baseline Loss: 2.6567 | Actual Loss: 0.7863\n",
      "Baseline Loss: 2.7046 | Actual Loss: 0.6616\n",
      "Baseline Loss: 2.6660 | Actual Loss: 0.4457\n",
      "Baseline Loss: 2.6876 | Actual Loss: 0.2971\n",
      "Baseline Loss: 2.2856 | Actual Loss: 0.0979\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6997\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 108/1000 [00:34<04:51,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6840 | Actual Loss: 0.2972\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.4923\n",
      "Epoch 108/1000: Train Loss: 0.4727, Val Loss: 0.4954\n",
      "New best validation loss: 0.4954\n",
      "Baseline Loss: 2.7005 | Actual Loss: 0.6424\n",
      "Baseline Loss: 2.6962 | Actual Loss: 0.2003\n",
      "Baseline Loss: 2.6692 | Actual Loss: 0.5120\n",
      "Baseline Loss: 2.6994 | Actual Loss: 0.4821\n",
      "Baseline Loss: 2.6832 | Actual Loss: 0.6634\n",
      "Baseline Loss: 2.6802 | Actual Loss: 0.4968\n",
      "Baseline Loss: 2.6850 | Actual Loss: 0.4673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 109/1000 [00:34<04:36,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6820 | Actual Loss: 0.3782\n",
      "Baseline Loss: 2.6244 | Actual Loss: 0.3449\n",
      "Baseline Loss: 2.6544 | Actual Loss: 0.7667\n",
      "Baseline Loss: 2.6740 | Actual Loss: 0.5628\n",
      "Baseline Loss: 2.6865 | Actual Loss: 0.4296\n",
      "Baseline Loss: 2.6687 | Actual Loss: 0.3488\n",
      "Baseline Loss: 2.6658 | Actual Loss: 0.3080\n",
      "Baseline Loss: 2.6650 | Actual Loss: 0.7612\n",
      "Baseline Loss: 2.2462 | Actual Loss: 1.0418\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6763\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.5073\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3614\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5735\n",
      "Epoch 109/1000: Train Loss: 0.5254, Val Loss: 0.5296\n",
      "Baseline Loss: 2.6888 | Actual Loss: 0.4085\n",
      "Baseline Loss: 2.7100 | Actual Loss: 1.9246\n",
      "Baseline Loss: 2.6815 | Actual Loss: 0.6893\n",
      "Baseline Loss: 2.6356 | Actual Loss: 0.3286\n",
      "Baseline Loss: 2.6533 | Actual Loss: 0.4711\n",
      "Baseline Loss: 2.7123 | Actual Loss: 0.3678\n",
      "Baseline Loss: 2.6858 | Actual Loss: 0.3806\n",
      "Baseline Loss: 2.6323 | Actual Loss: 0.6788\n",
      "Baseline Loss: 2.6851 | Actual Loss: 0.6196\n",
      "Baseline Loss: 2.6771 | Actual Loss: 0.2015\n",
      "Baseline Loss: 2.6877 | Actual Loss: 0.7362\n",
      "Baseline Loss: 2.6641 | Actual Loss: 0.2774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 110/1000 [00:34<04:47,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6944 | Actual Loss: 0.4454\n",
      "Baseline Loss: 2.6417 | Actual Loss: 0.8234\n",
      "Baseline Loss: 2.6933 | Actual Loss: 0.5519\n",
      "Baseline Loss: 2.2718 | Actual Loss: 0.0367\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7904\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.5018\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.5898\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.6201\n",
      "Epoch 110/1000: Train Loss: 0.5588, Val Loss: 0.6255\n",
      "Baseline Loss: 2.6777 | Actual Loss: 1.0322\n",
      "Baseline Loss: 2.7037 | Actual Loss: 0.7915\n",
      "Baseline Loss: 2.6538 | Actual Loss: 0.3032\n",
      "Baseline Loss: 2.6759 | Actual Loss: 0.6915\n",
      "Baseline Loss: 2.6710 | Actual Loss: 0.5226\n",
      "Baseline Loss: 2.6773 | Actual Loss: 0.3306\n",
      "Baseline Loss: 2.6909 | Actual Loss: 0.3935\n",
      "Baseline Loss: 2.7167 | Actual Loss: 0.4628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 111/1000 [00:34<04:33,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6572 | Actual Loss: 0.2995\n",
      "Baseline Loss: 2.6598 | Actual Loss: 0.5423\n",
      "Baseline Loss: 2.7021 | Actual Loss: 0.4729\n",
      "Baseline Loss: 2.6509 | Actual Loss: 0.3896\n",
      "Baseline Loss: 2.6348 | Actual Loss: 0.7860\n",
      "Baseline Loss: 2.6629 | Actual Loss: 1.2248\n",
      "Baseline Loss: 2.6595 | Actual Loss: 1.3902\n",
      "Baseline Loss: 2.2417 | Actual Loss: 0.6469\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.8395\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.5900\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.6284\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.4841\n",
      "Epoch 111/1000: Train Loss: 0.6425, Val Loss: 0.6355\n",
      "Baseline Loss: 2.6633 | Actual Loss: 0.7102\n",
      "Baseline Loss: 2.6769 | Actual Loss: 1.7720\n",
      "Baseline Loss: 2.6551 | Actual Loss: 0.5696\n",
      "Baseline Loss: 2.6823 | Actual Loss: 0.5133\n",
      "Baseline Loss: 2.6698 | Actual Loss: 0.2882\n",
      "Baseline Loss: 2.6530 | Actual Loss: 0.3474\n",
      "Baseline Loss: 2.6740 | Actual Loss: 0.6426\n",
      "Baseline Loss: 2.6579 | Actual Loss: 0.3105\n",
      "Baseline Loss: 2.6526 | Actual Loss: 0.5986\n",
      "Baseline Loss: 2.6790 | Actual Loss: 0.5017\n",
      "Baseline Loss: 2.6951 | Actual Loss: 0.3688\n",
      "Baseline Loss: 2.6511 | Actual Loss: 0.5092\n",
      "Baseline Loss: 2.6868 | Actual Loss: 0.6201\n",
      "Baseline Loss: 2.6506 | Actual Loss: 0.5211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 112/1000 [00:35<04:38,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6693 | Actual Loss: 0.4777\n",
      "Baseline Loss: 2.2809 | Actual Loss: 0.5448\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7432\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.5531\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4584\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.4956\n",
      "Epoch 112/1000: Train Loss: 0.5810, Val Loss: 0.5626\n",
      "Baseline Loss: 2.6960 | Actual Loss: 0.3290\n",
      "Baseline Loss: 2.6503 | Actual Loss: 0.5516\n",
      "Baseline Loss: 2.6940 | Actual Loss: 0.7654\n",
      "Baseline Loss: 2.6915 | Actual Loss: 0.4851\n",
      "Baseline Loss: 2.6810 | Actual Loss: 2.0313\n",
      "Baseline Loss: 2.6460 | Actual Loss: 0.4877\n",
      "Baseline Loss: 2.6844 | Actual Loss: 0.4550\n",
      "Baseline Loss: 2.6245 | Actual Loss: 0.6771\n",
      "Baseline Loss: 2.6734 | Actual Loss: 0.4467\n",
      "Baseline Loss: 2.7386 | Actual Loss: 0.7997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█▏        | 113/1000 [00:35<04:22,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6886 | Actual Loss: 0.2930\n",
      "Baseline Loss: 2.6568 | Actual Loss: 0.3227\n",
      "Baseline Loss: 2.6401 | Actual Loss: 0.3014\n",
      "Baseline Loss: 2.6904 | Actual Loss: 0.3472\n",
      "Baseline Loss: 2.6734 | Actual Loss: 0.7709\n",
      "Baseline Loss: 2.3050 | Actual Loss: 0.3356\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6741\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4989\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4287\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5543\n",
      "Epoch 113/1000: Train Loss: 0.5875, Val Loss: 0.5390\n",
      "Baseline Loss: 2.6786 | Actual Loss: 0.3660\n",
      "Baseline Loss: 2.6821 | Actual Loss: 0.5359\n",
      "Baseline Loss: 2.7116 | Actual Loss: 0.3930\n",
      "Baseline Loss: 2.6661 | Actual Loss: 0.3963\n",
      "Baseline Loss: 2.6836 | Actual Loss: 0.3285\n",
      "Baseline Loss: 2.7016 | Actual Loss: 1.4649\n",
      "Baseline Loss: 2.6940 | Actual Loss: 0.3821\n",
      "Baseline Loss: 2.6500 | Actual Loss: 0.3658\n",
      "Baseline Loss: 2.6992 | Actual Loss: 0.3359\n",
      "Baseline Loss: 2.6557 | Actual Loss: 0.2619\n",
      "Baseline Loss: 2.6941 | Actual Loss: 0.7950\n",
      "Baseline Loss: 2.6632 | Actual Loss: 0.2025\n",
      "Baseline Loss: 2.6418 | Actual Loss: 0.4085\n",
      "Baseline Loss: 2.6740 | Actual Loss: 0.3235\n",
      "Baseline Loss: 2.6709 | Actual Loss: 0.4905\n",
      "Baseline Loss: 2.2483 | Actual Loss: 0.0832\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6940\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.6356\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█▏        | 114/1000 [00:35<04:32,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6117 | Actual Loss: 0.5407\n",
      "Epoch 114/1000: Train Loss: 0.4459, Val Loss: 0.5761\n",
      "Baseline Loss: 2.6769 | Actual Loss: 0.6502\n",
      "Baseline Loss: 2.6858 | Actual Loss: 0.6414\n",
      "Baseline Loss: 2.6699 | Actual Loss: 0.4084\n",
      "Baseline Loss: 2.6547 | Actual Loss: 0.5098\n",
      "Baseline Loss: 2.6986 | Actual Loss: 0.3664\n",
      "Baseline Loss: 2.6730 | Actual Loss: 0.6168\n",
      "Baseline Loss: 2.6962 | Actual Loss: 0.3665\n",
      "Baseline Loss: 2.6563 | Actual Loss: 0.1114\n",
      "Baseline Loss: 2.6874 | Actual Loss: 0.6291\n",
      "Baseline Loss: 2.7076 | Actual Loss: 0.3356\n",
      "Baseline Loss: 2.6647 | Actual Loss: 0.3129\n",
      "Baseline Loss: 2.6619 | Actual Loss: 0.3572\n",
      "Baseline Loss: 2.7027 | Actual Loss: 0.2854\n",
      "Baseline Loss: 2.6596 | Actual Loss: 0.7380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 115/1000 [00:36<04:43,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6708 | Actual Loss: 0.3033\n",
      "Baseline Loss: 2.2464 | Actual Loss: 0.2111\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6136\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4932\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3236\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.6039\n",
      "Epoch 115/1000: Train Loss: 0.4277, Val Loss: 0.5086\n",
      "Baseline Loss: 2.6367 | Actual Loss: 1.9826\n",
      "Baseline Loss: 2.6595 | Actual Loss: 0.3147\n",
      "Baseline Loss: 2.6787 | Actual Loss: 0.7999\n",
      "Baseline Loss: 2.6956 | Actual Loss: 0.5868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 116/1000 [00:36<04:27,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6462 | Actual Loss: 0.4727\n",
      "Baseline Loss: 2.6508 | Actual Loss: 0.4041\n",
      "Baseline Loss: 2.7177 | Actual Loss: 0.1967\n",
      "Baseline Loss: 2.6737 | Actual Loss: 0.4692\n",
      "Baseline Loss: 2.6794 | Actual Loss: 0.4466\n",
      "Baseline Loss: 2.6514 | Actual Loss: 0.3345\n",
      "Baseline Loss: 2.6609 | Actual Loss: 0.7264\n",
      "Baseline Loss: 2.7115 | Actual Loss: 0.5462\n",
      "Baseline Loss: 2.6937 | Actual Loss: 0.6334\n",
      "Baseline Loss: 2.7115 | Actual Loss: 0.1252\n",
      "Baseline Loss: 2.6452 | Actual Loss: 0.6746\n",
      "Baseline Loss: 2.2333 | Actual Loss: 0.0661\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6688\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.5307\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4088\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.4539\n",
      "Epoch 116/1000: Train Loss: 0.5487, Val Loss: 0.5155\n",
      "Baseline Loss: 2.6531 | Actual Loss: 0.7501\n",
      "Baseline Loss: 2.6597 | Actual Loss: 0.3824\n",
      "Baseline Loss: 2.6819 | Actual Loss: 0.1268\n",
      "Baseline Loss: 2.6521 | Actual Loss: 0.5779\n",
      "Baseline Loss: 2.6951 | Actual Loss: 0.6738\n",
      "Baseline Loss: 2.6616 | Actual Loss: 0.5468\n",
      "Baseline Loss: 2.7127 | Actual Loss: 0.5226\n",
      "Baseline Loss: 2.6722 | Actual Loss: 0.5593\n",
      "Baseline Loss: 2.6987 | Actual Loss: 0.4944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 117/1000 [00:36<04:32,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6719 | Actual Loss: 0.2795\n",
      "Baseline Loss: 2.6552 | Actual Loss: 1.4564\n",
      "Baseline Loss: 2.6330 | Actual Loss: 0.5951\n",
      "Baseline Loss: 2.6356 | Actual Loss: 0.4473\n",
      "Baseline Loss: 2.6660 | Actual Loss: 0.4003\n",
      "Baseline Loss: 2.6598 | Actual Loss: 0.6953\n",
      "Baseline Loss: 2.2978 | Actual Loss: 2.2642\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6442\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.8442\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.7235\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.4393\n",
      "Epoch 117/1000: Train Loss: 0.6733, Val Loss: 0.6628\n",
      "Baseline Loss: 2.6455 | Actual Loss: 1.1236\n",
      "Baseline Loss: 2.6484 | Actual Loss: 0.2650\n",
      "Baseline Loss: 2.6917 | Actual Loss: 0.5141\n",
      "Baseline Loss: 2.6464 | Actual Loss: 0.4787\n",
      "Baseline Loss: 2.6730 | Actual Loss: 0.4887\n",
      "Baseline Loss: 2.6624 | Actual Loss: 0.5841\n",
      "Baseline Loss: 2.6942 | Actual Loss: 1.4814\n",
      "Baseline Loss: 2.6958 | Actual Loss: 0.6518\n",
      "Baseline Loss: 2.6906 | Actual Loss: 0.3432\n",
      "Baseline Loss: 2.6622 | Actual Loss: 0.2651\n",
      "Baseline Loss: 2.6479 | Actual Loss: 0.4458\n",
      "Baseline Loss: 2.6856 | Actual Loss: 0.2411\n",
      "Baseline Loss: 2.6682 | Actual Loss: 1.4313\n",
      "Baseline Loss: 2.6782 | Actual Loss: 0.2318\n",
      "Baseline Loss: 2.6935 | Actual Loss: 0.5336\n",
      "Baseline Loss: 2.2820 | Actual Loss: 0.5903\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 118/1000 [00:37<04:43,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6644 | Actual Loss: 0.5355\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4106\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.4270\n",
      "Epoch 118/1000: Train Loss: 0.6044, Val Loss: 0.5253\n",
      "Baseline Loss: 2.6858 | Actual Loss: 0.2890\n",
      "Baseline Loss: 2.6787 | Actual Loss: 0.5236\n",
      "Baseline Loss: 2.6480 | Actual Loss: 0.3308\n",
      "Baseline Loss: 2.6775 | Actual Loss: 0.6770\n",
      "Baseline Loss: 2.6737 | Actual Loss: 0.7970\n",
      "Baseline Loss: 2.6549 | Actual Loss: 0.4227\n",
      "Baseline Loss: 2.6541 | Actual Loss: 0.4442\n",
      "Baseline Loss: 2.6984 | Actual Loss: 0.2511\n",
      "Baseline Loss: 2.6722 | Actual Loss: 0.5626\n",
      "Baseline Loss: 2.6721 | Actual Loss: 0.7663\n",
      "Baseline Loss: 2.6599 | Actual Loss: 0.7216\n",
      "Baseline Loss: 2.7033 | Actual Loss: 0.3211\n",
      "Baseline Loss: 2.6752 | Actual Loss: 0.2341\n",
      "Baseline Loss: 2.6725 | Actual Loss: 0.3656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 119/1000 [00:37<04:27,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7620 | Actual Loss: 0.2865\n",
      "Baseline Loss: 2.2525 | Actual Loss: 1.0401\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6698\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.7421\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.5871\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.9430\n",
      "Epoch 119/1000: Train Loss: 0.5021, Val Loss: 0.7355\n",
      "Baseline Loss: 2.6723 | Actual Loss: 0.2593\n",
      "Baseline Loss: 2.6649 | Actual Loss: 0.5610\n",
      "Baseline Loss: 2.6885 | Actual Loss: 0.9550\n",
      "Baseline Loss: 2.6490 | Actual Loss: 0.5302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 120/1000 [00:37<04:33,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6827 | Actual Loss: 0.4386\n",
      "Baseline Loss: 2.6796 | Actual Loss: 0.8238\n",
      "Baseline Loss: 2.6751 | Actual Loss: 0.5648\n",
      "Baseline Loss: 2.6908 | Actual Loss: 0.4412\n",
      "Baseline Loss: 2.6699 | Actual Loss: 0.2803\n",
      "Baseline Loss: 2.6983 | Actual Loss: 0.6303\n",
      "Baseline Loss: 2.6829 | Actual Loss: 0.3209\n",
      "Baseline Loss: 2.7294 | Actual Loss: 0.3427\n",
      "Baseline Loss: 2.6880 | Actual Loss: 0.3136\n",
      "Baseline Loss: 2.6527 | Actual Loss: 0.8473\n",
      "Baseline Loss: 2.7004 | Actual Loss: 0.5224\n",
      "Baseline Loss: 2.2948 | Actual Loss: 0.1698\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7996\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.5323\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4753\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5762\n",
      "Epoch 120/1000: Train Loss: 0.5001, Val Loss: 0.5958\n",
      "Baseline Loss: 2.6817 | Actual Loss: 0.3604\n",
      "Baseline Loss: 2.6971 | Actual Loss: 0.5294\n",
      "Baseline Loss: 2.6528 | Actual Loss: 0.9376\n",
      "Baseline Loss: 2.6380 | Actual Loss: 0.5614\n",
      "Baseline Loss: 2.7285 | Actual Loss: 0.2754\n",
      "Baseline Loss: 2.6802 | Actual Loss: 0.5026\n",
      "Baseline Loss: 2.6819 | Actual Loss: 0.4124\n",
      "Baseline Loss: 2.7383 | Actual Loss: 0.5432\n",
      "Baseline Loss: 2.6628 | Actual Loss: 0.2565\n",
      "Baseline Loss: 2.6550 | Actual Loss: 0.6574\n",
      "Baseline Loss: 2.6540 | Actual Loss: 0.6527\n",
      "Baseline Loss: 2.6532 | Actual Loss: 0.3312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 121/1000 [00:38<04:37,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6595 | Actual Loss: 0.2395\n",
      "Baseline Loss: 2.6893 | Actual Loss: 2.2906\n",
      "Baseline Loss: 2.6369 | Actual Loss: 1.3577\n",
      "Baseline Loss: 2.2817 | Actual Loss: 0.4296\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.8065\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.6978\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.6799\n",
      "Baseline Loss: 2.6117 | Actual Loss: 1.4337\n",
      "Epoch 121/1000: Train Loss: 0.6461, Val Loss: 0.9045\n",
      "Baseline Loss: 2.6813 | Actual Loss: 1.6775\n",
      "Baseline Loss: 2.6991 | Actual Loss: 0.1570\n",
      "Baseline Loss: 2.6962 | Actual Loss: 0.5984\n",
      "Baseline Loss: 2.6793 | Actual Loss: 0.5317\n",
      "Baseline Loss: 2.6656 | Actual Loss: 0.3930\n",
      "Baseline Loss: 2.6603 | Actual Loss: 0.4290\n",
      "Baseline Loss: 2.6818 | Actual Loss: 2.0692\n",
      "Baseline Loss: 2.6800 | Actual Loss: 0.7078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 122/1000 [00:38<04:23,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7135 | Actual Loss: 0.4771\n",
      "Baseline Loss: 2.6511 | Actual Loss: 0.6739\n",
      "Baseline Loss: 2.6286 | Actual Loss: 2.0891\n",
      "Baseline Loss: 2.6764 | Actual Loss: 0.2135\n",
      "Baseline Loss: 2.6550 | Actual Loss: 0.1500\n",
      "Baseline Loss: 2.6661 | Actual Loss: 0.5847\n",
      "Baseline Loss: 2.6926 | Actual Loss: 0.4691\n",
      "Baseline Loss: 2.2408 | Actual Loss: 0.1531\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7053\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.5652\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4867\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5364\n",
      "Epoch 122/1000: Train Loss: 0.7109, Val Loss: 0.5734\n",
      "Baseline Loss: 2.6688 | Actual Loss: 0.3836\n",
      "Baseline Loss: 2.6689 | Actual Loss: 0.2421\n",
      "Baseline Loss: 2.6523 | Actual Loss: 1.7997\n",
      "Baseline Loss: 2.6329 | Actual Loss: 0.5163\n",
      "Baseline Loss: 2.6744 | Actual Loss: 2.2162\n",
      "Baseline Loss: 2.6601 | Actual Loss: 0.2675\n",
      "Baseline Loss: 2.6956 | Actual Loss: 0.3483\n",
      "Baseline Loss: 2.6955 | Actual Loss: 0.4097\n",
      "Baseline Loss: 2.6576 | Actual Loss: 1.1978\n",
      "Baseline Loss: 2.6400 | Actual Loss: 0.1956\n",
      "Baseline Loss: 2.6811 | Actual Loss: 0.3084\n",
      "Baseline Loss: 2.7057 | Actual Loss: 0.1225\n",
      "Baseline Loss: 2.6919 | Actual Loss: 0.3928\n",
      "Baseline Loss: 2.6775 | Actual Loss: 0.3496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 123/1000 [00:38<04:38,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6822 | Actual Loss: 0.6938\n",
      "Baseline Loss: 2.2626 | Actual Loss: 0.4768\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6862\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.5952\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4158\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5096\n",
      "Epoch 123/1000: Train Loss: 0.6200, Val Loss: 0.5517\n",
      "Baseline Loss: 2.6678 | Actual Loss: 1.4460\n",
      "Baseline Loss: 2.6616 | Actual Loss: 0.6244\n",
      "Baseline Loss: 2.7058 | Actual Loss: 0.3880\n",
      "Baseline Loss: 2.6696 | Actual Loss: 0.4545\n",
      "Baseline Loss: 2.6787 | Actual Loss: 0.3738\n",
      "Baseline Loss: 2.6802 | Actual Loss: 0.9444\n",
      "Baseline Loss: 2.6738 | Actual Loss: 0.4687\n",
      "Baseline Loss: 2.6919 | Actual Loss: 0.5875\n",
      "Baseline Loss: 2.6637 | Actual Loss: 0.3136\n",
      "Baseline Loss: 2.6671 | Actual Loss: 0.9136\n",
      "Baseline Loss: 2.6558 | Actual Loss: 0.3527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 124/1000 [00:39<04:39,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6407 | Actual Loss: 0.7685\n",
      "Baseline Loss: 2.6556 | Actual Loss: 0.4435\n",
      "Baseline Loss: 2.6458 | Actual Loss: 0.3045\n",
      "Baseline Loss: 2.6739 | Actual Loss: 0.3806\n",
      "Baseline Loss: 2.2623 | Actual Loss: 0.1061\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6502\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4764\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3574\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.6677\n",
      "Epoch 124/1000: Train Loss: 0.5544, Val Loss: 0.5379\n",
      "Baseline Loss: 2.6593 | Actual Loss: 0.2467\n",
      "Baseline Loss: 2.6900 | Actual Loss: 0.2842\n",
      "Baseline Loss: 2.6819 | Actual Loss: 0.5390\n",
      "Baseline Loss: 2.7163 | Actual Loss: 0.4396\n",
      "Baseline Loss: 2.6482 | Actual Loss: 0.3463\n",
      "Baseline Loss: 2.6955 | Actual Loss: 0.3203\n",
      "Baseline Loss: 2.6926 | Actual Loss: 0.3937\n",
      "Baseline Loss: 2.6529 | Actual Loss: 0.2982\n",
      "Baseline Loss: 2.6572 | Actual Loss: 0.4191\n",
      "Baseline Loss: 2.6921 | Actual Loss: 0.4322\n",
      "Baseline Loss: 2.6289 | Actual Loss: 0.5160\n",
      "Baseline Loss: 2.7031 | Actual Loss: 0.4001\n",
      "Baseline Loss: 2.6418 | Actual Loss: 2.4366\n",
      "Baseline Loss: 2.6760 | Actual Loss: 0.7306\n",
      "Baseline Loss: 2.6685 | Actual Loss: 0.4800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▎        | 125/1000 [00:39<04:27,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2687 | Actual Loss: 0.1227\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6919\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.5328\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3843\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5489\n",
      "Epoch 125/1000: Train Loss: 0.5253, Val Loss: 0.5395\n",
      "Baseline Loss: 2.6801 | Actual Loss: 0.3376\n",
      "Baseline Loss: 2.6849 | Actual Loss: 1.1760\n",
      "Baseline Loss: 2.6602 | Actual Loss: 0.6685\n",
      "Baseline Loss: 2.7132 | Actual Loss: 0.7245\n",
      "Baseline Loss: 2.6897 | Actual Loss: 0.4432\n",
      "Baseline Loss: 2.6693 | Actual Loss: 0.6963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 126/1000 [00:39<04:34,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6294 | Actual Loss: 0.5859\n",
      "Baseline Loss: 2.6682 | Actual Loss: 0.5842\n",
      "Baseline Loss: 2.7041 | Actual Loss: 0.6230\n",
      "Baseline Loss: 2.6689 | Actual Loss: 0.4079\n",
      "Baseline Loss: 2.6810 | Actual Loss: 0.6128\n",
      "Baseline Loss: 2.6693 | Actual Loss: 0.4183\n",
      "Baseline Loss: 2.7150 | Actual Loss: 0.4765\n",
      "Baseline Loss: 2.6505 | Actual Loss: 0.2771\n",
      "Baseline Loss: 2.6856 | Actual Loss: 0.5548\n",
      "Baseline Loss: 2.2447 | Actual Loss: 0.3539\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7885\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.5046\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3827\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5625\n",
      "Epoch 126/1000: Train Loss: 0.5588, Val Loss: 0.5596\n",
      "Baseline Loss: 2.7158 | Actual Loss: 0.4071\n",
      "Baseline Loss: 2.6420 | Actual Loss: 0.2729\n",
      "Baseline Loss: 2.6481 | Actual Loss: 0.5996\n",
      "Baseline Loss: 2.6960 | Actual Loss: 0.3837\n",
      "Baseline Loss: 2.6982 | Actual Loss: 1.1811\n",
      "Baseline Loss: 2.6674 | Actual Loss: 0.3144\n",
      "Baseline Loss: 2.7090 | Actual Loss: 0.6374\n",
      "Baseline Loss: 2.6488 | Actual Loss: 0.3763\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4164\n",
      "Baseline Loss: 2.7084 | Actual Loss: 0.4953\n",
      "Baseline Loss: 2.6727 | Actual Loss: 0.5139\n",
      "Baseline Loss: 2.6976 | Actual Loss: 0.4428\n",
      "Baseline Loss: 2.6708 | Actual Loss: 0.4635\n",
      "Baseline Loss: 2.6480 | Actual Loss: 0.5247\n",
      "Baseline Loss: 2.6473 | Actual Loss: 0.4318\n",
      "Baseline Loss: 2.2847 | Actual Loss: 0.3515\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6795\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.5239\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.2564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 127/1000 [00:39<04:38,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6117 | Actual Loss: 0.7321\n",
      "Epoch 127/1000: Train Loss: 0.4883, Val Loss: 0.5480\n",
      "Baseline Loss: 2.6965 | Actual Loss: 0.6685\n",
      "Baseline Loss: 2.6369 | Actual Loss: 0.7018\n",
      "Baseline Loss: 2.6715 | Actual Loss: 0.5127\n",
      "Baseline Loss: 2.6471 | Actual Loss: 0.2123\n",
      "Baseline Loss: 2.6847 | Actual Loss: 0.4207\n",
      "Baseline Loss: 2.6668 | Actual Loss: 0.4425\n",
      "Baseline Loss: 2.6631 | Actual Loss: 0.2455\n",
      "Baseline Loss: 2.6829 | Actual Loss: 0.3115\n",
      "Baseline Loss: 2.7209 | Actual Loss: 0.6512\n",
      "Baseline Loss: 2.6791 | Actual Loss: 0.2483\n",
      "Baseline Loss: 2.6738 | Actual Loss: 0.4639\n",
      "Baseline Loss: 2.7025 | Actual Loss: 0.4162\n",
      "Baseline Loss: 2.6248 | Actual Loss: 0.4873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 128/1000 [00:40<04:25,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6840 | Actual Loss: 0.2584\n",
      "Baseline Loss: 2.7582 | Actual Loss: 0.3313\n",
      "Baseline Loss: 2.2575 | Actual Loss: 0.3997\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.9126\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.7346\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.5919\n",
      "Baseline Loss: 2.6117 | Actual Loss: 1.0768\n",
      "Epoch 128/1000: Train Loss: 0.4232, Val Loss: 0.8289\n",
      "Baseline Loss: 2.6728 | Actual Loss: 0.3731\n",
      "Baseline Loss: 2.6553 | Actual Loss: 0.9308\n",
      "Baseline Loss: 2.6367 | Actual Loss: 2.3140\n",
      "Baseline Loss: 2.7001 | Actual Loss: 0.4114\n",
      "Baseline Loss: 2.6962 | Actual Loss: 0.9152\n",
      "Baseline Loss: 2.6858 | Actual Loss: 2.2449\n",
      "Baseline Loss: 2.6347 | Actual Loss: 0.1903\n",
      "Baseline Loss: 2.6655 | Actual Loss: 0.3326\n",
      "Baseline Loss: 2.6745 | Actual Loss: 0.6072\n",
      "Baseline Loss: 2.6649 | Actual Loss: 1.4927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 129/1000 [00:40<04:30,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6906 | Actual Loss: 0.2165\n",
      "Baseline Loss: 2.7072 | Actual Loss: 0.5965\n",
      "Baseline Loss: 2.6552 | Actual Loss: 0.4470\n",
      "Baseline Loss: 2.6493 | Actual Loss: 0.8209\n",
      "Baseline Loss: 2.6917 | Actual Loss: 0.7376\n",
      "Baseline Loss: 2.2257 | Actual Loss: 0.1758\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6209\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.7192\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.2380\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5811\n",
      "Epoch 129/1000: Train Loss: 0.8004, Val Loss: 0.5398\n",
      "Baseline Loss: 2.6632 | Actual Loss: 0.5680\n",
      "Baseline Loss: 2.6315 | Actual Loss: 0.5631\n",
      "Baseline Loss: 2.6560 | Actual Loss: 0.3909\n",
      "Baseline Loss: 2.6784 | Actual Loss: 0.2914\n",
      "Baseline Loss: 2.6657 | Actual Loss: 0.8914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 130/1000 [00:40<04:15,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6928 | Actual Loss: 0.6936\n",
      "Baseline Loss: 2.6336 | Actual Loss: 0.5434\n",
      "Baseline Loss: 2.6931 | Actual Loss: 0.2902\n",
      "Baseline Loss: 2.6825 | Actual Loss: 2.2102\n",
      "Baseline Loss: 2.6657 | Actual Loss: 0.3999\n",
      "Baseline Loss: 2.6811 | Actual Loss: 0.4822\n",
      "Baseline Loss: 2.6817 | Actual Loss: 0.2764\n",
      "Baseline Loss: 2.6753 | Actual Loss: 0.3741\n",
      "Baseline Loss: 2.6505 | Actual Loss: 0.5866\n",
      "Baseline Loss: 2.7229 | Actual Loss: 2.0282\n",
      "Baseline Loss: 2.3233 | Actual Loss: 0.2379\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7124\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.5766\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4772\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5518\n",
      "Epoch 130/1000: Train Loss: 0.6767, Val Loss: 0.5795\n",
      "Baseline Loss: 2.6878 | Actual Loss: 0.4554\n",
      "Baseline Loss: 2.6896 | Actual Loss: 0.6802\n",
      "Baseline Loss: 2.7065 | Actual Loss: 0.6609\n",
      "Baseline Loss: 2.6932 | Actual Loss: 0.5227\n",
      "Baseline Loss: 2.6355 | Actual Loss: 0.3709\n",
      "Baseline Loss: 2.6586 | Actual Loss: 0.5125\n",
      "Baseline Loss: 2.7042 | Actual Loss: 0.4029\n",
      "Baseline Loss: 2.6667 | Actual Loss: 0.6524\n",
      "Baseline Loss: 2.6740 | Actual Loss: 0.6480\n",
      "Baseline Loss: 2.6570 | Actual Loss: 0.3652\n",
      "Baseline Loss: 2.6906 | Actual Loss: 0.5194\n",
      "Baseline Loss: 2.6600 | Actual Loss: 0.2832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 131/1000 [00:41<04:25,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6765 | Actual Loss: 0.2419\n",
      "Baseline Loss: 2.6916 | Actual Loss: 1.8356\n",
      "Baseline Loss: 2.6816 | Actual Loss: 0.7453\n",
      "Baseline Loss: 2.2558 | Actual Loss: 1.5332\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.8112\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.5169\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.8507\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.9261\n",
      "Epoch 131/1000: Train Loss: 0.6519, Val Loss: 0.7762\n",
      "Baseline Loss: 2.6828 | Actual Loss: 0.3630\n",
      "Baseline Loss: 2.6618 | Actual Loss: 0.2470\n",
      "Baseline Loss: 2.6747 | Actual Loss: 0.2684\n",
      "Baseline Loss: 2.6796 | Actual Loss: 0.3931\n",
      "Baseline Loss: 2.7090 | Actual Loss: 0.6784\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.3845\n",
      "Baseline Loss: 2.6709 | Actual Loss: 0.3836\n",
      "Baseline Loss: 2.6686 | Actual Loss: 0.5933\n",
      "Baseline Loss: 2.6597 | Actual Loss: 0.5130\n",
      "Baseline Loss: 2.6574 | Actual Loss: 1.8710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 132/1000 [00:41<04:12,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6662 | Actual Loss: 0.7195\n",
      "Baseline Loss: 2.6502 | Actual Loss: 0.6568\n",
      "Baseline Loss: 2.6844 | Actual Loss: 0.5059\n",
      "Baseline Loss: 2.6352 | Actual Loss: 0.5625\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2798\n",
      "Baseline Loss: 2.2886 | Actual Loss: 0.5585\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6426\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4867\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4259\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5575\n",
      "Epoch 132/1000: Train Loss: 0.5611, Val Loss: 0.5282\n",
      "Baseline Loss: 2.6726 | Actual Loss: 0.4227\n",
      "Baseline Loss: 2.6595 | Actual Loss: 0.2608\n",
      "Baseline Loss: 2.7228 | Actual Loss: 0.5411\n",
      "Baseline Loss: 2.6508 | Actual Loss: 0.4998\n",
      "Baseline Loss: 2.6901 | Actual Loss: 0.5726\n",
      "Baseline Loss: 2.6730 | Actual Loss: 0.1578\n",
      "Baseline Loss: 2.6679 | Actual Loss: 1.0744\n",
      "Baseline Loss: 2.6995 | Actual Loss: 0.4991\n",
      "Baseline Loss: 2.6402 | Actual Loss: 1.5561\n",
      "Baseline Loss: 2.7041 | Actual Loss: 0.5227\n",
      "Baseline Loss: 2.6878 | Actual Loss: 0.8110\n",
      "Baseline Loss: 2.6678 | Actual Loss: 0.2661\n",
      "Baseline Loss: 2.6846 | Actual Loss: 0.6122\n",
      "Baseline Loss: 2.6730 | Actual Loss: 0.2611\n",
      "Baseline Loss: 2.6691 | Actual Loss: 0.2922\n",
      "Baseline Loss: 2.3083 | Actual Loss: 0.4477\n",
      "Baseline Loss: 2.6907 | Actual Loss: 1.1230\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.5954\n",
      "Baseline Loss: 2.6840 | Actual Loss: 1.0324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 133/1000 [00:41<04:24,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6117 | Actual Loss: 1.2128\n",
      "Epoch 133/1000: Train Loss: 0.5498, Val Loss: 0.9909\n",
      "Baseline Loss: 2.6639 | Actual Loss: 0.5260\n",
      "Baseline Loss: 2.6816 | Actual Loss: 0.2554\n",
      "Baseline Loss: 2.6481 | Actual Loss: 0.3593\n",
      "Baseline Loss: 2.6746 | Actual Loss: 0.7082\n",
      "Baseline Loss: 2.6709 | Actual Loss: 0.4006\n",
      "Baseline Loss: 2.6633 | Actual Loss: 0.3566\n",
      "Baseline Loss: 2.6889 | Actual Loss: 1.0029\n",
      "Baseline Loss: 2.6637 | Actual Loss: 0.5895\n",
      "Baseline Loss: 2.6566 | Actual Loss: 0.3838\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.8595\n",
      "Baseline Loss: 2.6941 | Actual Loss: 0.5694\n",
      "Baseline Loss: 2.6877 | Actual Loss: 0.5431\n",
      "Baseline Loss: 2.7195 | Actual Loss: 0.3793\n",
      "Baseline Loss: 2.6578 | Actual Loss: 0.4692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 134/1000 [00:42<04:36,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6957 | Actual Loss: 0.3323\n",
      "Baseline Loss: 2.3245 | Actual Loss: 0.1362\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6936\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.5006\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4281\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5172\n",
      "Epoch 134/1000: Train Loss: 0.4920, Val Loss: 0.5349\n",
      "Baseline Loss: 2.6463 | Actual Loss: 0.3743\n",
      "Baseline Loss: 2.6423 | Actual Loss: 0.7052\n",
      "Baseline Loss: 2.6622 | Actual Loss: 0.5203\n",
      "Baseline Loss: 2.6950 | Actual Loss: 0.6517\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.2918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▎        | 135/1000 [00:42<04:23,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6372 | Actual Loss: 0.3530\n",
      "Baseline Loss: 2.6804 | Actual Loss: 0.4682\n",
      "Baseline Loss: 2.6642 | Actual Loss: 0.3800\n",
      "Baseline Loss: 2.6802 | Actual Loss: 0.4966\n",
      "Baseline Loss: 2.6949 | Actual Loss: 0.1658\n",
      "Baseline Loss: 2.6841 | Actual Loss: 0.3619\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.2387\n",
      "Baseline Loss: 2.6892 | Actual Loss: 0.2584\n",
      "Baseline Loss: 2.6378 | Actual Loss: 0.5219\n",
      "Baseline Loss: 2.7359 | Actual Loss: 0.7245\n",
      "Baseline Loss: 2.2502 | Actual Loss: 0.0499\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7946\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4617\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3774\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5223\n",
      "Epoch 135/1000: Train Loss: 0.4101, Val Loss: 0.5390\n",
      "Baseline Loss: 2.6968 | Actual Loss: 0.2837\n",
      "Baseline Loss: 2.6965 | Actual Loss: 0.6759\n",
      "Baseline Loss: 2.7024 | Actual Loss: 0.6149\n",
      "Baseline Loss: 2.7001 | Actual Loss: 0.4205\n",
      "Baseline Loss: 2.6808 | Actual Loss: 0.1938\n",
      "Baseline Loss: 2.7051 | Actual Loss: 0.1943\n",
      "Baseline Loss: 2.6338 | Actual Loss: 0.5103\n",
      "Baseline Loss: 2.6909 | Actual Loss: 0.5778\n",
      "Baseline Loss: 2.6663 | Actual Loss: 0.3314\n",
      "Baseline Loss: 2.6585 | Actual Loss: 0.4392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▎        | 136/1000 [00:42<04:32,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6759 | Actual Loss: 0.2482\n",
      "Baseline Loss: 2.6637 | Actual Loss: 0.2648\n",
      "Baseline Loss: 2.6431 | Actual Loss: 0.3444\n",
      "Baseline Loss: 2.6779 | Actual Loss: 0.3158\n",
      "Baseline Loss: 2.6241 | Actual Loss: 0.3828\n",
      "Baseline Loss: 2.1957 | Actual Loss: 0.3560\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7278\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4607\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3664\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5919\n",
      "Epoch 136/1000: Train Loss: 0.3846, Val Loss: 0.5367\n",
      "Baseline Loss: 2.6327 | Actual Loss: 0.1867\n",
      "Baseline Loss: 2.6720 | Actual Loss: 0.5372\n",
      "Baseline Loss: 2.6879 | Actual Loss: 0.3001\n",
      "Baseline Loss: 2.6588 | Actual Loss: 0.8406\n",
      "Baseline Loss: 2.6569 | Actual Loss: 0.3034\n",
      "Baseline Loss: 2.6812 | Actual Loss: 0.3455\n",
      "Baseline Loss: 2.6660 | Actual Loss: 0.7162\n",
      "Baseline Loss: 2.6562 | Actual Loss: 0.5308\n",
      "Baseline Loss: 2.6939 | Actual Loss: 1.0556\n",
      "Baseline Loss: 2.6718 | Actual Loss: 0.7285\n",
      "Baseline Loss: 2.6926 | Actual Loss: 1.9651\n",
      "Baseline Loss: 2.7089 | Actual Loss: 0.7056\n",
      "Baseline Loss: 2.6678 | Actual Loss: 0.3368\n",
      "Baseline Loss: 2.6968 | Actual Loss: 0.4005\n",
      "Baseline Loss: 2.6365 | Actual Loss: 0.3184\n",
      "Baseline Loss: 2.2963 | Actual Loss: 0.2576\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▎        | 137/1000 [00:43<04:39,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6644 | Actual Loss: 0.4551\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4835\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5561\n",
      "Epoch 137/1000: Train Loss: 0.5955, Val Loss: 0.5254\n",
      "Baseline Loss: 2.6702 | Actual Loss: 0.1305\n",
      "Baseline Loss: 2.6856 | Actual Loss: 0.2495\n",
      "Baseline Loss: 2.6480 | Actual Loss: 0.3258\n",
      "Baseline Loss: 2.6564 | Actual Loss: 0.5649\n",
      "Baseline Loss: 2.6746 | Actual Loss: 0.2580\n",
      "Baseline Loss: 2.6886 | Actual Loss: 1.2327\n",
      "Baseline Loss: 2.7213 | Actual Loss: 0.5033\n",
      "Baseline Loss: 2.6922 | Actual Loss: 0.4512\n",
      "Baseline Loss: 2.7020 | Actual Loss: 1.0551\n",
      "Baseline Loss: 2.6471 | Actual Loss: 0.3141\n",
      "Baseline Loss: 2.6673 | Actual Loss: 0.6292\n",
      "Baseline Loss: 2.7008 | Actual Loss: 0.4263\n",
      "Baseline Loss: 2.6845 | Actual Loss: 0.3268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 138/1000 [00:43<04:27,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6247 | Actual Loss: 0.6219\n",
      "Baseline Loss: 2.6822 | Actual Loss: 0.4264\n",
      "Baseline Loss: 2.2236 | Actual Loss: 0.3995\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6190\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4625\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4432\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5222\n",
      "Epoch 138/1000: Train Loss: 0.4947, Val Loss: 0.5117\n",
      "Baseline Loss: 2.7051 | Actual Loss: 0.3530\n",
      "Baseline Loss: 2.6447 | Actual Loss: 0.5764\n",
      "Baseline Loss: 2.6386 | Actual Loss: 0.8576\n",
      "Baseline Loss: 2.6943 | Actual Loss: 0.3867\n",
      "Baseline Loss: 2.7254 | Actual Loss: 0.3373\n",
      "Baseline Loss: 2.7143 | Actual Loss: 0.1752\n",
      "Baseline Loss: 2.6636 | Actual Loss: 0.4455\n",
      "Baseline Loss: 2.6849 | Actual Loss: 0.4184\n",
      "Baseline Loss: 2.7037 | Actual Loss: 0.6833\n",
      "Baseline Loss: 2.6521 | Actual Loss: 0.5223\n",
      "Baseline Loss: 2.6512 | Actual Loss: 0.4530\n",
      "Baseline Loss: 2.6531 | Actual Loss: 0.3024\n",
      "Baseline Loss: 2.6871 | Actual Loss: 0.4763\n",
      "Baseline Loss: 2.6227 | Actual Loss: 0.3571\n",
      "Baseline Loss: 2.6586 | Actual Loss: 0.5307\n",
      "Baseline Loss: 2.3038 | Actual Loss: 1.6191\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.5664\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4659\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 139/1000 [00:43<04:36,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6117 | Actual Loss: 0.4743\n",
      "Epoch 139/1000: Train Loss: 0.5309, Val Loss: 0.4776\n",
      "New best validation loss: 0.4776\n",
      "Baseline Loss: 2.6992 | Actual Loss: 0.4247\n",
      "Baseline Loss: 2.6915 | Actual Loss: 0.8389\n",
      "Baseline Loss: 2.6943 | Actual Loss: 0.2923\n",
      "Baseline Loss: 2.6587 | Actual Loss: 0.5269\n",
      "Baseline Loss: 2.6537 | Actual Loss: 0.2787\n",
      "Baseline Loss: 2.6733 | Actual Loss: 0.3998\n",
      "Baseline Loss: 2.6966 | Actual Loss: 0.2242\n",
      "Baseline Loss: 2.6878 | Actual Loss: 0.1759\n",
      "Baseline Loss: 2.6438 | Actual Loss: 1.0254\n",
      "Baseline Loss: 2.6975 | Actual Loss: 0.6087\n",
      "Baseline Loss: 2.6729 | Actual Loss: 0.5449\n",
      "Baseline Loss: 2.6538 | Actual Loss: 0.3420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 140/1000 [00:43<04:41,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6448 | Actual Loss: 0.3197\n",
      "Baseline Loss: 2.6842 | Actual Loss: 0.3481\n",
      "Baseline Loss: 2.6703 | Actual Loss: 0.4417\n",
      "Baseline Loss: 2.3826 | Actual Loss: 0.0903\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6701\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4884\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3661\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5515\n",
      "Epoch 140/1000: Train Loss: 0.4301, Val Loss: 0.5190\n",
      "Baseline Loss: 2.6718 | Actual Loss: 0.4345\n",
      "Baseline Loss: 2.6199 | Actual Loss: 0.5863\n",
      "Baseline Loss: 2.6719 | Actual Loss: 0.5670\n",
      "Baseline Loss: 2.6859 | Actual Loss: 0.5276\n",
      "Baseline Loss: 2.7041 | Actual Loss: 0.2261\n",
      "Baseline Loss: 2.6967 | Actual Loss: 0.5237\n",
      "Baseline Loss: 2.6711 | Actual Loss: 0.5470\n",
      "Baseline Loss: 2.6646 | Actual Loss: 0.3238\n",
      "Baseline Loss: 2.7077 | Actual Loss: 1.7261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 141/1000 [00:44<04:23,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6929 | Actual Loss: 0.3941\n",
      "Baseline Loss: 2.6772 | Actual Loss: 0.5118\n",
      "Baseline Loss: 2.6505 | Actual Loss: 0.2059\n",
      "Baseline Loss: 2.6603 | Actual Loss: 0.6457\n",
      "Baseline Loss: 2.6454 | Actual Loss: 0.4243\n",
      "Baseline Loss: 2.6823 | Actual Loss: 0.1573\n",
      "Baseline Loss: 2.3221 | Actual Loss: 0.1926\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6682\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4545\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3440\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5918\n",
      "Epoch 141/1000: Train Loss: 0.4996, Val Loss: 0.5146\n",
      "Baseline Loss: 2.7027 | Actual Loss: 0.5831\n",
      "Baseline Loss: 2.7206 | Actual Loss: 0.3614\n",
      "Baseline Loss: 2.6412 | Actual Loss: 0.3222\n",
      "Baseline Loss: 2.7040 | Actual Loss: 1.7563\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.1508\n",
      "Baseline Loss: 2.6785 | Actual Loss: 0.1719\n",
      "Baseline Loss: 2.6670 | Actual Loss: 0.1304\n",
      "Baseline Loss: 2.6913 | Actual Loss: 1.0467\n",
      "Baseline Loss: 2.6648 | Actual Loss: 0.4078\n",
      "Baseline Loss: 2.6339 | Actual Loss: 0.6141\n",
      "Baseline Loss: 2.6899 | Actual Loss: 0.3438\n",
      "Baseline Loss: 2.6476 | Actual Loss: 0.6698\n",
      "Baseline Loss: 2.7004 | Actual Loss: 0.2032\n",
      "Baseline Loss: 2.6811 | Actual Loss: 0.4361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 142/1000 [00:44<04:33,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7103 | Actual Loss: 0.3824\n",
      "Baseline Loss: 2.2981 | Actual Loss: 0.2271\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.5750\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4651\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4133\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5715\n",
      "Epoch 142/1000: Train Loss: 0.4879, Val Loss: 0.5062\n",
      "Baseline Loss: 2.6720 | Actual Loss: 0.2438\n",
      "Baseline Loss: 2.6614 | Actual Loss: 0.4280\n",
      "Baseline Loss: 2.6641 | Actual Loss: 0.4492\n",
      "Baseline Loss: 2.7058 | Actual Loss: 0.4108\n",
      "Baseline Loss: 2.6778 | Actual Loss: 0.5267\n",
      "Baseline Loss: 2.6788 | Actual Loss: 0.4232\n",
      "Baseline Loss: 2.6888 | Actual Loss: 0.4207\n",
      "Baseline Loss: 2.6629 | Actual Loss: 0.3749\n",
      "Baseline Loss: 2.6669 | Actual Loss: 0.2383\n",
      "Baseline Loss: 2.6486 | Actual Loss: 0.2306\n",
      "Baseline Loss: 2.6835 | Actual Loss: 0.2938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 143/1000 [00:44<04:38,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6761 | Actual Loss: 0.1640\n",
      "Baseline Loss: 2.6941 | Actual Loss: 0.7392\n",
      "Baseline Loss: 2.6354 | Actual Loss: 0.7500\n",
      "Baseline Loss: 2.7216 | Actual Loss: 0.8401\n",
      "Baseline Loss: 2.2590 | Actual Loss: 0.3496\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7378\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4668\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3325\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.6063\n",
      "Epoch 143/1000: Train Loss: 0.4302, Val Loss: 0.5358\n",
      "Baseline Loss: 2.7052 | Actual Loss: 0.4127\n",
      "Baseline Loss: 2.6705 | Actual Loss: 0.5159\n",
      "Baseline Loss: 2.6766 | Actual Loss: 0.6127\n",
      "Baseline Loss: 2.6688 | Actual Loss: 1.7309\n",
      "Baseline Loss: 2.6649 | Actual Loss: 0.7461\n",
      "Baseline Loss: 2.6854 | Actual Loss: 0.4445\n",
      "Baseline Loss: 2.6580 | Actual Loss: 0.4051\n",
      "Baseline Loss: 2.6425 | Actual Loss: 0.6240\n",
      "Baseline Loss: 2.6531 | Actual Loss: 0.6327\n",
      "Baseline Loss: 2.6657 | Actual Loss: 0.3316\n",
      "Baseline Loss: 2.6595 | Actual Loss: 0.3662\n",
      "Baseline Loss: 2.7128 | Actual Loss: 0.6876\n",
      "Baseline Loss: 2.6897 | Actual Loss: 0.4656\n",
      "Baseline Loss: 2.7226 | Actual Loss: 0.2839\n",
      "Baseline Loss: 2.6642 | Actual Loss: 0.0865\n",
      "Baseline Loss: 2.2545 | Actual Loss: 0.2442\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6094\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 144/1000 [00:45<04:21,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6840 | Actual Loss: 0.3488\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5293\n",
      "Epoch 144/1000: Train Loss: 0.5369, Val Loss: 0.4900\n",
      "Baseline Loss: 2.7314 | Actual Loss: 0.3418\n",
      "Baseline Loss: 2.7180 | Actual Loss: 0.5476\n",
      "Baseline Loss: 2.6739 | Actual Loss: 0.6022\n",
      "Baseline Loss: 2.7070 | Actual Loss: 0.3914\n",
      "Baseline Loss: 2.6562 | Actual Loss: 0.3397\n",
      "Baseline Loss: 2.7044 | Actual Loss: 0.7714\n",
      "Baseline Loss: 2.6673 | Actual Loss: 0.2002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 145/1000 [00:45<04:32,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6601 | Actual Loss: 0.3155\n",
      "Baseline Loss: 2.6683 | Actual Loss: 0.3793\n",
      "Baseline Loss: 2.6598 | Actual Loss: 0.4413\n",
      "Baseline Loss: 2.6378 | Actual Loss: 0.4323\n",
      "Baseline Loss: 2.6715 | Actual Loss: 0.6154\n",
      "Baseline Loss: 2.7045 | Actual Loss: 0.4411\n",
      "Baseline Loss: 2.6477 | Actual Loss: 0.3095\n",
      "Baseline Loss: 2.6553 | Actual Loss: 0.2779\n",
      "Baseline Loss: 2.2623 | Actual Loss: 0.0418\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6642\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4543\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3561\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5490\n",
      "Epoch 145/1000: Train Loss: 0.4030, Val Loss: 0.5059\n",
      "Baseline Loss: 2.6788 | Actual Loss: 0.2111\n",
      "Baseline Loss: 2.6827 | Actual Loss: 0.3868\n",
      "Baseline Loss: 2.6712 | Actual Loss: 0.4288\n",
      "Baseline Loss: 2.6819 | Actual Loss: 0.8977\n",
      "Baseline Loss: 2.6470 | Actual Loss: 0.4471\n",
      "Baseline Loss: 2.6998 | Actual Loss: 0.4563\n",
      "Baseline Loss: 2.6771 | Actual Loss: 0.2404\n",
      "Baseline Loss: 2.6741 | Actual Loss: 1.9676\n",
      "Baseline Loss: 2.6668 | Actual Loss: 0.2269\n",
      "Baseline Loss: 2.6585 | Actual Loss: 0.5011\n",
      "Baseline Loss: 2.6423 | Actual Loss: 0.7416\n",
      "Baseline Loss: 2.6626 | Actual Loss: 0.4552\n",
      "Baseline Loss: 2.6810 | Actual Loss: 1.6856\n",
      "Baseline Loss: 2.6851 | Actual Loss: 0.3001\n",
      "Baseline Loss: 2.6826 | Actual Loss: 0.4044\n",
      "Baseline Loss: 2.2888 | Actual Loss: 0.1961\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6936\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4557\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 146/1000 [00:45<04:37,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6117 | Actual Loss: 0.5879\n",
      "Epoch 146/1000: Train Loss: 0.5967, Val Loss: 0.5395\n",
      "Baseline Loss: 2.6588 | Actual Loss: 0.5662\n",
      "Baseline Loss: 2.6651 | Actual Loss: 0.4681\n",
      "Baseline Loss: 2.6877 | Actual Loss: 0.5543\n",
      "Baseline Loss: 2.6601 | Actual Loss: 0.5972\n",
      "Baseline Loss: 2.7113 | Actual Loss: 0.3201\n",
      "Baseline Loss: 2.6655 | Actual Loss: 0.2876\n",
      "Baseline Loss: 2.6883 | Actual Loss: 0.3532\n",
      "Baseline Loss: 2.6948 | Actual Loss: 0.2132\n",
      "Baseline Loss: 2.6690 | Actual Loss: 0.4712\n",
      "Baseline Loss: 2.6601 | Actual Loss: 0.2760\n",
      "Baseline Loss: 2.6810 | Actual Loss: 0.3620\n",
      "Baseline Loss: 2.7317 | Actual Loss: 0.4099\n",
      "Baseline Loss: 2.6205 | Actual Loss: 0.4219\n",
      "Baseline Loss: 2.6436 | Actual Loss: 0.4003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 147/1000 [00:46<04:22,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6598 | Actual Loss: 0.3828\n",
      "Baseline Loss: 2.2853 | Actual Loss: 0.1035\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6920\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4605\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3384\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.6526\n",
      "Epoch 147/1000: Train Loss: 0.3867, Val Loss: 0.5359\n",
      "Baseline Loss: 2.6680 | Actual Loss: 1.1355\n",
      "Baseline Loss: 2.6797 | Actual Loss: 0.1483\n",
      "Baseline Loss: 2.6586 | Actual Loss: 0.7628\n",
      "Baseline Loss: 2.6675 | Actual Loss: 0.3379\n",
      "Baseline Loss: 2.6565 | Actual Loss: 0.5040\n",
      "Baseline Loss: 2.6456 | Actual Loss: 0.2472\n",
      "Baseline Loss: 2.6899 | Actual Loss: 0.5728\n",
      "Baseline Loss: 2.7157 | Actual Loss: 0.0862\n",
      "Baseline Loss: 2.6642 | Actual Loss: 0.4802\n",
      "Baseline Loss: 2.6526 | Actual Loss: 0.3353\n",
      "Baseline Loss: 2.6549 | Actual Loss: 0.2809\n",
      "Baseline Loss: 2.7806 | Actual Loss: 0.3786\n",
      "Baseline Loss: 2.7156 | Actual Loss: 0.5330\n",
      "Baseline Loss: 2.6634 | Actual Loss: 0.2659\n",
      "Baseline Loss: 2.6680 | Actual Loss: 0.0938\n",
      "Baseline Loss: 2.2821 | Actual Loss: 1.4128\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6345\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4528\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 148/1000 [00:46<04:30,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6117 | Actual Loss: 0.5456\n",
      "Epoch 148/1000: Train Loss: 0.4734, Val Loss: 0.4981\n",
      "Baseline Loss: 2.6863 | Actual Loss: 0.5765\n",
      "Baseline Loss: 2.6406 | Actual Loss: 0.3688\n",
      "Baseline Loss: 2.7205 | Actual Loss: 0.2901\n",
      "Baseline Loss: 2.7762 | Actual Loss: 0.6215\n",
      "Baseline Loss: 2.6740 | Actual Loss: 0.1641\n",
      "Baseline Loss: 2.7111 | Actual Loss: 0.4188\n",
      "Baseline Loss: 2.6517 | Actual Loss: 1.1593\n",
      "Baseline Loss: 2.6494 | Actual Loss: 0.7318\n",
      "Baseline Loss: 2.6449 | Actual Loss: 0.6194\n",
      "Baseline Loss: 2.6221 | Actual Loss: 0.5633\n",
      "Baseline Loss: 2.6711 | Actual Loss: 0.3018\n",
      "Baseline Loss: 2.6532 | Actual Loss: 0.5315\n",
      "Baseline Loss: 2.7122 | Actual Loss: 0.2597\n",
      "Baseline Loss: 2.6619 | Actual Loss: 0.3867\n",
      "Baseline Loss: 2.7079 | Actual Loss: 0.5567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 149/1000 [00:46<04:14,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2718 | Actual Loss: 0.3026\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6271\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4591\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4048\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.6072\n",
      "Epoch 149/1000: Train Loss: 0.4908, Val Loss: 0.5245\n",
      "Baseline Loss: 2.6671 | Actual Loss: 0.7197\n",
      "Baseline Loss: 2.6725 | Actual Loss: 0.6870\n",
      "Baseline Loss: 2.6429 | Actual Loss: 0.5346\n",
      "Baseline Loss: 2.6705 | Actual Loss: 0.3877\n",
      "Baseline Loss: 2.6660 | Actual Loss: 0.3198\n",
      "Baseline Loss: 2.6622 | Actual Loss: 0.2541\n",
      "Baseline Loss: 2.6518 | Actual Loss: 1.1634\n",
      "Baseline Loss: 2.6833 | Actual Loss: 0.2164\n",
      "Baseline Loss: 2.6450 | Actual Loss: 0.6027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 150/1000 [00:47<04:21,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6481 | Actual Loss: 0.2924\n",
      "Baseline Loss: 2.6757 | Actual Loss: 0.2773\n",
      "Baseline Loss: 2.6906 | Actual Loss: 0.1794\n",
      "Baseline Loss: 2.6960 | Actual Loss: 0.2081\n",
      "Baseline Loss: 2.6862 | Actual Loss: 0.2413\n",
      "Baseline Loss: 2.7226 | Actual Loss: 0.5151\n",
      "Baseline Loss: 2.3183 | Actual Loss: 0.1650\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6954\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4727\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3015\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5800\n",
      "Epoch 150/1000: Train Loss: 0.4227, Val Loss: 0.5124\n",
      "Baseline Loss: 2.6499 | Actual Loss: 0.4499\n",
      "Baseline Loss: 2.6505 | Actual Loss: 0.2509\n",
      "Baseline Loss: 2.6568 | Actual Loss: 0.3434\n",
      "Baseline Loss: 2.7125 | Actual Loss: 0.6322\n",
      "Baseline Loss: 2.6723 | Actual Loss: 0.2198\n",
      "Baseline Loss: 2.6848 | Actual Loss: 0.1941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 151/1000 [00:47<04:12,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6880 | Actual Loss: 0.4097\n",
      "Baseline Loss: 2.7039 | Actual Loss: 0.1921\n",
      "Baseline Loss: 2.6333 | Actual Loss: 0.4461\n",
      "Baseline Loss: 2.6542 | Actual Loss: 0.5608\n",
      "Baseline Loss: 2.7223 | Actual Loss: 0.1377\n",
      "Baseline Loss: 2.6802 | Actual Loss: 0.5874\n",
      "Baseline Loss: 2.6814 | Actual Loss: 0.5575\n",
      "Baseline Loss: 2.6511 | Actual Loss: 0.5405\n",
      "Baseline Loss: 2.6441 | Actual Loss: 0.4009\n",
      "Baseline Loss: 2.2573 | Actual Loss: 0.7556\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6940\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4548\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4660\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5333\n",
      "Epoch 151/1000: Train Loss: 0.4174, Val Loss: 0.5370\n",
      "Baseline Loss: 2.7284 | Actual Loss: 0.1330\n",
      "Baseline Loss: 2.7138 | Actual Loss: 0.3141\n",
      "Baseline Loss: 2.6270 | Actual Loss: 0.7378\n",
      "Baseline Loss: 2.6560 | Actual Loss: 0.7465\n",
      "Baseline Loss: 2.6410 | Actual Loss: 0.4386\n",
      "Baseline Loss: 2.6887 | Actual Loss: 0.2943\n",
      "Baseline Loss: 2.6780 | Actual Loss: 0.1535\n",
      "Baseline Loss: 2.6622 | Actual Loss: 0.3873\n",
      "Baseline Loss: 2.6903 | Actual Loss: 1.1757\n",
      "Baseline Loss: 2.6818 | Actual Loss: 0.1902\n",
      "Baseline Loss: 2.6650 | Actual Loss: 0.3290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 152/1000 [00:47<04:24,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6486 | Actual Loss: 0.4284\n",
      "Baseline Loss: 2.6781 | Actual Loss: 0.8120\n",
      "Baseline Loss: 2.6657 | Actual Loss: 0.4697\n",
      "Baseline Loss: 2.6828 | Actual Loss: 0.3670\n",
      "Baseline Loss: 2.3020 | Actual Loss: 0.3888\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7249\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4547\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3166\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5427\n",
      "Epoch 152/1000: Train Loss: 0.4604, Val Loss: 0.5097\n",
      "Baseline Loss: 2.6838 | Actual Loss: 0.5098\n",
      "Baseline Loss: 2.6652 | Actual Loss: 0.2107\n",
      "Baseline Loss: 2.6635 | Actual Loss: 0.1308\n",
      "Baseline Loss: 2.6582 | Actual Loss: 0.4399\n",
      "Baseline Loss: 2.6999 | Actual Loss: 0.1544\n",
      "Baseline Loss: 2.6778 | Actual Loss: 0.3845\n",
      "Baseline Loss: 2.6622 | Actual Loss: 0.3812\n",
      "Baseline Loss: 2.7152 | Actual Loss: 0.2826\n",
      "Baseline Loss: 2.6688 | Actual Loss: 0.2677\n",
      "Baseline Loss: 2.6531 | Actual Loss: 0.6162\n",
      "Baseline Loss: 2.6518 | Actual Loss: 0.8022\n",
      "Baseline Loss: 2.6778 | Actual Loss: 1.2558\n",
      "Baseline Loss: 2.6551 | Actual Loss: 0.2495\n",
      "Baseline Loss: 2.7257 | Actual Loss: 0.5226\n",
      "Baseline Loss: 2.6486 | Actual Loss: 0.4876\n",
      "Baseline Loss: 2.2780 | Actual Loss: 2.1455\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6868\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 153/1000 [00:48<04:35,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6840 | Actual Loss: 0.4250\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.6930\n",
      "Epoch 153/1000: Train Loss: 0.5526, Val Loss: 0.5664\n",
      "Baseline Loss: 2.6583 | Actual Loss: 0.2995\n",
      "Baseline Loss: 2.6836 | Actual Loss: 0.6114\n",
      "Baseline Loss: 2.6744 | Actual Loss: 0.6015\n",
      "Baseline Loss: 2.6690 | Actual Loss: 0.2603\n",
      "Baseline Loss: 2.7192 | Actual Loss: 0.2304\n",
      "Baseline Loss: 2.6826 | Actual Loss: 0.5344\n",
      "Baseline Loss: 2.6528 | Actual Loss: 0.2738\n",
      "Baseline Loss: 2.6930 | Actual Loss: 0.6249\n",
      "Baseline Loss: 2.6591 | Actual Loss: 0.8253\n",
      "Baseline Loss: 2.6626 | Actual Loss: 0.5376\n",
      "Baseline Loss: 2.6739 | Actual Loss: 0.2594\n",
      "Baseline Loss: 2.6553 | Actual Loss: 0.5751\n",
      "Baseline Loss: 2.6719 | Actual Loss: 0.3454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 154/1000 [00:48<04:23,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6825 | Actual Loss: 0.4739\n",
      "Baseline Loss: 2.6490 | Actual Loss: 0.3927\n",
      "Baseline Loss: 2.2383 | Actual Loss: 0.1995\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6919\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4732\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4114\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5469\n",
      "Epoch 154/1000: Train Loss: 0.4403, Val Loss: 0.5309\n",
      "Baseline Loss: 2.7058 | Actual Loss: 0.8011\n",
      "Baseline Loss: 2.6680 | Actual Loss: 0.4043\n",
      "Baseline Loss: 2.6800 | Actual Loss: 0.4683\n",
      "Baseline Loss: 2.6926 | Actual Loss: 1.0651\n",
      "Baseline Loss: 2.6712 | Actual Loss: 0.6963\n",
      "Baseline Loss: 2.6899 | Actual Loss: 0.1524\n",
      "Baseline Loss: 2.6725 | Actual Loss: 0.2725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 155/1000 [00:48<04:30,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6759 | Actual Loss: 0.1791\n",
      "Baseline Loss: 2.6839 | Actual Loss: 0.5038\n",
      "Baseline Loss: 2.6783 | Actual Loss: 0.4566\n",
      "Baseline Loss: 2.6811 | Actual Loss: 0.7065\n",
      "Baseline Loss: 2.6492 | Actual Loss: 0.2928\n",
      "Baseline Loss: 2.6928 | Actual Loss: 0.4796\n",
      "Baseline Loss: 2.6822 | Actual Loss: 0.3547\n",
      "Baseline Loss: 2.6421 | Actual Loss: 0.2469\n",
      "Baseline Loss: 2.2844 | Actual Loss: 0.8279\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6911\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4688\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3000\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.6363\n",
      "Epoch 155/1000: Train Loss: 0.4943, Val Loss: 0.5240\n",
      "Baseline Loss: 2.6761 | Actual Loss: 0.2699\n",
      "Baseline Loss: 2.6722 | Actual Loss: 0.5955\n",
      "Baseline Loss: 2.6452 | Actual Loss: 0.4786\n",
      "Baseline Loss: 2.6582 | Actual Loss: 2.0742\n",
      "Baseline Loss: 2.6639 | Actual Loss: 1.2556\n",
      "Baseline Loss: 2.6659 | Actual Loss: 0.1496\n",
      "Baseline Loss: 2.6929 | Actual Loss: 0.4779\n",
      "Baseline Loss: 2.6814 | Actual Loss: 0.2959\n",
      "Baseline Loss: 2.6768 | Actual Loss: 0.2258\n",
      "Baseline Loss: 2.7081 | Actual Loss: 0.6882\n",
      "Baseline Loss: 2.6946 | Actual Loss: 0.3205\n",
      "Baseline Loss: 2.7052 | Actual Loss: 0.3550\n",
      "Baseline Loss: 2.6788 | Actual Loss: 0.4004\n",
      "Baseline Loss: 2.6424 | Actual Loss: 0.4269\n",
      "Baseline Loss: 2.6697 | Actual Loss: 0.6520\n",
      "Baseline Loss: 2.2897 | Actual Loss: 0.0861\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 156/1000 [00:49<04:37,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6644 | Actual Loss: 0.4790\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4183\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5457\n",
      "Epoch 156/1000: Train Loss: 0.5470, Val Loss: 0.5216\n",
      "Baseline Loss: 2.6961 | Actual Loss: 0.4113\n",
      "Baseline Loss: 2.6963 | Actual Loss: 0.2445\n",
      "Baseline Loss: 2.6759 | Actual Loss: 0.4578\n",
      "Baseline Loss: 2.6399 | Actual Loss: 0.3972\n",
      "Baseline Loss: 2.6719 | Actual Loss: 0.9554\n",
      "Baseline Loss: 2.6523 | Actual Loss: 0.9724\n",
      "Baseline Loss: 2.6806 | Actual Loss: 0.1969\n",
      "Baseline Loss: 2.6539 | Actual Loss: 0.4248\n",
      "Baseline Loss: 2.6423 | Actual Loss: 0.2707\n",
      "Baseline Loss: 2.6799 | Actual Loss: 0.4519\n",
      "Baseline Loss: 2.6946 | Actual Loss: 0.6070\n",
      "Baseline Loss: 2.6636 | Actual Loss: 0.2000\n",
      "Baseline Loss: 2.7323 | Actual Loss: 0.3886\n",
      "Baseline Loss: 2.6924 | Actual Loss: 0.1245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 157/1000 [00:49<04:19,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6752 | Actual Loss: 0.2469\n",
      "Baseline Loss: 2.2832 | Actual Loss: 0.5432\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6224\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4764\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4211\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5041\n",
      "Epoch 157/1000: Train Loss: 0.4308, Val Loss: 0.5060\n",
      "Baseline Loss: 2.7194 | Actual Loss: 0.3803\n",
      "Baseline Loss: 2.7180 | Actual Loss: 0.3822\n",
      "Baseline Loss: 2.6680 | Actual Loss: 0.7436\n",
      "Baseline Loss: 2.6297 | Actual Loss: 0.4451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 158/1000 [00:49<04:26,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6679 | Actual Loss: 0.4700\n",
      "Baseline Loss: 2.6928 | Actual Loss: 0.3880\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4396\n",
      "Baseline Loss: 2.6682 | Actual Loss: 0.3896\n",
      "Baseline Loss: 2.6891 | Actual Loss: 0.3947\n",
      "Baseline Loss: 2.7026 | Actual Loss: 0.6692\n",
      "Baseline Loss: 2.6402 | Actual Loss: 0.5120\n",
      "Baseline Loss: 2.6436 | Actual Loss: 0.4436\n",
      "Baseline Loss: 2.6515 | Actual Loss: 0.4232\n",
      "Baseline Loss: 2.6802 | Actual Loss: 1.1806\n",
      "Baseline Loss: 2.6780 | Actual Loss: 0.1273\n",
      "Baseline Loss: 2.2056 | Actual Loss: 0.7404\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6637\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4572\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4912\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5058\n",
      "Epoch 158/1000: Train Loss: 0.5081, Val Loss: 0.5295\n",
      "Baseline Loss: 2.6696 | Actual Loss: 0.3272\n",
      "Baseline Loss: 2.6870 | Actual Loss: 0.4252\n",
      "Baseline Loss: 2.6500 | Actual Loss: 0.5604\n",
      "Baseline Loss: 2.6616 | Actual Loss: 0.3188\n",
      "Baseline Loss: 2.6429 | Actual Loss: 0.2175\n",
      "Baseline Loss: 2.6767 | Actual Loss: 0.4414\n",
      "Baseline Loss: 2.6710 | Actual Loss: 0.2413\n",
      "Baseline Loss: 2.6821 | Actual Loss: 0.5360\n",
      "Baseline Loss: 2.6551 | Actual Loss: 0.3822\n",
      "Baseline Loss: 2.6977 | Actual Loss: 1.7033\n",
      "Baseline Loss: 2.7286 | Actual Loss: 0.5583\n",
      "Baseline Loss: 2.6898 | Actual Loss: 0.3877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 159/1000 [00:49<04:33,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6948 | Actual Loss: 0.3903\n",
      "Baseline Loss: 2.6877 | Actual Loss: 0.4144\n",
      "Baseline Loss: 2.7076 | Actual Loss: 0.9699\n",
      "Baseline Loss: 2.2477 | Actual Loss: 0.1077\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6497\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4773\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4175\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5471\n",
      "Epoch 159/1000: Train Loss: 0.4989, Val Loss: 0.5229\n",
      "Baseline Loss: 2.6289 | Actual Loss: 0.4072\n",
      "Baseline Loss: 2.6637 | Actual Loss: 0.3939\n",
      "Baseline Loss: 2.6935 | Actual Loss: 0.2688\n",
      "Baseline Loss: 2.7034 | Actual Loss: 0.6854\n",
      "Baseline Loss: 2.6993 | Actual Loss: 0.3619\n",
      "Baseline Loss: 2.6847 | Actual Loss: 0.1593\n",
      "Baseline Loss: 2.6762 | Actual Loss: 0.5952\n",
      "Baseline Loss: 2.6766 | Actual Loss: 0.2384\n",
      "Baseline Loss: 2.6955 | Actual Loss: 0.3536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 160/1000 [00:50<04:16,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6506 | Actual Loss: 0.6173\n",
      "Baseline Loss: 2.6555 | Actual Loss: 1.2561\n",
      "Baseline Loss: 2.6838 | Actual Loss: 1.2302\n",
      "Baseline Loss: 2.6756 | Actual Loss: 0.5555\n",
      "Baseline Loss: 2.6987 | Actual Loss: 0.3825\n",
      "Baseline Loss: 2.6634 | Actual Loss: 0.9430\n",
      "Baseline Loss: 2.2658 | Actual Loss: 0.1411\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6646\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4773\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3877\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5292\n",
      "Epoch 160/1000: Train Loss: 0.5368, Val Loss: 0.5147\n",
      "Baseline Loss: 2.6487 | Actual Loss: 0.5022\n",
      "Baseline Loss: 2.6382 | Actual Loss: 0.6133\n",
      "Baseline Loss: 2.6903 | Actual Loss: 0.4997\n",
      "Baseline Loss: 2.6571 | Actual Loss: 0.4667\n",
      "Baseline Loss: 2.6682 | Actual Loss: 0.2273\n",
      "Baseline Loss: 2.7312 | Actual Loss: 0.3867\n",
      "Baseline Loss: 2.6615 | Actual Loss: 2.4638\n",
      "Baseline Loss: 2.7097 | Actual Loss: 0.4401\n",
      "Baseline Loss: 2.7047 | Actual Loss: 0.5586\n",
      "Baseline Loss: 2.6971 | Actual Loss: 0.3371\n",
      "Baseline Loss: 2.6727 | Actual Loss: 0.6559\n",
      "Baseline Loss: 2.6539 | Actual Loss: 1.2335\n",
      "Baseline Loss: 2.6925 | Actual Loss: 0.3426\n",
      "Baseline Loss: 2.6683 | Actual Loss: 0.5603\n",
      "Baseline Loss: 2.7077 | Actual Loss: 0.1466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 161/1000 [00:50<04:22,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2675 | Actual Loss: 0.1206\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6478\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4540\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4259\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5653\n",
      "Epoch 161/1000: Train Loss: 0.5972, Val Loss: 0.5232\n",
      "Baseline Loss: 2.6782 | Actual Loss: 0.4077\n",
      "Baseline Loss: 2.6978 | Actual Loss: 0.6647\n",
      "Baseline Loss: 2.6883 | Actual Loss: 0.2429\n",
      "Baseline Loss: 2.6833 | Actual Loss: 0.4128\n",
      "Baseline Loss: 2.6631 | Actual Loss: 0.4014\n",
      "Baseline Loss: 2.6355 | Actual Loss: 0.7295\n",
      "Baseline Loss: 2.6972 | Actual Loss: 0.3725\n",
      "Baseline Loss: 2.6592 | Actual Loss: 0.2937\n",
      "Baseline Loss: 2.6419 | Actual Loss: 1.0753\n",
      "Baseline Loss: 2.6670 | Actual Loss: 0.1676\n",
      "Baseline Loss: 2.6593 | Actual Loss: 0.3768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 162/1000 [00:50<04:30,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6777 | Actual Loss: 0.4235\n",
      "Baseline Loss: 2.6678 | Actual Loss: 0.3375\n",
      "Baseline Loss: 2.6595 | Actual Loss: 0.3625\n",
      "Baseline Loss: 2.7437 | Actual Loss: 0.4689\n",
      "Baseline Loss: 2.2429 | Actual Loss: 0.0592\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6789\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4619\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4084\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5806\n",
      "Epoch 162/1000: Train Loss: 0.4248, Val Loss: 0.5324\n",
      "Baseline Loss: 2.6573 | Actual Loss: 0.6331\n",
      "Baseline Loss: 2.6650 | Actual Loss: 0.4408\n",
      "Baseline Loss: 2.7100 | Actual Loss: 0.6139\n",
      "Baseline Loss: 2.7171 | Actual Loss: 0.1012\n",
      "Baseline Loss: 2.6524 | Actual Loss: 0.6006\n",
      "Baseline Loss: 2.7018 | Actual Loss: 0.2302\n",
      "Baseline Loss: 2.6408 | Actual Loss: 0.6659\n",
      "Baseline Loss: 2.6673 | Actual Loss: 0.2217\n",
      "Baseline Loss: 2.6730 | Actual Loss: 0.3710\n",
      "Baseline Loss: 2.6745 | Actual Loss: 0.4141\n",
      "Baseline Loss: 2.6868 | Actual Loss: 0.6318\n",
      "Baseline Loss: 2.6922 | Actual Loss: 0.5732\n",
      "Baseline Loss: 2.6557 | Actual Loss: 0.2414\n",
      "Baseline Loss: 2.6617 | Actual Loss: 0.3981\n",
      "Baseline Loss: 2.6538 | Actual Loss: 0.3514\n",
      "Baseline Loss: 2.2325 | Actual Loss: 1.3790\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6741\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▋        | 163/1000 [00:51<04:14,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6840 | Actual Loss: 0.4814\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.6144\n",
      "Epoch 163/1000: Train Loss: 0.4917, Val Loss: 0.5609\n",
      "Baseline Loss: 2.6773 | Actual Loss: 0.4134\n",
      "Baseline Loss: 2.6780 | Actual Loss: 0.2447\n",
      "Baseline Loss: 2.6849 | Actual Loss: 0.3680\n",
      "Baseline Loss: 2.6632 | Actual Loss: 0.2812\n",
      "Baseline Loss: 2.6699 | Actual Loss: 0.3609\n",
      "Baseline Loss: 2.6779 | Actual Loss: 0.5178\n",
      "Baseline Loss: 2.6900 | Actual Loss: 0.8866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▋        | 164/1000 [00:51<04:21,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6410 | Actual Loss: 1.2993\n",
      "Baseline Loss: 2.7146 | Actual Loss: 0.5748\n",
      "Baseline Loss: 2.6938 | Actual Loss: 0.4855\n",
      "Baseline Loss: 2.6726 | Actual Loss: 0.2893\n",
      "Baseline Loss: 2.7082 | Actual Loss: 0.2800\n",
      "Baseline Loss: 2.6898 | Actual Loss: 0.6753\n",
      "Baseline Loss: 2.6492 | Actual Loss: 0.4875\n",
      "Baseline Loss: 2.6790 | Actual Loss: 0.3101\n",
      "Baseline Loss: 2.3044 | Actual Loss: 0.1212\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7303\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4570\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4200\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5884\n",
      "Epoch 164/1000: Train Loss: 0.4747, Val Loss: 0.5489\n",
      "Baseline Loss: 2.6562 | Actual Loss: 0.5177\n",
      "Baseline Loss: 2.6471 | Actual Loss: 0.2839\n",
      "Baseline Loss: 2.7162 | Actual Loss: 0.2682\n",
      "Baseline Loss: 2.6653 | Actual Loss: 0.1430\n",
      "Baseline Loss: 2.6688 | Actual Loss: 0.2847\n",
      "Baseline Loss: 2.6595 | Actual Loss: 0.2591\n",
      "Baseline Loss: 2.6881 | Actual Loss: 0.4983\n",
      "Baseline Loss: 2.6723 | Actual Loss: 0.4393\n",
      "Baseline Loss: 2.6761 | Actual Loss: 0.4584\n",
      "Baseline Loss: 2.7088 | Actual Loss: 0.6084\n",
      "Baseline Loss: 2.6681 | Actual Loss: 0.3811\n",
      "Baseline Loss: 2.6475 | Actual Loss: 0.2095\n",
      "Baseline Loss: 2.7054 | Actual Loss: 0.4286\n",
      "Baseline Loss: 2.6480 | Actual Loss: 0.6482\n",
      "Baseline Loss: 2.6806 | Actual Loss: 0.4147\n",
      "Baseline Loss: 2.2517 | Actual Loss: 1.3799\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6557\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4808\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▋        | 165/1000 [00:51<04:29,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6117 | Actual Loss: 0.5060\n",
      "Epoch 165/1000: Train Loss: 0.4514, Val Loss: 0.5163\n",
      "Baseline Loss: 2.6437 | Actual Loss: 0.4203\n",
      "Baseline Loss: 2.6368 | Actual Loss: 0.5226\n",
      "Baseline Loss: 2.6753 | Actual Loss: 0.9587\n",
      "Baseline Loss: 2.7401 | Actual Loss: 0.2948\n",
      "Baseline Loss: 2.6688 | Actual Loss: 0.8833\n",
      "Baseline Loss: 2.6685 | Actual Loss: 0.3535\n",
      "Baseline Loss: 2.6533 | Actual Loss: 0.2922\n",
      "Baseline Loss: 2.6879 | Actual Loss: 0.6091\n",
      "Baseline Loss: 2.6475 | Actual Loss: 0.4422\n",
      "Baseline Loss: 2.6612 | Actual Loss: 0.2464\n",
      "Baseline Loss: 2.6842 | Actual Loss: 0.4622\n",
      "Baseline Loss: 2.6753 | Actual Loss: 0.5452\n",
      "Baseline Loss: 2.6854 | Actual Loss: 0.4569\n",
      "Baseline Loss: 2.6531 | Actual Loss: 0.2311\n",
      "Baseline Loss: 2.6898 | Actual Loss: 0.5255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 166/1000 [00:52<04:13,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.3317 | Actual Loss: 0.6733\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6145\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4816\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4240\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5157\n",
      "Epoch 166/1000: Train Loss: 0.4948, Val Loss: 0.5089\n",
      "Baseline Loss: 2.6800 | Actual Loss: 0.3505\n",
      "Baseline Loss: 2.6636 | Actual Loss: 0.5338\n",
      "Baseline Loss: 2.6788 | Actual Loss: 0.3326\n",
      "Baseline Loss: 2.6597 | Actual Loss: 0.2583\n",
      "Baseline Loss: 2.6730 | Actual Loss: 0.6089\n",
      "Baseline Loss: 2.6714 | Actual Loss: 0.3810\n",
      "Baseline Loss: 2.6763 | Actual Loss: 0.7040\n",
      "Baseline Loss: 2.6668 | Actual Loss: 0.3281\n",
      "Baseline Loss: 2.6911 | Actual Loss: 0.2696\n",
      "Baseline Loss: 2.6858 | Actual Loss: 0.5237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 167/1000 [00:52<04:23,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6451 | Actual Loss: 0.2174\n",
      "Baseline Loss: 2.6716 | Actual Loss: 0.3001\n",
      "Baseline Loss: 2.6767 | Actual Loss: 0.1780\n",
      "Baseline Loss: 2.7040 | Actual Loss: 0.3180\n",
      "Baseline Loss: 2.6681 | Actual Loss: 0.3115\n",
      "Baseline Loss: 2.2618 | Actual Loss: 0.2392\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6308\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4628\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3367\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5780\n",
      "Epoch 167/1000: Train Loss: 0.3659, Val Loss: 0.5021\n",
      "Baseline Loss: 2.6659 | Actual Loss: 0.4011\n",
      "Baseline Loss: 2.6829 | Actual Loss: 1.0170\n",
      "Baseline Loss: 2.6626 | Actual Loss: 0.3822\n",
      "Baseline Loss: 2.6713 | Actual Loss: 0.4134\n",
      "Baseline Loss: 2.6458 | Actual Loss: 0.6355\n",
      "Baseline Loss: 2.6233 | Actual Loss: 0.2138\n",
      "Baseline Loss: 2.6573 | Actual Loss: 0.4414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 168/1000 [00:52<04:10,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6546 | Actual Loss: 0.3478\n",
      "Baseline Loss: 2.7263 | Actual Loss: 0.8622\n",
      "Baseline Loss: 2.6842 | Actual Loss: 0.1084\n",
      "Baseline Loss: 2.7044 | Actual Loss: 0.4188\n",
      "Baseline Loss: 2.6707 | Actual Loss: 0.2053\n",
      "Baseline Loss: 2.6924 | Actual Loss: 0.6246\n",
      "Baseline Loss: 2.6952 | Actual Loss: 0.3796\n",
      "Baseline Loss: 2.6960 | Actual Loss: 0.4065\n",
      "Baseline Loss: 2.2826 | Actual Loss: 0.3042\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.5912\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4601\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3375\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.4988\n",
      "Epoch 168/1000: Train Loss: 0.4476, Val Loss: 0.4719\n",
      "New best validation loss: 0.4719\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.2630\n",
      "Baseline Loss: 2.6819 | Actual Loss: 0.3499\n",
      "Baseline Loss: 2.7228 | Actual Loss: 0.5766\n",
      "Baseline Loss: 2.6533 | Actual Loss: 0.4744\n",
      "Baseline Loss: 2.6793 | Actual Loss: 0.2662\n",
      "Baseline Loss: 2.6841 | Actual Loss: 0.2357\n",
      "Baseline Loss: 2.6936 | Actual Loss: 0.2024\n",
      "Baseline Loss: 2.6515 | Actual Loss: 0.8666\n",
      "Baseline Loss: 2.6610 | Actual Loss: 0.4658\n",
      "Baseline Loss: 2.7255 | Actual Loss: 0.6141\n",
      "Baseline Loss: 2.6625 | Actual Loss: 0.4983\n",
      "Baseline Loss: 2.6553 | Actual Loss: 0.1731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 169/1000 [00:53<04:14,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6704 | Actual Loss: 0.3924\n",
      "Baseline Loss: 2.6849 | Actual Loss: 0.1801\n",
      "Baseline Loss: 2.6985 | Actual Loss: 0.2354\n",
      "Baseline Loss: 2.3190 | Actual Loss: 0.1076\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6432\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4613\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4044\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5546\n",
      "Epoch 169/1000: Train Loss: 0.3688, Val Loss: 0.5159\n",
      "Baseline Loss: 2.6912 | Actual Loss: 0.3378\n",
      "Baseline Loss: 2.6736 | Actual Loss: 0.5099\n",
      "Baseline Loss: 2.6727 | Actual Loss: 0.2826\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.5129\n",
      "Baseline Loss: 2.7045 | Actual Loss: 0.3056\n",
      "Baseline Loss: 2.6691 | Actual Loss: 0.2697\n",
      "Baseline Loss: 2.6646 | Actual Loss: 0.4744\n",
      "Baseline Loss: 2.6817 | Actual Loss: 0.4153\n",
      "Baseline Loss: 2.6660 | Actual Loss: 0.3770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 170/1000 [00:53<04:07,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6708 | Actual Loss: 2.1183\n",
      "Baseline Loss: 2.6387 | Actual Loss: 0.2487\n",
      "Baseline Loss: 2.6894 | Actual Loss: 0.6079\n",
      "Baseline Loss: 2.6750 | Actual Loss: 0.5341\n",
      "Baseline Loss: 2.6710 | Actual Loss: 0.5030\n",
      "Baseline Loss: 2.6518 | Actual Loss: 0.1617\n",
      "Baseline Loss: 2.2564 | Actual Loss: 0.9501\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7458\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4570\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3363\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5433\n",
      "Epoch 170/1000: Train Loss: 0.5381, Val Loss: 0.5206\n",
      "Baseline Loss: 2.6475 | Actual Loss: 0.2958\n",
      "Baseline Loss: 2.6255 | Actual Loss: 0.4048\n",
      "Baseline Loss: 2.7375 | Actual Loss: 0.3468\n",
      "Baseline Loss: 2.6736 | Actual Loss: 0.6155\n",
      "Baseline Loss: 2.6394 | Actual Loss: 0.3819\n",
      "Baseline Loss: 2.6798 | Actual Loss: 0.6140\n",
      "Baseline Loss: 2.6808 | Actual Loss: 0.3513\n",
      "Baseline Loss: 2.6663 | Actual Loss: 1.7581\n",
      "Baseline Loss: 2.6682 | Actual Loss: 0.3623\n",
      "Baseline Loss: 2.7141 | Actual Loss: 0.2947\n",
      "Baseline Loss: 2.6618 | Actual Loss: 0.5315\n",
      "Baseline Loss: 2.6632 | Actual Loss: 0.4658\n",
      "Baseline Loss: 2.7412 | Actual Loss: 0.6230\n",
      "Baseline Loss: 2.6620 | Actual Loss: 0.4033\n",
      "Baseline Loss: 2.6444 | Actual Loss: 0.3293\n",
      "Baseline Loss: 2.2868 | Actual Loss: 0.3914\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6649\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 171/1000 [00:53<04:20,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6840 | Actual Loss: 0.3595\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5592\n",
      "Epoch 171/1000: Train Loss: 0.5106, Val Loss: 0.5108\n",
      "Baseline Loss: 2.6446 | Actual Loss: 0.3385\n",
      "Baseline Loss: 2.6749 | Actual Loss: 0.7673\n",
      "Baseline Loss: 2.6491 | Actual Loss: 0.4125\n",
      "Baseline Loss: 2.7145 | Actual Loss: 0.3535\n",
      "Baseline Loss: 2.6839 | Actual Loss: 0.2325\n",
      "Baseline Loss: 2.6887 | Actual Loss: 0.5155\n",
      "Baseline Loss: 2.6449 | Actual Loss: 0.3954\n",
      "Baseline Loss: 2.6878 | Actual Loss: 0.4817\n",
      "Baseline Loss: 2.6970 | Actual Loss: 0.2539\n",
      "Baseline Loss: 2.6746 | Actual Loss: 0.7155\n",
      "Baseline Loss: 2.6643 | Actual Loss: 0.2268\n",
      "Baseline Loss: 2.6713 | Actual Loss: 0.4885\n",
      "Baseline Loss: 2.6608 | Actual Loss: 0.3869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 172/1000 [00:54<04:30,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6761 | Actual Loss: 0.5159\n",
      "Baseline Loss: 2.6880 | Actual Loss: 0.3455\n",
      "Baseline Loss: 2.2643 | Actual Loss: 0.4279\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6720\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4595\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3905\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5693\n",
      "Epoch 172/1000: Train Loss: 0.4286, Val Loss: 0.5228\n",
      "Baseline Loss: 2.6969 | Actual Loss: 0.2634\n",
      "Baseline Loss: 2.6549 | Actual Loss: 0.6020\n",
      "Baseline Loss: 2.6745 | Actual Loss: 0.6242\n",
      "Baseline Loss: 2.6600 | Actual Loss: 0.6311\n",
      "Baseline Loss: 2.6503 | Actual Loss: 0.4908\n",
      "Baseline Loss: 2.6539 | Actual Loss: 0.5556\n",
      "Baseline Loss: 2.6531 | Actual Loss: 0.2592\n",
      "Baseline Loss: 2.6410 | Actual Loss: 0.3511\n",
      "Baseline Loss: 2.7171 | Actual Loss: 0.3296\n",
      "Baseline Loss: 2.6960 | Actual Loss: 0.4998\n",
      "Baseline Loss: 2.6367 | Actual Loss: 0.3081\n",
      "Baseline Loss: 2.6915 | Actual Loss: 0.7092\n",
      "Baseline Loss: 2.6720 | Actual Loss: 0.2992\n",
      "Baseline Loss: 2.6783 | Actual Loss: 0.3208\n",
      "Baseline Loss: 2.7001 | Actual Loss: 0.3144\n",
      "Baseline Loss: 2.3594 | Actual Loss: 0.0556\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 173/1000 [00:54<04:17,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6644 | Actual Loss: 0.4635\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4043\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5311\n",
      "Epoch 173/1000: Train Loss: 0.4134, Val Loss: 0.5070\n",
      "Baseline Loss: 2.6866 | Actual Loss: 0.6586\n",
      "Baseline Loss: 2.7063 | Actual Loss: 0.4333\n",
      "Baseline Loss: 2.6311 | Actual Loss: 0.4519\n",
      "Baseline Loss: 2.6809 | Actual Loss: 2.1866\n",
      "Baseline Loss: 2.6851 | Actual Loss: 0.4286\n",
      "Baseline Loss: 2.7127 | Actual Loss: 0.2582\n",
      "Baseline Loss: 2.6845 | Actual Loss: 0.4675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 174/1000 [00:54<04:22,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6391 | Actual Loss: 0.2437\n",
      "Baseline Loss: 2.6921 | Actual Loss: 0.3458\n",
      "Baseline Loss: 2.6952 | Actual Loss: 0.5334\n",
      "Baseline Loss: 2.6297 | Actual Loss: 0.6695\n",
      "Baseline Loss: 2.6668 | Actual Loss: 0.3985\n",
      "Baseline Loss: 2.6734 | Actual Loss: 0.3329\n",
      "Baseline Loss: 2.6625 | Actual Loss: 0.4068\n",
      "Baseline Loss: 2.7165 | Actual Loss: 0.9206\n",
      "Baseline Loss: 2.2132 | Actual Loss: 0.4101\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6504\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4694\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3970\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5312\n",
      "Epoch 174/1000: Train Loss: 0.5716, Val Loss: 0.5120\n",
      "Baseline Loss: 2.6924 | Actual Loss: 0.1418\n",
      "Baseline Loss: 2.6947 | Actual Loss: 0.1918\n",
      "Baseline Loss: 2.6218 | Actual Loss: 0.4994\n",
      "Baseline Loss: 2.6726 | Actual Loss: 0.4556\n",
      "Baseline Loss: 2.7100 | Actual Loss: 0.3590\n",
      "Baseline Loss: 2.6897 | Actual Loss: 1.2512\n",
      "Baseline Loss: 2.6363 | Actual Loss: 0.3644\n",
      "Baseline Loss: 2.6437 | Actual Loss: 1.0789\n",
      "Baseline Loss: 2.6506 | Actual Loss: 0.3798\n",
      "Baseline Loss: 2.7134 | Actual Loss: 0.8330\n",
      "Baseline Loss: 2.6839 | Actual Loss: 0.2981\n",
      "Baseline Loss: 2.6609 | Actual Loss: 0.5450\n",
      "Baseline Loss: 2.7051 | Actual Loss: 0.2229\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.1532\n",
      "Baseline Loss: 2.6609 | Actual Loss: 0.4236\n",
      "Baseline Loss: 2.2359 | Actual Loss: 0.1286\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 175/1000 [00:54<04:28,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6644 | Actual Loss: 0.4684\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3863\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.4883\n",
      "Epoch 175/1000: Train Loss: 0.4579, Val Loss: 0.5074\n",
      "Baseline Loss: 2.6864 | Actual Loss: 0.2587\n",
      "Baseline Loss: 2.6350 | Actual Loss: 0.4904\n",
      "Baseline Loss: 2.6533 | Actual Loss: 1.0320\n",
      "Baseline Loss: 2.6880 | Actual Loss: 0.5054\n",
      "Baseline Loss: 2.6479 | Actual Loss: 0.4133\n",
      "Baseline Loss: 2.6405 | Actual Loss: 0.3357\n",
      "Baseline Loss: 2.6919 | Actual Loss: 0.3593\n",
      "Baseline Loss: 2.7110 | Actual Loss: 0.3023\n",
      "Baseline Loss: 2.7041 | Actual Loss: 0.3562\n",
      "Baseline Loss: 2.6410 | Actual Loss: 0.3842\n",
      "Baseline Loss: 2.6954 | Actual Loss: 0.3850\n",
      "Baseline Loss: 2.6361 | Actual Loss: 0.4270\n",
      "Baseline Loss: 2.7146 | Actual Loss: 0.3746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 176/1000 [00:55<04:15,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6883 | Actual Loss: 0.6397\n",
      "Baseline Loss: 2.6848 | Actual Loss: 1.1912\n",
      "Baseline Loss: 2.3735 | Actual Loss: 0.1673\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6542\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4650\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4301\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5348\n",
      "Epoch 176/1000: Train Loss: 0.4764, Val Loss: 0.5210\n",
      "Baseline Loss: 2.6836 | Actual Loss: 0.3648\n",
      "Baseline Loss: 2.6937 | Actual Loss: 0.4974\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 177/1000 [00:55<04:19,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6443 | Actual Loss: 0.4091\n",
      "Baseline Loss: 2.7085 | Actual Loss: 0.4486\n",
      "Baseline Loss: 2.6614 | Actual Loss: 2.3141\n",
      "Baseline Loss: 2.6877 | Actual Loss: 0.0794\n",
      "Baseline Loss: 2.6922 | Actual Loss: 0.6052\n",
      "Baseline Loss: 2.6706 | Actual Loss: 0.4962\n",
      "Baseline Loss: 2.6388 | Actual Loss: 0.8295\n",
      "Baseline Loss: 2.6942 | Actual Loss: 0.2579\n",
      "Baseline Loss: 2.6540 | Actual Loss: 0.1213\n",
      "Baseline Loss: 2.6624 | Actual Loss: 0.2914\n",
      "Baseline Loss: 2.6249 | Actual Loss: 0.6225\n",
      "Baseline Loss: 2.7120 | Actual Loss: 0.5125\n",
      "Baseline Loss: 2.3217 | Actual Loss: 0.4131\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6440\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4605\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4058\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5072\n",
      "Epoch 177/1000: Train Loss: 0.5374, Val Loss: 0.5044\n",
      "Baseline Loss: 2.6739 | Actual Loss: 0.3603\n",
      "Baseline Loss: 2.6608 | Actual Loss: 0.2213\n",
      "Baseline Loss: 2.6740 | Actual Loss: 0.1862\n",
      "Baseline Loss: 2.6398 | Actual Loss: 0.3987\n",
      "Baseline Loss: 2.6562 | Actual Loss: 0.3303\n",
      "Baseline Loss: 2.6427 | Actual Loss: 0.3954\n",
      "Baseline Loss: 2.6934 | Actual Loss: 0.4998\n",
      "Baseline Loss: 2.7058 | Actual Loss: 1.4560\n",
      "Baseline Loss: 2.7047 | Actual Loss: 0.2759\n",
      "Baseline Loss: 2.6765 | Actual Loss: 0.4074\n",
      "Baseline Loss: 2.6914 | Actual Loss: 0.4862\n",
      "Baseline Loss: 2.6749 | Actual Loss: 0.6010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 178/1000 [00:55<04:25,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7071 | Actual Loss: 0.4738\n",
      "Baseline Loss: 2.6516 | Actual Loss: 0.3127\n",
      "Baseline Loss: 2.6595 | Actual Loss: 0.4254\n",
      "Baseline Loss: 2.2108 | Actual Loss: 0.3403\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6329\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4627\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.2830\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5519\n",
      "Epoch 178/1000: Train Loss: 0.4482, Val Loss: 0.4826\n",
      "Baseline Loss: 2.6545 | Actual Loss: 0.4632\n",
      "Baseline Loss: 2.6545 | Actual Loss: 1.0714\n",
      "Baseline Loss: 2.6985 | Actual Loss: 0.3212\n",
      "Baseline Loss: 2.6903 | Actual Loss: 0.4028\n",
      "Baseline Loss: 2.6695 | Actual Loss: 0.4315\n",
      "Baseline Loss: 2.6401 | Actual Loss: 0.1040\n",
      "Baseline Loss: 2.6621 | Actual Loss: 0.2535\n",
      "Baseline Loss: 2.7119 | Actual Loss: 2.1009\n",
      "Baseline Loss: 2.6801 | Actual Loss: 0.2383\n",
      "Baseline Loss: 2.6656 | Actual Loss: 0.5515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 179/1000 [00:56<04:10,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6980 | Actual Loss: 0.3379\n",
      "Baseline Loss: 2.6717 | Actual Loss: 1.0936\n",
      "Baseline Loss: 2.6718 | Actual Loss: 0.6532\n",
      "Baseline Loss: 2.6792 | Actual Loss: 1.3594\n",
      "Baseline Loss: 2.6906 | Actual Loss: 0.1919\n",
      "Baseline Loss: 2.2108 | Actual Loss: 0.3240\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6919\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4714\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4956\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.4864\n",
      "Epoch 179/1000: Train Loss: 0.6186, Val Loss: 0.5363\n",
      "Baseline Loss: 2.6759 | Actual Loss: 0.4724\n",
      "Baseline Loss: 2.7154 | Actual Loss: 0.2764\n",
      "Baseline Loss: 2.6771 | Actual Loss: 0.6092\n",
      "Baseline Loss: 2.6456 | Actual Loss: 0.8764\n",
      "Baseline Loss: 2.6835 | Actual Loss: 0.3584\n",
      "Baseline Loss: 2.6892 | Actual Loss: 0.3897\n",
      "Baseline Loss: 2.6806 | Actual Loss: 0.2199\n",
      "Baseline Loss: 2.6926 | Actual Loss: 0.4916\n",
      "Baseline Loss: 2.6610 | Actual Loss: 0.3460\n",
      "Baseline Loss: 2.6790 | Actual Loss: 0.4395\n",
      "Baseline Loss: 2.6656 | Actual Loss: 0.3330\n",
      "Baseline Loss: 2.6689 | Actual Loss: 0.4890\n",
      "Baseline Loss: 2.6892 | Actual Loss: 0.8386\n",
      "Baseline Loss: 2.6931 | Actual Loss: 0.3214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 180/1000 [00:56<04:19,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6752 | Actual Loss: 0.4643\n",
      "Baseline Loss: 2.2900 | Actual Loss: 0.0987\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6172\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4618\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4679\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5697\n",
      "Epoch 180/1000: Train Loss: 0.4390, Val Loss: 0.5291\n",
      "Baseline Loss: 2.7193 | Actual Loss: 0.4818\n",
      "Baseline Loss: 2.6587 | Actual Loss: 2.0831\n",
      "Baseline Loss: 2.7021 | Actual Loss: 0.2277\n",
      "Baseline Loss: 2.6656 | Actual Loss: 0.4287\n",
      "Baseline Loss: 2.7000 | Actual Loss: 0.8625\n",
      "Baseline Loss: 2.6693 | Actual Loss: 1.1873\n",
      "Baseline Loss: 2.7005 | Actual Loss: 0.3663\n",
      "Baseline Loss: 2.6388 | Actual Loss: 0.3577\n",
      "Baseline Loss: 2.6909 | Actual Loss: 0.3122\n",
      "Baseline Loss: 2.6997 | Actual Loss: 0.3057\n",
      "Baseline Loss: 2.6481 | Actual Loss: 0.2403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 181/1000 [00:56<04:27,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6697 | Actual Loss: 0.2641\n",
      "Baseline Loss: 2.6901 | Actual Loss: 0.6087\n",
      "Baseline Loss: 2.6556 | Actual Loss: 0.4010\n",
      "Baseline Loss: 2.6946 | Actual Loss: 0.5345\n",
      "Baseline Loss: 2.2206 | Actual Loss: 0.2416\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6829\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4549\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3642\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5023\n",
      "Epoch 181/1000: Train Loss: 0.5564, Val Loss: 0.5011\n",
      "Baseline Loss: 2.6715 | Actual Loss: 0.1597\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4945\n",
      "Baseline Loss: 2.7051 | Actual Loss: 0.4433\n",
      "Baseline Loss: 2.6431 | Actual Loss: 0.6290\n",
      "Baseline Loss: 2.6906 | Actual Loss: 0.1752\n",
      "Baseline Loss: 2.6796 | Actual Loss: 0.2715\n",
      "Baseline Loss: 2.6772 | Actual Loss: 0.2865\n",
      "Baseline Loss: 2.6992 | Actual Loss: 0.2325\n",
      "Baseline Loss: 2.6638 | Actual Loss: 0.5279\n",
      "Baseline Loss: 2.6934 | Actual Loss: 0.5255\n",
      "Baseline Loss: 2.6927 | Actual Loss: 0.3349\n",
      "Baseline Loss: 2.7255 | Actual Loss: 0.4482\n",
      "Baseline Loss: 2.6838 | Actual Loss: 0.3402\n",
      "Baseline Loss: 2.6449 | Actual Loss: 0.2938\n",
      "Baseline Loss: 2.6855 | Actual Loss: 0.3235\n",
      "Baseline Loss: 2.3257 | Actual Loss: 0.0864\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 182/1000 [00:57<04:10,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6644 | Actual Loss: 0.4541\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3838\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5313\n",
      "Epoch 182/1000: Train Loss: 0.3483, Val Loss: 0.5053\n",
      "Baseline Loss: 2.7269 | Actual Loss: 0.1590\n",
      "Baseline Loss: 2.6223 | Actual Loss: 0.9007\n",
      "Baseline Loss: 2.6929 | Actual Loss: 0.4715\n",
      "Baseline Loss: 2.6705 | Actual Loss: 0.5412\n",
      "Baseline Loss: 2.6778 | Actual Loss: 0.3168\n",
      "Baseline Loss: 2.6672 | Actual Loss: 0.3486\n",
      "Baseline Loss: 2.7045 | Actual Loss: 0.3654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 183/1000 [00:57<04:19,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6328 | Actual Loss: 0.4338\n",
      "Baseline Loss: 2.6706 | Actual Loss: 0.4620\n",
      "Baseline Loss: 2.6956 | Actual Loss: 0.5230\n",
      "Baseline Loss: 2.6270 | Actual Loss: 0.5220\n",
      "Baseline Loss: 2.6751 | Actual Loss: 0.3021\n",
      "Baseline Loss: 2.7216 | Actual Loss: 0.6077\n",
      "Baseline Loss: 2.6731 | Actual Loss: 0.1368\n",
      "Baseline Loss: 2.6844 | Actual Loss: 0.6531\n",
      "Baseline Loss: 2.3186 | Actual Loss: 0.1680\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6678\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4854\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4086\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5268\n",
      "Epoch 183/1000: Train Loss: 0.4320, Val Loss: 0.5221\n",
      "Baseline Loss: 2.6984 | Actual Loss: 0.1745\n",
      "Baseline Loss: 2.6579 | Actual Loss: 0.9787\n",
      "Baseline Loss: 2.6937 | Actual Loss: 0.5640\n",
      "Baseline Loss: 2.6915 | Actual Loss: 0.6981\n",
      "Baseline Loss: 2.6839 | Actual Loss: 0.3779\n",
      "Baseline Loss: 2.7246 | Actual Loss: 0.1974\n",
      "Baseline Loss: 2.6495 | Actual Loss: 0.2450\n",
      "Baseline Loss: 2.6730 | Actual Loss: 0.2042\n",
      "Baseline Loss: 2.6397 | Actual Loss: 0.9501\n",
      "Baseline Loss: 2.6920 | Actual Loss: 1.4176\n",
      "Baseline Loss: 2.6787 | Actual Loss: 1.3331\n",
      "Baseline Loss: 2.6469 | Actual Loss: 0.5519\n",
      "Baseline Loss: 2.6808 | Actual Loss: 0.4986\n",
      "Baseline Loss: 2.6601 | Actual Loss: 0.1808\n",
      "Baseline Loss: 2.6917 | Actual Loss: 0.2701\n",
      "Baseline Loss: 2.2123 | Actual Loss: 0.1760\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7072\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 184/1000 [00:57<04:25,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6840 | Actual Loss: 0.3212\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5205\n",
      "Epoch 184/1000: Train Loss: 0.5511, Val Loss: 0.5049\n",
      "Baseline Loss: 2.6589 | Actual Loss: 0.4113\n",
      "Baseline Loss: 2.6927 | Actual Loss: 0.3537\n",
      "Baseline Loss: 2.6452 | Actual Loss: 0.6428\n",
      "Baseline Loss: 2.6464 | Actual Loss: 0.3703\n",
      "Baseline Loss: 2.7077 | Actual Loss: 0.3255\n",
      "Baseline Loss: 2.6904 | Actual Loss: 0.7808\n",
      "Baseline Loss: 2.6841 | Actual Loss: 0.2475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 185/1000 [00:58<04:07,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6521 | Actual Loss: 0.7146\n",
      "Baseline Loss: 2.6725 | Actual Loss: 0.2891\n",
      "Baseline Loss: 2.6976 | Actual Loss: 0.3229\n",
      "Baseline Loss: 2.6762 | Actual Loss: 1.4773\n",
      "Baseline Loss: 2.6398 | Actual Loss: 0.3799\n",
      "Baseline Loss: 2.6665 | Actual Loss: 1.1983\n",
      "Baseline Loss: 2.7109 | Actual Loss: 0.4131\n",
      "Baseline Loss: 2.6768 | Actual Loss: 0.6475\n",
      "Baseline Loss: 2.3050 | Actual Loss: 0.0838\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6301\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4491\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3416\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5084\n",
      "Epoch 185/1000: Train Loss: 0.5412, Val Loss: 0.4823\n",
      "Baseline Loss: 2.6971 | Actual Loss: 0.3722\n",
      "Baseline Loss: 2.6411 | Actual Loss: 0.3842\n",
      "Baseline Loss: 2.6906 | Actual Loss: 0.3606\n",
      "Baseline Loss: 2.7120 | Actual Loss: 0.1209\n",
      "Baseline Loss: 2.6702 | Actual Loss: 0.1900\n",
      "Baseline Loss: 2.6970 | Actual Loss: 0.3325\n",
      "Baseline Loss: 2.6688 | Actual Loss: 0.7590\n",
      "Baseline Loss: 2.6771 | Actual Loss: 0.4661\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.3141\n",
      "Baseline Loss: 2.6901 | Actual Loss: 0.7091\n",
      "Baseline Loss: 2.6327 | Actual Loss: 0.3578\n",
      "Baseline Loss: 2.6815 | Actual Loss: 0.7586\n",
      "Baseline Loss: 2.6607 | Actual Loss: 0.7795\n",
      "Baseline Loss: 2.6749 | Actual Loss: 0.4347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▊        | 186/1000 [00:58<04:20,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6892 | Actual Loss: 0.2905\n",
      "Baseline Loss: 2.2338 | Actual Loss: 0.0973\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6531\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4551\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3882\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.6259\n",
      "Epoch 186/1000: Train Loss: 0.4204, Val Loss: 0.5306\n",
      "Baseline Loss: 2.6707 | Actual Loss: 0.4258\n",
      "Baseline Loss: 2.6793 | Actual Loss: 0.4779\n",
      "Baseline Loss: 2.6932 | Actual Loss: 0.7107\n",
      "Baseline Loss: 2.6745 | Actual Loss: 0.2507\n",
      "Baseline Loss: 2.6980 | Actual Loss: 0.6250\n",
      "Baseline Loss: 2.6665 | Actual Loss: 0.3395\n",
      "Baseline Loss: 2.7229 | Actual Loss: 0.2872\n",
      "Baseline Loss: 2.6913 | Actual Loss: 0.3902\n",
      "Baseline Loss: 2.6476 | Actual Loss: 0.4380\n",
      "Baseline Loss: 2.6778 | Actual Loss: 0.4795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▊        | 187/1000 [00:58<04:01,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7020 | Actual Loss: 0.1082\n",
      "Baseline Loss: 2.6229 | Actual Loss: 0.5764\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.2563\n",
      "Baseline Loss: 2.6683 | Actual Loss: 0.5827\n",
      "Baseline Loss: 2.6589 | Actual Loss: 0.7702\n",
      "Baseline Loss: 2.3298 | Actual Loss: 0.6991\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.5996\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4793\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3604\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.4607\n",
      "Epoch 187/1000: Train Loss: 0.4636, Val Loss: 0.4750\n",
      "Baseline Loss: 2.6967 | Actual Loss: 0.4795\n",
      "Baseline Loss: 2.6645 | Actual Loss: 0.3841\n",
      "Baseline Loss: 2.6851 | Actual Loss: 0.5566\n",
      "Baseline Loss: 2.6901 | Actual Loss: 0.5066\n",
      "Baseline Loss: 2.6720 | Actual Loss: 0.2292\n",
      "Baseline Loss: 2.6556 | Actual Loss: 0.3123\n",
      "Baseline Loss: 2.6965 | Actual Loss: 0.3330\n",
      "Baseline Loss: 2.6957 | Actual Loss: 0.6320\n",
      "Baseline Loss: 2.6318 | Actual Loss: 0.1878\n",
      "Baseline Loss: 2.6799 | Actual Loss: 0.3045\n",
      "Baseline Loss: 2.6659 | Actual Loss: 0.9892\n",
      "Baseline Loss: 2.6784 | Actual Loss: 1.2026\n",
      "Baseline Loss: 2.6722 | Actual Loss: 0.2363\n",
      "Baseline Loss: 2.6568 | Actual Loss: 0.3091\n",
      "Baseline Loss: 2.6893 | Actual Loss: 0.3397\n",
      "Baseline Loss: 2.3457 | Actual Loss: 0.0380\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 188/1000 [00:58<04:08,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6644 | Actual Loss: 0.4630\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3428\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5575\n",
      "Epoch 188/1000: Train Loss: 0.4400, Val Loss: 0.5162\n",
      "Baseline Loss: 2.6827 | Actual Loss: 0.5405\n",
      "Baseline Loss: 2.6890 | Actual Loss: 0.2578\n",
      "Baseline Loss: 2.6976 | Actual Loss: 0.5175\n",
      "Baseline Loss: 2.6397 | Actual Loss: 0.4139\n",
      "Baseline Loss: 2.6433 | Actual Loss: 0.2630\n",
      "Baseline Loss: 2.6695 | Actual Loss: 0.3361\n",
      "Baseline Loss: 2.6862 | Actual Loss: 0.3721\n",
      "Baseline Loss: 2.6650 | Actual Loss: 0.4116\n",
      "Baseline Loss: 2.6669 | Actual Loss: 0.3801\n",
      "Baseline Loss: 2.6750 | Actual Loss: 0.2506\n",
      "Baseline Loss: 2.6888 | Actual Loss: 0.2107\n",
      "Baseline Loss: 2.6565 | Actual Loss: 0.6806\n",
      "Baseline Loss: 2.6792 | Actual Loss: 0.4579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 189/1000 [00:59<03:58,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6625 | Actual Loss: 0.2166\n",
      "Baseline Loss: 2.7000 | Actual Loss: 0.3065\n",
      "Baseline Loss: 2.2384 | Actual Loss: 0.1587\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6611\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4756\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4010\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5943\n",
      "Epoch 189/1000: Train Loss: 0.3609, Val Loss: 0.5330\n",
      "Baseline Loss: 2.6493 | Actual Loss: 0.1603\n",
      "Baseline Loss: 2.6236 | Actual Loss: 0.4201\n",
      "Baseline Loss: 2.6682 | Actual Loss: 0.6111\n",
      "Baseline Loss: 2.6722 | Actual Loss: 0.1518\n",
      "Baseline Loss: 2.6752 | Actual Loss: 0.3466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 190/1000 [00:59<04:03,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6816 | Actual Loss: 0.6520\n",
      "Baseline Loss: 2.6959 | Actual Loss: 0.5264\n",
      "Baseline Loss: 2.6512 | Actual Loss: 0.1739\n",
      "Baseline Loss: 2.6766 | Actual Loss: 0.3070\n",
      "Baseline Loss: 2.6670 | Actual Loss: 0.2591\n",
      "Baseline Loss: 2.7214 | Actual Loss: 0.2320\n",
      "Baseline Loss: 2.6739 | Actual Loss: 0.9092\n",
      "Baseline Loss: 2.7053 | Actual Loss: 0.4347\n",
      "Baseline Loss: 2.6919 | Actual Loss: 0.5084\n",
      "Baseline Loss: 2.7009 | Actual Loss: 0.4347\n",
      "Baseline Loss: 2.2720 | Actual Loss: 0.5271\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6560\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4646\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4217\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.6243\n",
      "Epoch 190/1000: Train Loss: 0.4159, Val Loss: 0.5416\n",
      "Baseline Loss: 2.6589 | Actual Loss: 0.2632\n",
      "Baseline Loss: 2.7045 | Actual Loss: 1.0081\n",
      "Baseline Loss: 2.7046 | Actual Loss: 0.1673\n",
      "Baseline Loss: 2.6740 | Actual Loss: 0.5614\n",
      "Baseline Loss: 2.6363 | Actual Loss: 0.2347\n",
      "Baseline Loss: 2.6863 | Actual Loss: 0.3084\n",
      "Baseline Loss: 2.6992 | Actual Loss: 0.5058\n",
      "Baseline Loss: 2.6621 | Actual Loss: 0.5451\n",
      "Baseline Loss: 2.6997 | Actual Loss: 0.2299\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.2909\n",
      "Baseline Loss: 2.7045 | Actual Loss: 0.6919\n",
      "Baseline Loss: 2.6846 | Actual Loss: 0.4380\n",
      "Baseline Loss: 2.6452 | Actual Loss: 0.4150\n",
      "Baseline Loss: 2.6697 | Actual Loss: 0.5604\n",
      "Baseline Loss: 2.6820 | Actual Loss: 0.6117\n",
      "Baseline Loss: 2.2640 | Actual Loss: 0.0771\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 191/1000 [00:59<04:13,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6644 | Actual Loss: 0.4625\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3807\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5660\n",
      "Epoch 191/1000: Train Loss: 0.4318, Val Loss: 0.5051\n",
      "Baseline Loss: 2.6774 | Actual Loss: 0.3705\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.2669\n",
      "Baseline Loss: 2.6790 | Actual Loss: 0.5616\n",
      "Baseline Loss: 2.6828 | Actual Loss: 0.2483\n",
      "Baseline Loss: 2.6954 | Actual Loss: 0.4715\n",
      "Baseline Loss: 2.7405 | Actual Loss: 0.4069\n",
      "Baseline Loss: 2.6849 | Actual Loss: 0.9997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 192/1000 [01:00<04:00,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6480 | Actual Loss: 0.4801\n",
      "Baseline Loss: 2.6512 | Actual Loss: 0.5070\n",
      "Baseline Loss: 2.6581 | Actual Loss: 0.2347\n",
      "Baseline Loss: 2.6761 | Actual Loss: 0.3687\n",
      "Baseline Loss: 2.6552 | Actual Loss: 0.3565\n",
      "Baseline Loss: 2.6487 | Actual Loss: 0.4761\n",
      "Baseline Loss: 2.7075 | Actual Loss: 0.1301\n",
      "Baseline Loss: 2.7138 | Actual Loss: 1.2488\n",
      "Baseline Loss: 2.2264 | Actual Loss: 0.4526\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7518\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4702\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4133\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5114\n",
      "Epoch 192/1000: Train Loss: 0.4738, Val Loss: 0.5367\n",
      "Baseline Loss: 2.6510 | Actual Loss: 0.3655\n",
      "Baseline Loss: 2.6654 | Actual Loss: 0.3618\n",
      "Baseline Loss: 2.7195 | Actual Loss: 0.1381\n",
      "Baseline Loss: 2.6568 | Actual Loss: 0.2023\n",
      "Baseline Loss: 2.6795 | Actual Loss: 0.5076\n",
      "Baseline Loss: 2.6781 | Actual Loss: 0.2456\n",
      "Baseline Loss: 2.6513 | Actual Loss: 0.1885\n",
      "Baseline Loss: 2.7053 | Actual Loss: 0.5222\n",
      "Baseline Loss: 2.6703 | Actual Loss: 2.1734\n",
      "Baseline Loss: 2.6587 | Actual Loss: 0.6095\n",
      "Baseline Loss: 2.6880 | Actual Loss: 0.4513\n",
      "Baseline Loss: 2.6767 | Actual Loss: 0.5751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 193/1000 [01:00<04:10,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6740 | Actual Loss: 0.3023\n",
      "Baseline Loss: 2.6949 | Actual Loss: 0.4170\n",
      "Baseline Loss: 2.6832 | Actual Loss: 0.3710\n",
      "Baseline Loss: 2.2798 | Actual Loss: 1.7428\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7329\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4695\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3636\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5023\n",
      "Epoch 193/1000: Train Loss: 0.5734, Val Loss: 0.5171\n",
      "Baseline Loss: 2.6694 | Actual Loss: 0.4730\n",
      "Baseline Loss: 2.7082 | Actual Loss: 0.3052\n",
      "Baseline Loss: 2.6872 | Actual Loss: 0.2086\n",
      "Baseline Loss: 2.6877 | Actual Loss: 0.4249\n",
      "Baseline Loss: 2.6744 | Actual Loss: 0.4159\n",
      "Baseline Loss: 2.6616 | Actual Loss: 0.6197\n",
      "Baseline Loss: 2.6464 | Actual Loss: 0.4427\n",
      "Baseline Loss: 2.6610 | Actual Loss: 0.2703\n",
      "Baseline Loss: 2.6681 | Actual Loss: 0.2637\n",
      "Baseline Loss: 2.6938 | Actual Loss: 0.4671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 194/1000 [01:00<04:15,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6661 | Actual Loss: 0.3327\n",
      "Baseline Loss: 2.6671 | Actual Loss: 0.2031\n",
      "Baseline Loss: 2.6899 | Actual Loss: 0.2120\n",
      "Baseline Loss: 2.6982 | Actual Loss: 0.4897\n",
      "Baseline Loss: 2.6839 | Actual Loss: 0.3998\n",
      "Baseline Loss: 2.2456 | Actual Loss: 0.0608\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6713\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4769\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3970\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5438\n",
      "Epoch 194/1000: Train Loss: 0.3493, Val Loss: 0.5222\n",
      "Baseline Loss: 2.6547 | Actual Loss: 0.3194\n",
      "Baseline Loss: 2.6310 | Actual Loss: 0.1602\n",
      "Baseline Loss: 2.7025 | Actual Loss: 1.2755\n",
      "Baseline Loss: 2.6452 | Actual Loss: 0.2582\n",
      "Baseline Loss: 2.6517 | Actual Loss: 0.5143\n",
      "Baseline Loss: 2.6766 | Actual Loss: 0.3901\n",
      "Baseline Loss: 2.6691 | Actual Loss: 0.7525\n",
      "Baseline Loss: 2.7081 | Actual Loss: 0.4048\n",
      "Baseline Loss: 2.6925 | Actual Loss: 0.2817\n",
      "Baseline Loss: 2.6703 | Actual Loss: 0.4570\n",
      "Baseline Loss: 2.6642 | Actual Loss: 0.4374\n",
      "Baseline Loss: 2.7019 | Actual Loss: 0.8526\n",
      "Baseline Loss: 2.6939 | Actual Loss: 0.2221\n",
      "Baseline Loss: 2.6580 | Actual Loss: 0.6358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 195/1000 [01:01<04:02,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6744 | Actual Loss: 0.4286\n",
      "Baseline Loss: 2.1853 | Actual Loss: 0.0492\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7095\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4674\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3742\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5755\n",
      "Epoch 195/1000: Train Loss: 0.4650, Val Loss: 0.5316\n",
      "Baseline Loss: 2.6780 | Actual Loss: 0.2567\n",
      "Baseline Loss: 2.6807 | Actual Loss: 0.5700\n",
      "Baseline Loss: 2.6724 | Actual Loss: 0.5439\n",
      "Baseline Loss: 2.6823 | Actual Loss: 0.4438\n",
      "Baseline Loss: 2.6631 | Actual Loss: 0.2362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 196/1000 [01:01<04:16,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6815 | Actual Loss: 0.6370\n",
      "Baseline Loss: 2.6810 | Actual Loss: 0.6234\n",
      "Baseline Loss: 2.6456 | Actual Loss: 1.3287\n",
      "Baseline Loss: 2.6715 | Actual Loss: 0.4937\n",
      "Baseline Loss: 2.6636 | Actual Loss: 0.8887\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.2800\n",
      "Baseline Loss: 2.6680 | Actual Loss: 0.6766\n",
      "Baseline Loss: 2.6768 | Actual Loss: 0.3095\n",
      "Baseline Loss: 2.6934 | Actual Loss: 0.6583\n",
      "Baseline Loss: 2.6461 | Actual Loss: 0.2622\n",
      "Baseline Loss: 2.2687 | Actual Loss: 0.1726\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7277\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4556\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3581\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5098\n",
      "Epoch 196/1000: Train Loss: 0.5238, Val Loss: 0.5128\n",
      "Baseline Loss: 2.6504 | Actual Loss: 0.9633\n",
      "Baseline Loss: 2.7193 | Actual Loss: 0.5410\n",
      "Baseline Loss: 2.6797 | Actual Loss: 0.7183\n",
      "Baseline Loss: 2.7177 | Actual Loss: 0.3974\n",
      "Baseline Loss: 2.6729 | Actual Loss: 0.3009\n",
      "Baseline Loss: 2.6704 | Actual Loss: 0.3889\n",
      "Baseline Loss: 2.6630 | Actual Loss: 0.2477\n",
      "Baseline Loss: 2.6389 | Actual Loss: 0.3902\n",
      "Baseline Loss: 2.6650 | Actual Loss: 0.4569\n",
      "Baseline Loss: 2.6811 | Actual Loss: 0.2537\n",
      "Baseline Loss: 2.6280 | Actual Loss: 0.6232\n",
      "Baseline Loss: 2.6901 | Actual Loss: 0.5782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 197/1000 [01:01<04:21,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6699 | Actual Loss: 0.6147\n",
      "Baseline Loss: 2.7024 | Actual Loss: 0.3191\n",
      "Baseline Loss: 2.6736 | Actual Loss: 0.4396\n",
      "Baseline Loss: 2.3227 | Actual Loss: 0.3892\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7164\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4728\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3860\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5460\n",
      "Epoch 197/1000: Train Loss: 0.4764, Val Loss: 0.5303\n",
      "Baseline Loss: 2.6479 | Actual Loss: 0.3717\n",
      "Baseline Loss: 2.6709 | Actual Loss: 0.2581\n",
      "Baseline Loss: 2.7009 | Actual Loss: 0.7314\n",
      "Baseline Loss: 2.6632 | Actual Loss: 2.2762\n",
      "Baseline Loss: 2.6765 | Actual Loss: 0.3207\n",
      "Baseline Loss: 2.6555 | Actual Loss: 0.4502\n",
      "Baseline Loss: 2.6579 | Actual Loss: 0.2434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 198/1000 [01:02<04:08,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6916 | Actual Loss: 0.4075\n",
      "Baseline Loss: 2.6915 | Actual Loss: 0.4704\n",
      "Baseline Loss: 2.6847 | Actual Loss: 0.6626\n",
      "Baseline Loss: 2.6851 | Actual Loss: 0.2363\n",
      "Baseline Loss: 2.6701 | Actual Loss: 0.5670\n",
      "Baseline Loss: 2.6859 | Actual Loss: 0.5777\n",
      "Baseline Loss: 2.6879 | Actual Loss: 0.2038\n",
      "Baseline Loss: 2.6767 | Actual Loss: 0.5202\n",
      "Baseline Loss: 2.2346 | Actual Loss: 1.8887\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7037\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4485\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3108\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5568\n",
      "Epoch 198/1000: Train Loss: 0.6366, Val Loss: 0.5050\n",
      "Baseline Loss: 2.6254 | Actual Loss: 0.3514\n",
      "Baseline Loss: 2.6605 | Actual Loss: 0.3900\n",
      "Baseline Loss: 2.6348 | Actual Loss: 0.5657\n",
      "Baseline Loss: 2.7163 | Actual Loss: 0.5412\n",
      "Baseline Loss: 2.7048 | Actual Loss: 0.5667\n",
      "Baseline Loss: 2.6575 | Actual Loss: 0.5106\n",
      "Baseline Loss: 2.6567 | Actual Loss: 0.3515\n",
      "Baseline Loss: 2.7331 | Actual Loss: 0.8744\n",
      "Baseline Loss: 2.7348 | Actual Loss: 0.2767\n",
      "Baseline Loss: 2.6767 | Actual Loss: 0.2676\n",
      "Baseline Loss: 2.6986 | Actual Loss: 0.5188\n",
      "Baseline Loss: 2.7134 | Actual Loss: 0.1489\n",
      "Baseline Loss: 2.6767 | Actual Loss: 0.3669\n",
      "Baseline Loss: 2.6610 | Actual Loss: 0.2298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 199/1000 [01:02<04:17,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6460 | Actual Loss: 0.3566\n",
      "Baseline Loss: 2.2633 | Actual Loss: 0.2150\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6972\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4580\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3434\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5528\n",
      "Epoch 199/1000: Train Loss: 0.4082, Val Loss: 0.5129\n",
      "Baseline Loss: 2.6424 | Actual Loss: 0.4323\n",
      "Baseline Loss: 2.6698 | Actual Loss: 0.2741\n",
      "Baseline Loss: 2.6575 | Actual Loss: 0.2728\n",
      "Baseline Loss: 2.7174 | Actual Loss: 0.4226\n",
      "Baseline Loss: 2.7117 | Actual Loss: 0.2599\n",
      "Baseline Loss: 2.6395 | Actual Loss: 0.2216\n",
      "Baseline Loss: 2.6500 | Actual Loss: 0.3390\n",
      "Baseline Loss: 2.6815 | Actual Loss: 0.4282\n",
      "Baseline Loss: 2.6881 | Actual Loss: 0.2581\n",
      "Baseline Loss: 2.6824 | Actual Loss: 0.2117\n",
      "Baseline Loss: 2.6636 | Actual Loss: 0.4873\n",
      "Baseline Loss: 2.6645 | Actual Loss: 0.3625\n",
      "Baseline Loss: 2.6960 | Actual Loss: 0.1502\n",
      "Baseline Loss: 2.7033 | Actual Loss: 0.8011\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.5170\n",
      "Baseline Loss: 2.3339 | Actual Loss: 0.1128\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6375\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 200/1000 [01:02<04:30,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6840 | Actual Loss: 0.3516\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5033\n",
      "Epoch 200/1000: Train Loss: 0.3469, Val Loss: 0.4884\n",
      "Baseline Loss: 2.6784 | Actual Loss: 0.3187\n",
      "Baseline Loss: 2.6863 | Actual Loss: 0.3363\n",
      "Baseline Loss: 2.6559 | Actual Loss: 0.7757\n",
      "Baseline Loss: 2.6727 | Actual Loss: 0.4121\n",
      "Baseline Loss: 2.6844 | Actual Loss: 0.2633\n",
      "Baseline Loss: 2.6742 | Actual Loss: 0.6286\n",
      "Baseline Loss: 2.6705 | Actual Loss: 0.6077\n",
      "Baseline Loss: 2.6930 | Actual Loss: 0.2073\n",
      "Baseline Loss: 2.6711 | Actual Loss: 0.4175\n",
      "Baseline Loss: 2.6342 | Actual Loss: 0.3577\n",
      "Baseline Loss: 2.6988 | Actual Loss: 0.3549\n",
      "Baseline Loss: 2.6752 | Actual Loss: 0.2628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 201/1000 [01:03<04:15,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7007 | Actual Loss: 0.2840\n",
      "Baseline Loss: 2.6688 | Actual Loss: 0.5600\n",
      "Baseline Loss: 2.6669 | Actual Loss: 1.0844\n",
      "Baseline Loss: 2.3350 | Actual Loss: 0.9421\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7669\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4563\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3813\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5665\n",
      "Epoch 201/1000: Train Loss: 0.4883, Val Loss: 0.5428\n",
      "Baseline Loss: 2.6676 | Actual Loss: 1.4708\n",
      "Baseline Loss: 2.7109 | Actual Loss: 0.4226\n",
      "Baseline Loss: 2.6797 | Actual Loss: 0.5448\n",
      "Baseline Loss: 2.6722 | Actual Loss: 0.3768\n",
      "Baseline Loss: 2.6703 | Actual Loss: 0.3711\n",
      "Baseline Loss: 2.6386 | Actual Loss: 0.4148\n",
      "Baseline Loss: 2.6691 | Actual Loss: 0.4435\n",
      "Baseline Loss: 2.6713 | Actual Loss: 0.1488\n",
      "Baseline Loss: 2.6762 | Actual Loss: 0.3268\n",
      "Baseline Loss: 2.7007 | Actual Loss: 1.5865\n",
      "Baseline Loss: 2.7032 | Actual Loss: 0.2553\n",
      "Baseline Loss: 2.6668 | Actual Loss: 0.2378\n",
      "Baseline Loss: 2.6908 | Actual Loss: 0.4812\n",
      "Baseline Loss: 2.6575 | Actual Loss: 0.7564\n",
      "Baseline Loss: 2.6871 | Actual Loss: 0.4049\n",
      "Baseline Loss: 2.2215 | Actual Loss: 0.2552\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6482\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4960\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 202/1000 [01:03<04:25,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6117 | Actual Loss: 0.5498\n",
      "Epoch 202/1000: Train Loss: 0.5311, Val Loss: 0.5088\n",
      "Baseline Loss: 2.6496 | Actual Loss: 0.2472\n",
      "Baseline Loss: 2.6849 | Actual Loss: 0.4108\n",
      "Baseline Loss: 2.7150 | Actual Loss: 0.3570\n",
      "Baseline Loss: 2.6721 | Actual Loss: 0.4463\n",
      "Baseline Loss: 2.6774 | Actual Loss: 0.3159\n",
      "Baseline Loss: 2.7126 | Actual Loss: 0.3354\n",
      "Baseline Loss: 2.7045 | Actual Loss: 0.3830\n",
      "Baseline Loss: 2.6631 | Actual Loss: 0.3280\n",
      "Baseline Loss: 2.6922 | Actual Loss: 0.4973\n",
      "Baseline Loss: 2.7445 | Actual Loss: 0.2934\n",
      "Baseline Loss: 2.6683 | Actual Loss: 0.3370\n",
      "Baseline Loss: 2.6636 | Actual Loss: 0.1867\n",
      "Baseline Loss: 2.6542 | Actual Loss: 0.4972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 203/1000 [01:03<04:32,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6250 | Actual Loss: 0.4704\n",
      "Baseline Loss: 2.6746 | Actual Loss: 0.6151\n",
      "Baseline Loss: 2.3186 | Actual Loss: 0.0527\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.5948\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4454\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.2825\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5714\n",
      "Epoch 203/1000: Train Loss: 0.3608, Val Loss: 0.4735\n",
      "Baseline Loss: 2.6655 | Actual Loss: 0.2922\n",
      "Baseline Loss: 2.7187 | Actual Loss: 0.4304\n",
      "Baseline Loss: 2.6712 | Actual Loss: 0.3359\n",
      "Baseline Loss: 2.6923 | Actual Loss: 0.3773\n",
      "Baseline Loss: 2.6723 | Actual Loss: 1.8073\n",
      "Baseline Loss: 2.6331 | Actual Loss: 0.4793\n",
      "Baseline Loss: 2.6941 | Actual Loss: 0.4687\n",
      "Baseline Loss: 2.6522 | Actual Loss: 0.2630\n",
      "Baseline Loss: 2.6565 | Actual Loss: 0.3544\n",
      "Baseline Loss: 2.6478 | Actual Loss: 0.1136\n",
      "Baseline Loss: 2.6752 | Actual Loss: 0.5339\n",
      "Baseline Loss: 2.7028 | Actual Loss: 0.4696\n",
      "Baseline Loss: 2.6656 | Actual Loss: 0.1654\n",
      "Baseline Loss: 2.6503 | Actual Loss: 0.6004\n",
      "Baseline Loss: 2.7399 | Actual Loss: 0.8951\n",
      "Baseline Loss: 2.2788 | Actual Loss: 0.5513\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6331\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 204/1000 [01:04<04:16,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6840 | Actual Loss: 0.3518\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5393\n",
      "Epoch 204/1000: Train Loss: 0.5086, Val Loss: 0.5021\n",
      "Baseline Loss: 2.6499 | Actual Loss: 0.4078\n",
      "Baseline Loss: 2.7309 | Actual Loss: 0.2927\n",
      "Baseline Loss: 2.6829 | Actual Loss: 0.4962\n",
      "Baseline Loss: 2.6726 | Actual Loss: 0.4985\n",
      "Baseline Loss: 2.6760 | Actual Loss: 0.1912\n",
      "Baseline Loss: 2.6610 | Actual Loss: 0.3103\n",
      "Baseline Loss: 2.6654 | Actual Loss: 0.2637\n",
      "Baseline Loss: 2.6626 | Actual Loss: 0.3696\n",
      "Baseline Loss: 2.6909 | Actual Loss: 0.4193\n",
      "Baseline Loss: 2.6771 | Actual Loss: 0.5719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 205/1000 [01:04<04:24,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6809 | Actual Loss: 0.2662\n",
      "Baseline Loss: 2.6761 | Actual Loss: 0.2024\n",
      "Baseline Loss: 2.6478 | Actual Loss: 0.6190\n",
      "Baseline Loss: 2.6971 | Actual Loss: 0.1474\n",
      "Baseline Loss: 2.6946 | Actual Loss: 0.3064\n",
      "Baseline Loss: 2.2392 | Actual Loss: 2.1904\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7750\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4789\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4331\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5467\n",
      "Epoch 205/1000: Train Loss: 0.4721, Val Loss: 0.5584\n",
      "Baseline Loss: 2.6609 | Actual Loss: 0.3263\n",
      "Baseline Loss: 2.6775 | Actual Loss: 0.6775\n",
      "Baseline Loss: 2.6739 | Actual Loss: 0.0992\n",
      "Baseline Loss: 2.6398 | Actual Loss: 0.4348\n",
      "Baseline Loss: 2.6889 | Actual Loss: 0.1562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 206/1000 [01:04<04:11,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6953 | Actual Loss: 0.2838\n",
      "Baseline Loss: 2.6601 | Actual Loss: 0.5236\n",
      "Baseline Loss: 2.6611 | Actual Loss: 0.2599\n",
      "Baseline Loss: 2.7486 | Actual Loss: 0.7113\n",
      "Baseline Loss: 2.6677 | Actual Loss: 0.2280\n",
      "Baseline Loss: 2.6926 | Actual Loss: 0.4068\n",
      "Baseline Loss: 2.6689 | Actual Loss: 0.5392\n",
      "Baseline Loss: 2.6385 | Actual Loss: 0.1801\n",
      "Baseline Loss: 2.6922 | Actual Loss: 0.4166\n",
      "Baseline Loss: 2.7190 | Actual Loss: 0.8896\n",
      "Baseline Loss: 2.2999 | Actual Loss: 0.5021\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6925\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4773\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4112\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5347\n",
      "Epoch 206/1000: Train Loss: 0.4147, Val Loss: 0.5289\n",
      "Baseline Loss: 2.6659 | Actual Loss: 0.4327\n",
      "Baseline Loss: 2.6850 | Actual Loss: 0.3715\n",
      "Baseline Loss: 2.6436 | Actual Loss: 0.5668\n",
      "Baseline Loss: 2.6537 | Actual Loss: 0.2249\n",
      "Baseline Loss: 2.6763 | Actual Loss: 0.7000\n",
      "Baseline Loss: 2.6876 | Actual Loss: 0.4172\n",
      "Baseline Loss: 2.6584 | Actual Loss: 0.2265\n",
      "Baseline Loss: 2.6799 | Actual Loss: 0.5803\n",
      "Baseline Loss: 2.6891 | Actual Loss: 0.3589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 207/1000 [01:05<04:18,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6382 | Actual Loss: 0.4995\n",
      "Baseline Loss: 2.6527 | Actual Loss: 0.3835\n",
      "Baseline Loss: 2.6919 | Actual Loss: 0.3845\n",
      "Baseline Loss: 2.6876 | Actual Loss: 0.4737\n",
      "Baseline Loss: 2.7224 | Actual Loss: 0.2326\n",
      "Baseline Loss: 2.6896 | Actual Loss: 0.2715\n",
      "Baseline Loss: 2.3263 | Actual Loss: 0.1423\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6431\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4757\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3878\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5691\n",
      "Epoch 207/1000: Train Loss: 0.3917, Val Loss: 0.5189\n",
      "Baseline Loss: 2.6812 | Actual Loss: 0.4986\n",
      "Baseline Loss: 2.6720 | Actual Loss: 0.2534\n",
      "Baseline Loss: 2.6619 | Actual Loss: 0.4456\n",
      "Baseline Loss: 2.6833 | Actual Loss: 0.4021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 208/1000 [01:05<04:03,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6629 | Actual Loss: 0.2975\n",
      "Baseline Loss: 2.6500 | Actual Loss: 0.4575\n",
      "Baseline Loss: 2.7066 | Actual Loss: 0.5594\n",
      "Baseline Loss: 2.6933 | Actual Loss: 0.4423\n",
      "Baseline Loss: 2.6805 | Actual Loss: 0.5651\n",
      "Baseline Loss: 2.6749 | Actual Loss: 0.4257\n",
      "Baseline Loss: 2.6728 | Actual Loss: 0.4131\n",
      "Baseline Loss: 2.6649 | Actual Loss: 1.7991\n",
      "Baseline Loss: 2.6733 | Actual Loss: 0.1531\n",
      "Baseline Loss: 2.6818 | Actual Loss: 0.5782\n",
      "Baseline Loss: 2.6445 | Actual Loss: 0.4111\n",
      "Baseline Loss: 2.2206 | Actual Loss: 0.1947\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6099\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4672\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3222\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5541\n",
      "Epoch 208/1000: Train Loss: 0.4935, Val Loss: 0.4883\n",
      "Baseline Loss: 2.6476 | Actual Loss: 0.5410\n",
      "Baseline Loss: 2.6223 | Actual Loss: 0.2842\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.3623\n",
      "Baseline Loss: 2.6704 | Actual Loss: 0.4489\n",
      "Baseline Loss: 2.6859 | Actual Loss: 0.5942\n",
      "Baseline Loss: 2.6693 | Actual Loss: 0.5522\n",
      "Baseline Loss: 2.6680 | Actual Loss: 0.7079\n",
      "Baseline Loss: 2.6827 | Actual Loss: 0.8222\n",
      "Baseline Loss: 2.6763 | Actual Loss: 0.3572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 209/1000 [01:05<04:14,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7039 | Actual Loss: 0.4737\n",
      "Baseline Loss: 2.6932 | Actual Loss: 0.3341\n",
      "Baseline Loss: 2.6545 | Actual Loss: 0.3126\n",
      "Baseline Loss: 2.7291 | Actual Loss: 0.3623\n",
      "Baseline Loss: 2.6432 | Actual Loss: 0.5106\n",
      "Baseline Loss: 2.6844 | Actual Loss: 0.3464\n",
      "Baseline Loss: 2.2927 | Actual Loss: 0.0356\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.5810\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4687\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3654\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5355\n",
      "Epoch 209/1000: Train Loss: 0.4403, Val Loss: 0.4876\n",
      "Baseline Loss: 2.6784 | Actual Loss: 0.4406\n",
      "Baseline Loss: 2.6824 | Actual Loss: 0.2984\n",
      "Baseline Loss: 2.6613 | Actual Loss: 0.2965\n",
      "Baseline Loss: 2.6561 | Actual Loss: 0.2743\n",
      "Baseline Loss: 2.7159 | Actual Loss: 0.3545\n",
      "Baseline Loss: 2.6688 | Actual Loss: 0.3963\n",
      "Baseline Loss: 2.6696 | Actual Loss: 0.4371\n",
      "Baseline Loss: 2.6776 | Actual Loss: 0.4049\n",
      "Baseline Loss: 2.6635 | Actual Loss: 0.2157\n",
      "Baseline Loss: 2.6760 | Actual Loss: 0.5774\n",
      "Baseline Loss: 2.6759 | Actual Loss: 0.4002\n",
      "Baseline Loss: 2.7066 | Actual Loss: 0.3202\n",
      "Baseline Loss: 2.6667 | Actual Loss: 0.3408\n",
      "Baseline Loss: 2.6915 | Actual Loss: 1.2640\n",
      "Baseline Loss: 2.6614 | Actual Loss: 0.5702\n",
      "Baseline Loss: 2.2704 | Actual Loss: 0.0664\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7123\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 210/1000 [01:06<04:21,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6840 | Actual Loss: 0.3961\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5150\n",
      "Epoch 210/1000: Train Loss: 0.4161, Val Loss: 0.5289\n",
      "Baseline Loss: 2.6279 | Actual Loss: 0.6770\n",
      "Baseline Loss: 2.6736 | Actual Loss: 0.4315\n",
      "Baseline Loss: 2.6796 | Actual Loss: 0.3102\n",
      "Baseline Loss: 2.6639 | Actual Loss: 0.4080\n",
      "Baseline Loss: 2.6839 | Actual Loss: 1.6797\n",
      "Baseline Loss: 2.6627 | Actual Loss: 0.4753\n",
      "Baseline Loss: 2.7022 | Actual Loss: 0.4465\n",
      "Baseline Loss: 2.6574 | Actual Loss: 0.1353\n",
      "Baseline Loss: 2.6660 | Actual Loss: 0.3924\n",
      "Baseline Loss: 2.6542 | Actual Loss: 0.4120\n",
      "Baseline Loss: 2.6777 | Actual Loss: 0.3516\n",
      "Baseline Loss: 2.6503 | Actual Loss: 0.6109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 211/1000 [01:06<04:07,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6846 | Actual Loss: 0.2626\n",
      "Baseline Loss: 2.7014 | Actual Loss: 0.4680\n",
      "Baseline Loss: 2.7103 | Actual Loss: 0.2997\n",
      "Baseline Loss: 2.2645 | Actual Loss: 0.2881\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6375\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4658\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3868\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.4997\n",
      "Epoch 211/1000: Train Loss: 0.4780, Val Loss: 0.4974\n",
      "Baseline Loss: 2.6810 | Actual Loss: 0.5647\n",
      "Baseline Loss: 2.6871 | Actual Loss: 0.5195\n",
      "Baseline Loss: 2.7166 | Actual Loss: 1.1583\n",
      "Baseline Loss: 2.6699 | Actual Loss: 1.4351\n",
      "Baseline Loss: 2.6709 | Actual Loss: 0.2762\n",
      "Baseline Loss: 2.7167 | Actual Loss: 0.1563\n",
      "Baseline Loss: 2.6767 | Actual Loss: 0.2449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 212/1000 [01:06<04:17,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6783 | Actual Loss: 0.5145\n",
      "Baseline Loss: 2.6487 | Actual Loss: 0.1780\n",
      "Baseline Loss: 2.7152 | Actual Loss: 0.4557\n",
      "Baseline Loss: 2.6714 | Actual Loss: 0.5644\n",
      "Baseline Loss: 2.6880 | Actual Loss: 0.2818\n",
      "Baseline Loss: 2.6586 | Actual Loss: 0.3865\n",
      "Baseline Loss: 2.6626 | Actual Loss: 0.2231\n",
      "Baseline Loss: 2.6871 | Actual Loss: 0.4205\n",
      "Baseline Loss: 2.2806 | Actual Loss: 0.3522\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6325\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4587\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3548\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5692\n",
      "Epoch 212/1000: Train Loss: 0.4832, Val Loss: 0.5038\n",
      "Baseline Loss: 2.6703 | Actual Loss: 0.2109\n",
      "Baseline Loss: 2.6719 | Actual Loss: 0.4764\n",
      "Baseline Loss: 2.6736 | Actual Loss: 0.3126\n",
      "Baseline Loss: 2.6721 | Actual Loss: 0.4689\n",
      "Baseline Loss: 2.7085 | Actual Loss: 0.3907\n",
      "Baseline Loss: 2.6647 | Actual Loss: 0.4081\n",
      "Baseline Loss: 2.6382 | Actual Loss: 0.3249\n",
      "Baseline Loss: 2.6780 | Actual Loss: 0.2901\n",
      "Baseline Loss: 2.7091 | Actual Loss: 0.3582\n",
      "Baseline Loss: 2.6519 | Actual Loss: 0.4208\n",
      "Baseline Loss: 2.6954 | Actual Loss: 0.4956\n",
      "Baseline Loss: 2.7376 | Actual Loss: 0.3046\n",
      "Baseline Loss: 2.6522 | Actual Loss: 0.2826\n",
      "Baseline Loss: 2.6800 | Actual Loss: 0.2114\n",
      "Baseline Loss: 2.6544 | Actual Loss: 0.5706\n",
      "Baseline Loss: 2.3279 | Actual Loss: 0.4357\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██▏       | 213/1000 [01:07<04:25,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6644 | Actual Loss: 0.4585\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3020\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5043\n",
      "Epoch 213/1000: Train Loss: 0.3726, Val Loss: 0.4784\n",
      "Baseline Loss: 2.6587 | Actual Loss: 0.3638\n",
      "Baseline Loss: 2.6883 | Actual Loss: 1.2796\n",
      "Baseline Loss: 2.6910 | Actual Loss: 1.8320\n",
      "Baseline Loss: 2.6992 | Actual Loss: 0.3501\n",
      "Baseline Loss: 2.6586 | Actual Loss: 0.2030\n",
      "Baseline Loss: 2.6885 | Actual Loss: 0.5763\n",
      "Baseline Loss: 2.6659 | Actual Loss: 0.3897\n",
      "Baseline Loss: 2.6468 | Actual Loss: 0.4193\n",
      "Baseline Loss: 2.6395 | Actual Loss: 0.3164\n",
      "Baseline Loss: 2.7206 | Actual Loss: 0.2276\n",
      "Baseline Loss: 2.6613 | Actual Loss: 0.4553\n",
      "Baseline Loss: 2.6659 | Actual Loss: 1.2582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██▏       | 214/1000 [01:07<04:09,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6517 | Actual Loss: 2.2410\n",
      "Baseline Loss: 2.6856 | Actual Loss: 0.1615\n",
      "Baseline Loss: 2.6433 | Actual Loss: 0.2539\n",
      "Baseline Loss: 2.2634 | Actual Loss: 0.0825\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6438\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4693\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4344\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5285\n",
      "Epoch 214/1000: Train Loss: 0.6506, Val Loss: 0.5190\n",
      "Baseline Loss: 2.7148 | Actual Loss: 0.1799\n",
      "Baseline Loss: 2.6480 | Actual Loss: 0.1892\n",
      "Baseline Loss: 2.7096 | Actual Loss: 0.2035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 215/1000 [01:07<04:14,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6704 | Actual Loss: 0.3873\n",
      "Baseline Loss: 2.6482 | Actual Loss: 0.3748\n",
      "Baseline Loss: 2.6784 | Actual Loss: 0.4958\n",
      "Baseline Loss: 2.7204 | Actual Loss: 0.5056\n",
      "Baseline Loss: 2.7092 | Actual Loss: 0.1737\n",
      "Baseline Loss: 2.6847 | Actual Loss: 0.1131\n",
      "Baseline Loss: 2.6658 | Actual Loss: 0.3513\n",
      "Baseline Loss: 2.6279 | Actual Loss: 0.5701\n",
      "Baseline Loss: 2.6818 | Actual Loss: 1.3517\n",
      "Baseline Loss: 2.6342 | Actual Loss: 0.5770\n",
      "Baseline Loss: 2.6608 | Actual Loss: 0.1912\n",
      "Baseline Loss: 2.6573 | Actual Loss: 0.3894\n",
      "Baseline Loss: 2.2933 | Actual Loss: 0.3107\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6602\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4629\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4249\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5088\n",
      "Epoch 215/1000: Train Loss: 0.3978, Val Loss: 0.5142\n",
      "Baseline Loss: 2.6845 | Actual Loss: 0.4404\n",
      "Baseline Loss: 2.6649 | Actual Loss: 0.3737\n",
      "Baseline Loss: 2.7161 | Actual Loss: 0.6561\n",
      "Baseline Loss: 2.6847 | Actual Loss: 0.3074\n",
      "Baseline Loss: 2.6824 | Actual Loss: 0.7596\n",
      "Baseline Loss: 2.6797 | Actual Loss: 0.4702\n",
      "Baseline Loss: 2.6599 | Actual Loss: 0.7769\n",
      "Baseline Loss: 2.7060 | Actual Loss: 0.6258\n",
      "Baseline Loss: 2.6885 | Actual Loss: 0.6231\n",
      "Baseline Loss: 2.6570 | Actual Loss: 0.2096\n",
      "Baseline Loss: 2.6473 | Actual Loss: 0.2400\n",
      "Baseline Loss: 2.6685 | Actual Loss: 0.8249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 216/1000 [01:08<04:21,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6540 | Actual Loss: 0.3643\n",
      "Baseline Loss: 2.6647 | Actual Loss: 0.1433\n",
      "Baseline Loss: 2.7004 | Actual Loss: 0.3680\n",
      "Baseline Loss: 2.2675 | Actual Loss: 1.6744\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.5988\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4570\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3247\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.4692\n",
      "Epoch 216/1000: Train Loss: 0.5536, Val Loss: 0.4624\n",
      "New best validation loss: 0.4624\n",
      "Baseline Loss: 2.6389 | Actual Loss: 0.2593\n",
      "Baseline Loss: 2.6782 | Actual Loss: 0.4353\n",
      "Baseline Loss: 2.6564 | Actual Loss: 0.1859\n",
      "Baseline Loss: 2.6865 | Actual Loss: 0.3290\n",
      "Baseline Loss: 2.7252 | Actual Loss: 0.4980\n",
      "Baseline Loss: 2.7028 | Actual Loss: 0.2882\n",
      "Baseline Loss: 2.7109 | Actual Loss: 0.1419\n",
      "Baseline Loss: 2.6695 | Actual Loss: 0.4307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 217/1000 [01:08<04:05,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6927 | Actual Loss: 0.4217\n",
      "Baseline Loss: 2.6865 | Actual Loss: 0.5331\n",
      "Baseline Loss: 2.6525 | Actual Loss: 0.5209\n",
      "Baseline Loss: 2.7204 | Actual Loss: 0.2601\n",
      "Baseline Loss: 2.6276 | Actual Loss: 0.4742\n",
      "Baseline Loss: 2.6728 | Actual Loss: 0.1827\n",
      "Baseline Loss: 2.6450 | Actual Loss: 0.3369\n",
      "Baseline Loss: 2.2563 | Actual Loss: 0.8613\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6583\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4828\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3213\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5043\n",
      "Epoch 217/1000: Train Loss: 0.3850, Val Loss: 0.4917\n",
      "Baseline Loss: 2.6911 | Actual Loss: 0.2041\n",
      "Baseline Loss: 2.6559 | Actual Loss: 0.5414\n",
      "Baseline Loss: 2.7295 | Actual Loss: 0.6598\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.2567\n",
      "Baseline Loss: 2.6310 | Actual Loss: 0.2740\n",
      "Baseline Loss: 2.6863 | Actual Loss: 0.2140\n",
      "Baseline Loss: 2.6864 | Actual Loss: 0.3017\n",
      "Baseline Loss: 2.6753 | Actual Loss: 0.5079\n",
      "Baseline Loss: 2.7186 | Actual Loss: 0.6952\n",
      "Baseline Loss: 2.6979 | Actual Loss: 0.4019\n",
      "Baseline Loss: 2.7104 | Actual Loss: 0.3900\n",
      "Baseline Loss: 2.6494 | Actual Loss: 1.9605\n",
      "Baseline Loss: 2.6787 | Actual Loss: 0.8440\n",
      "Baseline Loss: 2.6725 | Actual Loss: 0.2038\n",
      "Baseline Loss: 2.6436 | Actual Loss: 0.5175\n",
      "Baseline Loss: 2.2426 | Actual Loss: 0.3043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 218/1000 [01:08<04:07,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6907 | Actual Loss: 0.7253\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4559\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3570\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.4998\n",
      "Epoch 218/1000: Train Loss: 0.5173, Val Loss: 0.5095\n",
      "Baseline Loss: 2.6562 | Actual Loss: 0.7575\n",
      "Baseline Loss: 2.6504 | Actual Loss: 0.7223\n",
      "Baseline Loss: 2.7022 | Actual Loss: 1.5975\n",
      "Baseline Loss: 2.6431 | Actual Loss: 0.2550\n",
      "Baseline Loss: 2.6658 | Actual Loss: 0.3200\n",
      "Baseline Loss: 2.6795 | Actual Loss: 0.7733\n",
      "Baseline Loss: 2.7306 | Actual Loss: 0.3545\n",
      "Baseline Loss: 2.7054 | Actual Loss: 0.2181\n",
      "Baseline Loss: 2.6568 | Actual Loss: 0.2935\n",
      "Baseline Loss: 2.6503 | Actual Loss: 0.3981\n",
      "Baseline Loss: 2.6535 | Actual Loss: 0.2299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 219/1000 [01:08<04:20,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6668 | Actual Loss: 0.5306\n",
      "Baseline Loss: 2.7047 | Actual Loss: 0.3377\n",
      "Baseline Loss: 2.6893 | Actual Loss: 0.5091\n",
      "Baseline Loss: 2.6607 | Actual Loss: 0.4205\n",
      "Baseline Loss: 2.2701 | Actual Loss: 0.2424\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7395\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4694\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3421\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5109\n",
      "Epoch 219/1000: Train Loss: 0.4975, Val Loss: 0.5155\n",
      "Baseline Loss: 2.6706 | Actual Loss: 0.2361\n",
      "Baseline Loss: 2.6714 | Actual Loss: 0.2907\n",
      "Baseline Loss: 2.6686 | Actual Loss: 0.4477\n",
      "Baseline Loss: 2.6962 | Actual Loss: 0.2846\n",
      "Baseline Loss: 2.6717 | Actual Loss: 0.1578\n",
      "Baseline Loss: 2.6752 | Actual Loss: 0.2802\n",
      "Baseline Loss: 2.6957 | Actual Loss: 0.4831\n",
      "Baseline Loss: 2.6975 | Actual Loss: 0.5601\n",
      "Baseline Loss: 2.6887 | Actual Loss: 0.3919\n",
      "Baseline Loss: 2.6877 | Actual Loss: 0.4898\n",
      "Baseline Loss: 2.6885 | Actual Loss: 0.2983\n",
      "Baseline Loss: 2.6799 | Actual Loss: 0.2674\n",
      "Baseline Loss: 2.6940 | Actual Loss: 0.4754\n",
      "Baseline Loss: 2.6386 | Actual Loss: 0.3587\n",
      "Baseline Loss: 2.6922 | Actual Loss: 0.1516\n",
      "Baseline Loss: 2.2721 | Actual Loss: 0.3281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 220/1000 [01:09<04:01,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6907 | Actual Loss: 0.7153\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4637\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3643\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5584\n",
      "Epoch 220/1000: Train Loss: 0.3438, Val Loss: 0.5254\n",
      "Baseline Loss: 2.6824 | Actual Loss: 0.5260\n",
      "Baseline Loss: 2.6921 | Actual Loss: 0.5546\n",
      "Baseline Loss: 2.7183 | Actual Loss: 0.3420\n",
      "Baseline Loss: 2.6354 | Actual Loss: 0.7569\n",
      "Baseline Loss: 2.6711 | Actual Loss: 0.4800\n",
      "Baseline Loss: 2.6407 | Actual Loss: 0.1999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 221/1000 [01:09<04:05,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7328 | Actual Loss: 0.3776\n",
      "Baseline Loss: 2.6809 | Actual Loss: 0.5644\n",
      "Baseline Loss: 2.6248 | Actual Loss: 0.4209\n",
      "Baseline Loss: 2.6731 | Actual Loss: 0.6729\n",
      "Baseline Loss: 2.6420 | Actual Loss: 0.5916\n",
      "Baseline Loss: 2.7007 | Actual Loss: 0.2248\n",
      "Baseline Loss: 2.6871 | Actual Loss: 0.4071\n",
      "Baseline Loss: 2.6688 | Actual Loss: 0.3341\n",
      "Baseline Loss: 2.6720 | Actual Loss: 0.3429\n",
      "Baseline Loss: 2.2704 | Actual Loss: 2.1553\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6263\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4669\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4626\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5644\n",
      "Epoch 221/1000: Train Loss: 0.5594, Val Loss: 0.5301\n",
      "Baseline Loss: 2.7019 | Actual Loss: 0.5061\n",
      "Baseline Loss: 2.6590 | Actual Loss: 0.2423\n",
      "Baseline Loss: 2.7170 | Actual Loss: 0.4325\n",
      "Baseline Loss: 2.6299 | Actual Loss: 0.2605\n",
      "Baseline Loss: 2.6542 | Actual Loss: 0.7549\n",
      "Baseline Loss: 2.6799 | Actual Loss: 0.5810\n",
      "Baseline Loss: 2.6616 | Actual Loss: 0.6544\n",
      "Baseline Loss: 2.6524 | Actual Loss: 0.1922\n",
      "Baseline Loss: 2.6516 | Actual Loss: 0.5595\n",
      "Baseline Loss: 2.6892 | Actual Loss: 0.5611\n",
      "Baseline Loss: 2.6484 | Actual Loss: 0.3208\n",
      "Baseline Loss: 2.6283 | Actual Loss: 0.4283\n",
      "Baseline Loss: 2.7170 | Actual Loss: 0.3301\n",
      "Baseline Loss: 2.6337 | Actual Loss: 0.2180\n",
      "Baseline Loss: 2.6969 | Actual Loss: 0.8949\n",
      "Baseline Loss: 2.3413 | Actual Loss: 0.0846\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6659\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4658\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 222/1000 [01:09<04:10,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6117 | Actual Loss: 0.5551\n",
      "Epoch 222/1000: Train Loss: 0.4388, Val Loss: 0.5082\n",
      "Baseline Loss: 2.6784 | Actual Loss: 0.5318\n",
      "Baseline Loss: 2.6744 | Actual Loss: 0.4240\n",
      "Baseline Loss: 2.6337 | Actual Loss: 0.2623\n",
      "Baseline Loss: 2.6910 | Actual Loss: 0.2452\n",
      "Baseline Loss: 2.6484 | Actual Loss: 0.4769\n",
      "Baseline Loss: 2.6935 | Actual Loss: 1.2557\n",
      "Baseline Loss: 2.6251 | Actual Loss: 0.4442\n",
      "Baseline Loss: 2.7075 | Actual Loss: 0.2021\n",
      "Baseline Loss: 2.7192 | Actual Loss: 0.5658\n",
      "Baseline Loss: 2.6629 | Actual Loss: 0.5724\n",
      "Baseline Loss: 2.6547 | Actual Loss: 0.2275\n",
      "Baseline Loss: 2.6738 | Actual Loss: 0.3094\n",
      "Baseline Loss: 2.6406 | Actual Loss: 0.4980\n",
      "Baseline Loss: 2.6845 | Actual Loss: 0.5727\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.7744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 223/1000 [01:10<03:53,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2901 | Actual Loss: 0.2037\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6813\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4710\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4132\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5500\n",
      "Epoch 223/1000: Train Loss: 0.4729, Val Loss: 0.5289\n",
      "Baseline Loss: 2.6677 | Actual Loss: 0.6200\n",
      "Baseline Loss: 2.6509 | Actual Loss: 0.1970\n",
      "Baseline Loss: 2.7010 | Actual Loss: 0.2116\n",
      "Baseline Loss: 2.6865 | Actual Loss: 0.4299\n",
      "Baseline Loss: 2.6708 | Actual Loss: 1.3600\n",
      "Baseline Loss: 2.6522 | Actual Loss: 0.1954\n",
      "Baseline Loss: 2.7119 | Actual Loss: 0.1789\n",
      "Baseline Loss: 2.6681 | Actual Loss: 0.2641\n",
      "Baseline Loss: 2.7008 | Actual Loss: 0.3610\n",
      "Baseline Loss: 2.6814 | Actual Loss: 1.7915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 224/1000 [01:10<04:07,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6894 | Actual Loss: 1.3230\n",
      "Baseline Loss: 2.6569 | Actual Loss: 0.3668\n",
      "Baseline Loss: 2.6863 | Actual Loss: 0.6209\n",
      "Baseline Loss: 2.6784 | Actual Loss: 0.4546\n",
      "Baseline Loss: 2.7062 | Actual Loss: 0.2838\n",
      "Baseline Loss: 2.2395 | Actual Loss: 0.0848\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6784\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4780\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3965\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5366\n",
      "Epoch 224/1000: Train Loss: 0.5465, Val Loss: 0.5224\n",
      "Baseline Loss: 2.6955 | Actual Loss: 0.7398\n",
      "Baseline Loss: 2.7056 | Actual Loss: 0.4695\n",
      "Baseline Loss: 2.6610 | Actual Loss: 0.4952\n",
      "Baseline Loss: 2.6766 | Actual Loss: 0.6519\n",
      "Baseline Loss: 2.6791 | Actual Loss: 0.5760\n",
      "Baseline Loss: 2.6567 | Actual Loss: 0.2380\n",
      "Baseline Loss: 2.7270 | Actual Loss: 0.2442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▎       | 225/1000 [01:10<03:52,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6622 | Actual Loss: 0.5034\n",
      "Baseline Loss: 2.7096 | Actual Loss: 0.3121\n",
      "Baseline Loss: 2.6653 | Actual Loss: 0.5640\n",
      "Baseline Loss: 2.6509 | Actual Loss: 0.9932\n",
      "Baseline Loss: 2.6426 | Actual Loss: 0.2836\n",
      "Baseline Loss: 2.6806 | Actual Loss: 0.1697\n",
      "Baseline Loss: 2.6725 | Actual Loss: 0.3114\n",
      "Baseline Loss: 2.6581 | Actual Loss: 0.3439\n",
      "Baseline Loss: 2.2648 | Actual Loss: 0.4390\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7067\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4529\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4354\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5133\n",
      "Epoch 225/1000: Train Loss: 0.4584, Val Loss: 0.5271\n",
      "Baseline Loss: 2.6570 | Actual Loss: 0.5594\n",
      "Baseline Loss: 2.6348 | Actual Loss: 0.3799\n",
      "Baseline Loss: 2.6658 | Actual Loss: 0.1293\n",
      "Baseline Loss: 2.6725 | Actual Loss: 0.5732\n",
      "Baseline Loss: 2.7333 | Actual Loss: 0.2286\n",
      "Baseline Loss: 2.6350 | Actual Loss: 0.6761\n",
      "Baseline Loss: 2.6903 | Actual Loss: 0.2738\n",
      "Baseline Loss: 2.6822 | Actual Loss: 0.3462\n",
      "Baseline Loss: 2.6577 | Actual Loss: 0.4724\n",
      "Baseline Loss: 2.6930 | Actual Loss: 0.3877\n",
      "Baseline Loss: 2.6999 | Actual Loss: 0.3002\n",
      "Baseline Loss: 2.6468 | Actual Loss: 0.1912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 226/1000 [01:11<04:04,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6322 | Actual Loss: 0.2210\n",
      "Baseline Loss: 2.7167 | Actual Loss: 0.2700\n",
      "Baseline Loss: 2.7303 | Actual Loss: 0.3855\n",
      "Baseline Loss: 2.2497 | Actual Loss: 1.5683\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7618\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4716\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3562\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5365\n",
      "Epoch 226/1000: Train Loss: 0.4352, Val Loss: 0.5315\n",
      "Baseline Loss: 2.6744 | Actual Loss: 0.2043\n",
      "Baseline Loss: 2.6784 | Actual Loss: 0.7246\n",
      "Baseline Loss: 2.6678 | Actual Loss: 0.2093\n",
      "Baseline Loss: 2.6668 | Actual Loss: 0.2514\n",
      "Baseline Loss: 2.7090 | Actual Loss: 0.3069\n",
      "Baseline Loss: 2.6662 | Actual Loss: 0.3427\n",
      "Baseline Loss: 2.6584 | Actual Loss: 0.5008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 227/1000 [01:11<03:54,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6783 | Actual Loss: 0.5133\n",
      "Baseline Loss: 2.7100 | Actual Loss: 0.2373\n",
      "Baseline Loss: 2.6354 | Actual Loss: 0.4878\n",
      "Baseline Loss: 2.6692 | Actual Loss: 0.2305\n",
      "Baseline Loss: 2.7058 | Actual Loss: 0.1760\n",
      "Baseline Loss: 2.6633 | Actual Loss: 0.1996\n",
      "Baseline Loss: 2.7123 | Actual Loss: 0.3700\n",
      "Baseline Loss: 2.6668 | Actual Loss: 0.3932\n",
      "Baseline Loss: 2.2681 | Actual Loss: 0.1586\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6333\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4728\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4645\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5500\n",
      "Epoch 227/1000: Train Loss: 0.3316, Val Loss: 0.5301\n",
      "Baseline Loss: 2.6503 | Actual Loss: 0.3187\n",
      "Baseline Loss: 2.6905 | Actual Loss: 0.2714\n",
      "Baseline Loss: 2.7157 | Actual Loss: 0.5008\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.5368\n",
      "Baseline Loss: 2.6471 | Actual Loss: 0.3682\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.5193\n",
      "Baseline Loss: 2.6594 | Actual Loss: 0.6343\n",
      "Baseline Loss: 2.7016 | Actual Loss: 0.2034\n",
      "Baseline Loss: 2.6743 | Actual Loss: 0.4987\n",
      "Baseline Loss: 2.6720 | Actual Loss: 0.9766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 228/1000 [01:11<04:07,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6873 | Actual Loss: 0.1422\n",
      "Baseline Loss: 2.7041 | Actual Loss: 0.6344\n",
      "Baseline Loss: 2.6481 | Actual Loss: 0.4347\n",
      "Baseline Loss: 2.7244 | Actual Loss: 0.3669\n",
      "Baseline Loss: 2.6498 | Actual Loss: 0.2576\n",
      "Baseline Loss: 2.2389 | Actual Loss: 0.1784\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7053\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4632\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4452\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5791\n",
      "Epoch 228/1000: Train Loss: 0.4276, Val Loss: 0.5482\n",
      "Baseline Loss: 2.7284 | Actual Loss: 0.4423\n",
      "Baseline Loss: 2.6651 | Actual Loss: 0.5102\n",
      "Baseline Loss: 2.6504 | Actual Loss: 0.3764\n",
      "Baseline Loss: 2.7044 | Actual Loss: 1.0793\n",
      "Baseline Loss: 2.6753 | Actual Loss: 0.5658\n",
      "Baseline Loss: 2.7070 | Actual Loss: 0.2369\n",
      "Baseline Loss: 2.6774 | Actual Loss: 0.1707\n",
      "Baseline Loss: 2.6689 | Actual Loss: 0.5112\n",
      "Baseline Loss: 2.6976 | Actual Loss: 0.5027\n",
      "Baseline Loss: 2.6291 | Actual Loss: 0.1778\n",
      "Baseline Loss: 2.7204 | Actual Loss: 0.4825\n",
      "Baseline Loss: 2.6605 | Actual Loss: 0.4875\n",
      "Baseline Loss: 2.6463 | Actual Loss: 0.1321\n",
      "Baseline Loss: 2.6599 | Actual Loss: 0.5647\n",
      "Baseline Loss: 2.6756 | Actual Loss: 0.3337\n",
      "Baseline Loss: 2.2412 | Actual Loss: 0.3298\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.5850\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 229/1000 [01:12<04:15,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6840 | Actual Loss: 0.4186\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5646\n",
      "Epoch 229/1000: Train Loss: 0.4315, Val Loss: 0.5099\n",
      "Baseline Loss: 2.6967 | Actual Loss: 0.4600\n",
      "Baseline Loss: 2.6707 | Actual Loss: 0.3994\n",
      "Baseline Loss: 2.6672 | Actual Loss: 0.2862\n",
      "Baseline Loss: 2.7135 | Actual Loss: 0.8482\n",
      "Baseline Loss: 2.6768 | Actual Loss: 0.4421\n",
      "Baseline Loss: 2.6588 | Actual Loss: 0.4973\n",
      "Baseline Loss: 2.6676 | Actual Loss: 0.3969\n",
      "Baseline Loss: 2.6641 | Actual Loss: 0.2259\n",
      "Baseline Loss: 2.6702 | Actual Loss: 0.4588\n",
      "Baseline Loss: 2.6787 | Actual Loss: 0.6633\n",
      "Baseline Loss: 2.6509 | Actual Loss: 0.2631\n",
      "Baseline Loss: 2.6744 | Actual Loss: 0.6733\n",
      "Baseline Loss: 2.6502 | Actual Loss: 0.2465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 230/1000 [01:12<04:03,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6787 | Actual Loss: 0.2406\n",
      "Baseline Loss: 2.6939 | Actual Loss: 0.4867\n",
      "Baseline Loss: 2.2951 | Actual Loss: 0.3494\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6526\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.5482\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3913\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5850\n",
      "Epoch 230/1000: Train Loss: 0.4336, Val Loss: 0.5443\n",
      "Baseline Loss: 2.6875 | Actual Loss: 0.2442\n",
      "Baseline Loss: 2.6412 | Actual Loss: 0.4392\n",
      "Baseline Loss: 2.6999 | Actual Loss: 0.3239\n",
      "Baseline Loss: 2.6563 | Actual Loss: 0.3840\n",
      "Baseline Loss: 2.6695 | Actual Loss: 0.4712\n",
      "Baseline Loss: 2.6687 | Actual Loss: 0.5246\n",
      "Baseline Loss: 2.6564 | Actual Loss: 0.2026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 231/1000 [01:12<04:14,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6851 | Actual Loss: 0.4746\n",
      "Baseline Loss: 2.6737 | Actual Loss: 0.6528\n",
      "Baseline Loss: 2.6847 | Actual Loss: 0.3058\n",
      "Baseline Loss: 2.6473 | Actual Loss: 0.1602\n",
      "Baseline Loss: 2.6656 | Actual Loss: 0.1892\n",
      "Baseline Loss: 2.7318 | Actual Loss: 0.2680\n",
      "Baseline Loss: 2.6827 | Actual Loss: 0.5809\n",
      "Baseline Loss: 2.6915 | Actual Loss: 0.5173\n",
      "Baseline Loss: 2.2824 | Actual Loss: 1.7038\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7747\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.5194\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3511\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5155\n",
      "Epoch 231/1000: Train Loss: 0.4651, Val Loss: 0.5402\n",
      "Baseline Loss: 2.6491 | Actual Loss: 0.3428\n",
      "Baseline Loss: 2.6481 | Actual Loss: 0.4510\n",
      "Baseline Loss: 2.6678 | Actual Loss: 0.2789\n",
      "Baseline Loss: 2.7086 | Actual Loss: 1.6953\n",
      "Baseline Loss: 2.6485 | Actual Loss: 0.3151\n",
      "Baseline Loss: 2.6827 | Actual Loss: 0.2336\n",
      "Baseline Loss: 2.7247 | Actual Loss: 0.1934\n",
      "Baseline Loss: 2.6594 | Actual Loss: 0.3382\n",
      "Baseline Loss: 2.7234 | Actual Loss: 0.4435\n",
      "Baseline Loss: 2.6769 | Actual Loss: 1.1527\n",
      "Baseline Loss: 2.6834 | Actual Loss: 0.4993\n",
      "Baseline Loss: 2.6673 | Actual Loss: 0.3493\n",
      "Baseline Loss: 2.7263 | Actual Loss: 0.3103\n",
      "Baseline Loss: 2.6357 | Actual Loss: 0.3883\n",
      "Baseline Loss: 2.6828 | Actual Loss: 0.4919\n",
      "Baseline Loss: 2.2334 | Actual Loss: 0.1699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 232/1000 [01:13<04:20,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6907 | Actual Loss: 0.6336\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4690\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3310\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5481\n",
      "Epoch 232/1000: Train Loss: 0.4784, Val Loss: 0.4954\n",
      "Baseline Loss: 2.6787 | Actual Loss: 0.3815\n",
      "Baseline Loss: 2.6731 | Actual Loss: 0.5785\n",
      "Baseline Loss: 2.6882 | Actual Loss: 0.5695\n",
      "Baseline Loss: 2.6791 | Actual Loss: 0.3446\n",
      "Baseline Loss: 2.6511 | Actual Loss: 0.5229\n",
      "Baseline Loss: 2.7100 | Actual Loss: 0.4339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 233/1000 [01:13<04:04,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6654 | Actual Loss: 0.3793\n",
      "Baseline Loss: 2.6519 | Actual Loss: 0.4156\n",
      "Baseline Loss: 2.6545 | Actual Loss: 0.3456\n",
      "Baseline Loss: 2.7191 | Actual Loss: 0.2908\n",
      "Baseline Loss: 2.6400 | Actual Loss: 0.6688\n",
      "Baseline Loss: 2.6665 | Actual Loss: 0.4362\n",
      "Baseline Loss: 2.6940 | Actual Loss: 0.4384\n",
      "Baseline Loss: 2.6593 | Actual Loss: 0.5577\n",
      "Baseline Loss: 2.6645 | Actual Loss: 0.3238\n",
      "Baseline Loss: 2.2411 | Actual Loss: 0.2402\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7071\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4626\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4621\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.4764\n",
      "Epoch 233/1000: Train Loss: 0.4330, Val Loss: 0.5270\n",
      "Baseline Loss: 2.6656 | Actual Loss: 0.0950\n",
      "Baseline Loss: 2.6920 | Actual Loss: 0.1411\n",
      "Baseline Loss: 2.6819 | Actual Loss: 0.3604\n",
      "Baseline Loss: 2.7109 | Actual Loss: 0.1721\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4521\n",
      "Baseline Loss: 2.6438 | Actual Loss: 0.4151\n",
      "Baseline Loss: 2.6806 | Actual Loss: 0.7092\n",
      "Baseline Loss: 2.6442 | Actual Loss: 0.5553\n",
      "Baseline Loss: 2.6516 | Actual Loss: 0.3752\n",
      "Baseline Loss: 2.6815 | Actual Loss: 0.3533\n",
      "Baseline Loss: 2.7121 | Actual Loss: 0.5012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 234/1000 [01:13<04:06,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6526 | Actual Loss: 0.3964\n",
      "Baseline Loss: 2.6721 | Actual Loss: 0.1879\n",
      "Baseline Loss: 2.6842 | Actual Loss: 0.5676\n",
      "Baseline Loss: 2.6528 | Actual Loss: 0.2331\n",
      "Baseline Loss: 2.3183 | Actual Loss: 0.3795\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6200\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4677\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3840\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5731\n",
      "Epoch 234/1000: Train Loss: 0.3684, Val Loss: 0.5112\n",
      "Baseline Loss: 2.7151 | Actual Loss: 0.5334\n",
      "Baseline Loss: 2.6269 | Actual Loss: 0.2347\n",
      "Baseline Loss: 2.6653 | Actual Loss: 0.6610\n",
      "Baseline Loss: 2.7265 | Actual Loss: 0.6413\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.6281\n",
      "Baseline Loss: 2.6396 | Actual Loss: 0.4616\n",
      "Baseline Loss: 2.6885 | Actual Loss: 0.3995\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.1856\n",
      "Baseline Loss: 2.6414 | Actual Loss: 0.4282\n",
      "Baseline Loss: 2.6614 | Actual Loss: 0.2064\n",
      "Baseline Loss: 2.6796 | Actual Loss: 0.3188\n",
      "Baseline Loss: 2.6786 | Actual Loss: 0.6231\n",
      "Baseline Loss: 2.6784 | Actual Loss: 0.4197\n",
      "Baseline Loss: 2.7092 | Actual Loss: 0.2483\n",
      "Baseline Loss: 2.6981 | Actual Loss: 0.3703\n",
      "Baseline Loss: 2.2476 | Actual Loss: 0.4495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██▎       | 235/1000 [01:14<04:13,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6907 | Actual Loss: 0.6568\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4744\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.2883\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5285\n",
      "Epoch 235/1000: Train Loss: 0.4256, Val Loss: 0.4870\n",
      "Baseline Loss: 2.6642 | Actual Loss: 0.8320\n",
      "Baseline Loss: 2.6741 | Actual Loss: 0.1069\n",
      "Baseline Loss: 2.6951 | Actual Loss: 0.6341\n",
      "Baseline Loss: 2.6542 | Actual Loss: 0.2632\n",
      "Baseline Loss: 2.6991 | Actual Loss: 0.6222\n",
      "Baseline Loss: 2.6670 | Actual Loss: 0.2874\n",
      "Baseline Loss: 2.6635 | Actual Loss: 0.3105\n",
      "Baseline Loss: 2.6862 | Actual Loss: 0.3500\n",
      "Baseline Loss: 2.6584 | Actual Loss: 0.4196\n",
      "Baseline Loss: 2.6628 | Actual Loss: 0.2661\n",
      "Baseline Loss: 2.6937 | Actual Loss: 0.2389\n",
      "Baseline Loss: 2.6815 | Actual Loss: 0.5008\n",
      "Baseline Loss: 2.6796 | Actual Loss: 0.3316\n",
      "Baseline Loss: 2.6533 | Actual Loss: 0.4907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██▎       | 236/1000 [01:14<03:55,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6728 | Actual Loss: 0.3574\n",
      "Baseline Loss: 2.2588 | Actual Loss: 1.0337\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.5936\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4824\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3754\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5248\n",
      "Epoch 236/1000: Train Loss: 0.4403, Val Loss: 0.4940\n",
      "Baseline Loss: 2.7184 | Actual Loss: 0.4671\n",
      "Baseline Loss: 2.6877 | Actual Loss: 0.2486\n",
      "Baseline Loss: 2.6757 | Actual Loss: 1.8819\n",
      "Baseline Loss: 2.6929 | Actual Loss: 0.2402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██▎       | 237/1000 [01:14<04:01,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6890 | Actual Loss: 0.5104\n",
      "Baseline Loss: 2.6514 | Actual Loss: 0.2925\n",
      "Baseline Loss: 2.6802 | Actual Loss: 0.4840\n",
      "Baseline Loss: 2.6901 | Actual Loss: 0.1294\n",
      "Baseline Loss: 2.6654 | Actual Loss: 1.7821\n",
      "Baseline Loss: 2.6871 | Actual Loss: 0.1460\n",
      "Baseline Loss: 2.6540 | Actual Loss: 0.3311\n",
      "Baseline Loss: 2.6383 | Actual Loss: 0.1158\n",
      "Baseline Loss: 2.6340 | Actual Loss: 0.8451\n",
      "Baseline Loss: 2.6733 | Actual Loss: 0.3666\n",
      "Baseline Loss: 2.6593 | Actual Loss: 0.2629\n",
      "Baseline Loss: 2.2480 | Actual Loss: 0.0484\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6518\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4593\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4470\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5306\n",
      "Epoch 237/1000: Train Loss: 0.5095, Val Loss: 0.5222\n",
      "Baseline Loss: 2.6490 | Actual Loss: 0.3221\n",
      "Baseline Loss: 2.6890 | Actual Loss: 0.6975\n",
      "Baseline Loss: 2.7095 | Actual Loss: 0.5523\n",
      "Baseline Loss: 2.6724 | Actual Loss: 0.2303\n",
      "Baseline Loss: 2.6771 | Actual Loss: 0.0883\n",
      "Baseline Loss: 2.6411 | Actual Loss: 0.3863\n",
      "Baseline Loss: 2.6494 | Actual Loss: 0.3231\n",
      "Baseline Loss: 2.6868 | Actual Loss: 0.4150\n",
      "Baseline Loss: 2.6724 | Actual Loss: 0.3958\n",
      "Baseline Loss: 2.6645 | Actual Loss: 0.2091\n",
      "Baseline Loss: 2.6825 | Actual Loss: 0.2072\n",
      "Baseline Loss: 2.7233 | Actual Loss: 0.5043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██▍       | 238/1000 [01:15<04:08,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6624 | Actual Loss: 0.7801\n",
      "Baseline Loss: 2.6749 | Actual Loss: 0.2929\n",
      "Baseline Loss: 2.6691 | Actual Loss: 0.1226\n",
      "Baseline Loss: 2.2084 | Actual Loss: 0.2684\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6810\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.5230\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3600\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5014\n",
      "Epoch 238/1000: Train Loss: 0.3622, Val Loss: 0.5164\n",
      "Baseline Loss: 2.6843 | Actual Loss: 0.1738\n",
      "Baseline Loss: 2.6536 | Actual Loss: 0.4433\n",
      "Baseline Loss: 2.6771 | Actual Loss: 0.8565\n",
      "Baseline Loss: 2.7286 | Actual Loss: 1.0398\n",
      "Baseline Loss: 2.6942 | Actual Loss: 0.3327\n",
      "Baseline Loss: 2.6837 | Actual Loss: 0.3134\n",
      "Baseline Loss: 2.6638 | Actual Loss: 0.5852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██▍       | 239/1000 [01:15<03:51,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6778 | Actual Loss: 0.2364\n",
      "Baseline Loss: 2.7052 | Actual Loss: 0.1827\n",
      "Baseline Loss: 2.6691 | Actual Loss: 0.8234\n",
      "Baseline Loss: 2.6746 | Actual Loss: 0.2938\n",
      "Baseline Loss: 2.6481 | Actual Loss: 0.3645\n",
      "Baseline Loss: 2.6464 | Actual Loss: 0.4007\n",
      "Baseline Loss: 2.6721 | Actual Loss: 0.2750\n",
      "Baseline Loss: 2.6870 | Actual Loss: 0.6533\n",
      "Baseline Loss: 2.3002 | Actual Loss: 0.8161\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6593\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4670\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3197\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5651\n",
      "Epoch 239/1000: Train Loss: 0.4869, Val Loss: 0.5028\n",
      "Baseline Loss: 2.7060 | Actual Loss: 0.2390\n",
      "Baseline Loss: 2.6802 | Actual Loss: 0.3521\n",
      "Baseline Loss: 2.6749 | Actual Loss: 0.2673\n",
      "Baseline Loss: 2.6603 | Actual Loss: 0.2121\n",
      "Baseline Loss: 2.6516 | Actual Loss: 0.7462\n",
      "Baseline Loss: 2.6750 | Actual Loss: 0.6734\n",
      "Baseline Loss: 2.7096 | Actual Loss: 0.3794\n",
      "Baseline Loss: 2.6702 | Actual Loss: 0.3070\n",
      "Baseline Loss: 2.6884 | Actual Loss: 0.6414\n",
      "Baseline Loss: 2.6841 | Actual Loss: 2.1106\n",
      "Baseline Loss: 2.6407 | Actual Loss: 0.2121\n",
      "Baseline Loss: 2.7063 | Actual Loss: 0.3628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██▍       | 240/1000 [01:15<04:00,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6637 | Actual Loss: 0.7716\n",
      "Baseline Loss: 2.6701 | Actual Loss: 0.1303\n",
      "Baseline Loss: 2.6646 | Actual Loss: 0.6552\n",
      "Baseline Loss: 2.2570 | Actual Loss: 0.0517\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6468\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4545\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4334\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5636\n",
      "Epoch 240/1000: Train Loss: 0.5070, Val Loss: 0.5246\n",
      "Baseline Loss: 2.6692 | Actual Loss: 0.3001\n",
      "Baseline Loss: 2.7028 | Actual Loss: 0.5290\n",
      "Baseline Loss: 2.6464 | Actual Loss: 0.2068\n",
      "Baseline Loss: 2.6711 | Actual Loss: 0.6701\n",
      "Baseline Loss: 2.6519 | Actual Loss: 0.3968\n",
      "Baseline Loss: 2.6518 | Actual Loss: 0.6409\n",
      "Baseline Loss: 2.6791 | Actual Loss: 0.3393\n",
      "Baseline Loss: 2.6732 | Actual Loss: 0.2984\n",
      "Baseline Loss: 2.7063 | Actual Loss: 0.1816\n",
      "Baseline Loss: 2.6614 | Actual Loss: 0.2669\n",
      "Baseline Loss: 2.6803 | Actual Loss: 0.4229\n",
      "Baseline Loss: 2.6797 | Actual Loss: 0.3256\n",
      "Baseline Loss: 2.6430 | Actual Loss: 0.4670\n",
      "Baseline Loss: 2.7238 | Actual Loss: 0.3790\n",
      "Baseline Loss: 2.7013 | Actual Loss: 0.4925\n",
      "Baseline Loss: 2.2417 | Actual Loss: 0.2325\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6847\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4921\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██▍       | 241/1000 [01:15<04:06,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6117 | Actual Loss: 0.4946\n",
      "Epoch 241/1000: Train Loss: 0.3843, Val Loss: 0.5190\n",
      "Baseline Loss: 2.6608 | Actual Loss: 0.4659\n",
      "Baseline Loss: 2.6662 | Actual Loss: 0.2030\n",
      "Baseline Loss: 2.7082 | Actual Loss: 0.2381\n",
      "Baseline Loss: 2.6677 | Actual Loss: 0.3704\n",
      "Baseline Loss: 2.6859 | Actual Loss: 0.2795\n",
      "Baseline Loss: 2.6467 | Actual Loss: 0.3951\n",
      "Baseline Loss: 2.6969 | Actual Loss: 0.4192\n",
      "Baseline Loss: 2.6665 | Actual Loss: 0.5717\n",
      "Baseline Loss: 2.6610 | Actual Loss: 0.7150\n",
      "Baseline Loss: 2.6519 | Actual Loss: 0.7326\n",
      "Baseline Loss: 2.6594 | Actual Loss: 0.3074\n",
      "Baseline Loss: 2.6839 | Actual Loss: 0.3798\n",
      "Baseline Loss: 2.6972 | Actual Loss: 0.1235\n",
      "Baseline Loss: 2.6562 | Actual Loss: 0.2957\n",
      "Baseline Loss: 2.6342 | Actual Loss: 0.3970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██▍       | 242/1000 [01:16<03:49,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2803 | Actual Loss: 0.2339\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6695\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4851\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3361\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.4617\n",
      "Epoch 242/1000: Train Loss: 0.3830, Val Loss: 0.4881\n",
      "Baseline Loss: 2.6686 | Actual Loss: 0.7216\n",
      "Baseline Loss: 2.7132 | Actual Loss: 0.5119\n",
      "Baseline Loss: 2.6587 | Actual Loss: 0.1358\n",
      "Baseline Loss: 2.6768 | Actual Loss: 0.6506\n",
      "Baseline Loss: 2.6951 | Actual Loss: 0.2758\n",
      "Baseline Loss: 2.6912 | Actual Loss: 0.3355\n",
      "Baseline Loss: 2.6726 | Actual Loss: 0.4474\n",
      "Baseline Loss: 2.6426 | Actual Loss: 0.2680\n",
      "Baseline Loss: 2.6637 | Actual Loss: 0.2248\n",
      "Baseline Loss: 2.6671 | Actual Loss: 0.7261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██▍       | 243/1000 [01:16<04:04,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6541 | Actual Loss: 0.5091\n",
      "Baseline Loss: 2.7549 | Actual Loss: 0.2289\n",
      "Baseline Loss: 2.6343 | Actual Loss: 0.4300\n",
      "Baseline Loss: 2.6661 | Actual Loss: 0.2967\n",
      "Baseline Loss: 2.6844 | Actual Loss: 0.3896\n",
      "Baseline Loss: 2.2551 | Actual Loss: 0.2761\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7146\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4662\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3764\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5055\n",
      "Epoch 243/1000: Train Loss: 0.4017, Val Loss: 0.5157\n",
      "Baseline Loss: 2.6890 | Actual Loss: 0.5113\n",
      "Baseline Loss: 2.6926 | Actual Loss: 0.5226\n",
      "Baseline Loss: 2.6669 | Actual Loss: 0.7611\n",
      "Baseline Loss: 2.6618 | Actual Loss: 0.3555\n",
      "Baseline Loss: 2.6931 | Actual Loss: 0.2692\n",
      "Baseline Loss: 2.6702 | Actual Loss: 0.1454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██▍       | 244/1000 [01:16<03:48,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6553 | Actual Loss: 0.5297\n",
      "Baseline Loss: 2.6866 | Actual Loss: 0.2492\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.4178\n",
      "Baseline Loss: 2.6762 | Actual Loss: 0.3815\n",
      "Baseline Loss: 2.7027 | Actual Loss: 0.3588\n",
      "Baseline Loss: 2.6305 | Actual Loss: 0.2568\n",
      "Baseline Loss: 2.7111 | Actual Loss: 0.4479\n",
      "Baseline Loss: 2.6478 | Actual Loss: 0.2814\n",
      "Baseline Loss: 2.6464 | Actual Loss: 0.3983\n",
      "Baseline Loss: 2.3740 | Actual Loss: 2.2268\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6503\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4567\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4425\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5526\n",
      "Epoch 244/1000: Train Loss: 0.5071, Val Loss: 0.5255\n",
      "Baseline Loss: 2.6867 | Actual Loss: 0.2818\n",
      "Baseline Loss: 2.6708 | Actual Loss: 0.3145\n",
      "Baseline Loss: 2.6743 | Actual Loss: 0.3300\n",
      "Baseline Loss: 2.6962 | Actual Loss: 0.5237\n",
      "Baseline Loss: 2.6549 | Actual Loss: 0.3893\n",
      "Baseline Loss: 2.6584 | Actual Loss: 0.8441\n",
      "Baseline Loss: 2.6566 | Actual Loss: 0.2324\n",
      "Baseline Loss: 2.6545 | Actual Loss: 0.3527\n",
      "Baseline Loss: 2.6714 | Actual Loss: 0.3031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██▍       | 245/1000 [01:17<03:56,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6678 | Actual Loss: 0.4666\n",
      "Baseline Loss: 2.6826 | Actual Loss: 0.2814\n",
      "Baseline Loss: 2.6818 | Actual Loss: 0.2521\n",
      "Baseline Loss: 2.7039 | Actual Loss: 0.2871\n",
      "Baseline Loss: 2.6862 | Actual Loss: 0.4978\n",
      "Baseline Loss: 2.6878 | Actual Loss: 0.6909\n",
      "Baseline Loss: 2.2712 | Actual Loss: 0.0586\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6630\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4451\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3002\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5235\n",
      "Epoch 245/1000: Train Loss: 0.3816, Val Loss: 0.4829\n",
      "Baseline Loss: 2.6879 | Actual Loss: 0.7774\n",
      "Baseline Loss: 2.6868 | Actual Loss: 0.2612\n",
      "Baseline Loss: 2.7247 | Actual Loss: 0.3601\n",
      "Baseline Loss: 2.6545 | Actual Loss: 1.9602\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.4668\n",
      "Baseline Loss: 2.6633 | Actual Loss: 0.3087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▍       | 246/1000 [01:17<03:47,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7057 | Actual Loss: 0.3184\n",
      "Baseline Loss: 2.6482 | Actual Loss: 0.4497\n",
      "Baseline Loss: 2.6911 | Actual Loss: 0.1542\n",
      "Baseline Loss: 2.6609 | Actual Loss: 0.5626\n",
      "Baseline Loss: 2.6937 | Actual Loss: 0.1439\n",
      "Baseline Loss: 2.6517 | Actual Loss: 0.5077\n",
      "Baseline Loss: 2.6630 | Actual Loss: 1.9703\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.2595\n",
      "Baseline Loss: 2.6557 | Actual Loss: 0.4177\n",
      "Baseline Loss: 2.2242 | Actual Loss: 0.0822\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.5779\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4655\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4391\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5328\n",
      "Epoch 246/1000: Train Loss: 0.5625, Val Loss: 0.5038\n",
      "Baseline Loss: 2.6727 | Actual Loss: 0.1388\n",
      "Baseline Loss: 2.6796 | Actual Loss: 0.2274\n",
      "Baseline Loss: 2.6368 | Actual Loss: 0.7306\n",
      "Baseline Loss: 2.7113 | Actual Loss: 0.5061\n",
      "Baseline Loss: 2.6981 | Actual Loss: 1.0864\n",
      "Baseline Loss: 2.6745 | Actual Loss: 0.1650\n",
      "Baseline Loss: 2.6910 | Actual Loss: 0.3453\n",
      "Baseline Loss: 2.6417 | Actual Loss: 0.3357\n",
      "Baseline Loss: 2.6761 | Actual Loss: 0.3653\n",
      "Baseline Loss: 2.6550 | Actual Loss: 0.3924\n",
      "Baseline Loss: 2.6725 | Actual Loss: 0.3602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▍       | 247/1000 [01:17<03:53,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6641 | Actual Loss: 0.4426\n",
      "Baseline Loss: 2.7064 | Actual Loss: 0.3834\n",
      "Baseline Loss: 2.6860 | Actual Loss: 0.5328\n",
      "Baseline Loss: 2.6762 | Actual Loss: 0.3769\n",
      "Baseline Loss: 2.2313 | Actual Loss: 0.4780\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6974\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4746\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4281\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5703\n",
      "Epoch 247/1000: Train Loss: 0.4292, Val Loss: 0.5426\n",
      "Baseline Loss: 2.6699 | Actual Loss: 0.3875\n",
      "Baseline Loss: 2.6579 | Actual Loss: 0.4134\n",
      "Baseline Loss: 2.6851 | Actual Loss: 0.4620\n",
      "Baseline Loss: 2.6654 | Actual Loss: 0.2168\n",
      "Baseline Loss: 2.7107 | Actual Loss: 0.5924\n",
      "Baseline Loss: 2.6824 | Actual Loss: 0.4957\n",
      "Baseline Loss: 2.6981 | Actual Loss: 0.5303\n",
      "Baseline Loss: 2.6765 | Actual Loss: 0.3499\n",
      "Baseline Loss: 2.6845 | Actual Loss: 0.5946\n",
      "Baseline Loss: 2.6770 | Actual Loss: 0.2787\n",
      "Baseline Loss: 2.7165 | Actual Loss: 0.1622\n",
      "Baseline Loss: 2.6546 | Actual Loss: 0.3879\n",
      "Baseline Loss: 2.6898 | Actual Loss: 0.6652\n",
      "Baseline Loss: 2.6767 | Actual Loss: 0.2678\n",
      "Baseline Loss: 2.6557 | Actual Loss: 0.3043\n",
      "Baseline Loss: 2.1990 | Actual Loss: 0.1278\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6787\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▍       | 248/1000 [01:18<04:01,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6840 | Actual Loss: 0.4364\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5326\n",
      "Epoch 248/1000: Train Loss: 0.3898, Val Loss: 0.5285\n",
      "Baseline Loss: 2.7135 | Actual Loss: 0.4473\n",
      "Baseline Loss: 2.6309 | Actual Loss: 0.1208\n",
      "Baseline Loss: 2.7016 | Actual Loss: 0.3301\n",
      "Baseline Loss: 2.6945 | Actual Loss: 0.3434\n",
      "Baseline Loss: 2.7021 | Actual Loss: 0.1529\n",
      "Baseline Loss: 2.6527 | Actual Loss: 0.5591\n",
      "Baseline Loss: 2.6696 | Actual Loss: 0.3501\n",
      "Baseline Loss: 2.6995 | Actual Loss: 0.2924\n",
      "Baseline Loss: 2.6282 | Actual Loss: 0.4260\n",
      "Baseline Loss: 2.6528 | Actual Loss: 0.4877\n",
      "Baseline Loss: 2.6866 | Actual Loss: 0.2573\n",
      "Baseline Loss: 2.6818 | Actual Loss: 0.2284\n",
      "Baseline Loss: 2.6503 | Actual Loss: 0.3228\n",
      "Baseline Loss: 2.6652 | Actual Loss: 0.5383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▍       | 249/1000 [01:18<03:49,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7022 | Actual Loss: 0.6282\n",
      "Baseline Loss: 2.3029 | Actual Loss: 0.2862\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6555\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4753\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4231\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5145\n",
      "Epoch 249/1000: Train Loss: 0.3607, Val Loss: 0.5171\n",
      "Baseline Loss: 2.6974 | Actual Loss: 0.3315\n",
      "Baseline Loss: 2.6478 | Actual Loss: 0.3568\n",
      "Baseline Loss: 2.6520 | Actual Loss: 0.4258\n",
      "Baseline Loss: 2.6504 | Actual Loss: 0.2683\n",
      "Baseline Loss: 2.6478 | Actual Loss: 1.5592\n",
      "Baseline Loss: 2.6841 | Actual Loss: 0.3758\n",
      "Baseline Loss: 2.7114 | Actual Loss: 0.3917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▌       | 250/1000 [01:18<03:59,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7141 | Actual Loss: 0.4437\n",
      "Baseline Loss: 2.6496 | Actual Loss: 0.2870\n",
      "Baseline Loss: 2.7226 | Actual Loss: 0.4262\n",
      "Baseline Loss: 2.6865 | Actual Loss: 0.7497\n",
      "Baseline Loss: 2.6692 | Actual Loss: 0.2683\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4376\n",
      "Baseline Loss: 2.6833 | Actual Loss: 0.6576\n",
      "Baseline Loss: 2.7038 | Actual Loss: 0.3249\n",
      "Baseline Loss: 2.2721 | Actual Loss: 2.1215\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7125\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4666\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4131\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5097\n",
      "Epoch 250/1000: Train Loss: 0.5891, Val Loss: 0.5255\n",
      "Baseline Loss: 2.6313 | Actual Loss: 0.6427\n",
      "Baseline Loss: 2.6598 | Actual Loss: 0.3973\n",
      "Baseline Loss: 2.6850 | Actual Loss: 0.6281\n",
      "Baseline Loss: 2.6518 | Actual Loss: 2.0806\n",
      "Baseline Loss: 2.6863 | Actual Loss: 0.6210\n",
      "Baseline Loss: 2.6851 | Actual Loss: 0.2360\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.2623\n",
      "Baseline Loss: 2.6774 | Actual Loss: 0.4175\n",
      "Baseline Loss: 2.7060 | Actual Loss: 0.2797\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3986\n",
      "Baseline Loss: 2.6404 | Actual Loss: 0.4238\n",
      "Baseline Loss: 2.7072 | Actual Loss: 0.7795\n",
      "Baseline Loss: 2.6468 | Actual Loss: 0.3837\n",
      "Baseline Loss: 2.6714 | Actual Loss: 0.1972\n",
      "Baseline Loss: 2.7377 | Actual Loss: 2.0522\n",
      "Baseline Loss: 2.2228 | Actual Loss: 0.2590\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▌       | 251/1000 [01:19<04:06,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6644 | Actual Loss: 0.4575\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4217\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5483\n",
      "Epoch 251/1000: Train Loss: 0.6287, Val Loss: 0.5115\n",
      "Baseline Loss: 2.7013 | Actual Loss: 0.4373\n",
      "Baseline Loss: 2.7162 | Actual Loss: 0.5389\n",
      "Baseline Loss: 2.6817 | Actual Loss: 0.6497\n",
      "Baseline Loss: 2.6703 | Actual Loss: 0.7680\n",
      "Baseline Loss: 2.6621 | Actual Loss: 0.2550\n",
      "Baseline Loss: 2.6541 | Actual Loss: 0.3581\n",
      "Baseline Loss: 2.6621 | Actual Loss: 0.4790\n",
      "Baseline Loss: 2.6826 | Actual Loss: 0.6863\n",
      "Baseline Loss: 2.6884 | Actual Loss: 0.2508\n",
      "Baseline Loss: 2.6770 | Actual Loss: 0.5549\n",
      "Baseline Loss: 2.6675 | Actual Loss: 0.4237\n",
      "Baseline Loss: 2.6683 | Actual Loss: 0.2039\n",
      "Baseline Loss: 2.6713 | Actual Loss: 0.2866\n",
      "Baseline Loss: 2.6665 | Actual Loss: 0.2314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▌       | 252/1000 [01:19<03:49,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6939 | Actual Loss: 0.2455\n",
      "Baseline Loss: 2.2273 | Actual Loss: 0.2240\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6266\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4932\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4067\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.4957\n",
      "Epoch 252/1000: Train Loss: 0.4121, Val Loss: 0.5056\n",
      "Baseline Loss: 2.6872 | Actual Loss: 0.7759\n",
      "Baseline Loss: 2.6764 | Actual Loss: 0.3629\n",
      "Baseline Loss: 2.6918 | Actual Loss: 0.5409\n",
      "Baseline Loss: 2.6767 | Actual Loss: 0.5318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▌       | 253/1000 [01:19<03:51,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6934 | Actual Loss: 0.2844\n",
      "Baseline Loss: 2.6797 | Actual Loss: 0.4343\n",
      "Baseline Loss: 2.6800 | Actual Loss: 0.5068\n",
      "Baseline Loss: 2.6603 | Actual Loss: 0.5769\n",
      "Baseline Loss: 2.6346 | Actual Loss: 0.5915\n",
      "Baseline Loss: 2.6610 | Actual Loss: 0.5268\n",
      "Baseline Loss: 2.6391 | Actual Loss: 0.4065\n",
      "Baseline Loss: 2.6891 | Actual Loss: 0.7659\n",
      "Baseline Loss: 2.7231 | Actual Loss: 0.1921\n",
      "Baseline Loss: 2.6744 | Actual Loss: 0.1978\n",
      "Baseline Loss: 2.6999 | Actual Loss: 0.4792\n",
      "Baseline Loss: 2.2341 | Actual Loss: 1.8084\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6752\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4905\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3648\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.6369\n",
      "Epoch 253/1000: Train Loss: 0.5614, Val Loss: 0.5419\n",
      "Baseline Loss: 2.7199 | Actual Loss: 0.3331\n",
      "Baseline Loss: 2.6872 | Actual Loss: 0.1411\n",
      "Baseline Loss: 2.6901 | Actual Loss: 0.6605\n",
      "Baseline Loss: 2.6826 | Actual Loss: 0.4377\n",
      "Baseline Loss: 2.6375 | Actual Loss: 0.8484\n",
      "Baseline Loss: 2.6560 | Actual Loss: 0.4378\n",
      "Baseline Loss: 2.6925 | Actual Loss: 0.1362\n",
      "Baseline Loss: 2.6761 | Actual Loss: 0.9788\n",
      "Baseline Loss: 2.6410 | Actual Loss: 0.3289\n",
      "Baseline Loss: 2.6665 | Actual Loss: 0.1633\n",
      "Baseline Loss: 2.6847 | Actual Loss: 0.2650\n",
      "Baseline Loss: 2.6636 | Actual Loss: 0.2178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▌       | 254/1000 [01:20<04:02,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6717 | Actual Loss: 0.5310\n",
      "Baseline Loss: 2.6402 | Actual Loss: 0.4003\n",
      "Baseline Loss: 2.6612 | Actual Loss: 0.4792\n",
      "Baseline Loss: 2.2885 | Actual Loss: 0.1471\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6984\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4641\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3950\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5377\n",
      "Epoch 254/1000: Train Loss: 0.4066, Val Loss: 0.5238\n",
      "Baseline Loss: 2.6607 | Actual Loss: 1.9648\n",
      "Baseline Loss: 2.7135 | Actual Loss: 0.4180\n",
      "Baseline Loss: 2.6799 | Actual Loss: 0.1990\n",
      "Baseline Loss: 2.6997 | Actual Loss: 0.4016\n",
      "Baseline Loss: 2.6450 | Actual Loss: 0.3020\n",
      "Baseline Loss: 2.6890 | Actual Loss: 0.2057\n",
      "Baseline Loss: 2.6349 | Actual Loss: 0.4974\n",
      "Baseline Loss: 2.6762 | Actual Loss: 0.4526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▌       | 255/1000 [01:20<03:45,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6529 | Actual Loss: 0.3201\n",
      "Baseline Loss: 2.6326 | Actual Loss: 1.0886\n",
      "Baseline Loss: 2.6813 | Actual Loss: 1.1165\n",
      "Baseline Loss: 2.7013 | Actual Loss: 0.5879\n",
      "Baseline Loss: 2.6804 | Actual Loss: 0.4672\n",
      "Baseline Loss: 2.6571 | Actual Loss: 0.7180\n",
      "Baseline Loss: 2.6798 | Actual Loss: 0.3347\n",
      "Baseline Loss: 2.2776 | Actual Loss: 1.7365\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6396\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4509\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4142\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5387\n",
      "Epoch 255/1000: Train Loss: 0.6757, Val Loss: 0.5108\n",
      "Baseline Loss: 2.6356 | Actual Loss: 0.1975\n",
      "Baseline Loss: 2.6615 | Actual Loss: 0.4229\n",
      "Baseline Loss: 2.6487 | Actual Loss: 0.4194\n",
      "Baseline Loss: 2.6900 | Actual Loss: 0.4482\n",
      "Baseline Loss: 2.6750 | Actual Loss: 0.3813\n",
      "Baseline Loss: 2.6590 | Actual Loss: 0.5138\n",
      "Baseline Loss: 2.7073 | Actual Loss: 0.6886\n",
      "Baseline Loss: 2.6923 | Actual Loss: 0.3872\n",
      "Baseline Loss: 2.6860 | Actual Loss: 0.4111\n",
      "Baseline Loss: 2.6810 | Actual Loss: 0.5941\n",
      "Baseline Loss: 2.7001 | Actual Loss: 0.2551\n",
      "Baseline Loss: 2.6759 | Actual Loss: 0.2712\n",
      "Baseline Loss: 2.6845 | Actual Loss: 0.3854\n",
      "Baseline Loss: 2.6558 | Actual Loss: 0.6615\n",
      "Baseline Loss: 2.6579 | Actual Loss: 0.6329\n",
      "Baseline Loss: 2.2211 | Actual Loss: 0.1681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▌       | 256/1000 [01:20<03:51,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6907 | Actual Loss: 0.6425\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4472\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4018\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5238\n",
      "Epoch 256/1000: Train Loss: 0.4274, Val Loss: 0.5038\n",
      "Baseline Loss: 2.6478 | Actual Loss: 0.1791\n",
      "Baseline Loss: 2.6523 | Actual Loss: 0.1796\n",
      "Baseline Loss: 2.6642 | Actual Loss: 0.3777\n",
      "Baseline Loss: 2.7088 | Actual Loss: 0.8149\n",
      "Baseline Loss: 2.6961 | Actual Loss: 0.4110\n",
      "Baseline Loss: 2.6795 | Actual Loss: 0.3561\n",
      "Baseline Loss: 2.6833 | Actual Loss: 1.0971\n",
      "Baseline Loss: 2.6321 | Actual Loss: 0.4941\n",
      "Baseline Loss: 2.6689 | Actual Loss: 0.4590\n",
      "Baseline Loss: 2.6602 | Actual Loss: 0.3049\n",
      "Baseline Loss: 2.6715 | Actual Loss: 0.5795\n",
      "Baseline Loss: 2.6968 | Actual Loss: 0.5653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▌       | 257/1000 [01:20<04:01,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6956 | Actual Loss: 0.5435\n",
      "Baseline Loss: 2.6772 | Actual Loss: 0.1824\n",
      "Baseline Loss: 2.6898 | Actual Loss: 0.5704\n",
      "Baseline Loss: 2.2005 | Actual Loss: 0.1136\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6868\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.5109\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3745\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5432\n",
      "Epoch 257/1000: Train Loss: 0.4518, Val Loss: 0.5289\n",
      "Baseline Loss: 2.6764 | Actual Loss: 0.4453\n",
      "Baseline Loss: 2.6583 | Actual Loss: 0.3612\n",
      "Baseline Loss: 2.6318 | Actual Loss: 0.4087\n",
      "Baseline Loss: 2.6819 | Actual Loss: 0.4810\n",
      "Baseline Loss: 2.6512 | Actual Loss: 0.4754\n",
      "Baseline Loss: 2.6676 | Actual Loss: 0.5556\n",
      "Baseline Loss: 2.6893 | Actual Loss: 1.2399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▌       | 258/1000 [01:21<03:44,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7072 | Actual Loss: 0.5713\n",
      "Baseline Loss: 2.6209 | Actual Loss: 0.3030\n",
      "Baseline Loss: 2.6626 | Actual Loss: 0.5918\n",
      "Baseline Loss: 2.6614 | Actual Loss: 0.2826\n",
      "Baseline Loss: 2.7156 | Actual Loss: 0.2603\n",
      "Baseline Loss: 2.6560 | Actual Loss: 0.2828\n",
      "Baseline Loss: 2.7265 | Actual Loss: 0.4806\n",
      "Baseline Loss: 2.7269 | Actual Loss: 0.4408\n",
      "Baseline Loss: 2.2791 | Actual Loss: 0.1400\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6040\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4775\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4141\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5379\n",
      "Epoch 258/1000: Train Loss: 0.4575, Val Loss: 0.5084\n",
      "Baseline Loss: 2.6569 | Actual Loss: 0.5003\n",
      "Baseline Loss: 2.6972 | Actual Loss: 0.4363\n",
      "Baseline Loss: 2.6768 | Actual Loss: 0.4787\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.6983\n",
      "Baseline Loss: 2.6676 | Actual Loss: 0.2640\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.2074\n",
      "Baseline Loss: 2.6936 | Actual Loss: 0.5032\n",
      "Baseline Loss: 2.6563 | Actual Loss: 0.3468\n",
      "Baseline Loss: 2.6735 | Actual Loss: 0.1281\n",
      "Baseline Loss: 2.6406 | Actual Loss: 0.1831\n",
      "Baseline Loss: 2.6804 | Actual Loss: 0.4192\n",
      "Baseline Loss: 2.7376 | Actual Loss: 0.1490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▌       | 259/1000 [01:21<03:57,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6504 | Actual Loss: 1.2434\n",
      "Baseline Loss: 2.6531 | Actual Loss: 0.5088\n",
      "Baseline Loss: 2.6302 | Actual Loss: 0.4370\n",
      "Baseline Loss: 2.2169 | Actual Loss: 0.3840\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6761\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4607\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3838\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5332\n",
      "Epoch 259/1000: Train Loss: 0.4305, Val Loss: 0.5135\n",
      "Baseline Loss: 2.6612 | Actual Loss: 0.1949\n",
      "Baseline Loss: 2.6253 | Actual Loss: 0.3990\n",
      "Baseline Loss: 2.6565 | Actual Loss: 0.2608\n",
      "Baseline Loss: 2.6571 | Actual Loss: 0.4349\n",
      "Baseline Loss: 2.6922 | Actual Loss: 0.4261\n",
      "Baseline Loss: 2.6920 | Actual Loss: 0.6316\n",
      "Baseline Loss: 2.6685 | Actual Loss: 0.3297\n",
      "Baseline Loss: 2.6954 | Actual Loss: 0.5432\n",
      "Baseline Loss: 2.6752 | Actual Loss: 1.6721\n",
      "Baseline Loss: 2.7016 | Actual Loss: 0.4316\n",
      "Baseline Loss: 2.7069 | Actual Loss: 0.4153\n",
      "Baseline Loss: 2.6996 | Actual Loss: 0.5812\n",
      "Baseline Loss: 2.6706 | Actual Loss: 0.5764\n",
      "Baseline Loss: 2.6546 | Actual Loss: 0.4428\n",
      "Baseline Loss: 2.6708 | Actual Loss: 0.4721\n",
      "Baseline Loss: 2.2429 | Actual Loss: 0.1237\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6870\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4659\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.2894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▌       | 260/1000 [01:21<03:59,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6117 | Actual Loss: 0.5427\n",
      "Epoch 260/1000: Train Loss: 0.4960, Val Loss: 0.4963\n",
      "Baseline Loss: 2.6854 | Actual Loss: 0.6983\n",
      "Baseline Loss: 2.6522 | Actual Loss: 0.4895\n",
      "Baseline Loss: 2.6712 | Actual Loss: 0.3666\n",
      "Baseline Loss: 2.6849 | Actual Loss: 0.5421\n",
      "Baseline Loss: 2.7107 | Actual Loss: 0.5167\n",
      "Baseline Loss: 2.6802 | Actual Loss: 0.4095\n",
      "Baseline Loss: 2.6951 | Actual Loss: 0.4670\n",
      "Baseline Loss: 2.6621 | Actual Loss: 0.4752\n",
      "Baseline Loss: 2.6571 | Actual Loss: 0.9481\n",
      "Baseline Loss: 2.6749 | Actual Loss: 0.5855\n",
      "Baseline Loss: 2.6499 | Actual Loss: 0.3019\n",
      "Baseline Loss: 2.6502 | Actual Loss: 0.1973\n",
      "Baseline Loss: 2.7171 | Actual Loss: 0.4178\n",
      "Baseline Loss: 2.6940 | Actual Loss: 0.1560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▌       | 261/1000 [01:22<03:42,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6920 | Actual Loss: 0.3042\n",
      "Baseline Loss: 2.2632 | Actual Loss: 0.0651\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6101\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4521\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4242\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5748\n",
      "Epoch 261/1000: Train Loss: 0.4338, Val Loss: 0.5153\n",
      "Baseline Loss: 2.6798 | Actual Loss: 0.3947\n",
      "Baseline Loss: 2.6504 | Actual Loss: 0.4753\n",
      "Baseline Loss: 2.6975 | Actual Loss: 0.3673\n",
      "Baseline Loss: 2.7106 | Actual Loss: 0.2299\n",
      "Baseline Loss: 2.6460 | Actual Loss: 0.3843\n",
      "Baseline Loss: 2.6240 | Actual Loss: 0.5192\n",
      "Baseline Loss: 2.6920 | Actual Loss: 0.3006\n",
      "Baseline Loss: 2.7023 | Actual Loss: 0.3136\n",
      "Baseline Loss: 2.6730 | Actual Loss: 0.2554\n",
      "Baseline Loss: 2.6855 | Actual Loss: 0.1606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▌       | 262/1000 [01:22<03:53,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6573 | Actual Loss: 0.3910\n",
      "Baseline Loss: 2.6596 | Actual Loss: 0.8811\n",
      "Baseline Loss: 2.6986 | Actual Loss: 0.3954\n",
      "Baseline Loss: 2.6799 | Actual Loss: 0.4750\n",
      "Baseline Loss: 2.6488 | Actual Loss: 0.4571\n",
      "Baseline Loss: 2.3406 | Actual Loss: 0.1046\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6589\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4967\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3342\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5811\n",
      "Epoch 262/1000: Train Loss: 0.3816, Val Loss: 0.5177\n",
      "Baseline Loss: 2.6629 | Actual Loss: 0.6242\n",
      "Baseline Loss: 2.6796 | Actual Loss: 0.4108\n",
      "Baseline Loss: 2.7394 | Actual Loss: 0.2734\n",
      "Baseline Loss: 2.6495 | Actual Loss: 0.9250\n",
      "Baseline Loss: 2.7171 | Actual Loss: 0.5896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▋       | 263/1000 [01:22<03:38,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6966 | Actual Loss: 0.3769\n",
      "Baseline Loss: 2.7073 | Actual Loss: 0.4303\n",
      "Baseline Loss: 2.6450 | Actual Loss: 0.2366\n",
      "Baseline Loss: 2.6829 | Actual Loss: 0.1761\n",
      "Baseline Loss: 2.6882 | Actual Loss: 0.5453\n",
      "Baseline Loss: 2.6791 | Actual Loss: 0.5506\n",
      "Baseline Loss: 2.6585 | Actual Loss: 0.3786\n",
      "Baseline Loss: 2.6510 | Actual Loss: 0.3849\n",
      "Baseline Loss: 2.6742 | Actual Loss: 0.3687\n",
      "Baseline Loss: 2.6578 | Actual Loss: 0.1536\n",
      "Baseline Loss: 2.2637 | Actual Loss: 0.1008\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6524\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.5181\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3347\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5085\n",
      "Epoch 263/1000: Train Loss: 0.4078, Val Loss: 0.5034\n",
      "Baseline Loss: 2.6749 | Actual Loss: 1.1282\n",
      "Baseline Loss: 2.6658 | Actual Loss: 0.6170\n",
      "Baseline Loss: 2.6544 | Actual Loss: 0.5986\n",
      "Baseline Loss: 2.6315 | Actual Loss: 0.4400\n",
      "Baseline Loss: 2.6457 | Actual Loss: 0.2384\n",
      "Baseline Loss: 2.6946 | Actual Loss: 0.7287\n",
      "Baseline Loss: 2.6939 | Actual Loss: 0.3189\n",
      "Baseline Loss: 2.6490 | Actual Loss: 0.4556\n",
      "Baseline Loss: 2.6993 | Actual Loss: 0.2587\n",
      "Baseline Loss: 2.6618 | Actual Loss: 0.4986\n",
      "Baseline Loss: 2.6844 | Actual Loss: 0.5247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▋       | 264/1000 [01:23<03:54,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7137 | Actual Loss: 0.2628\n",
      "Baseline Loss: 2.7194 | Actual Loss: 0.4414\n",
      "Baseline Loss: 2.6721 | Actual Loss: 0.3272\n",
      "Baseline Loss: 2.7203 | Actual Loss: 0.3982\n",
      "Baseline Loss: 2.2596 | Actual Loss: 0.0571\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.5844\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4493\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3857\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5428\n",
      "Epoch 264/1000: Train Loss: 0.4559, Val Loss: 0.4906\n",
      "Baseline Loss: 2.6518 | Actual Loss: 0.4579\n",
      "Baseline Loss: 2.6951 | Actual Loss: 0.4167\n",
      "Baseline Loss: 2.6612 | Actual Loss: 0.5461\n",
      "Baseline Loss: 2.6932 | Actual Loss: 0.3524\n",
      "Baseline Loss: 2.6935 | Actual Loss: 0.5252\n",
      "Baseline Loss: 2.6490 | Actual Loss: 0.3854\n",
      "Baseline Loss: 2.6370 | Actual Loss: 0.4885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▋       | 265/1000 [01:23<03:38,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6333 | Actual Loss: 0.6826\n",
      "Baseline Loss: 2.6650 | Actual Loss: 0.3329\n",
      "Baseline Loss: 2.6686 | Actual Loss: 0.2664\n",
      "Baseline Loss: 2.6883 | Actual Loss: 0.3271\n",
      "Baseline Loss: 2.6564 | Actual Loss: 0.2708\n",
      "Baseline Loss: 2.6986 | Actual Loss: 0.5562\n",
      "Baseline Loss: 2.6946 | Actual Loss: 0.3468\n",
      "Baseline Loss: 2.6669 | Actual Loss: 0.2134\n",
      "Baseline Loss: 2.2847 | Actual Loss: 0.5602\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6546\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4641\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.2878\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5523\n",
      "Epoch 265/1000: Train Loss: 0.4205, Val Loss: 0.4897\n",
      "Baseline Loss: 2.6893 | Actual Loss: 0.2436\n",
      "Baseline Loss: 2.6872 | Actual Loss: 0.4933\n",
      "Baseline Loss: 2.6736 | Actual Loss: 0.2736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▋       | 265/1000 [01:23<03:52,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6646 | Actual Loss: 0.2092\n",
      "Baseline Loss: 2.6302 | Actual Loss: 2.2699\n",
      "Baseline Loss: 2.6849 | Actual Loss: 0.3528\n",
      "Baseline Loss: 2.7086 | Actual Loss: 1.7494\n",
      "Baseline Loss: 2.6819 | Actual Loss: 0.1957\n",
      "Baseline Loss: 2.6730 | Actual Loss: 0.3833\n",
      "Baseline Loss: 2.6784 | Actual Loss: 0.1811\n",
      "Baseline Loss: 2.6571 | Actual Loss: 0.3466\n",
      "Baseline Loss: 2.6822 | Actual Loss: 0.5580\n",
      "Baseline Loss: 2.6681 | Actual Loss: 0.5698\n",
      "Baseline Loss: 2.6877 | Actual Loss: 0.4240\n",
      "Baseline Loss: 2.6405 | Actual Loss: 0.3858\n",
      "Baseline Loss: 2.2525 | Actual Loss: 0.4777\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.6807\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4953\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3731\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.5924\n",
      "Epoch 266/1000: Train Loss: 0.5696, Val Loss: 0.5354\n",
      "\n",
      "Early stopping at epoch 266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.46241509169340134"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.train_model(\n",
    "    data_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e0fc12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = GNNModelWithNewLoss(\n",
    "        num_node_features=data_list[0].x.shape[1],\n",
    "        num_edge_features=data_list[0].edge_attr.shape[1],\n",
    "        num_global_features=data_list[0].global_features.shape[1],\n",
    "        hidden_dim=512,\n",
    "        dropout_rate=0.1,\n",
    "        property_index=2,\n",
    "        save_path=\"premodels_new/3/2\"\n",
    "    ).to(devices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71b665fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training will be saved to: premodels_new/3/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7516 | Actual Loss: 3.7907\n",
      "Baseline Loss: 3.5003 | Actual Loss: 3.4160\n",
      "Baseline Loss: 3.6642 | Actual Loss: 3.6173\n",
      "Baseline Loss: 3.4354 | Actual Loss: 3.3968\n",
      "Baseline Loss: 3.5289 | Actual Loss: 3.4906\n",
      "Baseline Loss: 3.3720 | Actual Loss: 3.3464\n",
      "Baseline Loss: 3.5612 | Actual Loss: 3.4342\n",
      "Baseline Loss: 3.5053 | Actual Loss: 3.4701\n",
      "Baseline Loss: 3.5872 | Actual Loss: 3.4695\n",
      "Baseline Loss: 3.3300 | Actual Loss: 3.3152\n",
      "Baseline Loss: 3.4520 | Actual Loss: 3.4374\n",
      "Baseline Loss: 3.6878 | Actual Loss: 3.5693\n",
      "Baseline Loss: 3.3999 | Actual Loss: 3.3396\n",
      "Baseline Loss: 3.4364 | Actual Loss: 3.4163\n",
      "Baseline Loss: 3.7118 | Actual Loss: 3.6832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 1/1000 [00:00<06:21,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6889 | Actual Loss: 3.5366\n",
      "Baseline Loss: 3.5212 | Actual Loss: 3.5102\n",
      "Baseline Loss: 3.6101 | Actual Loss: 3.5703\n",
      "Baseline Loss: 3.5170 | Actual Loss: 3.3816\n",
      "Baseline Loss: 3.3188 | Actual Loss: 3.2627\n",
      "Epoch 1/1000: Train Loss: 3.4831, Val Loss: 3.4312\n",
      "New best validation loss: 3.4312\n",
      "Baseline Loss: 3.3517 | Actual Loss: 3.3375\n",
      "Baseline Loss: 3.5092 | Actual Loss: 3.4229\n",
      "Baseline Loss: 3.3857 | Actual Loss: 3.2859\n",
      "Baseline Loss: 3.5093 | Actual Loss: 3.4714\n",
      "Baseline Loss: 3.6272 | Actual Loss: 3.4575\n",
      "Baseline Loss: 3.4805 | Actual Loss: 3.3285\n",
      "Baseline Loss: 3.6317 | Actual Loss: 3.5365\n",
      "Baseline Loss: 3.6421 | Actual Loss: 3.5676\n",
      "Baseline Loss: 3.6138 | Actual Loss: 3.5306\n",
      "Baseline Loss: 3.3854 | Actual Loss: 3.3399\n",
      "Baseline Loss: 3.7731 | Actual Loss: 3.6832\n",
      "Baseline Loss: 3.6451 | Actual Loss: 3.5443\n",
      "Baseline Loss: 3.3988 | Actual Loss: 3.3138\n",
      "Baseline Loss: 3.5126 | Actual Loss: 3.4400\n",
      "Baseline Loss: 3.5747 | Actual Loss: 3.3060\n",
      "Baseline Loss: 3.4021 | Actual Loss: 3.2581\n",
      "Baseline Loss: 3.5212 | Actual Loss: 3.4576\n",
      "Baseline Loss: 3.6101 | Actual Loss: 3.4453\n",
      "Baseline Loss: 3.5170 | Actual Loss: 3.2457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 2/1000 [00:00<05:23,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3188 | Actual Loss: 3.1133\n",
      "Epoch 2/1000: Train Loss: 3.4265, Val Loss: 3.3155\n",
      "New best validation loss: 3.3155\n",
      "Baseline Loss: 3.4429 | Actual Loss: 3.3400\n",
      "Baseline Loss: 3.4668 | Actual Loss: 3.4036\n",
      "Baseline Loss: 3.4972 | Actual Loss: 3.2989\n",
      "Baseline Loss: 3.7073 | Actual Loss: 3.5641\n",
      "Baseline Loss: 3.6875 | Actual Loss: 3.5351\n",
      "Baseline Loss: 3.3101 | Actual Loss: 3.2147\n",
      "Baseline Loss: 3.5703 | Actual Loss: 3.3710\n",
      "Baseline Loss: 3.5202 | Actual Loss: 3.4597\n",
      "Baseline Loss: 3.4033 | Actual Loss: 3.2374\n",
      "Baseline Loss: 3.5534 | Actual Loss: 3.3742\n",
      "Baseline Loss: 3.5132 | Actual Loss: 3.1674\n",
      "Baseline Loss: 3.5293 | Actual Loss: 3.3244\n",
      "Baseline Loss: 3.4884 | Actual Loss: 3.2273\n",
      "Baseline Loss: 3.5088 | Actual Loss: 3.4002\n",
      "Baseline Loss: 3.5746 | Actual Loss: 3.4374\n",
      "Baseline Loss: 3.2728 | Actual Loss: 2.8364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 3/1000 [00:01<06:24,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5212 | Actual Loss: 3.5013\n",
      "Baseline Loss: 3.6101 | Actual Loss: 3.1550\n",
      "Baseline Loss: 3.5170 | Actual Loss: 3.3079\n",
      "Baseline Loss: 3.3188 | Actual Loss: 2.8401\n",
      "Epoch 3/1000: Train Loss: 3.3245, Val Loss: 3.2011\n",
      "New best validation loss: 3.2011\n",
      "Baseline Loss: 3.4578 | Actual Loss: 3.3094\n",
      "Baseline Loss: 3.6831 | Actual Loss: 3.3516\n",
      "Baseline Loss: 3.3922 | Actual Loss: 3.0076\n",
      "Baseline Loss: 3.5213 | Actual Loss: 3.2078\n",
      "Baseline Loss: 3.7417 | Actual Loss: 3.6445\n",
      "Baseline Loss: 3.5916 | Actual Loss: 3.2093\n",
      "Baseline Loss: 3.5087 | Actual Loss: 2.9992\n",
      "Baseline Loss: 3.6405 | Actual Loss: 3.1220\n",
      "Baseline Loss: 3.5051 | Actual Loss: 2.9651\n",
      "Baseline Loss: 3.6091 | Actual Loss: 3.2696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 4/1000 [00:01<06:00,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5578 | Actual Loss: 2.8604\n",
      "Baseline Loss: 3.3378 | Actual Loss: 2.7541\n",
      "Baseline Loss: 3.4738 | Actual Loss: 2.9670\n",
      "Baseline Loss: 3.4465 | Actual Loss: 2.9194\n",
      "Baseline Loss: 3.5499 | Actual Loss: 2.8927\n",
      "Baseline Loss: 3.1821 | Actual Loss: 2.4182\n",
      "Baseline Loss: 3.5212 | Actual Loss: 2.6627\n",
      "Baseline Loss: 3.6101 | Actual Loss: 2.4962\n",
      "Baseline Loss: 3.5170 | Actual Loss: 2.9422\n",
      "Baseline Loss: 3.3188 | Actual Loss: 2.3950\n",
      "Epoch 4/1000: Train Loss: 3.0561, Val Loss: 2.6240\n",
      "New best validation loss: 2.6240\n",
      "Baseline Loss: 3.5167 | Actual Loss: 2.7404\n",
      "Baseline Loss: 3.5168 | Actual Loss: 2.4566\n",
      "Baseline Loss: 3.5965 | Actual Loss: 2.7512\n",
      "Baseline Loss: 3.6229 | Actual Loss: 2.4860\n",
      "Baseline Loss: 3.4804 | Actual Loss: 2.5515\n",
      "Baseline Loss: 3.5415 | Actual Loss: 2.8322\n",
      "Baseline Loss: 3.4511 | Actual Loss: 2.7500\n",
      "Baseline Loss: 3.3442 | Actual Loss: 2.0162\n",
      "Baseline Loss: 3.4654 | Actual Loss: 2.1089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 5/1000 [00:01<06:15,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3298 | Actual Loss: 2.8875\n",
      "Baseline Loss: 3.7673 | Actual Loss: 2.4209\n",
      "Baseline Loss: 3.4965 | Actual Loss: 2.4596\n",
      "Baseline Loss: 3.5415 | Actual Loss: 2.1841\n",
      "Baseline Loss: 3.6694 | Actual Loss: 2.3368\n",
      "Baseline Loss: 3.6684 | Actual Loss: 2.3682\n",
      "Baseline Loss: 3.1883 | Actual Loss: 1.9677\n",
      "Baseline Loss: 3.5212 | Actual Loss: 1.8995\n",
      "Baseline Loss: 3.6101 | Actual Loss: 2.2571\n",
      "Baseline Loss: 3.5170 | Actual Loss: 2.0944\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.8004\n",
      "Epoch 5/1000: Train Loss: 2.4574, Val Loss: 2.0128\n",
      "New best validation loss: 2.0128\n",
      "Baseline Loss: 3.5324 | Actual Loss: 2.5249\n",
      "Baseline Loss: 3.2462 | Actual Loss: 2.6614\n",
      "Baseline Loss: 3.5623 | Actual Loss: 2.1318\n",
      "Baseline Loss: 3.5662 | Actual Loss: 1.9778\n",
      "Baseline Loss: 3.6638 | Actual Loss: 2.0505\n",
      "Baseline Loss: 3.5014 | Actual Loss: 2.8786\n",
      "Baseline Loss: 3.7319 | Actual Loss: 2.3224\n",
      "Baseline Loss: 3.7881 | Actual Loss: 1.5229\n",
      "Baseline Loss: 3.5173 | Actual Loss: 1.8557\n",
      "Baseline Loss: 3.5212 | Actual Loss: 2.1327\n",
      "Baseline Loss: 3.6598 | Actual Loss: 2.4134\n",
      "Baseline Loss: 3.3341 | Actual Loss: 1.6763\n",
      "Baseline Loss: 3.4277 | Actual Loss: 2.1332\n",
      "Baseline Loss: 3.6184 | Actual Loss: 2.6033\n",
      "Baseline Loss: 3.4814 | Actual Loss: 2.6022\n",
      "Baseline Loss: 3.3220 | Actual Loss: 2.3961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 6/1000 [00:02<06:38,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5212 | Actual Loss: 1.7502\n",
      "Baseline Loss: 3.6101 | Actual Loss: 2.0536\n",
      "Baseline Loss: 3.5170 | Actual Loss: 2.0972\n",
      "Baseline Loss: 3.3188 | Actual Loss: 2.1414\n",
      "Epoch 6/1000: Train Loss: 2.2427, Val Loss: 2.0106\n",
      "New best validation loss: 2.0106\n",
      "Baseline Loss: 3.4616 | Actual Loss: 1.7705\n",
      "Baseline Loss: 3.4360 | Actual Loss: 2.2351\n",
      "Baseline Loss: 3.4465 | Actual Loss: 2.4228\n",
      "Baseline Loss: 3.3374 | Actual Loss: 2.0682\n",
      "Baseline Loss: 3.6010 | Actual Loss: 3.0268\n",
      "Baseline Loss: 3.6456 | Actual Loss: 2.1770\n",
      "Baseline Loss: 3.4735 | Actual Loss: 2.1371\n",
      "Baseline Loss: 3.4857 | Actual Loss: 1.9709\n",
      "Baseline Loss: 3.8900 | Actual Loss: 2.1728\n",
      "Baseline Loss: 3.6278 | Actual Loss: 2.0635\n",
      "Baseline Loss: 3.7429 | Actual Loss: 2.3938\n",
      "Baseline Loss: 3.6549 | Actual Loss: 1.8477\n",
      "Baseline Loss: 3.6142 | Actual Loss: 2.3741\n",
      "Baseline Loss: 3.3543 | Actual Loss: 1.9847\n",
      "Baseline Loss: 3.4741 | Actual Loss: 2.2080\n",
      "Baseline Loss: 3.1609 | Actual Loss: 1.2102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 7/1000 [00:02<06:18,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5212 | Actual Loss: 1.5983\n",
      "Baseline Loss: 3.6101 | Actual Loss: 1.4795\n",
      "Baseline Loss: 3.5170 | Actual Loss: 2.2835\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.7850\n",
      "Epoch 7/1000: Train Loss: 2.1290, Val Loss: 1.7866\n",
      "New best validation loss: 1.7866\n",
      "Baseline Loss: 3.5967 | Actual Loss: 2.7353\n",
      "Baseline Loss: 3.4467 | Actual Loss: 2.0076\n",
      "Baseline Loss: 3.5173 | Actual Loss: 2.5208\n",
      "Baseline Loss: 3.3877 | Actual Loss: 1.9104\n",
      "Baseline Loss: 3.4852 | Actual Loss: 2.1693\n",
      "Baseline Loss: 3.5247 | Actual Loss: 2.7900\n",
      "Baseline Loss: 3.7625 | Actual Loss: 2.4285\n",
      "Baseline Loss: 3.4311 | Actual Loss: 2.3008\n",
      "Baseline Loss: 3.5324 | Actual Loss: 2.4478\n",
      "Baseline Loss: 3.5016 | Actual Loss: 2.1521\n",
      "Baseline Loss: 3.4548 | Actual Loss: 1.8358\n",
      "Baseline Loss: 3.4849 | Actual Loss: 1.9898\n",
      "Baseline Loss: 3.6318 | Actual Loss: 1.6662\n",
      "Baseline Loss: 3.6052 | Actual Loss: 1.5771\n",
      "Baseline Loss: 3.5125 | Actual Loss: 1.8754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 8/1000 [00:03<06:30,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4884 | Actual Loss: 2.2595\n",
      "Baseline Loss: 3.5212 | Actual Loss: 1.4966\n",
      "Baseline Loss: 3.6101 | Actual Loss: 1.6294\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.9343\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.8646\n",
      "Epoch 8/1000: Train Loss: 2.1667, Val Loss: 1.7312\n",
      "New best validation loss: 1.7312\n",
      "Baseline Loss: 3.4539 | Actual Loss: 2.6808\n",
      "Baseline Loss: 3.5012 | Actual Loss: 2.0462\n",
      "Baseline Loss: 3.4474 | Actual Loss: 2.1709\n",
      "Baseline Loss: 3.3712 | Actual Loss: 1.7920\n",
      "Baseline Loss: 3.4666 | Actual Loss: 2.5626\n",
      "Baseline Loss: 3.4539 | Actual Loss: 2.0122\n",
      "Baseline Loss: 3.5700 | Actual Loss: 1.8619\n",
      "Baseline Loss: 3.5830 | Actual Loss: 1.8893\n",
      "Baseline Loss: 3.5421 | Actual Loss: 1.4896\n",
      "Baseline Loss: 3.6229 | Actual Loss: 2.4225\n",
      "Baseline Loss: 3.6594 | Actual Loss: 1.5968\n",
      "Baseline Loss: 3.4942 | Actual Loss: 2.1383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 9/1000 [00:03<06:00,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6415 | Actual Loss: 2.0864\n",
      "Baseline Loss: 3.4581 | Actual Loss: 1.9172\n",
      "Baseline Loss: 3.6369 | Actual Loss: 1.8360\n",
      "Baseline Loss: 3.1517 | Actual Loss: 1.5336\n",
      "Baseline Loss: 3.5212 | Actual Loss: 1.5577\n",
      "Baseline Loss: 3.6101 | Actual Loss: 1.4790\n",
      "Baseline Loss: 3.5170 | Actual Loss: 2.4819\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.8097\n",
      "Epoch 9/1000: Train Loss: 2.0023, Val Loss: 1.8320\n",
      "Baseline Loss: 3.5281 | Actual Loss: 1.9628\n",
      "Baseline Loss: 3.5828 | Actual Loss: 2.2468\n",
      "Baseline Loss: 3.6232 | Actual Loss: 2.0390\n",
      "Baseline Loss: 3.6509 | Actual Loss: 2.1431\n",
      "Baseline Loss: 3.8492 | Actual Loss: 1.8374\n",
      "Baseline Loss: 3.4284 | Actual Loss: 1.6783\n",
      "Baseline Loss: 3.4662 | Actual Loss: 2.0930\n",
      "Baseline Loss: 3.5664 | Actual Loss: 1.9421\n",
      "Baseline Loss: 3.5083 | Actual Loss: 1.3608\n",
      "Baseline Loss: 3.4362 | Actual Loss: 1.6253\n",
      "Baseline Loss: 3.5292 | Actual Loss: 1.9719\n",
      "Baseline Loss: 3.5618 | Actual Loss: 2.7656\n",
      "Baseline Loss: 3.4544 | Actual Loss: 1.8596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 10/1000 [00:03<06:24,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4541 | Actual Loss: 1.4644\n",
      "Baseline Loss: 3.4620 | Actual Loss: 1.8557\n",
      "Baseline Loss: 3.4795 | Actual Loss: 1.5745\n",
      "Baseline Loss: 3.5212 | Actual Loss: 1.1896\n",
      "Baseline Loss: 3.6101 | Actual Loss: 1.7436\n",
      "Baseline Loss: 3.5170 | Actual Loss: 2.1299\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.8300\n",
      "Epoch 10/1000: Train Loss: 1.9013, Val Loss: 1.7233\n",
      "New best validation loss: 1.7233\n",
      "Baseline Loss: 3.3013 | Actual Loss: 2.0203\n",
      "Baseline Loss: 3.5569 | Actual Loss: 1.4073\n",
      "Baseline Loss: 3.4579 | Actual Loss: 1.4757\n",
      "Baseline Loss: 3.6497 | Actual Loss: 1.3198\n",
      "Baseline Loss: 3.4284 | Actual Loss: 1.7672\n",
      "Baseline Loss: 3.5150 | Actual Loss: 1.7846\n",
      "Baseline Loss: 3.4284 | Actual Loss: 1.5777\n",
      "Baseline Loss: 3.9318 | Actual Loss: 2.6588\n",
      "Baseline Loss: 3.4929 | Actual Loss: 1.6592\n",
      "Baseline Loss: 3.5008 | Actual Loss: 1.7976\n",
      "Baseline Loss: 3.4695 | Actual Loss: 2.0389\n",
      "Baseline Loss: 3.6454 | Actual Loss: 1.8241\n",
      "Baseline Loss: 3.5088 | Actual Loss: 1.8238\n",
      "Baseline Loss: 3.7784 | Actual Loss: 2.3237\n",
      "Baseline Loss: 3.4815 | Actual Loss: 1.6410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 11/1000 [00:04<06:19,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4494 | Actual Loss: 1.8929\n",
      "Baseline Loss: 3.5212 | Actual Loss: 1.5485\n",
      "Baseline Loss: 3.6101 | Actual Loss: 1.1130\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.9154\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.5460\n",
      "Epoch 11/1000: Train Loss: 1.8133, Val Loss: 1.5307\n",
      "New best validation loss: 1.5307\n",
      "Baseline Loss: 3.6461 | Actual Loss: 1.9495\n",
      "Baseline Loss: 3.7371 | Actual Loss: 1.3086\n",
      "Baseline Loss: 3.4430 | Actual Loss: 1.8173\n",
      "Baseline Loss: 3.3442 | Actual Loss: 1.6099\n",
      "Baseline Loss: 3.6602 | Actual Loss: 1.7236\n",
      "Baseline Loss: 3.6925 | Actual Loss: 1.6511\n",
      "Baseline Loss: 3.4471 | Actual Loss: 1.7497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 12/1000 [00:04<06:03,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4874 | Actual Loss: 2.0986\n",
      "Baseline Loss: 3.5699 | Actual Loss: 1.5035\n",
      "Baseline Loss: 3.5332 | Actual Loss: 1.8605\n",
      "Baseline Loss: 3.4517 | Actual Loss: 1.7600\n",
      "Baseline Loss: 3.5332 | Actual Loss: 2.1675\n",
      "Baseline Loss: 3.3640 | Actual Loss: 2.0382\n",
      "Baseline Loss: 3.3279 | Actual Loss: 1.5197\n",
      "Baseline Loss: 3.6884 | Actual Loss: 2.1365\n",
      "Baseline Loss: 3.4306 | Actual Loss: 1.7629\n",
      "Baseline Loss: 3.5212 | Actual Loss: 1.3872\n",
      "Baseline Loss: 3.6101 | Actual Loss: 1.2259\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.8025\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.6453\n",
      "Epoch 12/1000: Train Loss: 1.7911, Val Loss: 1.5152\n",
      "New best validation loss: 1.5152\n",
      "Baseline Loss: 3.4248 | Actual Loss: 1.5880\n",
      "Baseline Loss: 3.2791 | Actual Loss: 1.2432\n",
      "Baseline Loss: 3.3304 | Actual Loss: 1.4315\n",
      "Baseline Loss: 3.4728 | Actual Loss: 2.3095\n",
      "Baseline Loss: 3.5161 | Actual Loss: 1.7527\n",
      "Baseline Loss: 3.5011 | Actual Loss: 1.5606\n",
      "Baseline Loss: 3.5086 | Actual Loss: 1.5017\n",
      "Baseline Loss: 3.6404 | Actual Loss: 1.9095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏         | 13/1000 [00:04<06:15,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7214 | Actual Loss: 2.2591\n",
      "Baseline Loss: 3.5043 | Actual Loss: 1.9553\n",
      "Baseline Loss: 3.4693 | Actual Loss: 1.5735\n",
      "Baseline Loss: 3.4967 | Actual Loss: 1.7359\n",
      "Baseline Loss: 3.5204 | Actual Loss: 1.6608\n",
      "Baseline Loss: 3.6834 | Actual Loss: 2.3044\n",
      "Baseline Loss: 3.5709 | Actual Loss: 1.7033\n",
      "Baseline Loss: 3.0201 | Actual Loss: 1.9184\n",
      "Baseline Loss: 3.5212 | Actual Loss: 1.3052\n",
      "Baseline Loss: 3.6101 | Actual Loss: 1.5956\n",
      "Baseline Loss: 3.5170 | Actual Loss: 2.0181\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.6987\n",
      "Epoch 13/1000: Train Loss: 1.7755, Val Loss: 1.6544\n",
      "Baseline Loss: 3.7728 | Actual Loss: 1.9907\n",
      "Baseline Loss: 3.7121 | Actual Loss: 1.6308\n",
      "Baseline Loss: 3.4000 | Actual Loss: 1.5469\n",
      "Baseline Loss: 3.5528 | Actual Loss: 1.6831\n",
      "Baseline Loss: 3.4473 | Actual Loss: 2.0164\n",
      "Baseline Loss: 3.4211 | Actual Loss: 1.7258\n",
      "Baseline Loss: 3.5703 | Actual Loss: 1.6405\n",
      "Baseline Loss: 3.5543 | Actual Loss: 1.6636\n",
      "Baseline Loss: 3.6278 | Actual Loss: 1.9016\n",
      "Baseline Loss: 3.7941 | Actual Loss: 1.5682\n",
      "Baseline Loss: 3.4919 | Actual Loss: 1.8973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏         | 14/1000 [00:05<06:24,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4549 | Actual Loss: 1.8036\n",
      "Baseline Loss: 3.5377 | Actual Loss: 2.1980\n",
      "Baseline Loss: 3.2665 | Actual Loss: 1.7748\n",
      "Baseline Loss: 3.5172 | Actual Loss: 1.3033\n",
      "Baseline Loss: 3.4115 | Actual Loss: 1.9058\n",
      "Baseline Loss: 3.5212 | Actual Loss: 1.2933\n",
      "Baseline Loss: 3.6101 | Actual Loss: 1.5606\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.9756\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.7550\n",
      "Epoch 14/1000: Train Loss: 1.7657, Val Loss: 1.6461\n",
      "Baseline Loss: 3.5367 | Actual Loss: 2.1947\n",
      "Baseline Loss: 3.5281 | Actual Loss: 1.7121\n",
      "Baseline Loss: 3.5586 | Actual Loss: 1.5469\n",
      "Baseline Loss: 3.5409 | Actual Loss: 1.6651\n",
      "Baseline Loss: 3.5457 | Actual Loss: 1.7911\n",
      "Baseline Loss: 3.4969 | Actual Loss: 1.2509\n",
      "Baseline Loss: 3.4064 | Actual Loss: 1.8365\n",
      "Baseline Loss: 3.4189 | Actual Loss: 1.4208\n",
      "Baseline Loss: 3.6317 | Actual Loss: 2.5840\n",
      "Baseline Loss: 3.5162 | Actual Loss: 1.8573\n",
      "Baseline Loss: 3.5833 | Actual Loss: 2.3593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 15/1000 [00:05<06:14,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7423 | Actual Loss: 1.4842\n",
      "Baseline Loss: 3.3955 | Actual Loss: 2.2958\n",
      "Baseline Loss: 3.4464 | Actual Loss: 1.4552\n",
      "Baseline Loss: 3.6553 | Actual Loss: 1.8335\n",
      "Baseline Loss: 3.6292 | Actual Loss: 1.8223\n",
      "Baseline Loss: 3.5212 | Actual Loss: 1.4260\n",
      "Baseline Loss: 3.6101 | Actual Loss: 1.5163\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.9729\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.6107\n",
      "Epoch 15/1000: Train Loss: 1.8194, Val Loss: 1.6315\n",
      "Baseline Loss: 3.6600 | Actual Loss: 1.7393\n",
      "Baseline Loss: 3.5786 | Actual Loss: 1.6670\n",
      "Baseline Loss: 3.7629 | Actual Loss: 1.6893\n",
      "Baseline Loss: 3.5753 | Actual Loss: 1.9488\n",
      "Baseline Loss: 3.4463 | Actual Loss: 1.5894\n",
      "Baseline Loss: 3.5282 | Actual Loss: 1.8582\n",
      "Baseline Loss: 3.3931 | Actual Loss: 1.6460\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.5400\n",
      "Baseline Loss: 3.2659 | Actual Loss: 1.6629\n",
      "Baseline Loss: 3.4585 | Actual Loss: 1.8265\n",
      "Baseline Loss: 3.5630 | Actual Loss: 1.8842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 16/1000 [00:06<06:25,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4738 | Actual Loss: 1.8123\n",
      "Baseline Loss: 3.5320 | Actual Loss: 2.0515\n",
      "Baseline Loss: 3.8045 | Actual Loss: 1.4561\n",
      "Baseline Loss: 3.7127 | Actual Loss: 1.1520\n",
      "Baseline Loss: 3.2974 | Actual Loss: 1.1450\n",
      "Baseline Loss: 3.5212 | Actual Loss: 1.3971\n",
      "Baseline Loss: 3.6101 | Actual Loss: 1.2963\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.8632\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.4757\n",
      "Epoch 16/1000: Train Loss: 1.6668, Val Loss: 1.5081\n",
      "New best validation loss: 1.5081\n",
      "Baseline Loss: 3.3964 | Actual Loss: 2.0594\n",
      "Baseline Loss: 3.5877 | Actual Loss: 1.6820\n",
      "Baseline Loss: 3.5367 | Actual Loss: 1.6964\n",
      "Baseline Loss: 3.4179 | Actual Loss: 1.6422\n",
      "Baseline Loss: 3.5753 | Actual Loss: 1.3097\n",
      "Baseline Loss: 3.6185 | Actual Loss: 2.2906\n",
      "Baseline Loss: 3.4773 | Actual Loss: 1.7038\n",
      "Baseline Loss: 3.8262 | Actual Loss: 1.5745\n",
      "Baseline Loss: 3.6923 | Actual Loss: 1.1656\n",
      "Baseline Loss: 3.4702 | Actual Loss: 1.4671\n",
      "Baseline Loss: 3.6272 | Actual Loss: 1.2631\n",
      "Baseline Loss: 3.5790 | Actual Loss: 2.4716\n",
      "Baseline Loss: 3.3995 | Actual Loss: 1.6329\n",
      "Baseline Loss: 3.4617 | Actual Loss: 1.9572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 17/1000 [00:06<06:18,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5751 | Actual Loss: 1.9585\n",
      "Baseline Loss: 3.1971 | Actual Loss: 1.5716\n",
      "Baseline Loss: 3.5212 | Actual Loss: 1.2991\n",
      "Baseline Loss: 3.6101 | Actual Loss: 1.3537\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.7424\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.7147\n",
      "Epoch 17/1000: Train Loss: 1.7154, Val Loss: 1.5275\n",
      "Baseline Loss: 3.3919 | Actual Loss: 2.0325\n",
      "Baseline Loss: 3.6103 | Actual Loss: 1.8359\n",
      "Baseline Loss: 3.5874 | Actual Loss: 1.6203\n",
      "Baseline Loss: 3.6593 | Actual Loss: 1.6307\n",
      "Baseline Loss: 3.5415 | Actual Loss: 1.3857\n",
      "Baseline Loss: 3.7224 | Actual Loss: 1.8304\n",
      "Baseline Loss: 3.6184 | Actual Loss: 1.4060\n",
      "Baseline Loss: 3.4510 | Actual Loss: 1.7593\n",
      "Baseline Loss: 3.5245 | Actual Loss: 1.1784\n",
      "Baseline Loss: 3.5579 | Actual Loss: 1.9403\n",
      "Baseline Loss: 3.3447 | Actual Loss: 1.6052\n",
      "Baseline Loss: 3.6883 | Actual Loss: 1.8358\n",
      "Baseline Loss: 3.3576 | Actual Loss: 1.4991\n",
      "Baseline Loss: 3.6319 | Actual Loss: 2.4986\n",
      "Baseline Loss: 3.4585 | Actual Loss: 1.3408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 18/1000 [00:06<06:39,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.2019 | Actual Loss: 1.0463\n",
      "Baseline Loss: 3.5212 | Actual Loss: 1.1240\n",
      "Baseline Loss: 3.6101 | Actual Loss: 1.1031\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.7960\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.6999\n",
      "Epoch 18/1000: Train Loss: 1.6528, Val Loss: 1.4308\n",
      "New best validation loss: 1.4308\n",
      "Baseline Loss: 3.5453 | Actual Loss: 2.1529\n",
      "Baseline Loss: 3.7268 | Actual Loss: 2.0852\n",
      "Baseline Loss: 3.5879 | Actual Loss: 1.4096\n",
      "Baseline Loss: 3.3548 | Actual Loss: 1.5269\n",
      "Baseline Loss: 3.3167 | Actual Loss: 1.4212\n",
      "Baseline Loss: 3.5584 | Actual Loss: 1.8417\n",
      "Baseline Loss: 3.5008 | Actual Loss: 1.9605\n",
      "Baseline Loss: 3.5161 | Actual Loss: 1.1907\n",
      "Baseline Loss: 3.6321 | Actual Loss: 1.4816\n",
      "Baseline Loss: 3.3753 | Actual Loss: 1.8372\n",
      "Baseline Loss: 3.5373 | Actual Loss: 1.6403\n",
      "Baseline Loss: 3.6152 | Actual Loss: 1.9144\n",
      "Baseline Loss: 3.3274 | Actual Loss: 1.5414\n",
      "Baseline Loss: 3.4103 | Actual Loss: 1.8992\n",
      "Baseline Loss: 3.6101 | Actual Loss: 1.7694\n",
      "Baseline Loss: 3.2980 | Actual Loss: 1.8594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 19/1000 [00:07<06:46,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5212 | Actual Loss: 1.1910\n",
      "Baseline Loss: 3.6101 | Actual Loss: 1.1772\n",
      "Baseline Loss: 3.5170 | Actual Loss: 2.2357\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.5258\n",
      "Epoch 19/1000: Train Loss: 1.7207, Val Loss: 1.5324\n",
      "Baseline Loss: 3.3849 | Actual Loss: 1.6029\n",
      "Baseline Loss: 3.8378 | Actual Loss: 1.1990\n",
      "Baseline Loss: 3.5331 | Actual Loss: 2.2326\n",
      "Baseline Loss: 3.5503 | Actual Loss: 1.3822\n",
      "Baseline Loss: 3.4583 | Actual Loss: 1.7193\n",
      "Baseline Loss: 3.6781 | Actual Loss: 1.9723\n",
      "Baseline Loss: 3.5456 | Actual Loss: 2.1345\n",
      "Baseline Loss: 3.5872 | Actual Loss: 2.5047\n",
      "Baseline Loss: 3.5918 | Actual Loss: 1.5476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 20/1000 [00:07<06:35,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5371 | Actual Loss: 1.1864\n",
      "Baseline Loss: 3.4700 | Actual Loss: 1.4984\n",
      "Baseline Loss: 3.5626 | Actual Loss: 1.4547\n",
      "Baseline Loss: 3.5703 | Actual Loss: 1.5667\n",
      "Baseline Loss: 3.2760 | Actual Loss: 1.7651\n",
      "Baseline Loss: 3.4178 | Actual Loss: 1.5196\n",
      "Baseline Loss: 3.4115 | Actual Loss: 1.2714\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.9579\n",
      "Baseline Loss: 3.6101 | Actual Loss: 1.0851\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.6787\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.4089\n",
      "Epoch 20/1000: Train Loss: 1.6598, Val Loss: 1.2827\n",
      "New best validation loss: 1.2827\n",
      "Baseline Loss: 3.6044 | Actual Loss: 1.9060\n",
      "Baseline Loss: 3.5088 | Actual Loss: 1.7915\n",
      "Baseline Loss: 3.7169 | Actual Loss: 1.5828\n",
      "Baseline Loss: 3.5042 | Actual Loss: 1.6472\n",
      "Baseline Loss: 3.5581 | Actual Loss: 2.4884\n",
      "Baseline Loss: 3.5534 | Actual Loss: 1.3161\n",
      "Baseline Loss: 3.4923 | Actual Loss: 2.3008\n",
      "Baseline Loss: 3.5010 | Actual Loss: 1.5004\n",
      "Baseline Loss: 3.7937 | Actual Loss: 2.0541\n",
      "Baseline Loss: 3.4534 | Actual Loss: 1.6402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 21/1000 [00:08<06:35,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5089 | Actual Loss: 1.7178\n",
      "Baseline Loss: 3.3076 | Actual Loss: 1.4536\n",
      "Baseline Loss: 3.5201 | Actual Loss: 1.3891\n",
      "Baseline Loss: 3.5922 | Actual Loss: 1.3646\n",
      "Baseline Loss: 3.6972 | Actual Loss: 1.2725\n",
      "Baseline Loss: 3.0579 | Actual Loss: 1.2761\n",
      "Baseline Loss: 3.5212 | Actual Loss: 1.2129\n",
      "Baseline Loss: 3.6101 | Actual Loss: 1.3336\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.9308\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.4735\n",
      "Epoch 21/1000: Train Loss: 1.6688, Val Loss: 1.4877\n",
      "Baseline Loss: 3.6096 | Actual Loss: 1.3035\n",
      "Baseline Loss: 3.5624 | Actual Loss: 1.7248\n",
      "Baseline Loss: 3.4019 | Actual Loss: 1.6663\n",
      "Baseline Loss: 3.4177 | Actual Loss: 1.4270\n",
      "Baseline Loss: 3.4329 | Actual Loss: 1.9937\n",
      "Baseline Loss: 3.4966 | Actual Loss: 1.3927\n",
      "Baseline Loss: 3.6922 | Actual Loss: 2.2531\n",
      "Baseline Loss: 3.6055 | Actual Loss: 1.8165\n",
      "Baseline Loss: 3.6313 | Actual Loss: 0.9823\n",
      "Baseline Loss: 3.5461 | Actual Loss: 1.7953\n",
      "Baseline Loss: 3.5695 | Actual Loss: 1.5319\n",
      "Baseline Loss: 3.7521 | Actual Loss: 1.5724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 22/1000 [00:08<06:22,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6460 | Actual Loss: 1.5611\n",
      "Baseline Loss: 3.5012 | Actual Loss: 1.7971\n",
      "Baseline Loss: 3.2574 | Actual Loss: 1.4598\n",
      "Baseline Loss: 3.2485 | Actual Loss: 0.9048\n",
      "Baseline Loss: 3.5212 | Actual Loss: 1.1862\n",
      "Baseline Loss: 3.6101 | Actual Loss: 1.0816\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.5243\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.5927\n",
      "Epoch 22/1000: Train Loss: 1.5739, Val Loss: 1.3462\n",
      "Baseline Loss: 3.7993 | Actual Loss: 1.8335\n",
      "Baseline Loss: 3.5371 | Actual Loss: 1.2250\n",
      "Baseline Loss: 3.5051 | Actual Loss: 1.1968\n",
      "Baseline Loss: 3.4208 | Actual Loss: 1.6216\n",
      "Baseline Loss: 3.3819 | Actual Loss: 1.7938\n",
      "Baseline Loss: 3.4820 | Actual Loss: 1.8083\n",
      "Baseline Loss: 3.6009 | Actual Loss: 1.4313\n",
      "Baseline Loss: 3.4734 | Actual Loss: 1.5657\n",
      "Baseline Loss: 3.4469 | Actual Loss: 1.4810\n",
      "Baseline Loss: 3.3373 | Actual Loss: 1.2549\n",
      "Baseline Loss: 3.5919 | Actual Loss: 1.2975\n",
      "Baseline Loss: 3.5324 | Actual Loss: 1.9867\n",
      "Baseline Loss: 3.5834 | Actual Loss: 1.7162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 23/1000 [00:08<06:30,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6411 | Actual Loss: 2.5962\n",
      "Baseline Loss: 3.7996 | Actual Loss: 1.2163\n",
      "Baseline Loss: 3.6292 | Actual Loss: 2.1452\n",
      "Baseline Loss: 3.5212 | Actual Loss: 1.0545\n",
      "Baseline Loss: 3.6101 | Actual Loss: 1.1955\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.9010\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.4971\n",
      "Epoch 23/1000: Train Loss: 1.6356, Val Loss: 1.4120\n",
      "Baseline Loss: 3.5752 | Actual Loss: 1.3321\n",
      "Baseline Loss: 3.3723 | Actual Loss: 1.9807\n",
      "Baseline Loss: 3.5668 | Actual Loss: 2.2948\n",
      "Baseline Loss: 3.8269 | Actual Loss: 1.9316\n",
      "Baseline Loss: 3.6055 | Actual Loss: 1.6139\n",
      "Baseline Loss: 3.4469 | Actual Loss: 1.7389\n",
      "Baseline Loss: 3.6182 | Actual Loss: 1.3648\n",
      "Baseline Loss: 3.6049 | Actual Loss: 1.7540\n",
      "Baseline Loss: 3.3239 | Actual Loss: 1.5736\n",
      "Baseline Loss: 3.3730 | Actual Loss: 1.2770\n",
      "Baseline Loss: 3.5619 | Actual Loss: 1.2659\n",
      "Baseline Loss: 3.6358 | Actual Loss: 1.2189\n",
      "Baseline Loss: 3.4650 | Actual Loss: 1.7264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 24/1000 [00:09<06:38,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6087 | Actual Loss: 1.2089\n",
      "Baseline Loss: 3.4923 | Actual Loss: 2.2166\n",
      "Baseline Loss: 3.2032 | Actual Loss: 1.1375\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.9345\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.9436\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.7386\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.5658\n",
      "Epoch 24/1000: Train Loss: 1.6022, Val Loss: 1.2956\n",
      "Baseline Loss: 3.5125 | Actual Loss: 1.5324\n",
      "Baseline Loss: 3.6411 | Actual Loss: 1.2756\n",
      "Baseline Loss: 3.5614 | Actual Loss: 1.7941\n",
      "Baseline Loss: 3.4928 | Actual Loss: 1.9040\n",
      "Baseline Loss: 3.3046 | Actual Loss: 1.6984\n",
      "Baseline Loss: 3.4661 | Actual Loss: 1.5679\n",
      "Baseline Loss: 3.6786 | Actual Loss: 1.5174\n",
      "Baseline Loss: 3.4843 | Actual Loss: 1.5799\n",
      "Baseline Loss: 3.5254 | Actual Loss: 1.8909\n",
      "Baseline Loss: 3.5250 | Actual Loss: 1.8064\n",
      "Baseline Loss: 3.6008 | Actual Loss: 1.8345\n",
      "Baseline Loss: 3.4614 | Actual Loss: 1.2241\n",
      "Baseline Loss: 3.7322 | Actual Loss: 2.1139\n",
      "Baseline Loss: 3.4098 | Actual Loss: 1.5251\n",
      "Baseline Loss: 3.3891 | Actual Loss: 1.4626\n",
      "Baseline Loss: 3.2326 | Actual Loss: 0.8057\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.8821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▎         | 25/1000 [00:09<06:27,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6101 | Actual Loss: 1.1593\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.6013\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.3324\n",
      "Epoch 25/1000: Train Loss: 1.5958, Val Loss: 1.2438\n",
      "New best validation loss: 1.2438\n",
      "Baseline Loss: 3.6925 | Actual Loss: 1.7004\n",
      "Baseline Loss: 3.6834 | Actual Loss: 1.7679\n",
      "Baseline Loss: 3.4928 | Actual Loss: 2.0916\n",
      "Baseline Loss: 3.2621 | Actual Loss: 1.0586\n",
      "Baseline Loss: 3.3918 | Actual Loss: 1.1001\n",
      "Baseline Loss: 3.6228 | Actual Loss: 1.7241\n",
      "Baseline Loss: 3.4544 | Actual Loss: 2.0165\n",
      "Baseline Loss: 3.5914 | Actual Loss: 1.3288\n",
      "Baseline Loss: 3.4816 | Actual Loss: 1.8701\n",
      "Baseline Loss: 3.6545 | Actual Loss: 1.2321\n",
      "Baseline Loss: 3.5250 | Actual Loss: 1.6488\n",
      "Baseline Loss: 3.6410 | Actual Loss: 1.4650\n",
      "Baseline Loss: 3.2646 | Actual Loss: 1.5935\n",
      "Baseline Loss: 3.5961 | Actual Loss: 2.1599\n",
      "Baseline Loss: 3.5288 | Actual Loss: 1.3119\n",
      "Baseline Loss: 3.5301 | Actual Loss: 2.1959\n",
      "Baseline Loss: 3.5212 | Actual Loss: 1.0445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 26/1000 [00:10<06:45,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6101 | Actual Loss: 1.2723\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.7616\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.5797\n",
      "Epoch 26/1000: Train Loss: 1.6416, Val Loss: 1.4145\n",
      "Baseline Loss: 3.6319 | Actual Loss: 1.2009\n",
      "Baseline Loss: 3.5529 | Actual Loss: 1.4289\n",
      "Baseline Loss: 3.5054 | Actual Loss: 1.3469\n",
      "Baseline Loss: 3.5285 | Actual Loss: 1.8352\n",
      "Baseline Loss: 3.4139 | Actual Loss: 1.3772\n",
      "Baseline Loss: 3.6228 | Actual Loss: 1.2978\n",
      "Baseline Loss: 3.6004 | Actual Loss: 1.3347\n",
      "Baseline Loss: 3.3118 | Actual Loss: 1.8508\n",
      "Baseline Loss: 3.5629 | Actual Loss: 2.2934\n",
      "Baseline Loss: 3.7677 | Actual Loss: 1.3258\n",
      "Baseline Loss: 3.5292 | Actual Loss: 1.2762\n",
      "Baseline Loss: 3.6503 | Actual Loss: 2.0934\n",
      "Baseline Loss: 3.6875 | Actual Loss: 0.7232\n",
      "Baseline Loss: 3.6586 | Actual Loss: 1.6157\n",
      "Baseline Loss: 3.5059 | Actual Loss: 1.4369\n",
      "Baseline Loss: 3.2035 | Actual Loss: 1.2928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 27/1000 [00:10<06:50,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5212 | Actual Loss: 1.0196\n",
      "Baseline Loss: 3.6101 | Actual Loss: 1.1177\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.4445\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.4645\n",
      "Epoch 27/1000: Train Loss: 1.4831, Val Loss: 1.2616\n",
      "Baseline Loss: 3.6733 | Actual Loss: 1.2850\n",
      "Baseline Loss: 3.3994 | Actual Loss: 1.4168\n",
      "Baseline Loss: 3.5253 | Actual Loss: 1.5494\n",
      "Baseline Loss: 3.5789 | Actual Loss: 1.3225\n",
      "Baseline Loss: 3.8957 | Actual Loss: 1.7733\n",
      "Baseline Loss: 3.4542 | Actual Loss: 1.4832\n",
      "Baseline Loss: 3.7786 | Actual Loss: 1.6158\n",
      "Baseline Loss: 3.5840 | Actual Loss: 1.4203\n",
      "Baseline Loss: 3.3723 | Actual Loss: 1.6726\n",
      "Baseline Loss: 3.3569 | Actual Loss: 1.7486\n",
      "Baseline Loss: 3.4620 | Actual Loss: 1.5387\n",
      "Baseline Loss: 3.6868 | Actual Loss: 1.6777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 28/1000 [00:10<06:11,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5088 | Actual Loss: 1.1355\n",
      "Baseline Loss: 3.2663 | Actual Loss: 1.3210\n",
      "Baseline Loss: 3.3674 | Actual Loss: 1.3978\n",
      "Baseline Loss: 3.2810 | Actual Loss: 1.5323\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.8635\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.9486\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.5415\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.3300\n",
      "Epoch 28/1000: Train Loss: 1.4932, Val Loss: 1.1709\n",
      "New best validation loss: 1.1709\n",
      "Baseline Loss: 3.5705 | Actual Loss: 1.0531\n",
      "Baseline Loss: 3.5043 | Actual Loss: 1.3108\n",
      "Baseline Loss: 3.4062 | Actual Loss: 1.5400\n",
      "Baseline Loss: 3.5377 | Actual Loss: 1.8441\n",
      "Baseline Loss: 3.6226 | Actual Loss: 1.4356\n",
      "Baseline Loss: 3.5207 | Actual Loss: 1.5501\n",
      "Baseline Loss: 3.4281 | Actual Loss: 1.0009\n",
      "Baseline Loss: 3.7731 | Actual Loss: 1.1713\n",
      "Baseline Loss: 3.6049 | Actual Loss: 2.1983\n",
      "Baseline Loss: 3.4577 | Actual Loss: 1.8234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 29/1000 [00:11<06:17,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6742 | Actual Loss: 1.9047\n",
      "Baseline Loss: 3.5581 | Actual Loss: 1.4300\n",
      "Baseline Loss: 3.6458 | Actual Loss: 1.2744\n",
      "Baseline Loss: 3.5537 | Actual Loss: 1.3796\n",
      "Baseline Loss: 3.4140 | Actual Loss: 1.3003\n",
      "Baseline Loss: 3.1442 | Actual Loss: 0.7188\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.9401\n",
      "Baseline Loss: 3.6101 | Actual Loss: 1.1744\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.6834\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.6074\n",
      "Epoch 29/1000: Train Loss: 1.4335, Val Loss: 1.3513\n",
      "Baseline Loss: 3.6224 | Actual Loss: 0.9751\n",
      "Baseline Loss: 3.8104 | Actual Loss: 1.7132\n",
      "Baseline Loss: 3.6309 | Actual Loss: 1.1122\n",
      "Baseline Loss: 3.5489 | Actual Loss: 1.0954\n",
      "Baseline Loss: 3.4621 | Actual Loss: 1.1958\n",
      "Baseline Loss: 3.4966 | Actual Loss: 1.9450\n",
      "Baseline Loss: 3.5370 | Actual Loss: 1.7894\n",
      "Baseline Loss: 3.4283 | Actual Loss: 1.2578\n",
      "Baseline Loss: 3.4544 | Actual Loss: 2.2400\n",
      "Baseline Loss: 3.4205 | Actual Loss: 1.6247\n",
      "Baseline Loss: 3.7520 | Actual Loss: 1.4206\n",
      "Baseline Loss: 3.9316 | Actual Loss: 2.0299\n",
      "Baseline Loss: 3.5284 | Actual Loss: 1.0985\n",
      "Baseline Loss: 3.3048 | Actual Loss: 1.2751\n",
      "Baseline Loss: 3.4172 | Actual Loss: 1.5779\n",
      "Baseline Loss: 3.5619 | Actual Loss: 1.4280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 30/1000 [00:11<06:10,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5212 | Actual Loss: 0.9523\n",
      "Baseline Loss: 3.6101 | Actual Loss: 1.1620\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.6708\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.5770\n",
      "Epoch 30/1000: Train Loss: 1.4861, Val Loss: 1.3405\n",
      "Baseline Loss: 3.6592 | Actual Loss: 1.3305\n",
      "Baseline Loss: 3.5049 | Actual Loss: 1.4368\n",
      "Baseline Loss: 3.5625 | Actual Loss: 1.4727\n",
      "Baseline Loss: 3.7078 | Actual Loss: 1.1278\n",
      "Baseline Loss: 3.4505 | Actual Loss: 1.6687\n",
      "Baseline Loss: 3.3548 | Actual Loss: 1.4491\n",
      "Baseline Loss: 3.5168 | Actual Loss: 1.5757\n",
      "Baseline Loss: 3.6694 | Actual Loss: 1.4798\n",
      "Baseline Loss: 3.4431 | Actual Loss: 1.7751\n",
      "Baseline Loss: 3.7782 | Actual Loss: 1.2253\n",
      "Baseline Loss: 3.3982 | Actual Loss: 2.3456\n",
      "Baseline Loss: 3.4804 | Actual Loss: 2.0327\n",
      "Baseline Loss: 3.5703 | Actual Loss: 1.3881\n",
      "Baseline Loss: 3.2977 | Actual Loss: 1.3880\n",
      "Baseline Loss: 3.7838 | Actual Loss: 0.9321\n",
      "Baseline Loss: 3.3485 | Actual Loss: 1.1695\n",
      "Baseline Loss: 3.5212 | Actual Loss: 1.0230\n",
      "Baseline Loss: 3.6101 | Actual Loss: 1.1631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 31/1000 [00:12<06:08,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5170 | Actual Loss: 1.7192\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.4585\n",
      "Epoch 31/1000: Train Loss: 1.4873, Val Loss: 1.3409\n",
      "Baseline Loss: 3.4036 | Actual Loss: 1.4334\n",
      "Baseline Loss: 3.5082 | Actual Loss: 0.9975\n",
      "Baseline Loss: 3.5097 | Actual Loss: 1.2681\n",
      "Baseline Loss: 3.5960 | Actual Loss: 1.3540\n",
      "Baseline Loss: 3.4500 | Actual Loss: 1.2403\n",
      "Baseline Loss: 3.4854 | Actual Loss: 1.5362\n",
      "Baseline Loss: 3.4136 | Actual Loss: 1.3834\n",
      "Baseline Loss: 3.6409 | Actual Loss: 2.3912\n",
      "Baseline Loss: 3.5163 | Actual Loss: 1.6087\n",
      "Baseline Loss: 3.5998 | Actual Loss: 1.8392\n",
      "Baseline Loss: 3.4095 | Actual Loss: 1.3900\n",
      "Baseline Loss: 3.5749 | Actual Loss: 2.0035\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.1371\n",
      "Baseline Loss: 3.6826 | Actual Loss: 2.3627\n",
      "Baseline Loss: 3.5742 | Actual Loss: 1.1076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 32/1000 [00:12<06:29,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4990 | Actual Loss: 0.9242\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.8748\n",
      "Baseline Loss: 3.6101 | Actual Loss: 1.1319\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.7442\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.5458\n",
      "Epoch 32/1000: Train Loss: 1.4986, Val Loss: 1.3242\n",
      "Baseline Loss: 3.8951 | Actual Loss: 0.8174\n",
      "Baseline Loss: 3.3239 | Actual Loss: 1.2873\n",
      "Baseline Loss: 3.5455 | Actual Loss: 1.6883\n",
      "Baseline Loss: 3.2755 | Actual Loss: 1.6876\n",
      "Baseline Loss: 3.4062 | Actual Loss: 1.3523\n",
      "Baseline Loss: 3.6498 | Actual Loss: 1.4953\n",
      "Baseline Loss: 3.6504 | Actual Loss: 1.3697\n",
      "Baseline Loss: 3.5919 | Actual Loss: 1.9074\n",
      "Baseline Loss: 3.4590 | Actual Loss: 1.3160\n",
      "Baseline Loss: 3.4425 | Actual Loss: 0.9779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 33/1000 [00:12<06:09,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3516 | Actual Loss: 1.5199\n",
      "Baseline Loss: 3.5961 | Actual Loss: 1.5457\n",
      "Baseline Loss: 3.4971 | Actual Loss: 1.3896\n",
      "Baseline Loss: 3.6779 | Actual Loss: 1.4820\n",
      "Baseline Loss: 3.4168 | Actual Loss: 1.3846\n",
      "Baseline Loss: 3.6066 | Actual Loss: 0.6179\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.9155\n",
      "Baseline Loss: 3.6101 | Actual Loss: 1.0227\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.4326\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.4684\n",
      "Epoch 33/1000: Train Loss: 1.3649, Val Loss: 1.2098\n",
      "Baseline Loss: 3.4242 | Actual Loss: 1.3945\n",
      "Baseline Loss: 3.6878 | Actual Loss: 1.3074\n",
      "Baseline Loss: 3.3858 | Actual Loss: 1.2895\n",
      "Baseline Loss: 3.3546 | Actual Loss: 1.2964\n",
      "Baseline Loss: 3.7365 | Actual Loss: 1.1278\n",
      "Baseline Loss: 3.7675 | Actual Loss: 1.2881\n",
      "Baseline Loss: 3.4655 | Actual Loss: 1.3667\n",
      "Baseline Loss: 3.4931 | Actual Loss: 0.9863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 34/1000 [00:13<06:11,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6972 | Actual Loss: 1.3405\n",
      "Baseline Loss: 3.4581 | Actual Loss: 1.1483\n",
      "Baseline Loss: 3.3037 | Actual Loss: 1.2172\n",
      "Baseline Loss: 3.5335 | Actual Loss: 2.0500\n",
      "Baseline Loss: 3.5609 | Actual Loss: 1.3798\n",
      "Baseline Loss: 3.5165 | Actual Loss: 1.4932\n",
      "Baseline Loss: 3.4630 | Actual Loss: 1.5966\n",
      "Baseline Loss: 3.5192 | Actual Loss: 2.1718\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.8615\n",
      "Baseline Loss: 3.6101 | Actual Loss: 1.1009\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.3107\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.4577\n",
      "Epoch 34/1000: Train Loss: 1.4034, Val Loss: 1.1827\n",
      "Baseline Loss: 3.5093 | Actual Loss: 1.6468\n",
      "Baseline Loss: 3.6412 | Actual Loss: 3.2394\n",
      "Baseline Loss: 3.5213 | Actual Loss: 1.2892\n",
      "Baseline Loss: 3.4220 | Actual Loss: 1.1502\n",
      "Baseline Loss: 3.5334 | Actual Loss: 1.5053\n",
      "Baseline Loss: 3.5489 | Actual Loss: 1.5423\n",
      "Baseline Loss: 3.5839 | Actual Loss: 1.9802\n",
      "Baseline Loss: 3.5706 | Actual Loss: 1.4406\n",
      "Baseline Loss: 3.6549 | Actual Loss: 0.7704\n",
      "Baseline Loss: 3.4208 | Actual Loss: 1.4255\n",
      "Baseline Loss: 3.8103 | Actual Loss: 1.4029\n",
      "Baseline Loss: 3.3639 | Actual Loss: 1.1548\n",
      "Baseline Loss: 3.4399 | Actual Loss: 1.1039\n",
      "Baseline Loss: 3.6218 | Actual Loss: 1.6166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 35/1000 [00:13<06:05,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4348 | Actual Loss: 1.1405\n",
      "Baseline Loss: 3.1725 | Actual Loss: 1.6900\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.8498\n",
      "Baseline Loss: 3.6101 | Actual Loss: 1.1541\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.4716\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.4513\n",
      "Epoch 35/1000: Train Loss: 1.5062, Val Loss: 1.2317\n",
      "Baseline Loss: 3.3339 | Actual Loss: 1.3756\n",
      "Baseline Loss: 3.5662 | Actual Loss: 1.4174\n",
      "Baseline Loss: 3.3928 | Actual Loss: 0.9976\n",
      "Baseline Loss: 3.6057 | Actual Loss: 1.3849\n",
      "Baseline Loss: 3.6879 | Actual Loss: 0.6362\n",
      "Baseline Loss: 3.5327 | Actual Loss: 1.5989\n",
      "Baseline Loss: 3.7418 | Actual Loss: 1.8060\n",
      "Baseline Loss: 3.4887 | Actual Loss: 1.2208\n",
      "Baseline Loss: 3.4360 | Actual Loss: 1.2980\n",
      "Baseline Loss: 3.3477 | Actual Loss: 1.2904\n",
      "Baseline Loss: 3.7221 | Actual Loss: 2.5406\n",
      "Baseline Loss: 3.3373 | Actual Loss: 0.8103\n",
      "Baseline Loss: 3.6231 | Actual Loss: 1.0875\n",
      "Baseline Loss: 3.4739 | Actual Loss: 1.4297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 36/1000 [00:14<06:17,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5498 | Actual Loss: 0.7811\n",
      "Baseline Loss: 3.5402 | Actual Loss: 0.9420\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.8690\n",
      "Baseline Loss: 3.6101 | Actual Loss: 1.1469\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.8100\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.4325\n",
      "Epoch 36/1000: Train Loss: 1.2886, Val Loss: 1.3146\n",
      "Baseline Loss: 3.5048 | Actual Loss: 1.4956\n",
      "Baseline Loss: 3.4313 | Actual Loss: 1.2264\n",
      "Baseline Loss: 3.3511 | Actual Loss: 1.3632\n",
      "Baseline Loss: 3.4970 | Actual Loss: 2.2844\n",
      "Baseline Loss: 3.5163 | Actual Loss: 2.1681\n",
      "Baseline Loss: 3.6580 | Actual Loss: 1.7729\n",
      "Baseline Loss: 3.6369 | Actual Loss: 1.3000\n",
      "Baseline Loss: 3.4356 | Actual Loss: 1.3093\n",
      "Baseline Loss: 3.5328 | Actual Loss: 1.6389\n",
      "Baseline Loss: 3.6236 | Actual Loss: 1.2264\n",
      "Baseline Loss: 3.6056 | Actual Loss: 0.9331\n",
      "Baseline Loss: 3.5045 | Actual Loss: 0.9082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 37/1000 [00:14<06:18,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6829 | Actual Loss: 1.4331\n",
      "Baseline Loss: 3.4619 | Actual Loss: 1.6625\n",
      "Baseline Loss: 3.3614 | Actual Loss: 1.3648\n",
      "Baseline Loss: 3.6404 | Actual Loss: 1.5635\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.8456\n",
      "Baseline Loss: 3.6101 | Actual Loss: 1.1556\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.2376\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.4502\n",
      "Epoch 37/1000: Train Loss: 1.4782, Val Loss: 1.1723\n",
      "Baseline Loss: 3.5093 | Actual Loss: 2.1482\n",
      "Baseline Loss: 3.5421 | Actual Loss: 1.2869\n",
      "Baseline Loss: 3.4738 | Actual Loss: 1.7306\n",
      "Baseline Loss: 3.4810 | Actual Loss: 1.1322\n",
      "Baseline Loss: 3.5180 | Actual Loss: 1.0679\n",
      "Baseline Loss: 3.6000 | Actual Loss: 1.4293\n",
      "Baseline Loss: 3.5834 | Actual Loss: 1.7298\n",
      "Baseline Loss: 3.4204 | Actual Loss: 1.3482\n",
      "Baseline Loss: 3.5489 | Actual Loss: 1.4003\n",
      "Baseline Loss: 3.6648 | Actual Loss: 1.4661\n",
      "Baseline Loss: 3.5625 | Actual Loss: 1.1150\n",
      "Baseline Loss: 3.3607 | Actual Loss: 0.9693\n",
      "Baseline Loss: 3.5018 | Actual Loss: 1.3424\n",
      "Baseline Loss: 3.4547 | Actual Loss: 0.7948\n",
      "Baseline Loss: 3.5294 | Actual Loss: 1.6099\n",
      "Baseline Loss: 3.4399 | Actual Loss: 1.1495\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.7803\n",
      "Baseline Loss: 3.6101 | Actual Loss: 1.0911\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.3764\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.3895\n",
      "Epoch 38/1000: Train Loss: 1.3575, Val Loss: 1.1593\n",
      "New best validation loss: 1.1593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 38/1000 [00:14<05:59,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6060 | Actual Loss: 1.4227\n",
      "Baseline Loss: 3.3639 | Actual Loss: 1.0431\n",
      "Baseline Loss: 3.5176 | Actual Loss: 1.4213\n",
      "Baseline Loss: 3.3604 | Actual Loss: 1.0344\n",
      "Baseline Loss: 3.4924 | Actual Loss: 1.1642\n",
      "Baseline Loss: 3.4173 | Actual Loss: 1.5075\n",
      "Baseline Loss: 3.5746 | Actual Loss: 0.7885\n",
      "Baseline Loss: 3.5873 | Actual Loss: 2.2004\n",
      "Baseline Loss: 3.5492 | Actual Loss: 0.9930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 39/1000 [00:15<06:01,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4696 | Actual Loss: 1.6343\n",
      "Baseline Loss: 3.5541 | Actual Loss: 0.8993\n",
      "Baseline Loss: 3.5922 | Actual Loss: 2.5839\n",
      "Baseline Loss: 3.4922 | Actual Loss: 1.7504\n",
      "Baseline Loss: 3.5661 | Actual Loss: 1.2493\n",
      "Baseline Loss: 3.8158 | Actual Loss: 1.1239\n",
      "Baseline Loss: 3.1238 | Actual Loss: 1.0686\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.6765\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.9527\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.1484\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.3886\n",
      "Epoch 39/1000: Train Loss: 1.3678, Val Loss: 1.0415\n",
      "New best validation loss: 1.0415\n",
      "Baseline Loss: 3.4432 | Actual Loss: 1.5622\n",
      "Baseline Loss: 3.5409 | Actual Loss: 2.2088\n",
      "Baseline Loss: 3.5875 | Actual Loss: 1.1526\n",
      "Baseline Loss: 3.4657 | Actual Loss: 1.5407\n",
      "Baseline Loss: 3.5334 | Actual Loss: 1.0812\n",
      "Baseline Loss: 3.6456 | Actual Loss: 0.9259\n",
      "Baseline Loss: 3.6878 | Actual Loss: 1.2593\n",
      "Baseline Loss: 3.4814 | Actual Loss: 1.6270\n",
      "Baseline Loss: 3.4211 | Actual Loss: 1.5294\n",
      "Baseline Loss: 3.6093 | Actual Loss: 0.8907\n",
      "Baseline Loss: 3.4468 | Actual Loss: 1.2483\n",
      "Baseline Loss: 3.5623 | Actual Loss: 0.8265\n",
      "Baseline Loss: 3.6047 | Actual Loss: 1.3696\n",
      "Baseline Loss: 3.2824 | Actual Loss: 1.5755\n",
      "Baseline Loss: 3.6231 | Actual Loss: 0.7436\n",
      "Baseline Loss: 3.3058 | Actual Loss: 0.9887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 40/1000 [00:15<05:49,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5212 | Actual Loss: 0.8158\n",
      "Baseline Loss: 3.6101 | Actual Loss: 1.0217\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.3268\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.3674\n",
      "Epoch 40/1000: Train Loss: 1.2831, Val Loss: 1.1329\n",
      "Baseline Loss: 3.4362 | Actual Loss: 1.7559\n",
      "Baseline Loss: 3.4239 | Actual Loss: 1.5178\n",
      "Baseline Loss: 3.6878 | Actual Loss: 1.2533\n",
      "Baseline Loss: 3.6738 | Actual Loss: 0.8381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 41/1000 [00:15<05:52,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6192 | Actual Loss: 1.1901\n",
      "Baseline Loss: 3.3651 | Actual Loss: 1.0827\n",
      "Baseline Loss: 3.6092 | Actual Loss: 1.0992\n",
      "Baseline Loss: 3.5534 | Actual Loss: 1.4511\n",
      "Baseline Loss: 3.4853 | Actual Loss: 1.4582\n",
      "Baseline Loss: 3.5334 | Actual Loss: 0.9662\n",
      "Baseline Loss: 3.5326 | Actual Loss: 1.3640\n",
      "Baseline Loss: 3.4205 | Actual Loss: 1.2626\n",
      "Baseline Loss: 3.5165 | Actual Loss: 0.9546\n",
      "Baseline Loss: 3.3680 | Actual Loss: 0.6687\n",
      "Baseline Loss: 3.4512 | Actual Loss: 1.6241\n",
      "Baseline Loss: 3.4201 | Actual Loss: 1.3098\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.8965\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.8548\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.1799\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.3693\n",
      "Epoch 41/1000: Train Loss: 1.2373, Val Loss: 1.0752\n",
      "Baseline Loss: 3.4321 | Actual Loss: 1.2264\n",
      "Baseline Loss: 3.6367 | Actual Loss: 1.1572\n",
      "Baseline Loss: 3.4846 | Actual Loss: 0.8663\n",
      "Baseline Loss: 3.6092 | Actual Loss: 0.9527\n",
      "Baseline Loss: 3.5400 | Actual Loss: 1.4073\n",
      "Baseline Loss: 3.6412 | Actual Loss: 0.8644\n",
      "Baseline Loss: 3.4578 | Actual Loss: 0.9152\n",
      "Baseline Loss: 3.6730 | Actual Loss: 1.1076\n",
      "Baseline Loss: 3.5789 | Actual Loss: 1.5668\n",
      "Baseline Loss: 3.5207 | Actual Loss: 1.1057\n",
      "Baseline Loss: 3.6367 | Actual Loss: 1.0530\n",
      "Baseline Loss: 3.5795 | Actual Loss: 1.3061\n",
      "Baseline Loss: 3.4691 | Actual Loss: 1.1938\n",
      "Baseline Loss: 3.5419 | Actual Loss: 1.6108\n",
      "Baseline Loss: 3.5494 | Actual Loss: 1.6568\n",
      "Baseline Loss: 3.1886 | Actual Loss: 1.0495\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.8137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 42/1000 [00:16<06:17,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6101 | Actual Loss: 1.1753\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.1844\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.4851\n",
      "Epoch 42/1000: Train Loss: 1.1900, Val Loss: 1.1646\n",
      "Baseline Loss: 3.5752 | Actual Loss: 1.0269\n",
      "Baseline Loss: 3.4210 | Actual Loss: 1.2606\n",
      "Baseline Loss: 3.8952 | Actual Loss: 0.9994\n",
      "Baseline Loss: 3.7022 | Actual Loss: 0.8787\n",
      "Baseline Loss: 3.5041 | Actual Loss: 1.2488\n",
      "Baseline Loss: 3.4627 | Actual Loss: 0.9362\n",
      "Baseline Loss: 3.3681 | Actual Loss: 1.0417\n",
      "Baseline Loss: 3.4971 | Actual Loss: 1.1329\n",
      "Baseline Loss: 3.4577 | Actual Loss: 1.7898\n",
      "Baseline Loss: 3.5092 | Actual Loss: 1.4029\n",
      "Baseline Loss: 3.2576 | Actual Loss: 0.8639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 43/1000 [00:16<05:53,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5207 | Actual Loss: 1.9115\n",
      "Baseline Loss: 3.3442 | Actual Loss: 1.5065\n",
      "Baseline Loss: 3.5362 | Actual Loss: 1.6457\n",
      "Baseline Loss: 3.7625 | Actual Loss: 1.5060\n",
      "Baseline Loss: 3.4987 | Actual Loss: 1.0334\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.7899\n",
      "Baseline Loss: 3.6101 | Actual Loss: 1.0826\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.7104\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.3654\n",
      "Epoch 43/1000: Train Loss: 1.2615, Val Loss: 1.2371\n",
      "Baseline Loss: 3.3607 | Actual Loss: 1.1348\n",
      "Baseline Loss: 3.4592 | Actual Loss: 1.0651\n",
      "Baseline Loss: 3.3203 | Actual Loss: 1.0448\n",
      "Baseline Loss: 3.5331 | Actual Loss: 1.4329\n",
      "Baseline Loss: 3.5705 | Actual Loss: 1.1801\n",
      "Baseline Loss: 3.3999 | Actual Loss: 1.4306\n",
      "Baseline Loss: 3.4583 | Actual Loss: 1.3049\n",
      "Baseline Loss: 3.5883 | Actual Loss: 1.4364\n",
      "Baseline Loss: 3.7675 | Actual Loss: 0.9606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 44/1000 [00:17<06:08,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7781 | Actual Loss: 1.1890\n",
      "Baseline Loss: 3.7072 | Actual Loss: 1.4105\n",
      "Baseline Loss: 3.5664 | Actual Loss: 0.9863\n",
      "Baseline Loss: 3.4288 | Actual Loss: 1.2670\n",
      "Baseline Loss: 3.6009 | Actual Loss: 1.5190\n",
      "Baseline Loss: 3.4102 | Actual Loss: 1.4524\n",
      "Baseline Loss: 3.1117 | Actual Loss: 1.1258\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.7628\n",
      "Baseline Loss: 3.6101 | Actual Loss: 1.1059\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.3405\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.3693\n",
      "Epoch 44/1000: Train Loss: 1.2463, Val Loss: 1.1446\n",
      "Baseline Loss: 3.3117 | Actual Loss: 1.6022\n",
      "Baseline Loss: 3.5743 | Actual Loss: 1.1697\n",
      "Baseline Loss: 3.5405 | Actual Loss: 1.2490\n",
      "Baseline Loss: 3.5086 | Actual Loss: 1.1954\n",
      "Baseline Loss: 3.5419 | Actual Loss: 1.8059\n",
      "Baseline Loss: 3.5206 | Actual Loss: 0.9051\n",
      "Baseline Loss: 3.3551 | Actual Loss: 1.3132\n",
      "Baseline Loss: 3.6688 | Actual Loss: 2.1057\n",
      "Baseline Loss: 3.4974 | Actual Loss: 1.3560\n",
      "Baseline Loss: 3.4554 | Actual Loss: 1.3067\n",
      "Baseline Loss: 3.5050 | Actual Loss: 1.5564\n",
      "Baseline Loss: 3.4110 | Actual Loss: 1.1086\n",
      "Baseline Loss: 3.5129 | Actual Loss: 1.5437\n",
      "Baseline Loss: 3.4899 | Actual Loss: 0.9422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 45/1000 [00:17<06:13,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6544 | Actual Loss: 1.1321\n",
      "Baseline Loss: 3.2105 | Actual Loss: 0.6366\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.8120\n",
      "Baseline Loss: 3.6101 | Actual Loss: 1.0350\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.2902\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.2425\n",
      "Epoch 45/1000: Train Loss: 1.3080, Val Loss: 1.0949\n",
      "Baseline Loss: 3.4203 | Actual Loss: 1.4808\n",
      "Baseline Loss: 3.5450 | Actual Loss: 1.3632\n",
      "Baseline Loss: 3.4469 | Actual Loss: 1.3814\n",
      "Baseline Loss: 3.6451 | Actual Loss: 0.9371\n",
      "Baseline Loss: 3.9190 | Actual Loss: 1.3687\n",
      "Baseline Loss: 3.4811 | Actual Loss: 0.8824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 46/1000 [00:17<05:53,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5129 | Actual Loss: 0.9034\n",
      "Baseline Loss: 3.4822 | Actual Loss: 1.2746\n",
      "Baseline Loss: 3.7025 | Actual Loss: 1.7840\n",
      "Baseline Loss: 3.3602 | Actual Loss: 1.9104\n",
      "Baseline Loss: 3.4969 | Actual Loss: 2.0483\n",
      "Baseline Loss: 3.6093 | Actual Loss: 1.8219\n",
      "Baseline Loss: 3.4169 | Actual Loss: 0.5969\n",
      "Baseline Loss: 3.5036 | Actual Loss: 0.8518\n",
      "Baseline Loss: 3.5125 | Actual Loss: 1.3449\n",
      "Baseline Loss: 3.6292 | Actual Loss: 0.8108\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.7573\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.9419\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.4037\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.1965\n",
      "Epoch 46/1000: Train Loss: 1.2975, Val Loss: 1.0748\n",
      "Baseline Loss: 3.5242 | Actual Loss: 1.3005\n",
      "Baseline Loss: 3.5010 | Actual Loss: 1.6155\n",
      "Baseline Loss: 3.5202 | Actual Loss: 2.8760\n",
      "Baseline Loss: 3.2992 | Actual Loss: 1.4397\n",
      "Baseline Loss: 3.5916 | Actual Loss: 1.3829\n",
      "Baseline Loss: 3.4735 | Actual Loss: 1.1112\n",
      "Baseline Loss: 3.6409 | Actual Loss: 0.9851\n",
      "Baseline Loss: 3.4620 | Actual Loss: 1.0378\n",
      "Baseline Loss: 3.6090 | Actual Loss: 1.7678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 47/1000 [00:18<06:11,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5255 | Actual Loss: 1.1782\n",
      "Baseline Loss: 3.7321 | Actual Loss: 1.2256\n",
      "Baseline Loss: 3.5655 | Actual Loss: 1.0512\n",
      "Baseline Loss: 3.6456 | Actual Loss: 1.1535\n",
      "Baseline Loss: 3.5748 | Actual Loss: 1.0060\n",
      "Baseline Loss: 3.4205 | Actual Loss: 0.8348\n",
      "Baseline Loss: 3.2980 | Actual Loss: 1.3752\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.8943\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.9412\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.3140\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.0621\n",
      "Epoch 47/1000: Train Loss: 1.3338, Val Loss: 1.0529\n",
      "Baseline Loss: 3.5626 | Actual Loss: 1.2608\n",
      "Baseline Loss: 3.5163 | Actual Loss: 1.2646\n",
      "Baseline Loss: 3.5539 | Actual Loss: 0.8030\n",
      "Baseline Loss: 3.6920 | Actual Loss: 1.8969\n",
      "Baseline Loss: 3.5748 | Actual Loss: 1.2126\n",
      "Baseline Loss: 3.4657 | Actual Loss: 1.1555\n",
      "Baseline Loss: 3.3214 | Actual Loss: 1.1803\n",
      "Baseline Loss: 3.4617 | Actual Loss: 1.2755\n",
      "Baseline Loss: 3.5928 | Actual Loss: 1.3814\n",
      "Baseline Loss: 3.8603 | Actual Loss: 1.1847\n",
      "Baseline Loss: 3.4593 | Actual Loss: 1.0638\n",
      "Baseline Loss: 3.6459 | Actual Loss: 1.0312\n",
      "Baseline Loss: 3.5409 | Actual Loss: 1.2365\n",
      "Baseline Loss: 3.5409 | Actual Loss: 1.4912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 48/1000 [00:18<06:10,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3845 | Actual Loss: 1.1251\n",
      "Baseline Loss: 3.1530 | Actual Loss: 1.0335\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.6359\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.9109\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.2625\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.3384\n",
      "Epoch 48/1000: Train Loss: 1.2248, Val Loss: 1.0369\n",
      "New best validation loss: 1.0369\n",
      "Baseline Loss: 3.4100 | Actual Loss: 0.6797\n",
      "Baseline Loss: 3.6089 | Actual Loss: 1.1287\n",
      "Baseline Loss: 3.4735 | Actual Loss: 2.2604\n",
      "Baseline Loss: 3.6226 | Actual Loss: 1.5901\n",
      "Baseline Loss: 3.4624 | Actual Loss: 1.6770\n",
      "Baseline Loss: 3.4360 | Actual Loss: 0.6180\n",
      "Baseline Loss: 3.4067 | Actual Loss: 1.6370\n",
      "Baseline Loss: 3.5377 | Actual Loss: 1.3470\n",
      "Baseline Loss: 3.4359 | Actual Loss: 1.2282\n",
      "Baseline Loss: 3.6593 | Actual Loss: 1.0127\n",
      "Baseline Loss: 3.8050 | Actual Loss: 1.6332\n",
      "Baseline Loss: 3.5879 | Actual Loss: 0.9790\n",
      "Baseline Loss: 3.6929 | Actual Loss: 0.6532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 49/1000 [00:18<06:03,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4103 | Actual Loss: 1.2116\n",
      "Baseline Loss: 3.4893 | Actual Loss: 1.4533\n",
      "Baseline Loss: 3.2342 | Actual Loss: 1.3158\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.6787\n",
      "Baseline Loss: 3.6101 | Actual Loss: 1.0366\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.0848\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.3589\n",
      "Epoch 49/1000: Train Loss: 1.2766, Val Loss: 1.0398\n",
      "Baseline Loss: 3.4250 | Actual Loss: 1.0859\n",
      "Baseline Loss: 3.6924 | Actual Loss: 1.6186\n",
      "Baseline Loss: 3.4437 | Actual Loss: 1.0778\n",
      "Baseline Loss: 3.5710 | Actual Loss: 1.2559\n",
      "Baseline Loss: 3.6186 | Actual Loss: 0.8474\n",
      "Baseline Loss: 3.5575 | Actual Loss: 1.0330\n",
      "Baseline Loss: 3.6005 | Actual Loss: 1.1202\n",
      "Baseline Loss: 3.5174 | Actual Loss: 1.8262\n",
      "Baseline Loss: 3.2405 | Actual Loss: 1.1545\n",
      "Baseline Loss: 3.5420 | Actual Loss: 0.9487\n",
      "Baseline Loss: 3.3610 | Actual Loss: 1.3822\n",
      "Baseline Loss: 3.5800 | Actual Loss: 1.6831\n",
      "Baseline Loss: 3.4736 | Actual Loss: 2.7379\n",
      "Baseline Loss: 3.6694 | Actual Loss: 1.7409\n",
      "Baseline Loss: 3.5870 | Actual Loss: 1.3492\n",
      "Baseline Loss: 3.3664 | Actual Loss: 0.9082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 50/1000 [00:19<06:13,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5212 | Actual Loss: 0.7118\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.8790\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.1581\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.3915\n",
      "Epoch 50/1000: Train Loss: 1.3606, Val Loss: 1.0351\n",
      "New best validation loss: 1.0351\n",
      "Baseline Loss: 3.6681 | Actual Loss: 1.1776\n",
      "Baseline Loss: 3.4473 | Actual Loss: 0.8955\n",
      "Baseline Loss: 3.4881 | Actual Loss: 0.8029\n",
      "Baseline Loss: 3.4769 | Actual Loss: 1.3258\n",
      "Baseline Loss: 3.3708 | Actual Loss: 0.9536\n",
      "Baseline Loss: 3.5539 | Actual Loss: 1.2367\n",
      "Baseline Loss: 3.5825 | Actual Loss: 1.1408\n",
      "Baseline Loss: 3.6542 | Actual Loss: 1.1576\n",
      "Baseline Loss: 3.5375 | Actual Loss: 0.9982\n",
      "Baseline Loss: 3.4626 | Actual Loss: 1.1905\n",
      "Baseline Loss: 3.5459 | Actual Loss: 1.2716\n",
      "Baseline Loss: 3.5877 | Actual Loss: 1.3477\n",
      "Baseline Loss: 3.5570 | Actual Loss: 1.4484\n",
      "Baseline Loss: 3.4000 | Actual Loss: 1.1310\n",
      "Baseline Loss: 3.4621 | Actual Loss: 0.8948\n",
      "Baseline Loss: 3.3748 | Actual Loss: 1.5302\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.7082\n",
      "Baseline Loss: 3.6101 | Actual Loss: 1.0332\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.5646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 51/1000 [00:19<06:02,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3188 | Actual Loss: 1.3765\n",
      "Epoch 51/1000: Train Loss: 1.1564, Val Loss: 1.1706\n",
      "Baseline Loss: 3.4580 | Actual Loss: 1.6043\n",
      "Baseline Loss: 3.7074 | Actual Loss: 1.7684\n",
      "Baseline Loss: 3.7218 | Actual Loss: 0.9729\n",
      "Baseline Loss: 3.4508 | Actual Loss: 1.0600\n",
      "Baseline Loss: 3.4506 | Actual Loss: 1.2770\n",
      "Baseline Loss: 3.6014 | Actual Loss: 1.2041\n",
      "Baseline Loss: 3.6090 | Actual Loss: 1.0036\n",
      "Baseline Loss: 3.3508 | Actual Loss: 0.9523\n",
      "Baseline Loss: 3.4478 | Actual Loss: 0.8990\n",
      "Baseline Loss: 3.4665 | Actual Loss: 1.1461\n",
      "Baseline Loss: 3.4441 | Actual Loss: 1.2184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 52/1000 [00:20<05:59,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6874 | Actual Loss: 0.9501\n",
      "Baseline Loss: 3.4900 | Actual Loss: 1.9369\n",
      "Baseline Loss: 3.6541 | Actual Loss: 1.7849\n",
      "Baseline Loss: 3.4847 | Actual Loss: 1.2813\n",
      "Baseline Loss: 3.6765 | Actual Loss: 1.6786\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.6827\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.9236\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.5783\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.3487\n",
      "Epoch 52/1000: Train Loss: 1.2961, Val Loss: 1.1333\n",
      "Baseline Loss: 3.4734 | Actual Loss: 1.5430\n",
      "Baseline Loss: 3.4067 | Actual Loss: 1.1282\n",
      "Baseline Loss: 3.6274 | Actual Loss: 1.0196\n",
      "Baseline Loss: 3.5830 | Actual Loss: 1.5202\n",
      "Baseline Loss: 3.5093 | Actual Loss: 1.2607\n",
      "Baseline Loss: 3.5574 | Actual Loss: 0.8598\n",
      "Baseline Loss: 3.4435 | Actual Loss: 0.7644\n",
      "Baseline Loss: 3.7571 | Actual Loss: 0.7264\n",
      "Baseline Loss: 3.5968 | Actual Loss: 1.3852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 53/1000 [00:20<06:20,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6639 | Actual Loss: 1.1483\n",
      "Baseline Loss: 3.4391 | Actual Loss: 0.9996\n",
      "Baseline Loss: 3.5130 | Actual Loss: 1.1966\n",
      "Baseline Loss: 3.6099 | Actual Loss: 1.1953\n",
      "Baseline Loss: 3.4707 | Actual Loss: 1.1332\n",
      "Baseline Loss: 3.2817 | Actual Loss: 1.3372\n",
      "Baseline Loss: 3.4786 | Actual Loss: 1.4441\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.7750\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.9239\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.3080\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.3754\n",
      "Epoch 53/1000: Train Loss: 1.1664, Val Loss: 1.0956\n",
      "Baseline Loss: 3.5408 | Actual Loss: 0.6772\n",
      "Baseline Loss: 3.5361 | Actual Loss: 1.0716\n",
      "Baseline Loss: 3.5327 | Actual Loss: 1.1071\n",
      "Baseline Loss: 3.4539 | Actual Loss: 2.7105\n",
      "Baseline Loss: 3.3104 | Actual Loss: 0.5546\n",
      "Baseline Loss: 3.5658 | Actual Loss: 1.9410\n",
      "Baseline Loss: 3.4250 | Actual Loss: 1.2215\n",
      "Baseline Loss: 3.5581 | Actual Loss: 1.1675\n",
      "Baseline Loss: 3.6775 | Actual Loss: 2.4731\n",
      "Baseline Loss: 3.4286 | Actual Loss: 1.4564\n",
      "Baseline Loss: 3.5823 | Actual Loss: 0.9424\n",
      "Baseline Loss: 3.6047 | Actual Loss: 1.1246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 54/1000 [00:20<06:03,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5093 | Actual Loss: 1.5214\n",
      "Baseline Loss: 3.5451 | Actual Loss: 1.4837\n",
      "Baseline Loss: 3.6052 | Actual Loss: 1.5883\n",
      "Baseline Loss: 3.5198 | Actual Loss: 1.0208\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.6839\n",
      "Baseline Loss: 3.6101 | Actual Loss: 1.1189\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.5737\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.2707\n",
      "Epoch 54/1000: Train Loss: 1.3789, Val Loss: 1.1618\n",
      "Baseline Loss: 3.5288 | Actual Loss: 1.3314\n",
      "Baseline Loss: 3.4768 | Actual Loss: 0.8949\n",
      "Baseline Loss: 3.3373 | Actual Loss: 1.5650\n",
      "Baseline Loss: 3.5087 | Actual Loss: 1.2265\n",
      "Baseline Loss: 3.5174 | Actual Loss: 0.8587\n",
      "Baseline Loss: 3.4929 | Actual Loss: 1.1712\n",
      "Baseline Loss: 3.7220 | Actual Loss: 1.7499\n",
      "Baseline Loss: 3.5009 | Actual Loss: 1.4307\n",
      "Baseline Loss: 3.5162 | Actual Loss: 1.4572\n",
      "Baseline Loss: 3.5751 | Actual Loss: 0.9715\n",
      "Baseline Loss: 3.4998 | Actual Loss: 1.1907\n",
      "Baseline Loss: 3.6973 | Actual Loss: 0.7848\n",
      "Baseline Loss: 3.7122 | Actual Loss: 1.2208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 55/1000 [00:21<06:15,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5918 | Actual Loss: 1.1992\n",
      "Baseline Loss: 3.3172 | Actual Loss: 1.3122\n",
      "Baseline Loss: 3.6642 | Actual Loss: 0.3488\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.7797\n",
      "Baseline Loss: 3.6101 | Actual Loss: 1.0771\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.4740\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.3759\n",
      "Epoch 55/1000: Train Loss: 1.1696, Val Loss: 1.1767\n",
      "Baseline Loss: 3.6228 | Actual Loss: 1.8738\n",
      "Baseline Loss: 3.2858 | Actual Loss: 1.0259\n",
      "Baseline Loss: 3.6136 | Actual Loss: 1.0462\n",
      "Baseline Loss: 3.4980 | Actual Loss: 1.0954\n",
      "Baseline Loss: 3.4434 | Actual Loss: 1.0312\n",
      "Baseline Loss: 3.3752 | Actual Loss: 1.2848\n",
      "Baseline Loss: 3.6363 | Actual Loss: 0.6718\n",
      "Baseline Loss: 3.5618 | Actual Loss: 1.7657\n",
      "Baseline Loss: 3.4550 | Actual Loss: 1.2229\n",
      "Baseline Loss: 3.8890 | Actual Loss: 1.3962\n",
      "Baseline Loss: 3.4253 | Actual Loss: 1.0108\n",
      "Baseline Loss: 3.4657 | Actual Loss: 1.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 56/1000 [00:21<06:18,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5790 | Actual Loss: 1.1169\n",
      "Baseline Loss: 3.6215 | Actual Loss: 0.9914\n",
      "Baseline Loss: 3.4029 | Actual Loss: 1.3450\n",
      "Baseline Loss: 3.5841 | Actual Loss: 3.0741\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.6360\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.8712\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.1235\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.1395\n",
      "Epoch 56/1000: Train Loss: 1.3095, Val Loss: 0.9426\n",
      "New best validation loss: 0.9426\n",
      "Baseline Loss: 3.4657 | Actual Loss: 1.0491\n",
      "Baseline Loss: 3.7571 | Actual Loss: 0.4484\n",
      "Baseline Loss: 3.5584 | Actual Loss: 3.6089\n",
      "Baseline Loss: 3.5910 | Actual Loss: 1.4704\n",
      "Baseline Loss: 3.6645 | Actual Loss: 1.5272\n",
      "Baseline Loss: 3.3473 | Actual Loss: 1.5131\n",
      "Baseline Loss: 3.5877 | Actual Loss: 1.1665\n",
      "Baseline Loss: 3.5288 | Actual Loss: 0.8676\n",
      "Baseline Loss: 3.5173 | Actual Loss: 1.1732\n",
      "Baseline Loss: 3.4617 | Actual Loss: 1.2781\n",
      "Baseline Loss: 3.5245 | Actual Loss: 0.9465\n",
      "Baseline Loss: 3.6412 | Actual Loss: 0.7983\n",
      "Baseline Loss: 3.4245 | Actual Loss: 0.8777\n",
      "Baseline Loss: 3.5003 | Actual Loss: 0.8339\n",
      "Baseline Loss: 3.4971 | Actual Loss: 1.9804\n",
      "Baseline Loss: 3.4399 | Actual Loss: 1.1125\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.6581\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.9660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 57/1000 [00:22<06:06,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5170 | Actual Loss: 1.5916\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.2287\n",
      "Epoch 57/1000: Train Loss: 1.2907, Val Loss: 1.1111\n",
      "Baseline Loss: 3.4855 | Actual Loss: 0.9256\n",
      "Baseline Loss: 3.5334 | Actual Loss: 2.1765\n",
      "Baseline Loss: 3.4701 | Actual Loss: 0.7557\n",
      "Baseline Loss: 3.5368 | Actual Loss: 1.0161\n",
      "Baseline Loss: 3.3812 | Actual Loss: 0.8642\n",
      "Baseline Loss: 3.6497 | Actual Loss: 0.7144\n",
      "Baseline Loss: 3.7628 | Actual Loss: 0.6608\n",
      "Baseline Loss: 3.5244 | Actual Loss: 1.1960\n",
      "Baseline Loss: 3.6732 | Actual Loss: 1.3387\n",
      "Baseline Loss: 3.3964 | Actual Loss: 1.2826\n",
      "Baseline Loss: 3.4242 | Actual Loss: 1.1131\n",
      "Baseline Loss: 3.5202 | Actual Loss: 1.2439\n",
      "Baseline Loss: 3.5251 | Actual Loss: 2.1588\n",
      "Baseline Loss: 3.6138 | Actual Loss: 2.4953\n",
      "Baseline Loss: 3.5792 | Actual Loss: 0.7366\n",
      "Baseline Loss: 3.2342 | Actual Loss: 1.3542\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.7091\n",
      "Baseline Loss: 3.6101 | Actual Loss: 1.1100\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.5044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 58/1000 [00:22<06:15,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3188 | Actual Loss: 1.1841\n",
      "Epoch 58/1000: Train Loss: 1.2520, Val Loss: 1.1269\n",
      "Baseline Loss: 3.4889 | Actual Loss: 2.0719\n",
      "Baseline Loss: 3.8895 | Actual Loss: 1.6096\n",
      "Baseline Loss: 3.1517 | Actual Loss: 1.2202\n",
      "Baseline Loss: 3.5000 | Actual Loss: 1.0096\n",
      "Baseline Loss: 3.5747 | Actual Loss: 1.0355\n",
      "Baseline Loss: 3.4894 | Actual Loss: 0.8554\n",
      "Baseline Loss: 3.6186 | Actual Loss: 2.1756\n",
      "Baseline Loss: 3.5832 | Actual Loss: 1.3228\n",
      "Baseline Loss: 3.6686 | Actual Loss: 1.6991\n",
      "Baseline Loss: 3.5124 | Actual Loss: 1.0440\n",
      "Baseline Loss: 3.6228 | Actual Loss: 1.2655\n",
      "Baseline Loss: 3.5574 | Actual Loss: 2.0131\n",
      "Baseline Loss: 3.6276 | Actual Loss: 2.7594\n",
      "Baseline Loss: 3.4853 | Actual Loss: 1.1978\n",
      "Baseline Loss: 3.3855 | Actual Loss: 1.0694\n",
      "Baseline Loss: 3.5619 | Actual Loss: 0.7611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 59/1000 [00:22<06:24,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5212 | Actual Loss: 0.7485\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.7885\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.2426\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.0734\n",
      "Epoch 59/1000: Train Loss: 1.4444, Val Loss: 0.9633\n",
      "Baseline Loss: 3.4705 | Actual Loss: 1.4808\n",
      "Baseline Loss: 3.5015 | Actual Loss: 0.7211\n",
      "Baseline Loss: 3.4587 | Actual Loss: 1.6369\n",
      "Baseline Loss: 3.6406 | Actual Loss: 1.9604\n",
      "Baseline Loss: 3.5003 | Actual Loss: 1.6726\n",
      "Baseline Loss: 3.3919 | Actual Loss: 0.8216\n",
      "Baseline Loss: 3.3776 | Actual Loss: 1.1454\n",
      "Baseline Loss: 3.5736 | Actual Loss: 1.0918\n",
      "Baseline Loss: 3.7889 | Actual Loss: 0.8050\n",
      "Baseline Loss: 3.6093 | Actual Loss: 1.7325\n",
      "Baseline Loss: 3.6597 | Actual Loss: 0.7242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 60/1000 [00:23<06:01,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.2662 | Actual Loss: 0.9267\n",
      "Baseline Loss: 3.6180 | Actual Loss: 1.3782\n",
      "Baseline Loss: 3.4967 | Actual Loss: 1.8156\n",
      "Baseline Loss: 3.4246 | Actual Loss: 1.0772\n",
      "Baseline Loss: 3.1821 | Actual Loss: 0.6757\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.6998\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.9289\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.1051\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.1811\n",
      "Epoch 60/1000: Train Loss: 1.2291, Val Loss: 0.9787\n",
      "Baseline Loss: 3.5123 | Actual Loss: 2.9497\n",
      "Baseline Loss: 3.4401 | Actual Loss: 0.9810\n",
      "Baseline Loss: 3.6318 | Actual Loss: 1.1534\n",
      "Baseline Loss: 3.4691 | Actual Loss: 0.9628\n",
      "Baseline Loss: 3.6193 | Actual Loss: 1.1446\n",
      "Baseline Loss: 3.4354 | Actual Loss: 1.0907\n",
      "Baseline Loss: 3.4290 | Actual Loss: 0.9631\n",
      "Baseline Loss: 3.6778 | Actual Loss: 1.1335\n",
      "Baseline Loss: 3.4360 | Actual Loss: 1.1987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 61/1000 [00:23<06:06,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6882 | Actual Loss: 0.7207\n",
      "Baseline Loss: 3.6318 | Actual Loss: 1.9917\n",
      "Baseline Loss: 3.5212 | Actual Loss: 1.2564\n",
      "Baseline Loss: 3.6831 | Actual Loss: 1.0029\n",
      "Baseline Loss: 3.5794 | Actual Loss: 1.4967\n",
      "Baseline Loss: 3.3803 | Actual Loss: 1.2710\n",
      "Baseline Loss: 3.4990 | Actual Loss: 0.7955\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.6677\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.8256\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.3754\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.2086\n",
      "Epoch 61/1000: Train Loss: 1.2570, Val Loss: 1.0193\n",
      "Baseline Loss: 3.6140 | Actual Loss: 0.6258\n",
      "Baseline Loss: 3.4409 | Actual Loss: 1.7939\n",
      "Baseline Loss: 3.5283 | Actual Loss: 0.9110\n",
      "Baseline Loss: 3.3813 | Actual Loss: 1.3727\n",
      "Baseline Loss: 3.7734 | Actual Loss: 1.5494\n",
      "Baseline Loss: 3.3473 | Actual Loss: 1.4071\n",
      "Baseline Loss: 3.6591 | Actual Loss: 0.8838\n",
      "Baseline Loss: 3.5840 | Actual Loss: 0.8558\n",
      "Baseline Loss: 3.5782 | Actual Loss: 1.2313\n",
      "Baseline Loss: 3.7067 | Actual Loss: 0.6884\n",
      "Baseline Loss: 3.3642 | Actual Loss: 1.2493\n",
      "Baseline Loss: 3.3615 | Actual Loss: 0.8826\n",
      "Baseline Loss: 3.4972 | Actual Loss: 1.2191\n",
      "Baseline Loss: 3.7836 | Actual Loss: 2.4638\n",
      "Baseline Loss: 3.4024 | Actual Loss: 1.2361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 62/1000 [00:24<06:01,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3061 | Actual Loss: 0.9176\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.6746\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.8096\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.3006\n",
      "Baseline Loss: 3.3188 | Actual Loss: 0.9373\n",
      "Epoch 62/1000: Train Loss: 1.2055, Val Loss: 0.9305\n",
      "New best validation loss: 0.9305\n",
      "Baseline Loss: 3.4318 | Actual Loss: 1.6597\n",
      "Baseline Loss: 3.3112 | Actual Loss: 0.9790\n",
      "Baseline Loss: 3.4908 | Actual Loss: 0.9675\n",
      "Baseline Loss: 3.4734 | Actual Loss: 0.9600\n",
      "Baseline Loss: 3.4317 | Actual Loss: 0.5130\n",
      "Baseline Loss: 3.5124 | Actual Loss: 0.8778\n",
      "Baseline Loss: 3.7729 | Actual Loss: 1.3671\n",
      "Baseline Loss: 3.4817 | Actual Loss: 1.1883\n",
      "Baseline Loss: 3.5711 | Actual Loss: 1.5757\n",
      "Baseline Loss: 3.6049 | Actual Loss: 1.8955\n",
      "Baseline Loss: 3.6639 | Actual Loss: 0.8731\n",
      "Baseline Loss: 3.4241 | Actual Loss: 1.2849\n",
      "Baseline Loss: 3.6091 | Actual Loss: 1.3815\n",
      "Baseline Loss: 3.7677 | Actual Loss: 2.9203\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.0720\n",
      "Baseline Loss: 3.4887 | Actual Loss: 1.0874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 63/1000 [00:24<06:01,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5212 | Actual Loss: 0.6367\n",
      "Baseline Loss: 3.6101 | Actual Loss: 1.0766\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.4789\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.3312\n",
      "Epoch 63/1000: Train Loss: 1.2877, Val Loss: 1.1308\n",
      "Baseline Loss: 3.3961 | Actual Loss: 1.1776\n",
      "Baseline Loss: 3.4846 | Actual Loss: 1.5431\n",
      "Baseline Loss: 3.5009 | Actual Loss: 0.7692\n",
      "Baseline Loss: 3.7320 | Actual Loss: 1.0923\n",
      "Baseline Loss: 3.4216 | Actual Loss: 1.2938\n",
      "Baseline Loss: 3.5629 | Actual Loss: 1.6482\n",
      "Baseline Loss: 3.7729 | Actual Loss: 0.6319\n",
      "Baseline Loss: 3.4282 | Actual Loss: 1.2892\n",
      "Baseline Loss: 3.4470 | Actual Loss: 1.7255\n",
      "Baseline Loss: 3.4319 | Actual Loss: 0.8455\n",
      "Baseline Loss: 3.6743 | Actual Loss: 1.3776\n",
      "Baseline Loss: 3.3408 | Actual Loss: 1.2588\n",
      "Baseline Loss: 3.4462 | Actual Loss: 1.2073\n",
      "Baseline Loss: 3.5608 | Actual Loss: 1.0136\n",
      "Baseline Loss: 3.7317 | Actual Loss: 1.0795\n",
      "Baseline Loss: 3.1539 | Actual Loss: 0.3452\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.5911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 64/1000 [00:24<06:13,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6101 | Actual Loss: 0.8919\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.4251\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.3490\n",
      "Epoch 64/1000: Train Loss: 1.1436, Val Loss: 1.0643\n",
      "Baseline Loss: 3.6047 | Actual Loss: 1.1854\n",
      "Baseline Loss: 3.3413 | Actual Loss: 1.0400\n",
      "Baseline Loss: 3.3851 | Actual Loss: 1.2966\n",
      "Baseline Loss: 3.6011 | Actual Loss: 1.7039\n",
      "Baseline Loss: 3.5128 | Actual Loss: 0.9672\n",
      "Baseline Loss: 3.3848 | Actual Loss: 1.4893\n",
      "Baseline Loss: 3.4853 | Actual Loss: 0.6107\n",
      "Baseline Loss: 3.5790 | Actual Loss: 1.0989\n",
      "Baseline Loss: 3.5135 | Actual Loss: 1.0155\n",
      "Baseline Loss: 3.6693 | Actual Loss: 0.7123\n",
      "Baseline Loss: 3.6147 | Actual Loss: 1.6844\n",
      "Baseline Loss: 3.5679 | Actual Loss: 1.0550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 65/1000 [00:25<05:53,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7319 | Actual Loss: 2.7989\n",
      "Baseline Loss: 3.2917 | Actual Loss: 0.8236\n",
      "Baseline Loss: 3.4660 | Actual Loss: 1.3989\n",
      "Baseline Loss: 3.6407 | Actual Loss: 2.8805\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.6870\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.7765\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.1408\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.1394\n",
      "Epoch 65/1000: Train Loss: 1.3601, Val Loss: 0.9359\n",
      "Baseline Loss: 3.5497 | Actual Loss: 0.7680\n",
      "Baseline Loss: 3.4402 | Actual Loss: 0.4958\n",
      "Baseline Loss: 3.7725 | Actual Loss: 1.4761\n",
      "Baseline Loss: 3.6781 | Actual Loss: 1.1199\n",
      "Baseline Loss: 3.2297 | Actual Loss: 0.8911\n",
      "Baseline Loss: 3.4467 | Actual Loss: 1.4093\n",
      "Baseline Loss: 3.6450 | Actual Loss: 2.1607\n",
      "Baseline Loss: 3.4691 | Actual Loss: 0.9839\n",
      "Baseline Loss: 3.4591 | Actual Loss: 1.1918\n",
      "Baseline Loss: 3.5176 | Actual Loss: 0.6440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 66/1000 [00:25<05:52,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5411 | Actual Loss: 1.2576\n",
      "Baseline Loss: 3.5655 | Actual Loss: 1.6079\n",
      "Baseline Loss: 3.4474 | Actual Loss: 0.9443\n",
      "Baseline Loss: 3.5534 | Actual Loss: 1.2258\n",
      "Baseline Loss: 3.4322 | Actual Loss: 1.2434\n",
      "Baseline Loss: 3.8498 | Actual Loss: 0.4514\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.5913\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.9761\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.5601\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.1071\n",
      "Epoch 66/1000: Train Loss: 1.1169, Val Loss: 1.0586\n",
      "Baseline Loss: 3.5375 | Actual Loss: 1.2389\n",
      "Baseline Loss: 3.5493 | Actual Loss: 0.9530\n",
      "Baseline Loss: 3.5245 | Actual Loss: 1.4029\n",
      "Baseline Loss: 3.4971 | Actual Loss: 0.6135\n",
      "Baseline Loss: 3.5333 | Actual Loss: 1.6888\n",
      "Baseline Loss: 3.3683 | Actual Loss: 0.9282\n",
      "Baseline Loss: 3.5283 | Actual Loss: 1.4322\n",
      "Baseline Loss: 3.7623 | Actual Loss: 1.1329\n",
      "Baseline Loss: 3.4171 | Actual Loss: 1.2387\n",
      "Baseline Loss: 3.7119 | Actual Loss: 1.2690\n",
      "Baseline Loss: 3.4283 | Actual Loss: 1.0262\n",
      "Baseline Loss: 3.6545 | Actual Loss: 0.9353\n",
      "Baseline Loss: 3.5661 | Actual Loss: 1.1280\n",
      "Baseline Loss: 3.3467 | Actual Loss: 1.0019\n",
      "Baseline Loss: 3.4239 | Actual Loss: 1.1109\n",
      "Baseline Loss: 3.2491 | Actual Loss: 1.1729\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.5763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 67/1000 [00:25<05:49,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6101 | Actual Loss: 0.9545\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.6320\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.0642\n",
      "Epoch 67/1000: Train Loss: 1.1421, Val Loss: 1.0568\n",
      "Baseline Loss: 3.3928 | Actual Loss: 1.9147\n",
      "Baseline Loss: 3.7175 | Actual Loss: 0.6977\n",
      "Baseline Loss: 3.5549 | Actual Loss: 1.1265\n",
      "Baseline Loss: 3.3436 | Actual Loss: 1.1147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 68/1000 [00:26<05:46,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6633 | Actual Loss: 0.7829\n",
      "Baseline Loss: 3.6826 | Actual Loss: 1.3144\n",
      "Baseline Loss: 3.5617 | Actual Loss: 1.3546\n",
      "Baseline Loss: 3.4577 | Actual Loss: 1.0667\n",
      "Baseline Loss: 3.4027 | Actual Loss: 0.8087\n",
      "Baseline Loss: 3.5360 | Actual Loss: 1.1021\n",
      "Baseline Loss: 3.7176 | Actual Loss: 1.4844\n",
      "Baseline Loss: 3.3958 | Actual Loss: 0.8883\n",
      "Baseline Loss: 3.4705 | Actual Loss: 1.0676\n",
      "Baseline Loss: 3.5875 | Actual Loss: 1.1123\n",
      "Baseline Loss: 3.5924 | Actual Loss: 1.0121\n",
      "Baseline Loss: 3.7139 | Actual Loss: 2.2059\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.6465\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.8271\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.4032\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.1756\n",
      "Epoch 68/1000: Train Loss: 1.1909, Val Loss: 1.0131\n",
      "Baseline Loss: 3.8212 | Actual Loss: 1.1705\n",
      "Baseline Loss: 3.3576 | Actual Loss: 1.1331\n",
      "Baseline Loss: 3.6923 | Actual Loss: 1.1320\n",
      "Baseline Loss: 3.4434 | Actual Loss: 1.6574\n",
      "Baseline Loss: 3.3351 | Actual Loss: 1.4890\n",
      "Baseline Loss: 3.6320 | Actual Loss: 2.3745\n",
      "Baseline Loss: 3.5333 | Actual Loss: 1.0541\n",
      "Baseline Loss: 3.5422 | Actual Loss: 0.9656\n",
      "Baseline Loss: 3.4357 | Actual Loss: 0.7284\n",
      "Baseline Loss: 3.5416 | Actual Loss: 1.2876\n",
      "Baseline Loss: 3.5796 | Actual Loss: 1.2672\n",
      "Baseline Loss: 3.6832 | Actual Loss: 0.8714\n",
      "Baseline Loss: 3.4283 | Actual Loss: 0.8944\n",
      "Baseline Loss: 3.4966 | Actual Loss: 0.5352\n",
      "Baseline Loss: 3.6688 | Actual Loss: 1.1169\n",
      "Baseline Loss: 3.6524 | Actual Loss: 4.7377\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.5985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 69/1000 [00:26<06:10,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6101 | Actual Loss: 0.8269\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.3402\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.0149\n",
      "Epoch 69/1000: Train Loss: 1.4009, Val Loss: 0.9452\n",
      "Baseline Loss: 3.4971 | Actual Loss: 0.9803\n",
      "Baseline Loss: 3.4579 | Actual Loss: 1.3111\n",
      "Baseline Loss: 3.4661 | Actual Loss: 2.1004\n",
      "Baseline Loss: 3.6879 | Actual Loss: 0.6268\n",
      "Baseline Loss: 3.4889 | Actual Loss: 1.1463\n",
      "Baseline Loss: 3.4780 | Actual Loss: 0.9660\n",
      "Baseline Loss: 3.5697 | Actual Loss: 0.7237\n",
      "Baseline Loss: 3.6135 | Actual Loss: 0.9325\n",
      "Baseline Loss: 3.4782 | Actual Loss: 1.2388\n",
      "Baseline Loss: 3.3432 | Actual Loss: 1.0465\n",
      "Baseline Loss: 3.8376 | Actual Loss: 2.0400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 70/1000 [00:27<05:42,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5011 | Actual Loss: 1.6840\n",
      "Baseline Loss: 3.4889 | Actual Loss: 0.8227\n",
      "Baseline Loss: 3.6504 | Actual Loss: 0.9879\n",
      "Baseline Loss: 3.6464 | Actual Loss: 0.8967\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.3606\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.6699\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.9091\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.3518\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.2032\n",
      "Epoch 70/1000: Train Loss: 1.1790, Val Loss: 1.0335\n",
      "Baseline Loss: 3.5628 | Actual Loss: 0.6893\n",
      "Baseline Loss: 3.7220 | Actual Loss: 1.2223\n",
      "Baseline Loss: 3.7025 | Actual Loss: 0.6669\n",
      "Baseline Loss: 3.5409 | Actual Loss: 0.7371\n",
      "Baseline Loss: 3.7267 | Actual Loss: 1.0911\n",
      "Baseline Loss: 3.4934 | Actual Loss: 1.5750\n",
      "Baseline Loss: 3.3684 | Actual Loss: 1.2195\n",
      "Baseline Loss: 3.3993 | Actual Loss: 1.5661\n",
      "Baseline Loss: 3.5248 | Actual Loss: 1.2103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 71/1000 [00:27<05:49,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5878 | Actual Loss: 0.9466\n",
      "Baseline Loss: 3.4271 | Actual Loss: 1.0056\n",
      "Baseline Loss: 3.3891 | Actual Loss: 1.2726\n",
      "Baseline Loss: 3.5539 | Actual Loss: 0.8407\n",
      "Baseline Loss: 3.5961 | Actual Loss: 1.4910\n",
      "Baseline Loss: 3.5880 | Actual Loss: 0.9406\n",
      "Baseline Loss: 3.1389 | Actual Loss: 0.7547\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.6154\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.8696\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.1910\n",
      "Baseline Loss: 3.3188 | Actual Loss: 0.9019\n",
      "Epoch 71/1000: Train Loss: 1.0768, Val Loss: 0.8945\n",
      "New best validation loss: 0.8945\n",
      "Baseline Loss: 3.7028 | Actual Loss: 1.0704\n",
      "Baseline Loss: 3.6007 | Actual Loss: 0.9592\n",
      "Baseline Loss: 3.5749 | Actual Loss: 0.5332\n",
      "Baseline Loss: 3.7009 | Actual Loss: 1.2826\n",
      "Baseline Loss: 3.5491 | Actual Loss: 2.0661\n",
      "Baseline Loss: 3.4469 | Actual Loss: 1.1805\n",
      "Baseline Loss: 3.3408 | Actual Loss: 1.1100\n",
      "Baseline Loss: 3.4734 | Actual Loss: 0.6295\n",
      "Baseline Loss: 3.5245 | Actual Loss: 1.3873\n",
      "Baseline Loss: 3.4882 | Actual Loss: 1.2108\n",
      "Baseline Loss: 3.5664 | Actual Loss: 0.8067\n",
      "Baseline Loss: 3.6409 | Actual Loss: 0.6838\n",
      "Baseline Loss: 3.6319 | Actual Loss: 1.5858\n",
      "Baseline Loss: 3.6236 | Actual Loss: 2.2613\n",
      "Baseline Loss: 3.5006 | Actual Loss: 1.5546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 72/1000 [00:27<05:49,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.1183 | Actual Loss: 0.3083\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.6680\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.8412\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.0116\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.1607\n",
      "Epoch 72/1000: Train Loss: 1.1644, Val Loss: 0.9204\n",
      "Baseline Loss: 3.4241 | Actual Loss: 0.8904\n",
      "Baseline Loss: 3.3255 | Actual Loss: 2.1127\n",
      "Baseline Loss: 3.5250 | Actual Loss: 1.6236\n",
      "Baseline Loss: 3.6733 | Actual Loss: 0.9817\n",
      "Baseline Loss: 3.2819 | Actual Loss: 0.7509\n",
      "Baseline Loss: 3.7023 | Actual Loss: 0.8831\n",
      "Baseline Loss: 3.3372 | Actual Loss: 0.6402\n",
      "Baseline Loss: 3.7994 | Actual Loss: 0.7367\n",
      "Baseline Loss: 3.5827 | Actual Loss: 1.1600\n",
      "Baseline Loss: 3.4254 | Actual Loss: 1.0990\n",
      "Baseline Loss: 3.4959 | Actual Loss: 0.9430\n",
      "Baseline Loss: 3.5284 | Actual Loss: 0.9826\n",
      "Baseline Loss: 3.4584 | Actual Loss: 1.5010\n",
      "Baseline Loss: 3.7576 | Actual Loss: 1.3969\n",
      "Baseline Loss: 3.6877 | Actual Loss: 1.1055\n",
      "Baseline Loss: 3.7139 | Actual Loss: 0.8589\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.7034\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.8697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 73/1000 [00:28<05:50,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5170 | Actual Loss: 1.2375\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.2216\n",
      "Epoch 73/1000: Train Loss: 1.1041, Val Loss: 1.0080\n",
      "Baseline Loss: 3.6365 | Actual Loss: 2.5003\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.1124\n",
      "Baseline Loss: 3.7020 | Actual Loss: 1.2529\n",
      "Baseline Loss: 3.3749 | Actual Loss: 0.8165\n",
      "Baseline Loss: 3.7618 | Actual Loss: 1.4864\n",
      "Baseline Loss: 3.5874 | Actual Loss: 1.3838\n",
      "Baseline Loss: 3.4768 | Actual Loss: 0.9122\n",
      "Baseline Loss: 3.5541 | Actual Loss: 1.1945\n",
      "Baseline Loss: 3.3995 | Actual Loss: 0.8976\n",
      "Baseline Loss: 3.4242 | Actual Loss: 0.8613\n",
      "Baseline Loss: 3.5050 | Actual Loss: 1.3251\n",
      "Baseline Loss: 3.4732 | Actual Loss: 1.2167\n",
      "Baseline Loss: 3.4969 | Actual Loss: 2.0450\n",
      "Baseline Loss: 3.4857 | Actual Loss: 1.1076\n",
      "Baseline Loss: 3.5208 | Actual Loss: 1.0358\n",
      "Baseline Loss: 3.1827 | Actual Loss: 0.4049\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.7504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 74/1000 [00:28<06:04,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6101 | Actual Loss: 0.7955\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.1312\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.0863\n",
      "Epoch 74/1000: Train Loss: 1.2221, Val Loss: 0.9409\n",
      "Baseline Loss: 3.4034 | Actual Loss: 0.6907\n",
      "Baseline Loss: 3.2453 | Actual Loss: 0.8175\n",
      "Baseline Loss: 3.5701 | Actual Loss: 2.3987\n",
      "Baseline Loss: 3.5206 | Actual Loss: 1.5402\n",
      "Baseline Loss: 3.3611 | Actual Loss: 0.6198\n",
      "Baseline Loss: 3.6458 | Actual Loss: 1.8246\n",
      "Baseline Loss: 3.3535 | Actual Loss: 2.1888\n",
      "Baseline Loss: 3.7166 | Actual Loss: 1.5610\n",
      "Baseline Loss: 3.4740 | Actual Loss: 1.5288\n",
      "Baseline Loss: 3.6639 | Actual Loss: 0.9877\n",
      "Baseline Loss: 3.5749 | Actual Loss: 0.9861\n",
      "Baseline Loss: 3.6363 | Actual Loss: 1.4958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 75/1000 [00:28<05:46,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6552 | Actual Loss: 0.8835\n",
      "Baseline Loss: 3.5329 | Actual Loss: 1.1314\n",
      "Baseline Loss: 3.5413 | Actual Loss: 0.7406\n",
      "Baseline Loss: 3.3313 | Actual Loss: 0.3822\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.6081\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.9406\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.3860\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.2069\n",
      "Epoch 75/1000: Train Loss: 1.2361, Val Loss: 1.0354\n",
      "Baseline Loss: 3.5879 | Actual Loss: 1.3880\n",
      "Baseline Loss: 3.5409 | Actual Loss: 0.7967\n",
      "Baseline Loss: 3.5004 | Actual Loss: 1.1053\n",
      "Baseline Loss: 3.7222 | Actual Loss: 0.9579\n",
      "Baseline Loss: 3.4804 | Actual Loss: 2.2174\n",
      "Baseline Loss: 3.4254 | Actual Loss: 1.0338\n",
      "Baseline Loss: 3.5752 | Actual Loss: 0.6144\n",
      "Baseline Loss: 3.3737 | Actual Loss: 0.6798\n",
      "Baseline Loss: 3.6317 | Actual Loss: 0.8521\n",
      "Baseline Loss: 3.5913 | Actual Loss: 1.0023\n",
      "Baseline Loss: 3.6272 | Actual Loss: 1.7955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 76/1000 [00:29<05:43,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3785 | Actual Loss: 1.0294\n",
      "Baseline Loss: 3.6367 | Actual Loss: 1.5150\n",
      "Baseline Loss: 3.4895 | Actual Loss: 0.7713\n",
      "Baseline Loss: 3.5032 | Actual Loss: 0.8371\n",
      "Baseline Loss: 3.4390 | Actual Loss: 0.3295\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.6035\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.8477\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.1833\n",
      "Baseline Loss: 3.3188 | Actual Loss: 0.9518\n",
      "Epoch 76/1000: Train Loss: 1.0578, Val Loss: 0.8966\n",
      "Baseline Loss: 3.5965 | Actual Loss: 0.9900\n",
      "Baseline Loss: 3.4420 | Actual Loss: 2.8867\n",
      "Baseline Loss: 3.4626 | Actual Loss: 1.2331\n",
      "Baseline Loss: 3.6185 | Actual Loss: 1.6089\n",
      "Baseline Loss: 3.2542 | Actual Loss: 0.8331\n",
      "Baseline Loss: 3.6320 | Actual Loss: 1.0067\n",
      "Baseline Loss: 3.4404 | Actual Loss: 0.9338\n",
      "Baseline Loss: 3.5039 | Actual Loss: 0.6348\n",
      "Baseline Loss: 3.6370 | Actual Loss: 1.4001\n",
      "Baseline Loss: 3.5581 | Actual Loss: 3.1443\n",
      "Baseline Loss: 3.6276 | Actual Loss: 0.8219\n",
      "Baseline Loss: 3.3106 | Actual Loss: 1.3087\n",
      "Baseline Loss: 3.5006 | Actual Loss: 1.0324\n",
      "Baseline Loss: 3.6458 | Actual Loss: 0.8080\n",
      "Baseline Loss: 3.4818 | Actual Loss: 0.7789\n",
      "Baseline Loss: 3.3061 | Actual Loss: 1.3551\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.6762\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.8636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 77/1000 [00:29<05:41,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5170 | Actual Loss: 1.1054\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.1202\n",
      "Epoch 77/1000: Train Loss: 1.2985, Val Loss: 0.9413\n",
      "Baseline Loss: 3.6503 | Actual Loss: 2.1296\n",
      "Baseline Loss: 3.5844 | Actual Loss: 0.9815\n",
      "Baseline Loss: 3.6644 | Actual Loss: 0.5649\n",
      "Baseline Loss: 3.4969 | Actual Loss: 0.8242\n",
      "Baseline Loss: 3.5917 | Actual Loss: 0.5551\n",
      "Baseline Loss: 3.4169 | Actual Loss: 1.8056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 78/1000 [00:30<05:42,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4534 | Actual Loss: 1.2882\n",
      "Baseline Loss: 3.5042 | Actual Loss: 1.1458\n",
      "Baseline Loss: 3.5414 | Actual Loss: 0.7855\n",
      "Baseline Loss: 3.3672 | Actual Loss: 0.9361\n",
      "Baseline Loss: 3.4632 | Actual Loss: 0.6710\n",
      "Baseline Loss: 3.5247 | Actual Loss: 0.9672\n",
      "Baseline Loss: 3.6051 | Actual Loss: 1.8121\n",
      "Baseline Loss: 3.5370 | Actual Loss: 0.7248\n",
      "Baseline Loss: 3.4934 | Actual Loss: 1.1592\n",
      "Baseline Loss: 3.3925 | Actual Loss: 0.8725\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.6939\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.8175\n",
      "Baseline Loss: 3.5170 | Actual Loss: 0.9354\n",
      "Baseline Loss: 3.3188 | Actual Loss: 0.8374\n",
      "Epoch 78/1000: Train Loss: 1.0765, Val Loss: 0.8211\n",
      "New best validation loss: 0.8211\n",
      "Baseline Loss: 3.5092 | Actual Loss: 2.1583\n",
      "Baseline Loss: 3.8432 | Actual Loss: 0.7891\n",
      "Baseline Loss: 3.4513 | Actual Loss: 1.3680\n",
      "Baseline Loss: 3.3406 | Actual Loss: 0.8132\n",
      "Baseline Loss: 3.5616 | Actual Loss: 2.4239\n",
      "Baseline Loss: 3.2392 | Actual Loss: 1.1465\n",
      "Baseline Loss: 3.5918 | Actual Loss: 0.9684\n",
      "Baseline Loss: 3.6973 | Actual Loss: 1.2466\n",
      "Baseline Loss: 3.8894 | Actual Loss: 0.9978\n",
      "Baseline Loss: 3.6459 | Actual Loss: 1.3389\n",
      "Baseline Loss: 3.5874 | Actual Loss: 0.9972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 79/1000 [00:30<05:58,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5088 | Actual Loss: 0.6837\n",
      "Baseline Loss: 3.3894 | Actual Loss: 1.0499\n",
      "Baseline Loss: 3.5663 | Actual Loss: 0.8185\n",
      "Baseline Loss: 3.4065 | Actual Loss: 1.5914\n",
      "Baseline Loss: 3.3491 | Actual Loss: 1.0850\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.6751\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.8412\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.0916\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.1446\n",
      "Epoch 79/1000: Train Loss: 1.2173, Val Loss: 0.9381\n",
      "Baseline Loss: 3.5163 | Actual Loss: 0.9918\n",
      "Baseline Loss: 3.5048 | Actual Loss: 0.5389\n",
      "Baseline Loss: 3.6827 | Actual Loss: 1.4237\n",
      "Baseline Loss: 3.3241 | Actual Loss: 1.5519\n",
      "Baseline Loss: 3.6143 | Actual Loss: 0.8986\n",
      "Baseline Loss: 3.4112 | Actual Loss: 0.5390\n",
      "Baseline Loss: 3.5709 | Actual Loss: 1.7560\n",
      "Baseline Loss: 3.4860 | Actual Loss: 1.5639\n",
      "Baseline Loss: 3.5825 | Actual Loss: 1.2970\n",
      "Baseline Loss: 3.4852 | Actual Loss: 0.9140\n",
      "Baseline Loss: 3.4649 | Actual Loss: 0.9732\n",
      "Baseline Loss: 3.5784 | Actual Loss: 0.6602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 80/1000 [00:30<05:37,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5135 | Actual Loss: 1.5084\n",
      "Baseline Loss: 3.6187 | Actual Loss: 0.9358\n",
      "Baseline Loss: 3.6324 | Actual Loss: 0.7584\n",
      "Baseline Loss: 3.7268 | Actual Loss: 1.6732\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.5497\n",
      "Baseline Loss: 3.6101 | Actual Loss: 1.0007\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.2677\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.2624\n",
      "Epoch 80/1000: Train Loss: 1.1240, Val Loss: 1.0201\n",
      "Baseline Loss: 3.4318 | Actual Loss: 2.0601\n",
      "Baseline Loss: 3.4035 | Actual Loss: 0.8346\n",
      "Baseline Loss: 3.8721 | Actual Loss: 1.5021\n",
      "Baseline Loss: 3.5166 | Actual Loss: 1.4978\n",
      "Baseline Loss: 3.5918 | Actual Loss: 0.5918\n",
      "Baseline Loss: 3.3646 | Actual Loss: 1.3065\n",
      "Baseline Loss: 3.5010 | Actual Loss: 1.1797\n",
      "Baseline Loss: 3.6498 | Actual Loss: 1.2036\n",
      "Baseline Loss: 3.3899 | Actual Loss: 0.9823\n",
      "Baseline Loss: 3.8381 | Actual Loss: 0.7519\n",
      "Baseline Loss: 3.4624 | Actual Loss: 1.0467\n",
      "Baseline Loss: 3.4314 | Actual Loss: 0.8634\n",
      "Baseline Loss: 3.4579 | Actual Loss: 0.8985\n",
      "Baseline Loss: 3.7214 | Actual Loss: 3.3488\n",
      "Baseline Loss: 3.6412 | Actual Loss: 0.7956\n",
      "Baseline Loss: 3.1533 | Actual Loss: 1.3507\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.7320\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.7131\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.3308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 81/1000 [00:31<05:40,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3188 | Actual Loss: 0.8845\n",
      "Epoch 81/1000: Train Loss: 1.2634, Val Loss: 0.9151\n",
      "Baseline Loss: 3.3482 | Actual Loss: 1.1147\n",
      "Baseline Loss: 3.5488 | Actual Loss: 2.2748\n",
      "Baseline Loss: 3.6782 | Actual Loss: 2.2029\n",
      "Baseline Loss: 3.6138 | Actual Loss: 1.4277\n",
      "Baseline Loss: 3.5124 | Actual Loss: 3.1608\n",
      "Baseline Loss: 3.3198 | Actual Loss: 1.7550\n",
      "Baseline Loss: 3.5877 | Actual Loss: 1.3239\n",
      "Baseline Loss: 3.4767 | Actual Loss: 1.7833\n",
      "Baseline Loss: 3.6225 | Actual Loss: 0.5836\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.2287\n",
      "Baseline Loss: 3.5581 | Actual Loss: 1.2233\n",
      "Baseline Loss: 3.6460 | Actual Loss: 0.6795\n",
      "Baseline Loss: 3.3340 | Actual Loss: 1.2394\n",
      "Baseline Loss: 3.4971 | Actual Loss: 0.6082\n",
      "Baseline Loss: 3.5962 | Actual Loss: 1.6761\n",
      "Baseline Loss: 3.3316 | Actual Loss: 0.8975\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.5924\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.9868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 82/1000 [00:31<05:57,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5170 | Actual Loss: 1.4912\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.4251\n",
      "Epoch 82/1000: Train Loss: 1.4487, Val Loss: 1.1239\n",
      "Baseline Loss: 3.4062 | Actual Loss: 1.1591\n",
      "Baseline Loss: 3.4695 | Actual Loss: 1.2332\n",
      "Baseline Loss: 3.8101 | Actual Loss: 2.0324\n",
      "Baseline Loss: 3.6507 | Actual Loss: 1.1745\n",
      "Baseline Loss: 3.3552 | Actual Loss: 0.8601\n",
      "Baseline Loss: 3.5045 | Actual Loss: 1.4915\n",
      "Baseline Loss: 3.5707 | Actual Loss: 1.2756\n",
      "Baseline Loss: 3.5171 | Actual Loss: 1.2126\n",
      "Baseline Loss: 3.4616 | Actual Loss: 1.0231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 83/1000 [00:31<05:40,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5709 | Actual Loss: 1.8094\n",
      "Baseline Loss: 3.3508 | Actual Loss: 1.8741\n",
      "Baseline Loss: 3.6547 | Actual Loss: 1.5989\n",
      "Baseline Loss: 3.5204 | Actual Loss: 1.3934\n",
      "Baseline Loss: 3.4059 | Actual Loss: 1.1673\n",
      "Baseline Loss: 3.4429 | Actual Loss: 1.1241\n",
      "Baseline Loss: 3.5727 | Actual Loss: 0.2601\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.5862\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.9170\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.0908\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.2121\n",
      "Epoch 83/1000: Train Loss: 1.2931, Val Loss: 0.9515\n",
      "Baseline Loss: 3.5528 | Actual Loss: 1.3643\n",
      "Baseline Loss: 3.3338 | Actual Loss: 1.4981\n",
      "Baseline Loss: 3.4517 | Actual Loss: 1.0813\n",
      "Baseline Loss: 3.9253 | Actual Loss: 0.9334\n",
      "Baseline Loss: 3.5043 | Actual Loss: 0.7161\n",
      "Baseline Loss: 3.5537 | Actual Loss: 0.9465\n",
      "Baseline Loss: 3.6550 | Actual Loss: 1.5463\n",
      "Baseline Loss: 3.3379 | Actual Loss: 0.9257\n",
      "Baseline Loss: 3.7069 | Actual Loss: 0.7991\n",
      "Baseline Loss: 3.4397 | Actual Loss: 1.0033\n",
      "Baseline Loss: 3.6181 | Actual Loss: 1.2781\n",
      "Baseline Loss: 3.7164 | Actual Loss: 1.4750\n",
      "Baseline Loss: 3.4963 | Actual Loss: 4.2611\n",
      "Baseline Loss: 3.3792 | Actual Loss: 1.1205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 84/1000 [00:32<05:56,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6696 | Actual Loss: 2.3346\n",
      "Baseline Loss: 3.5835 | Actual Loss: 0.9072\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.7007\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.8757\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.3761\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.3346\n",
      "Epoch 84/1000: Train Loss: 1.3869, Val Loss: 1.0718\n",
      "Baseline Loss: 3.5183 | Actual Loss: 1.1060\n",
      "Baseline Loss: 3.5213 | Actual Loss: 0.5445\n",
      "Baseline Loss: 3.5617 | Actual Loss: 1.2718\n",
      "Baseline Loss: 3.6319 | Actual Loss: 1.4421\n",
      "Baseline Loss: 3.7074 | Actual Loss: 1.3695\n",
      "Baseline Loss: 3.3959 | Actual Loss: 1.3207\n",
      "Baseline Loss: 3.5331 | Actual Loss: 1.0429\n",
      "Baseline Loss: 3.7118 | Actual Loss: 0.8732\n",
      "Baseline Loss: 3.7625 | Actual Loss: 2.3534\n",
      "Baseline Loss: 3.5038 | Actual Loss: 1.3340\n",
      "Baseline Loss: 3.5660 | Actual Loss: 0.9903\n",
      "Baseline Loss: 3.6103 | Actual Loss: 0.8240\n",
      "Baseline Loss: 3.2484 | Actual Loss: 1.1193\n",
      "Baseline Loss: 3.5578 | Actual Loss: 1.8991\n",
      "Baseline Loss: 3.4008 | Actual Loss: 1.4346\n",
      "Baseline Loss: 3.4692 | Actual Loss: 1.3669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 85/1000 [00:32<05:57,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5212 | Actual Loss: 0.7452\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.8538\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.3116\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.3013\n",
      "Epoch 85/1000: Train Loss: 1.2683, Val Loss: 1.0530\n",
      "Baseline Loss: 3.3304 | Actual Loss: 0.8903\n",
      "Baseline Loss: 3.4590 | Actual Loss: 0.9260\n",
      "Baseline Loss: 3.3333 | Actual Loss: 0.8977\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.2444\n",
      "Baseline Loss: 3.7122 | Actual Loss: 1.0080\n",
      "Baseline Loss: 3.5748 | Actual Loss: 1.3045\n",
      "Baseline Loss: 3.5339 | Actual Loss: 0.5169\n",
      "Baseline Loss: 3.6097 | Actual Loss: 0.3103\n",
      "Baseline Loss: 3.6454 | Actual Loss: 1.1524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▊         | 86/1000 [00:33<05:47,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5545 | Actual Loss: 1.3414\n",
      "Baseline Loss: 3.6501 | Actual Loss: 1.1567\n",
      "Baseline Loss: 3.7078 | Actual Loss: 1.4256\n",
      "Baseline Loss: 3.5573 | Actual Loss: 0.8132\n",
      "Baseline Loss: 3.5203 | Actual Loss: 1.5572\n",
      "Baseline Loss: 3.7468 | Actual Loss: 1.0430\n",
      "Baseline Loss: 3.1309 | Actual Loss: 3.6162\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.6791\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.7712\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.0611\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.0740\n",
      "Epoch 86/1000: Train Loss: 1.2002, Val Loss: 0.8964\n",
      "Baseline Loss: 3.5959 | Actual Loss: 0.6120\n",
      "Baseline Loss: 3.4324 | Actual Loss: 3.3745\n",
      "Baseline Loss: 3.5367 | Actual Loss: 1.0078\n",
      "Baseline Loss: 3.5018 | Actual Loss: 1.2258\n",
      "Baseline Loss: 3.5289 | Actual Loss: 0.6116\n",
      "Baseline Loss: 3.5796 | Actual Loss: 0.3971\n",
      "Baseline Loss: 3.3818 | Actual Loss: 1.3706\n",
      "Baseline Loss: 3.5042 | Actual Loss: 0.8720\n",
      "Baseline Loss: 3.7781 | Actual Loss: 3.4812\n",
      "Baseline Loss: 3.5746 | Actual Loss: 0.9156\n",
      "Baseline Loss: 3.5492 | Actual Loss: 1.0626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▊         | 87/1000 [00:33<05:54,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4706 | Actual Loss: 1.9001\n",
      "Baseline Loss: 3.6004 | Actual Loss: 0.8100\n",
      "Baseline Loss: 3.3784 | Actual Loss: 0.8925\n",
      "Baseline Loss: 3.4543 | Actual Loss: 1.1498\n",
      "Baseline Loss: 3.2826 | Actual Loss: 1.0001\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.6129\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.9186\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.4055\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.3781\n",
      "Epoch 87/1000: Train Loss: 1.2927, Val Loss: 1.0788\n",
      "Baseline Loss: 3.4254 | Actual Loss: 0.8867\n",
      "Baseline Loss: 3.4282 | Actual Loss: 1.2648\n",
      "Baseline Loss: 3.4967 | Actual Loss: 0.9222\n",
      "Baseline Loss: 3.5578 | Actual Loss: 1.1421\n",
      "Baseline Loss: 3.5049 | Actual Loss: 0.6730\n",
      "Baseline Loss: 3.4316 | Actual Loss: 1.3141\n",
      "Baseline Loss: 3.4359 | Actual Loss: 1.0643\n",
      "Baseline Loss: 3.4735 | Actual Loss: 0.8760\n",
      "Baseline Loss: 3.5874 | Actual Loss: 0.6642\n",
      "Baseline Loss: 3.4814 | Actual Loss: 1.2903\n",
      "Baseline Loss: 3.5925 | Actual Loss: 0.9234\n",
      "Baseline Loss: 3.8048 | Actual Loss: 0.9429\n",
      "Baseline Loss: 3.6550 | Actual Loss: 2.0101\n",
      "Baseline Loss: 3.4885 | Actual Loss: 2.4971\n",
      "Baseline Loss: 3.5208 | Actual Loss: 0.5380\n",
      "Baseline Loss: 3.5838 | Actual Loss: 1.1293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 88/1000 [00:33<05:26,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5212 | Actual Loss: 0.6766\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.7710\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.0850\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.1538\n",
      "Epoch 88/1000: Train Loss: 1.1336, Val Loss: 0.9216\n",
      "Baseline Loss: 3.4724 | Actual Loss: 0.6248\n",
      "Baseline Loss: 3.5131 | Actual Loss: 0.8869\n",
      "Baseline Loss: 3.6002 | Actual Loss: 1.0350\n",
      "Baseline Loss: 3.6228 | Actual Loss: 0.8245\n",
      "Baseline Loss: 3.5793 | Actual Loss: 1.0667\n",
      "Baseline Loss: 3.5241 | Actual Loss: 1.4387\n",
      "Baseline Loss: 3.6967 | Actual Loss: 0.7570\n",
      "Baseline Loss: 3.6930 | Actual Loss: 1.1855\n",
      "Baseline Loss: 3.3860 | Actual Loss: 0.5754\n",
      "Baseline Loss: 3.4784 | Actual Loss: 1.2447\n",
      "Baseline Loss: 3.4736 | Actual Loss: 0.9363\n",
      "Baseline Loss: 3.6404 | Actual Loss: 0.6640\n",
      "Baseline Loss: 3.5414 | Actual Loss: 0.9248\n",
      "Baseline Loss: 3.5288 | Actual Loss: 1.3035\n",
      "Baseline Loss: 3.2470 | Actual Loss: 1.0463\n",
      "Baseline Loss: 3.4018 | Actual Loss: 0.8812\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.6239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 89/1000 [00:34<05:48,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6101 | Actual Loss: 0.8585\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.3336\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.3787\n",
      "Epoch 89/1000: Train Loss: 0.9622, Val Loss: 1.0487\n",
      "Baseline Loss: 3.5059 | Actual Loss: 1.5125\n",
      "Baseline Loss: 3.6277 | Actual Loss: 1.2721\n",
      "Baseline Loss: 3.6546 | Actual Loss: 0.3039\n",
      "Baseline Loss: 3.6456 | Actual Loss: 1.2024\n",
      "Baseline Loss: 3.4314 | Actual Loss: 1.3300\n",
      "Baseline Loss: 3.3920 | Actual Loss: 0.8501\n",
      "Baseline Loss: 3.4293 | Actual Loss: 1.4711\n",
      "Baseline Loss: 3.7171 | Actual Loss: 1.8183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 90/1000 [00:34<05:27,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5872 | Actual Loss: 2.9031\n",
      "Baseline Loss: 3.5334 | Actual Loss: 0.8984\n",
      "Baseline Loss: 3.6365 | Actual Loss: 0.5858\n",
      "Baseline Loss: 3.4556 | Actual Loss: 0.7637\n",
      "Baseline Loss: 3.3071 | Actual Loss: 1.6365\n",
      "Baseline Loss: 3.5701 | Actual Loss: 1.0337\n",
      "Baseline Loss: 3.4136 | Actual Loss: 0.6517\n",
      "Baseline Loss: 3.6886 | Actual Loss: 0.8843\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.6900\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.8481\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.4682\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.2488\n",
      "Epoch 90/1000: Train Loss: 1.1948, Val Loss: 1.0638\n",
      "Baseline Loss: 3.6008 | Actual Loss: 1.1076\n",
      "Baseline Loss: 3.4476 | Actual Loss: 1.1249\n",
      "Baseline Loss: 3.5794 | Actual Loss: 0.9377\n",
      "Baseline Loss: 3.3436 | Actual Loss: 1.0623\n",
      "Baseline Loss: 3.7936 | Actual Loss: 4.2491\n",
      "Baseline Loss: 3.7831 | Actual Loss: 0.8851\n",
      "Baseline Loss: 3.4943 | Actual Loss: 1.0285\n",
      "Baseline Loss: 3.7784 | Actual Loss: 2.9191\n",
      "Baseline Loss: 3.4931 | Actual Loss: 0.9715\n",
      "Baseline Loss: 3.4245 | Actual Loss: 1.0222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 91/1000 [00:35<05:54,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5015 | Actual Loss: 0.5754\n",
      "Baseline Loss: 3.6449 | Actual Loss: 2.2222\n",
      "Baseline Loss: 3.4537 | Actual Loss: 1.1096\n",
      "Baseline Loss: 3.3314 | Actual Loss: 0.6657\n",
      "Baseline Loss: 3.5378 | Actual Loss: 1.3034\n",
      "Baseline Loss: 3.3839 | Actual Loss: 3.6109\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.7203\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.8207\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.1724\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.3030\n",
      "Epoch 91/1000: Train Loss: 1.5497, Val Loss: 1.0041\n",
      "Baseline Loss: 3.3405 | Actual Loss: 1.1489\n",
      "Baseline Loss: 3.7069 | Actual Loss: 0.6428\n",
      "Baseline Loss: 3.6007 | Actual Loss: 0.6021\n",
      "Baseline Loss: 3.4928 | Actual Loss: 0.8697\n",
      "Baseline Loss: 3.3924 | Actual Loss: 3.2620\n",
      "Baseline Loss: 3.4358 | Actual Loss: 0.8144\n",
      "Baseline Loss: 3.5487 | Actual Loss: 0.5553\n",
      "Baseline Loss: 3.5415 | Actual Loss: 0.4315\n",
      "Baseline Loss: 3.2544 | Actual Loss: 0.7964\n",
      "Baseline Loss: 3.9886 | Actual Loss: 3.5013\n",
      "Baseline Loss: 3.5372 | Actual Loss: 1.2159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 92/1000 [00:35<05:53,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5880 | Actual Loss: 0.7249\n",
      "Baseline Loss: 3.4728 | Actual Loss: 1.7766\n",
      "Baseline Loss: 3.8954 | Actual Loss: 3.1971\n",
      "Baseline Loss: 3.3576 | Actual Loss: 0.7683\n",
      "Baseline Loss: 3.5951 | Actual Loss: 1.3506\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.6895\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.7262\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.0974\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.1258\n",
      "Epoch 92/1000: Train Loss: 1.3536, Val Loss: 0.9097\n",
      "Baseline Loss: 3.6007 | Actual Loss: 0.6159\n",
      "Baseline Loss: 3.4502 | Actual Loss: 1.5411\n",
      "Baseline Loss: 3.7316 | Actual Loss: 3.7362\n",
      "Baseline Loss: 3.4572 | Actual Loss: 1.1744\n",
      "Baseline Loss: 3.5129 | Actual Loss: 0.9412\n",
      "Baseline Loss: 3.3610 | Actual Loss: 1.1072\n",
      "Baseline Loss: 3.6317 | Actual Loss: 1.4669\n",
      "Baseline Loss: 3.6102 | Actual Loss: 0.6264\n",
      "Baseline Loss: 3.7423 | Actual Loss: 0.4798\n",
      "Baseline Loss: 3.3953 | Actual Loss: 0.6049\n",
      "Baseline Loss: 3.4093 | Actual Loss: 2.9546\n",
      "Baseline Loss: 3.5413 | Actual Loss: 1.3622\n",
      "Baseline Loss: 3.6496 | Actual Loss: 3.3228\n",
      "Baseline Loss: 3.5832 | Actual Loss: 0.6508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 93/1000 [00:35<05:42,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5332 | Actual Loss: 0.5694\n",
      "Baseline Loss: 3.2900 | Actual Loss: 0.8874\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.6585\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.9074\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.3290\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.2336\n",
      "Epoch 93/1000: Train Loss: 1.3776, Val Loss: 1.0321\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.0004\n",
      "Baseline Loss: 3.5661 | Actual Loss: 0.6935\n",
      "Baseline Loss: 3.4397 | Actual Loss: 1.2380\n",
      "Baseline Loss: 3.2771 | Actual Loss: 1.5114\n",
      "Baseline Loss: 3.7367 | Actual Loss: 1.4858\n",
      "Baseline Loss: 3.7525 | Actual Loss: 1.0667\n",
      "Baseline Loss: 3.4898 | Actual Loss: 0.7560\n",
      "Baseline Loss: 3.4784 | Actual Loss: 0.9576\n",
      "Baseline Loss: 3.6323 | Actual Loss: 1.6656\n",
      "Baseline Loss: 3.3721 | Actual Loss: 1.0141\n",
      "Baseline Loss: 3.4924 | Actual Loss: 1.0421\n",
      "Baseline Loss: 3.5163 | Actual Loss: 1.0336\n",
      "Baseline Loss: 3.5967 | Actual Loss: 0.7320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 94/1000 [00:36<06:01,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4425 | Actual Loss: 0.5501\n",
      "Baseline Loss: 3.6598 | Actual Loss: 0.6491\n",
      "Baseline Loss: 3.2740 | Actual Loss: 0.6062\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.6745\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.8360\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.2356\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.1009\n",
      "Epoch 94/1000: Train Loss: 1.0001, Val Loss: 0.9618\n",
      "Baseline Loss: 3.2887 | Actual Loss: 1.1714\n",
      "Baseline Loss: 3.7467 | Actual Loss: 1.3366\n",
      "Baseline Loss: 3.5538 | Actual Loss: 0.6484\n",
      "Baseline Loss: 3.6363 | Actual Loss: 1.0328\n",
      "Baseline Loss: 3.6781 | Actual Loss: 0.7199\n",
      "Baseline Loss: 3.4888 | Actual Loss: 0.6891\n",
      "Baseline Loss: 3.4098 | Actual Loss: 1.2903\n",
      "Baseline Loss: 3.4887 | Actual Loss: 1.4984\n",
      "Baseline Loss: 3.4889 | Actual Loss: 0.6737\n",
      "Baseline Loss: 3.7373 | Actual Loss: 0.9931\n",
      "Baseline Loss: 3.5253 | Actual Loss: 0.8494\n",
      "Baseline Loss: 3.4884 | Actual Loss: 0.5721\n",
      "Baseline Loss: 3.5405 | Actual Loss: 1.9529\n",
      "Baseline Loss: 3.6503 | Actual Loss: 2.3018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 95/1000 [00:36<05:59,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4936 | Actual Loss: 1.5965\n",
      "Baseline Loss: 3.4891 | Actual Loss: 1.7659\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.6787\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.9010\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.3376\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.2044\n",
      "Epoch 95/1000: Train Loss: 1.1933, Val Loss: 1.0304\n",
      "Baseline Loss: 3.5091 | Actual Loss: 0.5581\n",
      "Baseline Loss: 3.4205 | Actual Loss: 1.6232\n",
      "Baseline Loss: 3.5335 | Actual Loss: 0.8591\n",
      "Baseline Loss: 3.7580 | Actual Loss: 0.8366\n",
      "Baseline Loss: 3.5250 | Actual Loss: 0.7943\n",
      "Baseline Loss: 3.6141 | Actual Loss: 0.6129\n",
      "Baseline Loss: 3.4626 | Actual Loss: 1.2667\n",
      "Baseline Loss: 3.6363 | Actual Loss: 2.1959\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.6807\n",
      "Baseline Loss: 3.5011 | Actual Loss: 0.7843\n",
      "Baseline Loss: 3.2977 | Actual Loss: 3.4407\n",
      "Baseline Loss: 3.6878 | Actual Loss: 0.4965\n",
      "Baseline Loss: 3.5706 | Actual Loss: 0.9143\n",
      "Baseline Loss: 3.5920 | Actual Loss: 1.3631\n",
      "Baseline Loss: 3.6049 | Actual Loss: 0.8403\n",
      "Baseline Loss: 3.3497 | Actual Loss: 1.2769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 96/1000 [00:37<05:54,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5212 | Actual Loss: 0.6860\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.9602\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.3673\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.1824\n",
      "Epoch 96/1000: Train Loss: 1.1590, Val Loss: 1.0489\n",
      "Baseline Loss: 3.4103 | Actual Loss: 1.0868\n",
      "Baseline Loss: 3.5579 | Actual Loss: 0.6824\n",
      "Baseline Loss: 3.5543 | Actual Loss: 1.4452\n",
      "Baseline Loss: 3.4702 | Actual Loss: 1.0473\n",
      "Baseline Loss: 3.5788 | Actual Loss: 0.8400\n",
      "Baseline Loss: 3.5709 | Actual Loss: 0.5290\n",
      "Baseline Loss: 3.5892 | Actual Loss: 2.0149\n",
      "Baseline Loss: 3.7372 | Actual Loss: 2.7073\n",
      "Baseline Loss: 3.6222 | Actual Loss: 1.0467\n",
      "Baseline Loss: 3.2794 | Actual Loss: 0.7619\n",
      "Baseline Loss: 3.3782 | Actual Loss: 0.7795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 97/1000 [00:37<05:56,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3849 | Actual Loss: 1.7047\n",
      "Baseline Loss: 3.6596 | Actual Loss: 0.4589\n",
      "Baseline Loss: 3.4967 | Actual Loss: 1.2388\n",
      "Baseline Loss: 3.6005 | Actual Loss: 1.5558\n",
      "Baseline Loss: 3.2896 | Actual Loss: 1.4445\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.6269\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.8398\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.1312\n",
      "Baseline Loss: 3.3188 | Actual Loss: 0.9633\n",
      "Epoch 97/1000: Train Loss: 1.2090, Val Loss: 0.8903\n",
      "Baseline Loss: 3.5580 | Actual Loss: 1.1911\n",
      "Baseline Loss: 3.5742 | Actual Loss: 0.9379\n",
      "Baseline Loss: 3.7265 | Actual Loss: 0.8235\n",
      "Baseline Loss: 3.5961 | Actual Loss: 0.8050\n",
      "Baseline Loss: 3.7124 | Actual Loss: 0.5351\n",
      "Baseline Loss: 3.4359 | Actual Loss: 0.7989\n",
      "Baseline Loss: 3.5965 | Actual Loss: 1.1969\n",
      "Baseline Loss: 3.3400 | Actual Loss: 1.1298\n",
      "Baseline Loss: 3.5413 | Actual Loss: 1.6195\n",
      "Baseline Loss: 3.2758 | Actual Loss: 1.0611\n",
      "Baseline Loss: 3.5877 | Actual Loss: 1.0345\n",
      "Baseline Loss: 3.4895 | Actual Loss: 0.5751\n",
      "Baseline Loss: 3.3271 | Actual Loss: 1.0141\n",
      "Baseline Loss: 3.7319 | Actual Loss: 0.9692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 98/1000 [00:37<05:35,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4317 | Actual Loss: 1.2158\n",
      "Baseline Loss: 3.2906 | Actual Loss: 0.3484\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.6722\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.8427\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.2746\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.2747\n",
      "Epoch 98/1000: Train Loss: 0.9535, Val Loss: 1.0160\n",
      "Baseline Loss: 3.4356 | Actual Loss: 0.6437\n",
      "Baseline Loss: 3.4031 | Actual Loss: 2.2191\n",
      "Baseline Loss: 3.6731 | Actual Loss: 1.5979\n",
      "Baseline Loss: 3.6447 | Actual Loss: 0.8410\n",
      "Baseline Loss: 3.4971 | Actual Loss: 1.1843\n",
      "Baseline Loss: 3.4284 | Actual Loss: 1.4735\n",
      "Baseline Loss: 3.6235 | Actual Loss: 0.8102\n",
      "Baseline Loss: 3.6364 | Actual Loss: 1.0926\n",
      "Baseline Loss: 3.5961 | Actual Loss: 0.7830\n",
      "Baseline Loss: 3.5538 | Actual Loss: 1.2048\n",
      "Baseline Loss: 3.4857 | Actual Loss: 0.3923\n",
      "Baseline Loss: 3.3549 | Actual Loss: 0.9681\n",
      "Baseline Loss: 3.5873 | Actual Loss: 2.5315\n",
      "Baseline Loss: 3.6355 | Actual Loss: 0.8531\n",
      "Baseline Loss: 3.6279 | Actual Loss: 1.0309\n",
      "Baseline Loss: 3.4494 | Actual Loss: 0.6386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 99/1000 [00:38<05:53,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5212 | Actual Loss: 0.6742\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.7590\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.0800\n",
      "Baseline Loss: 3.3188 | Actual Loss: 0.9613\n",
      "Epoch 99/1000: Train Loss: 1.1415, Val Loss: 0.8686\n",
      "Baseline Loss: 3.5207 | Actual Loss: 3.2888\n",
      "Baseline Loss: 3.5492 | Actual Loss: 0.7670\n",
      "Baseline Loss: 3.4656 | Actual Loss: 1.3735\n",
      "Baseline Loss: 3.4391 | Actual Loss: 0.7988\n",
      "Baseline Loss: 3.5776 | Actual Loss: 0.5770\n",
      "Baseline Loss: 3.4174 | Actual Loss: 1.5822\n",
      "Baseline Loss: 3.6553 | Actual Loss: 0.7826\n",
      "Baseline Loss: 3.4175 | Actual Loss: 1.0524\n",
      "Baseline Loss: 3.5961 | Actual Loss: 0.7132\n",
      "Baseline Loss: 3.4405 | Actual Loss: 1.4072\n",
      "Baseline Loss: 3.6501 | Actual Loss: 1.6805\n",
      "Baseline Loss: 3.3413 | Actual Loss: 1.7764\n",
      "Baseline Loss: 3.6507 | Actual Loss: 1.9792\n",
      "Baseline Loss: 3.5206 | Actual Loss: 0.5719\n",
      "Baseline Loss: 3.6598 | Actual Loss: 4.1384\n",
      "Baseline Loss: 3.5954 | Actual Loss: 1.4980\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.7395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 100/1000 [00:38<05:57,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6101 | Actual Loss: 0.8544\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.4095\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.2720\n",
      "Epoch 100/1000: Train Loss: 1.4992, Val Loss: 1.0689\n",
      "Baseline Loss: 3.9440 | Actual Loss: 2.1983\n",
      "Baseline Loss: 3.2684 | Actual Loss: 1.0080\n",
      "Baseline Loss: 3.4145 | Actual Loss: 0.9824\n",
      "Baseline Loss: 3.5285 | Actual Loss: 1.1361\n",
      "Baseline Loss: 3.5360 | Actual Loss: 0.6593\n",
      "Baseline Loss: 3.3719 | Actual Loss: 1.0207\n",
      "Baseline Loss: 3.5315 | Actual Loss: 0.7902\n",
      "Baseline Loss: 3.4216 | Actual Loss: 1.3549\n",
      "Baseline Loss: 3.4065 | Actual Loss: 0.8690\n",
      "Baseline Loss: 3.4393 | Actual Loss: 1.1557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 101/1000 [00:38<05:45,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5887 | Actual Loss: 0.9154\n",
      "Baseline Loss: 3.7311 | Actual Loss: 1.5217\n",
      "Baseline Loss: 3.4362 | Actual Loss: 0.6718\n",
      "Baseline Loss: 3.4617 | Actual Loss: 1.1447\n",
      "Baseline Loss: 3.7473 | Actual Loss: 0.6115\n",
      "Baseline Loss: 3.5616 | Actual Loss: 1.3899\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.6849\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.8094\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.3879\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.4204\n",
      "Epoch 101/1000: Train Loss: 1.0894, Val Loss: 1.0756\n",
      "Baseline Loss: 3.4887 | Actual Loss: 0.6150\n",
      "Baseline Loss: 3.4772 | Actual Loss: 0.9394\n",
      "Baseline Loss: 3.5923 | Actual Loss: 0.8822\n",
      "Baseline Loss: 3.3516 | Actual Loss: 1.0927\n",
      "Baseline Loss: 3.5409 | Actual Loss: 1.3188\n",
      "Baseline Loss: 3.5282 | Actual Loss: 1.1582\n",
      "Baseline Loss: 3.4137 | Actual Loss: 0.5489\n",
      "Baseline Loss: 3.5416 | Actual Loss: 1.1600\n",
      "Baseline Loss: 3.7025 | Actual Loss: 0.4198\n",
      "Baseline Loss: 3.3512 | Actual Loss: 1.1331\n",
      "Baseline Loss: 3.7832 | Actual Loss: 2.5431\n",
      "Baseline Loss: 3.7474 | Actual Loss: 0.4845\n",
      "Baseline Loss: 3.4774 | Actual Loss: 1.3992\n",
      "Baseline Loss: 3.4329 | Actual Loss: 0.6643\n",
      "Baseline Loss: 3.4436 | Actual Loss: 0.3595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 102/1000 [00:39<05:45,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.2662 | Actual Loss: 0.7442\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.5902\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.7849\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.0880\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.0163\n",
      "Epoch 102/1000: Train Loss: 0.9664, Val Loss: 0.8698\n",
      "Baseline Loss: 3.6929 | Actual Loss: 2.1309\n",
      "Baseline Loss: 3.6190 | Actual Loss: 1.1475\n",
      "Baseline Loss: 3.4660 | Actual Loss: 1.3350\n",
      "Baseline Loss: 3.4107 | Actual Loss: 0.8961\n",
      "Baseline Loss: 3.8952 | Actual Loss: 1.1941\n",
      "Baseline Loss: 3.5579 | Actual Loss: 0.6027\n",
      "Baseline Loss: 3.5050 | Actual Loss: 1.2832\n",
      "Baseline Loss: 3.3929 | Actual Loss: 0.8590\n",
      "Baseline Loss: 3.4928 | Actual Loss: 0.9804\n",
      "Baseline Loss: 3.5136 | Actual Loss: 1.8459\n",
      "Baseline Loss: 3.5048 | Actual Loss: 1.1222\n",
      "Baseline Loss: 3.7514 | Actual Loss: 0.3819\n",
      "Baseline Loss: 3.3881 | Actual Loss: 3.1396\n",
      "Baseline Loss: 3.4924 | Actual Loss: 0.8211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 103/1000 [00:39<05:54,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3102 | Actual Loss: 0.4846\n",
      "Baseline Loss: 3.3577 | Actual Loss: 1.0565\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.6228\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.8311\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.5008\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.1796\n",
      "Epoch 103/1000: Train Loss: 1.2050, Val Loss: 1.0336\n",
      "Baseline Loss: 3.3025 | Actual Loss: 0.9550\n",
      "Baseline Loss: 3.6235 | Actual Loss: 0.7050\n",
      "Baseline Loss: 3.3747 | Actual Loss: 0.8885\n",
      "Baseline Loss: 3.6136 | Actual Loss: 0.9571\n",
      "Baseline Loss: 3.5540 | Actual Loss: 1.0787\n",
      "Baseline Loss: 3.3850 | Actual Loss: 1.4667\n",
      "Baseline Loss: 3.4922 | Actual Loss: 0.6739\n",
      "Baseline Loss: 3.4852 | Actual Loss: 0.8398\n",
      "Baseline Loss: 3.4247 | Actual Loss: 2.8734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 104/1000 [00:40<05:34,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5171 | Actual Loss: 1.0533\n",
      "Baseline Loss: 3.6061 | Actual Loss: 1.0202\n",
      "Baseline Loss: 3.4136 | Actual Loss: 1.0111\n",
      "Baseline Loss: 3.4179 | Actual Loss: 0.7477\n",
      "Baseline Loss: 3.5828 | Actual Loss: 0.5587\n",
      "Baseline Loss: 3.5327 | Actual Loss: 1.0847\n",
      "Baseline Loss: 3.3931 | Actual Loss: 0.9390\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.6963\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.8391\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.2403\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.2542\n",
      "Epoch 104/1000: Train Loss: 1.0533, Val Loss: 1.0075\n",
      "Baseline Loss: 3.4616 | Actual Loss: 1.3087\n",
      "Baseline Loss: 3.4510 | Actual Loss: 1.0043\n",
      "Baseline Loss: 3.5535 | Actual Loss: 2.6782\n",
      "Baseline Loss: 3.5283 | Actual Loss: 0.6052\n",
      "Baseline Loss: 3.4691 | Actual Loss: 0.7176\n",
      "Baseline Loss: 3.3811 | Actual Loss: 1.0362\n",
      "Baseline Loss: 3.6882 | Actual Loss: 3.6125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 105/1000 [00:40<05:35,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5056 | Actual Loss: 0.9579\n",
      "Baseline Loss: 3.5372 | Actual Loss: 1.1361\n",
      "Baseline Loss: 3.4287 | Actual Loss: 1.8904\n",
      "Baseline Loss: 3.6929 | Actual Loss: 0.9762\n",
      "Baseline Loss: 3.5010 | Actual Loss: 0.6583\n",
      "Baseline Loss: 3.4001 | Actual Loss: 1.0402\n",
      "Baseline Loss: 3.6455 | Actual Loss: 0.5668\n",
      "Baseline Loss: 3.5289 | Actual Loss: 0.9998\n",
      "Baseline Loss: 3.6410 | Actual Loss: 0.7647\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.7008\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.8541\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.2800\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.3064\n",
      "Epoch 105/1000: Train Loss: 1.2471, Val Loss: 1.0353\n",
      "Baseline Loss: 3.5752 | Actual Loss: 1.4831\n",
      "Baseline Loss: 3.4399 | Actual Loss: 1.0162\n",
      "Baseline Loss: 3.5584 | Actual Loss: 1.1025\n",
      "Baseline Loss: 3.5417 | Actual Loss: 0.7302\n",
      "Baseline Loss: 3.5213 | Actual Loss: 1.1419\n",
      "Baseline Loss: 3.4551 | Actual Loss: 2.3585\n",
      "Baseline Loss: 3.6742 | Actual Loss: 0.8844\n",
      "Baseline Loss: 3.7785 | Actual Loss: 1.0079\n",
      "Baseline Loss: 3.5329 | Actual Loss: 1.4692\n",
      "Baseline Loss: 3.5371 | Actual Loss: 1.0472\n",
      "Baseline Loss: 3.3891 | Actual Loss: 1.3605\n",
      "Baseline Loss: 3.4474 | Actual Loss: 0.6262\n",
      "Baseline Loss: 3.6883 | Actual Loss: 0.8414\n",
      "Baseline Loss: 3.3222 | Actual Loss: 0.9325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 106/1000 [00:40<05:35,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3383 | Actual Loss: 0.8369\n",
      "Baseline Loss: 3.5838 | Actual Loss: 0.1824\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.7001\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.8654\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.2286\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.4440\n",
      "Epoch 106/1000: Train Loss: 1.0638, Val Loss: 1.0595\n",
      "Baseline Loss: 3.3540 | Actual Loss: 0.7570\n",
      "Baseline Loss: 3.5448 | Actual Loss: 0.7993\n",
      "Baseline Loss: 3.3850 | Actual Loss: 0.8351\n",
      "Baseline Loss: 3.4773 | Actual Loss: 1.9455\n",
      "Baseline Loss: 3.3574 | Actual Loss: 1.3768\n",
      "Baseline Loss: 3.4738 | Actual Loss: 0.9353\n",
      "Baseline Loss: 3.4928 | Actual Loss: 0.8271\n",
      "Baseline Loss: 3.5132 | Actual Loss: 1.0681\n",
      "Baseline Loss: 3.4849 | Actual Loss: 1.2077\n",
      "Baseline Loss: 3.3866 | Actual Loss: 1.4530\n",
      "Baseline Loss: 3.7422 | Actual Loss: 3.7495\n",
      "Baseline Loss: 3.6826 | Actual Loss: 1.0589\n",
      "Baseline Loss: 3.6496 | Actual Loss: 0.2437\n",
      "Baseline Loss: 3.9010 | Actual Loss: 0.7416\n",
      "Baseline Loss: 3.5528 | Actual Loss: 0.4353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 107/1000 [00:41<05:41,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6292 | Actual Loss: 4.0691\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.7126\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.8343\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.2359\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.3129\n",
      "Epoch 107/1000: Train Loss: 1.3439, Val Loss: 1.0239\n",
      "Baseline Loss: 3.5167 | Actual Loss: 0.5049\n",
      "Baseline Loss: 3.5923 | Actual Loss: 0.9377\n",
      "Baseline Loss: 3.6017 | Actual Loss: 0.9375\n",
      "Baseline Loss: 3.5493 | Actual Loss: 0.8919\n",
      "Baseline Loss: 3.5657 | Actual Loss: 0.9054\n",
      "Baseline Loss: 3.5097 | Actual Loss: 1.0880\n",
      "Baseline Loss: 3.4888 | Actual Loss: 1.0667\n",
      "Baseline Loss: 3.6501 | Actual Loss: 0.4262\n",
      "Baseline Loss: 3.5752 | Actual Loss: 0.5382\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.7325\n",
      "Baseline Loss: 3.4292 | Actual Loss: 1.5568\n",
      "Baseline Loss: 3.5920 | Actual Loss: 0.4802\n",
      "Baseline Loss: 3.6922 | Actual Loss: 1.1654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 108/1000 [00:41<05:47,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6229 | Actual Loss: 1.2319\n",
      "Baseline Loss: 3.4684 | Actual Loss: 0.4376\n",
      "Baseline Loss: 3.1812 | Actual Loss: 0.7009\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.7473\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.8393\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.2646\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.3864\n",
      "Epoch 108/1000: Train Loss: 0.8501, Val Loss: 1.0594\n",
      "Baseline Loss: 3.4438 | Actual Loss: 1.0155\n",
      "Baseline Loss: 3.2946 | Actual Loss: 0.5564\n",
      "Baseline Loss: 3.3149 | Actual Loss: 0.7610\n",
      "Baseline Loss: 3.4103 | Actual Loss: 0.6998\n",
      "Baseline Loss: 3.7878 | Actual Loss: 0.7388\n",
      "Baseline Loss: 3.5456 | Actual Loss: 0.9695\n",
      "Baseline Loss: 3.4358 | Actual Loss: 1.2000\n",
      "Baseline Loss: 3.6415 | Actual Loss: 1.7127\n",
      "Baseline Loss: 3.6547 | Actual Loss: 0.5082\n",
      "Baseline Loss: 3.4810 | Actual Loss: 1.0520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 109/1000 [00:41<05:29,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4919 | Actual Loss: 1.1555\n",
      "Baseline Loss: 3.5450 | Actual Loss: 0.6582\n",
      "Baseline Loss: 3.6405 | Actual Loss: 1.2811\n",
      "Baseline Loss: 3.6412 | Actual Loss: 2.8095\n",
      "Baseline Loss: 3.5126 | Actual Loss: 0.7392\n",
      "Baseline Loss: 3.2424 | Actual Loss: 0.9365\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.6681\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.8834\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.1665\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.2244\n",
      "Epoch 109/1000: Train Loss: 1.0496, Val Loss: 0.9856\n",
      "Baseline Loss: 3.4357 | Actual Loss: 0.3773\n",
      "Baseline Loss: 3.4002 | Actual Loss: 0.7639\n",
      "Baseline Loss: 3.5500 | Actual Loss: 0.7777\n",
      "Baseline Loss: 3.3953 | Actual Loss: 1.2672\n",
      "Baseline Loss: 3.6922 | Actual Loss: 0.8691\n",
      "Baseline Loss: 3.5538 | Actual Loss: 0.9211\n",
      "Baseline Loss: 3.4848 | Actual Loss: 0.7711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 110/1000 [00:42<05:39,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6411 | Actual Loss: 0.8351\n",
      "Baseline Loss: 3.4427 | Actual Loss: 1.8209\n",
      "Baseline Loss: 3.6320 | Actual Loss: 0.7448\n",
      "Baseline Loss: 3.4703 | Actual Loss: 0.7333\n",
      "Baseline Loss: 3.5745 | Actual Loss: 0.5870\n",
      "Baseline Loss: 3.5539 | Actual Loss: 0.9249\n",
      "Baseline Loss: 3.4061 | Actual Loss: 1.4770\n",
      "Baseline Loss: 3.7421 | Actual Loss: 3.0992\n",
      "Baseline Loss: 3.4021 | Actual Loss: 0.4411\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.6828\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.8462\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.1451\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.2784\n",
      "Epoch 110/1000: Train Loss: 1.0257, Val Loss: 0.9881\n",
      "Baseline Loss: 3.3966 | Actual Loss: 0.7022\n",
      "Baseline Loss: 3.5207 | Actual Loss: 0.8183\n",
      "Baseline Loss: 3.4958 | Actual Loss: 0.3796\n",
      "Baseline Loss: 3.3779 | Actual Loss: 1.6704\n",
      "Baseline Loss: 3.5414 | Actual Loss: 1.0384\n",
      "Baseline Loss: 3.4142 | Actual Loss: 0.5569\n",
      "Baseline Loss: 3.5249 | Actual Loss: 1.0209\n",
      "Baseline Loss: 3.4823 | Actual Loss: 0.8891\n",
      "Baseline Loss: 3.5408 | Actual Loss: 0.5605\n",
      "Baseline Loss: 3.4395 | Actual Loss: 1.0810\n",
      "Baseline Loss: 3.5830 | Actual Loss: 1.2211\n",
      "Baseline Loss: 3.6132 | Actual Loss: 1.7956\n",
      "Baseline Loss: 3.6415 | Actual Loss: 0.8891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 111/1000 [00:42<05:58,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4578 | Actual Loss: 2.5102\n",
      "Baseline Loss: 3.7268 | Actual Loss: 1.3451\n",
      "Baseline Loss: 3.7142 | Actual Loss: 0.8258\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.6709\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.8455\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.4078\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.2382\n",
      "Epoch 111/1000: Train Loss: 1.0815, Val Loss: 1.0406\n",
      "Baseline Loss: 3.5333 | Actual Loss: 0.7996\n",
      "Baseline Loss: 3.5662 | Actual Loss: 1.1496\n",
      "Baseline Loss: 3.3828 | Actual Loss: 1.3573\n",
      "Baseline Loss: 3.5124 | Actual Loss: 0.7902\n",
      "Baseline Loss: 3.5359 | Actual Loss: 0.6177\n",
      "Baseline Loss: 3.4766 | Actual Loss: 1.6775\n",
      "Baseline Loss: 3.6833 | Actual Loss: 3.5931\n",
      "Baseline Loss: 3.6642 | Actual Loss: 0.6614\n",
      "Baseline Loss: 3.5288 | Actual Loss: 1.1271\n",
      "Baseline Loss: 3.4539 | Actual Loss: 1.2440\n",
      "Baseline Loss: 3.6057 | Actual Loss: 0.8620\n",
      "Baseline Loss: 3.5873 | Actual Loss: 1.1378\n",
      "Baseline Loss: 3.5085 | Actual Loss: 1.0774\n",
      "Baseline Loss: 3.5249 | Actual Loss: 0.8923\n",
      "Baseline Loss: 3.4069 | Actual Loss: 1.0999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 112/1000 [00:43<05:30,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3400 | Actual Loss: 1.0625\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.6645\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.8498\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.1353\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.2999\n",
      "Epoch 112/1000: Train Loss: 1.1969, Val Loss: 0.9874\n",
      "Baseline Loss: 3.5709 | Actual Loss: 0.5401\n",
      "Baseline Loss: 3.4346 | Actual Loss: 0.7996\n",
      "Baseline Loss: 3.4396 | Actual Loss: 0.8859\n",
      "Baseline Loss: 3.5710 | Actual Loss: 0.7487\n",
      "Baseline Loss: 3.4405 | Actual Loss: 1.0757\n",
      "Baseline Loss: 3.3993 | Actual Loss: 0.8584\n",
      "Baseline Loss: 3.3923 | Actual Loss: 0.9812\n",
      "Baseline Loss: 3.7272 | Actual Loss: 4.1210\n",
      "Baseline Loss: 3.3008 | Actual Loss: 0.8957\n",
      "Baseline Loss: 3.6837 | Actual Loss: 1.5720\n",
      "Baseline Loss: 3.6092 | Actual Loss: 0.6784\n",
      "Baseline Loss: 3.6737 | Actual Loss: 3.6122\n",
      "Baseline Loss: 3.5961 | Actual Loss: 0.8366\n",
      "Baseline Loss: 3.2919 | Actual Loss: 1.2367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█▏        | 113/1000 [00:43<05:52,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6581 | Actual Loss: 1.0091\n",
      "Baseline Loss: 3.6889 | Actual Loss: 1.5323\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.6539\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.7996\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.4036\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.3755\n",
      "Epoch 113/1000: Train Loss: 1.3365, Val Loss: 1.0582\n",
      "Baseline Loss: 3.5838 | Actual Loss: 0.7178\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.3520\n",
      "Baseline Loss: 3.4849 | Actual Loss: 1.2966\n",
      "Baseline Loss: 3.4888 | Actual Loss: 0.9052\n",
      "Baseline Loss: 3.7677 | Actual Loss: 0.7206\n",
      "Baseline Loss: 3.5462 | Actual Loss: 0.8463\n",
      "Baseline Loss: 3.6049 | Actual Loss: 0.7936\n",
      "Baseline Loss: 3.3364 | Actual Loss: 0.4255\n",
      "Baseline Loss: 3.5800 | Actual Loss: 0.7832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█▏        | 114/1000 [00:43<05:26,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4463 | Actual Loss: 0.6002\n",
      "Baseline Loss: 3.5658 | Actual Loss: 2.4384\n",
      "Baseline Loss: 3.3881 | Actual Loss: 0.6522\n",
      "Baseline Loss: 3.5366 | Actual Loss: 0.9332\n",
      "Baseline Loss: 3.6741 | Actual Loss: 1.7531\n",
      "Baseline Loss: 3.5207 | Actual Loss: 1.3975\n",
      "Baseline Loss: 3.4792 | Actual Loss: 3.6998\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.7026\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.8588\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.1791\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.2663\n",
      "Epoch 114/1000: Train Loss: 1.2072, Val Loss: 1.0017\n",
      "Baseline Loss: 3.5207 | Actual Loss: 0.6835\n",
      "Baseline Loss: 3.5575 | Actual Loss: 0.6957\n",
      "Baseline Loss: 3.5167 | Actual Loss: 1.3670\n",
      "Baseline Loss: 3.3746 | Actual Loss: 0.9922\n",
      "Baseline Loss: 3.5832 | Actual Loss: 0.9665\n",
      "Baseline Loss: 3.5404 | Actual Loss: 0.5546\n",
      "Baseline Loss: 3.6501 | Actual Loss: 0.5744\n",
      "Baseline Loss: 3.5457 | Actual Loss: 0.7022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 115/1000 [00:44<05:37,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3887 | Actual Loss: 0.7416\n",
      "Baseline Loss: 3.7368 | Actual Loss: 1.1630\n",
      "Baseline Loss: 3.4325 | Actual Loss: 1.8760\n",
      "Baseline Loss: 3.7936 | Actual Loss: 0.8281\n",
      "Baseline Loss: 3.6364 | Actual Loss: 1.0085\n",
      "Baseline Loss: 3.5927 | Actual Loss: 1.7060\n",
      "Baseline Loss: 3.4579 | Actual Loss: 0.9522\n",
      "Baseline Loss: 3.1041 | Actual Loss: 0.5445\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.7068\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.8680\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.1568\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.2362\n",
      "Epoch 115/1000: Train Loss: 0.9598, Val Loss: 0.9920\n",
      "Baseline Loss: 3.4852 | Actual Loss: 0.4469\n",
      "Baseline Loss: 3.4613 | Actual Loss: 1.1070\n",
      "Baseline Loss: 3.6931 | Actual Loss: 1.2270\n",
      "Baseline Loss: 3.5284 | Actual Loss: 0.9452\n",
      "Baseline Loss: 3.5372 | Actual Loss: 0.6068\n",
      "Baseline Loss: 3.5960 | Actual Loss: 0.2626\n",
      "Baseline Loss: 3.5210 | Actual Loss: 0.3586\n",
      "Baseline Loss: 3.7126 | Actual Loss: 1.0204\n",
      "Baseline Loss: 3.5620 | Actual Loss: 0.6872\n",
      "Baseline Loss: 3.4214 | Actual Loss: 1.2121\n",
      "Baseline Loss: 3.2641 | Actual Loss: 1.2234\n",
      "Baseline Loss: 3.4744 | Actual Loss: 1.2589\n",
      "Baseline Loss: 3.5492 | Actual Loss: 1.0285\n",
      "Baseline Loss: 3.5922 | Actual Loss: 1.0566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 116/1000 [00:44<05:24,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7832 | Actual Loss: 0.9614\n",
      "Baseline Loss: 3.0840 | Actual Loss: 1.4641\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.6637\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.8311\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.2037\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.2852\n",
      "Epoch 116/1000: Train Loss: 0.9292, Val Loss: 0.9959\n",
      "Baseline Loss: 3.3886 | Actual Loss: 0.8850\n",
      "Baseline Loss: 3.7374 | Actual Loss: 0.7796\n",
      "Baseline Loss: 3.5789 | Actual Loss: 1.3941\n",
      "Baseline Loss: 3.5203 | Actual Loss: 0.5889\n",
      "Baseline Loss: 3.4589 | Actual Loss: 1.0155\n",
      "Baseline Loss: 3.2820 | Actual Loss: 0.8772\n",
      "Baseline Loss: 3.4964 | Actual Loss: 0.5474\n",
      "Baseline Loss: 3.5706 | Actual Loss: 0.9026\n",
      "Baseline Loss: 3.5331 | Actual Loss: 1.1805\n",
      "Baseline Loss: 3.5790 | Actual Loss: 4.1024\n",
      "Baseline Loss: 4.0079 | Actual Loss: 2.6592\n",
      "Baseline Loss: 3.7165 | Actual Loss: 0.8090\n",
      "Baseline Loss: 3.4651 | Actual Loss: 0.9165\n",
      "Baseline Loss: 3.3712 | Actual Loss: 0.9724\n",
      "Baseline Loss: 3.3713 | Actual Loss: 1.1434\n",
      "Baseline Loss: 3.3220 | Actual Loss: 0.5615\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.6726\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.8834\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.2820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 117/1000 [00:45<05:31,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3188 | Actual Loss: 1.2750\n",
      "Epoch 117/1000: Train Loss: 1.2084, Val Loss: 1.0283\n",
      "Baseline Loss: 3.5674 | Actual Loss: 1.1103\n",
      "Baseline Loss: 3.4382 | Actual Loss: 0.7794\n",
      "Baseline Loss: 3.6103 | Actual Loss: 0.9305\n",
      "Baseline Loss: 3.6366 | Actual Loss: 3.2031\n",
      "Baseline Loss: 3.2478 | Actual Loss: 1.3369\n",
      "Baseline Loss: 3.6271 | Actual Loss: 0.7234\n",
      "Baseline Loss: 3.5167 | Actual Loss: 1.1049\n",
      "Baseline Loss: 3.6143 | Actual Loss: 1.0608\n",
      "Baseline Loss: 3.5457 | Actual Loss: 0.8495\n",
      "Baseline Loss: 3.6186 | Actual Loss: 2.8171\n",
      "Baseline Loss: 3.5290 | Actual Loss: 1.0168\n",
      "Baseline Loss: 3.5668 | Actual Loss: 0.8618\n",
      "Baseline Loss: 3.4360 | Actual Loss: 1.3778\n",
      "Baseline Loss: 3.4728 | Actual Loss: 0.7605\n",
      "Baseline Loss: 3.6366 | Actual Loss: 0.7093\n",
      "Baseline Loss: 3.3931 | Actual Loss: 0.8137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 118/1000 [00:45<05:52,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5212 | Actual Loss: 0.6949\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.8677\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.4021\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.3054\n",
      "Epoch 118/1000: Train Loss: 1.2160, Val Loss: 1.0675\n",
      "Baseline Loss: 3.6177 | Actual Loss: 0.6603\n",
      "Baseline Loss: 3.3338 | Actual Loss: 1.3762\n",
      "Baseline Loss: 3.5537 | Actual Loss: 0.9540\n",
      "Baseline Loss: 3.4893 | Actual Loss: 0.9419\n",
      "Baseline Loss: 3.6098 | Actual Loss: 0.5370\n",
      "Baseline Loss: 3.4972 | Actual Loss: 0.7085\n",
      "Baseline Loss: 3.5838 | Actual Loss: 1.1058\n",
      "Baseline Loss: 3.5961 | Actual Loss: 1.0779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 119/1000 [00:45<05:33,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5408 | Actual Loss: 0.7137\n",
      "Baseline Loss: 3.4977 | Actual Loss: 2.7863\n",
      "Baseline Loss: 3.4209 | Actual Loss: 1.0726\n",
      "Baseline Loss: 3.7472 | Actual Loss: 0.8614\n",
      "Baseline Loss: 3.3241 | Actual Loss: 1.0180\n",
      "Baseline Loss: 3.4135 | Actual Loss: 0.8512\n",
      "Baseline Loss: 3.8208 | Actual Loss: 1.8609\n",
      "Baseline Loss: 3.4494 | Actual Loss: 0.9940\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.7155\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.8206\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.2126\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.3092\n",
      "Epoch 119/1000: Train Loss: 1.0950, Val Loss: 1.0145\n",
      "Baseline Loss: 3.4137 | Actual Loss: 1.0346\n",
      "Baseline Loss: 3.5889 | Actual Loss: 0.8174\n",
      "Baseline Loss: 3.3406 | Actual Loss: 1.0875\n",
      "Baseline Loss: 3.5779 | Actual Loss: 0.5970\n",
      "Baseline Loss: 3.5746 | Actual Loss: 0.5134\n",
      "Baseline Loss: 3.6137 | Actual Loss: 0.4063\n",
      "Baseline Loss: 3.4391 | Actual Loss: 0.6585\n",
      "Baseline Loss: 3.6274 | Actual Loss: 0.4237\n",
      "Baseline Loss: 3.4690 | Actual Loss: 0.9478\n",
      "Baseline Loss: 3.5287 | Actual Loss: 1.4314\n",
      "Baseline Loss: 3.3719 | Actual Loss: 0.5681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 120/1000 [00:46<05:44,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6411 | Actual Loss: 0.8957\n",
      "Baseline Loss: 3.5918 | Actual Loss: 0.7785\n",
      "Baseline Loss: 3.5881 | Actual Loss: 2.9392\n",
      "Baseline Loss: 3.4441 | Actual Loss: 0.7771\n",
      "Baseline Loss: 3.6889 | Actual Loss: 1.7856\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.6407\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.8287\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.3168\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.2787\n",
      "Epoch 120/1000: Train Loss: 0.9789, Val Loss: 1.0162\n",
      "Baseline Loss: 3.4073 | Actual Loss: 0.8543\n",
      "Baseline Loss: 3.4773 | Actual Loss: 1.1322\n",
      "Baseline Loss: 3.7733 | Actual Loss: 0.2809\n",
      "Baseline Loss: 3.5092 | Actual Loss: 0.6962\n",
      "Baseline Loss: 3.5581 | Actual Loss: 1.0048\n",
      "Baseline Loss: 3.3679 | Actual Loss: 0.7768\n",
      "Baseline Loss: 3.4920 | Actual Loss: 0.9729\n",
      "Baseline Loss: 3.4354 | Actual Loss: 0.5568\n",
      "Baseline Loss: 3.6140 | Actual Loss: 0.8344\n",
      "Baseline Loss: 3.5664 | Actual Loss: 0.8080\n",
      "Baseline Loss: 3.5009 | Actual Loss: 1.8161\n",
      "Baseline Loss: 3.6872 | Actual Loss: 1.0997\n",
      "Baseline Loss: 3.5094 | Actual Loss: 1.0017\n",
      "Baseline Loss: 3.4250 | Actual Loss: 1.3067\n",
      "Baseline Loss: 3.4042 | Actual Loss: 1.1178\n",
      "Baseline Loss: 3.4592 | Actual Loss: 3.8505\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.7094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 121/1000 [00:46<05:28,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6101 | Actual Loss: 0.8437\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.1019\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.2739\n",
      "Epoch 121/1000: Train Loss: 1.1319, Val Loss: 0.9822\n",
      "Baseline Loss: 3.4478 | Actual Loss: 1.1055\n",
      "Baseline Loss: 3.5167 | Actual Loss: 0.8413\n",
      "Baseline Loss: 3.5201 | Actual Loss: 0.6040\n",
      "Baseline Loss: 3.5613 | Actual Loss: 1.1612\n",
      "Baseline Loss: 3.4699 | Actual Loss: 0.9249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 122/1000 [00:46<05:28,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.8325 | Actual Loss: 2.1450\n",
      "Baseline Loss: 3.6140 | Actual Loss: 0.7381\n",
      "Baseline Loss: 3.5956 | Actual Loss: 3.7301\n",
      "Baseline Loss: 3.3712 | Actual Loss: 0.9579\n",
      "Baseline Loss: 3.3101 | Actual Loss: 0.4818\n",
      "Baseline Loss: 3.6359 | Actual Loss: 1.1759\n",
      "Baseline Loss: 3.6360 | Actual Loss: 0.6455\n",
      "Baseline Loss: 3.4965 | Actual Loss: 2.9214\n",
      "Baseline Loss: 3.3737 | Actual Loss: 0.6288\n",
      "Baseline Loss: 3.5422 | Actual Loss: 0.3839\n",
      "Baseline Loss: 3.5516 | Actual Loss: 1.3857\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.7170\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.8557\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.2032\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.3520\n",
      "Epoch 122/1000: Train Loss: 1.2394, Val Loss: 1.0319\n",
      "Baseline Loss: 3.5781 | Actual Loss: 1.1468\n",
      "Baseline Loss: 3.5916 | Actual Loss: 1.0519\n",
      "Baseline Loss: 3.5574 | Actual Loss: 0.8036\n",
      "Baseline Loss: 3.4247 | Actual Loss: 0.7171\n",
      "Baseline Loss: 3.6360 | Actual Loss: 2.3711\n",
      "Baseline Loss: 3.4511 | Actual Loss: 0.6991\n",
      "Baseline Loss: 3.8158 | Actual Loss: 2.2907\n",
      "Baseline Loss: 3.5093 | Actual Loss: 0.6604\n",
      "Baseline Loss: 3.4062 | Actual Loss: 1.1580\n",
      "Baseline Loss: 3.6503 | Actual Loss: 1.5672\n",
      "Baseline Loss: 3.3785 | Actual Loss: 1.1179\n",
      "Baseline Loss: 3.4436 | Actual Loss: 1.7293\n",
      "Baseline Loss: 3.6008 | Actual Loss: 1.1828\n",
      "Baseline Loss: 3.4024 | Actual Loss: 0.7941\n",
      "Baseline Loss: 3.5877 | Actual Loss: 0.7206\n",
      "Baseline Loss: 3.9092 | Actual Loss: 0.8843\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.7005\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.8699\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.4967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 123/1000 [00:47<05:44,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3188 | Actual Loss: 1.3196\n",
      "Epoch 123/1000: Train Loss: 1.1809, Val Loss: 1.0967\n",
      "Baseline Loss: 3.6689 | Actual Loss: 0.5274\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.0502\n",
      "Baseline Loss: 3.5245 | Actual Loss: 0.5178\n",
      "Baseline Loss: 3.3713 | Actual Loss: 0.8662\n",
      "Baseline Loss: 3.6003 | Actual Loss: 0.9048\n",
      "Baseline Loss: 3.4925 | Actual Loss: 1.2586\n",
      "Baseline Loss: 3.6230 | Actual Loss: 1.2236\n",
      "Baseline Loss: 3.3577 | Actual Loss: 0.7304\n",
      "Baseline Loss: 3.6547 | Actual Loss: 1.1989\n",
      "Baseline Loss: 3.3788 | Actual Loss: 0.4215\n",
      "Baseline Loss: 3.4469 | Actual Loss: 0.7928\n",
      "Baseline Loss: 3.3607 | Actual Loss: 2.2539\n",
      "Baseline Loss: 3.5358 | Actual Loss: 0.7738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 124/1000 [00:47<05:14,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3995 | Actual Loss: 0.8383\n",
      "Baseline Loss: 3.7571 | Actual Loss: 3.1044\n",
      "Baseline Loss: 3.6527 | Actual Loss: 3.6891\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.7327\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.8795\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.3344\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.3748\n",
      "Epoch 124/1000: Train Loss: 1.2595, Val Loss: 1.0803\n",
      "Baseline Loss: 3.3780 | Actual Loss: 0.6880\n",
      "Baseline Loss: 3.4693 | Actual Loss: 0.8563\n",
      "Baseline Loss: 3.5706 | Actual Loss: 0.6712\n",
      "Baseline Loss: 3.4619 | Actual Loss: 0.6958\n",
      "Baseline Loss: 3.3609 | Actual Loss: 0.7615\n",
      "Baseline Loss: 3.4174 | Actual Loss: 1.0537\n",
      "Baseline Loss: 3.5500 | Actual Loss: 0.5954\n",
      "Baseline Loss: 3.5704 | Actual Loss: 1.4364\n",
      "Baseline Loss: 3.5704 | Actual Loss: 1.5591\n",
      "Baseline Loss: 3.5416 | Actual Loss: 1.4365\n",
      "Baseline Loss: 3.5249 | Actual Loss: 1.5263\n",
      "Baseline Loss: 3.9755 | Actual Loss: 1.4128\n",
      "Baseline Loss: 3.5790 | Actual Loss: 2.0457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▎        | 125/1000 [00:48<05:40,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5365 | Actual Loss: 0.7303\n",
      "Baseline Loss: 3.4506 | Actual Loss: 0.8218\n",
      "Baseline Loss: 3.4115 | Actual Loss: 1.3505\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.7262\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.8473\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.3162\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.3110\n",
      "Epoch 125/1000: Train Loss: 1.1026, Val Loss: 1.0502\n",
      "Baseline Loss: 3.3183 | Actual Loss: 1.3607\n",
      "Baseline Loss: 3.6359 | Actual Loss: 0.6737\n",
      "Baseline Loss: 3.6417 | Actual Loss: 0.6862\n",
      "Baseline Loss: 3.3162 | Actual Loss: 1.4911\n",
      "Baseline Loss: 3.5451 | Actual Loss: 1.5911\n",
      "Baseline Loss: 3.7122 | Actual Loss: 1.2466\n",
      "Baseline Loss: 3.6367 | Actual Loss: 1.1281\n",
      "Baseline Loss: 3.7273 | Actual Loss: 0.7755\n",
      "Baseline Loss: 3.4848 | Actual Loss: 0.9121\n",
      "Baseline Loss: 3.5923 | Actual Loss: 3.0589\n",
      "Baseline Loss: 3.6133 | Actual Loss: 0.8281\n",
      "Baseline Loss: 3.5130 | Actual Loss: 0.7055\n",
      "Baseline Loss: 3.6304 | Actual Loss: 1.1228\n",
      "Baseline Loss: 3.4930 | Actual Loss: 0.4193\n",
      "Baseline Loss: 3.5048 | Actual Loss: 0.7105\n",
      "Baseline Loss: 3.1321 | Actual Loss: 0.7463\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.6751\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.8369\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.5785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 126/1000 [00:48<05:19,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3188 | Actual Loss: 1.3744\n",
      "Epoch 126/1000: Train Loss: 1.0910, Val Loss: 1.1162\n",
      "Baseline Loss: 3.7120 | Actual Loss: 1.2994\n",
      "Baseline Loss: 3.7422 | Actual Loss: 0.7798\n",
      "Baseline Loss: 3.2986 | Actual Loss: 0.8148\n",
      "Baseline Loss: 3.5793 | Actual Loss: 1.3332\n",
      "Baseline Loss: 3.4178 | Actual Loss: 0.7007\n",
      "Baseline Loss: 3.3232 | Actual Loss: 0.9266\n",
      "Baseline Loss: 3.5579 | Actual Loss: 0.2897\n",
      "Baseline Loss: 3.4694 | Actual Loss: 0.9747\n",
      "Baseline Loss: 3.6975 | Actual Loss: 1.1975\n",
      "Baseline Loss: 3.6540 | Actual Loss: 0.9889\n",
      "Baseline Loss: 3.5622 | Actual Loss: 0.4755\n",
      "Baseline Loss: 3.4134 | Actual Loss: 0.9459\n",
      "Baseline Loss: 3.5248 | Actual Loss: 0.7815\n",
      "Baseline Loss: 3.5457 | Actual Loss: 1.0992\n",
      "Baseline Loss: 3.3646 | Actual Loss: 1.2699\n",
      "Baseline Loss: 3.9095 | Actual Loss: 1.8972\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.7256\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.8863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 127/1000 [00:48<05:38,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5170 | Actual Loss: 1.2042\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.2431\n",
      "Epoch 127/1000: Train Loss: 0.9859, Val Loss: 1.0148\n",
      "Baseline Loss: 3.6096 | Actual Loss: 1.0493\n",
      "Baseline Loss: 3.5581 | Actual Loss: 0.6229\n",
      "Baseline Loss: 3.6277 | Actual Loss: 1.1622\n",
      "Baseline Loss: 3.4112 | Actual Loss: 1.0424\n",
      "Baseline Loss: 3.4740 | Actual Loss: 0.7374\n",
      "Baseline Loss: 3.8492 | Actual Loss: 1.3768\n",
      "Baseline Loss: 3.5453 | Actual Loss: 0.4357\n",
      "Baseline Loss: 3.4741 | Actual Loss: 0.5960\n",
      "Baseline Loss: 3.5457 | Actual Loss: 3.1367\n",
      "Baseline Loss: 3.7784 | Actual Loss: 0.6546\n",
      "Baseline Loss: 3.4317 | Actual Loss: 0.8883\n",
      "Baseline Loss: 3.4628 | Actual Loss: 0.7699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 127/1000 [00:49<05:38,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3916 | Actual Loss: 0.7470\n",
      "Baseline Loss: 3.5656 | Actual Loss: 0.8257\n",
      "Baseline Loss: 3.5005 | Actual Loss: 0.9722\n",
      "Baseline Loss: 3.0069 | Actual Loss: 0.5475\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.6409\n",
      "Baseline Loss: 3.6101 | Actual Loss: 0.7989\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.0698\n",
      "Baseline Loss: 3.3188 | Actual Loss: 1.1663\n",
      "Epoch 128/1000: Train Loss: 0.9728, Val Loss: 0.9190\n",
      "\n",
      "Early stopping at epoch 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8210584968328476"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.train_model(\n",
    "    data_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2080382a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training will be saved to: premodels_new/6/0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8586 | Actual Loss: 2.8010\n",
      "Baseline Loss: 2.7802 | Actual Loss: 2.7335\n",
      "Baseline Loss: 2.8877 | Actual Loss: 2.8402\n",
      "Baseline Loss: 2.8056 | Actual Loss: 2.7802\n",
      "Baseline Loss: 2.7847 | Actual Loss: 2.7541\n",
      "Baseline Loss: 2.8152 | Actual Loss: 2.7987\n",
      "Baseline Loss: 2.9403 | Actual Loss: 2.9190\n",
      "Baseline Loss: 2.8548 | Actual Loss: 2.7961\n",
      "Baseline Loss: 2.8925 | Actual Loss: 2.8183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 1/1000 [00:00<06:40,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8351 | Actual Loss: 2.7773\n",
      "Baseline Loss: 2.7721 | Actual Loss: 2.6891\n",
      "Baseline Loss: 2.7990 | Actual Loss: 2.7330\n",
      "Baseline Loss: 2.8044 | Actual Loss: 2.7339\n",
      "Baseline Loss: 2.8196 | Actual Loss: 2.7532\n",
      "Baseline Loss: 2.9252 | Actual Loss: 2.8413\n",
      "Baseline Loss: 2.5189 | Actual Loss: 2.4681\n",
      "Baseline Loss: 2.8280 | Actual Loss: 2.7231\n",
      "Baseline Loss: 2.7565 | Actual Loss: 2.7021\n",
      "Baseline Loss: 2.8293 | Actual Loss: 2.7571\n",
      "Baseline Loss: 2.7468 | Actual Loss: 2.6717\n",
      "Epoch 1/1000: Train Loss: 2.7648, Val Loss: 2.7135\n",
      "New best validation loss: 2.7135\n",
      "Baseline Loss: 2.7819 | Actual Loss: 2.7652\n",
      "Baseline Loss: 2.7643 | Actual Loss: 2.7335\n",
      "Baseline Loss: 2.8706 | Actual Loss: 2.7345\n",
      "Baseline Loss: 2.8034 | Actual Loss: 2.7021\n",
      "Baseline Loss: 2.8704 | Actual Loss: 2.8539\n",
      "Baseline Loss: 2.8739 | Actual Loss: 2.7590\n",
      "Baseline Loss: 2.8135 | Actual Loss: 2.7234\n",
      "Baseline Loss: 2.7764 | Actual Loss: 2.7008\n",
      "Baseline Loss: 2.8874 | Actual Loss: 2.8153\n",
      "Baseline Loss: 2.8666 | Actual Loss: 2.7614\n",
      "Baseline Loss: 2.7972 | Actual Loss: 2.6667\n",
      "Baseline Loss: 2.7269 | Actual Loss: 2.5937\n",
      "Baseline Loss: 2.8276 | Actual Loss: 2.6744\n",
      "Baseline Loss: 2.8245 | Actual Loss: 2.6473\n",
      "Baseline Loss: 2.8598 | Actual Loss: 2.7001\n",
      "Baseline Loss: 2.7583 | Actual Loss: 2.5882\n",
      "Baseline Loss: 2.8280 | Actual Loss: 2.6089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 2/1000 [00:00<07:39,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7565 | Actual Loss: 2.6385\n",
      "Baseline Loss: 2.8293 | Actual Loss: 2.5927\n",
      "Baseline Loss: 2.7468 | Actual Loss: 2.5845\n",
      "Epoch 2/1000: Train Loss: 2.7137, Val Loss: 2.6061\n",
      "New best validation loss: 2.6061\n",
      "Baseline Loss: 2.7883 | Actual Loss: 2.6555\n",
      "Baseline Loss: 2.8403 | Actual Loss: 2.7288\n",
      "Baseline Loss: 2.7954 | Actual Loss: 2.6254\n",
      "Baseline Loss: 2.8204 | Actual Loss: 2.7000\n",
      "Baseline Loss: 2.8348 | Actual Loss: 2.5972\n",
      "Baseline Loss: 2.8518 | Actual Loss: 2.5495\n",
      "Baseline Loss: 2.8306 | Actual Loss: 2.6787\n",
      "Baseline Loss: 2.8078 | Actual Loss: 2.6708\n",
      "Baseline Loss: 2.8455 | Actual Loss: 2.6587\n",
      "Baseline Loss: 2.7537 | Actual Loss: 2.5764\n",
      "Baseline Loss: 2.7607 | Actual Loss: 2.5738\n",
      "Baseline Loss: 2.8668 | Actual Loss: 2.6025\n",
      "Baseline Loss: 3.0066 | Actual Loss: 2.7642\n",
      "Baseline Loss: 2.8244 | Actual Loss: 2.6360\n",
      "Baseline Loss: 2.8217 | Actual Loss: 2.5309\n",
      "Baseline Loss: 2.5042 | Actual Loss: 2.2687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 3/1000 [00:01<08:00,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8280 | Actual Loss: 2.5763\n",
      "Baseline Loss: 2.7565 | Actual Loss: 2.4248\n",
      "Baseline Loss: 2.8293 | Actual Loss: 2.5028\n",
      "Baseline Loss: 2.7468 | Actual Loss: 2.4681\n",
      "Epoch 3/1000: Train Loss: 2.6136, Val Loss: 2.4930\n",
      "New best validation loss: 2.4930\n",
      "Baseline Loss: 2.8668 | Actual Loss: 2.5596\n",
      "Baseline Loss: 2.8752 | Actual Loss: 2.5931\n",
      "Baseline Loss: 2.8441 | Actual Loss: 2.6465\n",
      "Baseline Loss: 2.8569 | Actual Loss: 2.5956\n",
      "Baseline Loss: 2.8173 | Actual Loss: 2.4880\n",
      "Baseline Loss: 2.8257 | Actual Loss: 2.4835\n",
      "Baseline Loss: 2.8463 | Actual Loss: 2.6024\n",
      "Baseline Loss: 2.8260 | Actual Loss: 2.4240\n",
      "Baseline Loss: 2.8281 | Actual Loss: 2.3596\n",
      "Baseline Loss: 2.8582 | Actual Loss: 2.6199\n",
      "Baseline Loss: 2.8082 | Actual Loss: 2.4490\n",
      "Baseline Loss: 2.8281 | Actual Loss: 2.3191\n",
      "Baseline Loss: 2.8384 | Actual Loss: 2.4695\n",
      "Baseline Loss: 2.8315 | Actual Loss: 2.5105\n",
      "Baseline Loss: 2.7558 | Actual Loss: 2.2520\n",
      "Baseline Loss: 2.5996 | Actual Loss: 2.0675\n",
      "Baseline Loss: 2.8280 | Actual Loss: 2.3843\n",
      "Baseline Loss: 2.7565 | Actual Loss: 2.3287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 4/1000 [00:01<07:25,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8293 | Actual Loss: 2.4676\n",
      "Baseline Loss: 2.7468 | Actual Loss: 2.2482\n",
      "Epoch 4/1000: Train Loss: 2.4650, Val Loss: 2.3572\n",
      "New best validation loss: 2.3572\n",
      "Baseline Loss: 2.8660 | Actual Loss: 2.4096\n",
      "Baseline Loss: 2.8096 | Actual Loss: 2.2654\n",
      "Baseline Loss: 2.9270 | Actual Loss: 2.5920\n",
      "Baseline Loss: 2.9411 | Actual Loss: 2.3740\n",
      "Baseline Loss: 2.8184 | Actual Loss: 2.3357\n",
      "Baseline Loss: 2.7693 | Actual Loss: 2.2101\n",
      "Baseline Loss: 2.8104 | Actual Loss: 2.3200\n",
      "Baseline Loss: 2.7781 | Actual Loss: 2.1378\n",
      "Baseline Loss: 2.8438 | Actual Loss: 2.3957\n",
      "Baseline Loss: 2.8500 | Actual Loss: 2.1536\n",
      "Baseline Loss: 2.8290 | Actual Loss: 2.2315\n",
      "Baseline Loss: 2.8512 | Actual Loss: 2.2043\n",
      "Baseline Loss: 2.8411 | Actual Loss: 2.4952\n",
      "Baseline Loss: 2.8130 | Actual Loss: 2.3140\n",
      "Baseline Loss: 2.8078 | Actual Loss: 2.5909\n",
      "Baseline Loss: 2.4959 | Actual Loss: 1.9123\n",
      "Baseline Loss: 2.8280 | Actual Loss: 2.1259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 5/1000 [00:02<07:51,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7565 | Actual Loss: 2.1943\n",
      "Baseline Loss: 2.8293 | Actual Loss: 2.3714\n",
      "Baseline Loss: 2.7468 | Actual Loss: 2.0970\n",
      "Epoch 5/1000: Train Loss: 2.3089, Val Loss: 2.1971\n",
      "New best validation loss: 2.1971\n",
      "Baseline Loss: 2.8512 | Actual Loss: 2.1006\n",
      "Baseline Loss: 2.8434 | Actual Loss: 2.3418\n",
      "Baseline Loss: 2.9252 | Actual Loss: 1.9972\n",
      "Baseline Loss: 2.8223 | Actual Loss: 2.3870\n",
      "Baseline Loss: 2.8196 | Actual Loss: 2.2505\n",
      "Baseline Loss: 2.8140 | Actual Loss: 1.9125\n",
      "Baseline Loss: 2.8360 | Actual Loss: 2.3091\n",
      "Baseline Loss: 2.7648 | Actual Loss: 1.7622\n",
      "Baseline Loss: 2.8348 | Actual Loss: 1.8866\n",
      "Baseline Loss: 2.7975 | Actual Loss: 1.9139\n",
      "Baseline Loss: 2.8331 | Actual Loss: 2.2519\n",
      "Baseline Loss: 2.7817 | Actual Loss: 2.2711\n",
      "Baseline Loss: 2.7907 | Actual Loss: 2.0183\n",
      "Baseline Loss: 2.9058 | Actual Loss: 2.3457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 6/1000 [00:02<08:02,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8479 | Actual Loss: 1.9854\n",
      "Baseline Loss: 2.6526 | Actual Loss: 1.9288\n",
      "Baseline Loss: 2.8280 | Actual Loss: 2.1210\n",
      "Baseline Loss: 2.7565 | Actual Loss: 2.1558\n",
      "Baseline Loss: 2.8293 | Actual Loss: 1.9002\n",
      "Baseline Loss: 2.7468 | Actual Loss: 1.8154\n",
      "Epoch 6/1000: Train Loss: 2.1039, Val Loss: 1.9981\n",
      "New best validation loss: 1.9981\n",
      "Baseline Loss: 2.8568 | Actual Loss: 1.9249\n",
      "Baseline Loss: 2.8611 | Actual Loss: 2.1459\n",
      "Baseline Loss: 2.7922 | Actual Loss: 1.8661\n",
      "Baseline Loss: 2.8251 | Actual Loss: 2.0910\n",
      "Baseline Loss: 2.7819 | Actual Loss: 2.4570\n",
      "Baseline Loss: 2.8398 | Actual Loss: 2.1362\n",
      "Baseline Loss: 2.8336 | Actual Loss: 2.1816\n",
      "Baseline Loss: 2.8220 | Actual Loss: 2.0985\n",
      "Baseline Loss: 2.7450 | Actual Loss: 1.7863\n",
      "Baseline Loss: 2.8943 | Actual Loss: 2.0515\n",
      "Baseline Loss: 2.8793 | Actual Loss: 1.9653\n",
      "Baseline Loss: 2.7862 | Actual Loss: 1.6805\n",
      "Baseline Loss: 2.7880 | Actual Loss: 1.8855\n",
      "Baseline Loss: 2.9483 | Actual Loss: 1.7841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 7/1000 [00:03<07:27,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8132 | Actual Loss: 1.8320\n",
      "Baseline Loss: 2.5574 | Actual Loss: 1.7965\n",
      "Baseline Loss: 2.8280 | Actual Loss: 2.2734\n",
      "Baseline Loss: 2.7565 | Actual Loss: 1.6745\n",
      "Baseline Loss: 2.8293 | Actual Loss: 1.8126\n",
      "Baseline Loss: 2.7468 | Actual Loss: 1.9884\n",
      "Epoch 7/1000: Train Loss: 1.9802, Val Loss: 1.9372\n",
      "New best validation loss: 1.9372\n",
      "Baseline Loss: 2.8251 | Actual Loss: 2.0193\n",
      "Baseline Loss: 2.7841 | Actual Loss: 2.1553\n",
      "Baseline Loss: 2.7607 | Actual Loss: 2.3860\n",
      "Baseline Loss: 2.8289 | Actual Loss: 1.8956\n",
      "Baseline Loss: 2.8478 | Actual Loss: 2.2761\n",
      "Baseline Loss: 2.8263 | Actual Loss: 1.7538\n",
      "Baseline Loss: 2.8244 | Actual Loss: 1.6736\n",
      "Baseline Loss: 2.7741 | Actual Loss: 2.0066\n",
      "Baseline Loss: 2.8630 | Actual Loss: 2.2004\n",
      "Baseline Loss: 2.8948 | Actual Loss: 1.6677\n",
      "Baseline Loss: 2.8239 | Actual Loss: 1.8920\n",
      "Baseline Loss: 2.7976 | Actual Loss: 1.7194\n",
      "Baseline Loss: 2.8463 | Actual Loss: 2.3180\n",
      "Baseline Loss: 2.8320 | Actual Loss: 1.6227\n",
      "Baseline Loss: 2.9150 | Actual Loss: 2.1265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 8/1000 [00:03<07:48,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5298 | Actual Loss: 1.7630\n",
      "Baseline Loss: 2.8280 | Actual Loss: 2.0299\n",
      "Baseline Loss: 2.7565 | Actual Loss: 1.7084\n",
      "Baseline Loss: 2.8293 | Actual Loss: 2.0260\n",
      "Baseline Loss: 2.7468 | Actual Loss: 1.9939\n",
      "Epoch 8/1000: Train Loss: 1.9672, Val Loss: 1.9396\n",
      "Baseline Loss: 2.8299 | Actual Loss: 2.2835\n",
      "Baseline Loss: 2.8361 | Actual Loss: 1.8049\n",
      "Baseline Loss: 2.7955 | Actual Loss: 1.8334\n",
      "Baseline Loss: 2.8001 | Actual Loss: 1.8699\n",
      "Baseline Loss: 2.8489 | Actual Loss: 1.7735\n",
      "Baseline Loss: 2.8771 | Actual Loss: 1.8881\n",
      "Baseline Loss: 2.8075 | Actual Loss: 1.6754\n",
      "Baseline Loss: 2.9002 | Actual Loss: 1.7148\n",
      "Baseline Loss: 2.8409 | Actual Loss: 1.7558\n",
      "Baseline Loss: 2.9310 | Actual Loss: 1.9452\n",
      "Baseline Loss: 2.7789 | Actual Loss: 1.9527\n",
      "Baseline Loss: 2.7612 | Actual Loss: 1.1896\n",
      "Baseline Loss: 2.8592 | Actual Loss: 1.8044\n",
      "Baseline Loss: 2.8241 | Actual Loss: 1.7963\n",
      "Baseline Loss: 2.8022 | Actual Loss: 2.3757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 9/1000 [00:04<07:49,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.4070 | Actual Loss: 1.6439\n",
      "Baseline Loss: 2.8280 | Actual Loss: 2.1114\n",
      "Baseline Loss: 2.7565 | Actual Loss: 1.5585\n",
      "Baseline Loss: 2.8293 | Actual Loss: 1.7262\n",
      "Baseline Loss: 2.7468 | Actual Loss: 1.5013\n",
      "Epoch 9/1000: Train Loss: 1.8317, Val Loss: 1.7244\n",
      "New best validation loss: 1.7244\n",
      "Baseline Loss: 2.7663 | Actual Loss: 1.6840\n",
      "Baseline Loss: 2.8492 | Actual Loss: 2.2081\n",
      "Baseline Loss: 2.8497 | Actual Loss: 1.4007\n",
      "Baseline Loss: 2.8277 | Actual Loss: 1.8977\n",
      "Baseline Loss: 2.7510 | Actual Loss: 1.4451\n",
      "Baseline Loss: 2.8157 | Actual Loss: 1.5626\n",
      "Baseline Loss: 2.8766 | Actual Loss: 1.9311\n",
      "Baseline Loss: 2.9037 | Actual Loss: 1.7780\n",
      "Baseline Loss: 2.8060 | Actual Loss: 1.7438\n",
      "Baseline Loss: 2.8350 | Actual Loss: 1.9876\n",
      "Baseline Loss: 2.7752 | Actual Loss: 1.7795\n",
      "Baseline Loss: 2.8944 | Actual Loss: 1.7520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 10/1000 [00:04<07:18,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8478 | Actual Loss: 2.3560\n",
      "Baseline Loss: 2.8205 | Actual Loss: 1.3981\n",
      "Baseline Loss: 2.8122 | Actual Loss: 2.0003\n",
      "Baseline Loss: 2.5788 | Actual Loss: 1.1985\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.7544\n",
      "Baseline Loss: 2.7565 | Actual Loss: 1.6931\n",
      "Baseline Loss: 2.8293 | Actual Loss: 2.0066\n",
      "Baseline Loss: 2.7468 | Actual Loss: 1.5550\n",
      "Epoch 10/1000: Train Loss: 1.7577, Val Loss: 1.7523\n",
      "Baseline Loss: 2.8519 | Actual Loss: 1.9390\n",
      "Baseline Loss: 2.8101 | Actual Loss: 2.0884\n",
      "Baseline Loss: 2.8523 | Actual Loss: 1.7501\n",
      "Baseline Loss: 2.8630 | Actual Loss: 1.5241\n",
      "Baseline Loss: 2.8979 | Actual Loss: 1.8347\n",
      "Baseline Loss: 2.8565 | Actual Loss: 1.4770\n",
      "Baseline Loss: 2.8069 | Actual Loss: 1.6160\n",
      "Baseline Loss: 2.8643 | Actual Loss: 1.6380\n",
      "Baseline Loss: 2.8176 | Actual Loss: 1.7917\n",
      "Baseline Loss: 2.8869 | Actual Loss: 1.5699\n",
      "Baseline Loss: 2.8523 | Actual Loss: 1.8646\n",
      "Baseline Loss: 2.7298 | Actual Loss: 1.5354\n",
      "Baseline Loss: 2.8349 | Actual Loss: 1.5576\n",
      "Baseline Loss: 2.8241 | Actual Loss: 1.4620\n",
      "Baseline Loss: 2.7475 | Actual Loss: 1.1031\n",
      "Baseline Loss: 2.5544 | Actual Loss: 1.6017\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.9922\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.9174\n",
      "Baseline Loss: 2.8293 | Actual Loss: 2.0574\n",
      "Baseline Loss: 2.7468 | Actual Loss: 1.6791\n",
      "Epoch 11/1000: Train Loss: 1.6471, Val Loss: 1.6615\n",
      "New best validation loss: 1.6615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 11/1000 [00:05<07:43,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8713 | Actual Loss: 1.7391\n",
      "Baseline Loss: 2.8909 | Actual Loss: 1.5262\n",
      "Baseline Loss: 2.8629 | Actual Loss: 1.7515\n",
      "Baseline Loss: 2.7910 | Actual Loss: 2.0128\n",
      "Baseline Loss: 2.8305 | Actual Loss: 1.2379\n",
      "Baseline Loss: 2.8410 | Actual Loss: 1.8621\n",
      "Baseline Loss: 2.7839 | Actual Loss: 1.5534\n",
      "Baseline Loss: 2.8520 | Actual Loss: 1.7357\n",
      "Baseline Loss: 2.8194 | Actual Loss: 1.4735\n",
      "Baseline Loss: 2.7644 | Actual Loss: 1.4704\n",
      "Baseline Loss: 2.8189 | Actual Loss: 1.1884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 12/1000 [00:05<07:17,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8727 | Actual Loss: 1.3734\n",
      "Baseline Loss: 2.8309 | Actual Loss: 1.4778\n",
      "Baseline Loss: 2.7936 | Actual Loss: 1.6438\n",
      "Baseline Loss: 2.7984 | Actual Loss: 1.3859\n",
      "Baseline Loss: 2.5366 | Actual Loss: 1.8699\n",
      "Baseline Loss: 2.8280 | Actual Loss: 2.0077\n",
      "Baseline Loss: 2.7565 | Actual Loss: 1.0918\n",
      "Baseline Loss: 2.8293 | Actual Loss: 1.9525\n",
      "Baseline Loss: 2.7468 | Actual Loss: 1.7068\n",
      "Epoch 12/1000: Train Loss: 1.5814, Val Loss: 1.6897\n",
      "Baseline Loss: 2.8518 | Actual Loss: 1.5500\n",
      "Baseline Loss: 2.8145 | Actual Loss: 1.1786\n",
      "Baseline Loss: 2.8767 | Actual Loss: 1.7651\n",
      "Baseline Loss: 2.8600 | Actual Loss: 1.2780\n",
      "Baseline Loss: 2.8415 | Actual Loss: 1.5157\n",
      "Baseline Loss: 2.8405 | Actual Loss: 1.7121\n",
      "Baseline Loss: 2.8928 | Actual Loss: 1.4041\n",
      "Baseline Loss: 2.8825 | Actual Loss: 1.7539\n",
      "Baseline Loss: 2.8854 | Actual Loss: 1.8149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏         | 13/1000 [00:05<07:29,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8288 | Actual Loss: 1.4166\n",
      "Baseline Loss: 2.8811 | Actual Loss: 1.0597\n",
      "Baseline Loss: 2.7516 | Actual Loss: 1.2377\n",
      "Baseline Loss: 2.7992 | Actual Loss: 1.0559\n",
      "Baseline Loss: 2.8086 | Actual Loss: 1.1972\n",
      "Baseline Loss: 2.7977 | Actual Loss: 2.1811\n",
      "Baseline Loss: 2.4764 | Actual Loss: 1.3832\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.9074\n",
      "Baseline Loss: 2.7565 | Actual Loss: 1.3379\n",
      "Baseline Loss: 2.8293 | Actual Loss: 1.8959\n",
      "Baseline Loss: 2.7468 | Actual Loss: 1.1555\n",
      "Epoch 13/1000: Train Loss: 1.4690, Val Loss: 1.5742\n",
      "New best validation loss: 1.5742\n",
      "Baseline Loss: 2.7621 | Actual Loss: 1.2877\n",
      "Baseline Loss: 2.8098 | Actual Loss: 1.2790\n",
      "Baseline Loss: 2.8494 | Actual Loss: 1.0911\n",
      "Baseline Loss: 2.7852 | Actual Loss: 0.8683\n",
      "Baseline Loss: 2.8728 | Actual Loss: 1.1265\n",
      "Baseline Loss: 2.8528 | Actual Loss: 1.3922\n",
      "Baseline Loss: 2.8954 | Actual Loss: 1.2849\n",
      "Baseline Loss: 2.7676 | Actual Loss: 1.2532\n",
      "Baseline Loss: 2.9113 | Actual Loss: 0.8753\n",
      "Baseline Loss: 2.8999 | Actual Loss: 1.7665\n",
      "Baseline Loss: 2.8474 | Actual Loss: 2.0696\n",
      "Baseline Loss: 2.8435 | Actual Loss: 1.2014\n",
      "Baseline Loss: 2.7638 | Actual Loss: 1.5067\n",
      "Baseline Loss: 2.8250 | Actual Loss: 1.4800\n",
      "Baseline Loss: 2.9194 | Actual Loss: 1.1066\n",
      "Baseline Loss: 2.5453 | Actual Loss: 0.7170\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.4664\n",
      "Baseline Loss: 2.7565 | Actual Loss: 1.2962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏         | 14/1000 [00:06<07:43,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8293 | Actual Loss: 1.4257\n",
      "Baseline Loss: 2.7468 | Actual Loss: 1.0817\n",
      "Epoch 14/1000: Train Loss: 1.2691, Val Loss: 1.3175\n",
      "New best validation loss: 1.3175\n",
      "Baseline Loss: 2.8150 | Actual Loss: 1.1181\n",
      "Baseline Loss: 2.8163 | Actual Loss: 0.8369\n",
      "Baseline Loss: 2.7981 | Actual Loss: 1.0155\n",
      "Baseline Loss: 2.7893 | Actual Loss: 1.4215\n",
      "Baseline Loss: 2.7992 | Actual Loss: 1.3673\n",
      "Baseline Loss: 2.9202 | Actual Loss: 1.4661\n",
      "Baseline Loss: 2.8218 | Actual Loss: 1.5718\n",
      "Baseline Loss: 2.8525 | Actual Loss: 1.3114\n",
      "Baseline Loss: 2.7580 | Actual Loss: 1.0729\n",
      "Baseline Loss: 2.8854 | Actual Loss: 1.2046\n",
      "Baseline Loss: 2.8289 | Actual Loss: 0.8837\n",
      "Baseline Loss: 2.8468 | Actual Loss: 1.2749\n",
      "Baseline Loss: 2.8163 | Actual Loss: 1.0090\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.3905\n",
      "Baseline Loss: 2.8170 | Actual Loss: 1.3413\n",
      "Baseline Loss: 2.5448 | Actual Loss: 0.6849\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.3611\n",
      "Baseline Loss: 2.7565 | Actual Loss: 1.0950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 15/1000 [00:06<07:23,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8293 | Actual Loss: 1.1328\n",
      "Baseline Loss: 2.7468 | Actual Loss: 1.0976\n",
      "Epoch 15/1000: Train Loss: 1.1856, Val Loss: 1.1717\n",
      "New best validation loss: 1.1717\n",
      "Baseline Loss: 2.8940 | Actual Loss: 1.3780\n",
      "Baseline Loss: 2.8535 | Actual Loss: 1.2100\n",
      "Baseline Loss: 2.7962 | Actual Loss: 0.9917\n",
      "Baseline Loss: 2.7863 | Actual Loss: 0.9951\n",
      "Baseline Loss: 2.8088 | Actual Loss: 1.1954\n",
      "Baseline Loss: 2.8000 | Actual Loss: 0.9937\n",
      "Baseline Loss: 2.7714 | Actual Loss: 1.0611\n",
      "Baseline Loss: 2.7983 | Actual Loss: 1.0829\n",
      "Baseline Loss: 2.8072 | Actual Loss: 0.9133\n",
      "Baseline Loss: 2.8269 | Actual Loss: 1.0852\n",
      "Baseline Loss: 2.8708 | Actual Loss: 1.1603\n",
      "Baseline Loss: 2.8906 | Actual Loss: 0.9743\n",
      "Baseline Loss: 2.8276 | Actual Loss: 0.6634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 16/1000 [00:07<07:40,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8642 | Actual Loss: 0.9663\n",
      "Baseline Loss: 2.7966 | Actual Loss: 1.4285\n",
      "Baseline Loss: 2.6028 | Actual Loss: 0.7121\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.5958\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.9753\n",
      "Baseline Loss: 2.8293 | Actual Loss: 1.4316\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.8919\n",
      "Epoch 16/1000: Train Loss: 1.0507, Val Loss: 1.2236\n",
      "Baseline Loss: 2.7638 | Actual Loss: 1.1027\n",
      "Baseline Loss: 2.8765 | Actual Loss: 1.4925\n",
      "Baseline Loss: 2.8519 | Actual Loss: 0.9994\n",
      "Baseline Loss: 2.8895 | Actual Loss: 1.4298\n",
      "Baseline Loss: 2.8222 | Actual Loss: 1.0606\n",
      "Baseline Loss: 2.8650 | Actual Loss: 1.1277\n",
      "Baseline Loss: 2.8662 | Actual Loss: 1.0437\n",
      "Baseline Loss: 2.8700 | Actual Loss: 1.2613\n",
      "Baseline Loss: 2.7604 | Actual Loss: 1.0851\n",
      "Baseline Loss: 2.8146 | Actual Loss: 0.8158\n",
      "Baseline Loss: 2.7991 | Actual Loss: 1.1088\n",
      "Baseline Loss: 2.8995 | Actual Loss: 1.2393\n",
      "Baseline Loss: 2.7874 | Actual Loss: 1.5938\n",
      "Baseline Loss: 2.7431 | Actual Loss: 0.9916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 17/1000 [00:07<07:46,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8761 | Actual Loss: 0.6883\n",
      "Baseline Loss: 2.5250 | Actual Loss: 1.2963\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.6576\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.8657\n",
      "Baseline Loss: 2.8293 | Actual Loss: 1.3539\n",
      "Baseline Loss: 2.7468 | Actual Loss: 1.0346\n",
      "Epoch 17/1000: Train Loss: 1.1461, Val Loss: 1.2279\n",
      "Baseline Loss: 2.7702 | Actual Loss: 0.9429\n",
      "Baseline Loss: 2.8609 | Actual Loss: 0.9340\n",
      "Baseline Loss: 2.8329 | Actual Loss: 1.3456\n",
      "Baseline Loss: 2.8596 | Actual Loss: 1.2056\n",
      "Baseline Loss: 2.8553 | Actual Loss: 1.5511\n",
      "Baseline Loss: 2.8336 | Actual Loss: 0.7828\n",
      "Baseline Loss: 2.7803 | Actual Loss: 0.8018\n",
      "Baseline Loss: 2.8567 | Actual Loss: 1.2157\n",
      "Baseline Loss: 2.7724 | Actual Loss: 1.4823\n",
      "Baseline Loss: 2.7922 | Actual Loss: 1.1083\n",
      "Baseline Loss: 2.9191 | Actual Loss: 0.9504\n",
      "Baseline Loss: 2.8811 | Actual Loss: 1.0421\n",
      "Baseline Loss: 2.8428 | Actual Loss: 0.6811\n",
      "Baseline Loss: 2.8374 | Actual Loss: 0.8177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 18/1000 [00:08<07:23,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8357 | Actual Loss: 1.0188\n",
      "Baseline Loss: 2.5705 | Actual Loss: 0.7367\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.2756\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.7845\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.9558\n",
      "Baseline Loss: 2.7468 | Actual Loss: 1.1744\n",
      "Epoch 18/1000: Train Loss: 1.0386, Val Loss: 1.0476\n",
      "New best validation loss: 1.0476\n",
      "Baseline Loss: 2.9059 | Actual Loss: 1.0195\n",
      "Baseline Loss: 2.7974 | Actual Loss: 1.0324\n",
      "Baseline Loss: 2.8407 | Actual Loss: 1.1118\n",
      "Baseline Loss: 2.7959 | Actual Loss: 0.6403\n",
      "Baseline Loss: 2.7919 | Actual Loss: 0.7703\n",
      "Baseline Loss: 2.8306 | Actual Loss: 0.6163\n",
      "Baseline Loss: 2.7882 | Actual Loss: 0.7755\n",
      "Baseline Loss: 2.8116 | Actual Loss: 0.9707\n",
      "Baseline Loss: 2.7678 | Actual Loss: 0.6620\n",
      "Baseline Loss: 2.8694 | Actual Loss: 1.7825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 19/1000 [00:08<07:38,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7788 | Actual Loss: 0.9407\n",
      "Baseline Loss: 2.8367 | Actual Loss: 0.8697\n",
      "Baseline Loss: 2.7888 | Actual Loss: 1.0280\n",
      "Baseline Loss: 2.9671 | Actual Loss: 0.9130\n",
      "Baseline Loss: 2.7783 | Actual Loss: 1.0838\n",
      "Baseline Loss: 2.6070 | Actual Loss: 0.6340\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.3257\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.9478\n",
      "Baseline Loss: 2.8293 | Actual Loss: 1.0094\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.9427\n",
      "Epoch 19/1000: Train Loss: 0.9282, Val Loss: 1.0564\n",
      "Baseline Loss: 2.8681 | Actual Loss: 1.0442\n",
      "Baseline Loss: 2.9193 | Actual Loss: 0.8655\n",
      "Baseline Loss: 2.7917 | Actual Loss: 1.2723\n",
      "Baseline Loss: 2.8042 | Actual Loss: 0.7606\n",
      "Baseline Loss: 2.8258 | Actual Loss: 1.4703\n",
      "Baseline Loss: 2.8265 | Actual Loss: 0.9640\n",
      "Baseline Loss: 2.7986 | Actual Loss: 1.1712\n",
      "Baseline Loss: 2.7880 | Actual Loss: 1.1003\n",
      "Baseline Loss: 2.7776 | Actual Loss: 0.8975\n",
      "Baseline Loss: 2.7674 | Actual Loss: 1.1486\n",
      "Baseline Loss: 2.9253 | Actual Loss: 0.9506\n",
      "Baseline Loss: 2.8522 | Actual Loss: 0.9993\n",
      "Baseline Loss: 2.7569 | Actual Loss: 1.2326\n",
      "Baseline Loss: 2.8119 | Actual Loss: 0.9226\n",
      "Baseline Loss: 2.9347 | Actual Loss: 0.7707\n",
      "Baseline Loss: 2.4928 | Actual Loss: 0.7566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 20/1000 [00:09<07:50,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8280 | Actual Loss: 1.6936\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.8091\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.9942\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.8191\n",
      "Epoch 20/1000: Train Loss: 1.0204, Val Loss: 1.0790\n",
      "Baseline Loss: 2.8389 | Actual Loss: 0.7796\n",
      "Baseline Loss: 2.9387 | Actual Loss: 1.0529\n",
      "Baseline Loss: 2.7865 | Actual Loss: 0.6088\n",
      "Baseline Loss: 2.8988 | Actual Loss: 0.8374\n",
      "Baseline Loss: 2.7847 | Actual Loss: 2.4372\n",
      "Baseline Loss: 2.9003 | Actual Loss: 0.8860\n",
      "Baseline Loss: 2.7613 | Actual Loss: 1.7750\n",
      "Baseline Loss: 2.8701 | Actual Loss: 1.9997\n",
      "Baseline Loss: 2.7715 | Actual Loss: 0.9300\n",
      "Baseline Loss: 2.7682 | Actual Loss: 1.9629\n",
      "Baseline Loss: 2.7591 | Actual Loss: 0.9322\n",
      "Baseline Loss: 2.8276 | Actual Loss: 1.3380\n",
      "Baseline Loss: 2.8844 | Actual Loss: 0.8223\n",
      "Baseline Loss: 2.8714 | Actual Loss: 0.7839\n",
      "Baseline Loss: 2.8539 | Actual Loss: 0.7755\n",
      "Baseline Loss: 2.6064 | Actual Loss: 1.1337\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.5645\n",
      "Baseline Loss: 2.7565 | Actual Loss: 1.0303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 21/1000 [00:09<07:24,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8293 | Actual Loss: 1.4000\n",
      "Baseline Loss: 2.7468 | Actual Loss: 1.0045\n",
      "Epoch 21/1000: Train Loss: 1.1909, Val Loss: 1.2499\n",
      "Baseline Loss: 2.8169 | Actual Loss: 0.8391\n",
      "Baseline Loss: 2.7931 | Actual Loss: 0.8597\n",
      "Baseline Loss: 2.8216 | Actual Loss: 0.9291\n",
      "Baseline Loss: 2.7800 | Actual Loss: 1.1388\n",
      "Baseline Loss: 2.8889 | Actual Loss: 0.7252\n",
      "Baseline Loss: 2.7801 | Actual Loss: 0.8415\n",
      "Baseline Loss: 2.7824 | Actual Loss: 0.9323\n",
      "Baseline Loss: 2.8587 | Actual Loss: 0.9187\n",
      "Baseline Loss: 2.8546 | Actual Loss: 0.7370\n",
      "Baseline Loss: 2.9518 | Actual Loss: 1.8232\n",
      "Baseline Loss: 2.7982 | Actual Loss: 1.3996\n",
      "Baseline Loss: 2.7868 | Actual Loss: 0.5975\n",
      "Baseline Loss: 2.9470 | Actual Loss: 0.9814\n",
      "Baseline Loss: 2.8210 | Actual Loss: 2.6805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 22/1000 [00:10<07:37,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8363 | Actual Loss: 0.9413\n",
      "Baseline Loss: 2.5546 | Actual Loss: 2.6834\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.4149\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.7930\n",
      "Baseline Loss: 2.8293 | Actual Loss: 1.2864\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.8347\n",
      "Epoch 22/1000: Train Loss: 1.1893, Val Loss: 1.0823\n",
      "Baseline Loss: 2.8483 | Actual Loss: 0.7132\n",
      "Baseline Loss: 2.8094 | Actual Loss: 1.3073\n",
      "Baseline Loss: 2.8144 | Actual Loss: 1.1484\n",
      "Baseline Loss: 2.8163 | Actual Loss: 0.8297\n",
      "Baseline Loss: 2.7886 | Actual Loss: 0.7729\n",
      "Baseline Loss: 2.8462 | Actual Loss: 0.8587\n",
      "Baseline Loss: 2.7384 | Actual Loss: 0.8024\n",
      "Baseline Loss: 2.8531 | Actual Loss: 1.4527\n",
      "Baseline Loss: 2.8790 | Actual Loss: 0.8038\n",
      "Baseline Loss: 2.8237 | Actual Loss: 1.2687\n",
      "Baseline Loss: 2.8771 | Actual Loss: 1.2582\n",
      "Baseline Loss: 2.8672 | Actual Loss: 0.9044\n",
      "Baseline Loss: 2.8080 | Actual Loss: 0.6569\n",
      "Baseline Loss: 2.8022 | Actual Loss: 0.7435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 23/1000 [00:10<07:51,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7369 | Actual Loss: 0.8040\n",
      "Baseline Loss: 2.6572 | Actual Loss: 0.4216\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.4953\n",
      "Baseline Loss: 2.7565 | Actual Loss: 1.0443\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.9778\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.7309\n",
      "Epoch 23/1000: Train Loss: 0.9217, Val Loss: 1.0621\n",
      "Baseline Loss: 2.8653 | Actual Loss: 1.2386\n",
      "Baseline Loss: 2.8796 | Actual Loss: 1.0958\n",
      "Baseline Loss: 2.8684 | Actual Loss: 0.9807\n",
      "Baseline Loss: 2.8284 | Actual Loss: 1.0451\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.9529\n",
      "Baseline Loss: 2.7961 | Actual Loss: 1.3147\n",
      "Baseline Loss: 2.7515 | Actual Loss: 0.7764\n",
      "Baseline Loss: 2.7255 | Actual Loss: 1.0028\n",
      "Baseline Loss: 2.8616 | Actual Loss: 0.8696\n",
      "Baseline Loss: 2.8457 | Actual Loss: 0.5869\n",
      "Baseline Loss: 2.8831 | Actual Loss: 0.8122\n",
      "Baseline Loss: 2.8387 | Actual Loss: 0.7466\n",
      "Baseline Loss: 2.7847 | Actual Loss: 0.7004\n",
      "Baseline Loss: 2.8399 | Actual Loss: 0.9267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 24/1000 [00:11<07:25,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8299 | Actual Loss: 0.7469\n",
      "Baseline Loss: 2.4999 | Actual Loss: 0.8406\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.3818\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.7893\n",
      "Baseline Loss: 2.8293 | Actual Loss: 1.2441\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.8440\n",
      "Epoch 24/1000: Train Loss: 0.9148, Val Loss: 1.0648\n",
      "Baseline Loss: 2.8907 | Actual Loss: 0.8813\n",
      "Baseline Loss: 2.8323 | Actual Loss: 0.5227\n",
      "Baseline Loss: 2.8891 | Actual Loss: 0.8460\n",
      "Baseline Loss: 2.8354 | Actual Loss: 0.8400\n",
      "Baseline Loss: 2.7857 | Actual Loss: 1.1921\n",
      "Baseline Loss: 2.8215 | Actual Loss: 1.1414\n",
      "Baseline Loss: 2.8294 | Actual Loss: 0.9105\n",
      "Baseline Loss: 2.8282 | Actual Loss: 1.1051\n",
      "Baseline Loss: 2.8373 | Actual Loss: 1.5209\n",
      "Baseline Loss: 2.8244 | Actual Loss: 0.8461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▎         | 25/1000 [00:11<07:36,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8780 | Actual Loss: 0.7905\n",
      "Baseline Loss: 2.7897 | Actual Loss: 1.0358\n",
      "Baseline Loss: 2.8360 | Actual Loss: 1.0914\n",
      "Baseline Loss: 2.7453 | Actual Loss: 0.7491\n",
      "Baseline Loss: 2.8455 | Actual Loss: 0.7551\n",
      "Baseline Loss: 2.5265 | Actual Loss: 0.5393\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.3975\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.7873\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.9950\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.6239\n",
      "Epoch 25/1000: Train Loss: 0.9230, Val Loss: 0.9509\n",
      "New best validation loss: 0.9509\n",
      "Baseline Loss: 2.8342 | Actual Loss: 1.6511\n",
      "Baseline Loss: 2.8049 | Actual Loss: 1.1368\n",
      "Baseline Loss: 2.8293 | Actual Loss: 1.3181\n",
      "Baseline Loss: 2.7521 | Actual Loss: 0.8894\n",
      "Baseline Loss: 2.8411 | Actual Loss: 0.8012\n",
      "Baseline Loss: 2.8500 | Actual Loss: 0.7513\n",
      "Baseline Loss: 2.7901 | Actual Loss: 0.5156\n",
      "Baseline Loss: 2.8644 | Actual Loss: 0.9527\n",
      "Baseline Loss: 2.7852 | Actual Loss: 0.8905\n",
      "Baseline Loss: 2.9317 | Actual Loss: 0.9660\n",
      "Baseline Loss: 2.7694 | Actual Loss: 0.5341\n",
      "Baseline Loss: 2.8734 | Actual Loss: 0.6997\n",
      "Baseline Loss: 2.7972 | Actual Loss: 0.7238\n",
      "Baseline Loss: 2.7814 | Actual Loss: 0.8242\n",
      "Baseline Loss: 2.8539 | Actual Loss: 1.0346\n",
      "Baseline Loss: 2.5113 | Actual Loss: 0.6299\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.1992\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.7454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 26/1000 [00:12<07:48,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8293 | Actual Loss: 1.2729\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.7758\n",
      "Epoch 26/1000: Train Loss: 0.8949, Val Loss: 0.9983\n",
      "Baseline Loss: 2.8471 | Actual Loss: 0.7135\n",
      "Baseline Loss: 2.9741 | Actual Loss: 0.8725\n",
      "Baseline Loss: 2.7519 | Actual Loss: 0.6422\n",
      "Baseline Loss: 2.8131 | Actual Loss: 1.1703\n",
      "Baseline Loss: 2.8135 | Actual Loss: 0.8481\n",
      "Baseline Loss: 2.8146 | Actual Loss: 0.7589\n",
      "Baseline Loss: 2.8230 | Actual Loss: 1.0398\n",
      "Baseline Loss: 2.8342 | Actual Loss: 0.7832\n",
      "Baseline Loss: 2.8374 | Actual Loss: 0.9391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 27/1000 [00:12<07:22,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9172 | Actual Loss: 1.3824\n",
      "Baseline Loss: 2.8012 | Actual Loss: 0.7650\n",
      "Baseline Loss: 2.7852 | Actual Loss: 0.5971\n",
      "Baseline Loss: 2.8975 | Actual Loss: 1.5019\n",
      "Baseline Loss: 2.8817 | Actual Loss: 1.0539\n",
      "Baseline Loss: 2.7271 | Actual Loss: 0.9075\n",
      "Baseline Loss: 2.4738 | Actual Loss: 0.7018\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.0365\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.7210\n",
      "Baseline Loss: 2.8293 | Actual Loss: 1.1026\n",
      "Baseline Loss: 2.7468 | Actual Loss: 1.4008\n",
      "Epoch 27/1000: Train Loss: 0.9173, Val Loss: 1.0652\n",
      "Baseline Loss: 2.8293 | Actual Loss: 1.1105\n",
      "Baseline Loss: 2.8705 | Actual Loss: 0.6232\n",
      "Baseline Loss: 2.8034 | Actual Loss: 0.9837\n",
      "Baseline Loss: 2.7965 | Actual Loss: 0.5797\n",
      "Baseline Loss: 2.8203 | Actual Loss: 0.7094\n",
      "Baseline Loss: 2.8519 | Actual Loss: 0.8906\n",
      "Baseline Loss: 2.8391 | Actual Loss: 1.2799\n",
      "Baseline Loss: 2.7773 | Actual Loss: 0.6965\n",
      "Baseline Loss: 2.8258 | Actual Loss: 0.7429\n",
      "Baseline Loss: 2.9290 | Actual Loss: 0.7836\n",
      "Baseline Loss: 2.8325 | Actual Loss: 0.7841\n",
      "Baseline Loss: 2.7806 | Actual Loss: 0.7730\n",
      "Baseline Loss: 2.7934 | Actual Loss: 0.6884\n",
      "Baseline Loss: 2.9053 | Actual Loss: 0.8394\n",
      "Baseline Loss: 2.8586 | Actual Loss: 0.8045\n",
      "Baseline Loss: 2.5803 | Actual Loss: 0.5956\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.4876\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.9214\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.7952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 28/1000 [00:13<07:43,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7468 | Actual Loss: 0.9102\n",
      "Epoch 28/1000: Train Loss: 0.8053, Val Loss: 1.0286\n",
      "Baseline Loss: 2.8804 | Actual Loss: 0.7946\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.6252\n",
      "Baseline Loss: 2.8392 | Actual Loss: 0.5178\n",
      "Baseline Loss: 2.8031 | Actual Loss: 0.7842\n",
      "Baseline Loss: 2.8138 | Actual Loss: 0.6477\n",
      "Baseline Loss: 2.8313 | Actual Loss: 0.9415\n",
      "Baseline Loss: 2.9045 | Actual Loss: 1.2729\n",
      "Baseline Loss: 2.8651 | Actual Loss: 1.2224\n",
      "Baseline Loss: 2.7566 | Actual Loss: 0.9745\n",
      "Baseline Loss: 2.8127 | Actual Loss: 1.0341\n",
      "Baseline Loss: 2.8492 | Actual Loss: 1.2150\n",
      "Baseline Loss: 2.8412 | Actual Loss: 0.4778\n",
      "Baseline Loss: 2.8600 | Actual Loss: 1.0441\n",
      "Baseline Loss: 2.8633 | Actual Loss: 1.6262\n",
      "Baseline Loss: 2.8133 | Actual Loss: 0.6182\n",
      "Baseline Loss: 2.7338 | Actual Loss: 1.3182\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.2304\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.7146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 29/1000 [00:13<07:31,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8293 | Actual Loss: 1.1510\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.7498\n",
      "Epoch 29/1000: Train Loss: 0.9446, Val Loss: 0.9615\n",
      "Baseline Loss: 2.7851 | Actual Loss: 0.7668\n",
      "Baseline Loss: 2.8774 | Actual Loss: 0.7357\n",
      "Baseline Loss: 2.8015 | Actual Loss: 0.6691\n",
      "Baseline Loss: 2.9046 | Actual Loss: 0.9591\n",
      "Baseline Loss: 2.8707 | Actual Loss: 1.0398\n",
      "Baseline Loss: 2.8311 | Actual Loss: 0.6000\n",
      "Baseline Loss: 2.7874 | Actual Loss: 0.8990\n",
      "Baseline Loss: 2.7946 | Actual Loss: 1.0620\n",
      "Baseline Loss: 2.8168 | Actual Loss: 0.5116\n",
      "Baseline Loss: 2.8428 | Actual Loss: 0.2294\n",
      "Baseline Loss: 2.8103 | Actual Loss: 1.0785\n",
      "Baseline Loss: 2.8435 | Actual Loss: 1.9642\n",
      "Baseline Loss: 2.8422 | Actual Loss: 1.1479\n",
      "Baseline Loss: 2.7465 | Actual Loss: 1.4802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 30/1000 [00:13<07:44,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8427 | Actual Loss: 0.7833\n",
      "Baseline Loss: 2.5610 | Actual Loss: 0.3569\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.4202\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.7182\n",
      "Baseline Loss: 2.8293 | Actual Loss: 1.2859\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.7531\n",
      "Epoch 30/1000: Train Loss: 0.8927, Val Loss: 1.0444\n",
      "Baseline Loss: 2.7592 | Actual Loss: 0.4335\n",
      "Baseline Loss: 2.8165 | Actual Loss: 1.1976\n",
      "Baseline Loss: 2.8230 | Actual Loss: 1.0563\n",
      "Baseline Loss: 2.8392 | Actual Loss: 0.5294\n",
      "Baseline Loss: 2.8342 | Actual Loss: 0.9739\n",
      "Baseline Loss: 2.8382 | Actual Loss: 0.7003\n",
      "Baseline Loss: 2.8229 | Actual Loss: 0.7397\n",
      "Baseline Loss: 2.7510 | Actual Loss: 0.9263\n",
      "Baseline Loss: 2.8327 | Actual Loss: 0.8218\n",
      "Baseline Loss: 2.8264 | Actual Loss: 0.5819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 31/1000 [00:14<08:00,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8801 | Actual Loss: 0.6227\n",
      "Baseline Loss: 2.8497 | Actual Loss: 0.8242\n",
      "Baseline Loss: 2.8251 | Actual Loss: 0.5885\n",
      "Baseline Loss: 2.8398 | Actual Loss: 0.4324\n",
      "Baseline Loss: 2.8715 | Actual Loss: 2.5474\n",
      "Baseline Loss: 2.5549 | Actual Loss: 2.5595\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.6807\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.6528\n",
      "Baseline Loss: 2.8293 | Actual Loss: 1.3142\n",
      "Baseline Loss: 2.7468 | Actual Loss: 1.9579\n",
      "Epoch 31/1000: Train Loss: 0.9710, Val Loss: 1.4014\n",
      "Baseline Loss: 2.8251 | Actual Loss: 1.0972\n",
      "Baseline Loss: 2.7510 | Actual Loss: 0.6780\n",
      "Baseline Loss: 2.8084 | Actual Loss: 1.3863\n",
      "Baseline Loss: 2.8627 | Actual Loss: 0.9885\n",
      "Baseline Loss: 2.8453 | Actual Loss: 1.0125\n",
      "Baseline Loss: 2.7550 | Actual Loss: 1.0714\n",
      "Baseline Loss: 2.8771 | Actual Loss: 1.2362\n",
      "Baseline Loss: 2.8047 | Actual Loss: 0.8616\n",
      "Baseline Loss: 2.8068 | Actual Loss: 1.0777\n",
      "Baseline Loss: 2.7784 | Actual Loss: 1.0781\n",
      "Baseline Loss: 2.8282 | Actual Loss: 0.6590\n",
      "Baseline Loss: 2.9041 | Actual Loss: 0.7856\n",
      "Baseline Loss: 2.8854 | Actual Loss: 0.8073\n",
      "Baseline Loss: 2.8519 | Actual Loss: 0.5800\n",
      "Baseline Loss: 2.9216 | Actual Loss: 0.7533\n",
      "Baseline Loss: 2.6275 | Actual Loss: 1.1153\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.3914\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.5500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 32/1000 [00:14<07:44,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8293 | Actual Loss: 1.5305\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.7452\n",
      "Epoch 32/1000: Train Loss: 0.9492, Val Loss: 1.0543\n",
      "Baseline Loss: 2.7408 | Actual Loss: 0.7624\n",
      "Baseline Loss: 2.7879 | Actual Loss: 0.7628\n",
      "Baseline Loss: 2.7755 | Actual Loss: 0.9025\n",
      "Baseline Loss: 2.8784 | Actual Loss: 0.7241\n",
      "Baseline Loss: 2.8386 | Actual Loss: 1.3951\n",
      "Baseline Loss: 2.8744 | Actual Loss: 2.5591\n",
      "Baseline Loss: 2.8885 | Actual Loss: 0.6114\n",
      "Baseline Loss: 2.9217 | Actual Loss: 0.7126\n",
      "Baseline Loss: 2.8022 | Actual Loss: 0.7156\n",
      "Baseline Loss: 2.8854 | Actual Loss: 0.4335\n",
      "Baseline Loss: 2.8142 | Actual Loss: 1.2885\n",
      "Baseline Loss: 2.7870 | Actual Loss: 0.3244\n",
      "Baseline Loss: 2.8400 | Actual Loss: 1.8943\n",
      "Baseline Loss: 2.8366 | Actual Loss: 0.8013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 33/1000 [00:15<07:52,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7985 | Actual Loss: 1.2658\n",
      "Baseline Loss: 2.5778 | Actual Loss: 0.2823\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.2586\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.7810\n",
      "Baseline Loss: 2.8293 | Actual Loss: 1.2750\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.7686\n",
      "Epoch 33/1000: Train Loss: 0.9647, Val Loss: 1.0208\n",
      "Baseline Loss: 2.8206 | Actual Loss: 1.1252\n",
      "Baseline Loss: 2.8438 | Actual Loss: 0.9707\n",
      "Baseline Loss: 2.8817 | Actual Loss: 0.8472\n",
      "Baseline Loss: 2.8254 | Actual Loss: 0.7701\n",
      "Baseline Loss: 2.8242 | Actual Loss: 0.7932\n",
      "Baseline Loss: 2.8797 | Actual Loss: 0.9132\n",
      "Baseline Loss: 2.8029 | Actual Loss: 0.9616\n",
      "Baseline Loss: 2.8520 | Actual Loss: 0.5513\n",
      "Baseline Loss: 2.8229 | Actual Loss: 0.5312\n",
      "Baseline Loss: 2.8102 | Actual Loss: 0.4927\n",
      "Baseline Loss: 2.8481 | Actual Loss: 0.9725\n",
      "Baseline Loss: 2.8695 | Actual Loss: 1.1395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 34/1000 [00:15<07:59,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8549 | Actual Loss: 1.2202\n",
      "Baseline Loss: 2.8105 | Actual Loss: 0.7566\n",
      "Baseline Loss: 2.8421 | Actual Loss: 1.2633\n",
      "Baseline Loss: 2.4990 | Actual Loss: 0.5722\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.0210\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.5462\n",
      "Baseline Loss: 2.8293 | Actual Loss: 1.0754\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.6013\n",
      "Epoch 34/1000: Train Loss: 0.8676, Val Loss: 0.8110\n",
      "New best validation loss: 0.8110\n",
      "Baseline Loss: 2.8524 | Actual Loss: 0.5208\n",
      "Baseline Loss: 2.9203 | Actual Loss: 0.8652\n",
      "Baseline Loss: 2.8978 | Actual Loss: 0.6096\n",
      "Baseline Loss: 2.8446 | Actual Loss: 1.2932\n",
      "Baseline Loss: 2.8541 | Actual Loss: 0.6535\n",
      "Baseline Loss: 2.8089 | Actual Loss: 1.0744\n",
      "Baseline Loss: 2.8621 | Actual Loss: 0.8883\n",
      "Baseline Loss: 2.8369 | Actual Loss: 0.7382\n",
      "Baseline Loss: 2.7936 | Actual Loss: 0.3476\n",
      "Baseline Loss: 2.8669 | Actual Loss: 0.4661\n",
      "Baseline Loss: 2.7889 | Actual Loss: 0.4950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 35/1000 [00:16<07:38,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7755 | Actual Loss: 0.9359\n",
      "Baseline Loss: 2.7555 | Actual Loss: 0.9534\n",
      "Baseline Loss: 2.8267 | Actual Loss: 1.4872\n",
      "Baseline Loss: 2.7841 | Actual Loss: 0.4942\n",
      "Baseline Loss: 2.5460 | Actual Loss: 0.9225\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.1394\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.6611\n",
      "Baseline Loss: 2.8293 | Actual Loss: 1.3262\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.7784\n",
      "Epoch 35/1000: Train Loss: 0.7966, Val Loss: 0.9763\n",
      "Baseline Loss: 2.8111 | Actual Loss: 0.4461\n",
      "Baseline Loss: 2.8822 | Actual Loss: 0.6691\n",
      "Baseline Loss: 2.8545 | Actual Loss: 0.8684\n",
      "Baseline Loss: 2.7958 | Actual Loss: 0.7324\n",
      "Baseline Loss: 2.8426 | Actual Loss: 0.7772\n",
      "Baseline Loss: 2.8026 | Actual Loss: 0.8435\n",
      "Baseline Loss: 2.8408 | Actual Loss: 0.7246\n",
      "Baseline Loss: 2.9142 | Actual Loss: 1.3131\n",
      "Baseline Loss: 2.8076 | Actual Loss: 0.5783\n",
      "Baseline Loss: 2.8536 | Actual Loss: 0.5841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 36/1000 [00:16<07:46,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7980 | Actual Loss: 1.2864\n",
      "Baseline Loss: 2.8675 | Actual Loss: 0.8740\n",
      "Baseline Loss: 2.8182 | Actual Loss: 0.6208\n",
      "Baseline Loss: 2.8863 | Actual Loss: 1.5844\n",
      "Baseline Loss: 2.9106 | Actual Loss: 0.6801\n",
      "Baseline Loss: 2.5092 | Actual Loss: 0.4883\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.0312\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.3690\n",
      "Baseline Loss: 2.8293 | Actual Loss: 1.1782\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.8242\n",
      "Epoch 36/1000: Train Loss: 0.8169, Val Loss: 0.8506\n",
      "Baseline Loss: 2.8593 | Actual Loss: 0.4955\n",
      "Baseline Loss: 2.7757 | Actual Loss: 0.4422\n",
      "Baseline Loss: 2.7904 | Actual Loss: 1.2623\n",
      "Baseline Loss: 2.8825 | Actual Loss: 0.4872\n",
      "Baseline Loss: 2.8335 | Actual Loss: 1.1438\n",
      "Baseline Loss: 2.7741 | Actual Loss: 1.4217\n",
      "Baseline Loss: 2.7881 | Actual Loss: 0.6479\n",
      "Baseline Loss: 2.8387 | Actual Loss: 0.6541\n",
      "Baseline Loss: 2.9554 | Actual Loss: 0.7881\n",
      "Baseline Loss: 2.8509 | Actual Loss: 0.5539\n",
      "Baseline Loss: 2.8507 | Actual Loss: 0.7940\n",
      "Baseline Loss: 2.8785 | Actual Loss: 0.8686\n",
      "Baseline Loss: 2.8473 | Actual Loss: 0.6112\n",
      "Baseline Loss: 2.7602 | Actual Loss: 0.3428\n",
      "Baseline Loss: 2.8613 | Actual Loss: 0.5699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 37/1000 [00:17<07:56,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5784 | Actual Loss: 0.9719\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.9364\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.4716\n",
      "Baseline Loss: 2.8293 | Actual Loss: 1.0484\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.9458\n",
      "Epoch 37/1000: Train Loss: 0.7535, Val Loss: 0.8506\n",
      "Baseline Loss: 2.8162 | Actual Loss: 1.3648\n",
      "Baseline Loss: 2.8337 | Actual Loss: 0.6310\n",
      "Baseline Loss: 2.7939 | Actual Loss: 0.8542\n",
      "Baseline Loss: 2.8555 | Actual Loss: 0.8958\n",
      "Baseline Loss: 2.8921 | Actual Loss: 1.0312\n",
      "Baseline Loss: 2.8499 | Actual Loss: 0.6687\n",
      "Baseline Loss: 2.8577 | Actual Loss: 0.5080\n",
      "Baseline Loss: 2.7759 | Actual Loss: 0.5627\n",
      "Baseline Loss: 2.8604 | Actual Loss: 0.5990\n",
      "Baseline Loss: 2.7755 | Actual Loss: 2.2196\n",
      "Baseline Loss: 2.8863 | Actual Loss: 0.7486\n",
      "Baseline Loss: 2.7834 | Actual Loss: 1.1768\n",
      "Baseline Loss: 2.8323 | Actual Loss: 0.7112\n",
      "Baseline Loss: 2.8107 | Actual Loss: 0.4496\n",
      "Baseline Loss: 2.8725 | Actual Loss: 0.6028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 38/1000 [00:17<07:40,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5117 | Actual Loss: 0.6328\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.4477\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.8175\n",
      "Baseline Loss: 2.8293 | Actual Loss: 1.0662\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.8392\n",
      "Epoch 38/1000: Train Loss: 0.8535, Val Loss: 1.0427\n",
      "Baseline Loss: 2.8802 | Actual Loss: 0.8340\n",
      "Baseline Loss: 2.8566 | Actual Loss: 0.6560\n",
      "Baseline Loss: 2.9079 | Actual Loss: 0.8826\n",
      "Baseline Loss: 2.8438 | Actual Loss: 1.0070\n",
      "Baseline Loss: 2.8286 | Actual Loss: 0.8249\n",
      "Baseline Loss: 2.9144 | Actual Loss: 0.5561\n",
      "Baseline Loss: 2.8364 | Actual Loss: 0.5754\n",
      "Baseline Loss: 2.7908 | Actual Loss: 0.6138\n",
      "Baseline Loss: 2.8058 | Actual Loss: 1.9100\n",
      "Baseline Loss: 2.7626 | Actual Loss: 0.6050\n",
      "Baseline Loss: 2.8542 | Actual Loss: 1.0387\n",
      "Baseline Loss: 2.8232 | Actual Loss: 1.0413\n",
      "Baseline Loss: 2.8712 | Actual Loss: 1.3201\n",
      "Baseline Loss: 2.8764 | Actual Loss: 0.5857\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.4515\n",
      "Baseline Loss: 2.4309 | Actual Loss: 0.4744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 39/1000 [00:18<07:36,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8280 | Actual Loss: 1.3882\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.6963\n",
      "Baseline Loss: 2.8293 | Actual Loss: 1.0273\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.6225\n",
      "Epoch 39/1000: Train Loss: 0.8360, Val Loss: 0.9336\n",
      "Baseline Loss: 2.8155 | Actual Loss: 0.6173\n",
      "Baseline Loss: 2.8071 | Actual Loss: 0.6204\n",
      "Baseline Loss: 2.8077 | Actual Loss: 0.4320\n",
      "Baseline Loss: 2.9515 | Actual Loss: 0.6550\n",
      "Baseline Loss: 2.8531 | Actual Loss: 0.7797\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.5851\n",
      "Baseline Loss: 2.8170 | Actual Loss: 0.7620\n",
      "Baseline Loss: 2.7942 | Actual Loss: 0.7654\n",
      "Baseline Loss: 2.8164 | Actual Loss: 0.8671\n",
      "Baseline Loss: 2.8269 | Actual Loss: 0.7337\n",
      "Baseline Loss: 2.8072 | Actual Loss: 0.7360\n",
      "Baseline Loss: 2.9005 | Actual Loss: 0.4332\n",
      "Baseline Loss: 2.8611 | Actual Loss: 0.5931\n",
      "Baseline Loss: 2.7718 | Actual Loss: 0.8915\n",
      "Baseline Loss: 2.8215 | Actual Loss: 0.7932\n",
      "Baseline Loss: 2.5312 | Actual Loss: 0.4976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 40/1000 [00:18<07:40,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8280 | Actual Loss: 1.4622\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.5587\n",
      "Baseline Loss: 2.8293 | Actual Loss: 1.2048\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.5036\n",
      "Epoch 40/1000: Train Loss: 0.6726, Val Loss: 0.9324\n",
      "Baseline Loss: 2.8877 | Actual Loss: 0.7721\n",
      "Baseline Loss: 2.8264 | Actual Loss: 0.6018\n",
      "Baseline Loss: 2.8203 | Actual Loss: 1.4529\n",
      "Baseline Loss: 2.8814 | Actual Loss: 0.6296\n",
      "Baseline Loss: 2.7799 | Actual Loss: 0.5104\n",
      "Baseline Loss: 2.8651 | Actual Loss: 1.7802\n",
      "Baseline Loss: 2.8801 | Actual Loss: 0.5980\n",
      "Baseline Loss: 2.8340 | Actual Loss: 0.9802\n",
      "Baseline Loss: 2.7751 | Actual Loss: 0.4961\n",
      "Baseline Loss: 2.7573 | Actual Loss: 0.5546\n",
      "Baseline Loss: 2.8875 | Actual Loss: 0.9718\n",
      "Baseline Loss: 2.8250 | Actual Loss: 0.4259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 41/1000 [00:19<07:35,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8199 | Actual Loss: 0.3525\n",
      "Baseline Loss: 2.8938 | Actual Loss: 1.0561\n",
      "Baseline Loss: 2.7715 | Actual Loss: 0.9816\n",
      "Baseline Loss: 2.5532 | Actual Loss: 0.4578\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.9454\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.5909\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.9931\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.5377\n",
      "Epoch 41/1000: Train Loss: 0.7889, Val Loss: 0.7668\n",
      "New best validation loss: 0.7668\n",
      "Baseline Loss: 2.9253 | Actual Loss: 1.2635\n",
      "Baseline Loss: 2.8024 | Actual Loss: 1.0802\n",
      "Baseline Loss: 2.8042 | Actual Loss: 0.9516\n",
      "Baseline Loss: 2.8265 | Actual Loss: 1.0190\n",
      "Baseline Loss: 2.8020 | Actual Loss: 0.6393\n",
      "Baseline Loss: 2.8273 | Actual Loss: 0.6582\n",
      "Baseline Loss: 2.7896 | Actual Loss: 0.5549\n",
      "Baseline Loss: 2.9108 | Actual Loss: 1.0167\n",
      "Baseline Loss: 2.8440 | Actual Loss: 0.6582\n",
      "Baseline Loss: 2.8095 | Actual Loss: 0.5593\n",
      "Baseline Loss: 2.7718 | Actual Loss: 0.4434\n",
      "Baseline Loss: 2.9610 | Actual Loss: 0.4821\n",
      "Baseline Loss: 2.8870 | Actual Loss: 0.5979\n",
      "Baseline Loss: 2.8611 | Actual Loss: 0.5072\n",
      "Baseline Loss: 2.7891 | Actual Loss: 0.6381\n",
      "Baseline Loss: 2.6436 | Actual Loss: 2.1572\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.4917\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.6901\n",
      "Baseline Loss: 2.8293 | Actual Loss: 1.3407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 42/1000 [00:19<07:33,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7468 | Actual Loss: 0.6698\n",
      "Epoch 42/1000: Train Loss: 0.8267, Val Loss: 1.0481\n",
      "Baseline Loss: 2.8651 | Actual Loss: 2.3963\n",
      "Baseline Loss: 2.8629 | Actual Loss: 0.4385\n",
      "Baseline Loss: 2.8620 | Actual Loss: 0.9591\n",
      "Baseline Loss: 2.8504 | Actual Loss: 0.6437\n",
      "Baseline Loss: 2.8165 | Actual Loss: 0.6339\n",
      "Baseline Loss: 2.7897 | Actual Loss: 0.7772\n",
      "Baseline Loss: 2.7869 | Actual Loss: 0.6051\n",
      "Baseline Loss: 2.7994 | Actual Loss: 0.8844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 43/1000 [00:20<07:08,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8606 | Actual Loss: 1.0781\n",
      "Baseline Loss: 2.7958 | Actual Loss: 0.3143\n",
      "Baseline Loss: 2.7946 | Actual Loss: 0.4403\n",
      "Baseline Loss: 2.9014 | Actual Loss: 1.0572\n",
      "Baseline Loss: 2.9589 | Actual Loss: 0.7388\n",
      "Baseline Loss: 2.8349 | Actual Loss: 0.8032\n",
      "Baseline Loss: 2.8335 | Actual Loss: 0.5509\n",
      "Baseline Loss: 2.4539 | Actual Loss: 0.2422\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.0599\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.7653\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.9431\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.7506\n",
      "Epoch 43/1000: Train Loss: 0.7852, Val Loss: 0.8797\n",
      "Baseline Loss: 2.8630 | Actual Loss: 0.5120\n",
      "Baseline Loss: 2.7809 | Actual Loss: 0.6844\n",
      "Baseline Loss: 2.8176 | Actual Loss: 0.5955\n",
      "Baseline Loss: 2.7879 | Actual Loss: 1.2538\n",
      "Baseline Loss: 2.7952 | Actual Loss: 1.2566\n",
      "Baseline Loss: 2.8229 | Actual Loss: 0.7603\n",
      "Baseline Loss: 2.8256 | Actual Loss: 0.5229\n",
      "Baseline Loss: 2.7759 | Actual Loss: 1.2982\n",
      "Baseline Loss: 2.8298 | Actual Loss: 0.6668\n",
      "Baseline Loss: 2.8425 | Actual Loss: 0.4147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 44/1000 [00:20<07:22,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8409 | Actual Loss: 0.6264\n",
      "Baseline Loss: 2.8324 | Actual Loss: 0.5499\n",
      "Baseline Loss: 2.8923 | Actual Loss: 0.4468\n",
      "Baseline Loss: 2.8621 | Actual Loss: 1.0009\n",
      "Baseline Loss: 2.8678 | Actual Loss: 0.9665\n",
      "Baseline Loss: 2.5253 | Actual Loss: 0.3589\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.2105\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.5447\n",
      "Baseline Loss: 2.8293 | Actual Loss: 1.0953\n",
      "Baseline Loss: 2.7468 | Actual Loss: 1.0031\n",
      "Epoch 44/1000: Train Loss: 0.7447, Val Loss: 0.9634\n",
      "Baseline Loss: 2.8103 | Actual Loss: 0.9166\n",
      "Baseline Loss: 2.8787 | Actual Loss: 0.4802\n",
      "Baseline Loss: 2.8965 | Actual Loss: 1.1571\n",
      "Baseline Loss: 2.7872 | Actual Loss: 0.4148\n",
      "Baseline Loss: 2.8644 | Actual Loss: 0.4366\n",
      "Baseline Loss: 2.8382 | Actual Loss: 1.7287\n",
      "Baseline Loss: 2.8687 | Actual Loss: 0.2825\n",
      "Baseline Loss: 2.8526 | Actual Loss: 0.5084\n",
      "Baseline Loss: 2.7740 | Actual Loss: 0.8798\n",
      "Baseline Loss: 2.8261 | Actual Loss: 2.8073\n",
      "Baseline Loss: 2.8854 | Actual Loss: 0.2708\n",
      "Baseline Loss: 2.7829 | Actual Loss: 0.8970\n",
      "Baseline Loss: 2.8784 | Actual Loss: 0.8830\n",
      "Baseline Loss: 2.7961 | Actual Loss: 0.5817\n",
      "Baseline Loss: 2.7492 | Actual Loss: 0.3067\n",
      "Baseline Loss: 2.6188 | Actual Loss: 2.3946\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.1059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 45/1000 [00:21<07:36,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7565 | Actual Loss: 0.7365\n",
      "Baseline Loss: 2.8293 | Actual Loss: 1.0284\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.6598\n",
      "Epoch 45/1000: Train Loss: 0.9341, Val Loss: 0.8827\n",
      "Baseline Loss: 2.8075 | Actual Loss: 1.0632\n",
      "Baseline Loss: 2.8765 | Actual Loss: 0.6870\n",
      "Baseline Loss: 2.7780 | Actual Loss: 0.7699\n",
      "Baseline Loss: 2.7728 | Actual Loss: 1.1695\n",
      "Baseline Loss: 2.8818 | Actual Loss: 0.6977\n",
      "Baseline Loss: 2.8021 | Actual Loss: 2.0491\n",
      "Baseline Loss: 2.9017 | Actual Loss: 0.6847\n",
      "Baseline Loss: 2.8490 | Actual Loss: 2.2995\n",
      "Baseline Loss: 2.8312 | Actual Loss: 0.7571\n",
      "Baseline Loss: 2.7918 | Actual Loss: 0.3810\n",
      "Baseline Loss: 2.8584 | Actual Loss: 0.3824\n",
      "Baseline Loss: 2.8509 | Actual Loss: 0.7594\n",
      "Baseline Loss: 2.8182 | Actual Loss: 2.4174\n",
      "Baseline Loss: 2.8440 | Actual Loss: 0.5206\n",
      "Baseline Loss: 2.8716 | Actual Loss: 0.3869\n",
      "Baseline Loss: 2.6236 | Actual Loss: 0.4541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 46/1000 [00:21<07:27,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8280 | Actual Loss: 0.8349\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.5188\n",
      "Baseline Loss: 2.8293 | Actual Loss: 1.1387\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.5037\n",
      "Epoch 46/1000: Train Loss: 0.9675, Val Loss: 0.7490\n",
      "New best validation loss: 0.7490\n",
      "Baseline Loss: 2.8264 | Actual Loss: 1.0583\n",
      "Baseline Loss: 2.7958 | Actual Loss: 0.3068\n",
      "Baseline Loss: 2.7956 | Actual Loss: 0.8470\n",
      "Baseline Loss: 2.8667 | Actual Loss: 1.0009\n",
      "Baseline Loss: 2.8545 | Actual Loss: 0.5770\n",
      "Baseline Loss: 2.8302 | Actual Loss: 0.2177\n",
      "Baseline Loss: 2.8227 | Actual Loss: 0.3085\n",
      "Baseline Loss: 2.7885 | Actual Loss: 0.6585\n",
      "Baseline Loss: 2.8134 | Actual Loss: 0.6874\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.8005\n",
      "Baseline Loss: 2.8323 | Actual Loss: 0.8145\n",
      "Baseline Loss: 2.8513 | Actual Loss: 0.6777\n",
      "Baseline Loss: 2.8439 | Actual Loss: 0.5299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 47/1000 [00:22<07:26,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8645 | Actual Loss: 0.9941\n",
      "Baseline Loss: 2.8117 | Actual Loss: 0.3755\n",
      "Baseline Loss: 2.6691 | Actual Loss: 0.1875\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.8152\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.6764\n",
      "Baseline Loss: 2.8293 | Actual Loss: 1.1318\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.4875\n",
      "Epoch 47/1000: Train Loss: 0.6276, Val Loss: 0.7777\n",
      "Baseline Loss: 2.7984 | Actual Loss: 0.4201\n",
      "Baseline Loss: 2.8255 | Actual Loss: 1.3038\n",
      "Baseline Loss: 2.7811 | Actual Loss: 0.5654\n",
      "Baseline Loss: 2.8340 | Actual Loss: 1.1182\n",
      "Baseline Loss: 2.8001 | Actual Loss: 0.7535\n",
      "Baseline Loss: 2.8611 | Actual Loss: 0.5749\n",
      "Baseline Loss: 2.7875 | Actual Loss: 0.5247\n",
      "Baseline Loss: 2.8373 | Actual Loss: 0.9098\n",
      "Baseline Loss: 2.8531 | Actual Loss: 0.5950\n",
      "Baseline Loss: 2.7920 | Actual Loss: 0.9770\n",
      "Baseline Loss: 2.8629 | Actual Loss: 0.7358\n",
      "Baseline Loss: 2.8585 | Actual Loss: 0.5352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 48/1000 [00:22<07:34,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8263 | Actual Loss: 0.3555\n",
      "Baseline Loss: 2.8146 | Actual Loss: 2.3541\n",
      "Baseline Loss: 2.8376 | Actual Loss: 0.5362\n",
      "Baseline Loss: 2.6117 | Actual Loss: 0.2735\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.2758\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.5658\n",
      "Baseline Loss: 2.8293 | Actual Loss: 1.0405\n",
      "Baseline Loss: 2.7468 | Actual Loss: 1.1047\n",
      "Epoch 48/1000: Train Loss: 0.7833, Val Loss: 0.9967\n",
      "Baseline Loss: 2.7876 | Actual Loss: 0.5493\n",
      "Baseline Loss: 2.8081 | Actual Loss: 1.6445\n",
      "Baseline Loss: 2.8108 | Actual Loss: 1.8356\n",
      "Baseline Loss: 2.8747 | Actual Loss: 0.5076\n",
      "Baseline Loss: 2.7297 | Actual Loss: 0.5653\n",
      "Baseline Loss: 2.8790 | Actual Loss: 0.3691\n",
      "Baseline Loss: 2.8355 | Actual Loss: 0.4829\n",
      "Baseline Loss: 2.8570 | Actual Loss: 0.5031\n",
      "Baseline Loss: 2.8730 | Actual Loss: 0.5930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 49/1000 [00:23<07:23,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8764 | Actual Loss: 1.0692\n",
      "Baseline Loss: 2.8084 | Actual Loss: 0.6520\n",
      "Baseline Loss: 2.7948 | Actual Loss: 0.3683\n",
      "Baseline Loss: 2.8807 | Actual Loss: 0.1986\n",
      "Baseline Loss: 2.8218 | Actual Loss: 0.5389\n",
      "Baseline Loss: 2.8090 | Actual Loss: 0.7562\n",
      "Baseline Loss: 2.5436 | Actual Loss: 0.3793\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.0631\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.5398\n",
      "Baseline Loss: 2.8293 | Actual Loss: 1.2064\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.5605\n",
      "Epoch 49/1000: Train Loss: 0.6883, Val Loss: 0.8425\n",
      "Baseline Loss: 2.7777 | Actual Loss: 0.4584\n",
      "Baseline Loss: 2.8513 | Actual Loss: 0.6325\n",
      "Baseline Loss: 2.8831 | Actual Loss: 0.4726\n",
      "Baseline Loss: 2.8766 | Actual Loss: 0.4275\n",
      "Baseline Loss: 2.8509 | Actual Loss: 1.0096\n",
      "Baseline Loss: 2.9001 | Actual Loss: 0.5524\n",
      "Baseline Loss: 2.7807 | Actual Loss: 0.3636\n",
      "Baseline Loss: 2.7758 | Actual Loss: 1.2918\n",
      "Baseline Loss: 2.8087 | Actual Loss: 0.5674\n",
      "Baseline Loss: 2.8344 | Actual Loss: 0.5536\n",
      "Baseline Loss: 2.7637 | Actual Loss: 0.9243\n",
      "Baseline Loss: 2.7519 | Actual Loss: 0.8116\n",
      "Baseline Loss: 2.7834 | Actual Loss: 0.3226\n",
      "Baseline Loss: 2.8443 | Actual Loss: 1.4137\n",
      "Baseline Loss: 2.9163 | Actual Loss: 0.8861\n",
      "Baseline Loss: 2.6495 | Actual Loss: 0.5613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 50/1000 [00:23<07:34,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8280 | Actual Loss: 0.9241\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.5589\n",
      "Baseline Loss: 2.8293 | Actual Loss: 1.1643\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.5025\n",
      "Epoch 50/1000: Train Loss: 0.7031, Val Loss: 0.7874\n",
      "Baseline Loss: 2.8140 | Actual Loss: 1.3308\n",
      "Baseline Loss: 2.8779 | Actual Loss: 0.5809\n",
      "Baseline Loss: 2.8052 | Actual Loss: 0.6806\n",
      "Baseline Loss: 2.7801 | Actual Loss: 0.5861\n",
      "Baseline Loss: 2.7551 | Actual Loss: 1.1097\n",
      "Baseline Loss: 2.9095 | Actual Loss: 0.4765\n",
      "Baseline Loss: 2.8850 | Actual Loss: 0.5961\n",
      "Baseline Loss: 2.7862 | Actual Loss: 0.5641\n",
      "Baseline Loss: 2.8325 | Actual Loss: 0.5712\n",
      "Baseline Loss: 2.7848 | Actual Loss: 1.3178\n",
      "Baseline Loss: 2.8507 | Actual Loss: 0.6648\n",
      "Baseline Loss: 2.8318 | Actual Loss: 0.3857\n",
      "Baseline Loss: 2.8262 | Actual Loss: 0.3674\n",
      "Baseline Loss: 2.7774 | Actual Loss: 0.3893\n",
      "Baseline Loss: 2.9906 | Actual Loss: 1.0050\n",
      "Baseline Loss: 2.7484 | Actual Loss: 1.6744\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.8897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 51/1000 [00:23<07:10,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7565 | Actual Loss: 0.5030\n",
      "Baseline Loss: 2.8293 | Actual Loss: 1.0963\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.4919\n",
      "Epoch 51/1000: Train Loss: 0.7688, Val Loss: 0.7452\n",
      "New best validation loss: 0.7452\n",
      "Baseline Loss: 2.8232 | Actual Loss: 0.5383\n",
      "Baseline Loss: 2.8779 | Actual Loss: 0.4184\n",
      "Baseline Loss: 2.8429 | Actual Loss: 0.5217\n",
      "Baseline Loss: 2.8533 | Actual Loss: 0.4581\n",
      "Baseline Loss: 2.8103 | Actual Loss: 0.5737\n",
      "Baseline Loss: 2.8261 | Actual Loss: 0.5275\n",
      "Baseline Loss: 2.8616 | Actual Loss: 0.5821\n",
      "Baseline Loss: 2.8255 | Actual Loss: 0.6831\n",
      "Baseline Loss: 2.8641 | Actual Loss: 0.7991\n",
      "Baseline Loss: 2.7919 | Actual Loss: 0.3540\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4941\n",
      "Baseline Loss: 2.8444 | Actual Loss: 1.9788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 52/1000 [00:24<07:29,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7784 | Actual Loss: 0.3467\n",
      "Baseline Loss: 2.8381 | Actual Loss: 0.7664\n",
      "Baseline Loss: 2.8211 | Actual Loss: 0.4473\n",
      "Baseline Loss: 2.6140 | Actual Loss: 1.1016\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.9925\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.5535\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.9748\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.4775\n",
      "Epoch 52/1000: Train Loss: 0.6619, Val Loss: 0.7495\n",
      "Baseline Loss: 2.7900 | Actual Loss: 1.0190\n",
      "Baseline Loss: 2.7843 | Actual Loss: 0.8618\n",
      "Baseline Loss: 2.8973 | Actual Loss: 0.6583\n",
      "Baseline Loss: 2.8181 | Actual Loss: 0.7365\n",
      "Baseline Loss: 2.8217 | Actual Loss: 0.2985\n",
      "Baseline Loss: 2.8809 | Actual Loss: 0.4647\n",
      "Baseline Loss: 2.9020 | Actual Loss: 0.3605\n",
      "Baseline Loss: 2.8349 | Actual Loss: 0.5541\n",
      "Baseline Loss: 2.8501 | Actual Loss: 1.1090\n",
      "Baseline Loss: 2.8127 | Actual Loss: 0.3690\n",
      "Baseline Loss: 2.7596 | Actual Loss: 0.5126\n",
      "Baseline Loss: 2.8609 | Actual Loss: 0.3557\n",
      "Baseline Loss: 2.7710 | Actual Loss: 0.3195\n",
      "Baseline Loss: 2.8843 | Actual Loss: 1.4630\n",
      "Baseline Loss: 2.7722 | Actual Loss: 0.8985\n",
      "Baseline Loss: 2.5274 | Actual Loss: 0.1938\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.0348\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.5614\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.6840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 53/1000 [00:24<07:34,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7468 | Actual Loss: 0.6078\n",
      "Epoch 53/1000: Train Loss: 0.6359, Val Loss: 0.7220\n",
      "New best validation loss: 0.7220\n",
      "Baseline Loss: 2.8016 | Actual Loss: 0.4320\n",
      "Baseline Loss: 2.8801 | Actual Loss: 0.6724\n",
      "Baseline Loss: 2.8510 | Actual Loss: 0.7764\n",
      "Baseline Loss: 2.8307 | Actual Loss: 1.5016\n",
      "Baseline Loss: 2.8720 | Actual Loss: 0.6512\n",
      "Baseline Loss: 2.8509 | Actual Loss: 0.4492\n",
      "Baseline Loss: 2.7875 | Actual Loss: 0.5917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 54/1000 [00:25<07:09,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8212 | Actual Loss: 1.0587\n",
      "Baseline Loss: 2.8122 | Actual Loss: 0.6994\n",
      "Baseline Loss: 2.8491 | Actual Loss: 0.4975\n",
      "Baseline Loss: 2.7806 | Actual Loss: 0.7065\n",
      "Baseline Loss: 2.7943 | Actual Loss: 0.3717\n",
      "Baseline Loss: 2.8142 | Actual Loss: 0.9373\n",
      "Baseline Loss: 2.8200 | Actual Loss: 0.7411\n",
      "Baseline Loss: 2.7692 | Actual Loss: 0.5539\n",
      "Baseline Loss: 2.4651 | Actual Loss: 0.3497\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.7549\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.6181\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.8821\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.5611\n",
      "Epoch 54/1000: Train Loss: 0.6869, Val Loss: 0.7041\n",
      "New best validation loss: 0.7041\n",
      "Baseline Loss: 2.8773 | Actual Loss: 0.4979\n",
      "Baseline Loss: 2.9569 | Actual Loss: 0.4950\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.5313\n",
      "Baseline Loss: 2.8540 | Actual Loss: 1.4696\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.9524\n",
      "Baseline Loss: 2.7921 | Actual Loss: 1.3599\n",
      "Baseline Loss: 2.8165 | Actual Loss: 0.8438\n",
      "Baseline Loss: 2.8450 | Actual Loss: 0.6010\n",
      "Baseline Loss: 2.7966 | Actual Loss: 0.5519\n",
      "Baseline Loss: 2.9327 | Actual Loss: 0.7317\n",
      "Baseline Loss: 2.8571 | Actual Loss: 0.6062\n",
      "Baseline Loss: 2.8651 | Actual Loss: 0.5326\n",
      "Baseline Loss: 2.8292 | Actual Loss: 0.4601\n",
      "Baseline Loss: 2.8171 | Actual Loss: 0.7641\n",
      "Baseline Loss: 2.7828 | Actual Loss: 0.5543\n",
      "Baseline Loss: 2.5613 | Actual Loss: 0.3739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 55/1000 [00:25<07:28,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8280 | Actual Loss: 0.9578\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.5349\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.7912\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.8172\n",
      "Epoch 55/1000: Train Loss: 0.7078, Val Loss: 0.7753\n",
      "Baseline Loss: 2.8325 | Actual Loss: 0.5205\n",
      "Baseline Loss: 2.8548 | Actual Loss: 0.5471\n",
      "Baseline Loss: 2.7908 | Actual Loss: 0.5649\n",
      "Baseline Loss: 2.8952 | Actual Loss: 0.3891\n",
      "Baseline Loss: 2.7528 | Actual Loss: 2.5449\n",
      "Baseline Loss: 2.8451 | Actual Loss: 0.9125\n",
      "Baseline Loss: 2.8404 | Actual Loss: 1.6535\n",
      "Baseline Loss: 2.8494 | Actual Loss: 1.3001\n",
      "Baseline Loss: 2.8476 | Actual Loss: 2.1999\n",
      "Baseline Loss: 2.8163 | Actual Loss: 0.4554\n",
      "Baseline Loss: 2.8240 | Actual Loss: 0.6012\n",
      "Baseline Loss: 2.8604 | Actual Loss: 1.8224\n",
      "Baseline Loss: 2.8966 | Actual Loss: 0.7640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 56/1000 [00:26<07:38,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7625 | Actual Loss: 0.3674\n",
      "Baseline Loss: 2.7741 | Actual Loss: 0.5016\n",
      "Baseline Loss: 2.4589 | Actual Loss: 0.6395\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.9712\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.6298\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.8029\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.6308\n",
      "Epoch 56/1000: Train Loss: 0.9865, Val Loss: 0.7587\n",
      "Baseline Loss: 2.8563 | Actual Loss: 0.7154\n",
      "Baseline Loss: 2.8376 | Actual Loss: 0.5825\n",
      "Baseline Loss: 2.8150 | Actual Loss: 0.5869\n",
      "Baseline Loss: 2.8458 | Actual Loss: 0.7637\n",
      "Baseline Loss: 2.7706 | Actual Loss: 0.5475\n",
      "Baseline Loss: 2.8524 | Actual Loss: 0.9992\n",
      "Baseline Loss: 2.7892 | Actual Loss: 0.8495\n",
      "Baseline Loss: 2.8071 | Actual Loss: 0.8036\n",
      "Baseline Loss: 2.8825 | Actual Loss: 0.4143\n",
      "Baseline Loss: 2.7960 | Actual Loss: 0.7703\n",
      "Baseline Loss: 2.8168 | Actual Loss: 0.2405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 57/1000 [00:26<07:15,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8342 | Actual Loss: 0.4774\n",
      "Baseline Loss: 2.8236 | Actual Loss: 1.3036\n",
      "Baseline Loss: 2.7949 | Actual Loss: 0.1750\n",
      "Baseline Loss: 2.8762 | Actual Loss: 0.5151\n",
      "Baseline Loss: 2.5680 | Actual Loss: 0.3982\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.6751\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.3836\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.6587\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.5051\n",
      "Epoch 57/1000: Train Loss: 0.6339, Val Loss: 0.5556\n",
      "New best validation loss: 0.5556\n",
      "Baseline Loss: 2.8500 | Actual Loss: 0.9981\n",
      "Baseline Loss: 2.8125 | Actual Loss: 0.3346\n",
      "Baseline Loss: 2.8150 | Actual Loss: 0.5138\n",
      "Baseline Loss: 2.7770 | Actual Loss: 0.4486\n",
      "Baseline Loss: 2.8437 | Actual Loss: 0.3364\n",
      "Baseline Loss: 2.8993 | Actual Loss: 1.1590\n",
      "Baseline Loss: 2.7842 | Actual Loss: 0.4237\n",
      "Baseline Loss: 2.8210 | Actual Loss: 0.7054\n",
      "Baseline Loss: 2.8428 | Actual Loss: 1.3758\n",
      "Baseline Loss: 2.8567 | Actual Loss: 0.3454\n",
      "Baseline Loss: 2.7846 | Actual Loss: 0.8508\n",
      "Baseline Loss: 2.8645 | Actual Loss: 1.1279\n",
      "Baseline Loss: 2.8154 | Actual Loss: 0.3106\n",
      "Baseline Loss: 2.7734 | Actual Loss: 0.5291\n",
      "Baseline Loss: 2.8170 | Actual Loss: 1.8227\n",
      "Baseline Loss: 2.7157 | Actual Loss: 0.4385\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.7304\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.6933\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.7989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 58/1000 [00:27<07:28,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7468 | Actual Loss: 0.5702\n",
      "Epoch 58/1000: Train Loss: 0.7325, Val Loss: 0.6982\n",
      "Baseline Loss: 2.8191 | Actual Loss: 0.4693\n",
      "Baseline Loss: 2.8621 | Actual Loss: 0.4316\n",
      "Baseline Loss: 2.8888 | Actual Loss: 0.5851\n",
      "Baseline Loss: 2.8270 | Actual Loss: 0.6816\n",
      "Baseline Loss: 2.8805 | Actual Loss: 0.5876\n",
      "Baseline Loss: 2.8263 | Actual Loss: 0.4439\n",
      "Baseline Loss: 2.8209 | Actual Loss: 0.5721\n",
      "Baseline Loss: 2.7812 | Actual Loss: 2.3902\n",
      "Baseline Loss: 2.8242 | Actual Loss: 0.6000\n",
      "Baseline Loss: 2.7226 | Actual Loss: 2.5165\n",
      "Baseline Loss: 2.8208 | Actual Loss: 2.2936\n",
      "Baseline Loss: 2.8995 | Actual Loss: 1.0914\n",
      "Baseline Loss: 2.8289 | Actual Loss: 0.5689\n",
      "Baseline Loss: 2.7863 | Actual Loss: 0.1897\n",
      "Baseline Loss: 2.8535 | Actual Loss: 0.5933\n",
      "Baseline Loss: 2.5250 | Actual Loss: 0.2147\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.9467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 59/1000 [00:27<07:24,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7565 | Actual Loss: 0.6723\n",
      "Baseline Loss: 2.8293 | Actual Loss: 1.0516\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.5408\n",
      "Epoch 59/1000: Train Loss: 0.8893, Val Loss: 0.8029\n",
      "Baseline Loss: 2.8045 | Actual Loss: 0.6694\n",
      "Baseline Loss: 2.8325 | Actual Loss: 0.5569\n",
      "Baseline Loss: 2.8271 | Actual Loss: 1.5219\n",
      "Baseline Loss: 2.7772 | Actual Loss: 0.4189\n",
      "Baseline Loss: 2.8319 | Actual Loss: 0.4850\n",
      "Baseline Loss: 2.8768 | Actual Loss: 0.6759\n",
      "Baseline Loss: 2.8026 | Actual Loss: 0.7413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 60/1000 [00:28<06:59,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9027 | Actual Loss: 0.5519\n",
      "Baseline Loss: 2.8989 | Actual Loss: 0.4148\n",
      "Baseline Loss: 2.7915 | Actual Loss: 0.6162\n",
      "Baseline Loss: 2.8461 | Actual Loss: 0.5899\n",
      "Baseline Loss: 2.8415 | Actual Loss: 0.5742\n",
      "Baseline Loss: 2.8257 | Actual Loss: 0.7352\n",
      "Baseline Loss: 2.7859 | Actual Loss: 0.4468\n",
      "Baseline Loss: 2.8330 | Actual Loss: 0.6527\n",
      "Baseline Loss: 2.5589 | Actual Loss: 0.1994\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.9350\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.4763\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.6874\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.4232\n",
      "Epoch 60/1000: Train Loss: 0.6156, Val Loss: 0.6305\n",
      "Baseline Loss: 2.8629 | Actual Loss: 0.5255\n",
      "Baseline Loss: 2.8136 | Actual Loss: 0.2641\n",
      "Baseline Loss: 2.8405 | Actual Loss: 0.8396\n",
      "Baseline Loss: 2.8044 | Actual Loss: 0.4128\n",
      "Baseline Loss: 2.9082 | Actual Loss: 0.5009\n",
      "Baseline Loss: 2.7927 | Actual Loss: 1.2800\n",
      "Baseline Loss: 2.8874 | Actual Loss: 0.4282\n",
      "Baseline Loss: 2.7569 | Actual Loss: 1.5476\n",
      "Baseline Loss: 2.8226 | Actual Loss: 0.5858\n",
      "Baseline Loss: 2.8001 | Actual Loss: 0.8856\n",
      "Baseline Loss: 2.7953 | Actual Loss: 1.7074\n",
      "Baseline Loss: 2.8496 | Actual Loss: 0.3934\n",
      "Baseline Loss: 2.8308 | Actual Loss: 0.2664\n",
      "Baseline Loss: 2.8386 | Actual Loss: 1.2597\n",
      "Baseline Loss: 2.8558 | Actual Loss: 1.0454\n",
      "Baseline Loss: 2.5055 | Actual Loss: 0.2314\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.8541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 61/1000 [00:28<07:17,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7565 | Actual Loss: 0.6746\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.8194\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.5829\n",
      "Epoch 61/1000: Train Loss: 0.7609, Val Loss: 0.7327\n",
      "Baseline Loss: 2.7706 | Actual Loss: 0.4573\n",
      "Baseline Loss: 2.7575 | Actual Loss: 0.6693\n",
      "Baseline Loss: 2.7934 | Actual Loss: 0.7580\n",
      "Baseline Loss: 2.8441 | Actual Loss: 0.5962\n",
      "Baseline Loss: 2.9351 | Actual Loss: 0.6940\n",
      "Baseline Loss: 2.8177 | Actual Loss: 0.2225\n",
      "Baseline Loss: 2.8764 | Actual Loss: 0.6583\n",
      "Baseline Loss: 2.8438 | Actual Loss: 0.9756\n",
      "Baseline Loss: 2.8524 | Actual Loss: 0.2008\n",
      "Baseline Loss: 2.8351 | Actual Loss: 0.3055\n",
      "Baseline Loss: 2.8206 | Actual Loss: 0.7154\n",
      "Baseline Loss: 2.7843 | Actual Loss: 0.8333\n",
      "Baseline Loss: 2.8382 | Actual Loss: 0.7234\n",
      "Baseline Loss: 2.7554 | Actual Loss: 0.6575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 62/1000 [00:29<07:28,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8858 | Actual Loss: 0.4832\n",
      "Baseline Loss: 2.7216 | Actual Loss: 2.7008\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.6843\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.5718\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.7843\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.6098\n",
      "Epoch 62/1000: Train Loss: 0.7282, Val Loss: 0.6625\n",
      "Baseline Loss: 2.7935 | Actual Loss: 0.6021\n",
      "Baseline Loss: 2.8060 | Actual Loss: 0.9995\n",
      "Baseline Loss: 2.8300 | Actual Loss: 0.3213\n",
      "Baseline Loss: 2.9109 | Actual Loss: 0.4161\n",
      "Baseline Loss: 2.7477 | Actual Loss: 0.4541\n",
      "Baseline Loss: 2.7944 | Actual Loss: 0.4367\n",
      "Baseline Loss: 2.7620 | Actual Loss: 2.7683\n",
      "Baseline Loss: 2.7916 | Actual Loss: 0.7401\n",
      "Baseline Loss: 2.9148 | Actual Loss: 0.3585\n",
      "Baseline Loss: 2.8670 | Actual Loss: 0.4756\n",
      "Baseline Loss: 2.8903 | Actual Loss: 1.0739\n",
      "Baseline Loss: 2.8451 | Actual Loss: 0.3146\n",
      "Baseline Loss: 2.8262 | Actual Loss: 0.3624\n",
      "Baseline Loss: 2.8026 | Actual Loss: 1.9061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 63/1000 [00:29<07:12,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7824 | Actual Loss: 0.5970\n",
      "Baseline Loss: 2.5532 | Actual Loss: 0.9101\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.6178\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.4454\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.7926\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.7509\n",
      "Epoch 63/1000: Train Loss: 0.7960, Val Loss: 0.6517\n",
      "Baseline Loss: 2.7824 | Actual Loss: 0.4352\n",
      "Baseline Loss: 2.9282 | Actual Loss: 1.2915\n",
      "Baseline Loss: 2.7788 | Actual Loss: 1.9015\n",
      "Baseline Loss: 2.8311 | Actual Loss: 0.5897\n",
      "Baseline Loss: 2.7727 | Actual Loss: 1.1049\n",
      "Baseline Loss: 2.9226 | Actual Loss: 0.4654\n",
      "Baseline Loss: 2.8485 | Actual Loss: 0.7206\n",
      "Baseline Loss: 2.7795 | Actual Loss: 0.2704\n",
      "Baseline Loss: 2.8320 | Actual Loss: 0.5164\n",
      "Baseline Loss: 2.8421 | Actual Loss: 0.4790\n",
      "Baseline Loss: 2.8734 | Actual Loss: 0.5850\n",
      "Baseline Loss: 2.8516 | Actual Loss: 0.4980\n",
      "Baseline Loss: 2.7949 | Actual Loss: 0.5571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 64/1000 [00:30<07:17,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8312 | Actual Loss: 0.4001\n",
      "Baseline Loss: 2.7889 | Actual Loss: 0.5573\n",
      "Baseline Loss: 2.4606 | Actual Loss: 0.4276\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.7062\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.4431\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.7257\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.3570\n",
      "Epoch 64/1000: Train Loss: 0.6750, Val Loss: 0.5580\n",
      "Baseline Loss: 2.8010 | Actual Loss: 0.5312\n",
      "Baseline Loss: 2.8931 | Actual Loss: 1.7565\n",
      "Baseline Loss: 2.8721 | Actual Loss: 0.3173\n",
      "Baseline Loss: 2.7682 | Actual Loss: 2.8047\n",
      "Baseline Loss: 2.7932 | Actual Loss: 0.9211\n",
      "Baseline Loss: 2.9001 | Actual Loss: 0.8197\n",
      "Baseline Loss: 2.8910 | Actual Loss: 0.8636\n",
      "Baseline Loss: 2.9291 | Actual Loss: 0.4743\n",
      "Baseline Loss: 2.8380 | Actual Loss: 1.4387\n",
      "Baseline Loss: 2.8286 | Actual Loss: 0.3346\n",
      "Baseline Loss: 2.7888 | Actual Loss: 0.7356\n",
      "Baseline Loss: 2.8267 | Actual Loss: 0.3229\n",
      "Baseline Loss: 2.8210 | Actual Loss: 0.2255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 65/1000 [00:30<07:21,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7900 | Actual Loss: 0.3168\n",
      "Baseline Loss: 2.8015 | Actual Loss: 0.4966\n",
      "Baseline Loss: 2.5239 | Actual Loss: 0.6940\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.5976\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.4029\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.8984\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.7355\n",
      "Epoch 65/1000: Train Loss: 0.8158, Val Loss: 0.6586\n",
      "Baseline Loss: 2.8330 | Actual Loss: 1.6210\n",
      "Baseline Loss: 2.9080 | Actual Loss: 0.7335\n",
      "Baseline Loss: 2.8109 | Actual Loss: 0.5170\n",
      "Baseline Loss: 2.8435 | Actual Loss: 1.1656\n",
      "Baseline Loss: 2.8885 | Actual Loss: 0.6239\n",
      "Baseline Loss: 2.8318 | Actual Loss: 0.4467\n",
      "Baseline Loss: 2.7776 | Actual Loss: 0.0966\n",
      "Baseline Loss: 2.8534 | Actual Loss: 1.1437\n",
      "Baseline Loss: 2.8015 | Actual Loss: 0.4364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 66/1000 [00:30<07:10,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7936 | Actual Loss: 0.4349\n",
      "Baseline Loss: 2.9205 | Actual Loss: 0.5141\n",
      "Baseline Loss: 2.8495 | Actual Loss: 0.6396\n",
      "Baseline Loss: 2.8078 | Actual Loss: 0.4761\n",
      "Baseline Loss: 2.7788 | Actual Loss: 0.5405\n",
      "Baseline Loss: 2.8621 | Actual Loss: 0.7848\n",
      "Baseline Loss: 2.5389 | Actual Loss: 0.4234\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.7413\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.4936\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.8452\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.5946\n",
      "Epoch 66/1000: Train Loss: 0.6624, Val Loss: 0.6687\n",
      "Baseline Loss: 2.8077 | Actual Loss: 0.2735\n",
      "Baseline Loss: 2.8990 | Actual Loss: 0.4626\n",
      "Baseline Loss: 2.8410 | Actual Loss: 0.5282\n",
      "Baseline Loss: 2.9009 | Actual Loss: 0.4755\n",
      "Baseline Loss: 2.7844 | Actual Loss: 0.1561\n",
      "Baseline Loss: 2.8549 | Actual Loss: 0.9820\n",
      "Baseline Loss: 2.8484 | Actual Loss: 0.3985\n",
      "Baseline Loss: 2.8557 | Actual Loss: 0.4829\n",
      "Baseline Loss: 2.7877 | Actual Loss: 0.5188\n",
      "Baseline Loss: 2.8229 | Actual Loss: 0.8683\n",
      "Baseline Loss: 2.9473 | Actual Loss: 0.5394\n",
      "Baseline Loss: 2.7792 | Actual Loss: 0.8709\n",
      "Baseline Loss: 2.8190 | Actual Loss: 1.1644\n",
      "Baseline Loss: 2.8245 | Actual Loss: 0.5516\n",
      "Baseline Loss: 2.8236 | Actual Loss: 0.3917\n",
      "Baseline Loss: 2.5788 | Actual Loss: 0.0687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 67/1000 [00:31<07:19,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8280 | Actual Loss: 0.7214\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.5812\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.5963\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.5744\n",
      "Epoch 67/1000: Train Loss: 0.5458, Val Loss: 0.6183\n",
      "Baseline Loss: 2.8562 | Actual Loss: 0.3953\n",
      "Baseline Loss: 2.7790 | Actual Loss: 0.3882\n",
      "Baseline Loss: 2.7951 | Actual Loss: 0.4673\n",
      "Baseline Loss: 2.8426 | Actual Loss: 0.4052\n",
      "Baseline Loss: 2.9284 | Actual Loss: 0.8106\n",
      "Baseline Loss: 2.7806 | Actual Loss: 0.7396\n",
      "Baseline Loss: 2.7872 | Actual Loss: 1.0281\n",
      "Baseline Loss: 2.8169 | Actual Loss: 0.8768\n",
      "Baseline Loss: 2.8409 | Actual Loss: 0.4912\n",
      "Baseline Loss: 2.8448 | Actual Loss: 0.2347\n",
      "Baseline Loss: 2.8240 | Actual Loss: 0.5958\n",
      "Baseline Loss: 2.7829 | Actual Loss: 0.5610\n",
      "Baseline Loss: 2.7946 | Actual Loss: 0.2773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 68/1000 [00:31<07:35,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8598 | Actual Loss: 1.3211\n",
      "Baseline Loss: 2.8248 | Actual Loss: 0.6328\n",
      "Baseline Loss: 2.5279 | Actual Loss: 0.0795\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.0361\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.3902\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.8406\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.5343\n",
      "Epoch 68/1000: Train Loss: 0.5815, Val Loss: 0.7003\n",
      "Baseline Loss: 2.8449 | Actual Loss: 0.5292\n",
      "Baseline Loss: 2.7613 | Actual Loss: 0.5894\n",
      "Baseline Loss: 2.8299 | Actual Loss: 0.3625\n",
      "Baseline Loss: 2.7964 | Actual Loss: 0.2322\n",
      "Baseline Loss: 2.8206 | Actual Loss: 0.3244\n",
      "Baseline Loss: 2.8956 | Actual Loss: 0.6378\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.8151\n",
      "Baseline Loss: 2.8282 | Actual Loss: 0.1974\n",
      "Baseline Loss: 2.8099 | Actual Loss: 0.3147\n",
      "Baseline Loss: 2.8708 | Actual Loss: 0.4281\n",
      "Baseline Loss: 2.7936 | Actual Loss: 0.4217\n",
      "Baseline Loss: 2.8254 | Actual Loss: 0.5964\n",
      "Baseline Loss: 2.9416 | Actual Loss: 0.3243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 69/1000 [00:32<07:20,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8053 | Actual Loss: 0.5956\n",
      "Baseline Loss: 2.7864 | Actual Loss: 0.2551\n",
      "Baseline Loss: 2.5039 | Actual Loss: 0.1640\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.7892\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.4114\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.7386\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.4280\n",
      "Epoch 69/1000: Train Loss: 0.4242, Val Loss: 0.5918\n",
      "Baseline Loss: 2.7927 | Actual Loss: 2.1990\n",
      "Baseline Loss: 2.8580 | Actual Loss: 0.4710\n",
      "Baseline Loss: 2.8502 | Actual Loss: 0.5600\n",
      "Baseline Loss: 2.8508 | Actual Loss: 0.4505\n",
      "Baseline Loss: 2.9245 | Actual Loss: 2.9404\n",
      "Baseline Loss: 2.7636 | Actual Loss: 0.3084\n",
      "Baseline Loss: 2.8736 | Actual Loss: 0.2351\n",
      "Baseline Loss: 2.8530 | Actual Loss: 0.7661\n",
      "Baseline Loss: 2.8503 | Actual Loss: 0.4031\n",
      "Baseline Loss: 2.8134 | Actual Loss: 0.4982\n",
      "Baseline Loss: 2.8457 | Actual Loss: 0.2835\n",
      "Baseline Loss: 2.7578 | Actual Loss: 2.4255\n",
      "Baseline Loss: 2.8433 | Actual Loss: 0.6521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 70/1000 [00:32<07:32,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7732 | Actual Loss: 0.2810\n",
      "Baseline Loss: 2.7999 | Actual Loss: 0.2689\n",
      "Baseline Loss: 2.6351 | Actual Loss: 1.5881\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.7565\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.3779\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.7992\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.5863\n",
      "Epoch 70/1000: Train Loss: 0.8957, Val Loss: 0.6300\n",
      "Baseline Loss: 2.8295 | Actual Loss: 0.2481\n",
      "Baseline Loss: 2.7921 | Actual Loss: 0.5056\n",
      "Baseline Loss: 2.7750 | Actual Loss: 0.8529\n",
      "Baseline Loss: 2.8607 | Actual Loss: 0.8988\n",
      "Baseline Loss: 2.7899 | Actual Loss: 0.3941\n",
      "Baseline Loss: 2.8484 | Actual Loss: 0.4214\n",
      "Baseline Loss: 2.8680 | Actual Loss: 0.5269\n",
      "Baseline Loss: 2.9357 | Actual Loss: 0.2847\n",
      "Baseline Loss: 2.8624 | Actual Loss: 1.0616\n",
      "Baseline Loss: 2.8039 | Actual Loss: 0.6320\n",
      "Baseline Loss: 2.8021 | Actual Loss: 2.8345\n",
      "Baseline Loss: 2.8192 | Actual Loss: 0.2040\n",
      "Baseline Loss: 2.8257 | Actual Loss: 0.4604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 71/1000 [00:33<07:35,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8289 | Actual Loss: 0.4534\n",
      "Baseline Loss: 2.8484 | Actual Loss: 0.3447\n",
      "Baseline Loss: 2.4178 | Actual Loss: 0.1020\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.5426\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.4135\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.5831\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.5098\n",
      "Epoch 71/1000: Train Loss: 0.6391, Val Loss: 0.5123\n",
      "New best validation loss: 0.5123\n",
      "Baseline Loss: 2.7806 | Actual Loss: 0.8995\n",
      "Baseline Loss: 2.8191 | Actual Loss: 0.4238\n",
      "Baseline Loss: 2.7818 | Actual Loss: 0.4028\n",
      "Baseline Loss: 2.8135 | Actual Loss: 0.7787\n",
      "Baseline Loss: 2.8062 | Actual Loss: 0.2157\n",
      "Baseline Loss: 2.7940 | Actual Loss: 0.5223\n",
      "Baseline Loss: 2.8439 | Actual Loss: 1.3477\n",
      "Baseline Loss: 2.8691 | Actual Loss: 0.6328\n",
      "Baseline Loss: 2.8724 | Actual Loss: 1.0878\n",
      "Baseline Loss: 2.8649 | Actual Loss: 1.9288\n",
      "Baseline Loss: 2.8193 | Actual Loss: 0.2493\n",
      "Baseline Loss: 2.7954 | Actual Loss: 0.7794\n",
      "Baseline Loss: 2.8689 | Actual Loss: 0.3841\n",
      "Baseline Loss: 2.8286 | Actual Loss: 0.4095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 72/1000 [00:33<07:18,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8689 | Actual Loss: 0.4998\n",
      "Baseline Loss: 2.5192 | Actual Loss: 0.5181\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.8141\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.6191\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.7845\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.5704\n",
      "Epoch 72/1000: Train Loss: 0.6925, Val Loss: 0.6970\n",
      "Baseline Loss: 2.7976 | Actual Loss: 0.2482\n",
      "Baseline Loss: 2.8026 | Actual Loss: 0.6668\n",
      "Baseline Loss: 2.9449 | Actual Loss: 0.6339\n",
      "Baseline Loss: 2.8531 | Actual Loss: 0.2424\n",
      "Baseline Loss: 2.8074 | Actual Loss: 0.2801\n",
      "Baseline Loss: 2.9187 | Actual Loss: 0.2137\n",
      "Baseline Loss: 2.8262 | Actual Loss: 0.6758\n",
      "Baseline Loss: 2.8487 | Actual Loss: 3.0209\n",
      "Baseline Loss: 2.8039 | Actual Loss: 0.5328\n",
      "Baseline Loss: 2.8698 | Actual Loss: 0.5630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 73/1000 [00:34<07:31,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7279 | Actual Loss: 0.7263\n",
      "Baseline Loss: 2.7746 | Actual Loss: 0.3383\n",
      "Baseline Loss: 2.7875 | Actual Loss: 0.6973\n",
      "Baseline Loss: 2.7756 | Actual Loss: 0.5914\n",
      "Baseline Loss: 2.9625 | Actual Loss: 0.2802\n",
      "Baseline Loss: 2.4299 | Actual Loss: 0.2372\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.9859\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.3755\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.7990\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.9173\n",
      "Epoch 73/1000: Train Loss: 0.6218, Val Loss: 0.7694\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3033\n",
      "Baseline Loss: 2.8573 | Actual Loss: 2.5005\n",
      "Baseline Loss: 2.8004 | Actual Loss: 0.5116\n",
      "Baseline Loss: 2.8386 | Actual Loss: 0.1878\n",
      "Baseline Loss: 2.8606 | Actual Loss: 0.4745\n",
      "Baseline Loss: 2.8550 | Actual Loss: 0.6208\n",
      "Baseline Loss: 2.7990 | Actual Loss: 0.4310\n",
      "Baseline Loss: 2.8441 | Actual Loss: 0.4877\n",
      "Baseline Loss: 2.7604 | Actual Loss: 0.6686\n",
      "Baseline Loss: 2.8653 | Actual Loss: 0.4592\n",
      "Baseline Loss: 2.8475 | Actual Loss: 0.3266\n",
      "Baseline Loss: 2.8231 | Actual Loss: 0.3452\n",
      "Baseline Loss: 2.8503 | Actual Loss: 0.5876\n",
      "Baseline Loss: 2.8498 | Actual Loss: 0.5477\n",
      "Baseline Loss: 2.8552 | Actual Loss: 0.6836\n",
      "Baseline Loss: 2.4326 | Actual Loss: 0.4098\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.7845\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.4609\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.6260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 74/1000 [00:34<07:36,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7468 | Actual Loss: 0.5641\n",
      "Epoch 74/1000: Train Loss: 0.5966, Val Loss: 0.6088\n",
      "Baseline Loss: 2.8229 | Actual Loss: 1.2033\n",
      "Baseline Loss: 2.8118 | Actual Loss: 0.2068\n",
      "Baseline Loss: 2.8324 | Actual Loss: 0.4564\n",
      "Baseline Loss: 2.8049 | Actual Loss: 0.3956\n",
      "Baseline Loss: 2.7977 | Actual Loss: 0.6430\n",
      "Baseline Loss: 2.9426 | Actual Loss: 0.3744\n",
      "Baseline Loss: 2.8184 | Actual Loss: 1.0681\n",
      "Baseline Loss: 2.7898 | Actual Loss: 0.2131\n",
      "Baseline Loss: 2.8888 | Actual Loss: 0.4006\n",
      "Baseline Loss: 2.7729 | Actual Loss: 1.6689\n",
      "Baseline Loss: 2.8926 | Actual Loss: 0.6206\n",
      "Baseline Loss: 2.7897 | Actual Loss: 0.7188\n",
      "Baseline Loss: 2.7752 | Actual Loss: 0.4288\n",
      "Baseline Loss: 2.8057 | Actual Loss: 0.6901\n",
      "Baseline Loss: 2.8760 | Actual Loss: 0.5538\n",
      "Baseline Loss: 2.5223 | Actual Loss: 0.1616\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.7937\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.5775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 75/1000 [00:35<07:20,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8293 | Actual Loss: 0.7029\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.4717\n",
      "Epoch 75/1000: Train Loss: 0.6127, Val Loss: 0.6364\n",
      "Baseline Loss: 2.8249 | Actual Loss: 0.2318\n",
      "Baseline Loss: 2.7985 | Actual Loss: 0.1236\n",
      "Baseline Loss: 2.8040 | Actual Loss: 0.2842\n",
      "Baseline Loss: 2.8915 | Actual Loss: 2.2520\n",
      "Baseline Loss: 2.8376 | Actual Loss: 0.3580\n",
      "Baseline Loss: 2.8552 | Actual Loss: 2.7660\n",
      "Baseline Loss: 2.7753 | Actual Loss: 0.2790\n",
      "Baseline Loss: 2.8074 | Actual Loss: 1.9049\n",
      "Baseline Loss: 2.8495 | Actual Loss: 0.3932\n",
      "Baseline Loss: 2.8651 | Actual Loss: 0.8238\n",
      "Baseline Loss: 2.7662 | Actual Loss: 0.4716\n",
      "Baseline Loss: 2.7782 | Actual Loss: 0.9887\n",
      "Baseline Loss: 2.8549 | Actual Loss: 0.6051\n",
      "Baseline Loss: 2.8376 | Actual Loss: 0.8294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 76/1000 [00:35<07:30,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8399 | Actual Loss: 0.3597\n",
      "Baseline Loss: 2.5701 | Actual Loss: 2.1260\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.6595\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.4659\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.7249\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.3039\n",
      "Epoch 76/1000: Train Loss: 0.9248, Val Loss: 0.5386\n",
      "Baseline Loss: 2.7903 | Actual Loss: 0.3485\n",
      "Baseline Loss: 2.7467 | Actual Loss: 0.3902\n",
      "Baseline Loss: 2.7869 | Actual Loss: 0.6142\n",
      "Baseline Loss: 2.8300 | Actual Loss: 0.5015\n",
      "Baseline Loss: 2.8455 | Actual Loss: 0.3673\n",
      "Baseline Loss: 2.8122 | Actual Loss: 0.2003\n",
      "Baseline Loss: 2.8392 | Actual Loss: 0.5791\n",
      "Baseline Loss: 2.8678 | Actual Loss: 0.5092\n",
      "Baseline Loss: 2.8179 | Actual Loss: 0.3302\n",
      "Baseline Loss: 2.8455 | Actual Loss: 0.8032\n",
      "Baseline Loss: 2.8563 | Actual Loss: 1.2842\n",
      "Baseline Loss: 2.8730 | Actual Loss: 0.3311\n",
      "Baseline Loss: 2.8081 | Actual Loss: 0.2422\n",
      "Baseline Loss: 2.8618 | Actual Loss: 1.0204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 77/1000 [00:36<07:16,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8299 | Actual Loss: 1.2179\n",
      "Baseline Loss: 2.5294 | Actual Loss: 0.3009\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.7643\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.5168\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.6751\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.5071\n",
      "Epoch 77/1000: Train Loss: 0.5650, Val Loss: 0.6158\n",
      "Baseline Loss: 2.8136 | Actual Loss: 0.4165\n",
      "Baseline Loss: 2.7829 | Actual Loss: 0.1746\n",
      "Baseline Loss: 2.8238 | Actual Loss: 0.2932\n",
      "Baseline Loss: 2.8686 | Actual Loss: 0.6103\n",
      "Baseline Loss: 2.8687 | Actual Loss: 0.4287\n",
      "Baseline Loss: 2.8398 | Actual Loss: 2.5105\n",
      "Baseline Loss: 2.7932 | Actual Loss: 0.2911\n",
      "Baseline Loss: 2.8891 | Actual Loss: 0.6600\n",
      "Baseline Loss: 2.7840 | Actual Loss: 0.4487\n",
      "Baseline Loss: 2.7985 | Actual Loss: 0.5803\n",
      "Baseline Loss: 2.8867 | Actual Loss: 0.2530\n",
      "Baseline Loss: 2.8858 | Actual Loss: 0.3610\n",
      "Baseline Loss: 2.8422 | Actual Loss: 0.5530\n",
      "Baseline Loss: 2.7795 | Actual Loss: 0.6933\n",
      "Baseline Loss: 2.7713 | Actual Loss: 0.7073\n",
      "Baseline Loss: 2.5959 | Actual Loss: 0.5279\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.7342\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.5493\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.7601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 78/1000 [00:36<07:28,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7468 | Actual Loss: 0.4902\n",
      "Epoch 78/1000: Train Loss: 0.5943, Val Loss: 0.6335\n",
      "Baseline Loss: 2.8649 | Actual Loss: 0.3148\n",
      "Baseline Loss: 2.8306 | Actual Loss: 0.5058\n",
      "Baseline Loss: 2.8244 | Actual Loss: 1.0422\n",
      "Baseline Loss: 2.7721 | Actual Loss: 0.6675\n",
      "Baseline Loss: 2.8833 | Actual Loss: 0.4727\n",
      "Baseline Loss: 2.8914 | Actual Loss: 0.8229\n",
      "Baseline Loss: 2.8007 | Actual Loss: 0.2511\n",
      "Baseline Loss: 2.8118 | Actual Loss: 0.3275\n",
      "Baseline Loss: 2.7902 | Actual Loss: 0.1613\n",
      "Baseline Loss: 2.8369 | Actual Loss: 0.7743\n",
      "Baseline Loss: 2.7855 | Actual Loss: 0.5581\n",
      "Baseline Loss: 2.8244 | Actual Loss: 0.5457\n",
      "Baseline Loss: 2.8053 | Actual Loss: 0.6198\n",
      "Baseline Loss: 2.8282 | Actual Loss: 0.5946\n",
      "Baseline Loss: 2.8487 | Actual Loss: 0.5085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 79/1000 [00:37<07:34,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7011 | Actual Loss: 0.1361\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.7907\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.5904\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.7118\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.4488\n",
      "Epoch 79/1000: Train Loss: 0.5189, Val Loss: 0.6354\n",
      "Baseline Loss: 2.8546 | Actual Loss: 0.5398\n",
      "Baseline Loss: 2.8256 | Actual Loss: 0.3580\n",
      "Baseline Loss: 2.8727 | Actual Loss: 1.2370\n",
      "Baseline Loss: 2.8493 | Actual Loss: 0.2318\n",
      "Baseline Loss: 2.8407 | Actual Loss: 0.5569\n",
      "Baseline Loss: 2.8497 | Actual Loss: 1.4229\n",
      "Baseline Loss: 2.7964 | Actual Loss: 0.7078\n",
      "Baseline Loss: 2.8170 | Actual Loss: 0.3638\n",
      "Baseline Loss: 2.8590 | Actual Loss: 0.2164\n",
      "Baseline Loss: 2.8146 | Actual Loss: 0.7181\n",
      "Baseline Loss: 2.8260 | Actual Loss: 0.4594\n",
      "Baseline Loss: 2.8456 | Actual Loss: 2.7096\n",
      "Baseline Loss: 2.8324 | Actual Loss: 0.3312\n",
      "Baseline Loss: 2.8360 | Actual Loss: 0.3533\n",
      "Baseline Loss: 2.8463 | Actual Loss: 0.7314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 80/1000 [00:37<07:19,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7074 | Actual Loss: 0.0798\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.7961\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.5429\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.5967\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.4148\n",
      "Epoch 80/1000: Train Loss: 0.6886, Val Loss: 0.5876\n",
      "Baseline Loss: 2.8309 | Actual Loss: 0.4981\n",
      "Baseline Loss: 2.8635 | Actual Loss: 0.1911\n",
      "Baseline Loss: 2.8282 | Actual Loss: 0.1567\n",
      "Baseline Loss: 2.7789 | Actual Loss: 0.6060\n",
      "Baseline Loss: 2.8393 | Actual Loss: 0.3517\n",
      "Baseline Loss: 2.8099 | Actual Loss: 0.5503\n",
      "Baseline Loss: 2.8648 | Actual Loss: 0.5499\n",
      "Baseline Loss: 2.7860 | Actual Loss: 0.4496\n",
      "Baseline Loss: 2.7994 | Actual Loss: 0.5144\n",
      "Baseline Loss: 2.8483 | Actual Loss: 0.3900\n",
      "Baseline Loss: 2.7772 | Actual Loss: 1.1626\n",
      "Baseline Loss: 2.8427 | Actual Loss: 0.3895\n",
      "Baseline Loss: 2.8264 | Actual Loss: 0.3263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 81/1000 [00:38<07:25,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8068 | Actual Loss: 2.3552\n",
      "Baseline Loss: 2.8270 | Actual Loss: 0.2387\n",
      "Baseline Loss: 2.6260 | Actual Loss: 2.1379\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.8326\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.4024\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.7258\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.5213\n",
      "Epoch 81/1000: Train Loss: 0.6793, Val Loss: 0.6205\n",
      "Baseline Loss: 2.8496 | Actual Loss: 0.5893\n",
      "Baseline Loss: 2.8381 | Actual Loss: 0.6648\n",
      "Baseline Loss: 2.8403 | Actual Loss: 0.5279\n",
      "Baseline Loss: 2.7946 | Actual Loss: 0.2897\n",
      "Baseline Loss: 2.8507 | Actual Loss: 0.5872\n",
      "Baseline Loss: 2.8021 | Actual Loss: 0.4613\n",
      "Baseline Loss: 2.8388 | Actual Loss: 0.3901\n",
      "Baseline Loss: 2.8696 | Actual Loss: 0.2613\n",
      "Baseline Loss: 2.8410 | Actual Loss: 0.6952\n",
      "Baseline Loss: 2.8990 | Actual Loss: 0.5480\n",
      "Baseline Loss: 2.7994 | Actual Loss: 0.4146\n",
      "Baseline Loss: 2.9055 | Actual Loss: 0.8682\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.3083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 82/1000 [00:38<07:24,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8131 | Actual Loss: 0.2793\n",
      "Baseline Loss: 2.8209 | Actual Loss: 2.6215\n",
      "Baseline Loss: 2.6514 | Actual Loss: 0.2178\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.9238\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.4098\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.7399\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.8735\n",
      "Epoch 82/1000: Train Loss: 0.6078, Val Loss: 0.7367\n",
      "Baseline Loss: 2.9535 | Actual Loss: 2.7598\n",
      "Baseline Loss: 2.7746 | Actual Loss: 0.2263\n",
      "Baseline Loss: 2.8552 | Actual Loss: 0.6253\n",
      "Baseline Loss: 2.8391 | Actual Loss: 0.3096\n",
      "Baseline Loss: 2.7942 | Actual Loss: 0.3579\n",
      "Baseline Loss: 2.7808 | Actual Loss: 0.6867\n",
      "Baseline Loss: 2.7514 | Actual Loss: 0.2541\n",
      "Baseline Loss: 2.8150 | Actual Loss: 0.9517\n",
      "Baseline Loss: 2.7740 | Actual Loss: 1.2118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 83/1000 [00:39<07:08,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8261 | Actual Loss: 0.3682\n",
      "Baseline Loss: 2.8698 | Actual Loss: 0.1904\n",
      "Baseline Loss: 2.8557 | Actual Loss: 0.7489\n",
      "Baseline Loss: 2.9028 | Actual Loss: 0.6476\n",
      "Baseline Loss: 2.8550 | Actual Loss: 0.4787\n",
      "Baseline Loss: 2.8405 | Actual Loss: 0.4140\n",
      "Baseline Loss: 2.5064 | Actual Loss: 0.3096\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.5952\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.4385\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.6315\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.4860\n",
      "Epoch 83/1000: Train Loss: 0.6588, Val Loss: 0.5378\n",
      "Baseline Loss: 2.7999 | Actual Loss: 0.4700\n",
      "Baseline Loss: 2.8152 | Actual Loss: 0.4543\n",
      "Baseline Loss: 2.8029 | Actual Loss: 0.7748\n",
      "Baseline Loss: 2.8053 | Actual Loss: 0.2325\n",
      "Baseline Loss: 2.7910 | Actual Loss: 0.6534\n",
      "Baseline Loss: 2.8320 | Actual Loss: 0.3929\n",
      "Baseline Loss: 2.8535 | Actual Loss: 0.5453\n",
      "Baseline Loss: 2.7940 | Actual Loss: 0.2767\n",
      "Baseline Loss: 2.9120 | Actual Loss: 0.5758\n",
      "Baseline Loss: 2.7719 | Actual Loss: 0.4922\n",
      "Baseline Loss: 2.8304 | Actual Loss: 0.8125\n",
      "Baseline Loss: 2.8422 | Actual Loss: 0.3267\n",
      "Baseline Loss: 2.8556 | Actual Loss: 0.4671\n",
      "Baseline Loss: 2.9212 | Actual Loss: 0.3304\n",
      "Baseline Loss: 2.8052 | Actual Loss: 0.3428\n",
      "Baseline Loss: 2.5526 | Actual Loss: 0.1525\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.5973\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.5269\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.7075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 84/1000 [00:39<07:07,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7468 | Actual Loss: 0.3911\n",
      "Epoch 84/1000: Train Loss: 0.4562, Val Loss: 0.5557\n",
      "Baseline Loss: 2.8432 | Actual Loss: 0.2750\n",
      "Baseline Loss: 2.9176 | Actual Loss: 0.5011\n",
      "Baseline Loss: 2.9500 | Actual Loss: 0.2452\n",
      "Baseline Loss: 2.8201 | Actual Loss: 0.2483\n",
      "Baseline Loss: 2.7993 | Actual Loss: 2.4651\n",
      "Baseline Loss: 2.8317 | Actual Loss: 0.4897\n",
      "Baseline Loss: 2.7878 | Actual Loss: 2.5743\n",
      "Baseline Loss: 2.8209 | Actual Loss: 0.2637\n",
      "Baseline Loss: 2.8205 | Actual Loss: 0.3982\n",
      "Baseline Loss: 2.8461 | Actual Loss: 0.6612\n",
      "Baseline Loss: 2.7661 | Actual Loss: 0.7110\n",
      "Baseline Loss: 2.8093 | Actual Loss: 0.5830\n",
      "Baseline Loss: 2.9532 | Actual Loss: 1.5737\n",
      "Baseline Loss: 2.8037 | Actual Loss: 0.2272\n",
      "Baseline Loss: 2.7651 | Actual Loss: 0.4968\n",
      "Baseline Loss: 2.5341 | Actual Loss: 0.4346\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.8937\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.5693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 85/1000 [00:40<07:18,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8293 | Actual Loss: 0.6770\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.4924\n",
      "Epoch 85/1000: Train Loss: 0.7593, Val Loss: 0.6581\n",
      "Baseline Loss: 2.8425 | Actual Loss: 1.0548\n",
      "Baseline Loss: 2.8056 | Actual Loss: 0.3346\n",
      "Baseline Loss: 2.8235 | Actual Loss: 0.4857\n",
      "Baseline Loss: 2.8658 | Actual Loss: 0.6451\n",
      "Baseline Loss: 2.8540 | Actual Loss: 0.5570\n",
      "Baseline Loss: 2.8035 | Actual Loss: 0.3771\n",
      "Baseline Loss: 2.8360 | Actual Loss: 0.6790\n",
      "Baseline Loss: 2.8352 | Actual Loss: 2.4348\n",
      "Baseline Loss: 2.8421 | Actual Loss: 0.6432\n",
      "Baseline Loss: 2.7770 | Actual Loss: 0.4666\n",
      "Baseline Loss: 2.8235 | Actual Loss: 0.3904\n",
      "Baseline Loss: 2.7900 | Actual Loss: 0.2950\n",
      "Baseline Loss: 2.8019 | Actual Loss: 0.6182\n",
      "Baseline Loss: 2.8936 | Actual Loss: 0.4013\n",
      "Baseline Loss: 2.7905 | Actual Loss: 0.1775\n",
      "Baseline Loss: 2.6299 | Actual Loss: 2.5114\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.3831\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.2839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▊         | 86/1000 [00:40<07:07,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8293 | Actual Loss: 0.6891\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.5932\n",
      "Epoch 86/1000: Train Loss: 0.7545, Val Loss: 0.7373\n",
      "Baseline Loss: 2.8247 | Actual Loss: 2.7106\n",
      "Baseline Loss: 2.8583 | Actual Loss: 2.0902\n",
      "Baseline Loss: 2.8406 | Actual Loss: 0.6420\n",
      "Baseline Loss: 2.8545 | Actual Loss: 0.8084\n",
      "Baseline Loss: 2.7867 | Actual Loss: 0.5281\n",
      "Baseline Loss: 2.7816 | Actual Loss: 0.5203\n",
      "Baseline Loss: 2.8031 | Actual Loss: 0.4810\n",
      "Baseline Loss: 2.8133 | Actual Loss: 0.7869\n",
      "Baseline Loss: 2.7854 | Actual Loss: 0.3623\n",
      "Baseline Loss: 2.8760 | Actual Loss: 0.4339\n",
      "Baseline Loss: 2.8369 | Actual Loss: 0.4661\n",
      "Baseline Loss: 2.8976 | Actual Loss: 0.8284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▊         | 87/1000 [00:41<07:19,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8607 | Actual Loss: 0.2844\n",
      "Baseline Loss: 2.8360 | Actual Loss: 0.4492\n",
      "Baseline Loss: 2.7645 | Actual Loss: 0.2074\n",
      "Baseline Loss: 2.4722 | Actual Loss: 0.0972\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.6100\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.4644\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.7391\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.6060\n",
      "Epoch 87/1000: Train Loss: 0.7310, Val Loss: 0.6049\n",
      "Baseline Loss: 2.7959 | Actual Loss: 0.3033\n",
      "Baseline Loss: 2.8242 | Actual Loss: 0.5673\n",
      "Baseline Loss: 2.8004 | Actual Loss: 1.0287\n",
      "Baseline Loss: 2.8030 | Actual Loss: 0.2123\n",
      "Baseline Loss: 2.8103 | Actual Loss: 0.4486\n",
      "Baseline Loss: 2.7890 | Actual Loss: 0.3922\n",
      "Baseline Loss: 2.8666 | Actual Loss: 1.2317\n",
      "Baseline Loss: 2.8455 | Actual Loss: 1.0211\n",
      "Baseline Loss: 2.8410 | Actual Loss: 0.1903\n",
      "Baseline Loss: 2.8080 | Actual Loss: 1.4795\n",
      "Baseline Loss: 2.8009 | Actual Loss: 0.4294\n",
      "Baseline Loss: 2.9085 | Actual Loss: 0.6904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 88/1000 [00:41<07:06,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8440 | Actual Loss: 2.1856\n",
      "Baseline Loss: 2.8062 | Actual Loss: 0.6468\n",
      "Baseline Loss: 2.9128 | Actual Loss: 0.9528\n",
      "Baseline Loss: 2.4971 | Actual Loss: 0.3929\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.7434\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.5517\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.6864\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.6047\n",
      "Epoch 88/1000: Train Loss: 0.7608, Val Loss: 0.6466\n",
      "Baseline Loss: 2.8115 | Actual Loss: 0.5750\n",
      "Baseline Loss: 2.8747 | Actual Loss: 0.5741\n",
      "Baseline Loss: 2.7707 | Actual Loss: 0.5386\n",
      "Baseline Loss: 2.7803 | Actual Loss: 0.7831\n",
      "Baseline Loss: 2.7640 | Actual Loss: 0.4647\n",
      "Baseline Loss: 2.8543 | Actual Loss: 0.6458\n",
      "Baseline Loss: 2.8326 | Actual Loss: 0.1362\n",
      "Baseline Loss: 2.8596 | Actual Loss: 0.5032\n",
      "Baseline Loss: 2.7151 | Actual Loss: 0.3411\n",
      "Baseline Loss: 2.8790 | Actual Loss: 0.2271\n",
      "Baseline Loss: 2.8412 | Actual Loss: 0.6078\n",
      "Baseline Loss: 2.9130 | Actual Loss: 0.2803\n",
      "Baseline Loss: 2.8273 | Actual Loss: 0.3564\n",
      "Baseline Loss: 2.8040 | Actual Loss: 0.8100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 89/1000 [00:42<07:08,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8987 | Actual Loss: 0.7202\n",
      "Baseline Loss: 2.6400 | Actual Loss: 0.8746\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.6793\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.3319\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.8120\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.9100\n",
      "Epoch 89/1000: Train Loss: 0.5274, Val Loss: 0.9333\n",
      "Baseline Loss: 2.8770 | Actual Loss: 0.3432\n",
      "Baseline Loss: 2.8665 | Actual Loss: 0.6744\n",
      "Baseline Loss: 2.8504 | Actual Loss: 0.4847\n",
      "Baseline Loss: 2.8211 | Actual Loss: 0.1800\n",
      "Baseline Loss: 2.8123 | Actual Loss: 0.2028\n",
      "Baseline Loss: 2.8474 | Actual Loss: 0.2849\n",
      "Baseline Loss: 2.8800 | Actual Loss: 2.3128\n",
      "Baseline Loss: 2.8569 | Actual Loss: 0.3470\n",
      "Baseline Loss: 2.7693 | Actual Loss: 0.5862\n",
      "Baseline Loss: 2.7800 | Actual Loss: 0.1830\n",
      "Baseline Loss: 2.8028 | Actual Loss: 0.1710\n",
      "Baseline Loss: 2.8361 | Actual Loss: 0.4453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 90/1000 [00:42<07:20,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7659 | Actual Loss: 0.9696\n",
      "Baseline Loss: 2.8225 | Actual Loss: 0.7312\n",
      "Baseline Loss: 2.8746 | Actual Loss: 0.5409\n",
      "Baseline Loss: 2.6038 | Actual Loss: 1.4169\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.9037\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.3604\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.7090\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.5166\n",
      "Epoch 90/1000: Train Loss: 0.6171, Val Loss: 0.6224\n",
      "Baseline Loss: 2.8313 | Actual Loss: 0.3566\n",
      "Baseline Loss: 2.8129 | Actual Loss: 0.7223\n",
      "Baseline Loss: 2.8532 | Actual Loss: 0.3468\n",
      "Baseline Loss: 2.7859 | Actual Loss: 0.4160\n",
      "Baseline Loss: 2.8507 | Actual Loss: 0.4389\n",
      "Baseline Loss: 2.8627 | Actual Loss: 0.6357\n",
      "Baseline Loss: 2.8404 | Actual Loss: 0.6238\n",
      "Baseline Loss: 2.8531 | Actual Loss: 0.7140\n",
      "Baseline Loss: 2.8196 | Actual Loss: 0.4553\n",
      "Baseline Loss: 2.8173 | Actual Loss: 0.6212\n",
      "Baseline Loss: 2.8094 | Actual Loss: 0.2777\n",
      "Baseline Loss: 2.8695 | Actual Loss: 2.5797\n",
      "Baseline Loss: 2.8073 | Actual Loss: 0.1726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 91/1000 [00:42<06:59,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8486 | Actual Loss: 0.4269\n",
      "Baseline Loss: 2.8788 | Actual Loss: 1.7603\n",
      "Baseline Loss: 2.6188 | Actual Loss: 0.2797\n",
      "Baseline Loss: 2.8280 | Actual Loss: 2.2401\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.3073\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.6239\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.7216\n",
      "Epoch 91/1000: Train Loss: 0.6767, Val Loss: 0.9732\n",
      "Baseline Loss: 2.8241 | Actual Loss: 2.8698\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.4173\n",
      "Baseline Loss: 2.8160 | Actual Loss: 0.1888\n",
      "Baseline Loss: 2.8087 | Actual Loss: 2.4765\n",
      "Baseline Loss: 2.8524 | Actual Loss: 0.7544\n",
      "Baseline Loss: 2.9055 | Actual Loss: 2.4294\n",
      "Baseline Loss: 2.8451 | Actual Loss: 0.2812\n",
      "Baseline Loss: 2.8183 | Actual Loss: 0.2955\n",
      "Baseline Loss: 2.7818 | Actual Loss: 1.7551\n",
      "Baseline Loss: 2.7652 | Actual Loss: 0.3332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 92/1000 [00:43<07:01,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8461 | Actual Loss: 2.4645\n",
      "Baseline Loss: 2.9276 | Actual Loss: 0.1959\n",
      "Baseline Loss: 2.7817 | Actual Loss: 0.1508\n",
      "Baseline Loss: 2.8169 | Actual Loss: 0.3645\n",
      "Baseline Loss: 2.8596 | Actual Loss: 0.5961\n",
      "Baseline Loss: 2.5213 | Actual Loss: 1.8217\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.0631\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.4249\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.7163\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.7481\n",
      "Epoch 92/1000: Train Loss: 1.0872, Val Loss: 0.7381\n",
      "Baseline Loss: 2.7756 | Actual Loss: 0.1891\n",
      "Baseline Loss: 2.8741 | Actual Loss: 0.4113\n",
      "Baseline Loss: 2.7847 | Actual Loss: 0.2239\n",
      "Baseline Loss: 2.9261 | Actual Loss: 2.3442\n",
      "Baseline Loss: 2.8140 | Actual Loss: 1.0238\n",
      "Baseline Loss: 2.8761 | Actual Loss: 2.2715\n",
      "Baseline Loss: 2.8520 | Actual Loss: 0.6470\n",
      "Baseline Loss: 2.8338 | Actual Loss: 0.2584\n",
      "Baseline Loss: 2.8172 | Actual Loss: 0.6091\n",
      "Baseline Loss: 2.8526 | Actual Loss: 0.4790\n",
      "Baseline Loss: 2.8659 | Actual Loss: 0.2608\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.4411\n",
      "Baseline Loss: 2.7591 | Actual Loss: 0.0983\n",
      "Baseline Loss: 2.8209 | Actual Loss: 0.4842\n",
      "Baseline Loss: 2.8339 | Actual Loss: 0.5727\n",
      "Baseline Loss: 2.4876 | Actual Loss: 2.0872\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.9875\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.4298\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.5365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 93/1000 [00:43<07:10,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7468 | Actual Loss: 0.5310\n",
      "Epoch 93/1000: Train Loss: 0.7751, Val Loss: 0.6212\n",
      "Baseline Loss: 2.8633 | Actual Loss: 0.6911\n",
      "Baseline Loss: 2.8231 | Actual Loss: 0.4790\n",
      "Baseline Loss: 2.8087 | Actual Loss: 0.6377\n",
      "Baseline Loss: 2.8622 | Actual Loss: 0.7909\n",
      "Baseline Loss: 2.8540 | Actual Loss: 0.5291\n",
      "Baseline Loss: 2.8406 | Actual Loss: 0.4898\n",
      "Baseline Loss: 2.8183 | Actual Loss: 0.7689\n",
      "Baseline Loss: 2.9231 | Actual Loss: 0.2643\n",
      "Baseline Loss: 2.8075 | Actual Loss: 0.5998\n",
      "Baseline Loss: 2.7796 | Actual Loss: 0.1819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 94/1000 [00:44<06:53,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7990 | Actual Loss: 0.9265\n",
      "Baseline Loss: 2.7757 | Actual Loss: 0.2962\n",
      "Baseline Loss: 2.7911 | Actual Loss: 0.4156\n",
      "Baseline Loss: 2.8374 | Actual Loss: 0.4250\n",
      "Baseline Loss: 2.8522 | Actual Loss: 0.2395\n",
      "Baseline Loss: 2.7087 | Actual Loss: 3.7066\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.6808\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.4246\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.6487\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.4661\n",
      "Epoch 94/1000: Train Loss: 0.7151, Val Loss: 0.5551\n",
      "Baseline Loss: 2.8375 | Actual Loss: 0.5793\n",
      "Baseline Loss: 2.7646 | Actual Loss: 0.2704\n",
      "Baseline Loss: 2.8388 | Actual Loss: 0.2355\n",
      "Baseline Loss: 2.8344 | Actual Loss: 0.3684\n",
      "Baseline Loss: 2.8189 | Actual Loss: 0.5616\n",
      "Baseline Loss: 2.8713 | Actual Loss: 0.7198\n",
      "Baseline Loss: 2.8515 | Actual Loss: 0.9790\n",
      "Baseline Loss: 2.8175 | Actual Loss: 0.8459\n",
      "Baseline Loss: 2.8195 | Actual Loss: 0.3889\n",
      "Baseline Loss: 2.8108 | Actual Loss: 0.2318\n",
      "Baseline Loss: 2.8868 | Actual Loss: 0.4253\n",
      "Baseline Loss: 2.7606 | Actual Loss: 0.2032\n",
      "Baseline Loss: 2.8721 | Actual Loss: 1.6376\n",
      "Baseline Loss: 2.8281 | Actual Loss: 0.5296\n",
      "Baseline Loss: 2.8965 | Actual Loss: 0.4428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 95/1000 [00:44<06:58,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5769 | Actual Loss: 0.1184\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.2789\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.4483\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.5753\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.4524\n",
      "Epoch 95/1000: Train Loss: 0.5336, Val Loss: 0.6888\n",
      "Baseline Loss: 2.8077 | Actual Loss: 0.3407\n",
      "Baseline Loss: 2.9043 | Actual Loss: 0.6276\n",
      "Baseline Loss: 2.8166 | Actual Loss: 0.5181\n",
      "Baseline Loss: 2.8311 | Actual Loss: 2.5184\n",
      "Baseline Loss: 2.7771 | Actual Loss: 0.7829\n",
      "Baseline Loss: 2.8400 | Actual Loss: 0.2120\n",
      "Baseline Loss: 2.8101 | Actual Loss: 0.4522\n",
      "Baseline Loss: 2.8362 | Actual Loss: 0.1381\n",
      "Baseline Loss: 2.8304 | Actual Loss: 1.0220\n",
      "Baseline Loss: 2.8152 | Actual Loss: 0.1332\n",
      "Baseline Loss: 2.8792 | Actual Loss: 2.4713\n",
      "Baseline Loss: 2.8662 | Actual Loss: 0.5514\n",
      "Baseline Loss: 2.8306 | Actual Loss: 0.2458\n",
      "Baseline Loss: 2.8375 | Actual Loss: 0.7498\n",
      "Baseline Loss: 2.8219 | Actual Loss: 0.2916\n",
      "Baseline Loss: 2.3868 | Actual Loss: 1.5118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 96/1000 [00:45<07:14,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8280 | Actual Loss: 2.4330\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.4791\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.5151\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.5479\n",
      "Epoch 96/1000: Train Loss: 0.7854, Val Loss: 0.9938\n",
      "Baseline Loss: 2.7286 | Actual Loss: 0.1977\n",
      "Baseline Loss: 2.8193 | Actual Loss: 0.6439\n",
      "Baseline Loss: 2.7781 | Actual Loss: 0.8287\n",
      "Baseline Loss: 2.8428 | Actual Loss: 0.4428\n",
      "Baseline Loss: 2.8716 | Actual Loss: 2.6593\n",
      "Baseline Loss: 2.7633 | Actual Loss: 0.3353\n",
      "Baseline Loss: 2.7963 | Actual Loss: 0.4769\n",
      "Baseline Loss: 2.8142 | Actual Loss: 0.3624\n",
      "Baseline Loss: 2.7981 | Actual Loss: 0.5932\n",
      "Baseline Loss: 2.9177 | Actual Loss: 0.6488\n",
      "Baseline Loss: 2.8792 | Actual Loss: 0.3138\n",
      "Baseline Loss: 2.8901 | Actual Loss: 0.3651\n",
      "Baseline Loss: 2.8422 | Actual Loss: 2.3085\n",
      "Baseline Loss: 2.8287 | Actual Loss: 0.2294\n",
      "Baseline Loss: 2.8467 | Actual Loss: 0.3721\n",
      "Baseline Loss: 2.5577 | Actual Loss: 0.8439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 97/1000 [00:45<06:54,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8280 | Actual Loss: 2.6290\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.3874\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.5930\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.4853\n",
      "Epoch 97/1000: Train Loss: 0.7264, Val Loss: 1.0237\n",
      "Baseline Loss: 2.8746 | Actual Loss: 0.3362\n",
      "Baseline Loss: 2.7793 | Actual Loss: 0.1494\n",
      "Baseline Loss: 2.8118 | Actual Loss: 0.2395\n",
      "Baseline Loss: 2.8532 | Actual Loss: 0.5026\n",
      "Baseline Loss: 2.7930 | Actual Loss: 0.4531\n",
      "Baseline Loss: 2.7997 | Actual Loss: 0.6770\n",
      "Baseline Loss: 2.8776 | Actual Loss: 1.6286\n",
      "Baseline Loss: 2.8289 | Actual Loss: 0.3134\n",
      "Baseline Loss: 2.8969 | Actual Loss: 0.6239\n",
      "Baseline Loss: 2.8090 | Actual Loss: 1.0945\n",
      "Baseline Loss: 2.7859 | Actual Loss: 0.4971\n",
      "Baseline Loss: 2.8589 | Actual Loss: 0.2266\n",
      "Baseline Loss: 2.8281 | Actual Loss: 0.5342\n",
      "Baseline Loss: 2.8524 | Actual Loss: 0.2817\n",
      "Baseline Loss: 2.8079 | Actual Loss: 0.2323\n",
      "Baseline Loss: 2.5987 | Actual Loss: 0.4107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 98/1000 [00:46<06:58,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8280 | Actual Loss: 1.9181\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.2840\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.5230\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.4662\n",
      "Epoch 98/1000: Train Loss: 0.5126, Val Loss: 0.7978\n",
      "Baseline Loss: 2.8152 | Actual Loss: 0.4757\n",
      "Baseline Loss: 2.8846 | Actual Loss: 1.6996\n",
      "Baseline Loss: 2.9138 | Actual Loss: 0.5366\n",
      "Baseline Loss: 2.7159 | Actual Loss: 0.2964\n",
      "Baseline Loss: 2.9097 | Actual Loss: 0.4346\n",
      "Baseline Loss: 2.8061 | Actual Loss: 0.6181\n",
      "Baseline Loss: 2.8899 | Actual Loss: 0.4348\n",
      "Baseline Loss: 2.7842 | Actual Loss: 0.1381\n",
      "Baseline Loss: 2.7718 | Actual Loss: 0.1263\n",
      "Baseline Loss: 2.9308 | Actual Loss: 0.7232\n",
      "Baseline Loss: 2.8285 | Actual Loss: 0.6584\n",
      "Baseline Loss: 2.8350 | Actual Loss: 0.2314\n",
      "Baseline Loss: 2.8564 | Actual Loss: 0.1235\n",
      "Baseline Loss: 2.8393 | Actual Loss: 0.2109\n",
      "Baseline Loss: 2.8885 | Actual Loss: 0.4449\n",
      "Baseline Loss: 2.5794 | Actual Loss: 1.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 99/1000 [00:46<06:52,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8280 | Actual Loss: 1.2854\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.3172\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.5189\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.4751\n",
      "Epoch 99/1000: Train Loss: 0.5252, Val Loss: 0.6491\n",
      "Baseline Loss: 2.8152 | Actual Loss: 0.1395\n",
      "Baseline Loss: 2.7639 | Actual Loss: 0.9616\n",
      "Baseline Loss: 2.8709 | Actual Loss: 0.5123\n",
      "Baseline Loss: 2.8562 | Actual Loss: 0.3723\n",
      "Baseline Loss: 2.8480 | Actual Loss: 1.1084\n",
      "Baseline Loss: 2.8230 | Actual Loss: 0.2751\n",
      "Baseline Loss: 2.8802 | Actual Loss: 0.3723\n",
      "Baseline Loss: 2.8113 | Actual Loss: 0.5923\n",
      "Baseline Loss: 2.8119 | Actual Loss: 0.2468\n",
      "Baseline Loss: 2.7402 | Actual Loss: 0.4049\n",
      "Baseline Loss: 2.8336 | Actual Loss: 0.3613\n",
      "Baseline Loss: 2.7957 | Actual Loss: 2.4840\n",
      "Baseline Loss: 2.8708 | Actual Loss: 0.7782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 100/1000 [00:47<07:06,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8901 | Actual Loss: 0.4885\n",
      "Baseline Loss: 2.8882 | Actual Loss: 0.5691\n",
      "Baseline Loss: 2.4786 | Actual Loss: 0.2955\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.8921\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.3893\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.5347\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.4665\n",
      "Epoch 100/1000: Train Loss: 0.6226, Val Loss: 0.5706\n",
      "Baseline Loss: 2.8045 | Actual Loss: 0.2899\n",
      "Baseline Loss: 2.8486 | Actual Loss: 0.2678\n",
      "Baseline Loss: 2.8079 | Actual Loss: 0.3167\n",
      "Baseline Loss: 2.8618 | Actual Loss: 0.4604\n",
      "Baseline Loss: 2.7288 | Actual Loss: 0.2042\n",
      "Baseline Loss: 2.8728 | Actual Loss: 0.2385\n",
      "Baseline Loss: 2.8166 | Actual Loss: 0.3149\n",
      "Baseline Loss: 2.8580 | Actual Loss: 0.4649\n",
      "Baseline Loss: 2.8461 | Actual Loss: 0.5538\n",
      "Baseline Loss: 2.8614 | Actual Loss: 0.1729\n",
      "Baseline Loss: 2.8102 | Actual Loss: 0.8018\n",
      "Baseline Loss: 2.8305 | Actual Loss: 2.2761\n",
      "Baseline Loss: 2.7950 | Actual Loss: 0.3506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 101/1000 [00:47<07:19,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9243 | Actual Loss: 0.4151\n",
      "Baseline Loss: 2.8141 | Actual Loss: 0.1869\n",
      "Baseline Loss: 2.7163 | Actual Loss: 1.9321\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.2470\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.4150\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.5375\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.4804\n",
      "Epoch 101/1000: Train Loss: 0.5779, Val Loss: 0.6700\n",
      "Baseline Loss: 2.8393 | Actual Loss: 0.5581\n",
      "Baseline Loss: 2.7997 | Actual Loss: 0.9984\n",
      "Baseline Loss: 2.9002 | Actual Loss: 1.0939\n",
      "Baseline Loss: 2.8430 | Actual Loss: 0.3170\n",
      "Baseline Loss: 2.8190 | Actual Loss: 0.4146\n",
      "Baseline Loss: 2.7927 | Actual Loss: 0.1541\n",
      "Baseline Loss: 2.8911 | Actual Loss: 0.5097\n",
      "Baseline Loss: 2.8726 | Actual Loss: 0.1684\n",
      "Baseline Loss: 2.8400 | Actual Loss: 0.5295\n",
      "Baseline Loss: 2.7956 | Actual Loss: 0.3031\n",
      "Baseline Loss: 2.8237 | Actual Loss: 0.5033\n",
      "Baseline Loss: 2.7777 | Actual Loss: 0.4014\n",
      "Baseline Loss: 2.8821 | Actual Loss: 0.4133\n",
      "Baseline Loss: 2.8214 | Actual Loss: 0.1729\n",
      "Baseline Loss: 2.8092 | Actual Loss: 0.2415\n",
      "Baseline Loss: 2.4530 | Actual Loss: 2.2315\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.2120\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.3795\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.5294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 102/1000 [00:48<07:06,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7468 | Actual Loss: 0.4903\n",
      "Epoch 102/1000: Train Loss: 0.5632, Val Loss: 0.6528\n",
      "Baseline Loss: 2.9276 | Actual Loss: 0.2983\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.1103\n",
      "Baseline Loss: 2.8584 | Actual Loss: 0.5074\n",
      "Baseline Loss: 2.8294 | Actual Loss: 1.3586\n",
      "Baseline Loss: 2.8208 | Actual Loss: 0.4023\n",
      "Baseline Loss: 2.8171 | Actual Loss: 0.3714\n",
      "Baseline Loss: 2.8691 | Actual Loss: 0.4513\n",
      "Baseline Loss: 2.7612 | Actual Loss: 0.3604\n",
      "Baseline Loss: 2.8381 | Actual Loss: 2.8088\n",
      "Baseline Loss: 2.7934 | Actual Loss: 0.0723\n",
      "Baseline Loss: 2.7894 | Actual Loss: 0.4975\n",
      "Baseline Loss: 2.8483 | Actual Loss: 0.8680\n",
      "Baseline Loss: 2.7866 | Actual Loss: 0.1450\n",
      "Baseline Loss: 2.7969 | Actual Loss: 0.1438\n",
      "Baseline Loss: 2.8416 | Actual Loss: 0.2842\n",
      "Baseline Loss: 2.5996 | Actual Loss: 0.2867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 103/1000 [00:48<07:15,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8280 | Actual Loss: 1.0030\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.3010\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.5234\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.4572\n",
      "Epoch 103/1000: Train Loss: 0.6229, Val Loss: 0.5712\n",
      "Baseline Loss: 2.8955 | Actual Loss: 0.1822\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.2851\n",
      "Baseline Loss: 2.8425 | Actual Loss: 0.4567\n",
      "Baseline Loss: 2.8315 | Actual Loss: 0.4991\n",
      "Baseline Loss: 2.8660 | Actual Loss: 0.5342\n",
      "Baseline Loss: 2.8107 | Actual Loss: 0.6462\n",
      "Baseline Loss: 2.8466 | Actual Loss: 0.4495\n",
      "Baseline Loss: 2.8922 | Actual Loss: 0.2056\n",
      "Baseline Loss: 2.7765 | Actual Loss: 0.2203\n",
      "Baseline Loss: 2.7467 | Actual Loss: 0.6277\n",
      "Baseline Loss: 2.8620 | Actual Loss: 0.7936\n",
      "Baseline Loss: 2.7938 | Actual Loss: 0.1790\n",
      "Baseline Loss: 2.8307 | Actual Loss: 0.1225\n",
      "Baseline Loss: 2.8543 | Actual Loss: 0.7636\n",
      "Baseline Loss: 2.8063 | Actual Loss: 0.2347\n",
      "Baseline Loss: 2.5604 | Actual Loss: 2.3895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 104/1000 [00:49<07:23,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8280 | Actual Loss: 1.1974\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.2990\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.5428\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.4942\n",
      "Epoch 104/1000: Train Loss: 0.5368, Val Loss: 0.6333\n",
      "Baseline Loss: 2.7872 | Actual Loss: 0.4871\n",
      "Baseline Loss: 2.8948 | Actual Loss: 0.2514\n",
      "Baseline Loss: 2.8922 | Actual Loss: 0.3613\n",
      "Baseline Loss: 2.8105 | Actual Loss: 0.5847\n",
      "Baseline Loss: 2.8604 | Actual Loss: 1.1530\n",
      "Baseline Loss: 2.8877 | Actual Loss: 0.4499\n",
      "Baseline Loss: 2.7529 | Actual Loss: 0.1294\n",
      "Baseline Loss: 2.8255 | Actual Loss: 2.4838\n",
      "Baseline Loss: 2.8441 | Actual Loss: 0.2730\n",
      "Baseline Loss: 2.8251 | Actual Loss: 0.3727\n",
      "Baseline Loss: 2.8468 | Actual Loss: 0.2065\n",
      "Baseline Loss: 2.7972 | Actual Loss: 1.6257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 105/1000 [00:49<07:08,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7600 | Actual Loss: 0.2467\n",
      "Baseline Loss: 2.8074 | Actual Loss: 0.1850\n",
      "Baseline Loss: 2.8591 | Actual Loss: 0.4357\n",
      "Baseline Loss: 2.5741 | Actual Loss: 0.6368\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.9117\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.2959\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.5639\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.5169\n",
      "Epoch 105/1000: Train Loss: 0.6177, Val Loss: 0.5721\n",
      "Baseline Loss: 2.7675 | Actual Loss: 0.6201\n",
      "Baseline Loss: 2.8524 | Actual Loss: 0.3835\n",
      "Baseline Loss: 2.8634 | Actual Loss: 0.3394\n",
      "Baseline Loss: 2.7979 | Actual Loss: 0.2243\n",
      "Baseline Loss: 2.7981 | Actual Loss: 0.2342\n",
      "Baseline Loss: 2.8182 | Actual Loss: 0.7659\n",
      "Baseline Loss: 2.8094 | Actual Loss: 1.0230\n",
      "Baseline Loss: 2.7988 | Actual Loss: 0.8549\n",
      "Baseline Loss: 2.8542 | Actual Loss: 0.3230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 106/1000 [00:50<07:12,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9061 | Actual Loss: 0.4037\n",
      "Baseline Loss: 2.7959 | Actual Loss: 0.0795\n",
      "Baseline Loss: 2.8719 | Actual Loss: 0.4850\n",
      "Baseline Loss: 2.8474 | Actual Loss: 0.8396\n",
      "Baseline Loss: 2.9048 | Actual Loss: 0.5872\n",
      "Baseline Loss: 2.8647 | Actual Loss: 0.3481\n",
      "Baseline Loss: 2.6070 | Actual Loss: 0.2346\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.2821\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.4689\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.6148\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.5235\n",
      "Epoch 106/1000: Train Loss: 0.4841, Val Loss: 0.7223\n",
      "Baseline Loss: 2.8568 | Actual Loss: 0.3816\n",
      "Baseline Loss: 2.7936 | Actual Loss: 0.1683\n",
      "Baseline Loss: 2.8481 | Actual Loss: 0.2983\n",
      "Baseline Loss: 2.8229 | Actual Loss: 0.1873\n",
      "Baseline Loss: 2.7795 | Actual Loss: 1.5516\n",
      "Baseline Loss: 2.8522 | Actual Loss: 0.3172\n",
      "Baseline Loss: 2.8286 | Actual Loss: 0.2918\n",
      "Baseline Loss: 2.8317 | Actual Loss: 0.7502\n",
      "Baseline Loss: 2.8077 | Actual Loss: 0.4473\n",
      "Baseline Loss: 2.8636 | Actual Loss: 0.5268\n",
      "Baseline Loss: 2.8129 | Actual Loss: 0.1986\n",
      "Baseline Loss: 2.7990 | Actual Loss: 1.2564\n",
      "Baseline Loss: 2.8549 | Actual Loss: 0.5384\n",
      "Baseline Loss: 2.8339 | Actual Loss: 0.3427\n",
      "Baseline Loss: 2.8631 | Actual Loss: 0.3953\n",
      "Baseline Loss: 2.5397 | Actual Loss: 1.9487\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.9476\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.2857\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.5700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 107/1000 [00:50<06:59,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7468 | Actual Loss: 0.5064\n",
      "Epoch 107/1000: Train Loss: 0.6000, Val Loss: 0.8274\n",
      "Baseline Loss: 2.8198 | Actual Loss: 2.4273\n",
      "Baseline Loss: 2.8268 | Actual Loss: 0.2888\n",
      "Baseline Loss: 2.7902 | Actual Loss: 0.6368\n",
      "Baseline Loss: 2.8899 | Actual Loss: 0.4567\n",
      "Baseline Loss: 2.8743 | Actual Loss: 0.2219\n",
      "Baseline Loss: 2.8421 | Actual Loss: 0.5600\n",
      "Baseline Loss: 2.8078 | Actual Loss: 0.2337\n",
      "Baseline Loss: 2.7819 | Actual Loss: 2.5162\n",
      "Baseline Loss: 2.8497 | Actual Loss: 0.8230\n",
      "Baseline Loss: 2.8568 | Actual Loss: 0.2380\n",
      "Baseline Loss: 2.8500 | Actual Loss: 0.4156\n",
      "Baseline Loss: 2.7591 | Actual Loss: 0.3691\n",
      "Baseline Loss: 2.8113 | Actual Loss: 0.6336\n",
      "Baseline Loss: 2.8092 | Actual Loss: 0.4487\n",
      "Baseline Loss: 2.8284 | Actual Loss: 1.3093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 108/1000 [00:51<07:01,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6557 | Actual Loss: 0.1211\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.9962\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.3180\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.7244\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.5823\n",
      "Epoch 108/1000: Train Loss: 0.7312, Val Loss: 0.6552\n",
      "Baseline Loss: 2.7823 | Actual Loss: 0.2316\n",
      "Baseline Loss: 2.7943 | Actual Loss: 0.5212\n",
      "Baseline Loss: 2.8294 | Actual Loss: 0.2203\n",
      "Baseline Loss: 2.8301 | Actual Loss: 0.5519\n",
      "Baseline Loss: 2.8981 | Actual Loss: 0.5739\n",
      "Baseline Loss: 2.7954 | Actual Loss: 0.1150\n",
      "Baseline Loss: 2.8071 | Actual Loss: 0.3576\n",
      "Baseline Loss: 2.8413 | Actual Loss: 0.8107\n",
      "Baseline Loss: 2.8337 | Actual Loss: 1.0890\n",
      "Baseline Loss: 2.8165 | Actual Loss: 0.5480\n",
      "Baseline Loss: 2.8626 | Actual Loss: 0.3085\n",
      "Baseline Loss: 2.8382 | Actual Loss: 0.4148\n",
      "Baseline Loss: 2.8468 | Actual Loss: 0.2024\n",
      "Baseline Loss: 2.7973 | Actual Loss: 0.4884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 109/1000 [00:51<07:05,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7927 | Actual Loss: 0.1684\n",
      "Baseline Loss: 2.6260 | Actual Loss: 2.3722\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.8167\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.4352\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.6137\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.5446\n",
      "Epoch 109/1000: Train Loss: 0.5609, Val Loss: 0.8526\n",
      "Baseline Loss: 2.9649 | Actual Loss: 0.2711\n",
      "Baseline Loss: 2.7267 | Actual Loss: 0.2479\n",
      "Baseline Loss: 2.7605 | Actual Loss: 0.3888\n",
      "Baseline Loss: 2.8793 | Actual Loss: 1.9574\n",
      "Baseline Loss: 2.7197 | Actual Loss: 0.3184\n",
      "Baseline Loss: 2.8247 | Actual Loss: 0.5272\n",
      "Baseline Loss: 2.7675 | Actual Loss: 0.2437\n",
      "Baseline Loss: 2.8679 | Actual Loss: 0.4651\n",
      "Baseline Loss: 2.8724 | Actual Loss: 0.4390\n",
      "Baseline Loss: 2.8373 | Actual Loss: 0.5200\n",
      "Baseline Loss: 2.8380 | Actual Loss: 0.2191\n",
      "Baseline Loss: 2.8089 | Actual Loss: 0.2800\n",
      "Baseline Loss: 2.8898 | Actual Loss: 0.4120\n",
      "Baseline Loss: 2.8887 | Actual Loss: 0.5252\n",
      "Baseline Loss: 2.8447 | Actual Loss: 0.2864\n",
      "Baseline Loss: 2.6569 | Actual Loss: 0.2933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 110/1000 [00:51<06:51,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8280 | Actual Loss: 0.8248\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.2713\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.5985\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.5458\n",
      "Epoch 110/1000: Train Loss: 0.4622, Val Loss: 0.5601\n",
      "Baseline Loss: 2.7944 | Actual Loss: 0.5526\n",
      "Baseline Loss: 2.8594 | Actual Loss: 0.4150\n",
      "Baseline Loss: 2.8059 | Actual Loss: 0.4811\n",
      "Baseline Loss: 2.8169 | Actual Loss: 0.8053\n",
      "Baseline Loss: 2.8791 | Actual Loss: 0.4101\n",
      "Baseline Loss: 2.8417 | Actual Loss: 0.4995\n",
      "Baseline Loss: 2.8693 | Actual Loss: 0.6069\n",
      "Baseline Loss: 2.8771 | Actual Loss: 0.5822\n",
      "Baseline Loss: 2.7958 | Actual Loss: 0.3569\n",
      "Baseline Loss: 2.8806 | Actual Loss: 0.2890\n",
      "Baseline Loss: 2.7896 | Actual Loss: 0.3363\n",
      "Baseline Loss: 2.8231 | Actual Loss: 0.4623\n",
      "Baseline Loss: 2.7955 | Actual Loss: 0.3897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 111/1000 [00:52<06:53,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8169 | Actual Loss: 0.2676\n",
      "Baseline Loss: 2.7873 | Actual Loss: 0.4851\n",
      "Baseline Loss: 2.5677 | Actual Loss: 1.9771\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.9374\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.4329\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.5093\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.5513\n",
      "Epoch 111/1000: Train Loss: 0.5573, Val Loss: 0.6077\n",
      "Baseline Loss: 2.8215 | Actual Loss: 0.4798\n",
      "Baseline Loss: 2.8089 | Actual Loss: 0.3999\n",
      "Baseline Loss: 2.7639 | Actual Loss: 2.3272\n",
      "Baseline Loss: 2.8542 | Actual Loss: 0.3219\n",
      "Baseline Loss: 2.9647 | Actual Loss: 0.4752\n",
      "Baseline Loss: 2.8311 | Actual Loss: 0.1769\n",
      "Baseline Loss: 2.8881 | Actual Loss: 0.2058\n",
      "Baseline Loss: 2.7753 | Actual Loss: 0.1839\n",
      "Baseline Loss: 2.8668 | Actual Loss: 0.3565\n",
      "Baseline Loss: 2.8427 | Actual Loss: 0.5071\n",
      "Baseline Loss: 2.7951 | Actual Loss: 0.2591\n",
      "Baseline Loss: 2.8228 | Actual Loss: 0.7970\n",
      "Baseline Loss: 2.8257 | Actual Loss: 0.2530\n",
      "Baseline Loss: 2.8774 | Actual Loss: 0.5874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 112/1000 [00:52<06:46,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7910 | Actual Loss: 0.6951\n",
      "Baseline Loss: 2.5631 | Actual Loss: 0.3223\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.0357\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.4034\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.5891\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.5484\n",
      "Epoch 112/1000: Train Loss: 0.5218, Val Loss: 0.6441\n",
      "Baseline Loss: 2.8337 | Actual Loss: 0.1095\n",
      "Baseline Loss: 2.8191 | Actual Loss: 0.8487\n",
      "Baseline Loss: 2.8314 | Actual Loss: 1.1869\n",
      "Baseline Loss: 2.8062 | Actual Loss: 0.3858\n",
      "Baseline Loss: 2.8745 | Actual Loss: 0.1432\n",
      "Baseline Loss: 2.8235 | Actual Loss: 0.4425\n",
      "Baseline Loss: 2.8331 | Actual Loss: 0.2378\n",
      "Baseline Loss: 2.8174 | Actual Loss: 0.4675\n",
      "Baseline Loss: 2.8144 | Actual Loss: 1.0804\n",
      "Baseline Loss: 2.8586 | Actual Loss: 0.2876\n",
      "Baseline Loss: 2.8533 | Actual Loss: 0.5671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█▏        | 113/1000 [00:53<06:57,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7731 | Actual Loss: 0.3653\n",
      "Baseline Loss: 2.8020 | Actual Loss: 0.4971\n",
      "Baseline Loss: 2.8051 | Actual Loss: 0.2923\n",
      "Baseline Loss: 2.8140 | Actual Loss: 0.2399\n",
      "Baseline Loss: 2.6327 | Actual Loss: 0.6603\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.7594\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.3001\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.5287\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.5437\n",
      "Epoch 113/1000: Train Loss: 0.4882, Val Loss: 0.5330\n",
      "Baseline Loss: 2.9448 | Actual Loss: 0.5998\n",
      "Baseline Loss: 2.7905 | Actual Loss: 0.3150\n",
      "Baseline Loss: 2.7988 | Actual Loss: 0.3635\n",
      "Baseline Loss: 2.8058 | Actual Loss: 0.2779\n",
      "Baseline Loss: 2.8587 | Actual Loss: 0.2835\n",
      "Baseline Loss: 2.8595 | Actual Loss: 0.4069\n",
      "Baseline Loss: 2.8444 | Actual Loss: 0.5890\n",
      "Baseline Loss: 2.8270 | Actual Loss: 0.3317\n",
      "Baseline Loss: 2.8531 | Actual Loss: 0.2432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█▏        | 114/1000 [00:53<06:58,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8263 | Actual Loss: 0.7213\n",
      "Baseline Loss: 2.8744 | Actual Loss: 0.3207\n",
      "Baseline Loss: 2.7804 | Actual Loss: 0.1371\n",
      "Baseline Loss: 2.8183 | Actual Loss: 0.2226\n",
      "Baseline Loss: 2.7649 | Actual Loss: 1.0735\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2040\n",
      "Baseline Loss: 2.6632 | Actual Loss: 0.2215\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.7863\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.3823\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.6286\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.6366\n",
      "Epoch 114/1000: Train Loss: 0.3944, Val Loss: 0.6085\n",
      "Baseline Loss: 2.7777 | Actual Loss: 0.7044\n",
      "Baseline Loss: 2.7873 | Actual Loss: 0.2367\n",
      "Baseline Loss: 2.8367 | Actual Loss: 0.2244\n",
      "Baseline Loss: 2.8826 | Actual Loss: 0.1578\n",
      "Baseline Loss: 2.8394 | Actual Loss: 0.5101\n",
      "Baseline Loss: 2.7714 | Actual Loss: 0.4390\n",
      "Baseline Loss: 2.8711 | Actual Loss: 0.1134\n",
      "Baseline Loss: 2.9196 | Actual Loss: 0.4211\n",
      "Baseline Loss: 2.8767 | Actual Loss: 0.3717\n",
      "Baseline Loss: 2.8298 | Actual Loss: 0.3986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 115/1000 [00:54<06:48,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8614 | Actual Loss: 0.2129\n",
      "Baseline Loss: 2.8307 | Actual Loss: 0.2994\n",
      "Baseline Loss: 2.7676 | Actual Loss: 0.1144\n",
      "Baseline Loss: 2.8001 | Actual Loss: 0.4860\n",
      "Baseline Loss: 2.8081 | Actual Loss: 0.6642\n",
      "Baseline Loss: 2.6866 | Actual Loss: 0.8892\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.0885\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.3163\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.7691\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.5703\n",
      "Epoch 115/1000: Train Loss: 0.3902, Val Loss: 0.6861\n",
      "Baseline Loss: 2.8718 | Actual Loss: 0.2978\n",
      "Baseline Loss: 2.8584 | Actual Loss: 0.2457\n",
      "Baseline Loss: 2.8518 | Actual Loss: 0.1871\n",
      "Baseline Loss: 2.8479 | Actual Loss: 0.2365\n",
      "Baseline Loss: 2.7701 | Actual Loss: 0.6580\n",
      "Baseline Loss: 2.7865 | Actual Loss: 0.9138\n",
      "Baseline Loss: 2.9859 | Actual Loss: 0.1275\n",
      "Baseline Loss: 2.7962 | Actual Loss: 0.6227\n",
      "Baseline Loss: 2.7841 | Actual Loss: 0.1130\n",
      "Baseline Loss: 2.7919 | Actual Loss: 0.1078\n",
      "Baseline Loss: 2.8666 | Actual Loss: 0.7325\n",
      "Baseline Loss: 2.8197 | Actual Loss: 0.8647\n",
      "Baseline Loss: 2.8066 | Actual Loss: 0.4498\n",
      "Baseline Loss: 2.8263 | Actual Loss: 0.6439\n",
      "Baseline Loss: 2.7859 | Actual Loss: 0.2254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 116/1000 [00:54<07:05,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5831 | Actual Loss: 0.4933\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.1124\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.2845\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.5120\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.5277\n",
      "Epoch 116/1000: Train Loss: 0.4325, Val Loss: 0.6091\n",
      "Baseline Loss: 2.8533 | Actual Loss: 0.1261\n",
      "Baseline Loss: 2.8012 | Actual Loss: 0.2785\n",
      "Baseline Loss: 2.7911 | Actual Loss: 1.0097\n",
      "Baseline Loss: 2.8302 | Actual Loss: 0.2375\n",
      "Baseline Loss: 2.8245 | Actual Loss: 0.5491\n",
      "Baseline Loss: 2.8805 | Actual Loss: 0.3893\n",
      "Baseline Loss: 2.8558 | Actual Loss: 0.7024\n",
      "Baseline Loss: 2.7962 | Actual Loss: 0.5209\n",
      "Baseline Loss: 2.7939 | Actual Loss: 0.2645\n",
      "Baseline Loss: 2.7638 | Actual Loss: 0.2225\n",
      "Baseline Loss: 2.7636 | Actual Loss: 0.3492\n",
      "Baseline Loss: 2.8261 | Actual Loss: 0.2138\n",
      "Baseline Loss: 2.8824 | Actual Loss: 0.0956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 117/1000 [00:55<07:03,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9095 | Actual Loss: 0.3759\n",
      "Baseline Loss: 2.9295 | Actual Loss: 0.2874\n",
      "Baseline Loss: 2.5912 | Actual Loss: 0.1309\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.8629\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.2901\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.4815\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.5196\n",
      "Epoch 117/1000: Train Loss: 0.3596, Val Loss: 0.5386\n",
      "Baseline Loss: 2.8848 | Actual Loss: 2.2487\n",
      "Baseline Loss: 2.8183 | Actual Loss: 0.3595\n",
      "Baseline Loss: 2.7951 | Actual Loss: 0.3483\n",
      "Baseline Loss: 2.8056 | Actual Loss: 0.1342\n",
      "Baseline Loss: 2.8429 | Actual Loss: 0.2082\n",
      "Baseline Loss: 2.8333 | Actual Loss: 0.3269\n",
      "Baseline Loss: 2.8533 | Actual Loss: 0.7198\n",
      "Baseline Loss: 2.7860 | Actual Loss: 0.2310\n",
      "Baseline Loss: 2.7466 | Actual Loss: 0.1827\n",
      "Baseline Loss: 2.8554 | Actual Loss: 0.1393\n",
      "Baseline Loss: 2.8299 | Actual Loss: 0.3939\n",
      "Baseline Loss: 2.8205 | Actual Loss: 0.6875\n",
      "Baseline Loss: 2.8744 | Actual Loss: 0.3051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 118/1000 [00:55<06:45,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8497 | Actual Loss: 0.4060\n",
      "Baseline Loss: 2.9146 | Actual Loss: 1.6502\n",
      "Baseline Loss: 2.6299 | Actual Loss: 0.1680\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.1169\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.3389\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.4876\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.4678\n",
      "Epoch 118/1000: Train Loss: 0.5318, Val Loss: 0.6028\n",
      "Baseline Loss: 2.8846 | Actual Loss: 0.2332\n",
      "Baseline Loss: 2.7770 | Actual Loss: 0.3448\n",
      "Baseline Loss: 2.7965 | Actual Loss: 0.1335\n",
      "Baseline Loss: 2.8692 | Actual Loss: 0.5805\n",
      "Baseline Loss: 2.7389 | Actual Loss: 0.1405\n",
      "Baseline Loss: 2.8553 | Actual Loss: 0.0853\n",
      "Baseline Loss: 2.7983 | Actual Loss: 0.3668\n",
      "Baseline Loss: 2.7941 | Actual Loss: 0.1427\n",
      "Baseline Loss: 2.8528 | Actual Loss: 0.8182\n",
      "Baseline Loss: 2.7734 | Actual Loss: 0.4218\n",
      "Baseline Loss: 2.9206 | Actual Loss: 0.3929\n",
      "Baseline Loss: 2.8939 | Actual Loss: 0.6242\n",
      "Baseline Loss: 2.8183 | Actual Loss: 0.5943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 119/1000 [00:56<07:00,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8869 | Actual Loss: 0.4917\n",
      "Baseline Loss: 2.8255 | Actual Loss: 0.4823\n",
      "Baseline Loss: 2.5283 | Actual Loss: 2.6823\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.0100\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.3620\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.4553\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.4883\n",
      "Epoch 119/1000: Train Loss: 0.5334, Val Loss: 0.5789\n",
      "Baseline Loss: 2.8262 | Actual Loss: 0.5242\n",
      "Baseline Loss: 2.8591 | Actual Loss: 0.4480\n",
      "Baseline Loss: 2.8268 | Actual Loss: 0.4814\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.5381\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.3082\n",
      "Baseline Loss: 2.7700 | Actual Loss: 0.2428\n",
      "Baseline Loss: 2.8790 | Actual Loss: 0.2875\n",
      "Baseline Loss: 2.8254 | Actual Loss: 0.4395\n",
      "Baseline Loss: 2.8590 | Actual Loss: 0.3176\n",
      "Baseline Loss: 2.8191 | Actual Loss: 2.1013\n",
      "Baseline Loss: 2.7530 | Actual Loss: 1.0077\n",
      "Baseline Loss: 2.8358 | Actual Loss: 0.2077\n",
      "Baseline Loss: 2.8050 | Actual Loss: 0.1763\n",
      "Baseline Loss: 2.7683 | Actual Loss: 0.3985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 120/1000 [00:56<06:59,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8474 | Actual Loss: 0.2756\n",
      "Baseline Loss: 2.6272 | Actual Loss: 2.3233\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.9121\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.4297\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.4639\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.4730\n",
      "Epoch 120/1000: Train Loss: 0.6299, Val Loss: 0.5697\n",
      "Baseline Loss: 2.8217 | Actual Loss: 0.5325\n",
      "Baseline Loss: 2.8929 | Actual Loss: 0.2379\n",
      "Baseline Loss: 2.8762 | Actual Loss: 0.5075\n",
      "Baseline Loss: 2.8440 | Actual Loss: 0.5188\n",
      "Baseline Loss: 2.8012 | Actual Loss: 0.3004\n",
      "Baseline Loss: 2.8086 | Actual Loss: 0.4986\n",
      "Baseline Loss: 2.8358 | Actual Loss: 0.4318\n",
      "Baseline Loss: 2.8595 | Actual Loss: 0.3258\n",
      "Baseline Loss: 2.8144 | Actual Loss: 0.4205\n",
      "Baseline Loss: 2.8318 | Actual Loss: 0.1115\n",
      "Baseline Loss: 2.8530 | Actual Loss: 0.4681\n",
      "Baseline Loss: 2.7792 | Actual Loss: 0.4976\n",
      "Baseline Loss: 2.9112 | Actual Loss: 2.1189\n",
      "Baseline Loss: 2.7964 | Actual Loss: 0.4859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 120/1000 [00:57<06:58,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8336 | Actual Loss: 0.3405\n",
      "Baseline Loss: 2.5939 | Actual Loss: 0.0814\n",
      "Baseline Loss: 2.8280 | Actual Loss: 1.0957\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.3147\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.5225\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.5069\n",
      "Epoch 121/1000: Train Loss: 0.4924, Val Loss: 0.6099\n",
      "\n",
      "Early stopping at epoch 121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5122599080204964"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devices = [\"cuda\" if torch.cuda.is_available() else \"cpu\"]\n",
    "model4 = GNNModelWithNewLoss(\n",
    "        num_node_features=data_list[0].x.shape[1],\n",
    "        num_edge_features=data_list[0].edge_attr.shape[1],\n",
    "        num_global_features=data_list[0].global_features.shape[1],\n",
    "        cov_num= 6,\n",
    "        hidden_dim=512,\n",
    "        dropout_rate=0.1,\n",
    "        property_index=0 ,\n",
    "        save_path= 'premodels_new/6/0' \n",
    "    ).to(devices[0])\n",
    "\n",
    "model4.train_model(\n",
    "    data_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea51dc95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training will be saved to: premodels_new/6/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6957 | Actual Loss: 2.6864\n",
      "Baseline Loss: 2.6897 | Actual Loss: 2.6888\n",
      "Baseline Loss: 2.7022 | Actual Loss: 2.6921\n",
      "Baseline Loss: 2.6635 | Actual Loss: 2.6510\n",
      "Baseline Loss: 2.6812 | Actual Loss: 2.6588\n",
      "Baseline Loss: 2.6425 | Actual Loss: 2.5949\n",
      "Baseline Loss: 2.6566 | Actual Loss: 2.6044\n",
      "Baseline Loss: 2.6623 | Actual Loss: 2.6095\n",
      "Baseline Loss: 2.6965 | Actual Loss: 2.6761\n",
      "Baseline Loss: 2.6691 | Actual Loss: 2.6563\n",
      "Baseline Loss: 2.6883 | Actual Loss: 2.6412\n",
      "Baseline Loss: 2.6961 | Actual Loss: 2.6566\n",
      "Baseline Loss: 2.6820 | Actual Loss: 2.6336\n",
      "Baseline Loss: 2.6923 | Actual Loss: 2.6559\n",
      "Baseline Loss: 2.6555 | Actual Loss: 2.6301\n",
      "Baseline Loss: 2.3237 | Actual Loss: 2.2773\n",
      "Baseline Loss: 2.6263 | Actual Loss: 2.6070\n",
      "Baseline Loss: 2.7243 | Actual Loss: 2.6697\n",
      "Baseline Loss: 2.6758 | Actual Loss: 2.6690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 1/1000 [00:00<08:19,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5648 | Actual Loss: 2.5390\n",
      "Epoch 1/1000: Train Loss: 2.6258, Val Loss: 2.6212\n",
      "New best validation loss: 2.6212\n",
      "Baseline Loss: 2.6596 | Actual Loss: 2.6033\n",
      "Baseline Loss: 2.6575 | Actual Loss: 2.6010\n",
      "Baseline Loss: 2.6635 | Actual Loss: 2.6279\n",
      "Baseline Loss: 2.6500 | Actual Loss: 2.6246\n",
      "Baseline Loss: 2.6862 | Actual Loss: 2.6335\n",
      "Baseline Loss: 2.7358 | Actual Loss: 2.7140\n",
      "Baseline Loss: 2.7041 | Actual Loss: 2.6523\n",
      "Baseline Loss: 2.6517 | Actual Loss: 2.5556\n",
      "Baseline Loss: 2.6645 | Actual Loss: 2.5843\n",
      "Baseline Loss: 2.6315 | Actual Loss: 2.5941\n",
      "Baseline Loss: 2.6678 | Actual Loss: 2.6381\n",
      "Baseline Loss: 2.7138 | Actual Loss: 2.6578\n",
      "Baseline Loss: 2.7122 | Actual Loss: 2.6374\n",
      "Baseline Loss: 2.7115 | Actual Loss: 2.6086\n",
      "Baseline Loss: 2.6783 | Actual Loss: 2.5630\n",
      "Baseline Loss: 2.2496 | Actual Loss: 2.1287\n",
      "Baseline Loss: 2.6263 | Actual Loss: 2.5297\n",
      "Baseline Loss: 2.7243 | Actual Loss: 2.6044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 2/1000 [00:01<08:23,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6758 | Actual Loss: 2.5288\n",
      "Baseline Loss: 2.5648 | Actual Loss: 2.4439\n",
      "Epoch 2/1000: Train Loss: 2.5890, Val Loss: 2.5267\n",
      "New best validation loss: 2.5267\n",
      "Baseline Loss: 2.6599 | Actual Loss: 2.5541\n",
      "Baseline Loss: 2.6897 | Actual Loss: 2.5889\n",
      "Baseline Loss: 2.6499 | Actual Loss: 2.5411\n",
      "Baseline Loss: 2.7389 | Actual Loss: 2.6621\n",
      "Baseline Loss: 2.6692 | Actual Loss: 2.5599\n",
      "Baseline Loss: 2.6274 | Actual Loss: 2.5047\n",
      "Baseline Loss: 2.6647 | Actual Loss: 2.5366\n",
      "Baseline Loss: 2.7028 | Actual Loss: 2.5124\n",
      "Baseline Loss: 2.7040 | Actual Loss: 2.5243\n",
      "Baseline Loss: 2.6513 | Actual Loss: 2.5407\n",
      "Baseline Loss: 2.6951 | Actual Loss: 2.5828\n",
      "Baseline Loss: 2.6391 | Actual Loss: 2.4627\n",
      "Baseline Loss: 2.7169 | Actual Loss: 2.5450\n",
      "Baseline Loss: 2.6737 | Actual Loss: 2.5440\n",
      "Baseline Loss: 2.6522 | Actual Loss: 2.4281\n",
      "Baseline Loss: 2.3613 | Actual Loss: 2.1712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 3/1000 [00:01<07:50,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6263 | Actual Loss: 2.3945\n",
      "Baseline Loss: 2.7243 | Actual Loss: 2.3564\n",
      "Baseline Loss: 2.6758 | Actual Loss: 2.5650\n",
      "Baseline Loss: 2.5648 | Actual Loss: 2.3815\n",
      "Epoch 3/1000: Train Loss: 2.5162, Val Loss: 2.4244\n",
      "New best validation loss: 2.4244\n",
      "Baseline Loss: 2.7094 | Actual Loss: 2.4586\n",
      "Baseline Loss: 2.6570 | Actual Loss: 2.3320\n",
      "Baseline Loss: 2.6846 | Actual Loss: 2.4090\n",
      "Baseline Loss: 2.6688 | Actual Loss: 2.3104\n",
      "Baseline Loss: 2.6743 | Actual Loss: 2.3600\n",
      "Baseline Loss: 2.6771 | Actual Loss: 2.4551\n",
      "Baseline Loss: 2.6806 | Actual Loss: 2.2947\n",
      "Baseline Loss: 2.7011 | Actual Loss: 2.3660\n",
      "Baseline Loss: 2.6718 | Actual Loss: 2.2498\n",
      "Baseline Loss: 2.6697 | Actual Loss: 2.4114\n",
      "Baseline Loss: 2.6558 | Actual Loss: 2.2389\n",
      "Baseline Loss: 2.6642 | Actual Loss: 2.1188\n",
      "Baseline Loss: 2.6741 | Actual Loss: 2.3071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 4/1000 [00:01<07:54,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6474 | Actual Loss: 2.2754\n",
      "Baseline Loss: 2.6894 | Actual Loss: 2.0761\n",
      "Baseline Loss: 2.2295 | Actual Loss: 1.7768\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.9835\n",
      "Baseline Loss: 2.7243 | Actual Loss: 2.1190\n",
      "Baseline Loss: 2.6758 | Actual Loss: 2.0955\n",
      "Baseline Loss: 2.5648 | Actual Loss: 1.9357\n",
      "Epoch 4/1000: Train Loss: 2.2775, Val Loss: 2.0334\n",
      "New best validation loss: 2.0334\n",
      "Baseline Loss: 2.6755 | Actual Loss: 2.0880\n",
      "Baseline Loss: 2.7219 | Actual Loss: 1.9620\n",
      "Baseline Loss: 2.6864 | Actual Loss: 1.9433\n",
      "Baseline Loss: 2.6661 | Actual Loss: 2.0274\n",
      "Baseline Loss: 2.6452 | Actual Loss: 2.2034\n",
      "Baseline Loss: 2.6678 | Actual Loss: 1.9646\n",
      "Baseline Loss: 2.6903 | Actual Loss: 2.1388\n",
      "Baseline Loss: 2.6653 | Actual Loss: 1.8357\n",
      "Baseline Loss: 2.6524 | Actual Loss: 1.7914\n",
      "Baseline Loss: 2.6702 | Actual Loss: 2.0334\n",
      "Baseline Loss: 2.6625 | Actual Loss: 1.7908\n",
      "Baseline Loss: 2.7031 | Actual Loss: 1.9693\n",
      "Baseline Loss: 2.6383 | Actual Loss: 1.8199\n",
      "Baseline Loss: 2.6450 | Actual Loss: 1.5956\n",
      "Baseline Loss: 2.7037 | Actual Loss: 1.7897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 5/1000 [00:02<07:34,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2654 | Actual Loss: 1.5277\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.7936\n",
      "Baseline Loss: 2.7243 | Actual Loss: 1.4348\n",
      "Baseline Loss: 2.6758 | Actual Loss: 1.6386\n",
      "Baseline Loss: 2.5648 | Actual Loss: 1.5046\n",
      "Epoch 5/1000: Train Loss: 1.9051, Val Loss: 1.5929\n",
      "New best validation loss: 1.5929\n",
      "Baseline Loss: 2.6901 | Actual Loss: 1.9896\n",
      "Baseline Loss: 2.6805 | Actual Loss: 1.7673\n",
      "Baseline Loss: 2.6636 | Actual Loss: 1.5463\n",
      "Baseline Loss: 2.6593 | Actual Loss: 1.5419\n",
      "Baseline Loss: 2.7072 | Actual Loss: 1.6421\n",
      "Baseline Loss: 2.6482 | Actual Loss: 1.5593\n",
      "Baseline Loss: 2.6943 | Actual Loss: 1.6100\n",
      "Baseline Loss: 2.6947 | Actual Loss: 1.8755\n",
      "Baseline Loss: 2.7019 | Actual Loss: 1.6175\n",
      "Baseline Loss: 2.6867 | Actual Loss: 1.6519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 6/1000 [00:02<07:55,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6626 | Actual Loss: 1.5553\n",
      "Baseline Loss: 2.6925 | Actual Loss: 1.7262\n",
      "Baseline Loss: 2.6532 | Actual Loss: 1.7268\n",
      "Baseline Loss: 2.6780 | Actual Loss: 1.4698\n",
      "Baseline Loss: 2.6724 | Actual Loss: 1.5901\n",
      "Baseline Loss: 2.3421 | Actual Loss: 1.0732\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.4414\n",
      "Baseline Loss: 2.7243 | Actual Loss: 1.7807\n",
      "Baseline Loss: 2.6758 | Actual Loss: 1.4288\n",
      "Baseline Loss: 2.5648 | Actual Loss: 1.1692\n",
      "Epoch 6/1000: Train Loss: 1.6214, Val Loss: 1.4550\n",
      "New best validation loss: 1.4550\n",
      "Baseline Loss: 2.7005 | Actual Loss: 1.4473\n",
      "Baseline Loss: 2.6378 | Actual Loss: 1.4590\n",
      "Baseline Loss: 2.6877 | Actual Loss: 1.2654\n",
      "Baseline Loss: 2.6913 | Actual Loss: 1.5162\n",
      "Baseline Loss: 2.6400 | Actual Loss: 1.4771\n",
      "Baseline Loss: 2.6463 | Actual Loss: 1.5807\n",
      "Baseline Loss: 2.7116 | Actual Loss: 1.3877\n",
      "Baseline Loss: 2.6732 | Actual Loss: 1.6100\n",
      "Baseline Loss: 2.7088 | Actual Loss: 1.4760\n",
      "Baseline Loss: 2.6833 | Actual Loss: 1.2766\n",
      "Baseline Loss: 2.6765 | Actual Loss: 1.4511\n",
      "Baseline Loss: 2.6689 | Actual Loss: 1.4699\n",
      "Baseline Loss: 2.7079 | Actual Loss: 1.4810\n",
      "Baseline Loss: 2.6598 | Actual Loss: 1.3117\n",
      "Baseline Loss: 2.6573 | Actual Loss: 1.5324\n",
      "Baseline Loss: 2.2305 | Actual Loss: 1.0199\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.5080\n",
      "Baseline Loss: 2.7243 | Actual Loss: 1.3890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 7/1000 [00:03<07:55,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6758 | Actual Loss: 1.3185\n",
      "Baseline Loss: 2.5648 | Actual Loss: 1.1951\n",
      "Epoch 7/1000: Train Loss: 1.4226, Val Loss: 1.3527\n",
      "New best validation loss: 1.3527\n",
      "Baseline Loss: 2.6698 | Actual Loss: 1.4737\n",
      "Baseline Loss: 2.6816 | Actual Loss: 1.6228\n",
      "Baseline Loss: 2.6458 | Actual Loss: 1.3841\n",
      "Baseline Loss: 2.6782 | Actual Loss: 1.3763\n",
      "Baseline Loss: 2.7037 | Actual Loss: 1.4036\n",
      "Baseline Loss: 2.7078 | Actual Loss: 1.6104\n",
      "Baseline Loss: 2.6786 | Actual Loss: 1.3564\n",
      "Baseline Loss: 2.6844 | Actual Loss: 1.4492\n",
      "Baseline Loss: 2.6718 | Actual Loss: 1.5348\n",
      "Baseline Loss: 2.6692 | Actual Loss: 1.7996\n",
      "Baseline Loss: 2.6518 | Actual Loss: 1.5718\n",
      "Baseline Loss: 2.6407 | Actual Loss: 1.5593\n",
      "Baseline Loss: 2.6524 | Actual Loss: 1.6735\n",
      "Baseline Loss: 2.6728 | Actual Loss: 1.5138\n",
      "Baseline Loss: 2.6609 | Actual Loss: 1.4011\n",
      "Baseline Loss: 2.3515 | Actual Loss: 0.7876\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.3040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 8/1000 [00:03<08:10,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7243 | Actual Loss: 1.2213\n",
      "Baseline Loss: 2.6758 | Actual Loss: 1.4675\n",
      "Baseline Loss: 2.5648 | Actual Loss: 1.1615\n",
      "Epoch 8/1000: Train Loss: 1.4699, Val Loss: 1.2886\n",
      "New best validation loss: 1.2886\n",
      "Baseline Loss: 2.6653 | Actual Loss: 1.2443\n",
      "Baseline Loss: 2.6909 | Actual Loss: 1.5495\n",
      "Baseline Loss: 2.6311 | Actual Loss: 1.3719\n",
      "Baseline Loss: 2.7171 | Actual Loss: 1.1145\n",
      "Baseline Loss: 2.6763 | Actual Loss: 1.2099\n",
      "Baseline Loss: 2.6820 | Actual Loss: 1.1613\n",
      "Baseline Loss: 2.6329 | Actual Loss: 1.4797\n",
      "Baseline Loss: 2.6691 | Actual Loss: 1.3267\n",
      "Baseline Loss: 2.6688 | Actual Loss: 1.1174\n",
      "Baseline Loss: 2.6163 | Actual Loss: 1.6091\n",
      "Baseline Loss: 2.6671 | Actual Loss: 1.2979\n",
      "Baseline Loss: 2.7159 | Actual Loss: 1.6694\n",
      "Baseline Loss: 2.6619 | Actual Loss: 1.4475\n",
      "Baseline Loss: 2.7267 | Actual Loss: 1.3744\n",
      "Baseline Loss: 2.6524 | Actual Loss: 1.5706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 9/1000 [00:04<07:50,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2597 | Actual Loss: 1.0251\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.2076\n",
      "Baseline Loss: 2.7243 | Actual Loss: 1.4067\n",
      "Baseline Loss: 2.6758 | Actual Loss: 1.2708\n",
      "Baseline Loss: 2.5648 | Actual Loss: 1.1163\n",
      "Epoch 9/1000: Train Loss: 1.3481, Val Loss: 1.2503\n",
      "New best validation loss: 1.2503\n",
      "Baseline Loss: 2.7019 | Actual Loss: 1.4723\n",
      "Baseline Loss: 2.6664 | Actual Loss: 1.3304\n",
      "Baseline Loss: 2.7041 | Actual Loss: 1.4113\n",
      "Baseline Loss: 2.7156 | Actual Loss: 1.4441\n",
      "Baseline Loss: 2.7394 | Actual Loss: 1.2438\n",
      "Baseline Loss: 2.6503 | Actual Loss: 1.1655\n",
      "Baseline Loss: 2.6642 | Actual Loss: 1.2798\n",
      "Baseline Loss: 2.6508 | Actual Loss: 1.3288\n",
      "Baseline Loss: 2.6693 | Actual Loss: 1.1844\n",
      "Baseline Loss: 2.6664 | Actual Loss: 1.2018\n",
      "Baseline Loss: 2.6627 | Actual Loss: 1.4765\n",
      "Baseline Loss: 2.6565 | Actual Loss: 1.5225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 10/1000 [00:04<07:48,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6596 | Actual Loss: 1.4139\n",
      "Baseline Loss: 2.7242 | Actual Loss: 1.7291\n",
      "Baseline Loss: 2.6771 | Actual Loss: 1.5588\n",
      "Baseline Loss: 2.2135 | Actual Loss: 0.9108\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.4766\n",
      "Baseline Loss: 2.7243 | Actual Loss: 1.2590\n",
      "Baseline Loss: 2.6758 | Actual Loss: 1.2963\n",
      "Baseline Loss: 2.5648 | Actual Loss: 1.0295\n",
      "Epoch 10/1000: Train Loss: 1.3546, Val Loss: 1.2654\n",
      "Baseline Loss: 2.6913 | Actual Loss: 1.4066\n",
      "Baseline Loss: 2.6689 | Actual Loss: 1.2134\n",
      "Baseline Loss: 2.6576 | Actual Loss: 1.3849\n",
      "Baseline Loss: 2.6749 | Actual Loss: 1.4732\n",
      "Baseline Loss: 2.7328 | Actual Loss: 1.5020\n",
      "Baseline Loss: 2.6843 | Actual Loss: 1.2327\n",
      "Baseline Loss: 2.6557 | Actual Loss: 1.3785\n",
      "Baseline Loss: 2.6348 | Actual Loss: 1.2710\n",
      "Baseline Loss: 2.6584 | Actual Loss: 1.2489\n",
      "Baseline Loss: 2.6349 | Actual Loss: 1.2846\n",
      "Baseline Loss: 2.7164 | Actual Loss: 1.4095\n",
      "Baseline Loss: 2.6705 | Actual Loss: 1.5274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 11/1000 [00:05<07:56,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6582 | Actual Loss: 1.5961\n",
      "Baseline Loss: 2.7104 | Actual Loss: 1.4042\n",
      "Baseline Loss: 2.7171 | Actual Loss: 1.3522\n",
      "Baseline Loss: 2.2084 | Actual Loss: 0.7031\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.0886\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.9676\n",
      "Baseline Loss: 2.6758 | Actual Loss: 1.0311\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.9931\n",
      "Epoch 11/1000: Train Loss: 1.3368, Val Loss: 1.0201\n",
      "New best validation loss: 1.0201\n",
      "Baseline Loss: 2.6537 | Actual Loss: 1.3775\n",
      "Baseline Loss: 2.6717 | Actual Loss: 1.1678\n",
      "Baseline Loss: 2.6481 | Actual Loss: 1.0992\n",
      "Baseline Loss: 2.7413 | Actual Loss: 1.2183\n",
      "Baseline Loss: 2.7202 | Actual Loss: 1.0454\n",
      "Baseline Loss: 2.7157 | Actual Loss: 1.4045\n",
      "Baseline Loss: 2.7248 | Actual Loss: 1.1232\n",
      "Baseline Loss: 2.6681 | Actual Loss: 1.2306\n",
      "Baseline Loss: 2.6727 | Actual Loss: 1.1990\n",
      "Baseline Loss: 2.6516 | Actual Loss: 1.4658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 12/1000 [00:05<07:40,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6884 | Actual Loss: 1.2638\n",
      "Baseline Loss: 2.6784 | Actual Loss: 1.3910\n",
      "Baseline Loss: 2.6281 | Actual Loss: 1.0261\n",
      "Baseline Loss: 2.6930 | Actual Loss: 1.4656\n",
      "Baseline Loss: 2.6833 | Actual Loss: 1.4129\n",
      "Baseline Loss: 2.2678 | Actual Loss: 1.0361\n",
      "Baseline Loss: 2.6263 | Actual Loss: 0.9971\n",
      "Baseline Loss: 2.7243 | Actual Loss: 1.0685\n",
      "Baseline Loss: 2.6758 | Actual Loss: 1.1107\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.8304\n",
      "Epoch 12/1000: Train Loss: 1.2454, Val Loss: 1.0017\n",
      "New best validation loss: 1.0017\n",
      "Baseline Loss: 2.6758 | Actual Loss: 1.3684\n",
      "Baseline Loss: 2.6659 | Actual Loss: 1.3112\n",
      "Baseline Loss: 2.6474 | Actual Loss: 1.0169\n",
      "Baseline Loss: 2.7576 | Actual Loss: 1.0697\n",
      "Baseline Loss: 2.6818 | Actual Loss: 1.3982\n",
      "Baseline Loss: 2.6820 | Actual Loss: 1.7875\n",
      "Baseline Loss: 2.6808 | Actual Loss: 2.1426\n",
      "Baseline Loss: 2.6544 | Actual Loss: 1.5829\n",
      "Baseline Loss: 2.7020 | Actual Loss: 1.1363\n",
      "Baseline Loss: 2.6273 | Actual Loss: 1.4709\n",
      "Baseline Loss: 2.6821 | Actual Loss: 1.3541\n",
      "Baseline Loss: 2.7205 | Actual Loss: 1.0705\n",
      "Baseline Loss: 2.6717 | Actual Loss: 1.0434\n",
      "Baseline Loss: 2.6680 | Actual Loss: 1.2348\n",
      "Baseline Loss: 2.6864 | Actual Loss: 1.1859\n",
      "Baseline Loss: 2.2744 | Actual Loss: 0.8195\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.2565\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.9903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏         | 13/1000 [00:06<07:40,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6758 | Actual Loss: 1.1605\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.9915\n",
      "Epoch 13/1000: Train Loss: 1.3121, Val Loss: 1.0997\n",
      "Baseline Loss: 2.7012 | Actual Loss: 1.4128\n",
      "Baseline Loss: 2.6888 | Actual Loss: 1.2368\n",
      "Baseline Loss: 2.6870 | Actual Loss: 1.2552\n",
      "Baseline Loss: 2.6536 | Actual Loss: 1.5595\n",
      "Baseline Loss: 2.6645 | Actual Loss: 1.0095\n",
      "Baseline Loss: 2.6822 | Actual Loss: 1.1888\n",
      "Baseline Loss: 2.7310 | Actual Loss: 1.0808\n",
      "Baseline Loss: 2.6486 | Actual Loss: 1.1463\n",
      "Baseline Loss: 2.6940 | Actual Loss: 1.0633\n",
      "Baseline Loss: 2.6895 | Actual Loss: 1.2114\n",
      "Baseline Loss: 2.6637 | Actual Loss: 0.9254\n",
      "Baseline Loss: 2.6754 | Actual Loss: 1.0093\n",
      "Baseline Loss: 2.6569 | Actual Loss: 1.1844\n",
      "Baseline Loss: 2.7163 | Actual Loss: 1.3679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏         | 14/1000 [00:06<07:57,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6524 | Actual Loss: 1.1532\n",
      "Baseline Loss: 2.3116 | Actual Loss: 1.1057\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.2645\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.9891\n",
      "Baseline Loss: 2.6758 | Actual Loss: 1.1637\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.9309\n",
      "Epoch 14/1000: Train Loss: 1.1819, Val Loss: 1.0870\n",
      "Baseline Loss: 2.6596 | Actual Loss: 1.0549\n",
      "Baseline Loss: 2.6679 | Actual Loss: 1.3434\n",
      "Baseline Loss: 2.6284 | Actual Loss: 1.3140\n",
      "Baseline Loss: 2.6546 | Actual Loss: 1.2710\n",
      "Baseline Loss: 2.6795 | Actual Loss: 1.4131\n",
      "Baseline Loss: 2.6658 | Actual Loss: 1.0891\n",
      "Baseline Loss: 2.6921 | Actual Loss: 1.2518\n",
      "Baseline Loss: 2.6937 | Actual Loss: 1.3369\n",
      "Baseline Loss: 2.6893 | Actual Loss: 1.4137\n",
      "Baseline Loss: 2.6691 | Actual Loss: 1.2291\n",
      "Baseline Loss: 2.6992 | Actual Loss: 1.2248\n",
      "Baseline Loss: 2.6695 | Actual Loss: 1.0219\n",
      "Baseline Loss: 2.6640 | Actual Loss: 1.1397\n",
      "Baseline Loss: 2.7168 | Actual Loss: 1.1356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 15/1000 [00:07<07:42,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6774 | Actual Loss: 1.0905\n",
      "Baseline Loss: 2.2695 | Actual Loss: 0.8464\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.2358\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.9771\n",
      "Baseline Loss: 2.6758 | Actual Loss: 1.3233\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.9857\n",
      "Epoch 15/1000: Train Loss: 1.1985, Val Loss: 1.1305\n",
      "Baseline Loss: 2.7168 | Actual Loss: 1.2362\n",
      "Baseline Loss: 2.6755 | Actual Loss: 1.1936\n",
      "Baseline Loss: 2.6851 | Actual Loss: 1.7939\n",
      "Baseline Loss: 2.6734 | Actual Loss: 1.4258\n",
      "Baseline Loss: 2.6928 | Actual Loss: 1.0347\n",
      "Baseline Loss: 2.6558 | Actual Loss: 1.0023\n",
      "Baseline Loss: 2.7020 | Actual Loss: 1.2655\n",
      "Baseline Loss: 2.6629 | Actual Loss: 1.2331\n",
      "Baseline Loss: 2.6659 | Actual Loss: 1.2322\n",
      "Baseline Loss: 2.6695 | Actual Loss: 1.2748\n",
      "Baseline Loss: 2.7203 | Actual Loss: 0.9421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 16/1000 [00:07<07:44,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6197 | Actual Loss: 1.2837\n",
      "Baseline Loss: 2.6437 | Actual Loss: 0.9310\n",
      "Baseline Loss: 2.7091 | Actual Loss: 1.0541\n",
      "Baseline Loss: 2.6985 | Actual Loss: 1.2349\n",
      "Baseline Loss: 2.3080 | Actual Loss: 1.2282\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.4351\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.7942\n",
      "Baseline Loss: 2.6758 | Actual Loss: 1.1413\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.8145\n",
      "Epoch 16/1000: Train Loss: 1.2104, Val Loss: 1.0463\n",
      "Baseline Loss: 2.6359 | Actual Loss: 1.5130\n",
      "Baseline Loss: 2.6878 | Actual Loss: 0.9449\n",
      "Baseline Loss: 2.7211 | Actual Loss: 1.4462\n",
      "Baseline Loss: 2.6674 | Actual Loss: 1.2138\n",
      "Baseline Loss: 2.6920 | Actual Loss: 1.1496\n",
      "Baseline Loss: 2.6610 | Actual Loss: 1.2969\n",
      "Baseline Loss: 2.6433 | Actual Loss: 1.0863\n",
      "Baseline Loss: 2.6890 | Actual Loss: 1.1492\n",
      "Baseline Loss: 2.6408 | Actual Loss: 1.3699\n",
      "Baseline Loss: 2.6635 | Actual Loss: 1.2401\n",
      "Baseline Loss: 2.6457 | Actual Loss: 0.9808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 17/1000 [00:08<07:29,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6612 | Actual Loss: 0.9316\n",
      "Baseline Loss: 2.6757 | Actual Loss: 1.2218\n",
      "Baseline Loss: 2.6455 | Actual Loss: 1.2339\n",
      "Baseline Loss: 2.6912 | Actual Loss: 0.6788\n",
      "Baseline Loss: 2.3823 | Actual Loss: 0.5552\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.1569\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.8118\n",
      "Baseline Loss: 2.6758 | Actual Loss: 1.1810\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.6385\n",
      "Epoch 17/1000: Train Loss: 1.1258, Val Loss: 0.9471\n",
      "New best validation loss: 0.9471\n",
      "Baseline Loss: 2.6532 | Actual Loss: 1.0948\n",
      "Baseline Loss: 2.6593 | Actual Loss: 0.9592\n",
      "Baseline Loss: 2.6778 | Actual Loss: 1.0591\n",
      "Baseline Loss: 2.6730 | Actual Loss: 1.0027\n",
      "Baseline Loss: 2.6782 | Actual Loss: 1.2110\n",
      "Baseline Loss: 2.6365 | Actual Loss: 0.6529\n",
      "Baseline Loss: 2.6714 | Actual Loss: 1.0676\n",
      "Baseline Loss: 2.6647 | Actual Loss: 1.8699\n",
      "Baseline Loss: 2.7158 | Actual Loss: 1.1203\n",
      "Baseline Loss: 2.7107 | Actual Loss: 1.1173\n",
      "Baseline Loss: 2.6729 | Actual Loss: 0.7106\n",
      "Baseline Loss: 2.6516 | Actual Loss: 1.1160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 18/1000 [00:08<07:40,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7088 | Actual Loss: 0.9287\n",
      "Baseline Loss: 2.6815 | Actual Loss: 1.0945\n",
      "Baseline Loss: 2.6700 | Actual Loss: 0.7941\n",
      "Baseline Loss: 2.2637 | Actual Loss: 1.1482\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.1248\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.9939\n",
      "Baseline Loss: 2.6758 | Actual Loss: 1.1009\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.5848\n",
      "Epoch 18/1000: Train Loss: 1.0592, Val Loss: 0.9511\n",
      "Baseline Loss: 2.6955 | Actual Loss: 1.2481\n",
      "Baseline Loss: 2.6713 | Actual Loss: 0.9829\n",
      "Baseline Loss: 2.6475 | Actual Loss: 0.8107\n",
      "Baseline Loss: 2.6717 | Actual Loss: 0.8100\n",
      "Baseline Loss: 2.6347 | Actual Loss: 1.1596\n",
      "Baseline Loss: 2.6866 | Actual Loss: 0.8440\n",
      "Baseline Loss: 2.6711 | Actual Loss: 1.2600\n",
      "Baseline Loss: 2.6607 | Actual Loss: 0.9543\n",
      "Baseline Loss: 2.6821 | Actual Loss: 0.8963\n",
      "Baseline Loss: 2.7048 | Actual Loss: 0.9018\n",
      "Baseline Loss: 2.6872 | Actual Loss: 1.1042\n",
      "Baseline Loss: 2.6868 | Actual Loss: 0.9494\n",
      "Baseline Loss: 2.6380 | Actual Loss: 0.9241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 19/1000 [00:08<07:25,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6873 | Actual Loss: 1.2266\n",
      "Baseline Loss: 2.7086 | Actual Loss: 1.1975\n",
      "Baseline Loss: 2.2815 | Actual Loss: 0.6872\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.2112\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.8498\n",
      "Baseline Loss: 2.6758 | Actual Loss: 1.1520\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.8487\n",
      "Epoch 19/1000: Train Loss: 0.9973, Val Loss: 1.0154\n",
      "Baseline Loss: 2.7085 | Actual Loss: 1.1211\n",
      "Baseline Loss: 2.6564 | Actual Loss: 0.7515\n",
      "Baseline Loss: 2.6638 | Actual Loss: 1.3533\n",
      "Baseline Loss: 2.6612 | Actual Loss: 1.3438\n",
      "Baseline Loss: 2.6461 | Actual Loss: 1.1554\n",
      "Baseline Loss: 2.7053 | Actual Loss: 1.8154\n",
      "Baseline Loss: 2.6657 | Actual Loss: 1.0021\n",
      "Baseline Loss: 2.6458 | Actual Loss: 0.8122\n",
      "Baseline Loss: 2.7025 | Actual Loss: 1.1860\n",
      "Baseline Loss: 2.7109 | Actual Loss: 0.9928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 20/1000 [00:09<07:32,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7088 | Actual Loss: 0.7636\n",
      "Baseline Loss: 2.6709 | Actual Loss: 0.8825\n",
      "Baseline Loss: 2.6570 | Actual Loss: 1.2527\n",
      "Baseline Loss: 2.6928 | Actual Loss: 0.8500\n",
      "Baseline Loss: 2.6624 | Actual Loss: 1.2881\n",
      "Baseline Loss: 2.2815 | Actual Loss: 1.2825\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.0958\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.9181\n",
      "Baseline Loss: 2.6758 | Actual Loss: 1.2182\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.6978\n",
      "Epoch 20/1000: Train Loss: 1.1158, Val Loss: 0.9825\n",
      "Baseline Loss: 2.6821 | Actual Loss: 1.0669\n",
      "Baseline Loss: 2.6610 | Actual Loss: 1.1291\n",
      "Baseline Loss: 2.6654 | Actual Loss: 1.3444\n",
      "Baseline Loss: 2.6809 | Actual Loss: 0.8468\n",
      "Baseline Loss: 2.6836 | Actual Loss: 1.0180\n",
      "Baseline Loss: 2.6532 | Actual Loss: 0.6915\n",
      "Baseline Loss: 2.6863 | Actual Loss: 0.9561\n",
      "Baseline Loss: 2.6621 | Actual Loss: 1.1567\n",
      "Baseline Loss: 2.7108 | Actual Loss: 1.1893\n",
      "Baseline Loss: 2.6394 | Actual Loss: 1.0515\n",
      "Baseline Loss: 2.6867 | Actual Loss: 0.6734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 21/1000 [00:09<07:45,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7094 | Actual Loss: 1.4185\n",
      "Baseline Loss: 2.6719 | Actual Loss: 0.9419\n",
      "Baseline Loss: 2.6541 | Actual Loss: 1.4379\n",
      "Baseline Loss: 2.7047 | Actual Loss: 1.1159\n",
      "Baseline Loss: 2.2102 | Actual Loss: 0.5967\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.1475\n",
      "Baseline Loss: 2.7243 | Actual Loss: 1.2188\n",
      "Baseline Loss: 2.6758 | Actual Loss: 1.1893\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.8048\n",
      "Epoch 21/1000: Train Loss: 1.0397, Val Loss: 1.0901\n",
      "Baseline Loss: 2.6621 | Actual Loss: 1.1997\n",
      "Baseline Loss: 2.6938 | Actual Loss: 1.1284\n",
      "Baseline Loss: 2.6898 | Actual Loss: 0.7864\n",
      "Baseline Loss: 2.6971 | Actual Loss: 0.8379\n",
      "Baseline Loss: 2.6781 | Actual Loss: 0.8689\n",
      "Baseline Loss: 2.6481 | Actual Loss: 0.7411\n",
      "Baseline Loss: 2.6745 | Actual Loss: 1.1451\n",
      "Baseline Loss: 2.6709 | Actual Loss: 0.9879\n",
      "Baseline Loss: 2.6269 | Actual Loss: 1.0940\n",
      "Baseline Loss: 2.6598 | Actual Loss: 1.0413\n",
      "Baseline Loss: 2.6931 | Actual Loss: 1.6000\n",
      "Baseline Loss: 2.7039 | Actual Loss: 0.9348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 22/1000 [00:10<07:25,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6734 | Actual Loss: 0.8657\n",
      "Baseline Loss: 2.6787 | Actual Loss: 0.9391\n",
      "Baseline Loss: 2.6837 | Actual Loss: 0.7937\n",
      "Baseline Loss: 2.2987 | Actual Loss: 1.1807\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.2476\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.8292\n",
      "Baseline Loss: 2.6758 | Actual Loss: 1.2262\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.6778\n",
      "Epoch 22/1000: Train Loss: 1.0090, Val Loss: 0.9952\n",
      "Baseline Loss: 2.7096 | Actual Loss: 1.0176\n",
      "Baseline Loss: 2.6629 | Actual Loss: 1.1669\n",
      "Baseline Loss: 2.7095 | Actual Loss: 1.4938\n",
      "Baseline Loss: 2.7277 | Actual Loss: 1.0528\n",
      "Baseline Loss: 2.6774 | Actual Loss: 1.2719\n",
      "Baseline Loss: 2.6794 | Actual Loss: 1.2812\n",
      "Baseline Loss: 2.6810 | Actual Loss: 1.0756\n",
      "Baseline Loss: 2.6581 | Actual Loss: 0.6607\n",
      "Baseline Loss: 2.6657 | Actual Loss: 1.2559\n",
      "Baseline Loss: 2.6520 | Actual Loss: 1.0560\n",
      "Baseline Loss: 2.6826 | Actual Loss: 0.8698\n",
      "Baseline Loss: 2.6588 | Actual Loss: 0.8217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 23/1000 [00:10<07:30,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6670 | Actual Loss: 0.9975\n",
      "Baseline Loss: 2.6937 | Actual Loss: 1.0020\n",
      "Baseline Loss: 2.6862 | Actual Loss: 1.4677\n",
      "Baseline Loss: 2.2380 | Actual Loss: 0.6378\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.7492\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.9656\n",
      "Baseline Loss: 2.6758 | Actual Loss: 1.1993\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.7432\n",
      "Epoch 23/1000: Train Loss: 1.0706, Val Loss: 1.1643\n",
      "Baseline Loss: 2.6568 | Actual Loss: 1.1419\n",
      "Baseline Loss: 2.7107 | Actual Loss: 0.7104\n",
      "Baseline Loss: 2.7210 | Actual Loss: 0.6730\n",
      "Baseline Loss: 2.6685 | Actual Loss: 0.8163\n",
      "Baseline Loss: 2.6820 | Actual Loss: 0.5089\n",
      "Baseline Loss: 2.7046 | Actual Loss: 0.9898\n",
      "Baseline Loss: 2.6425 | Actual Loss: 1.0187\n",
      "Baseline Loss: 2.6373 | Actual Loss: 1.5291\n",
      "Baseline Loss: 2.6699 | Actual Loss: 1.1640\n",
      "Baseline Loss: 2.6975 | Actual Loss: 1.0034\n",
      "Baseline Loss: 2.6476 | Actual Loss: 1.1532\n",
      "Baseline Loss: 2.6939 | Actual Loss: 1.0831\n",
      "Baseline Loss: 2.6613 | Actual Loss: 1.1873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 24/1000 [00:11<07:40,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6709 | Actual Loss: 0.9602\n",
      "Baseline Loss: 2.6869 | Actual Loss: 1.2746\n",
      "Baseline Loss: 2.3580 | Actual Loss: 0.6441\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.1061\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.7507\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.9706\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4887\n",
      "Epoch 24/1000: Train Loss: 0.9911, Val Loss: 0.8290\n",
      "New best validation loss: 0.8290\n",
      "Baseline Loss: 2.6762 | Actual Loss: 1.4175\n",
      "Baseline Loss: 2.6529 | Actual Loss: 0.8390\n",
      "Baseline Loss: 2.6518 | Actual Loss: 0.8687\n",
      "Baseline Loss: 2.7156 | Actual Loss: 0.9276\n",
      "Baseline Loss: 2.6611 | Actual Loss: 0.8195\n",
      "Baseline Loss: 2.6736 | Actual Loss: 1.1156\n",
      "Baseline Loss: 2.6524 | Actual Loss: 0.6736\n",
      "Baseline Loss: 2.6501 | Actual Loss: 0.9312\n",
      "Baseline Loss: 2.6488 | Actual Loss: 1.1169\n",
      "Baseline Loss: 2.6978 | Actual Loss: 1.3909\n",
      "Baseline Loss: 2.6718 | Actual Loss: 1.3053\n",
      "Baseline Loss: 2.7144 | Actual Loss: 1.0328\n",
      "Baseline Loss: 2.6536 | Actual Loss: 0.6850\n",
      "Baseline Loss: 2.6865 | Actual Loss: 0.8856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▎         | 25/1000 [00:11<07:22,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7176 | Actual Loss: 0.7885\n",
      "Baseline Loss: 2.2502 | Actual Loss: 1.4001\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.1738\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.7105\n",
      "Baseline Loss: 2.6758 | Actual Loss: 1.1381\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4909\n",
      "Epoch 25/1000: Train Loss: 1.0123, Val Loss: 0.8783\n",
      "Baseline Loss: 2.6382 | Actual Loss: 1.1836\n",
      "Baseline Loss: 2.6657 | Actual Loss: 0.7266\n",
      "Baseline Loss: 2.7287 | Actual Loss: 0.6768\n",
      "Baseline Loss: 2.6304 | Actual Loss: 0.8154\n",
      "Baseline Loss: 2.7151 | Actual Loss: 0.8337\n",
      "Baseline Loss: 2.7037 | Actual Loss: 1.1644\n",
      "Baseline Loss: 2.6836 | Actual Loss: 0.7002\n",
      "Baseline Loss: 2.6893 | Actual Loss: 1.0136\n",
      "Baseline Loss: 2.6670 | Actual Loss: 0.9109\n",
      "Baseline Loss: 2.6786 | Actual Loss: 0.8781\n",
      "Baseline Loss: 2.6404 | Actual Loss: 0.8791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 26/1000 [00:12<07:34,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6711 | Actual Loss: 1.1128\n",
      "Baseline Loss: 2.7156 | Actual Loss: 1.0246\n",
      "Baseline Loss: 2.6985 | Actual Loss: 1.4072\n",
      "Baseline Loss: 2.6586 | Actual Loss: 0.7977\n",
      "Baseline Loss: 2.3328 | Actual Loss: 0.8149\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.1714\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.8962\n",
      "Baseline Loss: 2.6758 | Actual Loss: 1.0606\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.7117\n",
      "Epoch 26/1000: Train Loss: 0.9337, Val Loss: 0.9600\n",
      "Baseline Loss: 2.6816 | Actual Loss: 0.9761\n",
      "Baseline Loss: 2.7026 | Actual Loss: 0.8708\n",
      "Baseline Loss: 2.6884 | Actual Loss: 0.7692\n",
      "Baseline Loss: 2.6744 | Actual Loss: 0.8241\n",
      "Baseline Loss: 2.6761 | Actual Loss: 0.7056\n",
      "Baseline Loss: 2.6455 | Actual Loss: 0.5947\n",
      "Baseline Loss: 2.6298 | Actual Loss: 0.7195\n",
      "Baseline Loss: 2.6861 | Actual Loss: 1.4418\n",
      "Baseline Loss: 2.6884 | Actual Loss: 0.7777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 27/1000 [00:12<07:41,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7164 | Actual Loss: 0.6374\n",
      "Baseline Loss: 2.6859 | Actual Loss: 0.9181\n",
      "Baseline Loss: 2.7109 | Actual Loss: 0.8604\n",
      "Baseline Loss: 2.7021 | Actual Loss: 1.0128\n",
      "Baseline Loss: 2.6998 | Actual Loss: 1.3113\n",
      "Baseline Loss: 2.6353 | Actual Loss: 0.5921\n",
      "Baseline Loss: 2.2880 | Actual Loss: 0.8825\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.3061\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.7066\n",
      "Baseline Loss: 2.6758 | Actual Loss: 1.1747\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.5259\n",
      "Epoch 27/1000: Train Loss: 0.8684, Val Loss: 0.9283\n",
      "Baseline Loss: 2.7026 | Actual Loss: 0.9880\n",
      "Baseline Loss: 2.6760 | Actual Loss: 1.1183\n",
      "Baseline Loss: 2.6803 | Actual Loss: 0.7877\n",
      "Baseline Loss: 2.7008 | Actual Loss: 1.0321\n",
      "Baseline Loss: 2.7102 | Actual Loss: 0.4227\n",
      "Baseline Loss: 2.6597 | Actual Loss: 1.0254\n",
      "Baseline Loss: 2.6795 | Actual Loss: 0.7925\n",
      "Baseline Loss: 2.7322 | Actual Loss: 0.9919\n",
      "Baseline Loss: 2.6945 | Actual Loss: 1.0534\n",
      "Baseline Loss: 2.6483 | Actual Loss: 1.0596\n",
      "Baseline Loss: 2.6526 | Actual Loss: 1.9716\n",
      "Baseline Loss: 2.6704 | Actual Loss: 1.4457\n",
      "Baseline Loss: 2.6700 | Actual Loss: 1.0241\n",
      "Baseline Loss: 2.6613 | Actual Loss: 0.4315\n",
      "Baseline Loss: 2.6491 | Actual Loss: 0.7967\n",
      "Baseline Loss: 2.2215 | Actual Loss: 1.0167\n",
      "Baseline Loss: 2.6263 | Actual Loss: 0.9530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 28/1000 [00:13<07:53,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7243 | Actual Loss: 0.6547\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.9144\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.5341\n",
      "Epoch 28/1000: Train Loss: 0.9974, Val Loss: 0.7640\n",
      "New best validation loss: 0.7640\n",
      "Baseline Loss: 2.6824 | Actual Loss: 1.0449\n",
      "Baseline Loss: 2.6762 | Actual Loss: 1.2929\n",
      "Baseline Loss: 2.7114 | Actual Loss: 0.6902\n",
      "Baseline Loss: 2.7153 | Actual Loss: 0.9733\n",
      "Baseline Loss: 2.6443 | Actual Loss: 0.8533\n",
      "Baseline Loss: 2.6558 | Actual Loss: 1.2122\n",
      "Baseline Loss: 2.6329 | Actual Loss: 0.7923\n",
      "Baseline Loss: 2.6548 | Actual Loss: 0.9362\n",
      "Baseline Loss: 2.7228 | Actual Loss: 0.7763\n",
      "Baseline Loss: 2.6975 | Actual Loss: 0.8146\n",
      "Baseline Loss: 2.6676 | Actual Loss: 0.8743\n",
      "Baseline Loss: 2.6706 | Actual Loss: 0.9518\n",
      "Baseline Loss: 2.6213 | Actual Loss: 0.7357\n",
      "Baseline Loss: 2.6817 | Actual Loss: 0.6610\n",
      "Baseline Loss: 2.7110 | Actual Loss: 1.0537\n",
      "Baseline Loss: 2.2800 | Actual Loss: 0.7092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 29/1000 [00:13<07:35,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6263 | Actual Loss: 0.9997\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.6235\n",
      "Baseline Loss: 2.6758 | Actual Loss: 1.1634\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.5655\n",
      "Epoch 29/1000: Train Loss: 0.8982, Val Loss: 0.8380\n",
      "Baseline Loss: 2.6498 | Actual Loss: 0.7257\n",
      "Baseline Loss: 2.6803 | Actual Loss: 0.9289\n",
      "Baseline Loss: 2.6962 | Actual Loss: 1.3097\n",
      "Baseline Loss: 2.6461 | Actual Loss: 0.8833\n",
      "Baseline Loss: 2.6946 | Actual Loss: 1.0784\n",
      "Baseline Loss: 2.7376 | Actual Loss: 0.8572\n",
      "Baseline Loss: 2.7266 | Actual Loss: 1.0342\n",
      "Baseline Loss: 2.6891 | Actual Loss: 0.9534\n",
      "Baseline Loss: 2.6389 | Actual Loss: 1.1473\n",
      "Baseline Loss: 2.7277 | Actual Loss: 1.0582\n",
      "Baseline Loss: 2.7041 | Actual Loss: 1.2400\n",
      "Baseline Loss: 2.6707 | Actual Loss: 1.1933\n",
      "Baseline Loss: 2.6335 | Actual Loss: 0.4436\n",
      "Baseline Loss: 2.6589 | Actual Loss: 0.9952\n",
      "Baseline Loss: 2.6487 | Actual Loss: 1.1729\n",
      "Baseline Loss: 2.2549 | Actual Loss: 0.5214\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.2381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 30/1000 [00:14<07:36,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7243 | Actual Loss: 0.7880\n",
      "Baseline Loss: 2.6758 | Actual Loss: 1.0294\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.6514\n",
      "Epoch 30/1000: Train Loss: 0.9714, Val Loss: 0.9267\n",
      "Baseline Loss: 2.6632 | Actual Loss: 0.8114\n",
      "Baseline Loss: 2.6701 | Actual Loss: 0.7142\n",
      "Baseline Loss: 2.6683 | Actual Loss: 1.0229\n",
      "Baseline Loss: 2.6988 | Actual Loss: 1.2348\n",
      "Baseline Loss: 2.6836 | Actual Loss: 1.2139\n",
      "Baseline Loss: 2.6523 | Actual Loss: 0.8908\n",
      "Baseline Loss: 2.6762 | Actual Loss: 0.5702\n",
      "Baseline Loss: 2.6734 | Actual Loss: 0.7656\n",
      "Baseline Loss: 2.6622 | Actual Loss: 2.4027\n",
      "Baseline Loss: 2.7095 | Actual Loss: 0.9941\n",
      "Baseline Loss: 2.6522 | Actual Loss: 1.0551\n",
      "Baseline Loss: 2.6659 | Actual Loss: 2.0724\n",
      "Baseline Loss: 2.6782 | Actual Loss: 0.8324\n",
      "Baseline Loss: 2.6786 | Actual Loss: 0.8802\n",
      "Baseline Loss: 2.6976 | Actual Loss: 1.0675\n",
      "Baseline Loss: 2.2485 | Actual Loss: 0.5070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 31/1000 [00:14<07:49,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6263 | Actual Loss: 1.0156\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.7529\n",
      "Baseline Loss: 2.6758 | Actual Loss: 1.0337\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.6559\n",
      "Epoch 31/1000: Train Loss: 1.0647, Val Loss: 0.8645\n",
      "Baseline Loss: 2.6816 | Actual Loss: 1.0445\n",
      "Baseline Loss: 2.7092 | Actual Loss: 1.1715\n",
      "Baseline Loss: 2.6502 | Actual Loss: 1.1035\n",
      "Baseline Loss: 2.6712 | Actual Loss: 0.7979\n",
      "Baseline Loss: 2.7058 | Actual Loss: 0.9374\n",
      "Baseline Loss: 2.6789 | Actual Loss: 0.7750\n",
      "Baseline Loss: 2.6901 | Actual Loss: 1.0921\n",
      "Baseline Loss: 2.6781 | Actual Loss: 0.8153\n",
      "Baseline Loss: 2.6484 | Actual Loss: 1.3329\n",
      "Baseline Loss: 2.7067 | Actual Loss: 1.3882\n",
      "Baseline Loss: 2.6658 | Actual Loss: 0.6899\n",
      "Baseline Loss: 2.6383 | Actual Loss: 0.6781\n",
      "Baseline Loss: 2.6417 | Actual Loss: 0.8723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 32/1000 [00:15<07:28,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6642 | Actual Loss: 1.0481\n",
      "Baseline Loss: 2.7320 | Actual Loss: 0.8478\n",
      "Baseline Loss: 2.2572 | Actual Loss: 0.7023\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.0944\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.7276\n",
      "Baseline Loss: 2.6758 | Actual Loss: 1.1624\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.6162\n",
      "Epoch 32/1000: Train Loss: 0.9560, Val Loss: 0.9001\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.8350\n",
      "Baseline Loss: 2.7100 | Actual Loss: 0.9954\n",
      "Baseline Loss: 2.6808 | Actual Loss: 1.1867\n",
      "Baseline Loss: 2.6829 | Actual Loss: 0.9280\n",
      "Baseline Loss: 2.6551 | Actual Loss: 1.1076\n",
      "Baseline Loss: 2.6939 | Actual Loss: 0.7623\n",
      "Baseline Loss: 2.7106 | Actual Loss: 0.9165\n",
      "Baseline Loss: 2.6551 | Actual Loss: 0.5470\n",
      "Baseline Loss: 2.6520 | Actual Loss: 0.7566\n",
      "Baseline Loss: 2.6794 | Actual Loss: 1.2236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 33/1000 [00:15<07:31,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6537 | Actual Loss: 0.5082\n",
      "Baseline Loss: 2.7331 | Actual Loss: 1.5608\n",
      "Baseline Loss: 2.6622 | Actual Loss: 0.7638\n",
      "Baseline Loss: 2.6947 | Actual Loss: 0.7944\n",
      "Baseline Loss: 2.6527 | Actual Loss: 1.0870\n",
      "Baseline Loss: 2.2395 | Actual Loss: 0.3378\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.3937\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.6779\n",
      "Baseline Loss: 2.6758 | Actual Loss: 1.1080\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.5180\n",
      "Epoch 33/1000: Train Loss: 0.8944, Val Loss: 0.9244\n",
      "Baseline Loss: 2.6576 | Actual Loss: 0.9741\n",
      "Baseline Loss: 2.6525 | Actual Loss: 0.6574\n",
      "Baseline Loss: 2.6926 | Actual Loss: 1.3311\n",
      "Baseline Loss: 2.6642 | Actual Loss: 1.0204\n",
      "Baseline Loss: 2.6979 | Actual Loss: 0.8066\n",
      "Baseline Loss: 2.7145 | Actual Loss: 0.6758\n",
      "Baseline Loss: 2.6683 | Actual Loss: 0.6052\n",
      "Baseline Loss: 2.6564 | Actual Loss: 0.7294\n",
      "Baseline Loss: 2.6914 | Actual Loss: 0.5672\n",
      "Baseline Loss: 2.7143 | Actual Loss: 1.3004\n",
      "Baseline Loss: 2.6264 | Actual Loss: 0.9897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 34/1000 [00:15<07:21,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6791 | Actual Loss: 0.9585\n",
      "Baseline Loss: 2.6630 | Actual Loss: 0.5804\n",
      "Baseline Loss: 2.6285 | Actual Loss: 1.2801\n",
      "Baseline Loss: 2.6719 | Actual Loss: 0.6462\n",
      "Baseline Loss: 2.2972 | Actual Loss: 0.6354\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.1683\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.6632\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.9330\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.7637\n",
      "Epoch 34/1000: Train Loss: 0.8599, Val Loss: 0.8821\n",
      "Baseline Loss: 2.7189 | Actual Loss: 0.8577\n",
      "Baseline Loss: 2.6763 | Actual Loss: 0.7767\n",
      "Baseline Loss: 2.6360 | Actual Loss: 1.1021\n",
      "Baseline Loss: 2.6833 | Actual Loss: 0.9237\n",
      "Baseline Loss: 2.6862 | Actual Loss: 0.7886\n",
      "Baseline Loss: 2.6820 | Actual Loss: 0.8310\n",
      "Baseline Loss: 2.6663 | Actual Loss: 1.1382\n",
      "Baseline Loss: 2.6771 | Actual Loss: 0.9001\n",
      "Baseline Loss: 2.6996 | Actual Loss: 0.6577\n",
      "Baseline Loss: 2.6724 | Actual Loss: 0.8461\n",
      "Baseline Loss: 2.6898 | Actual Loss: 1.0169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 35/1000 [00:16<07:33,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6462 | Actual Loss: 0.8796\n",
      "Baseline Loss: 2.6546 | Actual Loss: 1.0406\n",
      "Baseline Loss: 2.7176 | Actual Loss: 0.8977\n",
      "Baseline Loss: 2.6778 | Actual Loss: 0.6404\n",
      "Baseline Loss: 2.2284 | Actual Loss: 0.2584\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.6931\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.6491\n",
      "Baseline Loss: 2.6758 | Actual Loss: 1.0193\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.5645\n",
      "Epoch 35/1000: Train Loss: 0.8472, Val Loss: 0.9815\n",
      "Baseline Loss: 2.6529 | Actual Loss: 0.7609\n",
      "Baseline Loss: 2.6913 | Actual Loss: 1.0580\n",
      "Baseline Loss: 2.6752 | Actual Loss: 0.6465\n",
      "Baseline Loss: 2.6782 | Actual Loss: 1.5225\n",
      "Baseline Loss: 2.6835 | Actual Loss: 0.7330\n",
      "Baseline Loss: 2.6788 | Actual Loss: 0.7392\n",
      "Baseline Loss: 2.6914 | Actual Loss: 0.6220\n",
      "Baseline Loss: 2.7156 | Actual Loss: 0.4146\n",
      "Baseline Loss: 2.6848 | Actual Loss: 0.9563\n",
      "Baseline Loss: 2.6888 | Actual Loss: 0.8684\n",
      "Baseline Loss: 2.6883 | Actual Loss: 0.9722\n",
      "Baseline Loss: 2.6642 | Actual Loss: 0.7909\n",
      "Baseline Loss: 2.6760 | Actual Loss: 1.1054\n",
      "Baseline Loss: 2.6585 | Actual Loss: 0.7683\n",
      "Baseline Loss: 2.6869 | Actual Loss: 0.9112\n",
      "Baseline Loss: 2.2242 | Actual Loss: 0.4402\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.1612\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.5836\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.9718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 36/1000 [00:16<07:34,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5648 | Actual Loss: 0.4591\n",
      "Epoch 36/1000: Train Loss: 0.8318, Val Loss: 0.7940\n",
      "Baseline Loss: 2.6871 | Actual Loss: 0.9164\n",
      "Baseline Loss: 2.6811 | Actual Loss: 1.0582\n",
      "Baseline Loss: 2.6749 | Actual Loss: 0.7342\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.6724\n",
      "Baseline Loss: 2.7139 | Actual Loss: 0.8491\n",
      "Baseline Loss: 2.7078 | Actual Loss: 0.6896\n",
      "Baseline Loss: 2.7009 | Actual Loss: 0.8505\n",
      "Baseline Loss: 2.6795 | Actual Loss: 0.9361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 37/1000 [00:17<07:15,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6576 | Actual Loss: 0.8879\n",
      "Baseline Loss: 2.6962 | Actual Loss: 0.8120\n",
      "Baseline Loss: 2.6563 | Actual Loss: 0.8968\n",
      "Baseline Loss: 2.6674 | Actual Loss: 0.9377\n",
      "Baseline Loss: 2.6971 | Actual Loss: 1.4809\n",
      "Baseline Loss: 2.6474 | Actual Loss: 0.4309\n",
      "Baseline Loss: 2.6831 | Actual Loss: 0.4637\n",
      "Baseline Loss: 2.3092 | Actual Loss: 0.7458\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.6025\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.7159\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.9435\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.5966\n",
      "Epoch 37/1000: Train Loss: 0.8351, Val Loss: 0.9646\n",
      "Baseline Loss: 2.7001 | Actual Loss: 0.9308\n",
      "Baseline Loss: 2.6871 | Actual Loss: 1.0102\n",
      "Baseline Loss: 2.6740 | Actual Loss: 0.7460\n",
      "Baseline Loss: 2.6877 | Actual Loss: 0.8470\n",
      "Baseline Loss: 2.6768 | Actual Loss: 0.8910\n",
      "Baseline Loss: 2.7277 | Actual Loss: 0.7569\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.4905\n",
      "Baseline Loss: 2.6753 | Actual Loss: 0.6772\n",
      "Baseline Loss: 2.6573 | Actual Loss: 0.9340\n",
      "Baseline Loss: 2.6652 | Actual Loss: 0.9641\n",
      "Baseline Loss: 2.6622 | Actual Loss: 0.8457\n",
      "Baseline Loss: 2.6757 | Actual Loss: 0.3338\n",
      "Baseline Loss: 2.6763 | Actual Loss: 1.2330\n",
      "Baseline Loss: 2.6638 | Actual Loss: 0.7615\n",
      "Baseline Loss: 2.6574 | Actual Loss: 1.2836\n",
      "Baseline Loss: 2.2732 | Actual Loss: 0.7588\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.2653\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.6525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 38/1000 [00:17<07:29,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6758 | Actual Loss: 0.9615\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.6367\n",
      "Epoch 38/1000: Train Loss: 0.8415, Val Loss: 0.8790\n",
      "Baseline Loss: 2.7002 | Actual Loss: 0.8061\n",
      "Baseline Loss: 2.6709 | Actual Loss: 0.3922\n",
      "Baseline Loss: 2.6749 | Actual Loss: 1.2115\n",
      "Baseline Loss: 2.7112 | Actual Loss: 0.6803\n",
      "Baseline Loss: 2.7048 | Actual Loss: 0.9595\n",
      "Baseline Loss: 2.7016 | Actual Loss: 0.6009\n",
      "Baseline Loss: 2.6780 | Actual Loss: 0.3468\n",
      "Baseline Loss: 2.6398 | Actual Loss: 1.9828\n",
      "Baseline Loss: 2.6445 | Actual Loss: 1.0072\n",
      "Baseline Loss: 2.6789 | Actual Loss: 0.8107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 39/1000 [00:18<07:11,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6921 | Actual Loss: 0.8896\n",
      "Baseline Loss: 2.6615 | Actual Loss: 0.5988\n",
      "Baseline Loss: 2.6769 | Actual Loss: 0.9592\n",
      "Baseline Loss: 2.6787 | Actual Loss: 0.8846\n",
      "Baseline Loss: 2.6879 | Actual Loss: 0.6591\n",
      "Baseline Loss: 2.3638 | Actual Loss: 0.4397\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.1523\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.7641\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.9645\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.5653\n",
      "Epoch 39/1000: Train Loss: 0.8268, Val Loss: 0.8615\n",
      "Baseline Loss: 2.6413 | Actual Loss: 0.6439\n",
      "Baseline Loss: 2.7000 | Actual Loss: 0.6832\n",
      "Baseline Loss: 2.6679 | Actual Loss: 0.4517\n",
      "Baseline Loss: 2.6730 | Actual Loss: 0.8595\n",
      "Baseline Loss: 2.7056 | Actual Loss: 0.6806\n",
      "Baseline Loss: 2.6976 | Actual Loss: 1.5502\n",
      "Baseline Loss: 2.6742 | Actual Loss: 0.7766\n",
      "Baseline Loss: 2.6326 | Actual Loss: 0.7372\n",
      "Baseline Loss: 2.6711 | Actual Loss: 1.0234\n",
      "Baseline Loss: 2.6671 | Actual Loss: 0.6310\n",
      "Baseline Loss: 2.6965 | Actual Loss: 0.6713\n",
      "Baseline Loss: 2.7045 | Actual Loss: 0.6665\n",
      "Baseline Loss: 2.6649 | Actual Loss: 0.6825\n",
      "Baseline Loss: 2.6965 | Actual Loss: 0.6359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 40/1000 [00:18<07:22,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6541 | Actual Loss: 1.2836\n",
      "Baseline Loss: 2.2785 | Actual Loss: 0.6507\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.0093\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.6437\n",
      "Baseline Loss: 2.6758 | Actual Loss: 1.0339\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.6042\n",
      "Epoch 40/1000: Train Loss: 0.7892, Val Loss: 0.8228\n",
      "Baseline Loss: 2.6348 | Actual Loss: 0.7636\n",
      "Baseline Loss: 2.6836 | Actual Loss: 0.5901\n",
      "Baseline Loss: 2.7083 | Actual Loss: 1.1691\n",
      "Baseline Loss: 2.6442 | Actual Loss: 0.6103\n",
      "Baseline Loss: 2.6632 | Actual Loss: 0.7694\n",
      "Baseline Loss: 2.6568 | Actual Loss: 0.6273\n",
      "Baseline Loss: 2.7063 | Actual Loss: 0.7562\n",
      "Baseline Loss: 2.7226 | Actual Loss: 0.4531\n",
      "Baseline Loss: 2.6772 | Actual Loss: 1.4305\n",
      "Baseline Loss: 2.6414 | Actual Loss: 1.3958\n",
      "Baseline Loss: 2.6733 | Actual Loss: 0.4031\n",
      "Baseline Loss: 2.6681 | Actual Loss: 0.8204\n",
      "Baseline Loss: 2.6776 | Actual Loss: 0.8697\n",
      "Baseline Loss: 2.7213 | Actual Loss: 0.6382\n",
      "Baseline Loss: 2.6708 | Actual Loss: 1.5420\n",
      "Baseline Loss: 2.2525 | Actual Loss: 0.6163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 41/1000 [00:19<07:34,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6263 | Actual Loss: 1.0788\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.5445\n",
      "Baseline Loss: 2.6758 | Actual Loss: 1.1214\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.5548\n",
      "Epoch 41/1000: Train Loss: 0.8409, Val Loss: 0.8248\n",
      "Baseline Loss: 2.6346 | Actual Loss: 0.9351\n",
      "Baseline Loss: 2.6599 | Actual Loss: 0.6585\n",
      "Baseline Loss: 2.7106 | Actual Loss: 0.9968\n",
      "Baseline Loss: 2.6533 | Actual Loss: 0.7129\n",
      "Baseline Loss: 2.6539 | Actual Loss: 0.8368\n",
      "Baseline Loss: 2.6413 | Actual Loss: 1.2081\n",
      "Baseline Loss: 2.6654 | Actual Loss: 0.8337\n",
      "Baseline Loss: 2.6383 | Actual Loss: 0.7470\n",
      "Baseline Loss: 2.7091 | Actual Loss: 0.4453\n",
      "Baseline Loss: 2.7031 | Actual Loss: 2.1994\n",
      "Baseline Loss: 2.6749 | Actual Loss: 0.4846\n",
      "Baseline Loss: 2.6471 | Actual Loss: 1.1087\n",
      "Baseline Loss: 2.7286 | Actual Loss: 0.6883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 42/1000 [00:19<07:14,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7015 | Actual Loss: 0.9433\n",
      "Baseline Loss: 2.6606 | Actual Loss: 0.5015\n",
      "Baseline Loss: 2.2558 | Actual Loss: 0.4280\n",
      "Baseline Loss: 2.6263 | Actual Loss: 0.9489\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.5948\n",
      "Baseline Loss: 2.6758 | Actual Loss: 1.0455\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.5897\n",
      "Epoch 42/1000: Train Loss: 0.8580, Val Loss: 0.7947\n",
      "Baseline Loss: 2.7251 | Actual Loss: 0.5044\n",
      "Baseline Loss: 2.6768 | Actual Loss: 1.1587\n",
      "Baseline Loss: 2.6608 | Actual Loss: 0.9215\n",
      "Baseline Loss: 2.6565 | Actual Loss: 0.7849\n",
      "Baseline Loss: 2.6628 | Actual Loss: 0.9122\n",
      "Baseline Loss: 2.6821 | Actual Loss: 0.5977\n",
      "Baseline Loss: 2.6737 | Actual Loss: 0.6744\n",
      "Baseline Loss: 2.7086 | Actual Loss: 0.5991\n",
      "Baseline Loss: 2.6744 | Actual Loss: 1.0320\n",
      "Baseline Loss: 2.6610 | Actual Loss: 0.6649\n",
      "Baseline Loss: 2.6672 | Actual Loss: 0.6655\n",
      "Baseline Loss: 2.6900 | Actual Loss: 0.8976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 43/1000 [00:20<07:31,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6586 | Actual Loss: 1.1197\n",
      "Baseline Loss: 2.6777 | Actual Loss: 0.8681\n",
      "Baseline Loss: 2.6800 | Actual Loss: 1.0528\n",
      "Baseline Loss: 2.2730 | Actual Loss: 0.4816\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.7252\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.4261\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.9022\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.3679\n",
      "Epoch 43/1000: Train Loss: 0.8084, Val Loss: 0.8553\n",
      "Baseline Loss: 2.7051 | Actual Loss: 0.3771\n",
      "Baseline Loss: 2.6856 | Actual Loss: 0.8235\n",
      "Baseline Loss: 2.6834 | Actual Loss: 0.9158\n",
      "Baseline Loss: 2.6825 | Actual Loss: 0.7174\n",
      "Baseline Loss: 2.6806 | Actual Loss: 0.6808\n",
      "Baseline Loss: 2.6899 | Actual Loss: 0.9901\n",
      "Baseline Loss: 2.6838 | Actual Loss: 0.4260\n",
      "Baseline Loss: 2.6682 | Actual Loss: 0.7724\n",
      "Baseline Loss: 2.6699 | Actual Loss: 0.6107\n",
      "Baseline Loss: 2.6606 | Actual Loss: 0.9968\n",
      "Baseline Loss: 2.6817 | Actual Loss: 0.8653\n",
      "Baseline Loss: 2.6975 | Actual Loss: 0.6829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 44/1000 [00:20<07:15,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6113 | Actual Loss: 1.0957\n",
      "Baseline Loss: 2.6446 | Actual Loss: 0.7039\n",
      "Baseline Loss: 2.7107 | Actual Loss: 1.4412\n",
      "Baseline Loss: 2.3008 | Actual Loss: 0.3147\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.1252\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.5107\n",
      "Baseline Loss: 2.6758 | Actual Loss: 1.0008\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.5159\n",
      "Epoch 44/1000: Train Loss: 0.7759, Val Loss: 0.7881\n",
      "Baseline Loss: 2.6818 | Actual Loss: 0.9969\n",
      "Baseline Loss: 2.6415 | Actual Loss: 0.8581\n",
      "Baseline Loss: 2.6950 | Actual Loss: 2.5366\n",
      "Baseline Loss: 2.6714 | Actual Loss: 0.5669\n",
      "Baseline Loss: 2.6672 | Actual Loss: 0.7975\n",
      "Baseline Loss: 2.7404 | Actual Loss: 1.1464\n",
      "Baseline Loss: 2.6937 | Actual Loss: 0.4611\n",
      "Baseline Loss: 2.6677 | Actual Loss: 0.7394\n",
      "Baseline Loss: 2.6625 | Actual Loss: 0.9248\n",
      "Baseline Loss: 2.6927 | Actual Loss: 0.8225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 45/1000 [00:21<07:29,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6746 | Actual Loss: 0.8157\n",
      "Baseline Loss: 2.6475 | Actual Loss: 0.7152\n",
      "Baseline Loss: 2.6213 | Actual Loss: 0.9243\n",
      "Baseline Loss: 2.6936 | Actual Loss: 1.3573\n",
      "Baseline Loss: 2.7509 | Actual Loss: 0.8678\n",
      "Baseline Loss: 2.2465 | Actual Loss: 0.5413\n",
      "Baseline Loss: 2.6263 | Actual Loss: 0.8974\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.6876\n",
      "Baseline Loss: 2.6758 | Actual Loss: 1.0845\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.5161\n",
      "Epoch 45/1000: Train Loss: 0.9420, Val Loss: 0.7964\n",
      "Baseline Loss: 2.6882 | Actual Loss: 0.7541\n",
      "Baseline Loss: 2.7032 | Actual Loss: 0.8096\n",
      "Baseline Loss: 2.6526 | Actual Loss: 0.9615\n",
      "Baseline Loss: 2.6593 | Actual Loss: 1.2360\n",
      "Baseline Loss: 2.6244 | Actual Loss: 0.4589\n",
      "Baseline Loss: 2.6864 | Actual Loss: 0.9328\n",
      "Baseline Loss: 2.7173 | Actual Loss: 0.7895\n",
      "Baseline Loss: 2.7098 | Actual Loss: 0.7361\n",
      "Baseline Loss: 2.6960 | Actual Loss: 0.7896\n",
      "Baseline Loss: 2.6603 | Actual Loss: 0.6682\n",
      "Baseline Loss: 2.7368 | Actual Loss: 0.4014\n",
      "Baseline Loss: 2.6413 | Actual Loss: 1.0730\n",
      "Baseline Loss: 2.6665 | Actual Loss: 0.5908\n",
      "Baseline Loss: 2.6845 | Actual Loss: 0.6410\n",
      "Baseline Loss: 2.6614 | Actual Loss: 0.5979\n",
      "Baseline Loss: 2.2701 | Actual Loss: 0.7940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 46/1000 [00:21<07:37,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6263 | Actual Loss: 0.7141\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.6839\n",
      "Baseline Loss: 2.6758 | Actual Loss: 1.1245\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.5039\n",
      "Epoch 46/1000: Train Loss: 0.7647, Val Loss: 0.7566\n",
      "New best validation loss: 0.7566\n",
      "Baseline Loss: 2.7195 | Actual Loss: 0.7766\n",
      "Baseline Loss: 2.6967 | Actual Loss: 0.6757\n",
      "Baseline Loss: 2.6814 | Actual Loss: 0.7626\n",
      "Baseline Loss: 2.6721 | Actual Loss: 0.9412\n",
      "Baseline Loss: 2.7082 | Actual Loss: 0.8388\n",
      "Baseline Loss: 2.6922 | Actual Loss: 0.7536\n",
      "Baseline Loss: 2.6849 | Actual Loss: 1.1114\n",
      "Baseline Loss: 2.6718 | Actual Loss: 0.6374\n",
      "Baseline Loss: 2.6732 | Actual Loss: 0.6032\n",
      "Baseline Loss: 2.6247 | Actual Loss: 0.5112\n",
      "Baseline Loss: 2.6771 | Actual Loss: 0.6482\n",
      "Baseline Loss: 2.6361 | Actual Loss: 0.6213\n",
      "Baseline Loss: 2.7002 | Actual Loss: 0.5125\n",
      "Baseline Loss: 2.6337 | Actual Loss: 0.8138\n",
      "Baseline Loss: 2.6802 | Actual Loss: 1.3572\n",
      "Baseline Loss: 2.2587 | Actual Loss: 1.4775\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.3371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 47/1000 [00:22<07:44,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7243 | Actual Loss: 0.5037\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.9668\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4621\n",
      "Epoch 47/1000: Train Loss: 0.8151, Val Loss: 0.8174\n",
      "Baseline Loss: 2.6673 | Actual Loss: 0.3765\n",
      "Baseline Loss: 2.6759 | Actual Loss: 0.6742\n",
      "Baseline Loss: 2.6800 | Actual Loss: 0.6925\n",
      "Baseline Loss: 2.6880 | Actual Loss: 1.0066\n",
      "Baseline Loss: 2.7102 | Actual Loss: 0.8149\n",
      "Baseline Loss: 2.6353 | Actual Loss: 0.9486\n",
      "Baseline Loss: 2.6381 | Actual Loss: 1.2164\n",
      "Baseline Loss: 2.7218 | Actual Loss: 0.9411\n",
      "Baseline Loss: 2.6998 | Actual Loss: 0.9824\n",
      "Baseline Loss: 2.6901 | Actual Loss: 1.0770\n",
      "Baseline Loss: 2.6832 | Actual Loss: 0.8423\n",
      "Baseline Loss: 2.6636 | Actual Loss: 0.8061\n",
      "Baseline Loss: 2.6953 | Actual Loss: 0.7620\n",
      "Baseline Loss: 2.6797 | Actual Loss: 0.5230\n",
      "Baseline Loss: 2.6708 | Actual Loss: 0.7247\n",
      "Baseline Loss: 2.2966 | Actual Loss: 0.2535\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.6222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 48/1000 [00:22<07:25,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7243 | Actual Loss: 0.4841\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.7981\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4558\n",
      "Epoch 48/1000: Train Loss: 0.7901, Val Loss: 0.8400\n",
      "Baseline Loss: 2.6991 | Actual Loss: 1.4502\n",
      "Baseline Loss: 2.6581 | Actual Loss: 0.7342\n",
      "Baseline Loss: 2.6769 | Actual Loss: 1.3340\n",
      "Baseline Loss: 2.6984 | Actual Loss: 1.1255\n",
      "Baseline Loss: 2.6683 | Actual Loss: 0.9887\n",
      "Baseline Loss: 2.7125 | Actual Loss: 0.4833\n",
      "Baseline Loss: 2.6885 | Actual Loss: 0.5096\n",
      "Baseline Loss: 2.6654 | Actual Loss: 1.1905\n",
      "Baseline Loss: 2.6931 | Actual Loss: 1.0483\n",
      "Baseline Loss: 2.7024 | Actual Loss: 0.5671\n",
      "Baseline Loss: 2.6772 | Actual Loss: 0.7142\n",
      "Baseline Loss: 2.6812 | Actual Loss: 0.8194\n",
      "Baseline Loss: 2.6881 | Actual Loss: 0.6441\n",
      "Baseline Loss: 2.6707 | Actual Loss: 0.8309\n",
      "Baseline Loss: 2.6143 | Actual Loss: 0.9097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 49/1000 [00:23<07:29,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2325 | Actual Loss: 0.2947\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.3466\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.4769\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.9281\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4797\n",
      "Epoch 49/1000: Train Loss: 0.8528, Val Loss: 0.8078\n",
      "Baseline Loss: 2.6408 | Actual Loss: 0.7433\n",
      "Baseline Loss: 2.7359 | Actual Loss: 0.7053\n",
      "Baseline Loss: 2.7009 | Actual Loss: 0.4948\n",
      "Baseline Loss: 2.6778 | Actual Loss: 1.0251\n",
      "Baseline Loss: 2.6329 | Actual Loss: 0.4720\n",
      "Baseline Loss: 2.6320 | Actual Loss: 0.4748\n",
      "Baseline Loss: 2.6513 | Actual Loss: 0.5986\n",
      "Baseline Loss: 2.6534 | Actual Loss: 0.6053\n",
      "Baseline Loss: 2.6606 | Actual Loss: 0.4469\n",
      "Baseline Loss: 2.6942 | Actual Loss: 1.8704\n",
      "Baseline Loss: 2.6933 | Actual Loss: 0.6087\n",
      "Baseline Loss: 2.6876 | Actual Loss: 0.5620\n",
      "Baseline Loss: 2.6756 | Actual Loss: 0.7208\n",
      "Baseline Loss: 2.6568 | Actual Loss: 0.5720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 50/1000 [00:23<07:35,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6907 | Actual Loss: 1.5823\n",
      "Baseline Loss: 2.2620 | Actual Loss: 0.5616\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.4986\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.4278\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.8146\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.6129\n",
      "Epoch 50/1000: Train Loss: 0.7527, Val Loss: 0.8385\n",
      "Baseline Loss: 2.6891 | Actual Loss: 0.6234\n",
      "Baseline Loss: 2.6779 | Actual Loss: 0.8280\n",
      "Baseline Loss: 2.6787 | Actual Loss: 0.8234\n",
      "Baseline Loss: 2.6360 | Actual Loss: 0.7895\n",
      "Baseline Loss: 2.6771 | Actual Loss: 0.7515\n",
      "Baseline Loss: 2.6692 | Actual Loss: 0.9025\n",
      "Baseline Loss: 2.6675 | Actual Loss: 0.6559\n",
      "Baseline Loss: 2.6928 | Actual Loss: 0.9906\n",
      "Baseline Loss: 2.7121 | Actual Loss: 0.7051\n",
      "Baseline Loss: 2.6625 | Actual Loss: 0.3892\n",
      "Baseline Loss: 2.6733 | Actual Loss: 0.7833\n",
      "Baseline Loss: 2.6959 | Actual Loss: 1.0461\n",
      "Baseline Loss: 2.6619 | Actual Loss: 0.8391\n",
      "Baseline Loss: 2.6730 | Actual Loss: 0.6911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 51/1000 [00:23<07:22,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6596 | Actual Loss: 0.7157\n",
      "Baseline Loss: 2.3113 | Actual Loss: 0.4286\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.6347\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.4235\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.8533\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.6659\n",
      "Epoch 51/1000: Train Loss: 0.7477, Val Loss: 0.8943\n",
      "Baseline Loss: 2.6820 | Actual Loss: 1.1970\n",
      "Baseline Loss: 2.7498 | Actual Loss: 0.5810\n",
      "Baseline Loss: 2.6326 | Actual Loss: 0.6568\n",
      "Baseline Loss: 2.6893 | Actual Loss: 0.7698\n",
      "Baseline Loss: 2.6709 | Actual Loss: 1.1693\n",
      "Baseline Loss: 2.7216 | Actual Loss: 0.6753\n",
      "Baseline Loss: 2.7002 | Actual Loss: 2.1486\n",
      "Baseline Loss: 2.6502 | Actual Loss: 0.8617\n",
      "Baseline Loss: 2.6563 | Actual Loss: 0.6296\n",
      "Baseline Loss: 2.6629 | Actual Loss: 1.8473\n",
      "Baseline Loss: 2.6336 | Actual Loss: 0.6408\n",
      "Baseline Loss: 2.6731 | Actual Loss: 0.7238\n",
      "Baseline Loss: 2.6819 | Actual Loss: 0.9301\n",
      "Baseline Loss: 2.6565 | Actual Loss: 0.8921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 52/1000 [00:24<07:28,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6723 | Actual Loss: 0.9143\n",
      "Baseline Loss: 2.3150 | Actual Loss: 0.6039\n",
      "Baseline Loss: 2.6263 | Actual Loss: 0.8832\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.6987\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.9688\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.5046\n",
      "Epoch 52/1000: Train Loss: 0.9526, Val Loss: 0.7638\n",
      "Baseline Loss: 2.7126 | Actual Loss: 0.4182\n",
      "Baseline Loss: 2.6978 | Actual Loss: 0.8084\n",
      "Baseline Loss: 2.6568 | Actual Loss: 0.6137\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.9562\n",
      "Baseline Loss: 2.6452 | Actual Loss: 1.0180\n",
      "Baseline Loss: 2.6604 | Actual Loss: 0.3899\n",
      "Baseline Loss: 2.6798 | Actual Loss: 0.2782\n",
      "Baseline Loss: 2.7019 | Actual Loss: 1.2784\n",
      "Baseline Loss: 2.6419 | Actual Loss: 0.7634\n",
      "Baseline Loss: 2.7338 | Actual Loss: 1.1463\n",
      "Baseline Loss: 2.6478 | Actual Loss: 0.4141\n",
      "Baseline Loss: 2.6926 | Actual Loss: 0.9264\n",
      "Baseline Loss: 2.6622 | Actual Loss: 0.8102\n",
      "Baseline Loss: 2.6723 | Actual Loss: 0.7761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 53/1000 [00:24<07:38,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7007 | Actual Loss: 1.2123\n",
      "Baseline Loss: 2.2616 | Actual Loss: 0.8039\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.4691\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.4697\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.9971\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4038\n",
      "Epoch 53/1000: Train Loss: 0.7883, Val Loss: 0.8349\n",
      "Baseline Loss: 2.6627 | Actual Loss: 1.5881\n",
      "Baseline Loss: 2.7289 | Actual Loss: 0.7065\n",
      "Baseline Loss: 2.6400 | Actual Loss: 0.7639\n",
      "Baseline Loss: 2.6595 | Actual Loss: 0.7787\n",
      "Baseline Loss: 2.6668 | Actual Loss: 0.9429\n",
      "Baseline Loss: 2.7008 | Actual Loss: 0.2124\n",
      "Baseline Loss: 2.7132 | Actual Loss: 0.9598\n",
      "Baseline Loss: 2.7100 | Actual Loss: 0.5637\n",
      "Baseline Loss: 2.6712 | Actual Loss: 0.5329\n",
      "Baseline Loss: 2.6733 | Actual Loss: 0.6893\n",
      "Baseline Loss: 2.6425 | Actual Loss: 0.5528\n",
      "Baseline Loss: 2.6431 | Actual Loss: 1.1605\n",
      "Baseline Loss: 2.6999 | Actual Loss: 0.4831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 54/1000 [00:25<07:26,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6974 | Actual Loss: 1.3433\n",
      "Baseline Loss: 2.6812 | Actual Loss: 0.5218\n",
      "Baseline Loss: 2.3144 | Actual Loss: 0.8476\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.0380\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.5989\n",
      "Baseline Loss: 2.6758 | Actual Loss: 1.0036\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.3434\n",
      "Epoch 54/1000: Train Loss: 0.7905, Val Loss: 0.7460\n",
      "New best validation loss: 0.7460\n",
      "Baseline Loss: 2.6695 | Actual Loss: 0.2952\n",
      "Baseline Loss: 2.6695 | Actual Loss: 0.6841\n",
      "Baseline Loss: 2.6114 | Actual Loss: 0.7122\n",
      "Baseline Loss: 2.6610 | Actual Loss: 0.8376\n",
      "Baseline Loss: 2.7265 | Actual Loss: 0.9609\n",
      "Baseline Loss: 2.6514 | Actual Loss: 0.8643\n",
      "Baseline Loss: 2.7154 | Actual Loss: 0.7911\n",
      "Baseline Loss: 2.6583 | Actual Loss: 1.0069\n",
      "Baseline Loss: 2.6809 | Actual Loss: 1.6453\n",
      "Baseline Loss: 2.6879 | Actual Loss: 2.2768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 55/1000 [00:25<07:30,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7391 | Actual Loss: 1.1906\n",
      "Baseline Loss: 2.6800 | Actual Loss: 0.8075\n",
      "Baseline Loss: 2.6720 | Actual Loss: 0.4269\n",
      "Baseline Loss: 2.6707 | Actual Loss: 0.6825\n",
      "Baseline Loss: 2.6913 | Actual Loss: 0.4371\n",
      "Baseline Loss: 2.2879 | Actual Loss: 0.2625\n",
      "Baseline Loss: 2.6263 | Actual Loss: 0.9253\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.5029\n",
      "Baseline Loss: 2.6758 | Actual Loss: 1.0430\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.3926\n",
      "Epoch 55/1000: Train Loss: 0.8676, Val Loss: 0.7159\n",
      "New best validation loss: 0.7159\n",
      "Baseline Loss: 2.6516 | Actual Loss: 0.6059\n",
      "Baseline Loss: 2.6523 | Actual Loss: 0.5697\n",
      "Baseline Loss: 2.6923 | Actual Loss: 0.4510\n",
      "Baseline Loss: 2.6739 | Actual Loss: 0.5960\n",
      "Baseline Loss: 2.6921 | Actual Loss: 0.4270\n",
      "Baseline Loss: 2.6770 | Actual Loss: 0.6076\n",
      "Baseline Loss: 2.6502 | Actual Loss: 0.5933\n",
      "Baseline Loss: 2.6621 | Actual Loss: 1.0927\n",
      "Baseline Loss: 2.6538 | Actual Loss: 0.6496\n",
      "Baseline Loss: 2.7085 | Actual Loss: 0.5204\n",
      "Baseline Loss: 2.6933 | Actual Loss: 0.6723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 56/1000 [00:26<07:12,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6709 | Actual Loss: 0.8502\n",
      "Baseline Loss: 2.6942 | Actual Loss: 0.6760\n",
      "Baseline Loss: 2.6970 | Actual Loss: 0.7773\n",
      "Baseline Loss: 2.6959 | Actual Loss: 0.7489\n",
      "Baseline Loss: 2.2211 | Actual Loss: 0.2033\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.1028\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.5446\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.8095\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4839\n",
      "Epoch 56/1000: Train Loss: 0.6276, Val Loss: 0.7352\n",
      "Baseline Loss: 2.6807 | Actual Loss: 1.7947\n",
      "Baseline Loss: 2.6549 | Actual Loss: 1.0195\n",
      "Baseline Loss: 2.6364 | Actual Loss: 0.9862\n",
      "Baseline Loss: 2.6826 | Actual Loss: 0.9863\n",
      "Baseline Loss: 2.6835 | Actual Loss: 0.5880\n",
      "Baseline Loss: 2.6856 | Actual Loss: 0.7688\n",
      "Baseline Loss: 2.6800 | Actual Loss: 0.9209\n",
      "Baseline Loss: 2.6504 | Actual Loss: 0.7346\n",
      "Baseline Loss: 2.6969 | Actual Loss: 0.5931\n",
      "Baseline Loss: 2.6872 | Actual Loss: 0.6243\n",
      "Baseline Loss: 2.7094 | Actual Loss: 0.4743\n",
      "Baseline Loss: 2.7257 | Actual Loss: 0.4265\n",
      "Baseline Loss: 2.6441 | Actual Loss: 0.5428\n",
      "Baseline Loss: 2.6939 | Actual Loss: 0.5964\n",
      "Baseline Loss: 2.6740 | Actual Loss: 1.6403\n",
      "Baseline Loss: 2.2670 | Actual Loss: 0.6417\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.9563\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.5732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 57/1000 [00:26<07:12,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6758 | Actual Loss: 0.8205\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.5465\n",
      "Epoch 57/1000: Train Loss: 0.8337, Val Loss: 0.9741\n",
      "Baseline Loss: 2.6497 | Actual Loss: 0.8858\n",
      "Baseline Loss: 2.6647 | Actual Loss: 0.4276\n",
      "Baseline Loss: 2.6591 | Actual Loss: 0.8026\n",
      "Baseline Loss: 2.7001 | Actual Loss: 0.7582\n",
      "Baseline Loss: 2.7106 | Actual Loss: 0.3499\n",
      "Baseline Loss: 2.6940 | Actual Loss: 0.7095\n",
      "Baseline Loss: 2.7070 | Actual Loss: 0.9449\n",
      "Baseline Loss: 2.6882 | Actual Loss: 0.6178\n",
      "Baseline Loss: 2.6748 | Actual Loss: 1.1826\n",
      "Baseline Loss: 2.6667 | Actual Loss: 0.4423\n",
      "Baseline Loss: 2.6871 | Actual Loss: 0.7157\n",
      "Baseline Loss: 2.6958 | Actual Loss: 0.9739\n",
      "Baseline Loss: 2.7132 | Actual Loss: 0.7886\n",
      "Baseline Loss: 2.6905 | Actual Loss: 0.7294\n",
      "Baseline Loss: 2.6639 | Actual Loss: 0.5054\n",
      "Baseline Loss: 2.2181 | Actual Loss: 0.7265\n",
      "Baseline Loss: 2.6263 | Actual Loss: 0.8126\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.5741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 58/1000 [00:27<07:04,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6758 | Actual Loss: 0.9763\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.6256\n",
      "Epoch 58/1000: Train Loss: 0.7225, Val Loss: 0.7472\n",
      "Baseline Loss: 2.6698 | Actual Loss: 0.6230\n",
      "Baseline Loss: 2.6868 | Actual Loss: 0.6166\n",
      "Baseline Loss: 2.6550 | Actual Loss: 1.0221\n",
      "Baseline Loss: 2.6729 | Actual Loss: 0.2398\n",
      "Baseline Loss: 2.6671 | Actual Loss: 0.5192\n",
      "Baseline Loss: 2.7263 | Actual Loss: 0.7238\n",
      "Baseline Loss: 2.6616 | Actual Loss: 0.6520\n",
      "Baseline Loss: 2.6856 | Actual Loss: 0.5826\n",
      "Baseline Loss: 2.6869 | Actual Loss: 0.6211\n",
      "Baseline Loss: 2.6876 | Actual Loss: 0.3689\n",
      "Baseline Loss: 2.6512 | Actual Loss: 0.3989\n",
      "Baseline Loss: 2.6856 | Actual Loss: 0.5417\n",
      "Baseline Loss: 2.6498 | Actual Loss: 0.6699\n",
      "Baseline Loss: 2.6978 | Actual Loss: 0.6725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 59/1000 [00:27<07:19,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6671 | Actual Loss: 2.3538\n",
      "Baseline Loss: 2.2727 | Actual Loss: 2.0592\n",
      "Baseline Loss: 2.6263 | Actual Loss: 2.1989\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.4554\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.7568\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4641\n",
      "Epoch 59/1000: Train Loss: 0.7916, Val Loss: 0.9688\n",
      "Baseline Loss: 2.6802 | Actual Loss: 0.4279\n",
      "Baseline Loss: 2.7031 | Actual Loss: 1.0949\n",
      "Baseline Loss: 2.7335 | Actual Loss: 1.3770\n",
      "Baseline Loss: 2.6840 | Actual Loss: 1.3650\n",
      "Baseline Loss: 2.7095 | Actual Loss: 0.7010\n",
      "Baseline Loss: 2.6577 | Actual Loss: 0.7940\n",
      "Baseline Loss: 2.6484 | Actual Loss: 1.8635\n",
      "Baseline Loss: 2.6420 | Actual Loss: 1.7716\n",
      "Baseline Loss: 2.6903 | Actual Loss: 0.7343\n",
      "Baseline Loss: 2.6876 | Actual Loss: 0.3184\n",
      "Baseline Loss: 2.6489 | Actual Loss: 1.0474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 60/1000 [00:28<07:16,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6648 | Actual Loss: 0.6715\n",
      "Baseline Loss: 2.6920 | Actual Loss: 1.3004\n",
      "Baseline Loss: 2.6886 | Actual Loss: 0.9225\n",
      "Baseline Loss: 2.6317 | Actual Loss: 0.7743\n",
      "Baseline Loss: 2.2404 | Actual Loss: 2.0969\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.4371\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3910\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.6978\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.8173\n",
      "Epoch 60/1000: Train Loss: 1.0788, Val Loss: 0.8358\n",
      "Baseline Loss: 2.7058 | Actual Loss: 1.1871\n",
      "Baseline Loss: 2.6580 | Actual Loss: 0.2665\n",
      "Baseline Loss: 2.6617 | Actual Loss: 0.7944\n",
      "Baseline Loss: 2.7109 | Actual Loss: 0.5549\n",
      "Baseline Loss: 2.6829 | Actual Loss: 0.7306\n",
      "Baseline Loss: 2.6842 | Actual Loss: 0.7437\n",
      "Baseline Loss: 2.6733 | Actual Loss: 0.4403\n",
      "Baseline Loss: 2.6849 | Actual Loss: 0.4732\n",
      "Baseline Loss: 2.6528 | Actual Loss: 0.7274\n",
      "Baseline Loss: 2.6836 | Actual Loss: 0.2475\n",
      "Baseline Loss: 2.6571 | Actual Loss: 0.7801\n",
      "Baseline Loss: 2.6692 | Actual Loss: 0.2464\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.9680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 61/1000 [00:28<07:09,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6931 | Actual Loss: 0.7544\n",
      "Baseline Loss: 2.6775 | Actual Loss: 0.6669\n",
      "Baseline Loss: 2.3080 | Actual Loss: 0.3182\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.0115\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.4364\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.6832\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.7752\n",
      "Epoch 61/1000: Train Loss: 0.6187, Val Loss: 0.7266\n",
      "Baseline Loss: 2.6531 | Actual Loss: 0.6813\n",
      "Baseline Loss: 2.6420 | Actual Loss: 0.7689\n",
      "Baseline Loss: 2.6498 | Actual Loss: 0.8795\n",
      "Baseline Loss: 2.6802 | Actual Loss: 0.7212\n",
      "Baseline Loss: 2.6682 | Actual Loss: 0.9519\n",
      "Baseline Loss: 2.6494 | Actual Loss: 0.6701\n",
      "Baseline Loss: 2.6890 | Actual Loss: 0.6525\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.8856\n",
      "Baseline Loss: 2.6817 | Actual Loss: 0.9741\n",
      "Baseline Loss: 2.6670 | Actual Loss: 0.6290\n",
      "Baseline Loss: 2.6564 | Actual Loss: 0.9569\n",
      "Baseline Loss: 2.7094 | Actual Loss: 0.8216\n",
      "Baseline Loss: 2.6908 | Actual Loss: 0.8615\n",
      "Baseline Loss: 2.6878 | Actual Loss: 0.8132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 62/1000 [00:29<07:18,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6721 | Actual Loss: 0.6534\n",
      "Baseline Loss: 2.3044 | Actual Loss: 0.6533\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.0374\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.4095\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.8780\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.5704\n",
      "Epoch 62/1000: Train Loss: 0.7859, Val Loss: 0.7238\n",
      "Baseline Loss: 2.7123 | Actual Loss: 0.5661\n",
      "Baseline Loss: 2.6526 | Actual Loss: 1.0020\n",
      "Baseline Loss: 2.6828 | Actual Loss: 1.0159\n",
      "Baseline Loss: 2.6585 | Actual Loss: 1.6166\n",
      "Baseline Loss: 2.6745 | Actual Loss: 0.4985\n",
      "Baseline Loss: 2.6938 | Actual Loss: 1.7548\n",
      "Baseline Loss: 2.7000 | Actual Loss: 0.2710\n",
      "Baseline Loss: 2.6481 | Actual Loss: 1.0041\n",
      "Baseline Loss: 2.6751 | Actual Loss: 1.3742\n",
      "Baseline Loss: 2.6656 | Actual Loss: 1.2598\n",
      "Baseline Loss: 2.7237 | Actual Loss: 0.4418\n",
      "Baseline Loss: 2.6980 | Actual Loss: 0.6299\n",
      "Baseline Loss: 2.7076 | Actual Loss: 0.5269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 63/1000 [00:29<07:29,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6213 | Actual Loss: 1.7043\n",
      "Baseline Loss: 2.6551 | Actual Loss: 0.8577\n",
      "Baseline Loss: 2.2581 | Actual Loss: 0.2444\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.0517\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3875\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.8605\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4353\n",
      "Epoch 63/1000: Train Loss: 0.9230, Val Loss: 0.6837\n",
      "New best validation loss: 0.6837\n",
      "Baseline Loss: 2.6979 | Actual Loss: 0.9331\n",
      "Baseline Loss: 2.6859 | Actual Loss: 0.8239\n",
      "Baseline Loss: 2.6620 | Actual Loss: 0.3536\n",
      "Baseline Loss: 2.6684 | Actual Loss: 0.8639\n",
      "Baseline Loss: 2.6711 | Actual Loss: 0.9925\n",
      "Baseline Loss: 2.6765 | Actual Loss: 0.5580\n",
      "Baseline Loss: 2.6905 | Actual Loss: 1.1592\n",
      "Baseline Loss: 2.6504 | Actual Loss: 0.4572\n",
      "Baseline Loss: 2.6972 | Actual Loss: 0.8379\n",
      "Baseline Loss: 2.6746 | Actual Loss: 0.6693\n",
      "Baseline Loss: 2.7024 | Actual Loss: 0.9012\n",
      "Baseline Loss: 2.6848 | Actual Loss: 0.7958\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.9948\n",
      "Baseline Loss: 2.6870 | Actual Loss: 0.4653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 64/1000 [00:30<07:10,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6642 | Actual Loss: 0.4397\n",
      "Baseline Loss: 2.2390 | Actual Loss: 0.6537\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.0220\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.4005\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.8797\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4969\n",
      "Epoch 64/1000: Train Loss: 0.7437, Val Loss: 0.6998\n",
      "Baseline Loss: 2.7082 | Actual Loss: 0.6549\n",
      "Baseline Loss: 2.6819 | Actual Loss: 0.6144\n",
      "Baseline Loss: 2.6917 | Actual Loss: 0.5546\n",
      "Baseline Loss: 2.6469 | Actual Loss: 0.7411\n",
      "Baseline Loss: 2.6570 | Actual Loss: 0.4437\n",
      "Baseline Loss: 2.6444 | Actual Loss: 0.6062\n",
      "Baseline Loss: 2.6596 | Actual Loss: 0.3716\n",
      "Baseline Loss: 2.6885 | Actual Loss: 2.1778\n",
      "Baseline Loss: 2.6663 | Actual Loss: 1.1291\n",
      "Baseline Loss: 2.6799 | Actual Loss: 1.0154\n",
      "Baseline Loss: 2.6835 | Actual Loss: 1.2820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 65/1000 [00:30<07:18,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6895 | Actual Loss: 2.4383\n",
      "Baseline Loss: 2.6780 | Actual Loss: 0.4362\n",
      "Baseline Loss: 2.6446 | Actual Loss: 0.4271\n",
      "Baseline Loss: 2.6679 | Actual Loss: 1.8857\n",
      "Baseline Loss: 2.2615 | Actual Loss: 0.3474\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.9930\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.4448\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.7055\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.6492\n",
      "Epoch 65/1000: Train Loss: 0.9453, Val Loss: 0.9481\n",
      "Baseline Loss: 2.6886 | Actual Loss: 0.6976\n",
      "Baseline Loss: 2.6697 | Actual Loss: 0.6422\n",
      "Baseline Loss: 2.6635 | Actual Loss: 1.6769\n",
      "Baseline Loss: 2.6898 | Actual Loss: 0.2506\n",
      "Baseline Loss: 2.6725 | Actual Loss: 0.8745\n",
      "Baseline Loss: 2.6629 | Actual Loss: 0.9400\n",
      "Baseline Loss: 2.6638 | Actual Loss: 0.6211\n",
      "Baseline Loss: 2.7177 | Actual Loss: 0.6403\n",
      "Baseline Loss: 2.6771 | Actual Loss: 0.7502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 66/1000 [00:30<07:25,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6771 | Actual Loss: 0.7278\n",
      "Baseline Loss: 2.6515 | Actual Loss: 0.7677\n",
      "Baseline Loss: 2.6830 | Actual Loss: 0.4071\n",
      "Baseline Loss: 2.6705 | Actual Loss: 0.5891\n",
      "Baseline Loss: 2.6756 | Actual Loss: 0.6790\n",
      "Baseline Loss: 2.6653 | Actual Loss: 0.8788\n",
      "Baseline Loss: 2.2999 | Actual Loss: 2.6293\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.1713\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3666\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.9698\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4199\n",
      "Epoch 66/1000: Train Loss: 0.8608, Val Loss: 0.7319\n",
      "Baseline Loss: 2.6709 | Actual Loss: 0.6055\n",
      "Baseline Loss: 2.6746 | Actual Loss: 1.1104\n",
      "Baseline Loss: 2.6777 | Actual Loss: 0.5682\n",
      "Baseline Loss: 2.6913 | Actual Loss: 0.7103\n",
      "Baseline Loss: 2.6550 | Actual Loss: 0.4912\n",
      "Baseline Loss: 2.7029 | Actual Loss: 0.3336\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.2973\n",
      "Baseline Loss: 2.6912 | Actual Loss: 0.6600\n",
      "Baseline Loss: 2.6946 | Actual Loss: 1.4933\n",
      "Baseline Loss: 2.6688 | Actual Loss: 1.1691\n",
      "Baseline Loss: 2.6636 | Actual Loss: 0.4757\n",
      "Baseline Loss: 2.6785 | Actual Loss: 0.4748\n",
      "Baseline Loss: 2.6964 | Actual Loss: 0.4024\n",
      "Baseline Loss: 2.6593 | Actual Loss: 0.3187\n",
      "Baseline Loss: 2.6515 | Actual Loss: 2.1150\n",
      "Baseline Loss: 2.3383 | Actual Loss: 0.4030\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.7987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 67/1000 [00:31<07:28,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7243 | Actual Loss: 0.3530\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.8167\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.3888\n",
      "Epoch 67/1000: Train Loss: 0.7268, Val Loss: 0.8393\n",
      "Baseline Loss: 2.6639 | Actual Loss: 0.4495\n",
      "Baseline Loss: 2.6809 | Actual Loss: 0.4020\n",
      "Baseline Loss: 2.6858 | Actual Loss: 0.3971\n",
      "Baseline Loss: 2.6406 | Actual Loss: 2.0155\n",
      "Baseline Loss: 2.6586 | Actual Loss: 0.7681\n",
      "Baseline Loss: 2.6793 | Actual Loss: 0.5998\n",
      "Baseline Loss: 2.6686 | Actual Loss: 1.0929\n",
      "Baseline Loss: 2.6979 | Actual Loss: 1.2844\n",
      "Baseline Loss: 2.6862 | Actual Loss: 0.8083\n",
      "Baseline Loss: 2.6882 | Actual Loss: 0.8846\n",
      "Baseline Loss: 2.6875 | Actual Loss: 0.5930\n",
      "Baseline Loss: 2.6565 | Actual Loss: 0.9206\n",
      "Baseline Loss: 2.6947 | Actual Loss: 0.6320\n",
      "Baseline Loss: 2.6438 | Actual Loss: 0.9114\n",
      "Baseline Loss: 2.6450 | Actual Loss: 0.7242\n",
      "Baseline Loss: 2.2957 | Actual Loss: 0.1242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 68/1000 [00:31<07:15,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6263 | Actual Loss: 1.4091\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.4911\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.7068\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.5739\n",
      "Epoch 68/1000: Train Loss: 0.7880, Val Loss: 0.7952\n",
      "Baseline Loss: 2.6793 | Actual Loss: 1.9573\n",
      "Baseline Loss: 2.6576 | Actual Loss: 0.3903\n",
      "Baseline Loss: 2.7221 | Actual Loss: 0.1664\n",
      "Baseline Loss: 2.6751 | Actual Loss: 1.2661\n",
      "Baseline Loss: 2.6599 | Actual Loss: 0.2426\n",
      "Baseline Loss: 2.6661 | Actual Loss: 0.5609\n",
      "Baseline Loss: 2.7070 | Actual Loss: 1.4658\n",
      "Baseline Loss: 2.6866 | Actual Loss: 2.4173\n",
      "Baseline Loss: 2.6672 | Actual Loss: 1.1980\n",
      "Baseline Loss: 2.6628 | Actual Loss: 0.9085\n",
      "Baseline Loss: 2.6593 | Actual Loss: 0.6533\n",
      "Baseline Loss: 2.6824 | Actual Loss: 0.6685\n",
      "Baseline Loss: 2.6870 | Actual Loss: 0.3122\n",
      "Baseline Loss: 2.6379 | Actual Loss: 0.4735\n",
      "Baseline Loss: 2.6801 | Actual Loss: 0.8889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 69/1000 [00:32<07:18,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2909 | Actual Loss: 1.0082\n",
      "Baseline Loss: 2.6263 | Actual Loss: 0.8866\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.6346\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.8367\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.5208\n",
      "Epoch 69/1000: Train Loss: 0.9111, Val Loss: 0.7197\n",
      "Baseline Loss: 2.6737 | Actual Loss: 1.1897\n",
      "Baseline Loss: 2.6741 | Actual Loss: 0.4735\n",
      "Baseline Loss: 2.6799 | Actual Loss: 1.4321\n",
      "Baseline Loss: 2.6404 | Actual Loss: 0.5047\n",
      "Baseline Loss: 2.6666 | Actual Loss: 1.8571\n",
      "Baseline Loss: 2.6763 | Actual Loss: 0.7497\n",
      "Baseline Loss: 2.6832 | Actual Loss: 0.6649\n",
      "Baseline Loss: 2.6473 | Actual Loss: 0.8579\n",
      "Baseline Loss: 2.6901 | Actual Loss: 0.6403\n",
      "Baseline Loss: 2.6520 | Actual Loss: 0.4666\n",
      "Baseline Loss: 2.6741 | Actual Loss: 0.7456\n",
      "Baseline Loss: 2.6612 | Actual Loss: 0.3830\n",
      "Baseline Loss: 2.7205 | Actual Loss: 0.9821\n",
      "Baseline Loss: 2.7146 | Actual Loss: 0.3439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 70/1000 [00:32<07:27,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6989 | Actual Loss: 2.4233\n",
      "Baseline Loss: 2.3304 | Actual Loss: 0.4372\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.8481\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.6027\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.8558\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.9232\n",
      "Epoch 70/1000: Train Loss: 0.8845, Val Loss: 1.0574\n",
      "Baseline Loss: 2.6527 | Actual Loss: 1.7611\n",
      "Baseline Loss: 2.6708 | Actual Loss: 0.3697\n",
      "Baseline Loss: 2.6680 | Actual Loss: 0.6107\n",
      "Baseline Loss: 2.6947 | Actual Loss: 0.8142\n",
      "Baseline Loss: 2.6911 | Actual Loss: 0.8335\n",
      "Baseline Loss: 2.6697 | Actual Loss: 1.2760\n",
      "Baseline Loss: 2.6689 | Actual Loss: 0.7936\n",
      "Baseline Loss: 2.6574 | Actual Loss: 0.3902\n",
      "Baseline Loss: 2.6528 | Actual Loss: 0.8637\n",
      "Baseline Loss: 2.6827 | Actual Loss: 0.8143\n",
      "Baseline Loss: 2.6593 | Actual Loss: 0.6838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 71/1000 [00:33<07:13,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7207 | Actual Loss: 1.0710\n",
      "Baseline Loss: 2.6560 | Actual Loss: 0.3627\n",
      "Baseline Loss: 2.6892 | Actual Loss: 0.7585\n",
      "Baseline Loss: 2.7116 | Actual Loss: 0.5257\n",
      "Baseline Loss: 2.2625 | Actual Loss: 0.2040\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.0963\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.5933\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.8973\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.6303\n",
      "Epoch 71/1000: Train Loss: 0.7583, Val Loss: 0.8043\n",
      "Baseline Loss: 2.7465 | Actual Loss: 0.9827\n",
      "Baseline Loss: 2.6845 | Actual Loss: 0.5408\n",
      "Baseline Loss: 2.6809 | Actual Loss: 0.9441\n",
      "Baseline Loss: 2.7166 | Actual Loss: 0.7095\n",
      "Baseline Loss: 2.7108 | Actual Loss: 0.3866\n",
      "Baseline Loss: 2.6517 | Actual Loss: 0.3917\n",
      "Baseline Loss: 2.6693 | Actual Loss: 0.8961\n",
      "Baseline Loss: 2.6325 | Actual Loss: 0.6041\n",
      "Baseline Loss: 2.6739 | Actual Loss: 0.6675\n",
      "Baseline Loss: 2.6782 | Actual Loss: 0.4427\n",
      "Baseline Loss: 2.6708 | Actual Loss: 0.4497\n",
      "Baseline Loss: 2.6975 | Actual Loss: 0.7405\n",
      "Baseline Loss: 2.7073 | Actual Loss: 0.6427\n",
      "Baseline Loss: 2.6534 | Actual Loss: 0.7059\n",
      "Baseline Loss: 2.6443 | Actual Loss: 1.2833\n",
      "Baseline Loss: 2.2774 | Actual Loss: 0.4851\n",
      "Baseline Loss: 2.6263 | Actual Loss: 0.7708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 72/1000 [00:33<07:30,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7243 | Actual Loss: 0.3813\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.7451\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.5656\n",
      "Epoch 72/1000: Train Loss: 0.6796, Val Loss: 0.6157\n",
      "New best validation loss: 0.6157\n",
      "Baseline Loss: 2.6830 | Actual Loss: 0.9015\n",
      "Baseline Loss: 2.6897 | Actual Loss: 0.4211\n",
      "Baseline Loss: 2.6784 | Actual Loss: 0.6782\n",
      "Baseline Loss: 2.6839 | Actual Loss: 0.8269\n",
      "Baseline Loss: 2.6631 | Actual Loss: 0.5763\n",
      "Baseline Loss: 2.6660 | Actual Loss: 0.6710\n",
      "Baseline Loss: 2.6641 | Actual Loss: 0.3722\n",
      "Baseline Loss: 2.6997 | Actual Loss: 0.4842\n",
      "Baseline Loss: 2.6706 | Actual Loss: 0.4488\n",
      "Baseline Loss: 2.6630 | Actual Loss: 0.5270\n",
      "Baseline Loss: 2.6540 | Actual Loss: 0.6557\n",
      "Baseline Loss: 2.6820 | Actual Loss: 0.6078\n",
      "Baseline Loss: 2.6876 | Actual Loss: 0.3121\n",
      "Baseline Loss: 2.6636 | Actual Loss: 1.1038\n",
      "Baseline Loss: 2.6566 | Actual Loss: 0.7609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 73/1000 [00:34<07:15,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2724 | Actual Loss: 1.0272\n",
      "Baseline Loss: 2.6263 | Actual Loss: 0.8506\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3988\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.7772\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4586\n",
      "Epoch 73/1000: Train Loss: 0.6484, Val Loss: 0.6213\n",
      "Baseline Loss: 2.6992 | Actual Loss: 0.4969\n",
      "Baseline Loss: 2.6777 | Actual Loss: 0.7935\n",
      "Baseline Loss: 2.6741 | Actual Loss: 0.7084\n",
      "Baseline Loss: 2.6455 | Actual Loss: 0.6136\n",
      "Baseline Loss: 2.6619 | Actual Loss: 0.5533\n",
      "Baseline Loss: 2.6615 | Actual Loss: 0.5292\n",
      "Baseline Loss: 2.6951 | Actual Loss: 0.9033\n",
      "Baseline Loss: 2.6580 | Actual Loss: 1.0513\n",
      "Baseline Loss: 2.6678 | Actual Loss: 0.7728\n",
      "Baseline Loss: 2.6968 | Actual Loss: 0.8268\n",
      "Baseline Loss: 2.6728 | Actual Loss: 0.7142\n",
      "Baseline Loss: 2.7070 | Actual Loss: 0.8764\n",
      "Baseline Loss: 2.7004 | Actual Loss: 0.6436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 74/1000 [00:34<07:20,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6664 | Actual Loss: 0.6826\n",
      "Baseline Loss: 2.6728 | Actual Loss: 2.3483\n",
      "Baseline Loss: 2.2909 | Actual Loss: 0.1625\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.7185\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3747\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.7128\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.5047\n",
      "Epoch 74/1000: Train Loss: 0.7923, Val Loss: 0.8277\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.4311\n",
      "Baseline Loss: 2.7134 | Actual Loss: 0.2931\n",
      "Baseline Loss: 2.6618 | Actual Loss: 0.7453\n",
      "Baseline Loss: 2.6755 | Actual Loss: 1.5944\n",
      "Baseline Loss: 2.6966 | Actual Loss: 0.4485\n",
      "Baseline Loss: 2.6366 | Actual Loss: 1.1605\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.5177\n",
      "Baseline Loss: 2.6931 | Actual Loss: 0.3123\n",
      "Baseline Loss: 2.7061 | Actual Loss: 1.3294\n",
      "Baseline Loss: 2.6823 | Actual Loss: 0.3038\n",
      "Baseline Loss: 2.6426 | Actual Loss: 0.5360\n",
      "Baseline Loss: 2.6818 | Actual Loss: 0.6370\n",
      "Baseline Loss: 2.6469 | Actual Loss: 0.5580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 75/1000 [00:35<07:19,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6576 | Actual Loss: 0.6667\n",
      "Baseline Loss: 2.6447 | Actual Loss: 0.5654\n",
      "Baseline Loss: 2.1909 | Actual Loss: 0.1953\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.6159\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3849\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.6303\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4291\n",
      "Epoch 75/1000: Train Loss: 0.6434, Val Loss: 0.7651\n",
      "Baseline Loss: 2.6935 | Actual Loss: 0.7332\n",
      "Baseline Loss: 2.6750 | Actual Loss: 0.8328\n",
      "Baseline Loss: 2.6653 | Actual Loss: 0.9802\n",
      "Baseline Loss: 2.7021 | Actual Loss: 1.3975\n",
      "Baseline Loss: 2.6439 | Actual Loss: 0.9836\n",
      "Baseline Loss: 2.6505 | Actual Loss: 0.6532\n",
      "Baseline Loss: 2.7035 | Actual Loss: 2.5554\n",
      "Baseline Loss: 2.6934 | Actual Loss: 0.5223\n",
      "Baseline Loss: 2.6988 | Actual Loss: 0.4286\n",
      "Baseline Loss: 2.6361 | Actual Loss: 0.7088\n",
      "Baseline Loss: 2.6728 | Actual Loss: 0.7121\n",
      "Baseline Loss: 2.6592 | Actual Loss: 0.7095\n",
      "Baseline Loss: 2.6797 | Actual Loss: 0.3044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 76/1000 [00:35<06:57,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6990 | Actual Loss: 0.8672\n",
      "Baseline Loss: 2.6538 | Actual Loss: 0.5935\n",
      "Baseline Loss: 2.3095 | Actual Loss: 1.9890\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.0398\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.4108\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.7413\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4327\n",
      "Epoch 76/1000: Train Loss: 0.9357, Val Loss: 0.6562\n",
      "Baseline Loss: 2.6614 | Actual Loss: 0.5300\n",
      "Baseline Loss: 2.6603 | Actual Loss: 0.7492\n",
      "Baseline Loss: 2.6876 | Actual Loss: 0.7149\n",
      "Baseline Loss: 2.6702 | Actual Loss: 0.7441\n",
      "Baseline Loss: 2.6665 | Actual Loss: 0.6418\n",
      "Baseline Loss: 2.6520 | Actual Loss: 0.4463\n",
      "Baseline Loss: 2.6616 | Actual Loss: 0.4100\n",
      "Baseline Loss: 2.6642 | Actual Loss: 1.0670\n",
      "Baseline Loss: 2.6499 | Actual Loss: 0.7842\n",
      "Baseline Loss: 2.6668 | Actual Loss: 0.4961\n",
      "Baseline Loss: 2.7302 | Actual Loss: 0.6989\n",
      "Baseline Loss: 2.6740 | Actual Loss: 0.5955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 77/1000 [00:36<07:13,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7544 | Actual Loss: 0.7382\n",
      "Baseline Loss: 2.6708 | Actual Loss: 1.5822\n",
      "Baseline Loss: 2.6590 | Actual Loss: 0.5918\n",
      "Baseline Loss: 2.3317 | Actual Loss: 0.2418\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.0120\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3404\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.9582\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4150\n",
      "Epoch 77/1000: Train Loss: 0.6895, Val Loss: 0.6814\n",
      "Baseline Loss: 2.6485 | Actual Loss: 0.5897\n",
      "Baseline Loss: 2.6994 | Actual Loss: 0.7826\n",
      "Baseline Loss: 2.7079 | Actual Loss: 0.8338\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.7565\n",
      "Baseline Loss: 2.6933 | Actual Loss: 0.4609\n",
      "Baseline Loss: 2.6699 | Actual Loss: 0.6855\n",
      "Baseline Loss: 2.6632 | Actual Loss: 0.5281\n",
      "Baseline Loss: 2.6656 | Actual Loss: 0.4111\n",
      "Baseline Loss: 2.6687 | Actual Loss: 0.4780\n",
      "Baseline Loss: 2.6526 | Actual Loss: 0.3676\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.8569\n",
      "Baseline Loss: 2.6620 | Actual Loss: 0.2374\n",
      "Baseline Loss: 2.6833 | Actual Loss: 0.5554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 78/1000 [00:36<06:55,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6293 | Actual Loss: 1.0432\n",
      "Baseline Loss: 2.7363 | Actual Loss: 0.3207\n",
      "Baseline Loss: 2.3044 | Actual Loss: 0.1704\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.7431\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.4292\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.4052\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.8526\n",
      "Epoch 78/1000: Train Loss: 0.5674, Val Loss: 0.8575\n",
      "Baseline Loss: 2.6877 | Actual Loss: 0.3983\n",
      "Baseline Loss: 2.7002 | Actual Loss: 0.5256\n",
      "Baseline Loss: 2.6992 | Actual Loss: 0.4966\n",
      "Baseline Loss: 2.6581 | Actual Loss: 0.9136\n",
      "Baseline Loss: 2.6685 | Actual Loss: 0.6806\n",
      "Baseline Loss: 2.6560 | Actual Loss: 0.6929\n",
      "Baseline Loss: 2.6696 | Actual Loss: 0.5354\n",
      "Baseline Loss: 2.6664 | Actual Loss: 0.8381\n",
      "Baseline Loss: 2.7653 | Actual Loss: 0.7060\n",
      "Baseline Loss: 2.7342 | Actual Loss: 0.6551\n",
      "Baseline Loss: 2.6725 | Actual Loss: 0.8633\n",
      "Baseline Loss: 2.6504 | Actual Loss: 0.4992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 79/1000 [00:37<07:08,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6702 | Actual Loss: 0.8923\n",
      "Baseline Loss: 2.6624 | Actual Loss: 0.8889\n",
      "Baseline Loss: 2.6631 | Actual Loss: 0.8652\n",
      "Baseline Loss: 2.2907 | Actual Loss: 1.2664\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.3327\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.4312\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.8004\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.6322\n",
      "Epoch 79/1000: Train Loss: 0.7323, Val Loss: 0.7991\n",
      "Baseline Loss: 2.6961 | Actual Loss: 0.7381\n",
      "Baseline Loss: 2.6278 | Actual Loss: 0.5140\n",
      "Baseline Loss: 2.6817 | Actual Loss: 0.3286\n",
      "Baseline Loss: 2.6612 | Actual Loss: 0.4795\n",
      "Baseline Loss: 2.6685 | Actual Loss: 1.0797\n",
      "Baseline Loss: 2.6795 | Actual Loss: 0.4975\n",
      "Baseline Loss: 2.7103 | Actual Loss: 0.9194\n",
      "Baseline Loss: 2.7034 | Actual Loss: 0.7516\n",
      "Baseline Loss: 2.6774 | Actual Loss: 0.4642\n",
      "Baseline Loss: 2.6579 | Actual Loss: 0.4660\n",
      "Baseline Loss: 2.6561 | Actual Loss: 0.5523\n",
      "Baseline Loss: 2.7346 | Actual Loss: 1.5708\n",
      "Baseline Loss: 2.6567 | Actual Loss: 0.8882\n",
      "Baseline Loss: 2.6914 | Actual Loss: 0.7366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 80/1000 [00:37<07:19,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6721 | Actual Loss: 0.4682\n",
      "Baseline Loss: 2.2551 | Actual Loss: 1.9065\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.1889\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.4774\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.9136\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4611\n",
      "Epoch 80/1000: Train Loss: 0.7726, Val Loss: 0.7603\n",
      "Baseline Loss: 2.6719 | Actual Loss: 0.6312\n",
      "Baseline Loss: 2.6486 | Actual Loss: 0.5753\n",
      "Baseline Loss: 2.7117 | Actual Loss: 0.4767\n",
      "Baseline Loss: 2.7148 | Actual Loss: 0.9357\n",
      "Baseline Loss: 2.6574 | Actual Loss: 0.7593\n",
      "Baseline Loss: 2.6936 | Actual Loss: 0.4513\n",
      "Baseline Loss: 2.6804 | Actual Loss: 0.2032\n",
      "Baseline Loss: 2.6723 | Actual Loss: 1.2249\n",
      "Baseline Loss: 2.7045 | Actual Loss: 0.8283\n",
      "Baseline Loss: 2.6600 | Actual Loss: 0.6795\n",
      "Baseline Loss: 2.6855 | Actual Loss: 0.8294\n",
      "Baseline Loss: 2.6878 | Actual Loss: 1.0456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 81/1000 [00:37<06:54,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6839 | Actual Loss: 0.4030\n",
      "Baseline Loss: 2.6692 | Actual Loss: 0.3958\n",
      "Baseline Loss: 2.6625 | Actual Loss: 0.7732\n",
      "Baseline Loss: 2.2385 | Actual Loss: 0.1744\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.3357\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.4309\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.7151\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4448\n",
      "Epoch 81/1000: Train Loss: 0.6492, Val Loss: 0.7316\n",
      "Baseline Loss: 2.7054 | Actual Loss: 0.3683\n",
      "Baseline Loss: 2.6851 | Actual Loss: 1.4797\n",
      "Baseline Loss: 2.6321 | Actual Loss: 0.5383\n",
      "Baseline Loss: 2.6763 | Actual Loss: 0.6064\n",
      "Baseline Loss: 2.6670 | Actual Loss: 0.5965\n",
      "Baseline Loss: 2.7081 | Actual Loss: 0.3318\n",
      "Baseline Loss: 2.6637 | Actual Loss: 0.6875\n",
      "Baseline Loss: 2.6383 | Actual Loss: 0.7930\n",
      "Baseline Loss: 2.7298 | Actual Loss: 0.6196\n",
      "Baseline Loss: 2.7086 | Actual Loss: 0.9807\n",
      "Baseline Loss: 2.6856 | Actual Loss: 0.6481\n",
      "Baseline Loss: 2.6643 | Actual Loss: 0.6543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 82/1000 [00:38<07:13,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7037 | Actual Loss: 0.6358\n",
      "Baseline Loss: 2.6349 | Actual Loss: 0.3165\n",
      "Baseline Loss: 2.6699 | Actual Loss: 0.5663\n",
      "Baseline Loss: 2.3092 | Actual Loss: 0.8593\n",
      "Baseline Loss: 2.6263 | Actual Loss: 2.0887\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.5918\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.4532\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.6359\n",
      "Epoch 82/1000: Train Loss: 0.6676, Val Loss: 0.9424\n",
      "Baseline Loss: 2.6958 | Actual Loss: 0.5905\n",
      "Baseline Loss: 2.6987 | Actual Loss: 0.3199\n",
      "Baseline Loss: 2.6991 | Actual Loss: 2.1452\n",
      "Baseline Loss: 2.6777 | Actual Loss: 0.8630\n",
      "Baseline Loss: 2.7063 | Actual Loss: 0.8421\n",
      "Baseline Loss: 2.6350 | Actual Loss: 0.7628\n",
      "Baseline Loss: 2.7275 | Actual Loss: 0.6933\n",
      "Baseline Loss: 2.6694 | Actual Loss: 0.4587\n",
      "Baseline Loss: 2.6965 | Actual Loss: 0.8351\n",
      "Baseline Loss: 2.6548 | Actual Loss: 0.8214\n",
      "Baseline Loss: 2.6573 | Actual Loss: 0.9055\n",
      "Baseline Loss: 2.6845 | Actual Loss: 1.0673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 83/1000 [00:38<06:55,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6744 | Actual Loss: 0.7644\n",
      "Baseline Loss: 2.6639 | Actual Loss: 0.6513\n",
      "Baseline Loss: 2.6642 | Actual Loss: 1.1060\n",
      "Baseline Loss: 2.2823 | Actual Loss: 0.4339\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.1807\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.4989\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.8668\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4917\n",
      "Epoch 83/1000: Train Loss: 0.8288, Val Loss: 0.7595\n",
      "Baseline Loss: 2.6935 | Actual Loss: 0.5491\n",
      "Baseline Loss: 2.6169 | Actual Loss: 0.6149\n",
      "Baseline Loss: 2.6782 | Actual Loss: 0.8107\n",
      "Baseline Loss: 2.6988 | Actual Loss: 0.2757\n",
      "Baseline Loss: 2.7110 | Actual Loss: 0.5330\n",
      "Baseline Loss: 2.6241 | Actual Loss: 1.3735\n",
      "Baseline Loss: 2.6727 | Actual Loss: 0.8790\n",
      "Baseline Loss: 2.6399 | Actual Loss: 0.5683\n",
      "Baseline Loss: 2.7014 | Actual Loss: 0.1863\n",
      "Baseline Loss: 2.6915 | Actual Loss: 0.7249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 84/1000 [00:39<07:00,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6760 | Actual Loss: 1.4161\n",
      "Baseline Loss: 2.6849 | Actual Loss: 0.6885\n",
      "Baseline Loss: 2.6873 | Actual Loss: 0.9183\n",
      "Baseline Loss: 2.6499 | Actual Loss: 0.6137\n",
      "Baseline Loss: 2.7070 | Actual Loss: 0.5624\n",
      "Baseline Loss: 2.2455 | Actual Loss: 0.4431\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.1812\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.5017\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.9111\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4233\n",
      "Epoch 84/1000: Train Loss: 0.6973, Val Loss: 0.7543\n",
      "Baseline Loss: 2.6830 | Actual Loss: 0.5842\n",
      "Baseline Loss: 2.6559 | Actual Loss: 0.8292\n",
      "Baseline Loss: 2.6708 | Actual Loss: 0.8510\n",
      "Baseline Loss: 2.6767 | Actual Loss: 0.7522\n",
      "Baseline Loss: 2.6743 | Actual Loss: 0.7366\n",
      "Baseline Loss: 2.6512 | Actual Loss: 0.6165\n",
      "Baseline Loss: 2.6522 | Actual Loss: 0.5290\n",
      "Baseline Loss: 2.6727 | Actual Loss: 0.6860\n",
      "Baseline Loss: 2.6774 | Actual Loss: 0.6343\n",
      "Baseline Loss: 2.6382 | Actual Loss: 0.8662\n",
      "Baseline Loss: 2.7172 | Actual Loss: 0.5522\n",
      "Baseline Loss: 2.7005 | Actual Loss: 0.5708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 85/1000 [00:39<07:16,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6806 | Actual Loss: 0.7352\n",
      "Baseline Loss: 2.6970 | Actual Loss: 0.3929\n",
      "Baseline Loss: 2.7059 | Actual Loss: 0.9447\n",
      "Baseline Loss: 2.2525 | Actual Loss: 0.4641\n",
      "Baseline Loss: 2.6263 | Actual Loss: 2.0269\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.5068\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.5542\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.7680\n",
      "Epoch 85/1000: Train Loss: 0.6716, Val Loss: 0.9640\n",
      "Baseline Loss: 2.6880 | Actual Loss: 0.3661\n",
      "Baseline Loss: 2.7058 | Actual Loss: 0.3833\n",
      "Baseline Loss: 2.6655 | Actual Loss: 0.6079\n",
      "Baseline Loss: 2.6720 | Actual Loss: 0.5854\n",
      "Baseline Loss: 2.6708 | Actual Loss: 0.8396\n",
      "Baseline Loss: 2.6832 | Actual Loss: 0.7477\n",
      "Baseline Loss: 2.6981 | Actual Loss: 0.3877\n",
      "Baseline Loss: 2.6834 | Actual Loss: 1.1304\n",
      "Baseline Loss: 2.6637 | Actual Loss: 0.3683\n",
      "Baseline Loss: 2.6656 | Actual Loss: 0.4098\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.6046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▊         | 86/1000 [00:40<07:11,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6387 | Actual Loss: 0.2885\n",
      "Baseline Loss: 2.7107 | Actual Loss: 0.7918\n",
      "Baseline Loss: 2.6802 | Actual Loss: 0.7131\n",
      "Baseline Loss: 2.6718 | Actual Loss: 0.9481\n",
      "Baseline Loss: 2.3074 | Actual Loss: 0.5191\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.2032\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3732\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.7303\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.5154\n",
      "Epoch 86/1000: Train Loss: 0.6057, Val Loss: 0.7055\n",
      "Baseline Loss: 2.6549 | Actual Loss: 0.6814\n",
      "Baseline Loss: 2.6763 | Actual Loss: 0.7974\n",
      "Baseline Loss: 2.6563 | Actual Loss: 0.5120\n",
      "Baseline Loss: 2.6845 | Actual Loss: 0.9210\n",
      "Baseline Loss: 2.7030 | Actual Loss: 0.5945\n",
      "Baseline Loss: 2.6805 | Actual Loss: 0.2320\n",
      "Baseline Loss: 2.6671 | Actual Loss: 0.3892\n",
      "Baseline Loss: 2.6340 | Actual Loss: 0.3776\n",
      "Baseline Loss: 2.7234 | Actual Loss: 0.7487\n",
      "Baseline Loss: 2.6741 | Actual Loss: 0.6631\n",
      "Baseline Loss: 2.6357 | Actual Loss: 0.7981\n",
      "Baseline Loss: 2.6885 | Actual Loss: 0.7953\n",
      "Baseline Loss: 2.6479 | Actual Loss: 0.3025\n",
      "Baseline Loss: 2.6699 | Actual Loss: 0.5645\n",
      "Baseline Loss: 2.6513 | Actual Loss: 0.6351\n",
      "Baseline Loss: 2.3235 | Actual Loss: 0.2972\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.5337\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.4050\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.7214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▊         | 87/1000 [00:40<07:02,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5648 | Actual Loss: 0.4815\n",
      "Epoch 87/1000: Train Loss: 0.5819, Val Loss: 0.7854\n",
      "Baseline Loss: 2.6970 | Actual Loss: 0.5935\n",
      "Baseline Loss: 2.6670 | Actual Loss: 0.5461\n",
      "Baseline Loss: 2.6788 | Actual Loss: 0.6089\n",
      "Baseline Loss: 2.6928 | Actual Loss: 0.4696\n",
      "Baseline Loss: 2.6611 | Actual Loss: 0.8173\n",
      "Baseline Loss: 2.6733 | Actual Loss: 0.6631\n",
      "Baseline Loss: 2.7121 | Actual Loss: 0.4677\n",
      "Baseline Loss: 2.6832 | Actual Loss: 0.6311\n",
      "Baseline Loss: 2.7278 | Actual Loss: 0.4791\n",
      "Baseline Loss: 2.6483 | Actual Loss: 0.4970\n",
      "Baseline Loss: 2.6897 | Actual Loss: 0.6486\n",
      "Baseline Loss: 2.6718 | Actual Loss: 0.3679\n",
      "Baseline Loss: 2.6732 | Actual Loss: 2.3649\n",
      "Baseline Loss: 2.6759 | Actual Loss: 0.4231\n",
      "Baseline Loss: 2.6910 | Actual Loss: 1.3912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 88/1000 [00:41<07:18,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2416 | Actual Loss: 0.1115\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.3968\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3385\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.8199\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4165\n",
      "Epoch 88/1000: Train Loss: 0.6925, Val Loss: 0.7429\n",
      "Baseline Loss: 2.6696 | Actual Loss: 0.5292\n",
      "Baseline Loss: 2.6691 | Actual Loss: 0.7735\n",
      "Baseline Loss: 2.7320 | Actual Loss: 0.6079\n",
      "Baseline Loss: 2.6590 | Actual Loss: 0.4141\n",
      "Baseline Loss: 2.7133 | Actual Loss: 0.6994\n",
      "Baseline Loss: 2.7138 | Actual Loss: 0.6701\n",
      "Baseline Loss: 2.6613 | Actual Loss: 0.7743\n",
      "Baseline Loss: 2.6531 | Actual Loss: 0.6391\n",
      "Baseline Loss: 2.6443 | Actual Loss: 0.4141\n",
      "Baseline Loss: 2.6793 | Actual Loss: 0.5521\n",
      "Baseline Loss: 2.6324 | Actual Loss: 1.5095\n",
      "Baseline Loss: 2.6647 | Actual Loss: 0.6168\n",
      "Baseline Loss: 2.6711 | Actual Loss: 0.4115\n",
      "Baseline Loss: 2.6646 | Actual Loss: 2.2831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 89/1000 [00:41<07:17,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6991 | Actual Loss: 0.8945\n",
      "Baseline Loss: 2.2736 | Actual Loss: 0.2797\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.3818\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.4287\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.7117\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4188\n",
      "Epoch 89/1000: Train Loss: 0.7543, Val Loss: 0.7353\n",
      "Baseline Loss: 2.7236 | Actual Loss: 0.9524\n",
      "Baseline Loss: 2.6699 | Actual Loss: 0.5788\n",
      "Baseline Loss: 2.6550 | Actual Loss: 1.6764\n",
      "Baseline Loss: 2.6671 | Actual Loss: 0.3549\n",
      "Baseline Loss: 2.6629 | Actual Loss: 0.7956\n",
      "Baseline Loss: 2.6826 | Actual Loss: 0.3757\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4899\n",
      "Baseline Loss: 2.6538 | Actual Loss: 0.8962\n",
      "Baseline Loss: 2.6622 | Actual Loss: 0.9649\n",
      "Baseline Loss: 2.6616 | Actual Loss: 0.5004\n",
      "Baseline Loss: 2.7321 | Actual Loss: 1.1574\n",
      "Baseline Loss: 2.6684 | Actual Loss: 0.9395\n",
      "Baseline Loss: 2.6877 | Actual Loss: 0.3523\n",
      "Baseline Loss: 2.6675 | Actual Loss: 0.7267\n",
      "Baseline Loss: 2.6579 | Actual Loss: 0.4677\n",
      "Baseline Loss: 2.2903 | Actual Loss: 0.2716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 90/1000 [00:42<06:57,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6263 | Actual Loss: 1.1133\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3491\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.8680\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4457\n",
      "Epoch 90/1000: Train Loss: 0.7188, Val Loss: 0.6941\n",
      "Baseline Loss: 2.6789 | Actual Loss: 0.3014\n",
      "Baseline Loss: 2.6825 | Actual Loss: 0.8008\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.4325\n",
      "Baseline Loss: 2.7182 | Actual Loss: 0.4415\n",
      "Baseline Loss: 2.6575 | Actual Loss: 0.6557\n",
      "Baseline Loss: 2.6341 | Actual Loss: 0.4339\n",
      "Baseline Loss: 2.6860 | Actual Loss: 0.7708\n",
      "Baseline Loss: 2.6787 | Actual Loss: 0.9521\n",
      "Baseline Loss: 2.6657 | Actual Loss: 0.6083\n",
      "Baseline Loss: 2.6546 | Actual Loss: 0.3002\n",
      "Baseline Loss: 2.6423 | Actual Loss: 1.0897\n",
      "Baseline Loss: 2.6815 | Actual Loss: 0.3692\n",
      "Baseline Loss: 2.7515 | Actual Loss: 0.4344\n",
      "Baseline Loss: 2.6948 | Actual Loss: 0.5153\n",
      "Baseline Loss: 2.6602 | Actual Loss: 1.7077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 91/1000 [00:42<07:11,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2859 | Actual Loss: 0.4628\n",
      "Baseline Loss: 2.6263 | Actual Loss: 2.1743\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.5453\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.5894\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.8492\n",
      "Epoch 91/1000: Train Loss: 0.6423, Val Loss: 1.0396\n",
      "Baseline Loss: 2.7144 | Actual Loss: 1.3633\n",
      "Baseline Loss: 2.6382 | Actual Loss: 0.5874\n",
      "Baseline Loss: 2.6819 | Actual Loss: 0.3448\n",
      "Baseline Loss: 2.6563 | Actual Loss: 0.4566\n",
      "Baseline Loss: 2.6868 | Actual Loss: 0.5347\n",
      "Baseline Loss: 2.6916 | Actual Loss: 0.4851\n",
      "Baseline Loss: 2.6618 | Actual Loss: 0.8411\n",
      "Baseline Loss: 2.7187 | Actual Loss: 0.2089\n",
      "Baseline Loss: 2.6628 | Actual Loss: 0.5782\n",
      "Baseline Loss: 2.6637 | Actual Loss: 0.5097\n",
      "Baseline Loss: 2.6869 | Actual Loss: 0.6914\n",
      "Baseline Loss: 2.6872 | Actual Loss: 0.3755\n",
      "Baseline Loss: 2.7034 | Actual Loss: 0.7630\n",
      "Baseline Loss: 2.6547 | Actual Loss: 0.6764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 92/1000 [00:43<07:14,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6724 | Actual Loss: 0.3458\n",
      "Baseline Loss: 2.2483 | Actual Loss: 0.2503\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.1470\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3894\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.5188\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.5304\n",
      "Epoch 92/1000: Train Loss: 0.5632, Val Loss: 0.6464\n",
      "Baseline Loss: 2.6849 | Actual Loss: 0.4746\n",
      "Baseline Loss: 2.6599 | Actual Loss: 0.5946\n",
      "Baseline Loss: 2.6840 | Actual Loss: 1.3645\n",
      "Baseline Loss: 2.6526 | Actual Loss: 0.6639\n",
      "Baseline Loss: 2.7016 | Actual Loss: 0.4594\n",
      "Baseline Loss: 2.6653 | Actual Loss: 0.5786\n",
      "Baseline Loss: 2.6376 | Actual Loss: 1.5869\n",
      "Baseline Loss: 2.7676 | Actual Loss: 0.9184\n",
      "Baseline Loss: 2.6823 | Actual Loss: 0.8976\n",
      "Baseline Loss: 2.6643 | Actual Loss: 0.6615\n",
      "Baseline Loss: 2.6599 | Actual Loss: 0.5667\n",
      "Baseline Loss: 2.6952 | Actual Loss: 0.2771\n",
      "Baseline Loss: 2.6448 | Actual Loss: 0.6689\n",
      "Baseline Loss: 2.6775 | Actual Loss: 0.3062\n",
      "Baseline Loss: 2.6916 | Actual Loss: 0.4087\n",
      "Baseline Loss: 2.2860 | Actual Loss: 0.2084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 93/1000 [00:43<06:55,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6263 | Actual Loss: 1.5955\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.5197\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.4855\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.6663\n",
      "Epoch 93/1000: Train Loss: 0.6648, Val Loss: 0.8168\n",
      "Baseline Loss: 2.6834 | Actual Loss: 0.8733\n",
      "Baseline Loss: 2.6927 | Actual Loss: 0.4633\n",
      "Baseline Loss: 2.6995 | Actual Loss: 2.1610\n",
      "Baseline Loss: 2.7031 | Actual Loss: 2.1285\n",
      "Baseline Loss: 2.6402 | Actual Loss: 0.2415\n",
      "Baseline Loss: 2.7051 | Actual Loss: 0.6267\n",
      "Baseline Loss: 2.6374 | Actual Loss: 0.2506\n",
      "Baseline Loss: 2.6754 | Actual Loss: 0.5727\n",
      "Baseline Loss: 2.6680 | Actual Loss: 0.3926\n",
      "Baseline Loss: 2.6718 | Actual Loss: 0.6140\n",
      "Baseline Loss: 2.6954 | Actual Loss: 1.0551\n",
      "Baseline Loss: 2.7033 | Actual Loss: 0.5457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 94/1000 [00:44<07:10,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6663 | Actual Loss: 0.3300\n",
      "Baseline Loss: 2.6810 | Actual Loss: 0.4569\n",
      "Baseline Loss: 2.6571 | Actual Loss: 0.5492\n",
      "Baseline Loss: 2.2539 | Actual Loss: 1.5711\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.0100\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.4554\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.7492\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4535\n",
      "Epoch 94/1000: Train Loss: 0.8020, Val Loss: 0.6670\n",
      "Baseline Loss: 2.6794 | Actual Loss: 1.6411\n",
      "Baseline Loss: 2.7091 | Actual Loss: 0.5981\n",
      "Baseline Loss: 2.6536 | Actual Loss: 0.5911\n",
      "Baseline Loss: 2.7294 | Actual Loss: 0.3779\n",
      "Baseline Loss: 2.6712 | Actual Loss: 0.6686\n",
      "Baseline Loss: 2.6665 | Actual Loss: 0.6773\n",
      "Baseline Loss: 2.6996 | Actual Loss: 0.5507\n",
      "Baseline Loss: 2.6635 | Actual Loss: 0.6494\n",
      "Baseline Loss: 2.6683 | Actual Loss: 0.5582\n",
      "Baseline Loss: 2.6394 | Actual Loss: 0.5873\n",
      "Baseline Loss: 2.7121 | Actual Loss: 0.6992\n",
      "Baseline Loss: 2.6745 | Actual Loss: 0.4588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 95/1000 [00:44<06:45,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6406 | Actual Loss: 1.1586\n",
      "Baseline Loss: 2.7047 | Actual Loss: 0.3613\n",
      "Baseline Loss: 2.6610 | Actual Loss: 1.7989\n",
      "Baseline Loss: 2.3311 | Actual Loss: 1.9375\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.0167\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3877\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.8173\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4290\n",
      "Epoch 95/1000: Train Loss: 0.8321, Val Loss: 0.6627\n",
      "Baseline Loss: 2.6450 | Actual Loss: 0.7328\n",
      "Baseline Loss: 2.7134 | Actual Loss: 0.5389\n",
      "Baseline Loss: 2.7278 | Actual Loss: 0.5450\n",
      "Baseline Loss: 2.6533 | Actual Loss: 0.5623\n",
      "Baseline Loss: 2.6487 | Actual Loss: 0.3863\n",
      "Baseline Loss: 2.6568 | Actual Loss: 0.5973\n",
      "Baseline Loss: 2.6812 | Actual Loss: 0.3601\n",
      "Baseline Loss: 2.6787 | Actual Loss: 0.4016\n",
      "Baseline Loss: 2.6372 | Actual Loss: 0.5407\n",
      "Baseline Loss: 2.6775 | Actual Loss: 0.6276\n",
      "Baseline Loss: 2.6886 | Actual Loss: 0.5853\n",
      "Baseline Loss: 2.6791 | Actual Loss: 0.5972\n",
      "Baseline Loss: 2.6981 | Actual Loss: 0.2093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 96/1000 [00:45<07:00,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6555 | Actual Loss: 0.9872\n",
      "Baseline Loss: 2.6728 | Actual Loss: 0.5197\n",
      "Baseline Loss: 2.2706 | Actual Loss: 1.2049\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.6019\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3477\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.4830\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.3204\n",
      "Epoch 96/1000: Train Loss: 0.5873, Val Loss: 0.6882\n",
      "Baseline Loss: 2.6697 | Actual Loss: 0.5520\n",
      "Baseline Loss: 2.6841 | Actual Loss: 0.6275\n",
      "Baseline Loss: 2.6933 | Actual Loss: 0.6434\n",
      "Baseline Loss: 2.7092 | Actual Loss: 0.9492\n",
      "Baseline Loss: 2.6860 | Actual Loss: 0.2408\n",
      "Baseline Loss: 2.6304 | Actual Loss: 0.1420\n",
      "Baseline Loss: 2.7260 | Actual Loss: 0.8190\n",
      "Baseline Loss: 2.6320 | Actual Loss: 1.4667\n",
      "Baseline Loss: 2.6387 | Actual Loss: 0.4526\n",
      "Baseline Loss: 2.6653 | Actual Loss: 0.5494\n",
      "Baseline Loss: 2.7235 | Actual Loss: 0.8926\n",
      "Baseline Loss: 2.7268 | Actual Loss: 0.7001\n",
      "Baseline Loss: 2.6685 | Actual Loss: 0.6507\n",
      "Baseline Loss: 2.6533 | Actual Loss: 0.5711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 97/1000 [00:45<06:40,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6755 | Actual Loss: 0.6427\n",
      "Baseline Loss: 2.1874 | Actual Loss: 0.8470\n",
      "Baseline Loss: 2.6263 | Actual Loss: 0.8756\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.4999\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.8147\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4620\n",
      "Epoch 97/1000: Train Loss: 0.6717, Val Loss: 0.6631\n",
      "Baseline Loss: 2.7194 | Actual Loss: 0.7370\n",
      "Baseline Loss: 2.6322 | Actual Loss: 0.7531\n",
      "Baseline Loss: 2.6823 | Actual Loss: 0.4740\n",
      "Baseline Loss: 2.6734 | Actual Loss: 0.5698\n",
      "Baseline Loss: 2.7020 | Actual Loss: 0.3482\n",
      "Baseline Loss: 2.6688 | Actual Loss: 0.4607\n",
      "Baseline Loss: 2.6980 | Actual Loss: 0.3956\n",
      "Baseline Loss: 2.6733 | Actual Loss: 0.5900\n",
      "Baseline Loss: 2.6915 | Actual Loss: 0.8947\n",
      "Baseline Loss: 2.6760 | Actual Loss: 0.5931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 98/1000 [00:45<06:45,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6487 | Actual Loss: 1.9854\n",
      "Baseline Loss: 2.6753 | Actual Loss: 0.5118\n",
      "Baseline Loss: 2.7067 | Actual Loss: 1.3765\n",
      "Baseline Loss: 2.6728 | Actual Loss: 1.8747\n",
      "Baseline Loss: 2.6672 | Actual Loss: 0.6612\n",
      "Baseline Loss: 2.2548 | Actual Loss: 1.5547\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.5730\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.5228\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.4843\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4695\n",
      "Epoch 98/1000: Train Loss: 0.8613, Val Loss: 0.7624\n",
      "Baseline Loss: 2.6872 | Actual Loss: 0.9839\n",
      "Baseline Loss: 2.6822 | Actual Loss: 0.5175\n",
      "Baseline Loss: 2.6661 | Actual Loss: 0.6200\n",
      "Baseline Loss: 2.6591 | Actual Loss: 0.6181\n",
      "Baseline Loss: 2.6708 | Actual Loss: 0.6623\n",
      "Baseline Loss: 2.7021 | Actual Loss: 0.4489\n",
      "Baseline Loss: 2.6878 | Actual Loss: 0.6085\n",
      "Baseline Loss: 2.6777 | Actual Loss: 0.4077\n",
      "Baseline Loss: 2.6839 | Actual Loss: 0.4966\n",
      "Baseline Loss: 2.6492 | Actual Loss: 0.6632\n",
      "Baseline Loss: 2.7126 | Actual Loss: 0.8935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 99/1000 [00:46<07:05,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6952 | Actual Loss: 0.5373\n",
      "Baseline Loss: 2.6722 | Actual Loss: 0.5721\n",
      "Baseline Loss: 2.6698 | Actual Loss: 0.4516\n",
      "Baseline Loss: 2.6504 | Actual Loss: 0.6509\n",
      "Baseline Loss: 2.2728 | Actual Loss: 0.1789\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.1928\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.5251\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.4318\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4430\n",
      "Epoch 99/1000: Train Loss: 0.5819, Val Loss: 0.6482\n",
      "Baseline Loss: 2.6890 | Actual Loss: 0.7948\n",
      "Baseline Loss: 2.6726 | Actual Loss: 0.7662\n",
      "Baseline Loss: 2.6311 | Actual Loss: 0.2604\n",
      "Baseline Loss: 2.6683 | Actual Loss: 0.5433\n",
      "Baseline Loss: 2.6303 | Actual Loss: 0.3087\n",
      "Baseline Loss: 2.6709 | Actual Loss: 0.4883\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5844\n",
      "Baseline Loss: 2.6925 | Actual Loss: 0.6546\n",
      "Baseline Loss: 2.6818 | Actual Loss: 0.3081\n",
      "Baseline Loss: 2.6771 | Actual Loss: 0.7452\n",
      "Baseline Loss: 2.6775 | Actual Loss: 0.4508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 100/1000 [00:46<06:42,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6791 | Actual Loss: 0.6364\n",
      "Baseline Loss: 2.6399 | Actual Loss: 0.3791\n",
      "Baseline Loss: 2.6528 | Actual Loss: 0.4848\n",
      "Baseline Loss: 2.6936 | Actual Loss: 0.2424\n",
      "Baseline Loss: 2.3418 | Actual Loss: 0.1989\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.3394\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3779\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.5149\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.3896\n",
      "Epoch 100/1000: Train Loss: 0.4904, Val Loss: 0.6555\n",
      "Baseline Loss: 2.6617 | Actual Loss: 0.4983\n",
      "Baseline Loss: 2.6506 | Actual Loss: 0.5934\n",
      "Baseline Loss: 2.6511 | Actual Loss: 0.1153\n",
      "Baseline Loss: 2.6693 | Actual Loss: 0.8562\n",
      "Baseline Loss: 2.6855 | Actual Loss: 0.9083\n",
      "Baseline Loss: 2.6808 | Actual Loss: 0.5805\n",
      "Baseline Loss: 2.6516 | Actual Loss: 0.5185\n",
      "Baseline Loss: 2.7359 | Actual Loss: 0.4778\n",
      "Baseline Loss: 2.6547 | Actual Loss: 0.5664\n",
      "Baseline Loss: 2.6808 | Actual Loss: 0.7558\n",
      "Baseline Loss: 2.6714 | Actual Loss: 0.8752\n",
      "Baseline Loss: 2.6888 | Actual Loss: 0.1941\n",
      "Baseline Loss: 2.6953 | Actual Loss: 0.5525\n",
      "Baseline Loss: 2.6746 | Actual Loss: 0.6165\n",
      "Baseline Loss: 2.6876 | Actual Loss: 0.3513\n",
      "Baseline Loss: 2.3174 | Actual Loss: 0.1292\n",
      "Baseline Loss: 2.6263 | Actual Loss: 2.0258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 101/1000 [00:47<06:57,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7243 | Actual Loss: 0.3905\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.4314\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.3822\n",
      "Epoch 101/1000: Train Loss: 0.5368, Val Loss: 0.8075\n",
      "Baseline Loss: 2.7473 | Actual Loss: 0.5492\n",
      "Baseline Loss: 2.6424 | Actual Loss: 0.4057\n",
      "Baseline Loss: 2.6432 | Actual Loss: 0.5278\n",
      "Baseline Loss: 2.6603 | Actual Loss: 0.3646\n",
      "Baseline Loss: 2.6686 | Actual Loss: 0.3269\n",
      "Baseline Loss: 2.7070 | Actual Loss: 0.5857\n",
      "Baseline Loss: 2.7007 | Actual Loss: 0.3850\n",
      "Baseline Loss: 2.6564 | Actual Loss: 0.5571\n",
      "Baseline Loss: 2.6680 | Actual Loss: 0.3756\n",
      "Baseline Loss: 2.6405 | Actual Loss: 1.3131\n",
      "Baseline Loss: 2.6823 | Actual Loss: 1.2699\n",
      "Baseline Loss: 2.6746 | Actual Loss: 0.7754\n",
      "Baseline Loss: 2.6519 | Actual Loss: 0.7984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 102/1000 [00:47<07:09,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7083 | Actual Loss: 0.3773\n",
      "Baseline Loss: 2.7184 | Actual Loss: 0.6699\n",
      "Baseline Loss: 2.3083 | Actual Loss: 0.1063\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.2181\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.4466\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.5201\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4111\n",
      "Epoch 102/1000: Train Loss: 0.5867, Val Loss: 0.6490\n",
      "Baseline Loss: 2.6697 | Actual Loss: 0.1144\n",
      "Baseline Loss: 2.6417 | Actual Loss: 0.3981\n",
      "Baseline Loss: 2.6883 | Actual Loss: 0.5072\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.8227\n",
      "Baseline Loss: 2.6896 | Actual Loss: 0.7204\n",
      "Baseline Loss: 2.6573 | Actual Loss: 0.5900\n",
      "Baseline Loss: 2.6679 | Actual Loss: 0.2959\n",
      "Baseline Loss: 2.6878 | Actual Loss: 0.6152\n",
      "Baseline Loss: 2.6588 | Actual Loss: 0.3695\n",
      "Baseline Loss: 2.7040 | Actual Loss: 0.7229\n",
      "Baseline Loss: 2.6612 | Actual Loss: 0.3378\n",
      "Baseline Loss: 2.6888 | Actual Loss: 0.8802\n",
      "Baseline Loss: 2.6670 | Actual Loss: 0.4669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 103/1000 [00:48<06:46,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6820 | Actual Loss: 0.8295\n",
      "Baseline Loss: 2.6701 | Actual Loss: 0.4793\n",
      "Baseline Loss: 2.2579 | Actual Loss: 0.2958\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.6040\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3697\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.5198\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4389\n",
      "Epoch 103/1000: Train Loss: 0.5279, Val Loss: 0.7331\n",
      "Baseline Loss: 2.6980 | Actual Loss: 0.4957\n",
      "Baseline Loss: 2.6666 | Actual Loss: 0.4647\n",
      "Baseline Loss: 2.6508 | Actual Loss: 0.4171\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.4659\n",
      "Baseline Loss: 2.6667 | Actual Loss: 0.7191\n",
      "Baseline Loss: 2.6819 | Actual Loss: 0.5106\n",
      "Baseline Loss: 2.6746 | Actual Loss: 0.6885\n",
      "Baseline Loss: 2.6822 | Actual Loss: 0.7362\n",
      "Baseline Loss: 2.7001 | Actual Loss: 0.5756\n",
      "Baseline Loss: 2.6970 | Actual Loss: 2.4292\n",
      "Baseline Loss: 2.7052 | Actual Loss: 0.7815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 104/1000 [00:48<07:03,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6999 | Actual Loss: 0.3118\n",
      "Baseline Loss: 2.6689 | Actual Loss: 0.4073\n",
      "Baseline Loss: 2.7089 | Actual Loss: 0.2366\n",
      "Baseline Loss: 2.6500 | Actual Loss: 0.3175\n",
      "Baseline Loss: 2.2721 | Actual Loss: 0.3276\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.1507\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.4061\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.6380\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.3405\n",
      "Epoch 104/1000: Train Loss: 0.6178, Val Loss: 0.6338\n",
      "Baseline Loss: 2.6836 | Actual Loss: 0.5296\n",
      "Baseline Loss: 2.6983 | Actual Loss: 0.2271\n",
      "Baseline Loss: 2.6591 | Actual Loss: 0.4009\n",
      "Baseline Loss: 2.6864 | Actual Loss: 0.9115\n",
      "Baseline Loss: 2.7066 | Actual Loss: 0.3423\n",
      "Baseline Loss: 2.6601 | Actual Loss: 0.4842\n",
      "Baseline Loss: 2.6478 | Actual Loss: 0.6976\n",
      "Baseline Loss: 2.6778 | Actual Loss: 0.3606\n",
      "Baseline Loss: 2.6851 | Actual Loss: 0.5255\n",
      "Baseline Loss: 2.6763 | Actual Loss: 2.1308\n",
      "Baseline Loss: 2.7115 | Actual Loss: 0.3614\n",
      "Baseline Loss: 2.6938 | Actual Loss: 0.6168\n",
      "Baseline Loss: 2.6559 | Actual Loss: 0.1804\n",
      "Baseline Loss: 2.6523 | Actual Loss: 0.4195\n",
      "Baseline Loss: 2.6818 | Actual Loss: 0.7685\n",
      "Baseline Loss: 2.2423 | Actual Loss: 0.7313\n",
      "Baseline Loss: 2.6263 | Actual Loss: 0.9947\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.4339\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.5039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 105/1000 [00:49<07:06,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5648 | Actual Loss: 0.2663\n",
      "Epoch 105/1000: Train Loss: 0.6055, Val Loss: 0.5497\n",
      "New best validation loss: 0.5497\n",
      "Baseline Loss: 2.6565 | Actual Loss: 0.3746\n",
      "Baseline Loss: 2.6498 | Actual Loss: 0.6462\n",
      "Baseline Loss: 2.7279 | Actual Loss: 0.7866\n",
      "Baseline Loss: 2.6769 | Actual Loss: 1.0401\n",
      "Baseline Loss: 2.6848 | Actual Loss: 0.3262\n",
      "Baseline Loss: 2.6625 | Actual Loss: 0.3813\n",
      "Baseline Loss: 2.6954 | Actual Loss: 0.5260\n",
      "Baseline Loss: 2.6449 | Actual Loss: 0.5953\n",
      "Baseline Loss: 2.7305 | Actual Loss: 0.2910\n",
      "Baseline Loss: 2.6888 | Actual Loss: 0.4855\n",
      "Baseline Loss: 2.6897 | Actual Loss: 0.4413\n",
      "Baseline Loss: 2.6995 | Actual Loss: 0.4609\n",
      "Baseline Loss: 2.7111 | Actual Loss: 0.8364\n",
      "Baseline Loss: 2.6892 | Actual Loss: 0.6622\n",
      "Baseline Loss: 2.6443 | Actual Loss: 0.1972\n",
      "Baseline Loss: 2.2561 | Actual Loss: 0.4666\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.0879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 106/1000 [00:49<07:11,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7243 | Actual Loss: 0.6098\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.5217\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.2777\n",
      "Epoch 106/1000: Train Loss: 0.5323, Val Loss: 0.6243\n",
      "Baseline Loss: 2.6516 | Actual Loss: 0.3685\n",
      "Baseline Loss: 2.6998 | Actual Loss: 2.1088\n",
      "Baseline Loss: 2.6795 | Actual Loss: 0.3728\n",
      "Baseline Loss: 2.6797 | Actual Loss: 0.7143\n",
      "Baseline Loss: 2.6835 | Actual Loss: 0.3909\n",
      "Baseline Loss: 2.6625 | Actual Loss: 0.3109\n",
      "Baseline Loss: 2.6790 | Actual Loss: 0.5123\n",
      "Baseline Loss: 2.6850 | Actual Loss: 0.3664\n",
      "Baseline Loss: 2.6626 | Actual Loss: 0.8111\n",
      "Baseline Loss: 2.6818 | Actual Loss: 0.3118\n",
      "Baseline Loss: 2.6664 | Actual Loss: 0.9107\n",
      "Baseline Loss: 2.6436 | Actual Loss: 0.2882\n",
      "Baseline Loss: 2.6574 | Actual Loss: 0.7558\n",
      "Baseline Loss: 2.6609 | Actual Loss: 0.2536\n",
      "Baseline Loss: 2.7174 | Actual Loss: 0.6824\n",
      "Baseline Loss: 2.3606 | Actual Loss: 0.2414\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.6758\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.4074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 107/1000 [00:50<06:56,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6758 | Actual Loss: 0.6030\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4566\n",
      "Epoch 107/1000: Train Loss: 0.5875, Val Loss: 0.7857\n",
      "Baseline Loss: 2.6721 | Actual Loss: 0.6549\n",
      "Baseline Loss: 2.6829 | Actual Loss: 0.4775\n",
      "Baseline Loss: 2.6746 | Actual Loss: 0.3695\n",
      "Baseline Loss: 2.6550 | Actual Loss: 0.2360\n",
      "Baseline Loss: 2.7104 | Actual Loss: 0.4503\n",
      "Baseline Loss: 2.7044 | Actual Loss: 0.5480\n",
      "Baseline Loss: 2.6799 | Actual Loss: 0.5122\n",
      "Baseline Loss: 2.6915 | Actual Loss: 0.2896\n",
      "Baseline Loss: 2.6672 | Actual Loss: 0.2127\n",
      "Baseline Loss: 2.6667 | Actual Loss: 0.5028\n",
      "Baseline Loss: 2.6730 | Actual Loss: 0.3510\n",
      "Baseline Loss: 2.6882 | Actual Loss: 0.5918\n",
      "Baseline Loss: 2.6456 | Actual Loss: 0.4997\n",
      "Baseline Loss: 2.6593 | Actual Loss: 0.4692\n",
      "Baseline Loss: 2.6699 | Actual Loss: 0.4763\n",
      "Baseline Loss: 2.3114 | Actual Loss: 0.5023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 108/1000 [00:50<07:05,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6263 | Actual Loss: 1.1457\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3875\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.4883\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4917\n",
      "Epoch 108/1000: Train Loss: 0.4465, Val Loss: 0.6283\n",
      "Baseline Loss: 2.6567 | Actual Loss: 0.8094\n",
      "Baseline Loss: 2.6503 | Actual Loss: 0.4475\n",
      "Baseline Loss: 2.7150 | Actual Loss: 0.4454\n",
      "Baseline Loss: 2.6899 | Actual Loss: 0.3945\n",
      "Baseline Loss: 2.7103 | Actual Loss: 0.3133\n",
      "Baseline Loss: 2.6838 | Actual Loss: 0.3024\n",
      "Baseline Loss: 2.6694 | Actual Loss: 0.4432\n",
      "Baseline Loss: 2.7233 | Actual Loss: 0.5104\n",
      "Baseline Loss: 2.6780 | Actual Loss: 0.5668\n",
      "Baseline Loss: 2.6909 | Actual Loss: 1.2778\n",
      "Baseline Loss: 2.6394 | Actual Loss: 1.1767\n",
      "Baseline Loss: 2.6991 | Actual Loss: 0.2959\n",
      "Baseline Loss: 2.6430 | Actual Loss: 0.8201\n",
      "Baseline Loss: 2.6656 | Actual Loss: 0.3588\n",
      "Baseline Loss: 2.6899 | Actual Loss: 0.3973\n",
      "Baseline Loss: 2.2462 | Actual Loss: 0.2393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 109/1000 [00:51<07:16,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6263 | Actual Loss: 1.3552\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3814\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.4131\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4651\n",
      "Epoch 109/1000: Train Loss: 0.5499, Val Loss: 0.6537\n",
      "Baseline Loss: 2.6582 | Actual Loss: 0.4360\n",
      "Baseline Loss: 2.6617 | Actual Loss: 0.5266\n",
      "Baseline Loss: 2.6605 | Actual Loss: 0.7558\n",
      "Baseline Loss: 2.7288 | Actual Loss: 0.6169\n",
      "Baseline Loss: 2.6842 | Actual Loss: 0.6243\n",
      "Baseline Loss: 2.6817 | Actual Loss: 0.0995\n",
      "Baseline Loss: 2.6704 | Actual Loss: 0.5321\n",
      "Baseline Loss: 2.6659 | Actual Loss: 0.4752\n",
      "Baseline Loss: 2.6894 | Actual Loss: 0.5205\n",
      "Baseline Loss: 2.6705 | Actual Loss: 2.4264\n",
      "Baseline Loss: 2.7041 | Actual Loss: 0.1939\n",
      "Baseline Loss: 2.6913 | Actual Loss: 0.6199\n",
      "Baseline Loss: 2.6407 | Actual Loss: 0.7432\n",
      "Baseline Loss: 2.6679 | Actual Loss: 0.6609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 110/1000 [00:51<06:48,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7182 | Actual Loss: 0.5965\n",
      "Baseline Loss: 2.2889 | Actual Loss: 0.0692\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.2391\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3844\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.5685\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.3881\n",
      "Epoch 110/1000: Train Loss: 0.6186, Val Loss: 0.6450\n",
      "Baseline Loss: 2.6310 | Actual Loss: 2.2632\n",
      "Baseline Loss: 2.7007 | Actual Loss: 0.1727\n",
      "Baseline Loss: 2.7009 | Actual Loss: 0.5866\n",
      "Baseline Loss: 2.7632 | Actual Loss: 0.4490\n",
      "Baseline Loss: 2.6663 | Actual Loss: 0.4268\n",
      "Baseline Loss: 2.6806 | Actual Loss: 0.3680\n",
      "Baseline Loss: 2.6847 | Actual Loss: 0.4782\n",
      "Baseline Loss: 2.6683 | Actual Loss: 0.6413\n",
      "Baseline Loss: 2.6723 | Actual Loss: 0.8567\n",
      "Baseline Loss: 2.6631 | Actual Loss: 0.5728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 111/1000 [00:52<06:58,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7047 | Actual Loss: 0.6916\n",
      "Baseline Loss: 2.6714 | Actual Loss: 0.3280\n",
      "Baseline Loss: 2.6647 | Actual Loss: 0.7195\n",
      "Baseline Loss: 2.6873 | Actual Loss: 0.3062\n",
      "Baseline Loss: 2.6888 | Actual Loss: 0.8427\n",
      "Baseline Loss: 2.2990 | Actual Loss: 0.1803\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.8351\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.4142\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.5762\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4283\n",
      "Epoch 111/1000: Train Loss: 0.6177, Val Loss: 0.8135\n",
      "Baseline Loss: 2.7114 | Actual Loss: 0.4557\n",
      "Baseline Loss: 2.6761 | Actual Loss: 2.3581\n",
      "Baseline Loss: 2.6784 | Actual Loss: 0.5122\n",
      "Baseline Loss: 2.6573 | Actual Loss: 1.5946\n",
      "Baseline Loss: 2.6458 | Actual Loss: 0.3553\n",
      "Baseline Loss: 2.6452 | Actual Loss: 0.3197\n",
      "Baseline Loss: 2.7058 | Actual Loss: 0.6295\n",
      "Baseline Loss: 2.7034 | Actual Loss: 0.4525\n",
      "Baseline Loss: 2.6581 | Actual Loss: 0.2365\n",
      "Baseline Loss: 2.6550 | Actual Loss: 0.1364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 112/1000 [00:52<06:50,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6765 | Actual Loss: 0.3279\n",
      "Baseline Loss: 2.7174 | Actual Loss: 0.6001\n",
      "Baseline Loss: 2.7161 | Actual Loss: 0.4814\n",
      "Baseline Loss: 2.6774 | Actual Loss: 0.6892\n",
      "Baseline Loss: 2.6877 | Actual Loss: 0.2684\n",
      "Baseline Loss: 2.2444 | Actual Loss: 0.3739\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.2982\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3951\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.6333\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4248\n",
      "Epoch 112/1000: Train Loss: 0.6120, Val Loss: 0.6878\n",
      "Baseline Loss: 2.6530 | Actual Loss: 2.0388\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.7998\n",
      "Baseline Loss: 2.7081 | Actual Loss: 0.3373\n",
      "Baseline Loss: 2.6529 | Actual Loss: 0.4326\n",
      "Baseline Loss: 2.6691 | Actual Loss: 0.3746\n",
      "Baseline Loss: 2.6935 | Actual Loss: 0.5444\n",
      "Baseline Loss: 2.6914 | Actual Loss: 0.5278\n",
      "Baseline Loss: 2.6601 | Actual Loss: 0.3187\n",
      "Baseline Loss: 2.6963 | Actual Loss: 0.7788\n",
      "Baseline Loss: 2.6575 | Actual Loss: 0.4094\n",
      "Baseline Loss: 2.6914 | Actual Loss: 0.5265\n",
      "Baseline Loss: 2.6650 | Actual Loss: 0.5391\n",
      "Baseline Loss: 2.6650 | Actual Loss: 0.4680\n",
      "Baseline Loss: 2.6327 | Actual Loss: 0.4213\n",
      "Baseline Loss: 2.6509 | Actual Loss: 0.3400\n",
      "Baseline Loss: 2.2391 | Actual Loss: 0.1351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█▏        | 113/1000 [00:52<07:02,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6263 | Actual Loss: 1.1196\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3741\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.6125\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.3053\n",
      "Epoch 113/1000: Train Loss: 0.5620, Val Loss: 0.6029\n",
      "Baseline Loss: 2.7123 | Actual Loss: 0.4706\n",
      "Baseline Loss: 2.6546 | Actual Loss: 0.6376\n",
      "Baseline Loss: 2.6679 | Actual Loss: 2.4188\n",
      "Baseline Loss: 2.6504 | Actual Loss: 0.2437\n",
      "Baseline Loss: 2.6705 | Actual Loss: 0.1791\n",
      "Baseline Loss: 2.6702 | Actual Loss: 0.3209\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4858\n",
      "Baseline Loss: 2.6454 | Actual Loss: 0.5581\n",
      "Baseline Loss: 2.6759 | Actual Loss: 0.4671\n",
      "Baseline Loss: 2.6887 | Actual Loss: 0.4568\n",
      "Baseline Loss: 2.6885 | Actual Loss: 1.3045\n",
      "Baseline Loss: 2.6843 | Actual Loss: 0.7434\n",
      "Baseline Loss: 2.6966 | Actual Loss: 0.7558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█▏        | 114/1000 [00:53<07:10,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6559 | Actual Loss: 0.1456\n",
      "Baseline Loss: 2.6669 | Actual Loss: 0.4382\n",
      "Baseline Loss: 2.2629 | Actual Loss: 0.5825\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.1904\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3619\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.5630\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.3991\n",
      "Epoch 114/1000: Train Loss: 0.6380, Val Loss: 0.6286\n",
      "Baseline Loss: 2.6707 | Actual Loss: 0.5217\n",
      "Baseline Loss: 2.6989 | Actual Loss: 0.5536\n",
      "Baseline Loss: 2.7357 | Actual Loss: 1.1849\n",
      "Baseline Loss: 2.6804 | Actual Loss: 0.6660\n",
      "Baseline Loss: 2.6816 | Actual Loss: 0.6458\n",
      "Baseline Loss: 2.7439 | Actual Loss: 0.2873\n",
      "Baseline Loss: 2.6678 | Actual Loss: 0.4427\n",
      "Baseline Loss: 2.6497 | Actual Loss: 0.2840\n",
      "Baseline Loss: 2.6563 | Actual Loss: 1.2955\n",
      "Baseline Loss: 2.6806 | Actual Loss: 0.6785\n",
      "Baseline Loss: 2.6629 | Actual Loss: 0.4739\n",
      "Baseline Loss: 2.6605 | Actual Loss: 0.6314\n",
      "Baseline Loss: 2.7088 | Actual Loss: 0.7349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 115/1000 [00:53<06:49,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6633 | Actual Loss: 0.3327\n",
      "Baseline Loss: 2.6482 | Actual Loss: 0.4391\n",
      "Baseline Loss: 2.2132 | Actual Loss: 0.2088\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.2818\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3843\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.5448\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.2612\n",
      "Epoch 115/1000: Train Loss: 0.5863, Val Loss: 0.6180\n",
      "Baseline Loss: 2.6715 | Actual Loss: 0.3978\n",
      "Baseline Loss: 2.6985 | Actual Loss: 0.4489\n",
      "Baseline Loss: 2.6909 | Actual Loss: 0.6663\n",
      "Baseline Loss: 2.6821 | Actual Loss: 0.5083\n",
      "Baseline Loss: 2.6819 | Actual Loss: 0.7280\n",
      "Baseline Loss: 2.6530 | Actual Loss: 0.7570\n",
      "Baseline Loss: 2.6447 | Actual Loss: 2.0646\n",
      "Baseline Loss: 2.6406 | Actual Loss: 0.5654\n",
      "Baseline Loss: 2.6784 | Actual Loss: 0.5819\n",
      "Baseline Loss: 2.6934 | Actual Loss: 0.4062\n",
      "Baseline Loss: 2.7141 | Actual Loss: 0.6649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 116/1000 [00:54<06:55,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6673 | Actual Loss: 0.4592\n",
      "Baseline Loss: 2.6476 | Actual Loss: 0.5175\n",
      "Baseline Loss: 2.6629 | Actual Loss: 0.4675\n",
      "Baseline Loss: 2.6791 | Actual Loss: 1.5373\n",
      "Baseline Loss: 2.2806 | Actual Loss: 0.8219\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.2088\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3496\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.4943\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4877\n",
      "Epoch 116/1000: Train Loss: 0.7245, Val Loss: 0.6351\n",
      "Baseline Loss: 2.6924 | Actual Loss: 0.2768\n",
      "Baseline Loss: 2.6721 | Actual Loss: 0.5583\n",
      "Baseline Loss: 2.7216 | Actual Loss: 0.5002\n",
      "Baseline Loss: 2.6888 | Actual Loss: 0.3710\n",
      "Baseline Loss: 2.6686 | Actual Loss: 0.8006\n",
      "Baseline Loss: 2.6972 | Actual Loss: 0.5846\n",
      "Baseline Loss: 2.6767 | Actual Loss: 0.4776\n",
      "Baseline Loss: 2.6523 | Actual Loss: 0.5034\n",
      "Baseline Loss: 2.6497 | Actual Loss: 0.4974\n",
      "Baseline Loss: 2.7141 | Actual Loss: 0.1854\n",
      "Baseline Loss: 2.6838 | Actual Loss: 0.2546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 117/1000 [00:54<06:35,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6658 | Actual Loss: 0.4051\n",
      "Baseline Loss: 2.6794 | Actual Loss: 0.2699\n",
      "Baseline Loss: 2.6974 | Actual Loss: 0.4908\n",
      "Baseline Loss: 2.6581 | Actual Loss: 0.5897\n",
      "Baseline Loss: 2.2558 | Actual Loss: 0.3588\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.6575\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3745\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.6098\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.3197\n",
      "Epoch 117/1000: Train Loss: 0.4453, Val Loss: 0.7404\n",
      "Baseline Loss: 2.6766 | Actual Loss: 0.6518\n",
      "Baseline Loss: 2.6675 | Actual Loss: 0.4954\n",
      "Baseline Loss: 2.7078 | Actual Loss: 0.6992\n",
      "Baseline Loss: 2.6993 | Actual Loss: 0.1704\n",
      "Baseline Loss: 2.6838 | Actual Loss: 0.4145\n",
      "Baseline Loss: 2.6526 | Actual Loss: 0.5099\n",
      "Baseline Loss: 2.6733 | Actual Loss: 0.6156\n",
      "Baseline Loss: 2.6664 | Actual Loss: 0.4071\n",
      "Baseline Loss: 2.6467 | Actual Loss: 0.5821\n",
      "Baseline Loss: 2.6636 | Actual Loss: 0.5532\n",
      "Baseline Loss: 2.6421 | Actual Loss: 0.4285\n",
      "Baseline Loss: 2.6791 | Actual Loss: 0.1034\n",
      "Baseline Loss: 2.7022 | Actual Loss: 0.5295\n",
      "Baseline Loss: 2.6397 | Actual Loss: 0.2015\n",
      "Baseline Loss: 2.6629 | Actual Loss: 0.8647\n",
      "Baseline Loss: 2.3490 | Actual Loss: 0.1823\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.4224\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.4772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 118/1000 [00:55<06:45,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6758 | Actual Loss: 0.4045\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.2980\n",
      "Epoch 118/1000: Train Loss: 0.4631, Val Loss: 0.6505\n",
      "Baseline Loss: 2.6850 | Actual Loss: 0.3324\n",
      "Baseline Loss: 2.6738 | Actual Loss: 0.2869\n",
      "Baseline Loss: 2.7453 | Actual Loss: 0.5046\n",
      "Baseline Loss: 2.7111 | Actual Loss: 0.6170\n",
      "Baseline Loss: 2.6542 | Actual Loss: 0.5192\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.8556\n",
      "Baseline Loss: 2.6645 | Actual Loss: 0.7143\n",
      "Baseline Loss: 2.6517 | Actual Loss: 0.2338\n",
      "Baseline Loss: 2.7200 | Actual Loss: 0.3170\n",
      "Baseline Loss: 2.6800 | Actual Loss: 1.0520\n",
      "Baseline Loss: 2.6541 | Actual Loss: 0.6042\n",
      "Baseline Loss: 2.6912 | Actual Loss: 0.6453\n",
      "Baseline Loss: 2.6504 | Actual Loss: 0.2635\n",
      "Baseline Loss: 2.6720 | Actual Loss: 0.7176\n",
      "Baseline Loss: 2.6515 | Actual Loss: 0.4555\n",
      "Baseline Loss: 2.3014 | Actual Loss: 1.6565\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.5408\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.4779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 119/1000 [00:55<06:56,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6758 | Actual Loss: 0.5319\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.3644\n",
      "Epoch 119/1000: Train Loss: 0.6110, Val Loss: 0.7287\n",
      "Baseline Loss: 2.6589 | Actual Loss: 0.4544\n",
      "Baseline Loss: 2.7310 | Actual Loss: 1.5688\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.3437\n",
      "Baseline Loss: 2.6522 | Actual Loss: 0.3435\n",
      "Baseline Loss: 2.6802 | Actual Loss: 0.3677\n",
      "Baseline Loss: 2.6615 | Actual Loss: 0.3134\n",
      "Baseline Loss: 2.6443 | Actual Loss: 0.9559\n",
      "Baseline Loss: 2.7492 | Actual Loss: 0.5280\n",
      "Baseline Loss: 2.6804 | Actual Loss: 0.4773\n",
      "Baseline Loss: 2.6967 | Actual Loss: 0.3285\n",
      "Baseline Loss: 2.6765 | Actual Loss: 0.4752\n",
      "Baseline Loss: 2.6591 | Actual Loss: 0.6448\n",
      "Baseline Loss: 2.6397 | Actual Loss: 0.5733\n",
      "Baseline Loss: 2.6974 | Actual Loss: 0.6273\n",
      "Baseline Loss: 2.6595 | Actual Loss: 0.3166\n",
      "Baseline Loss: 2.2464 | Actual Loss: 0.2455\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.3346\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.4139\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.4904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 120/1000 [00:56<06:36,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5648 | Actual Loss: 0.4259\n",
      "Epoch 120/1000: Train Loss: 0.5353, Val Loss: 0.6662\n",
      "Baseline Loss: 2.6537 | Actual Loss: 0.3096\n",
      "Baseline Loss: 2.6551 | Actual Loss: 0.3443\n",
      "Baseline Loss: 2.6565 | Actual Loss: 0.4804\n",
      "Baseline Loss: 2.6663 | Actual Loss: 1.3153\n",
      "Baseline Loss: 2.7030 | Actual Loss: 0.3769\n",
      "Baseline Loss: 2.6977 | Actual Loss: 0.2595\n",
      "Baseline Loss: 2.6485 | Actual Loss: 0.6116\n",
      "Baseline Loss: 2.6944 | Actual Loss: 0.4685\n",
      "Baseline Loss: 2.6987 | Actual Loss: 0.2878\n",
      "Baseline Loss: 2.6707 | Actual Loss: 0.8626\n",
      "Baseline Loss: 2.6742 | Actual Loss: 0.7681\n",
      "Baseline Loss: 2.6552 | Actual Loss: 0.4744\n",
      "Baseline Loss: 2.7598 | Actual Loss: 0.2262\n",
      "Baseline Loss: 2.6704 | Actual Loss: 0.6373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 121/1000 [00:56<06:54,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6938 | Actual Loss: 0.4179\n",
      "Baseline Loss: 2.2791 | Actual Loss: 0.4626\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.6483\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.4215\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.5436\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4816\n",
      "Epoch 121/1000: Train Loss: 0.5189, Val Loss: 0.7737\n",
      "Baseline Loss: 2.6728 | Actual Loss: 0.6687\n",
      "Baseline Loss: 2.6451 | Actual Loss: 0.1381\n",
      "Baseline Loss: 2.6550 | Actual Loss: 1.5831\n",
      "Baseline Loss: 2.6871 | Actual Loss: 0.9184\n",
      "Baseline Loss: 2.6509 | Actual Loss: 0.5540\n",
      "Baseline Loss: 2.6875 | Actual Loss: 0.2462\n",
      "Baseline Loss: 2.7040 | Actual Loss: 0.1645\n",
      "Baseline Loss: 2.6737 | Actual Loss: 0.4211\n",
      "Baseline Loss: 2.6663 | Actual Loss: 0.5974\n",
      "Baseline Loss: 2.6935 | Actual Loss: 0.9533\n",
      "Baseline Loss: 2.6617 | Actual Loss: 0.9478\n",
      "Baseline Loss: 2.6869 | Actual Loss: 0.3718\n",
      "Baseline Loss: 2.6536 | Actual Loss: 0.5861\n",
      "Baseline Loss: 2.6691 | Actual Loss: 0.5106\n",
      "Baseline Loss: 2.6926 | Actual Loss: 0.4124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 122/1000 [00:57<06:34,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2972 | Actual Loss: 0.1072\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.1686\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3831\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.6727\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4263\n",
      "Epoch 122/1000: Train Loss: 0.5738, Val Loss: 0.6627\n",
      "Baseline Loss: 2.6608 | Actual Loss: 0.5047\n",
      "Baseline Loss: 2.6791 | Actual Loss: 0.5289\n",
      "Baseline Loss: 2.6773 | Actual Loss: 0.7626\n",
      "Baseline Loss: 2.6542 | Actual Loss: 0.5968\n",
      "Baseline Loss: 2.6938 | Actual Loss: 0.5696\n",
      "Baseline Loss: 2.6762 | Actual Loss: 0.1631\n",
      "Baseline Loss: 2.6749 | Actual Loss: 1.9487\n",
      "Baseline Loss: 2.7477 | Actual Loss: 0.4811\n",
      "Baseline Loss: 2.6581 | Actual Loss: 0.7979\n",
      "Baseline Loss: 2.6497 | Actual Loss: 0.2887\n",
      "Baseline Loss: 2.7016 | Actual Loss: 2.2754\n",
      "Baseline Loss: 2.6906 | Actual Loss: 0.4354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 123/1000 [00:57<06:40,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6664 | Actual Loss: 0.2635\n",
      "Baseline Loss: 2.6666 | Actual Loss: 0.5561\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.3336\n",
      "Baseline Loss: 2.2560 | Actual Loss: 0.3615\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.7078\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.4512\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.6384\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.3063\n",
      "Epoch 123/1000: Train Loss: 0.6792, Val Loss: 0.7759\n",
      "Baseline Loss: 2.6730 | Actual Loss: 0.4681\n",
      "Baseline Loss: 2.6746 | Actual Loss: 0.4448\n",
      "Baseline Loss: 2.6574 | Actual Loss: 0.3563\n",
      "Baseline Loss: 2.6456 | Actual Loss: 0.8446\n",
      "Baseline Loss: 2.6610 | Actual Loss: 0.6107\n",
      "Baseline Loss: 2.6746 | Actual Loss: 2.2357\n",
      "Baseline Loss: 2.6511 | Actual Loss: 1.4403\n",
      "Baseline Loss: 2.6859 | Actual Loss: 0.3398\n",
      "Baseline Loss: 2.6855 | Actual Loss: 0.4181\n",
      "Baseline Loss: 2.7059 | Actual Loss: 0.2173\n",
      "Baseline Loss: 2.6663 | Actual Loss: 0.6624\n",
      "Baseline Loss: 2.6860 | Actual Loss: 1.2342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 124/1000 [00:58<06:57,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6629 | Actual Loss: 0.3728\n",
      "Baseline Loss: 2.6966 | Actual Loss: 0.4314\n",
      "Baseline Loss: 2.6462 | Actual Loss: 0.5740\n",
      "Baseline Loss: 2.2227 | Actual Loss: 0.2922\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.9115\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3928\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.4867\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4499\n",
      "Epoch 124/1000: Train Loss: 0.6839, Val Loss: 0.8102\n",
      "Baseline Loss: 2.6779 | Actual Loss: 0.4010\n",
      "Baseline Loss: 2.6436 | Actual Loss: 0.4039\n",
      "Baseline Loss: 2.6734 | Actual Loss: 1.3220\n",
      "Baseline Loss: 2.6977 | Actual Loss: 0.2983\n",
      "Baseline Loss: 2.6864 | Actual Loss: 0.7351\n",
      "Baseline Loss: 2.6855 | Actual Loss: 0.4918\n",
      "Baseline Loss: 2.6649 | Actual Loss: 0.4718\n",
      "Baseline Loss: 2.6385 | Actual Loss: 0.6434\n",
      "Baseline Loss: 2.6860 | Actual Loss: 0.2271\n",
      "Baseline Loss: 2.7305 | Actual Loss: 0.6809\n",
      "Baseline Loss: 2.6340 | Actual Loss: 0.3080\n",
      "Baseline Loss: 2.6714 | Actual Loss: 0.5944\n",
      "Baseline Loss: 2.6904 | Actual Loss: 0.7468\n",
      "Baseline Loss: 2.6691 | Actual Loss: 0.6488\n",
      "Baseline Loss: 2.6842 | Actual Loss: 0.4621\n",
      "Baseline Loss: 2.2847 | Actual Loss: 0.1069\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.8070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▎        | 125/1000 [00:58<07:16,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7243 | Actual Loss: 0.4288\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.4216\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.3498\n",
      "Epoch 125/1000: Train Loss: 0.5339, Val Loss: 0.7518\n",
      "Baseline Loss: 2.7157 | Actual Loss: 2.3073\n",
      "Baseline Loss: 2.6272 | Actual Loss: 0.7445\n",
      "Baseline Loss: 2.6821 | Actual Loss: 0.7064\n",
      "Baseline Loss: 2.6751 | Actual Loss: 0.4053\n",
      "Baseline Loss: 2.6868 | Actual Loss: 0.5266\n",
      "Baseline Loss: 2.6509 | Actual Loss: 0.3882\n",
      "Baseline Loss: 2.6649 | Actual Loss: 0.3908\n",
      "Baseline Loss: 2.6797 | Actual Loss: 0.6382\n",
      "Baseline Loss: 2.6624 | Actual Loss: 0.3881\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.3772\n",
      "Baseline Loss: 2.6913 | Actual Loss: 0.3148\n",
      "Baseline Loss: 2.7110 | Actual Loss: 0.7346\n",
      "Baseline Loss: 2.6975 | Actual Loss: 0.6115\n",
      "Baseline Loss: 2.6952 | Actual Loss: 0.5051\n",
      "Baseline Loss: 2.6564 | Actual Loss: 0.2362\n",
      "Baseline Loss: 2.3116 | Actual Loss: 0.1650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 126/1000 [00:59<07:03,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6263 | Actual Loss: 1.3458\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.4098\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.5646\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.5431\n",
      "Epoch 126/1000: Train Loss: 0.5900, Val Loss: 0.7158\n",
      "Baseline Loss: 2.6636 | Actual Loss: 0.4820\n",
      "Baseline Loss: 2.6637 | Actual Loss: 0.5650\n",
      "Baseline Loss: 2.6688 | Actual Loss: 0.2688\n",
      "Baseline Loss: 2.7342 | Actual Loss: 0.3156\n",
      "Baseline Loss: 2.7426 | Actual Loss: 0.3823\n",
      "Baseline Loss: 2.7455 | Actual Loss: 0.5410\n",
      "Baseline Loss: 2.6411 | Actual Loss: 0.5790\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.7583\n",
      "Baseline Loss: 2.6546 | Actual Loss: 0.7322\n",
      "Baseline Loss: 2.6873 | Actual Loss: 0.3138\n",
      "Baseline Loss: 2.6597 | Actual Loss: 0.2580\n",
      "Baseline Loss: 2.6915 | Actual Loss: 0.2971\n",
      "Baseline Loss: 2.7018 | Actual Loss: 0.4607\n",
      "Baseline Loss: 2.7045 | Actual Loss: 0.5625\n",
      "Baseline Loss: 2.6267 | Actual Loss: 0.4406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 127/1000 [00:59<07:07,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2468 | Actual Loss: 2.3390\n",
      "Baseline Loss: 2.6263 | Actual Loss: 2.0003\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.4094\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.5018\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.2394\n",
      "Epoch 127/1000: Train Loss: 0.5810, Val Loss: 0.7877\n",
      "Baseline Loss: 2.6832 | Actual Loss: 1.0436\n",
      "Baseline Loss: 2.6702 | Actual Loss: 0.2526\n",
      "Baseline Loss: 2.6576 | Actual Loss: 0.6051\n",
      "Baseline Loss: 2.6501 | Actual Loss: 0.6354\n",
      "Baseline Loss: 2.6333 | Actual Loss: 1.9182\n",
      "Baseline Loss: 2.6595 | Actual Loss: 0.3735\n",
      "Baseline Loss: 2.6877 | Actual Loss: 0.5416\n",
      "Baseline Loss: 2.6568 | Actual Loss: 0.4925\n",
      "Baseline Loss: 2.6418 | Actual Loss: 0.2864\n",
      "Baseline Loss: 2.6871 | Actual Loss: 0.2963\n",
      "Baseline Loss: 2.6581 | Actual Loss: 0.3928\n",
      "Baseline Loss: 2.7104 | Actual Loss: 1.1773\n",
      "Baseline Loss: 2.6921 | Actual Loss: 0.5036\n",
      "Baseline Loss: 2.6919 | Actual Loss: 0.1417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 128/1000 [01:00<07:13,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7171 | Actual Loss: 0.5716\n",
      "Baseline Loss: 2.2689 | Actual Loss: 0.1347\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.0469\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.4131\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.5703\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.2830\n",
      "Epoch 128/1000: Train Loss: 0.5854, Val Loss: 0.5783\n",
      "Baseline Loss: 2.6613 | Actual Loss: 0.4921\n",
      "Baseline Loss: 2.6709 | Actual Loss: 0.3976\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4565\n",
      "Baseline Loss: 2.6420 | Actual Loss: 0.7354\n",
      "Baseline Loss: 2.6487 | Actual Loss: 0.3466\n",
      "Baseline Loss: 2.6488 | Actual Loss: 0.7257\n",
      "Baseline Loss: 2.6874 | Actual Loss: 0.4398\n",
      "Baseline Loss: 2.6523 | Actual Loss: 0.2335\n",
      "Baseline Loss: 2.7039 | Actual Loss: 0.4288\n",
      "Baseline Loss: 2.6893 | Actual Loss: 0.1944\n",
      "Baseline Loss: 2.6771 | Actual Loss: 0.4343\n",
      "Baseline Loss: 2.6968 | Actual Loss: 0.5159\n",
      "Baseline Loss: 2.6661 | Actual Loss: 0.3529\n",
      "Baseline Loss: 2.6950 | Actual Loss: 0.3231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 129/1000 [01:00<06:59,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6891 | Actual Loss: 0.2953\n",
      "Baseline Loss: 2.2711 | Actual Loss: 0.2235\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.2755\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.4034\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.5983\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.3408\n",
      "Epoch 129/1000: Train Loss: 0.4122, Val Loss: 0.6545\n",
      "Baseline Loss: 2.6600 | Actual Loss: 0.5129\n",
      "Baseline Loss: 2.7292 | Actual Loss: 0.6272\n",
      "Baseline Loss: 2.6688 | Actual Loss: 0.5888\n",
      "Baseline Loss: 2.6829 | Actual Loss: 2.1238\n",
      "Baseline Loss: 2.6648 | Actual Loss: 0.1965\n",
      "Baseline Loss: 2.7307 | Actual Loss: 0.4818\n",
      "Baseline Loss: 2.6393 | Actual Loss: 0.3698\n",
      "Baseline Loss: 2.6900 | Actual Loss: 0.2925\n",
      "Baseline Loss: 2.6906 | Actual Loss: 0.5749\n",
      "Baseline Loss: 2.6720 | Actual Loss: 0.5579\n",
      "Baseline Loss: 2.6531 | Actual Loss: 0.3689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 130/1000 [01:01<06:59,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6689 | Actual Loss: 0.6579\n",
      "Baseline Loss: 2.6528 | Actual Loss: 0.3773\n",
      "Baseline Loss: 2.6795 | Actual Loss: 0.6754\n",
      "Baseline Loss: 2.7107 | Actual Loss: 1.2448\n",
      "Baseline Loss: 2.3627 | Actual Loss: 0.3290\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.1854\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3716\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.6133\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.3089\n",
      "Epoch 130/1000: Train Loss: 0.6237, Val Loss: 0.6198\n",
      "Baseline Loss: 2.6744 | Actual Loss: 0.8381\n",
      "Baseline Loss: 2.6645 | Actual Loss: 0.3801\n",
      "Baseline Loss: 2.6957 | Actual Loss: 0.2634\n",
      "Baseline Loss: 2.6488 | Actual Loss: 0.4702\n",
      "Baseline Loss: 2.6974 | Actual Loss: 0.6033\n",
      "Baseline Loss: 2.6856 | Actual Loss: 0.5503\n",
      "Baseline Loss: 2.6940 | Actual Loss: 0.3232\n",
      "Baseline Loss: 2.6802 | Actual Loss: 0.4121\n",
      "Baseline Loss: 2.6767 | Actual Loss: 0.5319\n",
      "Baseline Loss: 2.6884 | Actual Loss: 0.3222\n",
      "Baseline Loss: 2.6887 | Actual Loss: 0.3002\n",
      "Baseline Loss: 2.6420 | Actual Loss: 0.4992\n",
      "Baseline Loss: 2.6660 | Actual Loss: 0.8799\n",
      "Baseline Loss: 2.6557 | Actual Loss: 0.6172\n",
      "Baseline Loss: 2.7031 | Actual Loss: 1.2589\n",
      "Baseline Loss: 2.3565 | Actual Loss: 0.7064\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.2106\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3631\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.6365\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.3447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 131/1000 [01:01<07:02,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/1000: Train Loss: 0.5598, Val Loss: 0.6387\n",
      "Baseline Loss: 2.6878 | Actual Loss: 0.6979\n",
      "Baseline Loss: 2.6519 | Actual Loss: 0.4274\n",
      "Baseline Loss: 2.6730 | Actual Loss: 0.3130\n",
      "Baseline Loss: 2.6654 | Actual Loss: 0.3762\n",
      "Baseline Loss: 2.6917 | Actual Loss: 0.4919\n",
      "Baseline Loss: 2.6820 | Actual Loss: 0.6192\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.5766\n",
      "Baseline Loss: 2.7286 | Actual Loss: 0.6188\n",
      "Baseline Loss: 2.6826 | Actual Loss: 0.5417\n",
      "Baseline Loss: 2.6721 | Actual Loss: 0.4681\n",
      "Baseline Loss: 2.7038 | Actual Loss: 0.7273\n",
      "Baseline Loss: 2.6646 | Actual Loss: 0.8518\n",
      "Baseline Loss: 2.6615 | Actual Loss: 0.6759\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.2744\n",
      "Baseline Loss: 2.6486 | Actual Loss: 0.8886\n",
      "Baseline Loss: 2.2606 | Actual Loss: 0.3915\n",
      "Baseline Loss: 2.6263 | Actual Loss: 0.7714\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.4186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 132/1000 [01:01<06:50,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6758 | Actual Loss: 0.4777\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.3312\n",
      "Epoch 132/1000: Train Loss: 0.5588, Val Loss: 0.4998\n",
      "New best validation loss: 0.4998\n",
      "Baseline Loss: 2.6554 | Actual Loss: 0.3755\n",
      "Baseline Loss: 2.6746 | Actual Loss: 0.2691\n",
      "Baseline Loss: 2.6685 | Actual Loss: 0.2952\n",
      "Baseline Loss: 2.6806 | Actual Loss: 0.4674\n",
      "Baseline Loss: 2.6769 | Actual Loss: 0.3562\n",
      "Baseline Loss: 2.7193 | Actual Loss: 0.6217\n",
      "Baseline Loss: 2.6762 | Actual Loss: 0.8954\n",
      "Baseline Loss: 2.7013 | Actual Loss: 0.4195\n",
      "Baseline Loss: 2.6873 | Actual Loss: 0.2389\n",
      "Baseline Loss: 2.6517 | Actual Loss: 0.4165\n",
      "Baseline Loss: 2.6338 | Actual Loss: 0.6669\n",
      "Baseline Loss: 2.6456 | Actual Loss: 0.1918\n",
      "Baseline Loss: 2.6878 | Actual Loss: 0.3338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 133/1000 [01:02<06:56,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6862 | Actual Loss: 1.3010\n",
      "Baseline Loss: 2.7077 | Actual Loss: 0.6794\n",
      "Baseline Loss: 2.3257 | Actual Loss: 1.8696\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.2714\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3601\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.4734\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.3998\n",
      "Epoch 133/1000: Train Loss: 0.5874, Val Loss: 0.6262\n",
      "Baseline Loss: 2.6521 | Actual Loss: 0.5329\n",
      "Baseline Loss: 2.6709 | Actual Loss: 0.7615\n",
      "Baseline Loss: 2.7069 | Actual Loss: 0.7086\n",
      "Baseline Loss: 2.6793 | Actual Loss: 0.2818\n",
      "Baseline Loss: 2.6735 | Actual Loss: 0.4940\n",
      "Baseline Loss: 2.7141 | Actual Loss: 0.4552\n",
      "Baseline Loss: 2.6603 | Actual Loss: 0.4380\n",
      "Baseline Loss: 2.6464 | Actual Loss: 0.3372\n",
      "Baseline Loss: 2.6795 | Actual Loss: 0.5068\n",
      "Baseline Loss: 2.7360 | Actual Loss: 0.4299\n",
      "Baseline Loss: 2.7146 | Actual Loss: 0.4953\n",
      "Baseline Loss: 2.6606 | Actual Loss: 0.7667\n",
      "Baseline Loss: 2.6985 | Actual Loss: 0.1943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 134/1000 [01:02<06:43,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6287 | Actual Loss: 0.3882\n",
      "Baseline Loss: 2.6452 | Actual Loss: 0.4784\n",
      "Baseline Loss: 2.3190 | Actual Loss: 0.1058\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.6412\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3743\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.5324\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.3757\n",
      "Epoch 134/1000: Train Loss: 0.4609, Val Loss: 0.7309\n",
      "Baseline Loss: 2.6584 | Actual Loss: 0.3961\n",
      "Baseline Loss: 2.6619 | Actual Loss: 0.4491\n",
      "Baseline Loss: 2.6281 | Actual Loss: 0.2774\n",
      "Baseline Loss: 2.6698 | Actual Loss: 0.8235\n",
      "Baseline Loss: 2.6817 | Actual Loss: 0.5832\n",
      "Baseline Loss: 2.6884 | Actual Loss: 0.6800\n",
      "Baseline Loss: 2.7133 | Actual Loss: 0.4640\n",
      "Baseline Loss: 2.6810 | Actual Loss: 0.7696\n",
      "Baseline Loss: 2.6911 | Actual Loss: 0.8502\n",
      "Baseline Loss: 2.6935 | Actual Loss: 0.4485\n",
      "Baseline Loss: 2.6702 | Actual Loss: 0.5110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▎        | 135/1000 [01:03<06:48,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6907 | Actual Loss: 0.5153\n",
      "Baseline Loss: 2.6827 | Actual Loss: 0.4091\n",
      "Baseline Loss: 2.6155 | Actual Loss: 0.2429\n",
      "Baseline Loss: 2.7121 | Actual Loss: 0.2041\n",
      "Baseline Loss: 2.2686 | Actual Loss: 0.2295\n",
      "Baseline Loss: 2.6263 | Actual Loss: 0.9715\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3694\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.4894\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.2388\n",
      "Epoch 135/1000: Train Loss: 0.4909, Val Loss: 0.5173\n",
      "Baseline Loss: 2.6589 | Actual Loss: 0.5932\n",
      "Baseline Loss: 2.6651 | Actual Loss: 0.4532\n",
      "Baseline Loss: 2.6756 | Actual Loss: 0.7908\n",
      "Baseline Loss: 2.7060 | Actual Loss: 0.2375\n",
      "Baseline Loss: 2.6491 | Actual Loss: 0.4936\n",
      "Baseline Loss: 2.6824 | Actual Loss: 0.4392\n",
      "Baseline Loss: 2.6542 | Actual Loss: 0.6651\n",
      "Baseline Loss: 2.6697 | Actual Loss: 0.4675\n",
      "Baseline Loss: 2.6575 | Actual Loss: 2.3845\n",
      "Baseline Loss: 2.6741 | Actual Loss: 1.1926\n",
      "Baseline Loss: 2.7215 | Actual Loss: 0.2885\n",
      "Baseline Loss: 2.7072 | Actual Loss: 0.3132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▎        | 136/1000 [01:03<06:35,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6584 | Actual Loss: 0.6620\n",
      "Baseline Loss: 2.7235 | Actual Loss: 0.2810\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.5233\n",
      "Baseline Loss: 2.2597 | Actual Loss: 0.4751\n",
      "Baseline Loss: 2.6263 | Actual Loss: 0.9298\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3906\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.4549\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4033\n",
      "Epoch 136/1000: Train Loss: 0.6413, Val Loss: 0.5447\n",
      "Baseline Loss: 2.7073 | Actual Loss: 0.3044\n",
      "Baseline Loss: 2.6429 | Actual Loss: 0.4435\n",
      "Baseline Loss: 2.6650 | Actual Loss: 0.6712\n",
      "Baseline Loss: 2.6475 | Actual Loss: 0.3298\n",
      "Baseline Loss: 2.6799 | Actual Loss: 0.5221\n",
      "Baseline Loss: 2.6699 | Actual Loss: 0.1660\n",
      "Baseline Loss: 2.7125 | Actual Loss: 0.4984\n",
      "Baseline Loss: 2.6748 | Actual Loss: 0.5722\n",
      "Baseline Loss: 2.6921 | Actual Loss: 0.7173\n",
      "Baseline Loss: 2.6852 | Actual Loss: 0.3245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▎        | 137/1000 [01:04<06:41,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6934 | Actual Loss: 2.4290\n",
      "Baseline Loss: 2.6595 | Actual Loss: 0.7268\n",
      "Baseline Loss: 2.6587 | Actual Loss: 2.5608\n",
      "Baseline Loss: 2.6899 | Actual Loss: 0.3520\n",
      "Baseline Loss: 2.6811 | Actual Loss: 0.3101\n",
      "Baseline Loss: 2.2847 | Actual Loss: 0.8542\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.5628\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3784\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.5305\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4283\n",
      "Epoch 137/1000: Train Loss: 0.7364, Val Loss: 0.7250\n",
      "Baseline Loss: 2.6766 | Actual Loss: 0.5246\n",
      "Baseline Loss: 2.6423 | Actual Loss: 2.7396\n",
      "Baseline Loss: 2.6685 | Actual Loss: 0.3563\n",
      "Baseline Loss: 2.7084 | Actual Loss: 0.9418\n",
      "Baseline Loss: 2.6868 | Actual Loss: 0.4590\n",
      "Baseline Loss: 2.6643 | Actual Loss: 0.8125\n",
      "Baseline Loss: 2.7517 | Actual Loss: 0.3690\n",
      "Baseline Loss: 2.6397 | Actual Loss: 1.5830\n",
      "Baseline Loss: 2.6544 | Actual Loss: 0.4223\n",
      "Baseline Loss: 2.6701 | Actual Loss: 0.9485\n",
      "Baseline Loss: 2.7010 | Actual Loss: 0.7146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 138/1000 [01:04<06:48,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6836 | Actual Loss: 0.4892\n",
      "Baseline Loss: 2.6939 | Actual Loss: 0.5203\n",
      "Baseline Loss: 2.6316 | Actual Loss: 0.4697\n",
      "Baseline Loss: 2.6637 | Actual Loss: 1.0347\n",
      "Baseline Loss: 2.2827 | Actual Loss: 0.2901\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.5008\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3604\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.4985\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4790\n",
      "Epoch 138/1000: Train Loss: 0.7922, Val Loss: 0.7097\n",
      "Baseline Loss: 2.6773 | Actual Loss: 2.1830\n",
      "Baseline Loss: 2.6772 | Actual Loss: 0.5031\n",
      "Baseline Loss: 2.6870 | Actual Loss: 0.2847\n",
      "Baseline Loss: 2.7132 | Actual Loss: 0.6984\n",
      "Baseline Loss: 2.6436 | Actual Loss: 0.7172\n",
      "Baseline Loss: 2.6784 | Actual Loss: 0.4591\n",
      "Baseline Loss: 2.6927 | Actual Loss: 0.7790\n",
      "Baseline Loss: 2.7153 | Actual Loss: 0.5142\n",
      "Baseline Loss: 2.6517 | Actual Loss: 0.4725\n",
      "Baseline Loss: 2.6549 | Actual Loss: 0.7061\n",
      "Baseline Loss: 2.7300 | Actual Loss: 0.4141\n",
      "Baseline Loss: 2.6528 | Actual Loss: 0.2216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 139/1000 [01:05<06:35,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6764 | Actual Loss: 0.5673\n",
      "Baseline Loss: 2.6711 | Actual Loss: 0.5340\n",
      "Baseline Loss: 2.6639 | Actual Loss: 0.2412\n",
      "Baseline Loss: 2.2264 | Actual Loss: 0.0935\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.4610\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3836\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.5538\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.3342\n",
      "Epoch 139/1000: Train Loss: 0.5868, Val Loss: 0.6831\n",
      "Baseline Loss: 2.6592 | Actual Loss: 1.6320\n",
      "Baseline Loss: 2.6391 | Actual Loss: 0.4526\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.5388\n",
      "Baseline Loss: 2.6809 | Actual Loss: 1.6805\n",
      "Baseline Loss: 2.7090 | Actual Loss: 0.8550\n",
      "Baseline Loss: 2.6432 | Actual Loss: 0.5010\n",
      "Baseline Loss: 2.6328 | Actual Loss: 0.3411\n",
      "Baseline Loss: 2.6802 | Actual Loss: 0.6086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 140/1000 [01:05<06:37,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7329 | Actual Loss: 0.4327\n",
      "Baseline Loss: 2.6760 | Actual Loss: 0.5703\n",
      "Baseline Loss: 2.6652 | Actual Loss: 0.1665\n",
      "Baseline Loss: 2.6820 | Actual Loss: 0.3892\n",
      "Baseline Loss: 2.6998 | Actual Loss: 0.2812\n",
      "Baseline Loss: 2.6712 | Actual Loss: 0.2806\n",
      "Baseline Loss: 2.6647 | Actual Loss: 0.4692\n",
      "Baseline Loss: 2.2768 | Actual Loss: 0.2775\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.2057\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3952\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.4543\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4770\n",
      "Epoch 140/1000: Train Loss: 0.5923, Val Loss: 0.6331\n",
      "Baseline Loss: 2.6835 | Actual Loss: 0.7552\n",
      "Baseline Loss: 2.7212 | Actual Loss: 0.5043\n",
      "Baseline Loss: 2.6740 | Actual Loss: 0.4688\n",
      "Baseline Loss: 2.6823 | Actual Loss: 0.2683\n",
      "Baseline Loss: 2.6927 | Actual Loss: 0.3433\n",
      "Baseline Loss: 2.6614 | Actual Loss: 0.6837\n",
      "Baseline Loss: 2.6616 | Actual Loss: 0.3239\n",
      "Baseline Loss: 2.6734 | Actual Loss: 0.5832\n",
      "Baseline Loss: 2.6297 | Actual Loss: 1.1691\n",
      "Baseline Loss: 2.6946 | Actual Loss: 0.3970\n",
      "Baseline Loss: 2.6826 | Actual Loss: 1.4049\n",
      "Baseline Loss: 2.6736 | Actual Loss: 0.4748\n",
      "Baseline Loss: 2.6568 | Actual Loss: 0.4272\n",
      "Baseline Loss: 2.6712 | Actual Loss: 0.2976\n",
      "Baseline Loss: 2.6671 | Actual Loss: 0.7639\n",
      "Baseline Loss: 2.3245 | Actual Loss: 1.3947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 141/1000 [01:06<06:46,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6263 | Actual Loss: 1.2304\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3808\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.4843\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.2850\n",
      "Epoch 141/1000: Train Loss: 0.6412, Val Loss: 0.5951\n",
      "Baseline Loss: 2.6551 | Actual Loss: 0.1789\n",
      "Baseline Loss: 2.6458 | Actual Loss: 0.4372\n",
      "Baseline Loss: 2.6282 | Actual Loss: 0.5711\n",
      "Baseline Loss: 2.6656 | Actual Loss: 2.3942\n",
      "Baseline Loss: 2.6778 | Actual Loss: 0.4171\n",
      "Baseline Loss: 2.6609 | Actual Loss: 0.4623\n",
      "Baseline Loss: 2.6982 | Actual Loss: 0.8104\n",
      "Baseline Loss: 2.6917 | Actual Loss: 0.6321\n",
      "Baseline Loss: 2.6991 | Actual Loss: 0.5535\n",
      "Baseline Loss: 2.6658 | Actual Loss: 0.4332\n",
      "Baseline Loss: 2.6997 | Actual Loss: 0.6279\n",
      "Baseline Loss: 2.6959 | Actual Loss: 0.2833\n",
      "Baseline Loss: 2.6704 | Actual Loss: 0.6766\n",
      "Baseline Loss: 2.6762 | Actual Loss: 0.6291\n",
      "Baseline Loss: 2.6750 | Actual Loss: 0.6271\n",
      "Baseline Loss: 2.2666 | Actual Loss: 0.1424\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.8581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 142/1000 [01:06<06:31,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7243 | Actual Loss: 0.3647\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.5492\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4494\n",
      "Epoch 142/1000: Train Loss: 0.6173, Val Loss: 0.8053\n",
      "Baseline Loss: 2.6515 | Actual Loss: 0.2099\n",
      "Baseline Loss: 2.6746 | Actual Loss: 0.5084\n",
      "Baseline Loss: 2.6836 | Actual Loss: 0.3681\n",
      "Baseline Loss: 2.6443 | Actual Loss: 0.3012\n",
      "Baseline Loss: 2.6790 | Actual Loss: 0.9153\n",
      "Baseline Loss: 2.6728 | Actual Loss: 0.3479\n",
      "Baseline Loss: 2.7126 | Actual Loss: 0.9030\n",
      "Baseline Loss: 2.6895 | Actual Loss: 0.2172\n",
      "Baseline Loss: 2.6678 | Actual Loss: 0.2932\n",
      "Baseline Loss: 2.6654 | Actual Loss: 0.6818\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.1636\n",
      "Baseline Loss: 2.6960 | Actual Loss: 0.2278\n",
      "Baseline Loss: 2.6789 | Actual Loss: 0.2170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 143/1000 [01:07<06:43,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6904 | Actual Loss: 0.5043\n",
      "Baseline Loss: 2.6550 | Actual Loss: 0.3872\n",
      "Baseline Loss: 2.2544 | Actual Loss: 0.3943\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.9207\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3645\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.4755\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.5118\n",
      "Epoch 143/1000: Train Loss: 0.4150, Val Loss: 0.8181\n",
      "Baseline Loss: 2.6438 | Actual Loss: 0.1711\n",
      "Baseline Loss: 2.6539 | Actual Loss: 0.3725\n",
      "Baseline Loss: 2.6750 | Actual Loss: 0.1633\n",
      "Baseline Loss: 2.6803 | Actual Loss: 0.7050\n",
      "Baseline Loss: 2.6699 | Actual Loss: 0.4222\n",
      "Baseline Loss: 2.7009 | Actual Loss: 0.7559\n",
      "Baseline Loss: 2.6841 | Actual Loss: 0.6036\n",
      "Baseline Loss: 2.6911 | Actual Loss: 1.1404\n",
      "Baseline Loss: 2.6829 | Actual Loss: 0.3840\n",
      "Baseline Loss: 2.7303 | Actual Loss: 0.4378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 144/1000 [01:07<06:46,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6781 | Actual Loss: 0.5228\n",
      "Baseline Loss: 2.6695 | Actual Loss: 0.7988\n",
      "Baseline Loss: 2.6698 | Actual Loss: 0.3983\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.3074\n",
      "Baseline Loss: 2.6511 | Actual Loss: 0.5892\n",
      "Baseline Loss: 2.3089 | Actual Loss: 0.0839\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.5530\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3845\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.5656\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.2803\n",
      "Epoch 144/1000: Train Loss: 0.4910, Val Loss: 0.6959\n",
      "Baseline Loss: 2.6869 | Actual Loss: 0.6427\n",
      "Baseline Loss: 2.6874 | Actual Loss: 0.5474\n",
      "Baseline Loss: 2.6663 | Actual Loss: 0.4197\n",
      "Baseline Loss: 2.6722 | Actual Loss: 0.5254\n",
      "Baseline Loss: 2.6645 | Actual Loss: 0.7419\n",
      "Baseline Loss: 2.6691 | Actual Loss: 0.5043\n",
      "Baseline Loss: 2.6689 | Actual Loss: 0.1598\n",
      "Baseline Loss: 2.6721 | Actual Loss: 0.4016\n",
      "Baseline Loss: 2.6936 | Actual Loss: 0.5513\n",
      "Baseline Loss: 2.6455 | Actual Loss: 0.5255\n",
      "Baseline Loss: 2.6580 | Actual Loss: 2.7793\n",
      "Baseline Loss: 2.7001 | Actual Loss: 0.5366\n",
      "Baseline Loss: 2.6864 | Actual Loss: 0.6231\n",
      "Baseline Loss: 2.6727 | Actual Loss: 0.4000\n",
      "Baseline Loss: 2.7085 | Actual Loss: 0.8105\n",
      "Baseline Loss: 2.2468 | Actual Loss: 1.0229\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.4068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 145/1000 [01:08<06:52,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7243 | Actual Loss: 0.3761\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.4781\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4238\n",
      "Epoch 145/1000: Train Loss: 0.6995, Val Loss: 0.6712\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4139\n",
      "Baseline Loss: 2.6537 | Actual Loss: 0.4296\n",
      "Baseline Loss: 2.6597 | Actual Loss: 0.2538\n",
      "Baseline Loss: 2.6849 | Actual Loss: 0.4014\n",
      "Baseline Loss: 2.6866 | Actual Loss: 0.4441\n",
      "Baseline Loss: 2.7097 | Actual Loss: 0.6306\n",
      "Baseline Loss: 2.6653 | Actual Loss: 0.3663\n",
      "Baseline Loss: 2.7018 | Actual Loss: 1.5259\n",
      "Baseline Loss: 2.6834 | Actual Loss: 1.0484\n",
      "Baseline Loss: 2.6696 | Actual Loss: 0.4028\n",
      "Baseline Loss: 2.6863 | Actual Loss: 0.5115\n",
      "Baseline Loss: 2.6575 | Actual Loss: 0.8492\n",
      "Baseline Loss: 2.6552 | Actual Loss: 0.3686\n",
      "Baseline Loss: 2.6329 | Actual Loss: 0.2469\n",
      "Baseline Loss: 2.7084 | Actual Loss: 0.6739\n",
      "Baseline Loss: 2.3368 | Actual Loss: 0.4932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 146/1000 [01:08<06:37,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6263 | Actual Loss: 1.3209\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.4093\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.4837\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4178\n",
      "Epoch 146/1000: Train Loss: 0.5662, Val Loss: 0.6579\n",
      "Baseline Loss: 2.6643 | Actual Loss: 0.2075\n",
      "Baseline Loss: 2.6728 | Actual Loss: 0.8454\n",
      "Baseline Loss: 2.6379 | Actual Loss: 0.2349\n",
      "Baseline Loss: 2.7016 | Actual Loss: 0.6569\n",
      "Baseline Loss: 2.6866 | Actual Loss: 0.5099\n",
      "Baseline Loss: 2.6593 | Actual Loss: 0.6948\n",
      "Baseline Loss: 2.6721 | Actual Loss: 0.4085\n",
      "Baseline Loss: 2.7119 | Actual Loss: 0.6714\n",
      "Baseline Loss: 2.7072 | Actual Loss: 0.5721\n",
      "Baseline Loss: 2.6925 | Actual Loss: 0.5311\n",
      "Baseline Loss: 2.6671 | Actual Loss: 0.5390\n",
      "Baseline Loss: 2.6692 | Actual Loss: 0.4777\n",
      "Baseline Loss: 2.6678 | Actual Loss: 0.2966\n",
      "Baseline Loss: 2.6882 | Actual Loss: 0.4853\n",
      "Baseline Loss: 2.7109 | Actual Loss: 0.3649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 147/1000 [01:09<06:54,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2370 | Actual Loss: 0.3931\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.3367\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3574\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.5902\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.3573\n",
      "Epoch 147/1000: Train Loss: 0.4931, Val Loss: 0.6604\n",
      "Baseline Loss: 2.7108 | Actual Loss: 0.4601\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4996\n",
      "Baseline Loss: 2.6791 | Actual Loss: 0.7862\n",
      "Baseline Loss: 2.6893 | Actual Loss: 0.6005\n",
      "Baseline Loss: 2.6438 | Actual Loss: 0.3298\n",
      "Baseline Loss: 2.6894 | Actual Loss: 0.2835\n",
      "Baseline Loss: 2.6780 | Actual Loss: 0.2569\n",
      "Baseline Loss: 2.6868 | Actual Loss: 0.7585\n",
      "Baseline Loss: 2.6420 | Actual Loss: 0.9255\n",
      "Baseline Loss: 2.6989 | Actual Loss: 0.3970\n",
      "Baseline Loss: 2.6716 | Actual Loss: 0.5543\n",
      "Baseline Loss: 2.6838 | Actual Loss: 0.3228\n",
      "Baseline Loss: 2.6921 | Actual Loss: 1.0298\n",
      "Baseline Loss: 2.6502 | Actual Loss: 0.3259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 148/1000 [01:09<07:00,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7175 | Actual Loss: 0.3292\n",
      "Baseline Loss: 2.2709 | Actual Loss: 0.4136\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.9805\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3797\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.4955\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.3681\n",
      "Epoch 148/1000: Train Loss: 0.5171, Val Loss: 0.8059\n",
      "Baseline Loss: 2.6552 | Actual Loss: 0.3662\n",
      "Baseline Loss: 2.6826 | Actual Loss: 0.2223\n",
      "Baseline Loss: 2.6926 | Actual Loss: 0.3029\n",
      "Baseline Loss: 2.6753 | Actual Loss: 0.3906\n",
      "Baseline Loss: 2.6464 | Actual Loss: 0.3425\n",
      "Baseline Loss: 2.6828 | Actual Loss: 0.1685\n",
      "Baseline Loss: 2.6753 | Actual Loss: 1.8407\n",
      "Baseline Loss: 2.6397 | Actual Loss: 0.7035\n",
      "Baseline Loss: 2.7164 | Actual Loss: 0.4733\n",
      "Baseline Loss: 2.6650 | Actual Loss: 0.2351\n",
      "Baseline Loss: 2.6554 | Actual Loss: 0.5210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 149/1000 [01:09<06:44,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6509 | Actual Loss: 0.5901\n",
      "Baseline Loss: 2.6817 | Actual Loss: 0.0818\n",
      "Baseline Loss: 2.6525 | Actual Loss: 0.5194\n",
      "Baseline Loss: 2.6838 | Actual Loss: 0.7419\n",
      "Baseline Loss: 2.2756 | Actual Loss: 0.1089\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.3692\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.4066\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.5982\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.3721\n",
      "Epoch 149/1000: Train Loss: 0.4755, Val Loss: 0.6865\n",
      "Baseline Loss: 2.7120 | Actual Loss: 0.7353\n",
      "Baseline Loss: 2.6362 | Actual Loss: 0.1793\n",
      "Baseline Loss: 2.6630 | Actual Loss: 0.1916\n",
      "Baseline Loss: 2.6917 | Actual Loss: 1.1532\n",
      "Baseline Loss: 2.6433 | Actual Loss: 0.2891\n",
      "Baseline Loss: 2.7063 | Actual Loss: 0.6333\n",
      "Baseline Loss: 2.6415 | Actual Loss: 0.3755\n",
      "Baseline Loss: 2.7047 | Actual Loss: 0.4461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 150/1000 [01:10<06:45,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6829 | Actual Loss: 0.6374\n",
      "Baseline Loss: 2.7169 | Actual Loss: 0.3897\n",
      "Baseline Loss: 2.6904 | Actual Loss: 0.7557\n",
      "Baseline Loss: 2.6701 | Actual Loss: 0.3757\n",
      "Baseline Loss: 2.6632 | Actual Loss: 0.4090\n",
      "Baseline Loss: 2.6385 | Actual Loss: 0.4047\n",
      "Baseline Loss: 2.7210 | Actual Loss: 0.5812\n",
      "Baseline Loss: 2.2963 | Actual Loss: 2.1535\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.2597\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3344\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.4696\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4172\n",
      "Epoch 150/1000: Train Loss: 0.6069, Val Loss: 0.6202\n",
      "Baseline Loss: 2.6664 | Actual Loss: 0.5891\n",
      "Baseline Loss: 2.6632 | Actual Loss: 0.4275\n",
      "Baseline Loss: 2.6594 | Actual Loss: 0.4646\n",
      "Baseline Loss: 2.6920 | Actual Loss: 0.2788\n",
      "Baseline Loss: 2.6833 | Actual Loss: 0.3315\n",
      "Baseline Loss: 2.6637 | Actual Loss: 0.6292\n",
      "Baseline Loss: 2.6505 | Actual Loss: 0.5462\n",
      "Baseline Loss: 2.6893 | Actual Loss: 0.7336\n",
      "Baseline Loss: 2.6812 | Actual Loss: 0.5283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 151/1000 [01:10<06:34,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6623 | Actual Loss: 0.3125\n",
      "Baseline Loss: 2.6642 | Actual Loss: 0.4659\n",
      "Baseline Loss: 2.6773 | Actual Loss: 0.8296\n",
      "Baseline Loss: 2.6656 | Actual Loss: 0.4222\n",
      "Baseline Loss: 2.6795 | Actual Loss: 0.4726\n",
      "Baseline Loss: 2.6788 | Actual Loss: 0.6974\n",
      "Baseline Loss: 2.3261 | Actual Loss: 0.1481\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.2055\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.4643\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.5829\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4312\n",
      "Epoch 151/1000: Train Loss: 0.4923, Val Loss: 0.6710\n",
      "Baseline Loss: 2.6681 | Actual Loss: 0.1948\n",
      "Baseline Loss: 2.6815 | Actual Loss: 0.6151\n",
      "Baseline Loss: 2.6695 | Actual Loss: 0.3366\n",
      "Baseline Loss: 2.6871 | Actual Loss: 0.3451\n",
      "Baseline Loss: 2.6994 | Actual Loss: 0.5987\n",
      "Baseline Loss: 2.6744 | Actual Loss: 0.3016\n",
      "Baseline Loss: 2.6701 | Actual Loss: 0.3478\n",
      "Baseline Loss: 2.6801 | Actual Loss: 0.8064\n",
      "Baseline Loss: 2.6935 | Actual Loss: 0.3694\n",
      "Baseline Loss: 2.7013 | Actual Loss: 0.6170\n",
      "Baseline Loss: 2.6851 | Actual Loss: 0.5451\n",
      "Baseline Loss: 2.7384 | Actual Loss: 0.6361\n",
      "Baseline Loss: 2.6853 | Actual Loss: 1.2261\n",
      "Baseline Loss: 2.6353 | Actual Loss: 0.7582\n",
      "Baseline Loss: 2.6834 | Actual Loss: 0.5927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 152/1000 [01:11<06:45,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.3041 | Actual Loss: 0.4546\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.4698\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3762\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.4466\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.3483\n",
      "Epoch 152/1000: Train Loss: 0.5466, Val Loss: 0.6602\n",
      "Baseline Loss: 2.7104 | Actual Loss: 0.5576\n",
      "Baseline Loss: 2.6521 | Actual Loss: 0.4966\n",
      "Baseline Loss: 2.6778 | Actual Loss: 0.4225\n",
      "Baseline Loss: 2.6804 | Actual Loss: 0.3459\n",
      "Baseline Loss: 2.6798 | Actual Loss: 0.4406\n",
      "Baseline Loss: 2.6951 | Actual Loss: 0.6622\n",
      "Baseline Loss: 2.6826 | Actual Loss: 0.7842\n",
      "Baseline Loss: 2.6889 | Actual Loss: 0.6596\n",
      "Baseline Loss: 2.6612 | Actual Loss: 0.4439\n",
      "Baseline Loss: 2.6586 | Actual Loss: 0.2542\n",
      "Baseline Loss: 2.6892 | Actual Loss: 0.6259\n",
      "Baseline Loss: 2.6959 | Actual Loss: 0.2279\n",
      "Baseline Loss: 2.6871 | Actual Loss: 0.6921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 153/1000 [01:11<06:53,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6333 | Actual Loss: 0.3128\n",
      "Baseline Loss: 2.6944 | Actual Loss: 0.6432\n",
      "Baseline Loss: 2.2927 | Actual Loss: 2.0381\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.1524\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3656\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.4879\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.2963\n",
      "Epoch 153/1000: Train Loss: 0.6005, Val Loss: 0.5756\n",
      "Baseline Loss: 2.6679 | Actual Loss: 0.3615\n",
      "Baseline Loss: 2.6824 | Actual Loss: 0.6078\n",
      "Baseline Loss: 2.6914 | Actual Loss: 0.5121\n",
      "Baseline Loss: 2.6608 | Actual Loss: 0.5898\n",
      "Baseline Loss: 2.6734 | Actual Loss: 0.8265\n",
      "Baseline Loss: 2.6816 | Actual Loss: 0.5214\n",
      "Baseline Loss: 2.7299 | Actual Loss: 0.1426\n",
      "Baseline Loss: 2.6943 | Actual Loss: 1.6374\n",
      "Baseline Loss: 2.6723 | Actual Loss: 0.5840\n",
      "Baseline Loss: 2.7008 | Actual Loss: 0.3107\n",
      "Baseline Loss: 2.6550 | Actual Loss: 0.6263\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.4538\n",
      "Baseline Loss: 2.7064 | Actual Loss: 0.6979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 154/1000 [01:12<06:38,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6366 | Actual Loss: 0.2316\n",
      "Baseline Loss: 2.6629 | Actual Loss: 0.4160\n",
      "Baseline Loss: 2.2497 | Actual Loss: 0.4758\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.0876\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.5118\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.6869\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4026\n",
      "Epoch 154/1000: Train Loss: 0.5622, Val Loss: 0.6722\n",
      "Baseline Loss: 2.6557 | Actual Loss: 0.4915\n",
      "Baseline Loss: 2.6952 | Actual Loss: 0.9973\n",
      "Baseline Loss: 2.7022 | Actual Loss: 0.4784\n",
      "Baseline Loss: 2.7115 | Actual Loss: 1.1947\n",
      "Baseline Loss: 2.6452 | Actual Loss: 0.5457\n",
      "Baseline Loss: 2.6671 | Actual Loss: 0.3272\n",
      "Baseline Loss: 2.6742 | Actual Loss: 0.6584\n",
      "Baseline Loss: 2.6787 | Actual Loss: 0.6534\n",
      "Baseline Loss: 2.6743 | Actual Loss: 0.6719\n",
      "Baseline Loss: 2.6982 | Actual Loss: 0.8037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 155/1000 [01:12<06:40,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6760 | Actual Loss: 0.6555\n",
      "Baseline Loss: 2.6829 | Actual Loss: 0.4085\n",
      "Baseline Loss: 2.6393 | Actual Loss: 0.4887\n",
      "Baseline Loss: 2.6844 | Actual Loss: 0.2920\n",
      "Baseline Loss: 2.6746 | Actual Loss: 0.4956\n",
      "Baseline Loss: 2.2549 | Actual Loss: 0.3238\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.5281\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3751\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.4607\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.3810\n",
      "Epoch 155/1000: Train Loss: 0.5929, Val Loss: 0.6862\n",
      "Baseline Loss: 2.6632 | Actual Loss: 0.5084\n",
      "Baseline Loss: 2.6511 | Actual Loss: 0.6688\n",
      "Baseline Loss: 2.6536 | Actual Loss: 0.3201\n",
      "Baseline Loss: 2.6470 | Actual Loss: 0.3854\n",
      "Baseline Loss: 2.6815 | Actual Loss: 0.6361\n",
      "Baseline Loss: 2.6895 | Actual Loss: 0.2925\n",
      "Baseline Loss: 2.6681 | Actual Loss: 0.5931\n",
      "Baseline Loss: 2.6658 | Actual Loss: 0.4114\n",
      "Baseline Loss: 2.6436 | Actual Loss: 0.4188\n",
      "Baseline Loss: 2.6786 | Actual Loss: 0.5609\n",
      "Baseline Loss: 2.6744 | Actual Loss: 0.5067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 156/1000 [01:13<06:27,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6991 | Actual Loss: 0.3872\n",
      "Baseline Loss: 2.6768 | Actual Loss: 0.3890\n",
      "Baseline Loss: 2.6697 | Actual Loss: 0.5925\n",
      "Baseline Loss: 2.6881 | Actual Loss: 0.5714\n",
      "Baseline Loss: 2.3297 | Actual Loss: 0.2718\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.0851\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3809\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.6934\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.5275\n",
      "Epoch 156/1000: Train Loss: 0.4696, Val Loss: 0.6717\n",
      "Baseline Loss: 2.6909 | Actual Loss: 0.6866\n",
      "Baseline Loss: 2.6784 | Actual Loss: 0.6731\n",
      "Baseline Loss: 2.6878 | Actual Loss: 0.3029\n",
      "Baseline Loss: 2.6460 | Actual Loss: 0.3979\n",
      "Baseline Loss: 2.6733 | Actual Loss: 0.4895\n",
      "Baseline Loss: 2.6750 | Actual Loss: 0.4923\n",
      "Baseline Loss: 2.6825 | Actual Loss: 1.0701\n",
      "Baseline Loss: 2.6470 | Actual Loss: 0.4968\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5511\n",
      "Baseline Loss: 2.6484 | Actual Loss: 0.4249\n",
      "Baseline Loss: 2.6595 | Actual Loss: 0.4638\n",
      "Baseline Loss: 2.6934 | Actual Loss: 1.6672\n",
      "Baseline Loss: 2.6734 | Actual Loss: 0.6194\n",
      "Baseline Loss: 2.6788 | Actual Loss: 0.5493\n",
      "Baseline Loss: 2.6894 | Actual Loss: 0.4160\n",
      "Baseline Loss: 2.3174 | Actual Loss: 0.3569\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.5984\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 157/1000 [01:13<06:31,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6758 | Actual Loss: 0.4978\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.3816\n",
      "Epoch 157/1000: Train Loss: 0.6036, Val Loss: 0.7183\n",
      "Baseline Loss: 2.6909 | Actual Loss: 0.4605\n",
      "Baseline Loss: 2.6968 | Actual Loss: 0.7106\n",
      "Baseline Loss: 2.6625 | Actual Loss: 0.4179\n",
      "Baseline Loss: 2.6494 | Actual Loss: 0.5674\n",
      "Baseline Loss: 2.6414 | Actual Loss: 0.2687\n",
      "Baseline Loss: 2.6847 | Actual Loss: 0.9084\n",
      "Baseline Loss: 2.6889 | Actual Loss: 0.3319\n",
      "Baseline Loss: 2.6528 | Actual Loss: 0.8710\n",
      "Baseline Loss: 2.6852 | Actual Loss: 0.7184\n",
      "Baseline Loss: 2.6756 | Actual Loss: 0.3428\n",
      "Baseline Loss: 2.7063 | Actual Loss: 0.3606\n",
      "Baseline Loss: 2.6894 | Actual Loss: 0.5454\n",
      "Baseline Loss: 2.6785 | Actual Loss: 0.4777\n",
      "Baseline Loss: 2.6457 | Actual Loss: 0.6692\n",
      "Baseline Loss: 2.6538 | Actual Loss: 0.5476\n",
      "Baseline Loss: 2.3098 | Actual Loss: 0.5130\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.4713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 158/1000 [01:14<06:46,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7243 | Actual Loss: 0.3871\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.5605\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.3170\n",
      "Epoch 158/1000: Train Loss: 0.5445, Val Loss: 0.6840\n",
      "Baseline Loss: 2.6746 | Actual Loss: 0.3116\n",
      "Baseline Loss: 2.6412 | Actual Loss: 0.6876\n",
      "Baseline Loss: 2.6942 | Actual Loss: 1.1005\n",
      "Baseline Loss: 2.6597 | Actual Loss: 0.5121\n",
      "Baseline Loss: 2.6674 | Actual Loss: 0.5399\n",
      "Baseline Loss: 2.6767 | Actual Loss: 0.7684\n",
      "Baseline Loss: 2.7044 | Actual Loss: 0.3136\n",
      "Baseline Loss: 2.6466 | Actual Loss: 0.2938\n",
      "Baseline Loss: 2.6883 | Actual Loss: 0.4786\n",
      "Baseline Loss: 2.7025 | Actual Loss: 0.6494\n",
      "Baseline Loss: 2.6444 | Actual Loss: 0.4691\n",
      "Baseline Loss: 2.6710 | Actual Loss: 0.9638\n",
      "Baseline Loss: 2.7133 | Actual Loss: 0.3052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 159/1000 [01:14<06:29,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6284 | Actual Loss: 0.1302\n",
      "Baseline Loss: 2.7004 | Actual Loss: 0.8931\n",
      "Baseline Loss: 2.2777 | Actual Loss: 0.4312\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.2662\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3704\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.4322\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4269\n",
      "Epoch 159/1000: Train Loss: 0.5530, Val Loss: 0.6239\n",
      "Baseline Loss: 2.6955 | Actual Loss: 0.4727\n",
      "Baseline Loss: 2.6655 | Actual Loss: 0.4840\n",
      "Baseline Loss: 2.6475 | Actual Loss: 0.5793\n",
      "Baseline Loss: 2.6705 | Actual Loss: 0.4102\n",
      "Baseline Loss: 2.6826 | Actual Loss: 0.3185\n",
      "Baseline Loss: 2.6687 | Actual Loss: 0.3522\n",
      "Baseline Loss: 2.6848 | Actual Loss: 0.2578\n",
      "Baseline Loss: 2.6691 | Actual Loss: 0.3567\n",
      "Baseline Loss: 2.7118 | Actual Loss: 0.4970\n",
      "Baseline Loss: 2.6666 | Actual Loss: 0.3920\n",
      "Baseline Loss: 2.6836 | Actual Loss: 0.5235\n",
      "Baseline Loss: 2.6346 | Actual Loss: 1.2195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 160/1000 [01:15<06:35,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6760 | Actual Loss: 0.4426\n",
      "Baseline Loss: 2.7205 | Actual Loss: 0.8054\n",
      "Baseline Loss: 2.6808 | Actual Loss: 0.9562\n",
      "Baseline Loss: 2.2876 | Actual Loss: 0.3573\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.5563\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.4052\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.6152\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.3304\n",
      "Epoch 160/1000: Train Loss: 0.5266, Val Loss: 0.7268\n",
      "Baseline Loss: 2.6743 | Actual Loss: 0.3201\n",
      "Baseline Loss: 2.6919 | Actual Loss: 0.1967\n",
      "Baseline Loss: 2.7077 | Actual Loss: 0.2592\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4019\n",
      "Baseline Loss: 2.6695 | Actual Loss: 0.4897\n",
      "Baseline Loss: 2.6799 | Actual Loss: 0.4715\n",
      "Baseline Loss: 2.6666 | Actual Loss: 0.4943\n",
      "Baseline Loss: 2.6827 | Actual Loss: 0.7965\n",
      "Baseline Loss: 2.7128 | Actual Loss: 1.2950\n",
      "Baseline Loss: 2.6661 | Actual Loss: 0.4140\n",
      "Baseline Loss: 2.6787 | Actual Loss: 0.5460\n",
      "Baseline Loss: 2.7029 | Actual Loss: 0.6158\n",
      "Baseline Loss: 2.6676 | Actual Loss: 0.7477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 161/1000 [01:15<06:26,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6689 | Actual Loss: 0.3469\n",
      "Baseline Loss: 2.6528 | Actual Loss: 0.5224\n",
      "Baseline Loss: 2.2331 | Actual Loss: 0.0981\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.2864\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.4677\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.6030\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.3334\n",
      "Epoch 161/1000: Train Loss: 0.5010, Val Loss: 0.6726\n",
      "Baseline Loss: 2.6895 | Actual Loss: 1.1701\n",
      "Baseline Loss: 2.6766 | Actual Loss: 0.4732\n",
      "Baseline Loss: 2.7319 | Actual Loss: 0.2275\n",
      "Baseline Loss: 2.7000 | Actual Loss: 0.4437\n",
      "Baseline Loss: 2.7126 | Actual Loss: 0.5336\n",
      "Baseline Loss: 2.6995 | Actual Loss: 0.5586\n",
      "Baseline Loss: 2.6712 | Actual Loss: 0.5844\n",
      "Baseline Loss: 2.6891 | Actual Loss: 0.4415\n",
      "Baseline Loss: 2.6427 | Actual Loss: 0.4066\n",
      "Baseline Loss: 2.6427 | Actual Loss: 0.4372\n",
      "Baseline Loss: 2.6370 | Actual Loss: 0.9148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 162/1000 [01:16<06:32,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6731 | Actual Loss: 0.2358\n",
      "Baseline Loss: 2.6775 | Actual Loss: 0.1985\n",
      "Baseline Loss: 2.6698 | Actual Loss: 0.9156\n",
      "Baseline Loss: 2.6622 | Actual Loss: 0.2917\n",
      "Baseline Loss: 2.2951 | Actual Loss: 1.8079\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.3285\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3656\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.5800\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.3568\n",
      "Epoch 162/1000: Train Loss: 0.6025, Val Loss: 0.6577\n",
      "Baseline Loss: 2.6491 | Actual Loss: 0.3150\n",
      "Baseline Loss: 2.7397 | Actual Loss: 0.4829\n",
      "Baseline Loss: 2.6743 | Actual Loss: 0.2855\n",
      "Baseline Loss: 2.6423 | Actual Loss: 0.6224\n",
      "Baseline Loss: 2.6949 | Actual Loss: 0.6056\n",
      "Baseline Loss: 2.6851 | Actual Loss: 1.0572\n",
      "Baseline Loss: 2.6515 | Actual Loss: 0.4068\n",
      "Baseline Loss: 2.6841 | Actual Loss: 0.3849\n",
      "Baseline Loss: 2.6605 | Actual Loss: 0.6487\n",
      "Baseline Loss: 2.6393 | Actual Loss: 0.5536\n",
      "Baseline Loss: 2.7005 | Actual Loss: 0.2948\n",
      "Baseline Loss: 2.7109 | Actual Loss: 0.1996\n",
      "Baseline Loss: 2.6416 | Actual Loss: 0.3725\n",
      "Baseline Loss: 2.7039 | Actual Loss: 0.7083\n",
      "Baseline Loss: 2.6698 | Actual Loss: 0.5492\n",
      "Baseline Loss: 2.2464 | Actual Loss: 0.5153\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.6314\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3749\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.5412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▋        | 163/1000 [01:16<06:33,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5648 | Actual Loss: 0.4347\n",
      "Epoch 163/1000: Train Loss: 0.5001, Val Loss: 0.7455\n",
      "Baseline Loss: 2.6658 | Actual Loss: 0.4623\n",
      "Baseline Loss: 2.6718 | Actual Loss: 0.2401\n",
      "Baseline Loss: 2.6366 | Actual Loss: 0.7062\n",
      "Baseline Loss: 2.6872 | Actual Loss: 0.4434\n",
      "Baseline Loss: 2.6880 | Actual Loss: 0.1416\n",
      "Baseline Loss: 2.6749 | Actual Loss: 0.2388\n",
      "Baseline Loss: 2.6479 | Actual Loss: 0.4246\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.3361\n",
      "Baseline Loss: 2.7047 | Actual Loss: 0.4646\n",
      "Baseline Loss: 2.6876 | Actual Loss: 0.4806\n",
      "Baseline Loss: 2.6683 | Actual Loss: 0.4205\n",
      "Baseline Loss: 2.6720 | Actual Loss: 0.6166\n",
      "Baseline Loss: 2.6588 | Actual Loss: 0.5324\n",
      "Baseline Loss: 2.6790 | Actual Loss: 0.4420\n",
      "Baseline Loss: 2.6960 | Actual Loss: 0.8665\n",
      "Baseline Loss: 2.2874 | Actual Loss: 0.1605\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.4981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▋        | 164/1000 [01:17<06:45,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7243 | Actual Loss: 0.3808\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.4428\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.3955\n",
      "Epoch 164/1000: Train Loss: 0.4361, Val Loss: 0.6793\n",
      "Baseline Loss: 2.6813 | Actual Loss: 0.2326\n",
      "Baseline Loss: 2.6964 | Actual Loss: 0.2615\n",
      "Baseline Loss: 2.6896 | Actual Loss: 0.5081\n",
      "Baseline Loss: 2.7092 | Actual Loss: 1.3744\n",
      "Baseline Loss: 2.7096 | Actual Loss: 0.9623\n",
      "Baseline Loss: 2.6636 | Actual Loss: 0.6611\n",
      "Baseline Loss: 2.6610 | Actual Loss: 0.7338\n",
      "Baseline Loss: 2.6845 | Actual Loss: 0.4852\n",
      "Baseline Loss: 2.6911 | Actual Loss: 0.4769\n",
      "Baseline Loss: 2.6680 | Actual Loss: 0.4379\n",
      "Baseline Loss: 2.6494 | Actual Loss: 0.3611\n",
      "Baseline Loss: 2.7228 | Actual Loss: 0.3749\n",
      "Baseline Loss: 2.6286 | Actual Loss: 0.7982\n",
      "Baseline Loss: 2.6619 | Actual Loss: 0.5088\n",
      "Baseline Loss: 2.6615 | Actual Loss: 0.3804\n",
      "Baseline Loss: 2.2930 | Actual Loss: 0.0627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▋        | 165/1000 [01:17<06:28,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6263 | Actual Loss: 1.4832\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.4370\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.5372\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4242\n",
      "Epoch 165/1000: Train Loss: 0.5387, Val Loss: 0.7204\n",
      "Baseline Loss: 2.7132 | Actual Loss: 0.5918\n",
      "Baseline Loss: 2.6744 | Actual Loss: 0.4276\n",
      "Baseline Loss: 2.6730 | Actual Loss: 0.5210\n",
      "Baseline Loss: 2.6959 | Actual Loss: 1.7378\n",
      "Baseline Loss: 2.6689 | Actual Loss: 0.1612\n",
      "Baseline Loss: 2.6459 | Actual Loss: 0.4333\n",
      "Baseline Loss: 2.6730 | Actual Loss: 0.4873\n",
      "Baseline Loss: 2.6926 | Actual Loss: 0.1592\n",
      "Baseline Loss: 2.6700 | Actual Loss: 0.4142\n",
      "Baseline Loss: 2.6787 | Actual Loss: 0.4623\n",
      "Baseline Loss: 2.6908 | Actual Loss: 0.3585\n",
      "Baseline Loss: 2.6906 | Actual Loss: 0.6882\n",
      "Baseline Loss: 2.6612 | Actual Loss: 0.5585\n",
      "Baseline Loss: 2.6854 | Actual Loss: 0.4581\n",
      "Baseline Loss: 2.7180 | Actual Loss: 0.6043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 166/1000 [01:18<06:38,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2818 | Actual Loss: 0.1262\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.9365\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.4065\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.4261\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.3182\n",
      "Epoch 166/1000: Train Loss: 0.5118, Val Loss: 0.7718\n",
      "Baseline Loss: 2.6510 | Actual Loss: 0.4614\n",
      "Baseline Loss: 2.6635 | Actual Loss: 0.4242\n",
      "Baseline Loss: 2.6416 | Actual Loss: 0.3047\n",
      "Baseline Loss: 2.6842 | Actual Loss: 0.4888\n",
      "Baseline Loss: 2.6553 | Actual Loss: 0.7512\n",
      "Baseline Loss: 2.6625 | Actual Loss: 0.1315\n",
      "Baseline Loss: 2.6972 | Actual Loss: 0.6323\n",
      "Baseline Loss: 2.7219 | Actual Loss: 0.3667\n",
      "Baseline Loss: 2.6998 | Actual Loss: 0.4288\n",
      "Baseline Loss: 2.7091 | Actual Loss: 0.6533\n",
      "Baseline Loss: 2.7377 | Actual Loss: 0.5528\n",
      "Baseline Loss: 2.7120 | Actual Loss: 0.8694\n",
      "Baseline Loss: 2.6150 | Actual Loss: 0.2226\n",
      "Baseline Loss: 2.6813 | Actual Loss: 0.2258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 167/1000 [01:18<06:44,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6780 | Actual Loss: 2.1323\n",
      "Baseline Loss: 2.2915 | Actual Loss: 0.2660\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.5066\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3727\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.5484\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4515\n",
      "Epoch 167/1000: Train Loss: 0.5570, Val Loss: 0.7198\n",
      "Baseline Loss: 2.6866 | Actual Loss: 0.6651\n",
      "Baseline Loss: 2.7040 | Actual Loss: 0.4209\n",
      "Baseline Loss: 2.7297 | Actual Loss: 0.2939\n",
      "Baseline Loss: 2.7027 | Actual Loss: 0.8426\n",
      "Baseline Loss: 2.6690 | Actual Loss: 0.3705\n",
      "Baseline Loss: 2.6689 | Actual Loss: 0.6709\n",
      "Baseline Loss: 2.6769 | Actual Loss: 0.6354\n",
      "Baseline Loss: 2.6503 | Actual Loss: 0.4796\n",
      "Baseline Loss: 2.6624 | Actual Loss: 0.2564\n",
      "Baseline Loss: 2.6740 | Actual Loss: 0.3121\n",
      "Baseline Loss: 2.6715 | Actual Loss: 0.4432\n",
      "Baseline Loss: 2.6533 | Actual Loss: 0.4436\n",
      "Baseline Loss: 2.6631 | Actual Loss: 0.2884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 168/1000 [01:18<06:21,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6745 | Actual Loss: 1.9468\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.6689\n",
      "Baseline Loss: 2.2963 | Actual Loss: 0.1152\n",
      "Baseline Loss: 2.6263 | Actual Loss: 0.9654\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.2874\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.4027\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.3607\n",
      "Epoch 168/1000: Train Loss: 0.5533, Val Loss: 0.5040\n",
      "Baseline Loss: 2.6689 | Actual Loss: 1.1858\n",
      "Baseline Loss: 2.7025 | Actual Loss: 0.5515\n",
      "Baseline Loss: 2.6930 | Actual Loss: 0.5672\n",
      "Baseline Loss: 2.6672 | Actual Loss: 0.6405\n",
      "Baseline Loss: 2.6637 | Actual Loss: 0.2915\n",
      "Baseline Loss: 2.6883 | Actual Loss: 0.3801\n",
      "Baseline Loss: 2.6697 | Actual Loss: 0.1809\n",
      "Baseline Loss: 2.6689 | Actual Loss: 0.3764\n",
      "Baseline Loss: 2.6560 | Actual Loss: 0.6748\n",
      "Baseline Loss: 2.6775 | Actual Loss: 1.6504\n",
      "Baseline Loss: 2.6959 | Actual Loss: 0.4164\n",
      "Baseline Loss: 2.6845 | Actual Loss: 1.0154\n",
      "Baseline Loss: 2.6529 | Actual Loss: 0.4581\n",
      "Baseline Loss: 2.6701 | Actual Loss: 0.3384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 169/1000 [01:19<06:32,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6767 | Actual Loss: 0.4675\n",
      "Baseline Loss: 2.2826 | Actual Loss: 0.2524\n",
      "Baseline Loss: 2.6263 | Actual Loss: 0.8059\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3851\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.5986\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4147\n",
      "Epoch 169/1000: Train Loss: 0.5905, Val Loss: 0.5511\n",
      "Baseline Loss: 2.6762 | Actual Loss: 0.5256\n",
      "Baseline Loss: 2.6975 | Actual Loss: 1.3826\n",
      "Baseline Loss: 2.6772 | Actual Loss: 0.1353\n",
      "Baseline Loss: 2.6909 | Actual Loss: 0.2956\n",
      "Baseline Loss: 2.6797 | Actual Loss: 0.1432\n",
      "Baseline Loss: 2.6539 | Actual Loss: 0.3776\n",
      "Baseline Loss: 2.6579 | Actual Loss: 0.3356\n",
      "Baseline Loss: 2.7097 | Actual Loss: 0.3445\n",
      "Baseline Loss: 2.6672 | Actual Loss: 0.4437\n",
      "Baseline Loss: 2.6728 | Actual Loss: 0.4609\n",
      "Baseline Loss: 2.6419 | Actual Loss: 0.4885\n",
      "Baseline Loss: 2.6506 | Actual Loss: 0.4720\n",
      "Baseline Loss: 2.6772 | Actual Loss: 0.6212\n",
      "Baseline Loss: 2.7018 | Actual Loss: 0.3886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 170/1000 [01:19<06:35,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6958 | Actual Loss: 0.6102\n",
      "Baseline Loss: 2.3178 | Actual Loss: 1.1125\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.5426\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3731\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.5350\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.3416\n",
      "Epoch 170/1000: Train Loss: 0.5086, Val Loss: 0.6981\n",
      "Baseline Loss: 2.6809 | Actual Loss: 0.8607\n",
      "Baseline Loss: 2.6448 | Actual Loss: 0.3303\n",
      "Baseline Loss: 2.7619 | Actual Loss: 0.5930\n",
      "Baseline Loss: 2.6741 | Actual Loss: 0.3988\n",
      "Baseline Loss: 2.6568 | Actual Loss: 0.5993\n",
      "Baseline Loss: 2.6838 | Actual Loss: 0.5178\n",
      "Baseline Loss: 2.6619 | Actual Loss: 0.3557\n",
      "Baseline Loss: 2.7116 | Actual Loss: 0.4918\n",
      "Baseline Loss: 2.6454 | Actual Loss: 0.4440\n",
      "Baseline Loss: 2.6595 | Actual Loss: 0.7013\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.3900\n",
      "Baseline Loss: 2.7338 | Actual Loss: 0.6053\n",
      "Baseline Loss: 2.6588 | Actual Loss: 0.6745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 171/1000 [01:20<06:24,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6453 | Actual Loss: 1.0803\n",
      "Baseline Loss: 2.6784 | Actual Loss: 0.2428\n",
      "Baseline Loss: 2.3086 | Actual Loss: 0.1783\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.4159\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.4312\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.4413\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.2847\n",
      "Epoch 171/1000: Train Loss: 0.5290, Val Loss: 0.6433\n",
      "Baseline Loss: 2.6493 | Actual Loss: 0.4711\n",
      "Baseline Loss: 2.7226 | Actual Loss: 0.5929\n",
      "Baseline Loss: 2.6898 | Actual Loss: 0.1613\n",
      "Baseline Loss: 2.7084 | Actual Loss: 0.6511\n",
      "Baseline Loss: 2.6835 | Actual Loss: 0.4715\n",
      "Baseline Loss: 2.6805 | Actual Loss: 0.5931\n",
      "Baseline Loss: 2.6684 | Actual Loss: 0.2538\n",
      "Baseline Loss: 2.6478 | Actual Loss: 0.4356\n",
      "Baseline Loss: 2.7335 | Actual Loss: 0.6050\n",
      "Baseline Loss: 2.7028 | Actual Loss: 0.4347\n",
      "Baseline Loss: 2.6522 | Actual Loss: 0.8074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 172/1000 [01:20<06:25,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6433 | Actual Loss: 0.3995\n",
      "Baseline Loss: 2.6966 | Actual Loss: 0.3986\n",
      "Baseline Loss: 2.6741 | Actual Loss: 0.3130\n",
      "Baseline Loss: 2.6604 | Actual Loss: 0.5908\n",
      "Baseline Loss: 2.2420 | Actual Loss: 0.2709\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.4925\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3777\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.5019\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.3563\n",
      "Epoch 172/1000: Train Loss: 0.4656, Val Loss: 0.6821\n",
      "Baseline Loss: 2.6731 | Actual Loss: 1.0070\n",
      "Baseline Loss: 2.6671 | Actual Loss: 0.5457\n",
      "Baseline Loss: 2.6606 | Actual Loss: 0.4357\n",
      "Baseline Loss: 2.6489 | Actual Loss: 0.4224\n",
      "Baseline Loss: 2.6618 | Actual Loss: 0.2307\n",
      "Baseline Loss: 2.6708 | Actual Loss: 0.7430\n",
      "Baseline Loss: 2.6878 | Actual Loss: 0.3726\n",
      "Baseline Loss: 2.6612 | Actual Loss: 0.5244\n",
      "Baseline Loss: 2.6641 | Actual Loss: 0.6990\n",
      "Baseline Loss: 2.6678 | Actual Loss: 0.2256\n",
      "Baseline Loss: 2.7059 | Actual Loss: 0.5240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 173/1000 [01:21<06:11,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7048 | Actual Loss: 0.4783\n",
      "Baseline Loss: 2.6535 | Actual Loss: 0.3052\n",
      "Baseline Loss: 2.6890 | Actual Loss: 1.4448\n",
      "Baseline Loss: 2.7305 | Actual Loss: 0.1739\n",
      "Baseline Loss: 2.3344 | Actual Loss: 0.9039\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.0815\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.4169\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.5644\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.3630\n",
      "Epoch 173/1000: Train Loss: 0.5648, Val Loss: 0.6065\n",
      "Baseline Loss: 2.7031 | Actual Loss: 0.4834\n",
      "Baseline Loss: 2.7076 | Actual Loss: 0.3719\n",
      "Baseline Loss: 2.6620 | Actual Loss: 0.4470\n",
      "Baseline Loss: 2.6683 | Actual Loss: 0.7938\n",
      "Baseline Loss: 2.6972 | Actual Loss: 0.5514\n",
      "Baseline Loss: 2.6600 | Actual Loss: 0.6494\n",
      "Baseline Loss: 2.6895 | Actual Loss: 2.0591\n",
      "Baseline Loss: 2.7111 | Actual Loss: 0.4197\n",
      "Baseline Loss: 2.6666 | Actual Loss: 0.3215\n",
      "Baseline Loss: 2.6593 | Actual Loss: 0.6170\n",
      "Baseline Loss: 2.6734 | Actual Loss: 0.3629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 174/1000 [01:21<06:22,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6884 | Actual Loss: 0.5120\n",
      "Baseline Loss: 2.6610 | Actual Loss: 0.6670\n",
      "Baseline Loss: 2.6725 | Actual Loss: 0.4162\n",
      "Baseline Loss: 2.6686 | Actual Loss: 0.6491\n",
      "Baseline Loss: 2.2642 | Actual Loss: 0.3728\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.7313\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3980\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.6426\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.3735\n",
      "Epoch 174/1000: Train Loss: 0.6059, Val Loss: 0.7863\n",
      "Baseline Loss: 2.6781 | Actual Loss: 0.5397\n",
      "Baseline Loss: 2.6570 | Actual Loss: 0.5019\n",
      "Baseline Loss: 2.7098 | Actual Loss: 0.4163\n",
      "Baseline Loss: 2.6625 | Actual Loss: 0.5840\n",
      "Baseline Loss: 2.7164 | Actual Loss: 0.3220\n",
      "Baseline Loss: 2.6954 | Actual Loss: 0.5114\n",
      "Baseline Loss: 2.6699 | Actual Loss: 1.0583\n",
      "Baseline Loss: 2.6698 | Actual Loss: 0.1474\n",
      "Baseline Loss: 2.6791 | Actual Loss: 0.6597\n",
      "Baseline Loss: 2.6790 | Actual Loss: 0.1603\n",
      "Baseline Loss: 2.6768 | Actual Loss: 0.5409\n",
      "Baseline Loss: 2.6700 | Actual Loss: 0.4492\n",
      "Baseline Loss: 2.6624 | Actual Loss: 0.6633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 175/1000 [01:22<06:12,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6624 | Actual Loss: 0.5761\n",
      "Baseline Loss: 2.6745 | Actual Loss: 0.4282\n",
      "Baseline Loss: 2.2806 | Actual Loss: 0.3513\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.4237\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.4014\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.5912\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.3985\n",
      "Epoch 175/1000: Train Loss: 0.4944, Val Loss: 0.7037\n",
      "Baseline Loss: 2.6425 | Actual Loss: 0.6212\n",
      "Baseline Loss: 2.6847 | Actual Loss: 0.3559\n",
      "Baseline Loss: 2.6322 | Actual Loss: 0.8007\n",
      "Baseline Loss: 2.6653 | Actual Loss: 0.3488\n",
      "Baseline Loss: 2.7038 | Actual Loss: 0.6689\n",
      "Baseline Loss: 2.6951 | Actual Loss: 0.7720\n",
      "Baseline Loss: 2.6740 | Actual Loss: 0.5940\n",
      "Baseline Loss: 2.6490 | Actual Loss: 0.5940\n",
      "Baseline Loss: 2.6609 | Actual Loss: 0.2382\n",
      "Baseline Loss: 2.7017 | Actual Loss: 0.3974\n",
      "Baseline Loss: 2.6510 | Actual Loss: 0.6013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 176/1000 [01:22<06:21,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6804 | Actual Loss: 0.3149\n",
      "Baseline Loss: 2.6887 | Actual Loss: 0.2978\n",
      "Baseline Loss: 2.6844 | Actual Loss: 0.4537\n",
      "Baseline Loss: 2.6342 | Actual Loss: 2.4646\n",
      "Baseline Loss: 2.2963 | Actual Loss: 0.7574\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.0796\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.4113\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.4894\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.2557\n",
      "Epoch 176/1000: Train Loss: 0.6425, Val Loss: 0.5590\n",
      "Baseline Loss: 2.7170 | Actual Loss: 0.8999\n",
      "Baseline Loss: 2.6701 | Actual Loss: 0.3158\n",
      "Baseline Loss: 2.6350 | Actual Loss: 0.7983\n",
      "Baseline Loss: 2.6971 | Actual Loss: 0.5934\n",
      "Baseline Loss: 2.6464 | Actual Loss: 0.6701\n",
      "Baseline Loss: 2.6727 | Actual Loss: 0.4758\n",
      "Baseline Loss: 2.7164 | Actual Loss: 0.4981\n",
      "Baseline Loss: 2.6818 | Actual Loss: 0.3496\n",
      "Baseline Loss: 2.7121 | Actual Loss: 0.7365\n",
      "Baseline Loss: 2.6661 | Actual Loss: 0.3784\n",
      "Baseline Loss: 2.6532 | Actual Loss: 0.4866\n",
      "Baseline Loss: 2.6916 | Actual Loss: 0.7226\n",
      "Baseline Loss: 2.6775 | Actual Loss: 0.7094\n",
      "Baseline Loss: 2.6642 | Actual Loss: 1.9140\n",
      "Baseline Loss: 2.6660 | Actual Loss: 0.1720\n",
      "Baseline Loss: 2.2011 | Actual Loss: 0.3608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 177/1000 [01:23<06:24,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6263 | Actual Loss: 1.2848\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.4205\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.4725\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.4145\n",
      "Epoch 177/1000: Train Loss: 0.6301, Val Loss: 0.6480\n",
      "Baseline Loss: 2.6871 | Actual Loss: 0.4345\n",
      "Baseline Loss: 2.6499 | Actual Loss: 0.8766\n",
      "Baseline Loss: 2.6704 | Actual Loss: 0.3562\n",
      "Baseline Loss: 2.6696 | Actual Loss: 0.8691\n",
      "Baseline Loss: 2.7018 | Actual Loss: 0.3430\n",
      "Baseline Loss: 2.6421 | Actual Loss: 0.7463\n",
      "Baseline Loss: 2.6781 | Actual Loss: 0.3967\n",
      "Baseline Loss: 2.6987 | Actual Loss: 0.1753\n",
      "Baseline Loss: 2.6744 | Actual Loss: 0.3467\n",
      "Baseline Loss: 2.6923 | Actual Loss: 0.7284\n",
      "Baseline Loss: 2.6925 | Actual Loss: 0.5986\n",
      "Baseline Loss: 2.6806 | Actual Loss: 0.1498\n",
      "Baseline Loss: 2.6932 | Actual Loss: 0.7904\n",
      "Baseline Loss: 2.7034 | Actual Loss: 0.3784\n",
      "Baseline Loss: 2.6736 | Actual Loss: 0.1967\n",
      "Baseline Loss: 2.3770 | Actual Loss: 0.1814\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.9464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 178/1000 [01:23<06:13,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7243 | Actual Loss: 0.3884\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.5450\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.3676\n",
      "Epoch 178/1000: Train Loss: 0.4730, Val Loss: 0.8119\n",
      "Baseline Loss: 2.6901 | Actual Loss: 0.4086\n",
      "Baseline Loss: 2.6657 | Actual Loss: 0.8321\n",
      "Baseline Loss: 2.6557 | Actual Loss: 0.6548\n",
      "Baseline Loss: 2.6776 | Actual Loss: 0.5509\n",
      "Baseline Loss: 2.6433 | Actual Loss: 0.6582\n",
      "Baseline Loss: 2.6913 | Actual Loss: 0.3982\n",
      "Baseline Loss: 2.6553 | Actual Loss: 0.5426\n",
      "Baseline Loss: 2.7489 | Actual Loss: 0.7593\n",
      "Baseline Loss: 2.6716 | Actual Loss: 0.5262\n",
      "Baseline Loss: 2.6760 | Actual Loss: 1.1064\n",
      "Baseline Loss: 2.6479 | Actual Loss: 0.5820\n",
      "Baseline Loss: 2.6729 | Actual Loss: 0.1354\n",
      "Baseline Loss: 2.7101 | Actual Loss: 0.6754\n",
      "Baseline Loss: 2.7000 | Actual Loss: 0.4094\n",
      "Baseline Loss: 2.6613 | Actual Loss: 0.7107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 179/1000 [01:24<06:19,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2835 | Actual Loss: 0.2866\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.3999\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.5304\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.4984\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.3504\n",
      "Epoch 179/1000: Train Loss: 0.5773, Val Loss: 0.6948\n",
      "Baseline Loss: 2.7271 | Actual Loss: 1.4129\n",
      "Baseline Loss: 2.6389 | Actual Loss: 0.7818\n",
      "Baseline Loss: 2.6905 | Actual Loss: 0.9758\n",
      "Baseline Loss: 2.6921 | Actual Loss: 0.4733\n",
      "Baseline Loss: 2.7005 | Actual Loss: 0.3160\n",
      "Baseline Loss: 2.6631 | Actual Loss: 0.6565\n",
      "Baseline Loss: 2.6704 | Actual Loss: 0.3014\n",
      "Baseline Loss: 2.6621 | Actual Loss: 0.2766\n",
      "Baseline Loss: 2.6677 | Actual Loss: 0.3622\n",
      "Baseline Loss: 2.6765 | Actual Loss: 0.2616\n",
      "Baseline Loss: 2.7104 | Actual Loss: 0.2761\n",
      "Baseline Loss: 2.6215 | Actual Loss: 0.5504\n",
      "Baseline Loss: 2.7273 | Actual Loss: 0.4539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 180/1000 [01:24<06:25,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6202 | Actual Loss: 0.2580\n",
      "Baseline Loss: 2.6855 | Actual Loss: 0.5585\n",
      "Baseline Loss: 2.2468 | Actual Loss: 0.1636\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.0980\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.4002\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.4757\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.3694\n",
      "Epoch 180/1000: Train Loss: 0.5049, Val Loss: 0.5858\n",
      "Baseline Loss: 2.6927 | Actual Loss: 0.3219\n",
      "Baseline Loss: 2.6259 | Actual Loss: 0.7115\n",
      "Baseline Loss: 2.6761 | Actual Loss: 0.2934\n",
      "Baseline Loss: 2.6581 | Actual Loss: 1.1332\n",
      "Baseline Loss: 2.6670 | Actual Loss: 0.2692\n",
      "Baseline Loss: 2.6717 | Actual Loss: 0.7161\n",
      "Baseline Loss: 2.6872 | Actual Loss: 0.5023\n",
      "Baseline Loss: 2.7065 | Actual Loss: 0.3548\n",
      "Baseline Loss: 2.6825 | Actual Loss: 0.2899\n",
      "Baseline Loss: 2.6808 | Actual Loss: 0.4708\n",
      "Baseline Loss: 2.7142 | Actual Loss: 0.2477\n",
      "Baseline Loss: 2.6605 | Actual Loss: 0.1443\n",
      "Baseline Loss: 2.6895 | Actual Loss: 0.3349\n",
      "Baseline Loss: 2.6952 | Actual Loss: 0.3505\n",
      "Baseline Loss: 2.6849 | Actual Loss: 0.3227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 181/1000 [01:24<06:10,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.3117 | Actual Loss: 0.4470\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.1041\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.3995\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.6502\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.2970\n",
      "Epoch 181/1000: Train Loss: 0.4319, Val Loss: 0.6127\n",
      "Baseline Loss: 2.6411 | Actual Loss: 0.4338\n",
      "Baseline Loss: 2.6687 | Actual Loss: 0.4591\n",
      "Baseline Loss: 2.7054 | Actual Loss: 0.6768\n",
      "Baseline Loss: 2.6554 | Actual Loss: 0.3367\n",
      "Baseline Loss: 2.7041 | Actual Loss: 0.4531\n",
      "Baseline Loss: 2.7052 | Actual Loss: 0.3127\n",
      "Baseline Loss: 2.7108 | Actual Loss: 0.5344\n",
      "Baseline Loss: 2.6694 | Actual Loss: 0.3323\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.3660\n",
      "Baseline Loss: 2.6590 | Actual Loss: 0.6136\n",
      "Baseline Loss: 2.6516 | Actual Loss: 0.9757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 181/1000 [01:25<06:26,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7380 | Actual Loss: 0.2822\n",
      "Baseline Loss: 2.6799 | Actual Loss: 1.2192\n",
      "Baseline Loss: 2.6532 | Actual Loss: 0.7517\n",
      "Baseline Loss: 2.6488 | Actual Loss: 0.4185\n",
      "Baseline Loss: 2.2404 | Actual Loss: 0.1798\n",
      "Baseline Loss: 2.6263 | Actual Loss: 1.9248\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.4020\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.5728\n",
      "Baseline Loss: 2.5648 | Actual Loss: 0.3950\n",
      "Epoch 182/1000: Train Loss: 0.5216, Val Loss: 0.8237\n",
      "\n",
      "Early stopping at epoch 182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.49975333362817764"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devices = [\"cuda\" if torch.cuda.is_available() else \"cpu\"]\n",
    "model5 = GNNModelWithNewLoss(\n",
    "        num_node_features=data_list[0].x.shape[1],\n",
    "        num_edge_features=data_list[0].edge_attr.shape[1],\n",
    "        num_global_features=data_list[0].global_features.shape[1],\n",
    "        cov_num= 6,\n",
    "        hidden_dim=512,\n",
    "        dropout_rate=0.1,\n",
    "        property_index= 1,\n",
    "        save_path= 'premodels_new/6/1' \n",
    "    ).to(devices[0])\n",
    "\n",
    "model5.train_model(\n",
    "    data_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "971916e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training will be saved to: premodels_new/6/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7887 | Actual Loss: 3.7450\n",
      "Baseline Loss: 3.5535 | Actual Loss: 3.6192\n",
      "Baseline Loss: 3.4539 | Actual Loss: 3.3939\n",
      "Baseline Loss: 3.4924 | Actual Loss: 3.3879\n",
      "Baseline Loss: 3.5789 | Actual Loss: 3.4810\n",
      "Baseline Loss: 3.5573 | Actual Loss: 3.3346\n",
      "Baseline Loss: 3.6831 | Actual Loss: 3.5366\n",
      "Baseline Loss: 3.5137 | Actual Loss: 3.4956\n",
      "Baseline Loss: 3.3338 | Actual Loss: 3.3440\n",
      "Baseline Loss: 3.3573 | Actual Loss: 3.3069\n",
      "Baseline Loss: 3.5793 | Actual Loss: 3.5105\n",
      "Baseline Loss: 3.4702 | Actual Loss: 3.4089\n",
      "Baseline Loss: 3.4470 | Actual Loss: 3.4152\n",
      "Baseline Loss: 3.4319 | Actual Loss: 3.3145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 1/1000 [00:00<09:04,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4323 | Actual Loss: 3.3615\n",
      "Baseline Loss: 3.4789 | Actual Loss: 3.3517\n",
      "Baseline Loss: 3.6273 | Actual Loss: 3.5329\n",
      "Baseline Loss: 3.5836 | Actual Loss: 3.3217\n",
      "Baseline Loss: 3.5497 | Actual Loss: 3.4987\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.6721\n",
      "Epoch 1/1000: Train Loss: 3.4379, Val Loss: 3.5063\n",
      "New best validation loss: 3.5063\n",
      "Baseline Loss: 3.7477 | Actual Loss: 3.5754\n",
      "Baseline Loss: 3.4702 | Actual Loss: 3.3212\n",
      "Baseline Loss: 3.3683 | Actual Loss: 3.2915\n",
      "Baseline Loss: 3.5135 | Actual Loss: 3.5036\n",
      "Baseline Loss: 3.5574 | Actual Loss: 3.4280\n",
      "Baseline Loss: 3.3885 | Actual Loss: 3.2164\n",
      "Baseline Loss: 3.5450 | Actual Loss: 3.4624\n",
      "Baseline Loss: 3.5706 | Actual Loss: 3.4494\n",
      "Baseline Loss: 3.3548 | Actual Loss: 3.1931\n",
      "Baseline Loss: 3.6687 | Actual Loss: 3.5323\n",
      "Baseline Loss: 3.4613 | Actual Loss: 3.2289\n",
      "Baseline Loss: 3.4070 | Actual Loss: 3.3136\n",
      "Baseline Loss: 3.4931 | Actual Loss: 3.2568\n",
      "Baseline Loss: 3.7529 | Actual Loss: 3.1938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 2/1000 [00:00<07:50,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5620 | Actual Loss: 3.2161\n",
      "Baseline Loss: 3.0997 | Actual Loss: 2.8387\n",
      "Baseline Loss: 3.6273 | Actual Loss: 3.2511\n",
      "Baseline Loss: 3.5836 | Actual Loss: 3.1705\n",
      "Baseline Loss: 3.5497 | Actual Loss: 3.3471\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.5373\n",
      "Epoch 2/1000: Train Loss: 3.3138, Val Loss: 3.3265\n",
      "New best validation loss: 3.3265\n",
      "Baseline Loss: 3.7121 | Actual Loss: 3.3830\n",
      "Baseline Loss: 3.3287 | Actual Loss: 2.8493\n",
      "Baseline Loss: 3.4928 | Actual Loss: 3.0196\n",
      "Baseline Loss: 3.4512 | Actual Loss: 3.1799\n",
      "Baseline Loss: 3.6969 | Actual Loss: 3.3887\n",
      "Baseline Loss: 3.5338 | Actual Loss: 3.0434\n",
      "Baseline Loss: 3.8048 | Actual Loss: 3.1729\n",
      "Baseline Loss: 3.5664 | Actual Loss: 3.2040\n",
      "Baseline Loss: 3.5874 | Actual Loss: 2.9064\n",
      "Baseline Loss: 3.5746 | Actual Loss: 3.2111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 3/1000 [00:01<07:47,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3048 | Actual Loss: 2.5891\n",
      "Baseline Loss: 3.3549 | Actual Loss: 2.8834\n",
      "Baseline Loss: 3.5091 | Actual Loss: 2.9733\n",
      "Baseline Loss: 3.4374 | Actual Loss: 2.7292\n",
      "Baseline Loss: 3.4849 | Actual Loss: 2.9072\n",
      "Baseline Loss: 3.5730 | Actual Loss: 3.2437\n",
      "Baseline Loss: 3.6273 | Actual Loss: 2.8833\n",
      "Baseline Loss: 3.5836 | Actual Loss: 2.8147\n",
      "Baseline Loss: 3.5497 | Actual Loss: 2.9346\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.0565\n",
      "Epoch 3/1000: Train Loss: 3.0428, Val Loss: 2.9223\n",
      "New best validation loss: 2.9223\n",
      "Baseline Loss: 3.3959 | Actual Loss: 2.4311\n",
      "Baseline Loss: 3.2977 | Actual Loss: 3.0025\n",
      "Baseline Loss: 3.5120 | Actual Loss: 2.2622\n",
      "Baseline Loss: 3.5368 | Actual Loss: 2.5777\n",
      "Baseline Loss: 3.4070 | Actual Loss: 2.4389\n",
      "Baseline Loss: 3.3590 | Actual Loss: 2.4479\n",
      "Baseline Loss: 3.5918 | Actual Loss: 2.8161\n",
      "Baseline Loss: 3.4289 | Actual Loss: 2.7399\n",
      "Baseline Loss: 3.4691 | Actual Loss: 2.4065\n",
      "Baseline Loss: 3.5533 | Actual Loss: 2.9564\n",
      "Baseline Loss: 3.5128 | Actual Loss: 2.4780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 4/1000 [00:01<08:15,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7999 | Actual Loss: 2.5014\n",
      "Baseline Loss: 3.5047 | Actual Loss: 2.4744\n",
      "Baseline Loss: 3.3444 | Actual Loss: 2.4030\n",
      "Baseline Loss: 3.5920 | Actual Loss: 2.2413\n",
      "Baseline Loss: 3.4682 | Actual Loss: 2.2086\n",
      "Baseline Loss: 3.6273 | Actual Loss: 2.5210\n",
      "Baseline Loss: 3.5836 | Actual Loss: 2.6293\n",
      "Baseline Loss: 3.5497 | Actual Loss: 2.0281\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.6014\n",
      "Epoch 4/1000: Train Loss: 2.5241, Val Loss: 2.6950\n",
      "New best validation loss: 2.6950\n",
      "Baseline Loss: 3.5705 | Actual Loss: 2.4393\n",
      "Baseline Loss: 3.5132 | Actual Loss: 2.0458\n",
      "Baseline Loss: 3.3649 | Actual Loss: 2.2551\n",
      "Baseline Loss: 3.5410 | Actual Loss: 2.0559\n",
      "Baseline Loss: 3.5611 | Actual Loss: 1.8694\n",
      "Baseline Loss: 3.3856 | Actual Loss: 1.8810\n",
      "Baseline Loss: 3.3711 | Actual Loss: 2.2619\n",
      "Baseline Loss: 3.4471 | Actual Loss: 2.2219\n",
      "Baseline Loss: 3.3886 | Actual Loss: 2.1458\n",
      "Baseline Loss: 3.6272 | Actual Loss: 1.9518\n",
      "Baseline Loss: 3.4852 | Actual Loss: 2.2623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 5/1000 [00:02<07:37,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4542 | Actual Loss: 2.2882\n",
      "Baseline Loss: 3.5288 | Actual Loss: 1.6488\n",
      "Baseline Loss: 3.5417 | Actual Loss: 1.9722\n",
      "Baseline Loss: 3.5006 | Actual Loss: 1.6360\n",
      "Baseline Loss: 3.6642 | Actual Loss: 1.4405\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.8972\n",
      "Baseline Loss: 3.5836 | Actual Loss: 1.9573\n",
      "Baseline Loss: 3.5497 | Actual Loss: 2.4669\n",
      "Baseline Loss: 3.9021 | Actual Loss: 2.6131\n",
      "Epoch 5/1000: Train Loss: 2.0235, Val Loss: 2.2336\n",
      "New best validation loss: 2.2336\n",
      "Baseline Loss: 3.3854 | Actual Loss: 1.9084\n",
      "Baseline Loss: 3.4931 | Actual Loss: 2.6076\n",
      "Baseline Loss: 3.4399 | Actual Loss: 2.7044\n",
      "Baseline Loss: 3.5405 | Actual Loss: 1.9365\n",
      "Baseline Loss: 3.5168 | Actual Loss: 2.1476\n",
      "Baseline Loss: 3.5458 | Actual Loss: 1.6951\n",
      "Baseline Loss: 3.5095 | Actual Loss: 2.1341\n",
      "Baseline Loss: 3.5377 | Actual Loss: 2.0445\n",
      "Baseline Loss: 3.4778 | Actual Loss: 2.2628\n",
      "Baseline Loss: 3.5329 | Actual Loss: 1.8786\n",
      "Baseline Loss: 3.6923 | Actual Loss: 1.9952\n",
      "Baseline Loss: 3.5793 | Actual Loss: 2.2028\n",
      "Baseline Loss: 3.4059 | Actual Loss: 2.2377\n",
      "Baseline Loss: 3.5368 | Actual Loss: 2.2639\n",
      "Baseline Loss: 3.3435 | Actual Loss: 1.8061\n",
      "Baseline Loss: 3.4393 | Actual Loss: 2.5485\n",
      "Baseline Loss: 3.6273 | Actual Loss: 2.0084\n",
      "Baseline Loss: 3.5836 | Actual Loss: 1.7878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 6/1000 [00:02<07:51,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5497 | Actual Loss: 2.4039\n",
      "Baseline Loss: 3.9021 | Actual Loss: 2.6149\n",
      "Epoch 6/1000: Train Loss: 2.1484, Val Loss: 2.2037\n",
      "New best validation loss: 2.2037\n",
      "Baseline Loss: 3.3755 | Actual Loss: 1.5961\n",
      "Baseline Loss: 3.5664 | Actual Loss: 1.7275\n",
      "Baseline Loss: 3.4040 | Actual Loss: 1.8029\n",
      "Baseline Loss: 3.7372 | Actual Loss: 2.4638\n",
      "Baseline Loss: 3.5789 | Actual Loss: 1.6523\n",
      "Baseline Loss: 3.2879 | Actual Loss: 2.0280\n",
      "Baseline Loss: 3.3344 | Actual Loss: 1.9084\n",
      "Baseline Loss: 3.6451 | Actual Loss: 1.9906\n",
      "Baseline Loss: 3.7418 | Actual Loss: 2.0953\n",
      "Baseline Loss: 3.3406 | Actual Loss: 2.0175\n",
      "Baseline Loss: 3.5409 | Actual Loss: 2.0090\n",
      "Baseline Loss: 3.6930 | Actual Loss: 1.6754\n",
      "Baseline Loss: 3.3618 | Actual Loss: 1.6782\n",
      "Baseline Loss: 3.5219 | Actual Loss: 2.0172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 7/1000 [00:03<08:04,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5706 | Actual Loss: 1.8816\n",
      "Baseline Loss: 3.2968 | Actual Loss: 1.6532\n",
      "Baseline Loss: 3.6273 | Actual Loss: 2.0047\n",
      "Baseline Loss: 3.5836 | Actual Loss: 1.3039\n",
      "Baseline Loss: 3.5497 | Actual Loss: 2.2477\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.0831\n",
      "Epoch 7/1000: Train Loss: 1.8873, Val Loss: 2.1598\n",
      "New best validation loss: 2.1598\n",
      "Baseline Loss: 3.4733 | Actual Loss: 2.3955\n",
      "Baseline Loss: 3.5654 | Actual Loss: 2.3914\n",
      "Baseline Loss: 3.5414 | Actual Loss: 1.8310\n",
      "Baseline Loss: 3.4659 | Actual Loss: 1.9412\n",
      "Baseline Loss: 3.3996 | Actual Loss: 1.7727\n",
      "Baseline Loss: 3.5792 | Actual Loss: 1.8463\n",
      "Baseline Loss: 3.5213 | Actual Loss: 1.8745\n",
      "Baseline Loss: 3.5176 | Actual Loss: 1.6613\n",
      "Baseline Loss: 3.6321 | Actual Loss: 1.7304\n",
      "Baseline Loss: 3.4325 | Actual Loss: 2.0561\n",
      "Baseline Loss: 3.6051 | Actual Loss: 1.9423\n",
      "Baseline Loss: 3.5118 | Actual Loss: 1.6732\n",
      "Baseline Loss: 3.3677 | Actual Loss: 1.7819\n",
      "Baseline Loss: 3.3852 | Actual Loss: 2.1720\n",
      "Baseline Loss: 3.4788 | Actual Loss: 1.2172\n",
      "Baseline Loss: 2.9908 | Actual Loss: 2.2056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 8/1000 [00:03<07:34,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6273 | Actual Loss: 1.6304\n",
      "Baseline Loss: 3.5836 | Actual Loss: 1.8465\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.7778\n",
      "Baseline Loss: 3.9021 | Actual Loss: 2.9346\n",
      "Epoch 8/1000: Train Loss: 1.9058, Val Loss: 2.0473\n",
      "New best validation loss: 2.0473\n",
      "Baseline Loss: 3.5662 | Actual Loss: 1.5289\n",
      "Baseline Loss: 3.7945 | Actual Loss: 2.1927\n",
      "Baseline Loss: 3.4074 | Actual Loss: 1.5683\n",
      "Baseline Loss: 3.4777 | Actual Loss: 1.8110\n",
      "Baseline Loss: 3.5661 | Actual Loss: 1.5184\n",
      "Baseline Loss: 3.5748 | Actual Loss: 2.3789\n",
      "Baseline Loss: 3.5203 | Actual Loss: 2.3522\n",
      "Baseline Loss: 3.3709 | Actual Loss: 1.9235\n",
      "Baseline Loss: 3.2453 | Actual Loss: 1.7730\n",
      "Baseline Loss: 3.5660 | Actual Loss: 1.4418\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.4681\n",
      "Baseline Loss: 3.5048 | Actual Loss: 2.0349\n",
      "Baseline Loss: 3.4961 | Actual Loss: 1.6753\n",
      "Baseline Loss: 3.4887 | Actual Loss: 1.4162\n",
      "Baseline Loss: 3.5161 | Actual Loss: 2.0181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 9/1000 [00:04<07:42,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.2186 | Actual Loss: 1.1290\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.6946\n",
      "Baseline Loss: 3.5836 | Actual Loss: 1.5877\n",
      "Baseline Loss: 3.5497 | Actual Loss: 2.0610\n",
      "Baseline Loss: 3.9021 | Actual Loss: 2.9442\n",
      "Epoch 9/1000: Train Loss: 1.7644, Val Loss: 2.0719\n",
      "Baseline Loss: 3.5578 | Actual Loss: 1.4939\n",
      "Baseline Loss: 3.3178 | Actual Loss: 1.9229\n",
      "Baseline Loss: 3.4103 | Actual Loss: 2.1838\n",
      "Baseline Loss: 3.5334 | Actual Loss: 1.6389\n",
      "Baseline Loss: 3.5373 | Actual Loss: 2.0460\n",
      "Baseline Loss: 3.4401 | Actual Loss: 1.7747\n",
      "Baseline Loss: 3.5881 | Actual Loss: 1.9971\n",
      "Baseline Loss: 3.3572 | Actual Loss: 1.5907\n",
      "Baseline Loss: 3.5789 | Actual Loss: 2.5898\n",
      "Baseline Loss: 3.2391 | Actual Loss: 1.9612\n",
      "Baseline Loss: 3.5462 | Actual Loss: 1.9718\n",
      "Baseline Loss: 3.4784 | Actual Loss: 1.7237\n",
      "Baseline Loss: 3.3678 | Actual Loss: 1.3028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 10/1000 [00:04<07:55,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6093 | Actual Loss: 1.4572\n",
      "Baseline Loss: 3.5053 | Actual Loss: 1.7302\n",
      "Baseline Loss: 3.5100 | Actual Loss: 0.8287\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.7672\n",
      "Baseline Loss: 3.5836 | Actual Loss: 1.9326\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.9086\n",
      "Baseline Loss: 3.9021 | Actual Loss: 2.7955\n",
      "Epoch 10/1000: Train Loss: 1.7633, Val Loss: 2.1010\n",
      "Baseline Loss: 3.6096 | Actual Loss: 2.0201\n",
      "Baseline Loss: 3.5089 | Actual Loss: 2.3773\n",
      "Baseline Loss: 3.3471 | Actual Loss: 1.4470\n",
      "Baseline Loss: 3.4064 | Actual Loss: 2.2584\n",
      "Baseline Loss: 3.5537 | Actual Loss: 1.5166\n",
      "Baseline Loss: 3.4845 | Actual Loss: 1.3382\n",
      "Baseline Loss: 3.6414 | Actual Loss: 2.2317\n",
      "Baseline Loss: 3.4625 | Actual Loss: 1.7678\n",
      "Baseline Loss: 3.3377 | Actual Loss: 1.4322\n",
      "Baseline Loss: 3.1227 | Actual Loss: 1.8803\n",
      "Baseline Loss: 3.6639 | Actual Loss: 1.8536\n",
      "Baseline Loss: 3.6890 | Actual Loss: 1.7578\n",
      "Baseline Loss: 3.7214 | Actual Loss: 1.6186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 11/1000 [00:05<07:31,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5798 | Actual Loss: 1.8435\n",
      "Baseline Loss: 3.4736 | Actual Loss: 1.8731\n",
      "Baseline Loss: 3.5094 | Actual Loss: 0.9280\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.9057\n",
      "Baseline Loss: 3.5836 | Actual Loss: 1.4075\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.9679\n",
      "Baseline Loss: 3.9021 | Actual Loss: 2.7512\n",
      "Epoch 11/1000: Train Loss: 1.7590, Val Loss: 2.0081\n",
      "New best validation loss: 2.0081\n",
      "Baseline Loss: 3.4741 | Actual Loss: 1.7317\n",
      "Baseline Loss: 3.5922 | Actual Loss: 1.7133\n",
      "Baseline Loss: 3.5044 | Actual Loss: 1.4682\n",
      "Baseline Loss: 3.5877 | Actual Loss: 1.8335\n",
      "Baseline Loss: 3.4257 | Actual Loss: 1.7930\n",
      "Baseline Loss: 3.5923 | Actual Loss: 2.3321\n",
      "Baseline Loss: 3.6141 | Actual Loss: 2.1460\n",
      "Baseline Loss: 3.4330 | Actual Loss: 1.5174\n",
      "Baseline Loss: 3.5247 | Actual Loss: 1.4103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 12/1000 [00:05<07:33,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4098 | Actual Loss: 1.2291\n",
      "Baseline Loss: 3.4396 | Actual Loss: 1.6601\n",
      "Baseline Loss: 3.6499 | Actual Loss: 1.4205\n",
      "Baseline Loss: 3.4499 | Actual Loss: 1.7495\n",
      "Baseline Loss: 3.4586 | Actual Loss: 1.5664\n",
      "Baseline Loss: 3.4351 | Actual Loss: 2.4423\n",
      "Baseline Loss: 3.7139 | Actual Loss: 2.2590\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.7229\n",
      "Baseline Loss: 3.5836 | Actual Loss: 1.8017\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.9813\n",
      "Baseline Loss: 3.9021 | Actual Loss: 2.6298\n",
      "Epoch 12/1000: Train Loss: 1.7670, Val Loss: 2.0339\n",
      "Baseline Loss: 3.8954 | Actual Loss: 2.1748\n",
      "Baseline Loss: 3.6372 | Actual Loss: 2.1941\n",
      "Baseline Loss: 3.3885 | Actual Loss: 1.4162\n",
      "Baseline Loss: 3.4740 | Actual Loss: 1.7920\n",
      "Baseline Loss: 3.4696 | Actual Loss: 1.6625\n",
      "Baseline Loss: 3.3571 | Actual Loss: 1.4463\n",
      "Baseline Loss: 3.4657 | Actual Loss: 1.4067\n",
      "Baseline Loss: 3.4434 | Actual Loss: 1.3222\n",
      "Baseline Loss: 3.7465 | Actual Loss: 1.3792\n",
      "Baseline Loss: 3.3993 | Actual Loss: 1.4943\n",
      "Baseline Loss: 3.4929 | Actual Loss: 2.0784\n",
      "Baseline Loss: 3.4822 | Actual Loss: 2.0395\n",
      "Baseline Loss: 3.5613 | Actual Loss: 1.5439\n",
      "Baseline Loss: 3.5008 | Actual Loss: 1.2658\n",
      "Baseline Loss: 3.5088 | Actual Loss: 1.1683\n",
      "Baseline Loss: 3.1663 | Actual Loss: 0.9852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏         | 13/1000 [00:06<07:48,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6273 | Actual Loss: 1.7996\n",
      "Baseline Loss: 3.5836 | Actual Loss: 1.6564\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.7421\n",
      "Baseline Loss: 3.9021 | Actual Loss: 2.2202\n",
      "Epoch 13/1000: Train Loss: 1.5856, Val Loss: 1.8546\n",
      "New best validation loss: 1.8546\n",
      "Baseline Loss: 3.4077 | Actual Loss: 1.3756\n",
      "Baseline Loss: 3.2975 | Actual Loss: 1.6810\n",
      "Baseline Loss: 3.5658 | Actual Loss: 1.4880\n",
      "Baseline Loss: 3.4840 | Actual Loss: 1.9583\n",
      "Baseline Loss: 3.7121 | Actual Loss: 1.0944\n",
      "Baseline Loss: 3.5453 | Actual Loss: 1.3423\n",
      "Baseline Loss: 3.5294 | Actual Loss: 1.9353\n",
      "Baseline Loss: 3.7627 | Actual Loss: 1.7058\n",
      "Baseline Loss: 3.4967 | Actual Loss: 1.7279\n",
      "Baseline Loss: 3.5510 | Actual Loss: 1.7905\n",
      "Baseline Loss: 3.4174 | Actual Loss: 1.1712\n",
      "Baseline Loss: 3.4765 | Actual Loss: 1.1243\n",
      "Baseline Loss: 3.4583 | Actual Loss: 1.6204\n",
      "Baseline Loss: 3.4660 | Actual Loss: 1.2224\n",
      "Baseline Loss: 3.5500 | Actual Loss: 1.6044\n",
      "Baseline Loss: 3.4207 | Actual Loss: 2.0438\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.3951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏         | 14/1000 [00:06<07:32,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5836 | Actual Loss: 1.5169\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.6956\n",
      "Baseline Loss: 3.9021 | Actual Loss: 1.7786\n",
      "Epoch 14/1000: Train Loss: 1.5554, Val Loss: 1.5966\n",
      "New best validation loss: 1.5966\n",
      "Baseline Loss: 3.4215 | Actual Loss: 1.6185\n",
      "Baseline Loss: 3.4734 | Actual Loss: 1.6445\n",
      "Baseline Loss: 3.4504 | Actual Loss: 1.3854\n",
      "Baseline Loss: 3.3923 | Actual Loss: 1.2313\n",
      "Baseline Loss: 3.6455 | Actual Loss: 1.6078\n",
      "Baseline Loss: 3.5488 | Actual Loss: 1.7400\n",
      "Baseline Loss: 3.3812 | Actual Loss: 1.2530\n",
      "Baseline Loss: 3.6928 | Actual Loss: 1.2080\n",
      "Baseline Loss: 3.5577 | Actual Loss: 1.6846\n",
      "Baseline Loss: 3.4250 | Actual Loss: 1.7181\n",
      "Baseline Loss: 3.3403 | Actual Loss: 1.8506\n",
      "Baseline Loss: 3.5289 | Actual Loss: 2.3481\n",
      "Baseline Loss: 3.5660 | Actual Loss: 1.1170\n",
      "Baseline Loss: 3.4539 | Actual Loss: 1.8241\n",
      "Baseline Loss: 3.7064 | Actual Loss: 1.3679\n",
      "Baseline Loss: 3.2418 | Actual Loss: 0.6278\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.7914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 15/1000 [00:07<07:29,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5836 | Actual Loss: 1.6177\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.8009\n",
      "Baseline Loss: 3.9021 | Actual Loss: 2.4767\n",
      "Epoch 15/1000: Train Loss: 1.5142, Val Loss: 1.9217\n",
      "Baseline Loss: 3.3467 | Actual Loss: 2.1431\n",
      "Baseline Loss: 3.6643 | Actual Loss: 1.2785\n",
      "Baseline Loss: 3.3776 | Actual Loss: 1.7358\n",
      "Baseline Loss: 3.4145 | Actual Loss: 1.4740\n",
      "Baseline Loss: 3.5373 | Actual Loss: 1.0919\n",
      "Baseline Loss: 3.4252 | Actual Loss: 1.0612\n",
      "Baseline Loss: 3.4920 | Actual Loss: 2.0826\n",
      "Baseline Loss: 3.5095 | Actual Loss: 1.5286\n",
      "Baseline Loss: 3.6598 | Actual Loss: 1.0018\n",
      "Baseline Loss: 3.5243 | Actual Loss: 1.6521\n",
      "Baseline Loss: 3.3436 | Actual Loss: 1.9283\n",
      "Baseline Loss: 3.3379 | Actual Loss: 1.6328\n",
      "Baseline Loss: 3.5784 | Actual Loss: 1.6234\n",
      "Baseline Loss: 3.3851 | Actual Loss: 1.3063\n",
      "Baseline Loss: 3.5787 | Actual Loss: 1.7557\n",
      "Baseline Loss: 3.7933 | Actual Loss: 1.9812\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.2448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 16/1000 [00:07<07:46,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5836 | Actual Loss: 1.3363\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.9141\n",
      "Baseline Loss: 3.9021 | Actual Loss: 2.6403\n",
      "Epoch 16/1000: Train Loss: 1.5798, Val Loss: 1.7838\n",
      "Baseline Loss: 3.5965 | Actual Loss: 1.4778\n",
      "Baseline Loss: 3.5086 | Actual Loss: 1.3854\n",
      "Baseline Loss: 3.2225 | Actual Loss: 1.4540\n",
      "Baseline Loss: 3.5419 | Actual Loss: 1.6598\n",
      "Baseline Loss: 3.5171 | Actual Loss: 2.0987\n",
      "Baseline Loss: 3.5628 | Actual Loss: 1.7720\n",
      "Baseline Loss: 3.6013 | Actual Loss: 1.2590\n",
      "Baseline Loss: 3.6924 | Actual Loss: 1.8327\n",
      "Baseline Loss: 3.4777 | Actual Loss: 1.3738\n",
      "Baseline Loss: 3.6971 | Actual Loss: 1.4130\n",
      "Baseline Loss: 3.4063 | Actual Loss: 1.4748\n",
      "Baseline Loss: 3.5332 | Actual Loss: 2.9917\n",
      "Baseline Loss: 3.3445 | Actual Loss: 1.2353\n",
      "Baseline Loss: 3.4104 | Actual Loss: 1.8939\n",
      "Baseline Loss: 3.4442 | Actual Loss: 1.7013\n",
      "Baseline Loss: 3.3754 | Actual Loss: 1.7104\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.4776\n",
      "Baseline Loss: 3.5836 | Actual Loss: 1.3434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 17/1000 [00:07<07:22,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5497 | Actual Loss: 1.5999\n",
      "Baseline Loss: 3.9021 | Actual Loss: 2.5564\n",
      "Epoch 17/1000: Train Loss: 1.6708, Val Loss: 1.7443\n",
      "Baseline Loss: 3.6639 | Actual Loss: 2.0149\n",
      "Baseline Loss: 3.4090 | Actual Loss: 1.6550\n",
      "Baseline Loss: 3.4732 | Actual Loss: 1.3013\n",
      "Baseline Loss: 3.4363 | Actual Loss: 2.1492\n",
      "Baseline Loss: 3.5247 | Actual Loss: 1.7925\n",
      "Baseline Loss: 3.5409 | Actual Loss: 1.2955\n",
      "Baseline Loss: 3.3318 | Actual Loss: 1.7538\n",
      "Baseline Loss: 3.6008 | Actual Loss: 1.2422\n",
      "Baseline Loss: 3.5010 | Actual Loss: 1.3561\n",
      "Baseline Loss: 3.4165 | Actual Loss: 1.1530\n",
      "Baseline Loss: 3.5716 | Actual Loss: 1.9258\n",
      "Baseline Loss: 3.4890 | Actual Loss: 1.4217\n",
      "Baseline Loss: 3.4739 | Actual Loss: 1.5675\n",
      "Baseline Loss: 3.6146 | Actual Loss: 1.5392\n",
      "Baseline Loss: 3.4135 | Actual Loss: 1.2478\n",
      "Baseline Loss: 3.3757 | Actual Loss: 1.2095\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.2633\n",
      "Baseline Loss: 3.5836 | Actual Loss: 1.3835\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.7215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 18/1000 [00:08<07:31,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.9021 | Actual Loss: 1.9068\n",
      "Epoch 18/1000: Train Loss: 1.5391, Val Loss: 1.5688\n",
      "New best validation loss: 1.5688\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.8937\n",
      "Baseline Loss: 3.3900 | Actual Loss: 1.1927\n",
      "Baseline Loss: 3.3511 | Actual Loss: 1.2343\n",
      "Baseline Loss: 3.4397 | Actual Loss: 1.5300\n",
      "Baseline Loss: 3.5373 | Actual Loss: 1.1036\n",
      "Baseline Loss: 3.5580 | Actual Loss: 1.9156\n",
      "Baseline Loss: 3.7830 | Actual Loss: 1.6890\n",
      "Baseline Loss: 3.5088 | Actual Loss: 1.8805\n",
      "Baseline Loss: 3.5162 | Actual Loss: 1.3396\n",
      "Baseline Loss: 3.3501 | Actual Loss: 1.2554\n",
      "Baseline Loss: 3.5743 | Actual Loss: 2.3907\n",
      "Baseline Loss: 3.4030 | Actual Loss: 1.9452\n",
      "Baseline Loss: 3.4617 | Actual Loss: 1.5743\n",
      "Baseline Loss: 3.7078 | Actual Loss: 1.4510\n",
      "Baseline Loss: 3.5178 | Actual Loss: 1.0386\n",
      "Baseline Loss: 3.7018 | Actual Loss: 1.3037\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.3951\n",
      "Baseline Loss: 3.5836 | Actual Loss: 1.5413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 19/1000 [00:08<07:20,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5497 | Actual Loss: 1.8256\n",
      "Baseline Loss: 3.9021 | Actual Loss: 2.4574\n",
      "Epoch 19/1000: Train Loss: 1.5461, Val Loss: 1.8048\n",
      "Baseline Loss: 3.4396 | Actual Loss: 1.3610\n",
      "Baseline Loss: 3.5798 | Actual Loss: 1.0475\n",
      "Baseline Loss: 3.5290 | Actual Loss: 0.9126\n",
      "Baseline Loss: 3.5134 | Actual Loss: 1.5546\n",
      "Baseline Loss: 3.6177 | Actual Loss: 1.3905\n",
      "Baseline Loss: 3.3582 | Actual Loss: 1.3262\n",
      "Baseline Loss: 3.4585 | Actual Loss: 1.0502\n",
      "Baseline Loss: 3.4241 | Actual Loss: 1.7812\n",
      "Baseline Loss: 3.6326 | Actual Loss: 1.0281\n",
      "Baseline Loss: 3.5131 | Actual Loss: 1.3964\n",
      "Baseline Loss: 3.5287 | Actual Loss: 1.3184\n",
      "Baseline Loss: 3.5543 | Actual Loss: 1.9520\n",
      "Baseline Loss: 3.6051 | Actual Loss: 1.2943\n",
      "Baseline Loss: 3.5747 | Actual Loss: 1.6709\n",
      "Baseline Loss: 3.4517 | Actual Loss: 1.0993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 20/1000 [00:09<07:27,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.1256 | Actual Loss: 1.3267\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.3541\n",
      "Baseline Loss: 3.5836 | Actual Loss: 1.4967\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.4367\n",
      "Baseline Loss: 3.9021 | Actual Loss: 2.1455\n",
      "Epoch 20/1000: Train Loss: 1.3444, Val Loss: 1.6083\n",
      "Baseline Loss: 3.4783 | Actual Loss: 1.4618\n",
      "Baseline Loss: 3.3739 | Actual Loss: 1.4782\n",
      "Baseline Loss: 3.5368 | Actual Loss: 1.0859\n",
      "Baseline Loss: 3.6271 | Actual Loss: 1.7017\n",
      "Baseline Loss: 3.4580 | Actual Loss: 1.1357\n",
      "Baseline Loss: 3.5292 | Actual Loss: 1.3472\n",
      "Baseline Loss: 3.3919 | Actual Loss: 1.1001\n",
      "Baseline Loss: 3.5792 | Actual Loss: 1.0266\n",
      "Baseline Loss: 3.5663 | Actual Loss: 1.2549\n",
      "Baseline Loss: 3.6005 | Actual Loss: 2.4308\n",
      "Baseline Loss: 3.4135 | Actual Loss: 1.3423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 21/1000 [00:09<07:50,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4106 | Actual Loss: 1.2884\n",
      "Baseline Loss: 3.4659 | Actual Loss: 1.3787\n",
      "Baseline Loss: 3.7518 | Actual Loss: 1.3156\n",
      "Baseline Loss: 3.4899 | Actual Loss: 2.0147\n",
      "Baseline Loss: 3.3739 | Actual Loss: 1.2985\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.2795\n",
      "Baseline Loss: 3.5836 | Actual Loss: 1.5842\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.7860\n",
      "Baseline Loss: 3.9021 | Actual Loss: 2.6572\n",
      "Epoch 21/1000: Train Loss: 1.4163, Val Loss: 1.8267\n",
      "Baseline Loss: 3.3779 | Actual Loss: 1.6773\n",
      "Baseline Loss: 3.5043 | Actual Loss: 1.2262\n",
      "Baseline Loss: 3.5091 | Actual Loss: 1.4852\n",
      "Baseline Loss: 3.4648 | Actual Loss: 1.5882\n",
      "Baseline Loss: 3.5794 | Actual Loss: 2.0981\n",
      "Baseline Loss: 3.4356 | Actual Loss: 1.2886\n",
      "Baseline Loss: 3.4147 | Actual Loss: 1.5260\n",
      "Baseline Loss: 3.5124 | Actual Loss: 1.3234\n",
      "Baseline Loss: 3.4322 | Actual Loss: 1.3466\n",
      "Baseline Loss: 3.6319 | Actual Loss: 0.9452\n",
      "Baseline Loss: 3.5795 | Actual Loss: 1.6954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 22/1000 [00:10<07:24,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4734 | Actual Loss: 1.1114\n",
      "Baseline Loss: 3.6223 | Actual Loss: 1.2693\n",
      "Baseline Loss: 3.5259 | Actual Loss: 1.1922\n",
      "Baseline Loss: 3.5368 | Actual Loss: 2.0596\n",
      "Baseline Loss: 3.2971 | Actual Loss: 1.2793\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.4049\n",
      "Baseline Loss: 3.5836 | Actual Loss: 1.1303\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.6190\n",
      "Baseline Loss: 3.9021 | Actual Loss: 2.1750\n",
      "Epoch 22/1000: Train Loss: 1.4445, Val Loss: 1.5823\n",
      "Baseline Loss: 3.3990 | Actual Loss: 1.1900\n",
      "Baseline Loss: 3.5414 | Actual Loss: 0.9499\n",
      "Baseline Loss: 3.7468 | Actual Loss: 1.6322\n",
      "Baseline Loss: 3.4174 | Actual Loss: 1.1756\n",
      "Baseline Loss: 3.4579 | Actual Loss: 1.3005\n",
      "Baseline Loss: 3.4294 | Actual Loss: 1.4154\n",
      "Baseline Loss: 3.3300 | Actual Loss: 1.6267\n",
      "Baseline Loss: 3.6041 | Actual Loss: 1.0881\n",
      "Baseline Loss: 3.5663 | Actual Loss: 1.1180\n",
      "Baseline Loss: 3.7017 | Actual Loss: 1.6773\n",
      "Baseline Loss: 3.3758 | Actual Loss: 1.0330\n",
      "Baseline Loss: 3.3646 | Actual Loss: 1.0500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 23/1000 [00:10<07:29,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6319 | Actual Loss: 0.9522\n",
      "Baseline Loss: 3.5213 | Actual Loss: 1.9643\n",
      "Baseline Loss: 3.2761 | Actual Loss: 1.3578\n",
      "Baseline Loss: 3.6889 | Actual Loss: 1.6242\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.1576\n",
      "Baseline Loss: 3.5836 | Actual Loss: 1.0297\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.7085\n",
      "Baseline Loss: 3.9021 | Actual Loss: 2.6230\n",
      "Epoch 23/1000: Train Loss: 1.3222, Val Loss: 1.6297\n",
      "Baseline Loss: 3.5587 | Actual Loss: 1.3254\n",
      "Baseline Loss: 3.6097 | Actual Loss: 1.3616\n",
      "Baseline Loss: 3.3638 | Actual Loss: 1.1277\n",
      "Baseline Loss: 3.7785 | Actual Loss: 1.5769\n",
      "Baseline Loss: 3.2984 | Actual Loss: 1.3521\n",
      "Baseline Loss: 3.5171 | Actual Loss: 1.7133\n",
      "Baseline Loss: 3.5585 | Actual Loss: 1.2596\n",
      "Baseline Loss: 3.6038 | Actual Loss: 1.7828\n",
      "Baseline Loss: 3.3407 | Actual Loss: 1.1246\n",
      "Baseline Loss: 3.5207 | Actual Loss: 1.0693\n",
      "Baseline Loss: 3.3620 | Actual Loss: 2.4409\n",
      "Baseline Loss: 3.7121 | Actual Loss: 1.1995\n",
      "Baseline Loss: 3.3308 | Actual Loss: 1.1930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 24/1000 [00:11<07:48,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5053 | Actual Loss: 1.1127\n",
      "Baseline Loss: 3.5784 | Actual Loss: 1.8854\n",
      "Baseline Loss: 3.2887 | Actual Loss: 1.7994\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.2769\n",
      "Baseline Loss: 3.5836 | Actual Loss: 1.0597\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.4771\n",
      "Baseline Loss: 3.9021 | Actual Loss: 2.8989\n",
      "Epoch 24/1000: Train Loss: 1.4578, Val Loss: 1.6781\n",
      "Baseline Loss: 3.5168 | Actual Loss: 1.0610\n",
      "Baseline Loss: 3.6450 | Actual Loss: 0.7893\n",
      "Baseline Loss: 3.3781 | Actual Loss: 1.3339\n",
      "Baseline Loss: 3.4010 | Actual Loss: 1.3342\n",
      "Baseline Loss: 3.4107 | Actual Loss: 1.0502\n",
      "Baseline Loss: 3.6918 | Actual Loss: 2.2791\n",
      "Baseline Loss: 3.4701 | Actual Loss: 1.4773\n",
      "Baseline Loss: 3.5092 | Actual Loss: 1.4455\n",
      "Baseline Loss: 3.3643 | Actual Loss: 1.1349\n",
      "Baseline Loss: 3.4545 | Actual Loss: 1.7123\n",
      "Baseline Loss: 3.6459 | Actual Loss: 1.6424\n",
      "Baseline Loss: 3.5042 | Actual Loss: 1.5224\n",
      "Baseline Loss: 3.5537 | Actual Loss: 1.5094\n",
      "Baseline Loss: 3.4278 | Actual Loss: 1.0692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▎         | 25/1000 [00:11<07:22,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5338 | Actual Loss: 1.3201\n",
      "Baseline Loss: 3.3845 | Actual Loss: 1.1969\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.3138\n",
      "Baseline Loss: 3.5836 | Actual Loss: 1.0128\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.5086\n",
      "Baseline Loss: 3.9021 | Actual Loss: 2.7562\n",
      "Epoch 25/1000: Train Loss: 1.3674, Val Loss: 1.6478\n",
      "Baseline Loss: 3.3988 | Actual Loss: 1.4026\n",
      "Baseline Loss: 3.5163 | Actual Loss: 1.9443\n",
      "Baseline Loss: 3.3619 | Actual Loss: 1.4280\n",
      "Baseline Loss: 3.3250 | Actual Loss: 1.6195\n",
      "Baseline Loss: 3.3994 | Actual Loss: 1.5742\n",
      "Baseline Loss: 3.4318 | Actual Loss: 1.4910\n",
      "Baseline Loss: 3.4691 | Actual Loss: 1.4104\n",
      "Baseline Loss: 3.3275 | Actual Loss: 1.3253\n",
      "Baseline Loss: 3.5285 | Actual Loss: 1.0057\n",
      "Baseline Loss: 3.4475 | Actual Loss: 1.1932\n",
      "Baseline Loss: 3.6546 | Actual Loss: 1.1764\n",
      "Baseline Loss: 3.5612 | Actual Loss: 1.2995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 26/1000 [00:12<07:38,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5878 | Actual Loss: 2.6006\n",
      "Baseline Loss: 3.4702 | Actual Loss: 2.1199\n",
      "Baseline Loss: 3.4467 | Actual Loss: 1.5999\n",
      "Baseline Loss: 3.6056 | Actual Loss: 3.0533\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.3630\n",
      "Baseline Loss: 3.5836 | Actual Loss: 1.3708\n",
      "Baseline Loss: 3.5497 | Actual Loss: 2.6734\n",
      "Baseline Loss: 3.9021 | Actual Loss: 2.7062\n",
      "Epoch 26/1000: Train Loss: 1.6402, Val Loss: 2.0283\n",
      "Baseline Loss: 3.3023 | Actual Loss: 0.9843\n",
      "Baseline Loss: 3.5331 | Actual Loss: 0.8738\n",
      "Baseline Loss: 3.4969 | Actual Loss: 1.0352\n",
      "Baseline Loss: 3.8325 | Actual Loss: 1.4206\n",
      "Baseline Loss: 3.5425 | Actual Loss: 1.5974\n",
      "Baseline Loss: 3.4129 | Actual Loss: 1.3795\n",
      "Baseline Loss: 3.3412 | Actual Loss: 2.2175\n",
      "Baseline Loss: 3.5002 | Actual Loss: 1.0521\n",
      "Baseline Loss: 3.5456 | Actual Loss: 1.3429\n",
      "Baseline Loss: 3.6187 | Actual Loss: 1.2647\n",
      "Baseline Loss: 3.4969 | Actual Loss: 1.6186\n",
      "Baseline Loss: 3.2854 | Actual Loss: 1.9452\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.6557\n",
      "Baseline Loss: 3.5539 | Actual Loss: 0.7514\n",
      "Baseline Loss: 3.5053 | Actual Loss: 1.7375\n",
      "Baseline Loss: 3.5945 | Actual Loss: 0.7858\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.4594\n",
      "Baseline Loss: 3.5836 | Actual Loss: 1.1300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 27/1000 [00:12<07:45,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5497 | Actual Loss: 1.3908\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.0738\n",
      "Epoch 27/1000: Train Loss: 1.3539, Val Loss: 1.7635\n",
      "Baseline Loss: 3.4700 | Actual Loss: 1.4609\n",
      "Baseline Loss: 3.7170 | Actual Loss: 1.5494\n",
      "Baseline Loss: 3.4175 | Actual Loss: 1.5838\n",
      "Baseline Loss: 3.4622 | Actual Loss: 1.6771\n",
      "Baseline Loss: 3.4022 | Actual Loss: 1.1866\n",
      "Baseline Loss: 3.5540 | Actual Loss: 1.6022\n",
      "Baseline Loss: 3.3591 | Actual Loss: 1.0345\n",
      "Baseline Loss: 3.6000 | Actual Loss: 0.7624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 28/1000 [00:13<07:19,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5248 | Actual Loss: 1.5029\n",
      "Baseline Loss: 3.4061 | Actual Loss: 1.1008\n",
      "Baseline Loss: 3.4097 | Actual Loss: 0.9323\n",
      "Baseline Loss: 3.7317 | Actual Loss: 1.0861\n",
      "Baseline Loss: 3.1975 | Actual Loss: 1.3698\n",
      "Baseline Loss: 3.4763 | Actual Loss: 2.1196\n",
      "Baseline Loss: 3.5622 | Actual Loss: 0.8133\n",
      "Baseline Loss: 3.2731 | Actual Loss: 0.3488\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.1972\n",
      "Baseline Loss: 3.5836 | Actual Loss: 1.3773\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.7113\n",
      "Baseline Loss: 3.9021 | Actual Loss: 2.3588\n",
      "Epoch 28/1000: Train Loss: 1.2582, Val Loss: 1.6611\n",
      "Baseline Loss: 3.4396 | Actual Loss: 1.4055\n",
      "Baseline Loss: 3.8160 | Actual Loss: 2.1325\n",
      "Baseline Loss: 3.5580 | Actual Loss: 1.1810\n",
      "Baseline Loss: 3.2972 | Actual Loss: 1.1675\n",
      "Baseline Loss: 3.6223 | Actual Loss: 1.3912\n",
      "Baseline Loss: 3.5793 | Actual Loss: 2.7499\n",
      "Baseline Loss: 3.4537 | Actual Loss: 1.0861\n",
      "Baseline Loss: 3.4179 | Actual Loss: 0.8447\n",
      "Baseline Loss: 3.5010 | Actual Loss: 1.1058\n",
      "Baseline Loss: 3.5218 | Actual Loss: 1.3646\n",
      "Baseline Loss: 3.3753 | Actual Loss: 1.4408\n",
      "Baseline Loss: 3.2640 | Actual Loss: 1.0590\n",
      "Baseline Loss: 3.5626 | Actual Loss: 0.9844\n",
      "Baseline Loss: 3.3952 | Actual Loss: 0.8693\n",
      "Baseline Loss: 3.5126 | Actual Loss: 1.1554\n",
      "Baseline Loss: 3.0718 | Actual Loss: 1.3805\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.1251\n",
      "Baseline Loss: 3.5836 | Actual Loss: 1.0969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 29/1000 [00:13<07:20,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5497 | Actual Loss: 1.7082\n",
      "Baseline Loss: 3.9021 | Actual Loss: 2.7562\n",
      "Epoch 29/1000: Train Loss: 1.3324, Val Loss: 1.6716\n",
      "Baseline Loss: 3.3436 | Actual Loss: 0.9011\n",
      "Baseline Loss: 3.6044 | Actual Loss: 1.1081\n",
      "Baseline Loss: 3.5251 | Actual Loss: 1.0984\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.0074\n",
      "Baseline Loss: 3.6973 | Actual Loss: 1.4141\n",
      "Baseline Loss: 3.3563 | Actual Loss: 1.3775\n",
      "Baseline Loss: 3.5005 | Actual Loss: 1.2383\n",
      "Baseline Loss: 3.6007 | Actual Loss: 1.9430\n",
      "Baseline Loss: 3.2490 | Actual Loss: 1.5530\n",
      "Baseline Loss: 3.7219 | Actual Loss: 3.0414\n",
      "Baseline Loss: 3.4510 | Actual Loss: 1.3045\n",
      "Baseline Loss: 3.6190 | Actual Loss: 1.4669\n",
      "Baseline Loss: 3.5091 | Actual Loss: 1.7485\n",
      "Baseline Loss: 3.3538 | Actual Loss: 0.9842\n",
      "Baseline Loss: 3.4727 | Actual Loss: 1.2426\n",
      "Baseline Loss: 3.0573 | Actual Loss: 1.1738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 30/1000 [00:14<07:36,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6273 | Actual Loss: 1.3424\n",
      "Baseline Loss: 3.5836 | Actual Loss: 1.4898\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.7214\n",
      "Baseline Loss: 3.9021 | Actual Loss: 2.5193\n",
      "Epoch 30/1000: Train Loss: 1.4127, Val Loss: 1.7682\n",
      "Baseline Loss: 3.4548 | Actual Loss: 0.7986\n",
      "Baseline Loss: 3.3181 | Actual Loss: 1.3536\n",
      "Baseline Loss: 3.7577 | Actual Loss: 0.7127\n",
      "Baseline Loss: 3.3218 | Actual Loss: 1.8040\n",
      "Baseline Loss: 3.4777 | Actual Loss: 1.5897\n",
      "Baseline Loss: 3.5573 | Actual Loss: 1.7757\n",
      "Baseline Loss: 3.4288 | Actual Loss: 1.1311\n",
      "Baseline Loss: 3.5043 | Actual Loss: 1.4286\n",
      "Baseline Loss: 3.4506 | Actual Loss: 1.1585\n",
      "Baseline Loss: 3.8042 | Actual Loss: 1.0104\n",
      "Baseline Loss: 3.4773 | Actual Loss: 1.3181\n",
      "Baseline Loss: 3.2828 | Actual Loss: 1.2735\n",
      "Baseline Loss: 3.3996 | Actual Loss: 0.8868\n",
      "Baseline Loss: 3.5085 | Actual Loss: 1.1032\n",
      "Baseline Loss: 3.6014 | Actual Loss: 1.3922\n",
      "Baseline Loss: 3.3931 | Actual Loss: 0.6460\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.1768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 31/1000 [00:14<07:16,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5836 | Actual Loss: 0.7131\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.5929\n",
      "Baseline Loss: 3.9021 | Actual Loss: 2.4354\n",
      "Epoch 31/1000: Train Loss: 1.2114, Val Loss: 1.4795\n",
      "New best validation loss: 1.4795\n",
      "Baseline Loss: 3.3202 | Actual Loss: 1.3252\n",
      "Baseline Loss: 3.3442 | Actual Loss: 0.8018\n",
      "Baseline Loss: 3.5082 | Actual Loss: 1.7667\n",
      "Baseline Loss: 3.4929 | Actual Loss: 0.9335\n",
      "Baseline Loss: 3.3996 | Actual Loss: 1.5163\n",
      "Baseline Loss: 3.5367 | Actual Loss: 1.5715\n",
      "Baseline Loss: 3.6928 | Actual Loss: 1.3052\n",
      "Baseline Loss: 3.5534 | Actual Loss: 2.7272\n",
      "Baseline Loss: 3.5625 | Actual Loss: 1.1821\n",
      "Baseline Loss: 3.6883 | Actual Loss: 2.0090\n",
      "Baseline Loss: 3.2735 | Actual Loss: 1.1090\n",
      "Baseline Loss: 3.6008 | Actual Loss: 2.2027\n",
      "Baseline Loss: 3.4062 | Actual Loss: 1.0110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 32/1000 [00:14<07:14,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5053 | Actual Loss: 0.9924\n",
      "Baseline Loss: 3.7222 | Actual Loss: 1.1349\n",
      "Baseline Loss: 3.4024 | Actual Loss: 0.4852\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.0899\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.9316\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.7895\n",
      "Baseline Loss: 3.9021 | Actual Loss: 2.1944\n",
      "Epoch 32/1000: Train Loss: 1.3796, Val Loss: 1.5013\n",
      "Baseline Loss: 3.4206 | Actual Loss: 1.6061\n",
      "Baseline Loss: 3.3995 | Actual Loss: 0.9807\n",
      "Baseline Loss: 3.6007 | Actual Loss: 0.8468\n",
      "Baseline Loss: 3.5008 | Actual Loss: 0.9323\n",
      "Baseline Loss: 3.5122 | Actual Loss: 0.9441\n",
      "Baseline Loss: 3.6234 | Actual Loss: 0.8568\n",
      "Baseline Loss: 3.5334 | Actual Loss: 1.2636\n",
      "Baseline Loss: 3.5619 | Actual Loss: 2.8628\n",
      "Baseline Loss: 3.3852 | Actual Loss: 1.9138\n",
      "Baseline Loss: 3.3275 | Actual Loss: 1.4182\n",
      "Baseline Loss: 3.4967 | Actual Loss: 0.8450\n",
      "Baseline Loss: 3.3112 | Actual Loss: 1.1246\n",
      "Baseline Loss: 3.6314 | Actual Loss: 1.4429\n",
      "Baseline Loss: 3.5617 | Actual Loss: 1.5619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 33/1000 [00:15<07:08,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4250 | Actual Loss: 1.2779\n",
      "Baseline Loss: 3.6889 | Actual Loss: 0.4384\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.2127\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.7190\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.7255\n",
      "Baseline Loss: 3.9021 | Actual Loss: 2.7758\n",
      "Epoch 33/1000: Train Loss: 1.2698, Val Loss: 1.6082\n",
      "Baseline Loss: 3.4514 | Actual Loss: 1.8923\n",
      "Baseline Loss: 3.3856 | Actual Loss: 1.6895\n",
      "Baseline Loss: 3.5581 | Actual Loss: 1.0131\n",
      "Baseline Loss: 3.6454 | Actual Loss: 1.5589\n",
      "Baseline Loss: 3.5499 | Actual Loss: 1.8656\n",
      "Baseline Loss: 3.4256 | Actual Loss: 1.4702\n",
      "Baseline Loss: 3.4729 | Actual Loss: 1.3373\n",
      "Baseline Loss: 3.4879 | Actual Loss: 1.2963\n",
      "Baseline Loss: 3.4172 | Actual Loss: 1.1336\n",
      "Baseline Loss: 3.6502 | Actual Loss: 1.4603\n",
      "Baseline Loss: 3.4471 | Actual Loss: 1.1844\n",
      "Baseline Loss: 3.5578 | Actual Loss: 1.5441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 34/1000 [00:15<07:16,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5619 | Actual Loss: 1.0128\n",
      "Baseline Loss: 3.5055 | Actual Loss: 1.4392\n",
      "Baseline Loss: 3.4878 | Actual Loss: 0.7077\n",
      "Baseline Loss: 3.2038 | Actual Loss: 0.6080\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.2603\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.8890\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.4512\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.3130\n",
      "Epoch 34/1000: Train Loss: 1.3258, Val Loss: 1.7284\n",
      "Baseline Loss: 3.4685 | Actual Loss: 1.4739\n",
      "Baseline Loss: 3.3689 | Actual Loss: 1.6299\n",
      "Baseline Loss: 3.4387 | Actual Loss: 1.1271\n",
      "Baseline Loss: 3.6969 | Actual Loss: 1.7461\n",
      "Baseline Loss: 3.5260 | Actual Loss: 0.9505\n",
      "Baseline Loss: 3.4470 | Actual Loss: 1.4715\n",
      "Baseline Loss: 3.4970 | Actual Loss: 1.3367\n",
      "Baseline Loss: 3.4699 | Actual Loss: 1.2496\n",
      "Baseline Loss: 3.5619 | Actual Loss: 1.0530\n",
      "Baseline Loss: 3.5207 | Actual Loss: 1.0461\n",
      "Baseline Loss: 3.2605 | Actual Loss: 1.1938\n",
      "Baseline Loss: 3.4548 | Actual Loss: 0.8589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 35/1000 [00:16<07:34,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6099 | Actual Loss: 1.0572\n",
      "Baseline Loss: 3.5748 | Actual Loss: 0.7515\n",
      "Baseline Loss: 3.3892 | Actual Loss: 1.6911\n",
      "Baseline Loss: 3.2029 | Actual Loss: 0.7100\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.1864\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.7842\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.4442\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.4042\n",
      "Epoch 35/1000: Train Loss: 1.2092, Val Loss: 1.7047\n",
      "Baseline Loss: 3.6095 | Actual Loss: 1.9753\n",
      "Baseline Loss: 3.3857 | Actual Loss: 1.1448\n",
      "Baseline Loss: 3.5709 | Actual Loss: 1.4334\n",
      "Baseline Loss: 3.4585 | Actual Loss: 1.4838\n",
      "Baseline Loss: 3.5966 | Actual Loss: 1.3501\n",
      "Baseline Loss: 3.5751 | Actual Loss: 1.5487\n",
      "Baseline Loss: 3.4616 | Actual Loss: 1.2891\n",
      "Baseline Loss: 3.5331 | Actual Loss: 0.8154\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.9323\n",
      "Baseline Loss: 3.4245 | Actual Loss: 1.4724\n",
      "Baseline Loss: 3.5456 | Actual Loss: 1.1379\n",
      "Baseline Loss: 3.5379 | Actual Loss: 1.0698\n",
      "Baseline Loss: 3.5655 | Actual Loss: 1.1900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 36/1000 [00:16<07:16,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4396 | Actual Loss: 0.9364\n",
      "Baseline Loss: 3.5664 | Actual Loss: 1.2778\n",
      "Baseline Loss: 3.0645 | Actual Loss: 0.6822\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.0303\n",
      "Baseline Loss: 3.5836 | Actual Loss: 1.4684\n",
      "Baseline Loss: 3.5497 | Actual Loss: 2.9717\n",
      "Baseline Loss: 3.9021 | Actual Loss: 2.7465\n",
      "Epoch 36/1000: Train Loss: 1.2337, Val Loss: 2.0542\n",
      "Baseline Loss: 3.5488 | Actual Loss: 0.5494\n",
      "Baseline Loss: 3.6692 | Actual Loss: 1.4465\n",
      "Baseline Loss: 3.5707 | Actual Loss: 0.9928\n",
      "Baseline Loss: 3.5461 | Actual Loss: 1.5445\n",
      "Baseline Loss: 3.4426 | Actual Loss: 0.8481\n",
      "Baseline Loss: 3.5752 | Actual Loss: 0.5438\n",
      "Baseline Loss: 3.5966 | Actual Loss: 1.2725\n",
      "Baseline Loss: 3.5248 | Actual Loss: 1.2105\n",
      "Baseline Loss: 3.4924 | Actual Loss: 1.0988\n",
      "Baseline Loss: 3.3377 | Actual Loss: 1.0760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 37/1000 [00:17<07:19,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.2822 | Actual Loss: 1.1714\n",
      "Baseline Loss: 3.4108 | Actual Loss: 1.6424\n",
      "Baseline Loss: 3.5625 | Actual Loss: 1.8278\n",
      "Baseline Loss: 3.5332 | Actual Loss: 1.2273\n",
      "Baseline Loss: 3.2964 | Actual Loss: 1.0142\n",
      "Baseline Loss: 3.4210 | Actual Loss: 1.2317\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.2090\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.6803\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.4416\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.8902\n",
      "Epoch 37/1000: Train Loss: 1.1686, Val Loss: 1.8053\n",
      "Baseline Loss: 3.2597 | Actual Loss: 1.1177\n",
      "Baseline Loss: 3.4846 | Actual Loss: 1.1088\n",
      "Baseline Loss: 3.5179 | Actual Loss: 0.4311\n",
      "Baseline Loss: 3.4286 | Actual Loss: 1.3060\n",
      "Baseline Loss: 3.4103 | Actual Loss: 0.7089\n",
      "Baseline Loss: 3.3787 | Actual Loss: 1.1455\n",
      "Baseline Loss: 3.6181 | Actual Loss: 1.3424\n",
      "Baseline Loss: 3.5451 | Actual Loss: 1.3583\n",
      "Baseline Loss: 3.6185 | Actual Loss: 0.8825\n",
      "Baseline Loss: 3.5324 | Actual Loss: 1.3202\n",
      "Baseline Loss: 3.4616 | Actual Loss: 0.7889\n",
      "Baseline Loss: 3.4774 | Actual Loss: 1.0958\n",
      "Baseline Loss: 3.6458 | Actual Loss: 0.8349\n",
      "Baseline Loss: 3.5207 | Actual Loss: 3.7241\n",
      "Baseline Loss: 3.5083 | Actual Loss: 0.9300\n",
      "Baseline Loss: 3.5841 | Actual Loss: 1.4110\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.0753\n",
      "Baseline Loss: 3.5836 | Actual Loss: 1.1967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 38/1000 [00:17<07:37,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5497 | Actual Loss: 1.7268\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.4345\n",
      "Epoch 38/1000: Train Loss: 1.2191, Val Loss: 1.8583\n",
      "Baseline Loss: 3.6455 | Actual Loss: 0.8963\n",
      "Baseline Loss: 3.4585 | Actual Loss: 0.9240\n",
      "Baseline Loss: 3.3377 | Actual Loss: 0.9974\n",
      "Baseline Loss: 3.5794 | Actual Loss: 2.8635\n",
      "Baseline Loss: 3.5335 | Actual Loss: 1.4064\n",
      "Baseline Loss: 3.5535 | Actual Loss: 1.0063\n",
      "Baseline Loss: 3.3273 | Actual Loss: 1.2675\n",
      "Baseline Loss: 3.2105 | Actual Loss: 1.1396\n",
      "Baseline Loss: 3.4581 | Actual Loss: 1.4430\n",
      "Baseline Loss: 3.5535 | Actual Loss: 2.3678\n",
      "Baseline Loss: 3.5462 | Actual Loss: 1.3264\n",
      "Baseline Loss: 3.7218 | Actual Loss: 1.6892\n",
      "Baseline Loss: 3.5089 | Actual Loss: 0.8208\n",
      "Baseline Loss: 3.2822 | Actual Loss: 1.5428\n",
      "Baseline Loss: 3.3718 | Actual Loss: 1.5098\n",
      "Baseline Loss: 3.5835 | Actual Loss: 3.3233\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.2029\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.8537\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.5902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 39/1000 [00:18<07:41,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.9021 | Actual Loss: 2.0773\n",
      "Epoch 39/1000: Train Loss: 1.5328, Val Loss: 1.4310\n",
      "New best validation loss: 1.4310\n",
      "Baseline Loss: 3.5131 | Actual Loss: 1.3437\n",
      "Baseline Loss: 3.4177 | Actual Loss: 1.3971\n",
      "Baseline Loss: 3.3179 | Actual Loss: 1.3506\n",
      "Baseline Loss: 3.5379 | Actual Loss: 1.3126\n",
      "Baseline Loss: 3.4578 | Actual Loss: 1.3820\n",
      "Baseline Loss: 3.5838 | Actual Loss: 1.0459\n",
      "Baseline Loss: 3.6142 | Actual Loss: 1.1896\n",
      "Baseline Loss: 3.3281 | Actual Loss: 1.7198\n",
      "Baseline Loss: 3.5130 | Actual Loss: 0.7348\n",
      "Baseline Loss: 3.8373 | Actual Loss: 1.0784\n",
      "Baseline Loss: 3.4700 | Actual Loss: 1.4468\n",
      "Baseline Loss: 3.5795 | Actual Loss: 1.0281\n",
      "Baseline Loss: 3.4696 | Actual Loss: 1.2697\n",
      "Baseline Loss: 3.3820 | Actual Loss: 1.3897\n",
      "Baseline Loss: 3.5622 | Actual Loss: 1.2791\n",
      "Baseline Loss: 3.5408 | Actual Loss: 0.9506\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.1550\n",
      "Baseline Loss: 3.5836 | Actual Loss: 1.1965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 40/1000 [00:18<07:28,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5497 | Actual Loss: 1.3986\n",
      "Baseline Loss: 3.9021 | Actual Loss: 2.5608\n",
      "Epoch 40/1000: Train Loss: 1.2449, Val Loss: 1.5777\n",
      "Baseline Loss: 3.6270 | Actual Loss: 1.3807\n",
      "Baseline Loss: 3.6490 | Actual Loss: 0.8980\n",
      "Baseline Loss: 3.6735 | Actual Loss: 0.9213\n",
      "Baseline Loss: 3.4296 | Actual Loss: 1.3070\n",
      "Baseline Loss: 3.4656 | Actual Loss: 1.5553\n",
      "Baseline Loss: 3.7474 | Actual Loss: 1.0610\n",
      "Baseline Loss: 3.4817 | Actual Loss: 1.1024\n",
      "Baseline Loss: 3.5836 | Actual Loss: 1.1653\n",
      "Baseline Loss: 3.2856 | Actual Loss: 0.9920\n",
      "Baseline Loss: 3.5091 | Actual Loss: 0.9781\n",
      "Baseline Loss: 3.5620 | Actual Loss: 2.0302\n",
      "Baseline Loss: 3.4548 | Actual Loss: 1.1778\n",
      "Baseline Loss: 3.4815 | Actual Loss: 1.4035\n",
      "Baseline Loss: 3.2007 | Actual Loss: 2.9440\n",
      "Baseline Loss: 3.5875 | Actual Loss: 1.3876\n",
      "Baseline Loss: 3.1962 | Actual Loss: 1.8008\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.0728\n",
      "Baseline Loss: 3.5836 | Actual Loss: 1.2338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 41/1000 [00:19<07:27,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5497 | Actual Loss: 1.5534\n",
      "Baseline Loss: 3.9021 | Actual Loss: 2.7688\n",
      "Epoch 41/1000: Train Loss: 1.3816, Val Loss: 1.6572\n",
      "Baseline Loss: 3.4964 | Actual Loss: 1.0427\n",
      "Baseline Loss: 3.5456 | Actual Loss: 1.4428\n",
      "Baseline Loss: 3.4107 | Actual Loss: 1.1801\n",
      "Baseline Loss: 3.2830 | Actual Loss: 0.8288\n",
      "Baseline Loss: 3.5705 | Actual Loss: 1.4768\n",
      "Baseline Loss: 3.5209 | Actual Loss: 1.0452\n",
      "Baseline Loss: 3.6197 | Actual Loss: 1.1104\n",
      "Baseline Loss: 3.5051 | Actual Loss: 1.1006\n",
      "Baseline Loss: 3.6412 | Actual Loss: 2.0469\n",
      "Baseline Loss: 3.4961 | Actual Loss: 1.0141\n",
      "Baseline Loss: 3.5003 | Actual Loss: 0.6977\n",
      "Baseline Loss: 3.5924 | Actual Loss: 0.6159\n",
      "Baseline Loss: 3.4141 | Actual Loss: 1.3032\n",
      "Baseline Loss: 3.2296 | Actual Loss: 1.3458\n",
      "Baseline Loss: 3.5195 | Actual Loss: 1.4346\n",
      "Baseline Loss: 3.3760 | Actual Loss: 1.3641\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.2048\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.8805\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.2869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 42/1000 [00:19<07:05,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.9021 | Actual Loss: 2.8257\n",
      "Epoch 42/1000: Train Loss: 1.1906, Val Loss: 1.5495\n",
      "Baseline Loss: 3.7472 | Actual Loss: 3.4677\n",
      "Baseline Loss: 3.3405 | Actual Loss: 0.7608\n",
      "Baseline Loss: 3.5329 | Actual Loss: 1.2695\n",
      "Baseline Loss: 3.5962 | Actual Loss: 1.2404\n",
      "Baseline Loss: 3.6687 | Actual Loss: 1.6401\n",
      "Baseline Loss: 3.7220 | Actual Loss: 2.3524\n",
      "Baseline Loss: 3.5174 | Actual Loss: 1.5585\n",
      "Baseline Loss: 3.4354 | Actual Loss: 1.3516\n",
      "Baseline Loss: 3.4547 | Actual Loss: 1.1238\n",
      "Baseline Loss: 3.3640 | Actual Loss: 1.2578\n",
      "Baseline Loss: 3.3952 | Actual Loss: 0.8454\n",
      "Baseline Loss: 3.3857 | Actual Loss: 0.5410\n",
      "Baseline Loss: 3.5208 | Actual Loss: 1.3284\n",
      "Baseline Loss: 3.4145 | Actual Loss: 1.6857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 43/1000 [00:19<07:23,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.2938 | Actual Loss: 1.0052\n",
      "Baseline Loss: 3.3748 | Actual Loss: 1.2231\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.1360\n",
      "Baseline Loss: 3.5836 | Actual Loss: 1.2609\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.2334\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.5333\n",
      "Epoch 43/1000: Train Loss: 1.4157, Val Loss: 1.7909\n",
      "Baseline Loss: 3.3913 | Actual Loss: 0.7393\n",
      "Baseline Loss: 3.4475 | Actual Loss: 1.1016\n",
      "Baseline Loss: 3.6930 | Actual Loss: 0.7526\n",
      "Baseline Loss: 3.2574 | Actual Loss: 1.0026\n",
      "Baseline Loss: 3.4572 | Actual Loss: 1.0014\n",
      "Baseline Loss: 3.7122 | Actual Loss: 1.2190\n",
      "Baseline Loss: 3.3967 | Actual Loss: 1.0622\n",
      "Baseline Loss: 3.4254 | Actual Loss: 1.1638\n",
      "Baseline Loss: 3.5923 | Actual Loss: 2.1609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 44/1000 [00:20<07:36,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5948 | Actual Loss: 1.3870\n",
      "Baseline Loss: 3.3928 | Actual Loss: 1.6959\n",
      "Baseline Loss: 3.5539 | Actual Loss: 1.1539\n",
      "Baseline Loss: 3.3929 | Actual Loss: 1.0074\n",
      "Baseline Loss: 3.4932 | Actual Loss: 1.1947\n",
      "Baseline Loss: 3.5538 | Actual Loss: 1.0501\n",
      "Baseline Loss: 3.2662 | Actual Loss: 1.0124\n",
      "Baseline Loss: 3.6273 | Actual Loss: 0.9466\n",
      "Baseline Loss: 3.5836 | Actual Loss: 1.0407\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.3653\n",
      "Baseline Loss: 3.9021 | Actual Loss: 2.4173\n",
      "Epoch 44/1000: Train Loss: 1.1691, Val Loss: 1.4425\n",
      "Baseline Loss: 3.5575 | Actual Loss: 1.1786\n",
      "Baseline Loss: 3.4926 | Actual Loss: 1.2095\n",
      "Baseline Loss: 3.4470 | Actual Loss: 1.6573\n",
      "Baseline Loss: 3.4974 | Actual Loss: 0.9098\n",
      "Baseline Loss: 3.5255 | Actual Loss: 1.2249\n",
      "Baseline Loss: 3.3751 | Actual Loss: 0.9486\n",
      "Baseline Loss: 3.3964 | Actual Loss: 1.3955\n",
      "Baseline Loss: 3.6270 | Actual Loss: 0.8201\n",
      "Baseline Loss: 3.6451 | Actual Loss: 0.7870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 45/1000 [00:20<07:23,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3573 | Actual Loss: 3.0538\n",
      "Baseline Loss: 3.4251 | Actual Loss: 1.5053\n",
      "Baseline Loss: 3.5128 | Actual Loss: 0.9462\n",
      "Baseline Loss: 3.6099 | Actual Loss: 1.2586\n",
      "Baseline Loss: 3.4972 | Actual Loss: 0.7752\n",
      "Baseline Loss: 3.4514 | Actual Loss: 1.0853\n",
      "Baseline Loss: 3.4018 | Actual Loss: 2.5440\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.2188\n",
      "Baseline Loss: 3.5836 | Actual Loss: 1.1251\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.3790\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.5432\n",
      "Epoch 45/1000: Train Loss: 1.3312, Val Loss: 1.8165\n",
      "Baseline Loss: 3.4659 | Actual Loss: 1.3549\n",
      "Baseline Loss: 3.6324 | Actual Loss: 0.9367\n",
      "Baseline Loss: 3.4736 | Actual Loss: 1.0931\n",
      "Baseline Loss: 3.4240 | Actual Loss: 1.2689\n",
      "Baseline Loss: 3.4776 | Actual Loss: 1.0346\n",
      "Baseline Loss: 3.2481 | Actual Loss: 1.0981\n",
      "Baseline Loss: 3.7120 | Actual Loss: 1.6064\n",
      "Baseline Loss: 3.4777 | Actual Loss: 1.4418\n",
      "Baseline Loss: 3.4735 | Actual Loss: 0.8234\n",
      "Baseline Loss: 3.5787 | Actual Loss: 1.1314\n",
      "Baseline Loss: 3.4769 | Actual Loss: 1.0989\n",
      "Baseline Loss: 3.5617 | Actual Loss: 0.8738\n",
      "Baseline Loss: 3.6556 | Actual Loss: 0.6818\n",
      "Baseline Loss: 3.3170 | Actual Loss: 1.2274\n",
      "Baseline Loss: 3.4545 | Actual Loss: 0.7438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 46/1000 [00:21<07:33,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.1114 | Actual Loss: 1.8295\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.3988\n",
      "Baseline Loss: 3.5836 | Actual Loss: 1.4078\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.7616\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.9666\n",
      "Epoch 46/1000: Train Loss: 1.1403, Val Loss: 2.1337\n",
      "Baseline Loss: 3.3616 | Actual Loss: 1.6627\n",
      "Baseline Loss: 3.4171 | Actual Loss: 0.6001\n",
      "Baseline Loss: 3.5410 | Actual Loss: 2.3567\n",
      "Baseline Loss: 3.5530 | Actual Loss: 1.1104\n",
      "Baseline Loss: 3.3857 | Actual Loss: 0.5790\n",
      "Baseline Loss: 3.4693 | Actual Loss: 1.5606\n",
      "Baseline Loss: 3.5701 | Actual Loss: 0.9172\n",
      "Baseline Loss: 3.5578 | Actual Loss: 2.3718\n",
      "Baseline Loss: 3.4702 | Actual Loss: 1.5025\n",
      "Baseline Loss: 3.3444 | Actual Loss: 1.1213\n",
      "Baseline Loss: 3.5095 | Actual Loss: 1.4036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 47/1000 [00:21<07:45,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5537 | Actual Loss: 1.0222\n",
      "Baseline Loss: 3.6141 | Actual Loss: 1.2296\n",
      "Baseline Loss: 3.6182 | Actual Loss: 1.0512\n",
      "Baseline Loss: 3.4881 | Actual Loss: 0.8463\n",
      "Baseline Loss: 3.4204 | Actual Loss: 0.5257\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.0790\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.9073\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.3022\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.3954\n",
      "Epoch 47/1000: Train Loss: 1.2413, Val Loss: 1.6710\n",
      "Baseline Loss: 3.5014 | Actual Loss: 1.0418\n",
      "Baseline Loss: 3.5834 | Actual Loss: 1.0190\n",
      "Baseline Loss: 3.3503 | Actual Loss: 1.6247\n",
      "Baseline Loss: 3.3891 | Actual Loss: 1.2459\n",
      "Baseline Loss: 3.5360 | Actual Loss: 0.9686\n",
      "Baseline Loss: 3.5877 | Actual Loss: 1.0334\n",
      "Baseline Loss: 3.4068 | Actual Loss: 1.4251\n",
      "Baseline Loss: 3.4970 | Actual Loss: 1.2615\n",
      "Baseline Loss: 3.5119 | Actual Loss: 1.7253\n",
      "Baseline Loss: 3.3640 | Actual Loss: 1.3092\n",
      "Baseline Loss: 3.4810 | Actual Loss: 1.2076\n",
      "Baseline Loss: 3.4699 | Actual Loss: 1.2998\n",
      "Baseline Loss: 3.3340 | Actual Loss: 1.3853\n",
      "Baseline Loss: 3.5332 | Actual Loss: 1.1762\n",
      "Baseline Loss: 3.5447 | Actual Loss: 1.3862\n",
      "Baseline Loss: 3.5948 | Actual Loss: 0.3851\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.1452\n",
      "Baseline Loss: 3.5836 | Actual Loss: 1.0024\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.2394\n",
      "Baseline Loss: 3.9021 | Actual Loss: 2.0285\n",
      "Epoch 48/1000: Train Loss: 1.2184, Val Loss: 1.3539\n",
      "New best validation loss: 1.3539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 48/1000 [00:22<07:48,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6234 | Actual Loss: 1.5673\n",
      "Baseline Loss: 3.5619 | Actual Loss: 1.4195\n",
      "Baseline Loss: 3.5584 | Actual Loss: 0.8660\n",
      "Baseline Loss: 3.2665 | Actual Loss: 0.8952\n",
      "Baseline Loss: 3.4854 | Actual Loss: 1.2979\n",
      "Baseline Loss: 3.5709 | Actual Loss: 1.0001\n",
      "Baseline Loss: 3.6093 | Actual Loss: 0.9894\n",
      "Baseline Loss: 3.3615 | Actual Loss: 1.2580\n",
      "Baseline Loss: 3.6005 | Actual Loss: 1.4620\n",
      "Baseline Loss: 3.3310 | Actual Loss: 1.0469\n",
      "Baseline Loss: 3.2609 | Actual Loss: 1.4848\n",
      "Baseline Loss: 3.4500 | Actual Loss: 1.1807\n",
      "Baseline Loss: 3.5705 | Actual Loss: 0.4826\n",
      "Baseline Loss: 3.5408 | Actual Loss: 0.7199\n",
      "Baseline Loss: 3.4853 | Actual Loss: 1.2975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 49/1000 [00:22<07:54,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3922 | Actual Loss: 1.8231\n",
      "Baseline Loss: 3.6273 | Actual Loss: 0.9682\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.9155\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.1741\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.9158\n",
      "Epoch 49/1000: Train Loss: 1.1744, Val Loss: 1.7434\n",
      "Baseline Loss: 3.3925 | Actual Loss: 1.5851\n",
      "Baseline Loss: 3.4890 | Actual Loss: 0.9653\n",
      "Baseline Loss: 3.5366 | Actual Loss: 0.9777\n",
      "Baseline Loss: 3.4321 | Actual Loss: 1.6353\n",
      "Baseline Loss: 3.5500 | Actual Loss: 0.7622\n",
      "Baseline Loss: 3.4967 | Actual Loss: 0.8990\n",
      "Baseline Loss: 3.5126 | Actual Loss: 1.1498\n",
      "Baseline Loss: 3.3578 | Actual Loss: 1.1262\n",
      "Baseline Loss: 3.6011 | Actual Loss: 0.8942\n",
      "Baseline Loss: 3.5620 | Actual Loss: 0.8534\n",
      "Baseline Loss: 3.4429 | Actual Loss: 1.3200\n",
      "Baseline Loss: 3.7025 | Actual Loss: 1.0116\n",
      "Baseline Loss: 3.5581 | Actual Loss: 1.8279\n",
      "Baseline Loss: 3.5333 | Actual Loss: 1.1117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 50/1000 [00:23<07:54,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4243 | Actual Loss: 2.7149\n",
      "Baseline Loss: 3.2173 | Actual Loss: 0.2544\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.1324\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.8151\n",
      "Baseline Loss: 3.5497 | Actual Loss: 0.9914\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.8977\n",
      "Epoch 50/1000: Train Loss: 1.1931, Val Loss: 1.7092\n",
      "Baseline Loss: 3.3384 | Actual Loss: 0.9777\n",
      "Baseline Loss: 3.3926 | Actual Loss: 0.5659\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.5601\n",
      "Baseline Loss: 3.4964 | Actual Loss: 0.9951\n",
      "Baseline Loss: 3.5574 | Actual Loss: 0.6778\n",
      "Baseline Loss: 3.4020 | Actual Loss: 1.5767\n",
      "Baseline Loss: 3.3822 | Actual Loss: 1.3788\n",
      "Baseline Loss: 3.6739 | Actual Loss: 1.0780\n",
      "Baseline Loss: 3.5794 | Actual Loss: 0.6735\n",
      "Baseline Loss: 3.4768 | Actual Loss: 1.0968\n",
      "Baseline Loss: 3.4392 | Actual Loss: 1.2332\n",
      "Baseline Loss: 3.4904 | Actual Loss: 1.1585\n",
      "Baseline Loss: 3.3649 | Actual Loss: 1.2376\n",
      "Baseline Loss: 3.4703 | Actual Loss: 1.1452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 51/1000 [00:23<07:25,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5368 | Actual Loss: 0.6356\n",
      "Baseline Loss: 3.2646 | Actual Loss: 0.4469\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.0622\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.7656\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.2233\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.7226\n",
      "Epoch 51/1000: Train Loss: 0.9648, Val Loss: 1.6934\n",
      "Baseline Loss: 3.6460 | Actual Loss: 1.5363\n",
      "Baseline Loss: 3.4695 | Actual Loss: 2.9590\n",
      "Baseline Loss: 3.3386 | Actual Loss: 0.8089\n",
      "Baseline Loss: 3.6140 | Actual Loss: 2.0676\n",
      "Baseline Loss: 3.7121 | Actual Loss: 2.0526\n",
      "Baseline Loss: 3.5196 | Actual Loss: 1.0393\n",
      "Baseline Loss: 3.5039 | Actual Loss: 1.5080\n",
      "Baseline Loss: 3.6405 | Actual Loss: 0.9897\n",
      "Baseline Loss: 3.5587 | Actual Loss: 1.3594\n",
      "Baseline Loss: 3.4065 | Actual Loss: 1.0023\n",
      "Baseline Loss: 3.4063 | Actual Loss: 0.7378\n",
      "Baseline Loss: 3.2668 | Actual Loss: 0.6013\n",
      "Baseline Loss: 3.4547 | Actual Loss: 1.4621\n",
      "Baseline Loss: 3.6407 | Actual Loss: 1.3251\n",
      "Baseline Loss: 3.3168 | Actual Loss: 1.1291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 52/1000 [00:24<07:29,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5513 | Actual Loss: 0.4737\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.0888\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.9058\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.2560\n",
      "Baseline Loss: 3.9021 | Actual Loss: 2.8350\n",
      "Epoch 52/1000: Train Loss: 1.3158, Val Loss: 1.5214\n",
      "Baseline Loss: 3.6319 | Actual Loss: 1.5332\n",
      "Baseline Loss: 3.6503 | Actual Loss: 0.9311\n",
      "Baseline Loss: 3.5666 | Actual Loss: 0.7019\n",
      "Baseline Loss: 3.5743 | Actual Loss: 0.7064\n",
      "Baseline Loss: 3.6228 | Actual Loss: 0.5280\n",
      "Baseline Loss: 3.4774 | Actual Loss: 0.6950\n",
      "Baseline Loss: 3.6058 | Actual Loss: 1.3397\n",
      "Baseline Loss: 3.3959 | Actual Loss: 1.8342\n",
      "Baseline Loss: 3.5618 | Actual Loss: 0.8592\n",
      "Baseline Loss: 3.7570 | Actual Loss: 3.0013\n",
      "Baseline Loss: 3.3854 | Actual Loss: 0.7961\n",
      "Baseline Loss: 3.3684 | Actual Loss: 1.3029\n",
      "Baseline Loss: 3.3442 | Actual Loss: 1.7104\n",
      "Baseline Loss: 3.4102 | Actual Loss: 1.5424\n",
      "Baseline Loss: 3.4617 | Actual Loss: 1.2222\n",
      "Baseline Loss: 3.1455 | Actual Loss: 0.6130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 53/1000 [00:24<07:34,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6273 | Actual Loss: 1.1272\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.9776\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.2830\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.0798\n",
      "Epoch 53/1000: Train Loss: 1.2073, Val Loss: 1.6169\n",
      "Baseline Loss: 3.4430 | Actual Loss: 1.3207\n",
      "Baseline Loss: 3.5662 | Actual Loss: 1.0408\n",
      "Baseline Loss: 3.6411 | Actual Loss: 1.0024\n",
      "Baseline Loss: 3.4659 | Actual Loss: 1.2689\n",
      "Baseline Loss: 3.5623 | Actual Loss: 0.9579\n",
      "Baseline Loss: 3.3298 | Actual Loss: 1.4437\n",
      "Baseline Loss: 3.5206 | Actual Loss: 0.8930\n",
      "Baseline Loss: 3.4063 | Actual Loss: 1.6453\n",
      "Baseline Loss: 3.3824 | Actual Loss: 0.9730\n",
      "Baseline Loss: 3.4937 | Actual Loss: 1.4693\n",
      "Baseline Loss: 3.5789 | Actual Loss: 1.2892\n",
      "Baseline Loss: 3.4967 | Actual Loss: 0.8619\n",
      "Baseline Loss: 3.4287 | Actual Loss: 0.8270\n",
      "Baseline Loss: 3.4034 | Actual Loss: 1.2700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 54/1000 [00:25<07:11,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7617 | Actual Loss: 0.3703\n",
      "Baseline Loss: 3.3565 | Actual Loss: 0.9010\n",
      "Baseline Loss: 3.6273 | Actual Loss: 0.9723\n",
      "Baseline Loss: 3.5836 | Actual Loss: 1.0880\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.1434\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.4654\n",
      "Epoch 54/1000: Train Loss: 1.0959, Val Loss: 1.6673\n",
      "Baseline Loss: 3.7170 | Actual Loss: 1.1528\n",
      "Baseline Loss: 3.8267 | Actual Loss: 1.3483\n",
      "Baseline Loss: 3.4031 | Actual Loss: 1.0500\n",
      "Baseline Loss: 3.3118 | Actual Loss: 1.0776\n",
      "Baseline Loss: 3.5579 | Actual Loss: 0.8907\n",
      "Baseline Loss: 3.6686 | Actual Loss: 3.1341\n",
      "Baseline Loss: 3.4666 | Actual Loss: 1.4320\n",
      "Baseline Loss: 3.5579 | Actual Loss: 1.8347\n",
      "Baseline Loss: 3.3694 | Actual Loss: 1.1587\n",
      "Baseline Loss: 3.5047 | Actual Loss: 0.7379\n",
      "Baseline Loss: 3.5716 | Actual Loss: 0.5566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 55/1000 [00:25<07:20,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4177 | Actual Loss: 1.9699\n",
      "Baseline Loss: 3.5050 | Actual Loss: 1.7744\n",
      "Baseline Loss: 3.3480 | Actual Loss: 0.8836\n",
      "Baseline Loss: 3.3574 | Actual Loss: 0.9362\n",
      "Baseline Loss: 3.3153 | Actual Loss: 0.7046\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.0642\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.7716\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.2111\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.2419\n",
      "Epoch 55/1000: Train Loss: 1.2901, Val Loss: 1.5722\n",
      "Baseline Loss: 3.5055 | Actual Loss: 1.0576\n",
      "Baseline Loss: 3.5743 | Actual Loss: 1.3321\n",
      "Baseline Loss: 3.3182 | Actual Loss: 1.2723\n",
      "Baseline Loss: 3.3081 | Actual Loss: 0.7552\n",
      "Baseline Loss: 3.4327 | Actual Loss: 0.9632\n",
      "Baseline Loss: 3.4888 | Actual Loss: 4.0979\n",
      "Baseline Loss: 3.6274 | Actual Loss: 0.6983\n",
      "Baseline Loss: 3.5539 | Actual Loss: 1.1641\n",
      "Baseline Loss: 3.4883 | Actual Loss: 1.2322\n",
      "Baseline Loss: 3.4358 | Actual Loss: 0.9552\n",
      "Baseline Loss: 3.6363 | Actual Loss: 1.3529\n",
      "Baseline Loss: 3.5532 | Actual Loss: 1.2669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 56/1000 [00:26<07:04,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6410 | Actual Loss: 2.9039\n",
      "Baseline Loss: 3.5753 | Actual Loss: 1.1759\n",
      "Baseline Loss: 3.5058 | Actual Loss: 1.0847\n",
      "Baseline Loss: 3.1392 | Actual Loss: 1.1401\n",
      "Baseline Loss: 3.6273 | Actual Loss: 0.9100\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.6442\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.3379\n",
      "Baseline Loss: 3.9021 | Actual Loss: 4.1242\n",
      "Epoch 56/1000: Train Loss: 1.4033, Val Loss: 1.7541\n",
      "Baseline Loss: 3.4178 | Actual Loss: 0.7690\n",
      "Baseline Loss: 3.5745 | Actual Loss: 0.9261\n",
      "Baseline Loss: 3.3569 | Actual Loss: 0.9532\n",
      "Baseline Loss: 3.8722 | Actual Loss: 1.2301\n",
      "Baseline Loss: 3.3793 | Actual Loss: 0.9249\n",
      "Baseline Loss: 3.4421 | Actual Loss: 0.9266\n",
      "Baseline Loss: 3.6054 | Actual Loss: 1.0902\n",
      "Baseline Loss: 3.4135 | Actual Loss: 1.1070\n",
      "Baseline Loss: 3.3504 | Actual Loss: 1.6919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 57/1000 [00:26<07:15,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5160 | Actual Loss: 0.6716\n",
      "Baseline Loss: 3.3749 | Actual Loss: 0.9779\n",
      "Baseline Loss: 3.5741 | Actual Loss: 0.9466\n",
      "Baseline Loss: 3.6228 | Actual Loss: 0.7746\n",
      "Baseline Loss: 3.5137 | Actual Loss: 0.9582\n",
      "Baseline Loss: 3.6737 | Actual Loss: 1.8219\n",
      "Baseline Loss: 3.2575 | Actual Loss: 0.9246\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.0743\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.7639\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.1841\n",
      "Baseline Loss: 3.9021 | Actual Loss: 2.6378\n",
      "Epoch 57/1000: Train Loss: 1.0434, Val Loss: 1.4150\n",
      "Baseline Loss: 3.4659 | Actual Loss: 1.1017\n",
      "Baseline Loss: 3.4925 | Actual Loss: 0.9691\n",
      "Baseline Loss: 3.4771 | Actual Loss: 0.8188\n",
      "Baseline Loss: 3.6271 | Actual Loss: 0.7351\n",
      "Baseline Loss: 3.4035 | Actual Loss: 1.3151\n",
      "Baseline Loss: 3.4471 | Actual Loss: 1.4602\n",
      "Baseline Loss: 3.5787 | Actual Loss: 2.5254\n",
      "Baseline Loss: 3.4846 | Actual Loss: 1.1033\n",
      "Baseline Loss: 3.4030 | Actual Loss: 0.7158\n",
      "Baseline Loss: 3.7519 | Actual Loss: 1.4741\n",
      "Baseline Loss: 3.4852 | Actual Loss: 0.7619\n",
      "Baseline Loss: 3.4825 | Actual Loss: 1.1657\n",
      "Baseline Loss: 3.4506 | Actual Loss: 0.6610\n",
      "Baseline Loss: 3.4357 | Actual Loss: 1.4446\n",
      "Baseline Loss: 3.5292 | Actual Loss: 1.4663\n",
      "Baseline Loss: 3.0019 | Actual Loss: 0.9393\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.0821\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.7558\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.0642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 58/1000 [00:27<07:24,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.9021 | Actual Loss: 3.2075\n",
      "Epoch 58/1000: Train Loss: 1.1661, Val Loss: 1.5274\n",
      "Baseline Loss: 3.4363 | Actual Loss: 0.8512\n",
      "Baseline Loss: 3.5918 | Actual Loss: 2.1982\n",
      "Baseline Loss: 3.3446 | Actual Loss: 0.9900\n",
      "Baseline Loss: 3.6136 | Actual Loss: 1.2345\n",
      "Baseline Loss: 3.4464 | Actual Loss: 1.3982\n",
      "Baseline Loss: 3.2368 | Actual Loss: 1.1049\n",
      "Baseline Loss: 3.6407 | Actual Loss: 1.2750\n",
      "Baseline Loss: 3.4930 | Actual Loss: 1.0356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 59/1000 [00:27<07:04,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3887 | Actual Loss: 0.9074\n",
      "Baseline Loss: 3.8151 | Actual Loss: 0.9367\n",
      "Baseline Loss: 3.6279 | Actual Loss: 1.1815\n",
      "Baseline Loss: 3.8208 | Actual Loss: 2.0764\n",
      "Baseline Loss: 3.6369 | Actual Loss: 0.8595\n",
      "Baseline Loss: 3.3508 | Actual Loss: 0.8323\n",
      "Baseline Loss: 3.4920 | Actual Loss: 1.3336\n",
      "Baseline Loss: 3.2186 | Actual Loss: 0.5025\n",
      "Baseline Loss: 3.6273 | Actual Loss: 0.9504\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.6346\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.3156\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.4198\n",
      "Epoch 59/1000: Train Loss: 1.1698, Val Loss: 1.5801\n",
      "Baseline Loss: 3.4696 | Actual Loss: 0.8589\n",
      "Baseline Loss: 3.6504 | Actual Loss: 1.1291\n",
      "Baseline Loss: 3.5045 | Actual Loss: 1.0619\n",
      "Baseline Loss: 3.8000 | Actual Loss: 3.2320\n",
      "Baseline Loss: 3.4512 | Actual Loss: 0.7295\n",
      "Baseline Loss: 3.4275 | Actual Loss: 1.2656\n",
      "Baseline Loss: 3.2878 | Actual Loss: 0.6749\n",
      "Baseline Loss: 3.6692 | Actual Loss: 1.2158\n",
      "Baseline Loss: 3.5833 | Actual Loss: 0.9704\n",
      "Baseline Loss: 3.4029 | Actual Loss: 3.2271\n",
      "Baseline Loss: 3.4810 | Actual Loss: 1.2581\n",
      "Baseline Loss: 3.4657 | Actual Loss: 0.9554\n",
      "Baseline Loss: 3.3889 | Actual Loss: 0.9555\n",
      "Baseline Loss: 3.6230 | Actual Loss: 1.0353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 60/1000 [00:28<07:22,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5014 | Actual Loss: 0.7734\n",
      "Baseline Loss: 3.2737 | Actual Loss: 1.0095\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.1617\n",
      "Baseline Loss: 3.5836 | Actual Loss: 1.8558\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.5991\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.8896\n",
      "Epoch 60/1000: Train Loss: 1.2720, Val Loss: 2.1265\n",
      "Baseline Loss: 3.5130 | Actual Loss: 0.9423\n",
      "Baseline Loss: 3.7679 | Actual Loss: 1.5540\n",
      "Baseline Loss: 3.5448 | Actual Loss: 1.3852\n",
      "Baseline Loss: 3.6279 | Actual Loss: 0.9571\n",
      "Baseline Loss: 3.5326 | Actual Loss: 0.7158\n",
      "Baseline Loss: 3.6049 | Actual Loss: 1.4670\n",
      "Baseline Loss: 3.4443 | Actual Loss: 1.5346\n",
      "Baseline Loss: 3.3509 | Actual Loss: 0.9372\n",
      "Baseline Loss: 3.3401 | Actual Loss: 1.0042\n",
      "Baseline Loss: 3.4896 | Actual Loss: 1.5680\n",
      "Baseline Loss: 3.3741 | Actual Loss: 1.0960\n",
      "Baseline Loss: 3.5461 | Actual Loss: 1.0393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 61/1000 [00:28<07:21,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4140 | Actual Loss: 0.6397\n",
      "Baseline Loss: 3.4814 | Actual Loss: 1.2785\n",
      "Baseline Loss: 3.6454 | Actual Loss: 2.6016\n",
      "Baseline Loss: 3.2179 | Actual Loss: 1.6663\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.0826\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.7748\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.1294\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.3764\n",
      "Epoch 61/1000: Train Loss: 1.2742, Val Loss: 1.5908\n",
      "Baseline Loss: 3.5749 | Actual Loss: 0.7776\n",
      "Baseline Loss: 3.5048 | Actual Loss: 0.7392\n",
      "Baseline Loss: 3.5697 | Actual Loss: 0.9547\n",
      "Baseline Loss: 3.3646 | Actual Loss: 2.9104\n",
      "Baseline Loss: 3.4929 | Actual Loss: 0.8621\n",
      "Baseline Loss: 3.6185 | Actual Loss: 1.6149\n",
      "Baseline Loss: 3.6273 | Actual Loss: 0.9447\n",
      "Baseline Loss: 3.4587 | Actual Loss: 0.9469\n",
      "Baseline Loss: 3.5382 | Actual Loss: 0.9172\n",
      "Baseline Loss: 3.6179 | Actual Loss: 0.9103\n",
      "Baseline Loss: 3.3440 | Actual Loss: 1.0626\n",
      "Baseline Loss: 3.5010 | Actual Loss: 1.2140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 62/1000 [00:28<06:56,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5417 | Actual Loss: 1.2354\n",
      "Baseline Loss: 3.3720 | Actual Loss: 0.7105\n",
      "Baseline Loss: 3.3680 | Actual Loss: 1.8034\n",
      "Baseline Loss: 3.1673 | Actual Loss: 2.8594\n",
      "Baseline Loss: 3.6273 | Actual Loss: 0.9534\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.9727\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.3251\n",
      "Baseline Loss: 3.9021 | Actual Loss: 4.0712\n",
      "Epoch 62/1000: Train Loss: 1.2790, Val Loss: 1.8306\n",
      "Baseline Loss: 3.4247 | Actual Loss: 0.6345\n",
      "Baseline Loss: 3.4033 | Actual Loss: 1.0130\n",
      "Baseline Loss: 3.4137 | Actual Loss: 2.0403\n",
      "Baseline Loss: 3.5085 | Actual Loss: 1.8353\n",
      "Baseline Loss: 3.4545 | Actual Loss: 0.9507\n",
      "Baseline Loss: 3.5333 | Actual Loss: 1.6622\n",
      "Baseline Loss: 3.5324 | Actual Loss: 1.2723\n",
      "Baseline Loss: 3.3540 | Actual Loss: 0.9803\n",
      "Baseline Loss: 3.6493 | Actual Loss: 1.3697\n",
      "Baseline Loss: 3.4810 | Actual Loss: 0.5984\n",
      "Baseline Loss: 3.5414 | Actual Loss: 1.0399\n",
      "Baseline Loss: 3.6186 | Actual Loss: 0.6130\n",
      "Baseline Loss: 3.5422 | Actual Loss: 1.3167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 63/1000 [00:29<07:20,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5999 | Actual Loss: 0.9992\n",
      "Baseline Loss: 3.5248 | Actual Loss: 0.9512\n",
      "Baseline Loss: 3.1821 | Actual Loss: 1.2610\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.1119\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.6411\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.0610\n",
      "Baseline Loss: 3.9021 | Actual Loss: 2.8495\n",
      "Epoch 63/1000: Train Loss: 1.1586, Val Loss: 1.4158\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.0325\n",
      "Baseline Loss: 3.4202 | Actual Loss: 1.0328\n",
      "Baseline Loss: 3.5214 | Actual Loss: 0.7687\n",
      "Baseline Loss: 3.5457 | Actual Loss: 1.2650\n",
      "Baseline Loss: 3.5337 | Actual Loss: 0.9940\n",
      "Baseline Loss: 3.4901 | Actual Loss: 0.6825\n",
      "Baseline Loss: 3.4432 | Actual Loss: 4.2818\n",
      "Baseline Loss: 3.5617 | Actual Loss: 2.0912\n",
      "Baseline Loss: 3.5081 | Actual Loss: 0.6278\n",
      "Baseline Loss: 3.5530 | Actual Loss: 3.3242\n",
      "Baseline Loss: 3.4854 | Actual Loss: 0.8990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 64/1000 [00:29<07:21,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6091 | Actual Loss: 1.6284\n",
      "Baseline Loss: 3.3666 | Actual Loss: 3.2082\n",
      "Baseline Loss: 3.5451 | Actual Loss: 1.3910\n",
      "Baseline Loss: 3.5293 | Actual Loss: 2.2290\n",
      "Baseline Loss: 3.2210 | Actual Loss: 1.3472\n",
      "Baseline Loss: 3.6273 | Actual Loss: 0.9609\n",
      "Baseline Loss: 3.5836 | Actual Loss: 1.0979\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.2672\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.3675\n",
      "Epoch 64/1000: Train Loss: 1.6752, Val Loss: 1.6734\n",
      "Baseline Loss: 3.4887 | Actual Loss: 0.8504\n",
      "Baseline Loss: 3.5420 | Actual Loss: 1.3102\n",
      "Baseline Loss: 3.5914 | Actual Loss: 0.9343\n",
      "Baseline Loss: 3.3422 | Actual Loss: 1.3216\n",
      "Baseline Loss: 3.5834 | Actual Loss: 0.6428\n",
      "Baseline Loss: 3.3383 | Actual Loss: 0.8119\n",
      "Baseline Loss: 3.4321 | Actual Loss: 1.1988\n",
      "Baseline Loss: 3.5317 | Actual Loss: 0.9472\n",
      "Baseline Loss: 3.5919 | Actual Loss: 1.5158\n",
      "Baseline Loss: 3.5655 | Actual Loss: 1.5337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 65/1000 [00:30<07:04,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7368 | Actual Loss: 2.8394\n",
      "Baseline Loss: 3.5658 | Actual Loss: 1.1814\n",
      "Baseline Loss: 3.6450 | Actual Loss: 1.3498\n",
      "Baseline Loss: 3.2897 | Actual Loss: 1.0667\n",
      "Baseline Loss: 3.3306 | Actual Loss: 0.6750\n",
      "Baseline Loss: 3.5727 | Actual Loss: 0.5566\n",
      "Baseline Loss: 3.6273 | Actual Loss: 0.9860\n",
      "Baseline Loss: 3.5836 | Actual Loss: 1.0781\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.3272\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.7180\n",
      "Epoch 65/1000: Train Loss: 1.1710, Val Loss: 1.7773\n",
      "Baseline Loss: 3.5783 | Actual Loss: 0.5523\n",
      "Baseline Loss: 3.5456 | Actual Loss: 0.4918\n",
      "Baseline Loss: 3.5324 | Actual Loss: 0.6781\n",
      "Baseline Loss: 3.3255 | Actual Loss: 0.9492\n",
      "Baseline Loss: 4.0148 | Actual Loss: 1.8743\n",
      "Baseline Loss: 3.5373 | Actual Loss: 0.8081\n",
      "Baseline Loss: 3.2475 | Actual Loss: 0.8757\n",
      "Baseline Loss: 3.5532 | Actual Loss: 1.6857\n",
      "Baseline Loss: 3.2951 | Actual Loss: 1.2895\n",
      "Baseline Loss: 3.4855 | Actual Loss: 1.0050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 66/1000 [00:30<07:19,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.2402 | Actual Loss: 0.9371\n",
      "Baseline Loss: 3.4443 | Actual Loss: 1.4562\n",
      "Baseline Loss: 3.6235 | Actual Loss: 3.2773\n",
      "Baseline Loss: 3.6004 | Actual Loss: 0.5861\n",
      "Baseline Loss: 3.5756 | Actual Loss: 0.7926\n",
      "Baseline Loss: 3.1805 | Actual Loss: 0.9298\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.0392\n",
      "Baseline Loss: 3.5836 | Actual Loss: 1.0341\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.2647\n",
      "Baseline Loss: 3.9021 | Actual Loss: 4.1302\n",
      "Epoch 66/1000: Train Loss: 1.1368, Val Loss: 1.8670\n",
      "Baseline Loss: 3.3917 | Actual Loss: 0.7135\n",
      "Baseline Loss: 3.4581 | Actual Loss: 1.0417\n",
      "Baseline Loss: 3.2727 | Actual Loss: 1.2094\n",
      "Baseline Loss: 3.3118 | Actual Loss: 0.8675\n",
      "Baseline Loss: 3.5011 | Actual Loss: 0.7342\n",
      "Baseline Loss: 3.5168 | Actual Loss: 0.8161\n",
      "Baseline Loss: 3.7067 | Actual Loss: 2.8215\n",
      "Baseline Loss: 3.5367 | Actual Loss: 2.7339\n",
      "Baseline Loss: 3.4972 | Actual Loss: 0.9016\n",
      "Baseline Loss: 3.6144 | Actual Loss: 1.2863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 67/1000 [00:31<07:23,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4367 | Actual Loss: 3.2227\n",
      "Baseline Loss: 3.4063 | Actual Loss: 1.0650\n",
      "Baseline Loss: 3.5364 | Actual Loss: 2.6876\n",
      "Baseline Loss: 3.4812 | Actual Loss: 0.7669\n",
      "Baseline Loss: 3.3199 | Actual Loss: 1.1196\n",
      "Baseline Loss: 3.2734 | Actual Loss: 0.5988\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.0269\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.9659\n",
      "Baseline Loss: 3.5497 | Actual Loss: 0.9699\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.2286\n",
      "Epoch 67/1000: Train Loss: 1.4116, Val Loss: 1.5478\n",
      "Baseline Loss: 3.6136 | Actual Loss: 1.2061\n",
      "Baseline Loss: 3.4894 | Actual Loss: 2.3587\n",
      "Baseline Loss: 3.4611 | Actual Loss: 1.1616\n",
      "Baseline Loss: 3.5534 | Actual Loss: 0.4424\n",
      "Baseline Loss: 3.5213 | Actual Loss: 2.0727\n",
      "Baseline Loss: 3.5095 | Actual Loss: 1.2140\n",
      "Baseline Loss: 3.4776 | Actual Loss: 0.7946\n",
      "Baseline Loss: 3.4210 | Actual Loss: 1.3285\n",
      "Baseline Loss: 3.4586 | Actual Loss: 0.7818\n",
      "Baseline Loss: 3.4465 | Actual Loss: 1.3576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 68/1000 [00:31<07:07,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6973 | Actual Loss: 2.9371\n",
      "Baseline Loss: 3.4209 | Actual Loss: 1.0627\n",
      "Baseline Loss: 3.4732 | Actual Loss: 1.1561\n",
      "Baseline Loss: 3.2544 | Actual Loss: 1.3286\n",
      "Baseline Loss: 3.6684 | Actual Loss: 1.3498\n",
      "Baseline Loss: 3.3673 | Actual Loss: 3.5313\n",
      "Baseline Loss: 3.6273 | Actual Loss: 0.9367\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.9759\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.0063\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.3315\n",
      "Epoch 68/1000: Train Loss: 1.5052, Val Loss: 1.5626\n",
      "Baseline Loss: 3.5583 | Actual Loss: 0.5246\n",
      "Baseline Loss: 3.4360 | Actual Loss: 0.7392\n",
      "Baseline Loss: 3.4068 | Actual Loss: 0.9730\n",
      "Baseline Loss: 3.3508 | Actual Loss: 1.2716\n",
      "Baseline Loss: 3.4023 | Actual Loss: 0.7858\n",
      "Baseline Loss: 3.2864 | Actual Loss: 1.0072\n",
      "Baseline Loss: 3.4178 | Actual Loss: 2.1646\n",
      "Baseline Loss: 3.4584 | Actual Loss: 1.7141\n",
      "Baseline Loss: 3.5018 | Actual Loss: 1.3242\n",
      "Baseline Loss: 3.7675 | Actual Loss: 1.1670\n",
      "Baseline Loss: 3.6689 | Actual Loss: 1.4831\n",
      "Baseline Loss: 3.4849 | Actual Loss: 0.5719\n",
      "Baseline Loss: 3.5704 | Actual Loss: 1.5017\n",
      "Baseline Loss: 3.6979 | Actual Loss: 0.5839\n",
      "Baseline Loss: 3.6547 | Actual Loss: 0.6406\n",
      "Baseline Loss: 3.1530 | Actual Loss: 3.2229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 69/1000 [00:32<07:19,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6273 | Actual Loss: 0.9513\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.9544\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.0972\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.0315\n",
      "Epoch 69/1000: Train Loss: 1.2297, Val Loss: 1.5086\n",
      "Baseline Loss: 3.5624 | Actual Loss: 0.6103\n",
      "Baseline Loss: 3.4923 | Actual Loss: 0.9728\n",
      "Baseline Loss: 3.4776 | Actual Loss: 0.9562\n",
      "Baseline Loss: 3.6406 | Actual Loss: 1.8025\n",
      "Baseline Loss: 3.6833 | Actual Loss: 0.8205\n",
      "Baseline Loss: 3.4283 | Actual Loss: 1.5068\n",
      "Baseline Loss: 3.6055 | Actual Loss: 1.0764\n",
      "Baseline Loss: 3.2243 | Actual Loss: 1.5912\n",
      "Baseline Loss: 3.3580 | Actual Loss: 0.9861\n",
      "Baseline Loss: 3.5335 | Actual Loss: 1.0494\n",
      "Baseline Loss: 3.4514 | Actual Loss: 0.6381\n",
      "Baseline Loss: 3.5371 | Actual Loss: 0.4940\n",
      "Baseline Loss: 3.4617 | Actual Loss: 1.1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 70/1000 [00:32<07:27,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4573 | Actual Loss: 0.8209\n",
      "Baseline Loss: 3.5373 | Actual Loss: 1.4294\n",
      "Baseline Loss: 3.3409 | Actual Loss: 0.7718\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.0692\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.8320\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.5532\n",
      "Baseline Loss: 3.9021 | Actual Loss: 2.1649\n",
      "Epoch 70/1000: Train Loss: 1.0423, Val Loss: 1.4048\n",
      "Baseline Loss: 3.5241 | Actual Loss: 1.2485\n",
      "Baseline Loss: 3.4924 | Actual Loss: 0.9369\n",
      "Baseline Loss: 3.4853 | Actual Loss: 1.4534\n",
      "Baseline Loss: 3.5249 | Actual Loss: 1.0480\n",
      "Baseline Loss: 3.4617 | Actual Loss: 1.3810\n",
      "Baseline Loss: 3.5093 | Actual Loss: 1.4282\n",
      "Baseline Loss: 3.6453 | Actual Loss: 1.0010\n",
      "Baseline Loss: 3.7121 | Actual Loss: 1.1711\n",
      "Baseline Loss: 3.4434 | Actual Loss: 0.4887\n",
      "Baseline Loss: 3.4778 | Actual Loss: 2.0626\n",
      "Baseline Loss: 3.5498 | Actual Loss: 1.1604\n",
      "Baseline Loss: 3.6596 | Actual Loss: 1.0112\n",
      "Baseline Loss: 3.4513 | Actual Loss: 1.5631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 71/1000 [00:33<07:15,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5622 | Actual Loss: 1.2757\n",
      "Baseline Loss: 3.4581 | Actual Loss: 1.1045\n",
      "Baseline Loss: 2.7818 | Actual Loss: 0.7306\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.2382\n",
      "Baseline Loss: 3.5836 | Actual Loss: 1.0816\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.2490\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.8260\n",
      "Epoch 71/1000: Train Loss: 1.1915, Val Loss: 1.8487\n",
      "Baseline Loss: 3.4626 | Actual Loss: 1.4143\n",
      "Baseline Loss: 3.3819 | Actual Loss: 1.1386\n",
      "Baseline Loss: 3.8209 | Actual Loss: 1.9207\n",
      "Baseline Loss: 3.4550 | Actual Loss: 0.8369\n",
      "Baseline Loss: 3.4169 | Actual Loss: 1.8995\n",
      "Baseline Loss: 3.4734 | Actual Loss: 1.2530\n",
      "Baseline Loss: 3.3994 | Actual Loss: 0.9644\n",
      "Baseline Loss: 3.6367 | Actual Loss: 1.3710\n",
      "Baseline Loss: 3.5126 | Actual Loss: 0.9265\n",
      "Baseline Loss: 3.5880 | Actual Loss: 1.4050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 72/1000 [00:33<07:27,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7023 | Actual Loss: 1.2159\n",
      "Baseline Loss: 3.5288 | Actual Loss: 1.0177\n",
      "Baseline Loss: 3.5245 | Actual Loss: 0.6096\n",
      "Baseline Loss: 3.5493 | Actual Loss: 0.8520\n",
      "Baseline Loss: 3.3681 | Actual Loss: 1.4718\n",
      "Baseline Loss: 3.4309 | Actual Loss: 2.0263\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.2086\n",
      "Baseline Loss: 3.5836 | Actual Loss: 1.3052\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.6680\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.6335\n",
      "Epoch 72/1000: Train Loss: 1.2702, Val Loss: 1.9538\n",
      "Baseline Loss: 3.4970 | Actual Loss: 2.1496\n",
      "Baseline Loss: 3.4425 | Actual Loss: 1.9361\n",
      "Baseline Loss: 3.6052 | Actual Loss: 2.9445\n",
      "Baseline Loss: 3.5790 | Actual Loss: 1.9340\n",
      "Baseline Loss: 3.4650 | Actual Loss: 0.6699\n",
      "Baseline Loss: 3.4135 | Actual Loss: 1.3801\n",
      "Baseline Loss: 3.3822 | Actual Loss: 0.4707\n",
      "Baseline Loss: 3.4357 | Actual Loss: 0.6402\n",
      "Baseline Loss: 3.6929 | Actual Loss: 0.8385\n",
      "Baseline Loss: 3.3516 | Actual Loss: 0.9966\n",
      "Baseline Loss: 3.5963 | Actual Loss: 1.0398\n",
      "Baseline Loss: 3.4505 | Actual Loss: 1.0325\n",
      "Baseline Loss: 3.5362 | Actual Loss: 0.9690\n",
      "Baseline Loss: 3.3687 | Actual Loss: 1.3230\n",
      "Baseline Loss: 3.5204 | Actual Loss: 0.8527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 73/1000 [00:34<07:30,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.1461 | Actual Loss: 0.7049\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.0482\n",
      "Baseline Loss: 3.5836 | Actual Loss: 1.4337\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.4176\n",
      "Baseline Loss: 3.9021 | Actual Loss: 4.0638\n",
      "Epoch 73/1000: Train Loss: 1.2426, Val Loss: 1.9908\n",
      "Baseline Loss: 3.4706 | Actual Loss: 0.6997\n",
      "Baseline Loss: 3.2885 | Actual Loss: 0.7329\n",
      "Baseline Loss: 3.6928 | Actual Loss: 1.7823\n",
      "Baseline Loss: 3.6097 | Actual Loss: 0.6737\n",
      "Baseline Loss: 3.5114 | Actual Loss: 0.3706\n",
      "Baseline Loss: 3.4502 | Actual Loss: 0.7750\n",
      "Baseline Loss: 3.5242 | Actual Loss: 0.7503\n",
      "Baseline Loss: 3.6277 | Actual Loss: 1.9017\n",
      "Baseline Loss: 3.4925 | Actual Loss: 0.9021\n",
      "Baseline Loss: 3.5494 | Actual Loss: 2.8171\n",
      "Baseline Loss: 3.5706 | Actual Loss: 0.7229\n",
      "Baseline Loss: 3.5624 | Actual Loss: 1.0485\n",
      "Baseline Loss: 3.3403 | Actual Loss: 0.9122\n",
      "Baseline Loss: 3.3930 | Actual Loss: 0.9676\n",
      "Baseline Loss: 3.3784 | Actual Loss: 2.2198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 74/1000 [00:34<07:16,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.1596 | Actual Loss: 1.6087\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.0083\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.7240\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.1062\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.3768\n",
      "Epoch 74/1000: Train Loss: 1.1803, Val Loss: 1.5538\n",
      "Baseline Loss: 3.3886 | Actual Loss: 0.9554\n",
      "Baseline Loss: 3.4584 | Actual Loss: 1.3256\n",
      "Baseline Loss: 3.5705 | Actual Loss: 0.9527\n",
      "Baseline Loss: 3.4891 | Actual Loss: 0.8371\n",
      "Baseline Loss: 3.4738 | Actual Loss: 0.9088\n",
      "Baseline Loss: 3.6645 | Actual Loss: 1.0950\n",
      "Baseline Loss: 3.3717 | Actual Loss: 1.3899\n",
      "Baseline Loss: 3.3748 | Actual Loss: 0.8958\n",
      "Baseline Loss: 3.4065 | Actual Loss: 0.7493\n",
      "Baseline Loss: 3.5047 | Actual Loss: 1.4685\n",
      "Baseline Loss: 3.5043 | Actual Loss: 1.3627\n",
      "Baseline Loss: 3.5262 | Actual Loss: 0.8336\n",
      "Baseline Loss: 3.5794 | Actual Loss: 1.0669\n",
      "Baseline Loss: 3.5168 | Actual Loss: 1.2970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 75/1000 [00:35<07:16,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4736 | Actual Loss: 1.2708\n",
      "Baseline Loss: 3.3143 | Actual Loss: 1.2216\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.0015\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.6068\n",
      "Baseline Loss: 3.5497 | Actual Loss: 0.9915\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.0338\n",
      "Epoch 75/1000: Train Loss: 1.1019, Val Loss: 1.4084\n",
      "Baseline Loss: 3.7076 | Actual Loss: 0.7625\n",
      "Baseline Loss: 3.6823 | Actual Loss: 0.6212\n",
      "Baseline Loss: 3.4064 | Actual Loss: 1.0229\n",
      "Baseline Loss: 3.4693 | Actual Loss: 0.6961\n",
      "Baseline Loss: 3.5087 | Actual Loss: 1.7201\n",
      "Baseline Loss: 3.6737 | Actual Loss: 3.4518\n",
      "Baseline Loss: 3.5787 | Actual Loss: 2.5441\n",
      "Baseline Loss: 3.4431 | Actual Loss: 0.9399\n",
      "Baseline Loss: 3.5922 | Actual Loss: 1.6259\n",
      "Baseline Loss: 3.4895 | Actual Loss: 1.1044\n",
      "Baseline Loss: 3.3141 | Actual Loss: 1.0667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 76/1000 [00:35<07:12,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5125 | Actual Loss: 1.0346\n",
      "Baseline Loss: 3.4818 | Actual Loss: 0.7886\n",
      "Baseline Loss: 3.3649 | Actual Loss: 0.8070\n",
      "Baseline Loss: 3.3345 | Actual Loss: 0.7744\n",
      "Baseline Loss: 3.1893 | Actual Loss: 1.2055\n",
      "Baseline Loss: 3.6273 | Actual Loss: 0.9930\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.7809\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.3117\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.3903\n",
      "Epoch 76/1000: Train Loss: 1.2604, Val Loss: 1.6190\n",
      "Baseline Loss: 3.3854 | Actual Loss: 0.9848\n",
      "Baseline Loss: 3.5881 | Actual Loss: 0.6116\n",
      "Baseline Loss: 3.6232 | Actual Loss: 1.5250\n",
      "Baseline Loss: 3.4586 | Actual Loss: 1.0951\n",
      "Baseline Loss: 3.5134 | Actual Loss: 0.9144\n",
      "Baseline Loss: 3.3299 | Actual Loss: 0.7969\n",
      "Baseline Loss: 3.5614 | Actual Loss: 0.7659\n",
      "Baseline Loss: 3.3447 | Actual Loss: 1.2096\n",
      "Baseline Loss: 3.4351 | Actual Loss: 1.2395\n",
      "Baseline Loss: 3.5165 | Actual Loss: 1.1705\n",
      "Baseline Loss: 3.4972 | Actual Loss: 1.5659\n",
      "Baseline Loss: 3.4137 | Actual Loss: 1.0275\n",
      "Baseline Loss: 3.7521 | Actual Loss: 0.8117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 77/1000 [00:36<07:19,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4849 | Actual Loss: 1.3532\n",
      "Baseline Loss: 3.4810 | Actual Loss: 0.5519\n",
      "Baseline Loss: 3.4109 | Actual Loss: 0.8509\n",
      "Baseline Loss: 3.6273 | Actual Loss: 0.9737\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.8827\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.2131\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.7811\n",
      "Epoch 77/1000: Train Loss: 1.0297, Val Loss: 1.7126\n",
      "Baseline Loss: 3.5922 | Actual Loss: 3.6329\n",
      "Baseline Loss: 3.4739 | Actual Loss: 0.8979\n",
      "Baseline Loss: 3.6923 | Actual Loss: 3.3762\n",
      "Baseline Loss: 3.3337 | Actual Loss: 1.0792\n",
      "Baseline Loss: 3.4399 | Actual Loss: 1.1772\n",
      "Baseline Loss: 3.5873 | Actual Loss: 0.6366\n",
      "Baseline Loss: 3.4817 | Actual Loss: 1.8691\n",
      "Baseline Loss: 3.5251 | Actual Loss: 0.8703\n",
      "Baseline Loss: 3.4150 | Actual Loss: 1.8355\n",
      "Baseline Loss: 3.6688 | Actual Loss: 0.7293\n",
      "Baseline Loss: 3.7025 | Actual Loss: 2.3492\n",
      "Baseline Loss: 3.4235 | Actual Loss: 0.4621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 78/1000 [00:36<07:00,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4353 | Actual Loss: 2.9907\n",
      "Baseline Loss: 3.5086 | Actual Loss: 0.9645\n",
      "Baseline Loss: 3.4806 | Actual Loss: 0.8255\n",
      "Baseline Loss: 3.2569 | Actual Loss: 0.9285\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.0120\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.6429\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.1783\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.9444\n",
      "Epoch 78/1000: Train Loss: 1.5390, Val Loss: 1.6944\n",
      "Baseline Loss: 3.3052 | Actual Loss: 1.2813\n",
      "Baseline Loss: 3.4137 | Actual Loss: 0.5953\n",
      "Baseline Loss: 3.6688 | Actual Loss: 0.7370\n",
      "Baseline Loss: 3.7568 | Actual Loss: 0.4825\n",
      "Baseline Loss: 3.3309 | Actual Loss: 0.6948\n",
      "Baseline Loss: 3.3828 | Actual Loss: 3.4520\n",
      "Baseline Loss: 3.5251 | Actual Loss: 0.8149\n",
      "Baseline Loss: 3.4171 | Actual Loss: 0.3860\n",
      "Baseline Loss: 3.6650 | Actual Loss: 1.2726\n",
      "Baseline Loss: 3.5047 | Actual Loss: 0.9148\n",
      "Baseline Loss: 3.4290 | Actual Loss: 1.9376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 79/1000 [00:36<07:04,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.8158 | Actual Loss: 1.0180\n",
      "Baseline Loss: 3.5625 | Actual Loss: 1.1004\n",
      "Baseline Loss: 3.4506 | Actual Loss: 0.7456\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.8317\n",
      "Baseline Loss: 2.9924 | Actual Loss: 0.5005\n",
      "Baseline Loss: 3.6273 | Actual Loss: 0.9133\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.5694\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.1409\n",
      "Baseline Loss: 3.9021 | Actual Loss: 4.0291\n",
      "Epoch 79/1000: Train Loss: 1.0478, Val Loss: 1.6632\n",
      "Baseline Loss: 3.6642 | Actual Loss: 0.9685\n",
      "Baseline Loss: 3.5706 | Actual Loss: 0.6636\n",
      "Baseline Loss: 3.3644 | Actual Loss: 0.9523\n",
      "Baseline Loss: 3.5256 | Actual Loss: 0.7979\n",
      "Baseline Loss: 3.2991 | Actual Loss: 0.5336\n",
      "Baseline Loss: 3.3920 | Actual Loss: 1.2171\n",
      "Baseline Loss: 3.5010 | Actual Loss: 0.5410\n",
      "Baseline Loss: 3.4811 | Actual Loss: 1.9028\n",
      "Baseline Loss: 3.5459 | Actual Loss: 0.7543\n",
      "Baseline Loss: 3.6878 | Actual Loss: 0.9532\n",
      "Baseline Loss: 3.6095 | Actual Loss: 1.0865\n",
      "Baseline Loss: 3.4034 | Actual Loss: 1.0506\n",
      "Baseline Loss: 3.7520 | Actual Loss: 2.3747\n",
      "Baseline Loss: 3.4462 | Actual Loss: 0.6485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 80/1000 [00:37<06:52,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6973 | Actual Loss: 0.9821\n",
      "Baseline Loss: 3.3065 | Actual Loss: 0.6304\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.0110\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.6027\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.1867\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.5759\n",
      "Epoch 80/1000: Train Loss: 1.0036, Val Loss: 1.5941\n",
      "Baseline Loss: 3.5000 | Actual Loss: 0.8758\n",
      "Baseline Loss: 3.4895 | Actual Loss: 0.8707\n",
      "Baseline Loss: 3.6451 | Actual Loss: 0.7793\n",
      "Baseline Loss: 3.6008 | Actual Loss: 0.9837\n",
      "Baseline Loss: 3.3152 | Actual Loss: 0.6764\n",
      "Baseline Loss: 3.4163 | Actual Loss: 0.9230\n",
      "Baseline Loss: 3.3400 | Actual Loss: 0.9414\n",
      "Baseline Loss: 3.3024 | Actual Loss: 0.4223\n",
      "Baseline Loss: 3.5284 | Actual Loss: 0.3344\n",
      "Baseline Loss: 3.5167 | Actual Loss: 1.0624\n",
      "Baseline Loss: 3.5538 | Actual Loss: 1.0746\n",
      "Baseline Loss: 3.6779 | Actual Loss: 0.7961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 81/1000 [00:37<07:03,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6827 | Actual Loss: 3.0350\n",
      "Baseline Loss: 3.2999 | Actual Loss: 1.2128\n",
      "Baseline Loss: 3.6594 | Actual Loss: 0.8688\n",
      "Baseline Loss: 3.2038 | Actual Loss: 1.3520\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.0485\n",
      "Baseline Loss: 3.5836 | Actual Loss: 1.0809\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.0063\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.9421\n",
      "Epoch 81/1000: Train Loss: 1.0130, Val Loss: 1.7695\n",
      "Baseline Loss: 3.4172 | Actual Loss: 0.9881\n",
      "Baseline Loss: 3.5207 | Actual Loss: 1.4463\n",
      "Baseline Loss: 3.4136 | Actual Loss: 1.3525\n",
      "Baseline Loss: 3.7321 | Actual Loss: 1.1785\n",
      "Baseline Loss: 3.3754 | Actual Loss: 0.6018\n",
      "Baseline Loss: 3.6927 | Actual Loss: 0.6538\n",
      "Baseline Loss: 3.4101 | Actual Loss: 1.1784\n",
      "Baseline Loss: 3.7476 | Actual Loss: 0.4488\n",
      "Baseline Loss: 3.3686 | Actual Loss: 1.1196\n",
      "Baseline Loss: 3.6014 | Actual Loss: 0.6609\n",
      "Baseline Loss: 3.5045 | Actual Loss: 0.9462\n",
      "Baseline Loss: 3.3613 | Actual Loss: 0.7568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 82/1000 [00:38<07:15,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4970 | Actual Loss: 1.3856\n",
      "Baseline Loss: 3.3626 | Actual Loss: 0.9176\n",
      "Baseline Loss: 3.5247 | Actual Loss: 1.2357\n",
      "Baseline Loss: 3.0972 | Actual Loss: 0.4442\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.0463\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.7586\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.2679\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.1100\n",
      "Epoch 82/1000: Train Loss: 0.9572, Val Loss: 1.5457\n",
      "Baseline Loss: 3.8321 | Actual Loss: 1.8204\n",
      "Baseline Loss: 3.6361 | Actual Loss: 0.7937\n",
      "Baseline Loss: 3.4767 | Actual Loss: 1.0517\n",
      "Baseline Loss: 3.3450 | Actual Loss: 1.1315\n",
      "Baseline Loss: 3.5370 | Actual Loss: 0.7689\n",
      "Baseline Loss: 3.5578 | Actual Loss: 0.6670\n",
      "Baseline Loss: 3.5088 | Actual Loss: 0.6998\n",
      "Baseline Loss: 3.5715 | Actual Loss: 0.7793\n",
      "Baseline Loss: 3.3510 | Actual Loss: 0.6855\n",
      "Baseline Loss: 3.6092 | Actual Loss: 1.2618\n",
      "Baseline Loss: 3.4204 | Actual Loss: 0.8481\n",
      "Baseline Loss: 3.5925 | Actual Loss: 0.7679\n",
      "Baseline Loss: 3.5367 | Actual Loss: 2.1182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 83/1000 [00:38<06:57,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5781 | Actual Loss: 1.2545\n",
      "Baseline Loss: 3.4057 | Actual Loss: 0.4697\n",
      "Baseline Loss: 3.3583 | Actual Loss: 0.7742\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.0218\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.4878\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.1648\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.7371\n",
      "Epoch 83/1000: Train Loss: 0.9933, Val Loss: 1.6029\n",
      "Baseline Loss: 3.5743 | Actual Loss: 0.7680\n",
      "Baseline Loss: 3.5658 | Actual Loss: 2.1444\n",
      "Baseline Loss: 3.4742 | Actual Loss: 0.8075\n",
      "Baseline Loss: 3.5004 | Actual Loss: 0.9935\n",
      "Baseline Loss: 3.3329 | Actual Loss: 0.9614\n",
      "Baseline Loss: 3.4283 | Actual Loss: 0.9009\n",
      "Baseline Loss: 3.3787 | Actual Loss: 0.7814\n",
      "Baseline Loss: 3.5093 | Actual Loss: 0.9834\n",
      "Baseline Loss: 3.3275 | Actual Loss: 0.6890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 84/1000 [00:39<06:59,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4250 | Actual Loss: 0.9995\n",
      "Baseline Loss: 3.4931 | Actual Loss: 1.9689\n",
      "Baseline Loss: 3.6181 | Actual Loss: 3.3299\n",
      "Baseline Loss: 3.4470 | Actual Loss: 0.8493\n",
      "Baseline Loss: 3.2908 | Actual Loss: 2.0898\n",
      "Baseline Loss: 3.6642 | Actual Loss: 0.9909\n",
      "Baseline Loss: 3.3931 | Actual Loss: 2.0944\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.0221\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.4877\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.0659\n",
      "Baseline Loss: 3.9021 | Actual Loss: 4.2117\n",
      "Epoch 84/1000: Train Loss: 1.3345, Val Loss: 1.6969\n",
      "Baseline Loss: 3.3565 | Actual Loss: 1.2527\n",
      "Baseline Loss: 3.5092 | Actual Loss: 1.4034\n",
      "Baseline Loss: 3.5748 | Actual Loss: 1.5719\n",
      "Baseline Loss: 3.4508 | Actual Loss: 0.4223\n",
      "Baseline Loss: 3.6095 | Actual Loss: 1.0577\n",
      "Baseline Loss: 3.4106 | Actual Loss: 1.2080\n",
      "Baseline Loss: 3.5134 | Actual Loss: 1.0842\n",
      "Baseline Loss: 3.2951 | Actual Loss: 0.9774\n",
      "Baseline Loss: 3.6050 | Actual Loss: 0.9577\n",
      "Baseline Loss: 3.5740 | Actual Loss: 1.0041\n",
      "Baseline Loss: 3.4776 | Actual Loss: 1.2936\n",
      "Baseline Loss: 3.8660 | Actual Loss: 0.7185\n",
      "Baseline Loss: 3.3745 | Actual Loss: 1.1389\n",
      "Baseline Loss: 3.5505 | Actual Loss: 1.0020\n",
      "Baseline Loss: 3.4926 | Actual Loss: 0.6370\n",
      "Baseline Loss: 2.8474 | Actual Loss: 0.7502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 85/1000 [00:39<07:13,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6273 | Actual Loss: 1.0139\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.7711\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.0725\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.7383\n",
      "Epoch 85/1000: Train Loss: 1.0300, Val Loss: 1.6490\n",
      "Baseline Loss: 3.5783 | Actual Loss: 0.9757\n",
      "Baseline Loss: 3.5416 | Actual Loss: 1.2065\n",
      "Baseline Loss: 3.4473 | Actual Loss: 1.0187\n",
      "Baseline Loss: 3.5379 | Actual Loss: 1.3541\n",
      "Baseline Loss: 3.3213 | Actual Loss: 1.1942\n",
      "Baseline Loss: 3.5678 | Actual Loss: 1.4259\n",
      "Baseline Loss: 3.5545 | Actual Loss: 1.3906\n",
      "Baseline Loss: 3.4590 | Actual Loss: 1.2103\n",
      "Baseline Loss: 3.5296 | Actual Loss: 0.7724\n",
      "Baseline Loss: 3.6542 | Actual Loss: 0.7537\n",
      "Baseline Loss: 3.7419 | Actual Loss: 0.7717\n",
      "Baseline Loss: 3.4425 | Actual Loss: 0.9131\n",
      "Baseline Loss: 3.7736 | Actual Loss: 1.3695\n",
      "Baseline Loss: 3.2361 | Actual Loss: 1.1059\n",
      "Baseline Loss: 3.3689 | Actual Loss: 0.9246\n",
      "Baseline Loss: 3.3664 | Actual Loss: 1.9845\n",
      "Baseline Loss: 3.6273 | Actual Loss: 0.9717\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.8041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▊         | 86/1000 [00:40<06:53,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5497 | Actual Loss: 0.9812\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.3427\n",
      "Epoch 86/1000: Train Loss: 1.1482, Val Loss: 1.5249\n",
      "Baseline Loss: 3.5041 | Actual Loss: 1.1183\n",
      "Baseline Loss: 3.4587 | Actual Loss: 1.0696\n",
      "Baseline Loss: 3.4853 | Actual Loss: 0.8146\n",
      "Baseline Loss: 3.2880 | Actual Loss: 1.0013\n",
      "Baseline Loss: 3.5751 | Actual Loss: 1.8944\n",
      "Baseline Loss: 3.7424 | Actual Loss: 1.2667\n",
      "Baseline Loss: 3.6319 | Actual Loss: 0.8731\n",
      "Baseline Loss: 3.7423 | Actual Loss: 1.4878\n",
      "Baseline Loss: 3.4548 | Actual Loss: 0.8716\n",
      "Baseline Loss: 3.5916 | Actual Loss: 1.5653\n",
      "Baseline Loss: 3.5171 | Actual Loss: 3.1064\n",
      "Baseline Loss: 3.3994 | Actual Loss: 0.5196\n",
      "Baseline Loss: 3.4367 | Actual Loss: 0.2815\n",
      "Baseline Loss: 3.7577 | Actual Loss: 0.9042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▊         | 87/1000 [00:40<07:07,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5623 | Actual Loss: 0.5542\n",
      "Baseline Loss: 3.1392 | Actual Loss: 1.0568\n",
      "Baseline Loss: 3.6273 | Actual Loss: 0.9967\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.7939\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.1564\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.8265\n",
      "Epoch 87/1000: Train Loss: 1.1491, Val Loss: 1.6934\n",
      "Baseline Loss: 3.5669 | Actual Loss: 0.7169\n",
      "Baseline Loss: 3.3109 | Actual Loss: 1.1686\n",
      "Baseline Loss: 3.5487 | Actual Loss: 1.0082\n",
      "Baseline Loss: 3.4783 | Actual Loss: 1.4165\n",
      "Baseline Loss: 3.4312 | Actual Loss: 0.2725\n",
      "Baseline Loss: 3.4473 | Actual Loss: 0.9913\n",
      "Baseline Loss: 3.5703 | Actual Loss: 0.7749\n",
      "Baseline Loss: 3.3708 | Actual Loss: 0.8008\n",
      "Baseline Loss: 3.5457 | Actual Loss: 1.4567\n",
      "Baseline Loss: 3.3346 | Actual Loss: 1.0527\n",
      "Baseline Loss: 3.4974 | Actual Loss: 0.8155\n",
      "Baseline Loss: 3.4971 | Actual Loss: 1.9192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 88/1000 [00:41<07:14,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6828 | Actual Loss: 0.8714\n",
      "Baseline Loss: 3.4469 | Actual Loss: 1.3748\n",
      "Baseline Loss: 3.6050 | Actual Loss: 1.1610\n",
      "Baseline Loss: 3.2575 | Actual Loss: 1.5297\n",
      "Baseline Loss: 3.6273 | Actual Loss: 0.9181\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.7152\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.4595\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.7165\n",
      "Epoch 88/1000: Train Loss: 1.0832, Val Loss: 1.7023\n",
      "Baseline Loss: 3.4934 | Actual Loss: 1.5191\n",
      "Baseline Loss: 3.5416 | Actual Loss: 0.7581\n",
      "Baseline Loss: 3.6547 | Actual Loss: 0.3774\n",
      "Baseline Loss: 3.6180 | Actual Loss: 0.9597\n",
      "Baseline Loss: 3.4863 | Actual Loss: 1.6980\n",
      "Baseline Loss: 3.4357 | Actual Loss: 1.2372\n",
      "Baseline Loss: 3.6597 | Actual Loss: 1.8056\n",
      "Baseline Loss: 3.7470 | Actual Loss: 4.0181\n",
      "Baseline Loss: 3.4175 | Actual Loss: 1.9729\n",
      "Baseline Loss: 3.4889 | Actual Loss: 3.9300\n",
      "Baseline Loss: 3.6324 | Actual Loss: 0.9861\n",
      "Baseline Loss: 3.4374 | Actual Loss: 0.8986\n",
      "Baseline Loss: 3.4744 | Actual Loss: 0.9368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 89/1000 [00:41<06:54,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3263 | Actual Loss: 0.7143\n",
      "Baseline Loss: 3.2771 | Actual Loss: 1.2987\n",
      "Baseline Loss: 3.7139 | Actual Loss: 1.2138\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.0035\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.7630\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.1284\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.3959\n",
      "Epoch 89/1000: Train Loss: 1.5203, Val Loss: 1.5727\n",
      "Baseline Loss: 3.4656 | Actual Loss: 0.9352\n",
      "Baseline Loss: 3.7529 | Actual Loss: 2.1650\n",
      "Baseline Loss: 3.4889 | Actual Loss: 0.9189\n",
      "Baseline Loss: 3.5578 | Actual Loss: 1.2303\n",
      "Baseline Loss: 3.4547 | Actual Loss: 0.5274\n",
      "Baseline Loss: 3.5499 | Actual Loss: 0.6941\n",
      "Baseline Loss: 3.5703 | Actual Loss: 1.7613\n",
      "Baseline Loss: 3.5333 | Actual Loss: 1.2830\n",
      "Baseline Loss: 3.4441 | Actual Loss: 1.1808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 90/1000 [00:42<07:04,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4171 | Actual Loss: 2.0855\n",
      "Baseline Loss: 3.3717 | Actual Loss: 0.6189\n",
      "Baseline Loss: 3.4881 | Actual Loss: 1.2762\n",
      "Baseline Loss: 3.5376 | Actual Loss: 1.3558\n",
      "Baseline Loss: 3.4786 | Actual Loss: 0.8312\n",
      "Baseline Loss: 3.3586 | Actual Loss: 1.0531\n",
      "Baseline Loss: 3.3214 | Actual Loss: 0.5577\n",
      "Baseline Loss: 3.6273 | Actual Loss: 0.8517\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.5034\n",
      "Baseline Loss: 3.5497 | Actual Loss: 0.9806\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.4177\n",
      "Epoch 90/1000: Train Loss: 1.1546, Val Loss: 1.4384\n",
      "Baseline Loss: 3.6930 | Actual Loss: 2.0825\n",
      "Baseline Loss: 3.6878 | Actual Loss: 0.8132\n",
      "Baseline Loss: 3.3739 | Actual Loss: 1.2542\n",
      "Baseline Loss: 3.5410 | Actual Loss: 3.5808\n",
      "Baseline Loss: 3.3573 | Actual Loss: 0.7637\n",
      "Baseline Loss: 3.6013 | Actual Loss: 0.9677\n",
      "Baseline Loss: 3.8549 | Actual Loss: 2.2687\n",
      "Baseline Loss: 3.4430 | Actual Loss: 0.8325\n",
      "Baseline Loss: 3.3275 | Actual Loss: 0.7234\n",
      "Baseline Loss: 3.4518 | Actual Loss: 0.8766\n",
      "Baseline Loss: 3.5050 | Actual Loss: 0.6382\n",
      "Baseline Loss: 3.5124 | Actual Loss: 1.9674\n",
      "Baseline Loss: 3.5488 | Actual Loss: 0.4425\n",
      "Baseline Loss: 3.3972 | Actual Loss: 2.9840\n",
      "Baseline Loss: 3.3946 | Actual Loss: 1.8307\n",
      "Baseline Loss: 3.1750 | Actual Loss: 0.4282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 91/1000 [00:42<07:10,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6273 | Actual Loss: 0.9622\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.8656\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.0388\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.7977\n",
      "Epoch 91/1000: Train Loss: 1.4034, Val Loss: 1.6661\n",
      "Baseline Loss: 3.6141 | Actual Loss: 1.7582\n",
      "Baseline Loss: 3.5364 | Actual Loss: 4.2021\n",
      "Baseline Loss: 3.3817 | Actual Loss: 0.7698\n",
      "Baseline Loss: 3.4068 | Actual Loss: 1.0327\n",
      "Baseline Loss: 3.4469 | Actual Loss: 0.8575\n",
      "Baseline Loss: 3.5207 | Actual Loss: 1.1748\n",
      "Baseline Loss: 3.3109 | Actual Loss: 0.8283\n",
      "Baseline Loss: 3.4168 | Actual Loss: 0.9023\n",
      "Baseline Loss: 3.5378 | Actual Loss: 1.2612\n",
      "Baseline Loss: 3.4925 | Actual Loss: 0.7857\n",
      "Baseline Loss: 3.4363 | Actual Loss: 1.0977\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.8295\n",
      "Baseline Loss: 3.5242 | Actual Loss: 1.3825\n",
      "Baseline Loss: 3.5618 | Actual Loss: 1.0836\n",
      "Baseline Loss: 3.6605 | Actual Loss: 1.0284\n",
      "Baseline Loss: 3.4789 | Actual Loss: 0.7013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 92/1000 [00:42<07:13,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6273 | Actual Loss: 1.0083\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.4639\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.0527\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.5725\n",
      "Epoch 92/1000: Train Loss: 1.2310, Val Loss: 1.5243\n",
      "Baseline Loss: 3.2762 | Actual Loss: 1.2098\n",
      "Baseline Loss: 3.6636 | Actual Loss: 1.0088\n",
      "Baseline Loss: 3.4585 | Actual Loss: 0.6905\n",
      "Baseline Loss: 3.4860 | Actual Loss: 1.1280\n",
      "Baseline Loss: 3.6875 | Actual Loss: 1.2746\n",
      "Baseline Loss: 3.4513 | Actual Loss: 0.2507\n",
      "Baseline Loss: 3.5177 | Actual Loss: 1.0933\n",
      "Baseline Loss: 3.5956 | Actual Loss: 1.8137\n",
      "Baseline Loss: 3.4621 | Actual Loss: 1.0275\n",
      "Baseline Loss: 3.1951 | Actual Loss: 1.0196\n",
      "Baseline Loss: 3.5283 | Actual Loss: 1.3255\n",
      "Baseline Loss: 3.4972 | Actual Loss: 0.9969\n",
      "Baseline Loss: 3.5050 | Actual Loss: 1.2673\n",
      "Baseline Loss: 3.5142 | Actual Loss: 0.7475\n",
      "Baseline Loss: 3.6265 | Actual Loss: 0.5146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 93/1000 [00:43<07:02,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4887 | Actual Loss: 3.9894\n",
      "Baseline Loss: 3.6273 | Actual Loss: 0.9979\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.6318\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.3154\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.1177\n",
      "Epoch 93/1000: Train Loss: 1.2098, Val Loss: 1.5157\n",
      "Baseline Loss: 3.5499 | Actual Loss: 3.9193\n",
      "Baseline Loss: 3.5370 | Actual Loss: 1.8056\n",
      "Baseline Loss: 3.4767 | Actual Loss: 1.4149\n",
      "Baseline Loss: 3.4391 | Actual Loss: 1.0361\n",
      "Baseline Loss: 3.4153 | Actual Loss: 1.0331\n",
      "Baseline Loss: 3.5408 | Actual Loss: 0.6295\n",
      "Baseline Loss: 3.4504 | Actual Loss: 0.8316\n",
      "Baseline Loss: 3.7937 | Actual Loss: 1.7491\n",
      "Baseline Loss: 3.4093 | Actual Loss: 0.5755\n",
      "Baseline Loss: 3.5654 | Actual Loss: 1.5764\n",
      "Baseline Loss: 3.3310 | Actual Loss: 0.7452\n",
      "Baseline Loss: 3.6454 | Actual Loss: 0.2681\n",
      "Baseline Loss: 3.5709 | Actual Loss: 0.7482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 94/1000 [00:43<07:05,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4668 | Actual Loss: 1.6047\n",
      "Baseline Loss: 3.4134 | Actual Loss: 1.3676\n",
      "Baseline Loss: 3.4210 | Actual Loss: 1.0534\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.0069\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.6107\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.1796\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.2510\n",
      "Epoch 94/1000: Train Loss: 1.2724, Val Loss: 1.5120\n",
      "Baseline Loss: 3.6504 | Actual Loss: 1.1168\n",
      "Baseline Loss: 3.5266 | Actual Loss: 1.4155\n",
      "Baseline Loss: 3.3993 | Actual Loss: 0.6613\n",
      "Baseline Loss: 3.4178 | Actual Loss: 1.8013\n",
      "Baseline Loss: 3.6279 | Actual Loss: 0.9205\n",
      "Baseline Loss: 3.4810 | Actual Loss: 1.1862\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.8293\n",
      "Baseline Loss: 3.5416 | Actual Loss: 1.9593\n",
      "Baseline Loss: 3.4735 | Actual Loss: 0.9091\n",
      "Baseline Loss: 3.4209 | Actual Loss: 0.6194\n",
      "Baseline Loss: 3.4694 | Actual Loss: 1.2065\n",
      "Baseline Loss: 3.3680 | Actual Loss: 0.9853\n",
      "Baseline Loss: 3.4533 | Actual Loss: 0.9577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 95/1000 [00:44<06:49,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4508 | Actual Loss: 1.7063\n",
      "Baseline Loss: 3.4273 | Actual Loss: 1.1430\n",
      "Baseline Loss: 3.2333 | Actual Loss: 3.1388\n",
      "Baseline Loss: 3.6273 | Actual Loss: 0.9522\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.7374\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.0722\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.9213\n",
      "Epoch 95/1000: Train Loss: 1.2848, Val Loss: 1.6708\n",
      "Baseline Loss: 3.6831 | Actual Loss: 0.7375\n",
      "Baseline Loss: 3.6880 | Actual Loss: 0.9255\n",
      "Baseline Loss: 3.5049 | Actual Loss: 1.2125\n",
      "Baseline Loss: 3.4211 | Actual Loss: 0.6644\n",
      "Baseline Loss: 3.4103 | Actual Loss: 1.0321\n",
      "Baseline Loss: 3.5377 | Actual Loss: 0.9054\n",
      "Baseline Loss: 3.3674 | Actual Loss: 0.7022\n",
      "Baseline Loss: 3.4965 | Actual Loss: 0.9638\n",
      "Baseline Loss: 3.5919 | Actual Loss: 1.9216\n",
      "Baseline Loss: 3.4549 | Actual Loss: 0.7327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 96/1000 [00:44<07:06,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5136 | Actual Loss: 1.2375\n",
      "Baseline Loss: 3.4014 | Actual Loss: 1.4115\n",
      "Baseline Loss: 3.4318 | Actual Loss: 1.3197\n",
      "Baseline Loss: 3.5873 | Actual Loss: 1.0091\n",
      "Baseline Loss: 3.4392 | Actual Loss: 0.3359\n",
      "Baseline Loss: 3.1596 | Actual Loss: 0.1246\n",
      "Baseline Loss: 3.6273 | Actual Loss: 0.9496\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.9136\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.1133\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.3311\n",
      "Epoch 96/1000: Train Loss: 0.9523, Val Loss: 1.5769\n",
      "Baseline Loss: 3.5699 | Actual Loss: 1.7002\n",
      "Baseline Loss: 3.4935 | Actual Loss: 0.9275\n",
      "Baseline Loss: 3.4360 | Actual Loss: 0.8316\n",
      "Baseline Loss: 3.4180 | Actual Loss: 1.1191\n",
      "Baseline Loss: 3.5704 | Actual Loss: 0.6989\n",
      "Baseline Loss: 3.3020 | Actual Loss: 0.5574\n",
      "Baseline Loss: 3.5705 | Actual Loss: 0.7137\n",
      "Baseline Loss: 3.4173 | Actual Loss: 1.3969\n",
      "Baseline Loss: 3.6050 | Actual Loss: 0.5938\n",
      "Baseline Loss: 3.2823 | Actual Loss: 1.1051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 97/1000 [00:45<07:06,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5298 | Actual Loss: 0.7605\n",
      "Baseline Loss: 3.5329 | Actual Loss: 0.9872\n",
      "Baseline Loss: 3.4215 | Actual Loss: 0.6202\n",
      "Baseline Loss: 3.6456 | Actual Loss: 1.6137\n",
      "Baseline Loss: 3.5459 | Actual Loss: 1.6555\n",
      "Baseline Loss: 3.4210 | Actual Loss: 2.1802\n",
      "Baseline Loss: 3.6273 | Actual Loss: 0.9037\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.6436\n",
      "Baseline Loss: 3.5497 | Actual Loss: 0.9878\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.6944\n",
      "Epoch 97/1000: Train Loss: 1.0913, Val Loss: 1.5574\n",
      "Baseline Loss: 3.6137 | Actual Loss: 0.4961\n",
      "Baseline Loss: 3.4250 | Actual Loss: 1.0381\n",
      "Baseline Loss: 3.2800 | Actual Loss: 0.9996\n",
      "Baseline Loss: 3.5530 | Actual Loss: 1.2617\n",
      "Baseline Loss: 3.5577 | Actual Loss: 1.1321\n",
      "Baseline Loss: 3.2887 | Actual Loss: 0.7768\n",
      "Baseline Loss: 3.6143 | Actual Loss: 0.8348\n",
      "Baseline Loss: 3.5662 | Actual Loss: 0.7918\n",
      "Baseline Loss: 3.2859 | Actual Loss: 0.9251\n",
      "Baseline Loss: 3.6417 | Actual Loss: 0.7830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 97/1000 [00:45<07:05,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4245 | Actual Loss: 1.2026\n",
      "Baseline Loss: 3.5371 | Actual Loss: 1.0227\n",
      "Baseline Loss: 3.9440 | Actual Loss: 0.8506\n",
      "Baseline Loss: 3.3882 | Actual Loss: 0.9814\n",
      "Baseline Loss: 3.3444 | Actual Loss: 1.1664\n",
      "Baseline Loss: 3.7525 | Actual Loss: 3.0926\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.0007\n",
      "Baseline Loss: 3.5836 | Actual Loss: 0.7298\n",
      "Baseline Loss: 3.5497 | Actual Loss: 1.1973\n",
      "Baseline Loss: 3.9021 | Actual Loss: 3.8348\n",
      "Epoch 98/1000: Train Loss: 1.0847, Val Loss: 1.6906\n",
      "\n",
      "Early stopping at epoch 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.353873461484909"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devices = [\"cuda\" if torch.cuda.is_available() else \"cpu\"]\n",
    "model6 = GNNModelWithNewLoss(\n",
    "        num_node_features=data_list[0].x.shape[1],\n",
    "        num_edge_features=data_list[0].edge_attr.shape[1],\n",
    "        num_global_features=data_list[0].global_features.shape[1],\n",
    "        cov_num= 6,\n",
    "        hidden_dim=512,\n",
    "        dropout_rate=0.1,\n",
    "        property_index= 2,\n",
    "        save_path= 'premodels_new/6/2' \n",
    "    ).to(devices[0])\n",
    "\n",
    "model6.train_model(\n",
    "    data_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b01e3575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training will be saved to: premodels_new/9/0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8051 | Actual Loss: 2.7725\n",
      "Baseline Loss: 2.8684 | Actual Loss: 2.7961\n",
      "Baseline Loss: 2.8865 | Actual Loss: 2.8234\n",
      "Baseline Loss: 2.8105 | Actual Loss: 2.7205\n",
      "Baseline Loss: 2.7908 | Actual Loss: 2.7488\n",
      "Baseline Loss: 2.7848 | Actual Loss: 2.7196\n",
      "Baseline Loss: 2.8026 | Actual Loss: 2.7548\n",
      "Baseline Loss: 2.8445 | Actual Loss: 2.7133\n",
      "Baseline Loss: 2.8622 | Actual Loss: 2.7861\n",
      "Baseline Loss: 2.8369 | Actual Loss: 2.7415\n",
      "Baseline Loss: 2.8555 | Actual Loss: 2.8004\n",
      "Baseline Loss: 2.9342 | Actual Loss: 2.8711\n",
      "Baseline Loss: 2.8706 | Actual Loss: 2.7648\n",
      "Baseline Loss: 2.8385 | Actual Loss: 2.7825\n",
      "Baseline Loss: 2.7956 | Actual Loss: 2.7603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 1/1000 [00:00<10:18,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5837 | Actual Loss: 2.5247\n",
      "Baseline Loss: 2.8420 | Actual Loss: 2.7692\n",
      "Baseline Loss: 2.7887 | Actual Loss: 2.6901\n",
      "Baseline Loss: 2.8632 | Actual Loss: 2.7459\n",
      "Baseline Loss: 2.7147 | Actual Loss: 2.6884\n",
      "Epoch 1/1000: Train Loss: 2.7550, Val Loss: 2.7234\n",
      "New best validation loss: 2.7234\n",
      "Baseline Loss: 2.7279 | Actual Loss: 2.6314\n",
      "Baseline Loss: 2.8304 | Actual Loss: 2.7308\n",
      "Baseline Loss: 2.8176 | Actual Loss: 2.7048\n",
      "Baseline Loss: 2.9580 | Actual Loss: 2.8542\n",
      "Baseline Loss: 2.8268 | Actual Loss: 2.7334\n",
      "Baseline Loss: 2.8221 | Actual Loss: 2.7024\n",
      "Baseline Loss: 2.8175 | Actual Loss: 2.6347\n",
      "Baseline Loss: 2.8618 | Actual Loss: 2.6516\n",
      "Baseline Loss: 2.8059 | Actual Loss: 2.7000\n",
      "Baseline Loss: 2.7682 | Actual Loss: 2.6186\n",
      "Baseline Loss: 2.8098 | Actual Loss: 2.6332\n",
      "Baseline Loss: 2.8150 | Actual Loss: 2.5918\n",
      "Baseline Loss: 2.8018 | Actual Loss: 2.5905\n",
      "Baseline Loss: 2.8438 | Actual Loss: 2.5313\n",
      "Baseline Loss: 2.8402 | Actual Loss: 2.6766\n",
      "Baseline Loss: 2.4741 | Actual Loss: 2.2847\n",
      "Baseline Loss: 2.8420 | Actual Loss: 2.6303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 2/1000 [00:01<10:03,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7887 | Actual Loss: 2.6263\n",
      "Baseline Loss: 2.8632 | Actual Loss: 2.6001\n",
      "Baseline Loss: 2.7147 | Actual Loss: 2.5404\n",
      "Epoch 2/1000: Train Loss: 2.6419, Val Loss: 2.5993\n",
      "New best validation loss: 2.5993\n",
      "Baseline Loss: 2.8069 | Actual Loss: 2.6066\n",
      "Baseline Loss: 2.7935 | Actual Loss: 2.4849\n",
      "Baseline Loss: 2.7739 | Actual Loss: 2.5618\n",
      "Baseline Loss: 2.9183 | Actual Loss: 2.7159\n",
      "Baseline Loss: 2.8405 | Actual Loss: 2.6017\n",
      "Baseline Loss: 2.8190 | Actual Loss: 2.7740\n",
      "Baseline Loss: 2.8807 | Actual Loss: 2.4915\n",
      "Baseline Loss: 2.7877 | Actual Loss: 2.4502\n",
      "Baseline Loss: 2.7538 | Actual Loss: 2.5414\n",
      "Baseline Loss: 2.7911 | Actual Loss: 2.5238\n",
      "Baseline Loss: 2.7987 | Actual Loss: 2.6277\n",
      "Baseline Loss: 2.9361 | Actual Loss: 2.3454\n",
      "Baseline Loss: 2.8370 | Actual Loss: 2.3765\n",
      "Baseline Loss: 2.8121 | Actual Loss: 2.4402\n",
      "Baseline Loss: 2.7610 | Actual Loss: 2.4439\n",
      "Baseline Loss: 2.4993 | Actual Loss: 1.9530\n",
      "Baseline Loss: 2.8420 | Actual Loss: 2.3744\n",
      "Baseline Loss: 2.7887 | Actual Loss: 2.2711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 3/1000 [00:01<09:16,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8632 | Actual Loss: 2.3688\n",
      "Baseline Loss: 2.7147 | Actual Loss: 2.2110\n",
      "Epoch 3/1000: Train Loss: 2.4962, Val Loss: 2.3063\n",
      "New best validation loss: 2.3063\n",
      "Baseline Loss: 2.8650 | Actual Loss: 2.4067\n",
      "Baseline Loss: 2.8064 | Actual Loss: 2.5315\n",
      "Baseline Loss: 2.7858 | Actual Loss: 2.2500\n",
      "Baseline Loss: 2.8989 | Actual Loss: 2.3553\n",
      "Baseline Loss: 2.8174 | Actual Loss: 2.2382\n",
      "Baseline Loss: 2.8631 | Actual Loss: 2.5922\n",
      "Baseline Loss: 2.8484 | Actual Loss: 2.5788\n",
      "Baseline Loss: 2.8666 | Actual Loss: 2.1941\n",
      "Baseline Loss: 2.8480 | Actual Loss: 2.2961\n",
      "Baseline Loss: 2.8012 | Actual Loss: 2.4548\n",
      "Baseline Loss: 2.8329 | Actual Loss: 1.9755\n",
      "Baseline Loss: 2.7735 | Actual Loss: 2.1125\n",
      "Baseline Loss: 2.8104 | Actual Loss: 2.2937\n",
      "Baseline Loss: 2.8074 | Actual Loss: 2.1868\n",
      "Baseline Loss: 2.8381 | Actual Loss: 2.1948\n",
      "Baseline Loss: 2.5607 | Actual Loss: 1.8973\n",
      "Baseline Loss: 2.8420 | Actual Loss: 2.1725\n",
      "Baseline Loss: 2.7887 | Actual Loss: 2.0453\n",
      "Baseline Loss: 2.8632 | Actual Loss: 2.0884\n",
      "Baseline Loss: 2.7147 | Actual Loss: 1.8468\n",
      "Epoch 4/1000: Train Loss: 2.2849, Val Loss: 2.0382\n",
      "New best validation loss: 2.0382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 4/1000 [00:02<09:36,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8136 | Actual Loss: 2.2394\n",
      "Baseline Loss: 2.9058 | Actual Loss: 2.2477\n",
      "Baseline Loss: 2.7625 | Actual Loss: 2.0406\n",
      "Baseline Loss: 2.7788 | Actual Loss: 2.2242\n",
      "Baseline Loss: 2.7958 | Actual Loss: 1.9781\n",
      "Baseline Loss: 2.8052 | Actual Loss: 1.9978\n",
      "Baseline Loss: 2.8425 | Actual Loss: 2.0449\n",
      "Baseline Loss: 2.7746 | Actual Loss: 2.5245\n",
      "Baseline Loss: 2.8857 | Actual Loss: 2.0718\n",
      "Baseline Loss: 2.7697 | Actual Loss: 2.2549\n",
      "Baseline Loss: 2.8473 | Actual Loss: 1.9093\n",
      "Baseline Loss: 2.9043 | Actual Loss: 2.0973\n",
      "Baseline Loss: 2.8688 | Actual Loss: 2.0868\n",
      "Baseline Loss: 2.7782 | Actual Loss: 2.0908\n",
      "Baseline Loss: 2.7990 | Actual Loss: 1.8998\n",
      "Baseline Loss: 2.6679 | Actual Loss: 1.9858\n",
      "Baseline Loss: 2.8420 | Actual Loss: 1.6615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 5/1000 [00:02<09:49,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7887 | Actual Loss: 2.0261\n",
      "Baseline Loss: 2.8632 | Actual Loss: 1.9968\n",
      "Baseline Loss: 2.7147 | Actual Loss: 1.8062\n",
      "Epoch 5/1000: Train Loss: 2.1058, Val Loss: 1.8726\n",
      "New best validation loss: 1.8726\n",
      "Baseline Loss: 2.9178 | Actual Loss: 1.9665\n",
      "Baseline Loss: 2.7758 | Actual Loss: 2.2123\n",
      "Baseline Loss: 2.8117 | Actual Loss: 2.1619\n",
      "Baseline Loss: 2.8056 | Actual Loss: 1.8643\n",
      "Baseline Loss: 2.7650 | Actual Loss: 2.0361\n",
      "Baseline Loss: 2.8989 | Actual Loss: 2.2840\n",
      "Baseline Loss: 2.8172 | Actual Loss: 1.9471\n",
      "Baseline Loss: 2.8797 | Actual Loss: 1.8406\n",
      "Baseline Loss: 2.7865 | Actual Loss: 2.3779\n",
      "Baseline Loss: 2.8277 | Actual Loss: 2.0414\n",
      "Baseline Loss: 2.8309 | Actual Loss: 1.8139\n",
      "Baseline Loss: 2.8498 | Actual Loss: 2.2704\n",
      "Baseline Loss: 2.8168 | Actual Loss: 2.1576\n",
      "Baseline Loss: 2.8356 | Actual Loss: 2.2500\n",
      "Baseline Loss: 2.7827 | Actual Loss: 1.6916\n",
      "Baseline Loss: 2.5036 | Actual Loss: 1.4289\n",
      "Baseline Loss: 2.8420 | Actual Loss: 1.6138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 6/1000 [00:03<09:23,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7887 | Actual Loss: 2.0350\n",
      "Baseline Loss: 2.8632 | Actual Loss: 1.9583\n",
      "Baseline Loss: 2.7147 | Actual Loss: 1.5703\n",
      "Epoch 6/1000: Train Loss: 2.0215, Val Loss: 1.7943\n",
      "New best validation loss: 1.7943\n",
      "Baseline Loss: 2.7866 | Actual Loss: 2.0730\n",
      "Baseline Loss: 2.8131 | Actual Loss: 2.0982\n",
      "Baseline Loss: 2.8737 | Actual Loss: 1.8273\n",
      "Baseline Loss: 2.8428 | Actual Loss: 1.5265\n",
      "Baseline Loss: 2.8199 | Actual Loss: 1.8519\n",
      "Baseline Loss: 2.8288 | Actual Loss: 1.8375\n",
      "Baseline Loss: 2.8540 | Actual Loss: 1.9405\n",
      "Baseline Loss: 2.8145 | Actual Loss: 1.6463\n",
      "Baseline Loss: 2.8271 | Actual Loss: 1.5788\n",
      "Baseline Loss: 2.8318 | Actual Loss: 2.2077\n",
      "Baseline Loss: 2.8684 | Actual Loss: 1.7139\n",
      "Baseline Loss: 2.8411 | Actual Loss: 2.0681\n",
      "Baseline Loss: 2.8330 | Actual Loss: 1.8901\n",
      "Baseline Loss: 2.8683 | Actual Loss: 2.0550\n",
      "Baseline Loss: 2.7882 | Actual Loss: 2.1564\n",
      "Baseline Loss: 2.5274 | Actual Loss: 1.6029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 7/1000 [00:04<09:23,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8420 | Actual Loss: 1.5861\n",
      "Baseline Loss: 2.7887 | Actual Loss: 2.0876\n",
      "Baseline Loss: 2.8632 | Actual Loss: 1.8072\n",
      "Baseline Loss: 2.7147 | Actual Loss: 1.7342\n",
      "Epoch 7/1000: Train Loss: 1.8796, Val Loss: 1.8038\n",
      "Baseline Loss: 2.8716 | Actual Loss: 2.0725\n",
      "Baseline Loss: 2.8315 | Actual Loss: 2.1800\n",
      "Baseline Loss: 2.8032 | Actual Loss: 1.8130\n",
      "Baseline Loss: 2.8312 | Actual Loss: 1.8207\n",
      "Baseline Loss: 2.8131 | Actual Loss: 1.5398\n",
      "Baseline Loss: 2.8065 | Actual Loss: 1.7148\n",
      "Baseline Loss: 2.8177 | Actual Loss: 1.7335\n",
      "Baseline Loss: 2.8628 | Actual Loss: 1.4031\n",
      "Baseline Loss: 2.8609 | Actual Loss: 1.9452\n",
      "Baseline Loss: 2.8326 | Actual Loss: 1.7563\n",
      "Baseline Loss: 2.9476 | Actual Loss: 2.1892\n",
      "Baseline Loss: 2.7562 | Actual Loss: 1.8890\n",
      "Baseline Loss: 2.8427 | Actual Loss: 1.6568\n",
      "Baseline Loss: 2.8557 | Actual Loss: 1.6656\n",
      "Baseline Loss: 2.7669 | Actual Loss: 1.6683\n",
      "Baseline Loss: 2.4589 | Actual Loss: 1.5894\n",
      "Baseline Loss: 2.8420 | Actual Loss: 1.8013\n",
      "Baseline Loss: 2.7887 | Actual Loss: 2.3473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 8/1000 [00:04<09:37,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8632 | Actual Loss: 1.6160\n",
      "Baseline Loss: 2.7147 | Actual Loss: 1.6976\n",
      "Epoch 8/1000: Train Loss: 1.7898, Val Loss: 1.8655\n",
      "Baseline Loss: 2.7853 | Actual Loss: 1.3576\n",
      "Baseline Loss: 2.8218 | Actual Loss: 1.7330\n",
      "Baseline Loss: 2.8568 | Actual Loss: 1.9496\n",
      "Baseline Loss: 2.8730 | Actual Loss: 2.0675\n",
      "Baseline Loss: 2.8194 | Actual Loss: 1.6633\n",
      "Baseline Loss: 2.8176 | Actual Loss: 1.9103\n",
      "Baseline Loss: 2.8247 | Actual Loss: 1.9881\n",
      "Baseline Loss: 2.7880 | Actual Loss: 1.7137\n",
      "Baseline Loss: 2.8056 | Actual Loss: 1.7807\n",
      "Baseline Loss: 2.8159 | Actual Loss: 1.4565\n",
      "Baseline Loss: 2.8178 | Actual Loss: 1.8651\n",
      "Baseline Loss: 2.8366 | Actual Loss: 1.9797\n",
      "Baseline Loss: 2.8515 | Actual Loss: 2.1558\n",
      "Baseline Loss: 2.7967 | Actual Loss: 1.2985\n",
      "Baseline Loss: 2.8705 | Actual Loss: 1.8891\n",
      "Baseline Loss: 2.6327 | Actual Loss: 1.5907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 9/1000 [00:05<09:10,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8420 | Actual Loss: 1.8531\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.9435\n",
      "Baseline Loss: 2.8632 | Actual Loss: 1.5773\n",
      "Baseline Loss: 2.7147 | Actual Loss: 1.7945\n",
      "Epoch 9/1000: Train Loss: 1.7750, Val Loss: 1.7921\n",
      "New best validation loss: 1.7921\n",
      "Baseline Loss: 2.9217 | Actual Loss: 2.3970\n",
      "Baseline Loss: 2.8835 | Actual Loss: 1.8949\n",
      "Baseline Loss: 2.8716 | Actual Loss: 1.4182\n",
      "Baseline Loss: 2.8260 | Actual Loss: 1.0441\n",
      "Baseline Loss: 2.8113 | Actual Loss: 1.3532\n",
      "Baseline Loss: 2.8013 | Actual Loss: 1.8002\n",
      "Baseline Loss: 2.8425 | Actual Loss: 1.8237\n",
      "Baseline Loss: 2.7517 | Actual Loss: 1.4089\n",
      "Baseline Loss: 2.8046 | Actual Loss: 1.5815\n",
      "Baseline Loss: 2.8590 | Actual Loss: 1.2126\n",
      "Baseline Loss: 2.8143 | Actual Loss: 1.6199\n",
      "Baseline Loss: 2.8501 | Actual Loss: 1.6903\n",
      "Baseline Loss: 2.8850 | Actual Loss: 1.4685\n",
      "Baseline Loss: 2.7987 | Actual Loss: 1.4012\n",
      "Baseline Loss: 2.8897 | Actual Loss: 0.9477\n",
      "Baseline Loss: 2.5083 | Actual Loss: 1.6390\n",
      "Baseline Loss: 2.8420 | Actual Loss: 1.4203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 10/1000 [00:05<09:21,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7887 | Actual Loss: 1.7104\n",
      "Baseline Loss: 2.8632 | Actual Loss: 1.2707\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.8691\n",
      "Epoch 10/1000: Train Loss: 1.5438, Val Loss: 1.3176\n",
      "New best validation loss: 1.3176\n",
      "Baseline Loss: 2.8329 | Actual Loss: 0.9630\n",
      "Baseline Loss: 2.8036 | Actual Loss: 1.5075\n",
      "Baseline Loss: 2.7703 | Actual Loss: 1.3510\n",
      "Baseline Loss: 2.8491 | Actual Loss: 1.1183\n",
      "Baseline Loss: 2.8071 | Actual Loss: 1.6168\n",
      "Baseline Loss: 2.8467 | Actual Loss: 1.4042\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.4278\n",
      "Baseline Loss: 2.8400 | Actual Loss: 1.3506\n",
      "Baseline Loss: 2.8666 | Actual Loss: 1.1652\n",
      "Baseline Loss: 2.8107 | Actual Loss: 1.0274\n",
      "Baseline Loss: 2.7456 | Actual Loss: 1.4988\n",
      "Baseline Loss: 2.8693 | Actual Loss: 1.3267\n",
      "Baseline Loss: 2.7850 | Actual Loss: 1.3033\n",
      "Baseline Loss: 2.8633 | Actual Loss: 1.2390\n",
      "Baseline Loss: 2.8747 | Actual Loss: 1.2995\n",
      "Baseline Loss: 2.4460 | Actual Loss: 1.0315\n",
      "Baseline Loss: 2.8420 | Actual Loss: 1.1746\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.2646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 11/1000 [00:06<09:28,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8632 | Actual Loss: 1.3231\n",
      "Baseline Loss: 2.7147 | Actual Loss: 1.0749\n",
      "Epoch 11/1000: Train Loss: 1.2894, Val Loss: 1.2093\n",
      "New best validation loss: 1.2093\n",
      "Baseline Loss: 2.9070 | Actual Loss: 1.6894\n",
      "Baseline Loss: 2.7768 | Actual Loss: 1.1412\n",
      "Baseline Loss: 2.8538 | Actual Loss: 1.4511\n",
      "Baseline Loss: 2.9200 | Actual Loss: 1.0764\n",
      "Baseline Loss: 2.8533 | Actual Loss: 1.1881\n",
      "Baseline Loss: 2.8823 | Actual Loss: 1.0456\n",
      "Baseline Loss: 2.8212 | Actual Loss: 1.2962\n",
      "Baseline Loss: 2.8148 | Actual Loss: 1.5608\n",
      "Baseline Loss: 2.7768 | Actual Loss: 1.4277\n",
      "Baseline Loss: 2.8606 | Actual Loss: 2.1891\n",
      "Baseline Loss: 2.7638 | Actual Loss: 1.1231\n",
      "Baseline Loss: 2.7824 | Actual Loss: 1.7578\n",
      "Baseline Loss: 2.8287 | Actual Loss: 1.6834\n",
      "Baseline Loss: 2.8119 | Actual Loss: 0.7820\n",
      "Baseline Loss: 2.8093 | Actual Loss: 1.1544\n",
      "Baseline Loss: 2.6995 | Actual Loss: 1.1037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 12/1000 [00:06<09:06,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8420 | Actual Loss: 1.3759\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.2564\n",
      "Baseline Loss: 2.8632 | Actual Loss: 1.0634\n",
      "Baseline Loss: 2.7147 | Actual Loss: 1.3354\n",
      "Epoch 12/1000: Train Loss: 1.3544, Val Loss: 1.2578\n",
      "Baseline Loss: 2.8621 | Actual Loss: 0.9287\n",
      "Baseline Loss: 2.8392 | Actual Loss: 1.1215\n",
      "Baseline Loss: 2.8012 | Actual Loss: 1.4282\n",
      "Baseline Loss: 2.8590 | Actual Loss: 1.4695\n",
      "Baseline Loss: 2.8463 | Actual Loss: 1.6131\n",
      "Baseline Loss: 2.8192 | Actual Loss: 1.2393\n",
      "Baseline Loss: 2.7294 | Actual Loss: 1.4179\n",
      "Baseline Loss: 2.7713 | Actual Loss: 1.1796\n",
      "Baseline Loss: 2.8059 | Actual Loss: 1.3435\n",
      "Baseline Loss: 2.8326 | Actual Loss: 1.0055\n",
      "Baseline Loss: 2.7556 | Actual Loss: 1.5277\n",
      "Baseline Loss: 2.8523 | Actual Loss: 0.9701\n",
      "Baseline Loss: 2.8954 | Actual Loss: 1.6025\n",
      "Baseline Loss: 2.8049 | Actual Loss: 1.4303\n",
      "Baseline Loss: 2.7883 | Actual Loss: 1.4508\n",
      "Baseline Loss: 2.5750 | Actual Loss: 1.6889\n",
      "Baseline Loss: 2.8420 | Actual Loss: 1.5722\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.2154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏         | 13/1000 [00:07<09:09,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8632 | Actual Loss: 1.1866\n",
      "Baseline Loss: 2.7147 | Actual Loss: 1.2607\n",
      "Epoch 13/1000: Train Loss: 1.3386, Val Loss: 1.3088\n",
      "Baseline Loss: 2.8875 | Actual Loss: 0.8049\n",
      "Baseline Loss: 2.8265 | Actual Loss: 1.1232\n",
      "Baseline Loss: 2.7964 | Actual Loss: 1.3065\n",
      "Baseline Loss: 2.7927 | Actual Loss: 1.1957\n",
      "Baseline Loss: 2.8519 | Actual Loss: 0.9000\n",
      "Baseline Loss: 2.8066 | Actual Loss: 1.3086\n",
      "Baseline Loss: 2.7937 | Actual Loss: 1.4322\n",
      "Baseline Loss: 2.8423 | Actual Loss: 1.3749\n",
      "Baseline Loss: 2.7999 | Actual Loss: 1.5579\n",
      "Baseline Loss: 2.8801 | Actual Loss: 1.4412\n",
      "Baseline Loss: 2.8171 | Actual Loss: 1.0414\n",
      "Baseline Loss: 2.8338 | Actual Loss: 1.0033\n",
      "Baseline Loss: 2.7492 | Actual Loss: 0.8953\n",
      "Baseline Loss: 2.7811 | Actual Loss: 1.6269\n",
      "Baseline Loss: 2.8191 | Actual Loss: 0.8393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏         | 14/1000 [00:07<08:59,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6082 | Actual Loss: 0.7855\n",
      "Baseline Loss: 2.8420 | Actual Loss: 1.2024\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.4813\n",
      "Baseline Loss: 2.8632 | Actual Loss: 1.5313\n",
      "Baseline Loss: 2.7147 | Actual Loss: 1.1670\n",
      "Epoch 14/1000: Train Loss: 1.1648, Val Loss: 1.3455\n",
      "Baseline Loss: 2.8408 | Actual Loss: 1.6089\n",
      "Baseline Loss: 2.7858 | Actual Loss: 1.2925\n",
      "Baseline Loss: 2.8673 | Actual Loss: 1.0063\n",
      "Baseline Loss: 2.8115 | Actual Loss: 0.9338\n",
      "Baseline Loss: 2.8698 | Actual Loss: 1.0978\n",
      "Baseline Loss: 2.7963 | Actual Loss: 0.9529\n",
      "Baseline Loss: 2.9322 | Actual Loss: 0.6116\n",
      "Baseline Loss: 2.8512 | Actual Loss: 1.1583\n",
      "Baseline Loss: 2.8071 | Actual Loss: 0.7314\n",
      "Baseline Loss: 2.9185 | Actual Loss: 0.9544\n",
      "Baseline Loss: 2.7695 | Actual Loss: 1.1299\n",
      "Baseline Loss: 2.8163 | Actual Loss: 0.9826\n",
      "Baseline Loss: 2.8157 | Actual Loss: 1.3101\n",
      "Baseline Loss: 2.8143 | Actual Loss: 1.4942\n",
      "Baseline Loss: 2.8012 | Actual Loss: 1.0919\n",
      "Baseline Loss: 2.5981 | Actual Loss: 1.1704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 15/1000 [00:08<09:17,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8420 | Actual Loss: 1.4075\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.9197\n",
      "Baseline Loss: 2.8632 | Actual Loss: 1.2571\n",
      "Baseline Loss: 2.7147 | Actual Loss: 1.0828\n",
      "Epoch 15/1000: Train Loss: 1.0954, Val Loss: 1.1668\n",
      "New best validation loss: 1.1668\n",
      "Baseline Loss: 2.8622 | Actual Loss: 1.1813\n",
      "Baseline Loss: 2.8168 | Actual Loss: 1.3507\n",
      "Baseline Loss: 2.8568 | Actual Loss: 1.1665\n",
      "Baseline Loss: 2.8468 | Actual Loss: 1.3226\n",
      "Baseline Loss: 2.8326 | Actual Loss: 1.2507\n",
      "Baseline Loss: 2.8491 | Actual Loss: 0.9354\n",
      "Baseline Loss: 2.7783 | Actual Loss: 0.9380\n",
      "Baseline Loss: 2.8715 | Actual Loss: 1.2769\n",
      "Baseline Loss: 2.8644 | Actual Loss: 1.6498\n",
      "Baseline Loss: 2.8053 | Actual Loss: 1.1054\n",
      "Baseline Loss: 2.8589 | Actual Loss: 1.7462\n",
      "Baseline Loss: 2.7991 | Actual Loss: 0.8348\n",
      "Baseline Loss: 2.8331 | Actual Loss: 1.4277\n",
      "Baseline Loss: 2.8483 | Actual Loss: 1.8564\n",
      "Baseline Loss: 2.8421 | Actual Loss: 0.7162\n",
      "Baseline Loss: 2.5751 | Actual Loss: 0.6132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 16/1000 [00:09<09:36,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8420 | Actual Loss: 1.1386\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.0767\n",
      "Baseline Loss: 2.8632 | Actual Loss: 1.0253\n",
      "Baseline Loss: 2.7147 | Actual Loss: 1.0087\n",
      "Epoch 16/1000: Train Loss: 1.2108, Val Loss: 1.0623\n",
      "New best validation loss: 1.0623\n",
      "Baseline Loss: 2.8114 | Actual Loss: 1.2557\n",
      "Baseline Loss: 2.8232 | Actual Loss: 1.1076\n",
      "Baseline Loss: 2.8177 | Actual Loss: 1.3075\n",
      "Baseline Loss: 2.8739 | Actual Loss: 1.0283\n",
      "Baseline Loss: 2.8754 | Actual Loss: 1.0250\n",
      "Baseline Loss: 2.7793 | Actual Loss: 0.7432\n",
      "Baseline Loss: 2.7755 | Actual Loss: 0.6830\n",
      "Baseline Loss: 2.8346 | Actual Loss: 0.9614\n",
      "Baseline Loss: 2.8233 | Actual Loss: 0.4556\n",
      "Baseline Loss: 2.8142 | Actual Loss: 1.1713\n",
      "Baseline Loss: 2.8727 | Actual Loss: 0.7358\n",
      "Baseline Loss: 2.8707 | Actual Loss: 1.8486\n",
      "Baseline Loss: 2.8205 | Actual Loss: 1.1871\n",
      "Baseline Loss: 2.8154 | Actual Loss: 1.8460\n",
      "Baseline Loss: 2.9459 | Actual Loss: 1.3108\n",
      "Baseline Loss: 2.6227 | Actual Loss: 1.8017\n",
      "Baseline Loss: 2.8420 | Actual Loss: 1.3902\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.1453\n",
      "Baseline Loss: 2.8632 | Actual Loss: 1.0792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 17/1000 [00:09<09:18,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7147 | Actual Loss: 0.7284\n",
      "Epoch 17/1000: Train Loss: 1.1543, Val Loss: 1.0858\n",
      "Baseline Loss: 2.8301 | Actual Loss: 1.2241\n",
      "Baseline Loss: 2.7790 | Actual Loss: 0.9337\n",
      "Baseline Loss: 2.8609 | Actual Loss: 1.1067\n",
      "Baseline Loss: 2.8474 | Actual Loss: 1.1444\n",
      "Baseline Loss: 2.7952 | Actual Loss: 0.8344\n",
      "Baseline Loss: 2.8392 | Actual Loss: 1.1927\n",
      "Baseline Loss: 2.7875 | Actual Loss: 1.1608\n",
      "Baseline Loss: 2.8266 | Actual Loss: 1.1963\n",
      "Baseline Loss: 2.7529 | Actual Loss: 1.2470\n",
      "Baseline Loss: 2.8993 | Actual Loss: 0.9657\n",
      "Baseline Loss: 2.7981 | Actual Loss: 0.9331\n",
      "Baseline Loss: 2.8590 | Actual Loss: 1.2268\n",
      "Baseline Loss: 2.7649 | Actual Loss: 1.0136\n",
      "Baseline Loss: 2.8242 | Actual Loss: 0.7358\n",
      "Baseline Loss: 2.8406 | Actual Loss: 1.2721\n",
      "Baseline Loss: 2.6150 | Actual Loss: 0.8558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 18/1000 [00:10<09:28,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8420 | Actual Loss: 1.4993\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.3445\n",
      "Baseline Loss: 2.8632 | Actual Loss: 1.7574\n",
      "Baseline Loss: 2.7147 | Actual Loss: 1.2606\n",
      "Epoch 18/1000: Train Loss: 1.0652, Val Loss: 1.4655\n",
      "Baseline Loss: 2.8294 | Actual Loss: 1.4347\n",
      "Baseline Loss: 2.8700 | Actual Loss: 2.4181\n",
      "Baseline Loss: 2.8194 | Actual Loss: 1.5947\n",
      "Baseline Loss: 2.7880 | Actual Loss: 1.6996\n",
      "Baseline Loss: 2.8240 | Actual Loss: 0.6476\n",
      "Baseline Loss: 2.8675 | Actual Loss: 1.0487\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.9334\n",
      "Baseline Loss: 2.8404 | Actual Loss: 0.9086\n",
      "Baseline Loss: 2.8913 | Actual Loss: 1.0184\n",
      "Baseline Loss: 2.7758 | Actual Loss: 0.7603\n",
      "Baseline Loss: 2.8113 | Actual Loss: 0.9946\n",
      "Baseline Loss: 2.8000 | Actual Loss: 0.9949\n",
      "Baseline Loss: 2.9153 | Actual Loss: 1.4519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 19/1000 [00:10<09:31,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7977 | Actual Loss: 1.2174\n",
      "Baseline Loss: 2.8163 | Actual Loss: 0.9080\n",
      "Baseline Loss: 2.6388 | Actual Loss: 0.7939\n",
      "Baseline Loss: 2.8420 | Actual Loss: 1.0738\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.1129\n",
      "Baseline Loss: 2.8632 | Actual Loss: 1.1071\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.9657\n",
      "Epoch 19/1000: Train Loss: 1.1765, Val Loss: 1.0649\n",
      "Baseline Loss: 2.7712 | Actual Loss: 0.8569\n",
      "Baseline Loss: 2.8106 | Actual Loss: 1.3793\n",
      "Baseline Loss: 2.8794 | Actual Loss: 0.7453\n",
      "Baseline Loss: 2.8118 | Actual Loss: 0.6174\n",
      "Baseline Loss: 2.8507 | Actual Loss: 1.1718\n",
      "Baseline Loss: 2.8600 | Actual Loss: 1.0426\n",
      "Baseline Loss: 2.8295 | Actual Loss: 0.9854\n",
      "Baseline Loss: 2.7671 | Actual Loss: 0.6469\n",
      "Baseline Loss: 2.8417 | Actual Loss: 0.9818\n",
      "Baseline Loss: 2.8510 | Actual Loss: 0.8255\n",
      "Baseline Loss: 2.8166 | Actual Loss: 1.0385\n",
      "Baseline Loss: 2.8785 | Actual Loss: 0.9505\n",
      "Baseline Loss: 2.7955 | Actual Loss: 0.8768\n",
      "Baseline Loss: 2.9055 | Actual Loss: 1.2449\n",
      "Baseline Loss: 2.8499 | Actual Loss: 1.2717\n",
      "Baseline Loss: 2.4348 | Actual Loss: 0.7249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 20/1000 [00:11<09:11,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8420 | Actual Loss: 1.1640\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.9855\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.8091\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.7028\n",
      "Epoch 20/1000: Train Loss: 0.9600, Val Loss: 0.9153\n",
      "New best validation loss: 0.9153\n",
      "Baseline Loss: 2.7773 | Actual Loss: 0.9759\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.9422\n",
      "Baseline Loss: 2.8317 | Actual Loss: 0.7500\n",
      "Baseline Loss: 2.8509 | Actual Loss: 0.8405\n",
      "Baseline Loss: 2.8129 | Actual Loss: 1.6517\n",
      "Baseline Loss: 2.8016 | Actual Loss: 1.2809\n",
      "Baseline Loss: 2.8577 | Actual Loss: 0.7682\n",
      "Baseline Loss: 2.8829 | Actual Loss: 1.1981\n",
      "Baseline Loss: 2.8288 | Actual Loss: 0.7300\n",
      "Baseline Loss: 2.7800 | Actual Loss: 0.8053\n",
      "Baseline Loss: 2.8595 | Actual Loss: 1.2005\n",
      "Baseline Loss: 2.7606 | Actual Loss: 0.8730\n",
      "Baseline Loss: 2.8096 | Actual Loss: 0.7355\n",
      "Baseline Loss: 2.8068 | Actual Loss: 1.3911\n",
      "Baseline Loss: 2.7927 | Actual Loss: 0.9603\n",
      "Baseline Loss: 2.5454 | Actual Loss: 0.2928\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.9407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 21/1000 [00:12<09:26,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7887 | Actual Loss: 1.0084\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.7974\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.8909\n",
      "Epoch 21/1000: Train Loss: 0.9623, Val Loss: 0.9094\n",
      "New best validation loss: 0.9094\n",
      "Baseline Loss: 2.7843 | Actual Loss: 1.1210\n",
      "Baseline Loss: 2.8098 | Actual Loss: 1.1220\n",
      "Baseline Loss: 2.7813 | Actual Loss: 1.0413\n",
      "Baseline Loss: 2.8006 | Actual Loss: 0.9005\n",
      "Baseline Loss: 2.8399 | Actual Loss: 0.8942\n",
      "Baseline Loss: 2.8379 | Actual Loss: 0.9807\n",
      "Baseline Loss: 2.8455 | Actual Loss: 0.6645\n",
      "Baseline Loss: 2.8400 | Actual Loss: 0.7542\n",
      "Baseline Loss: 2.7714 | Actual Loss: 0.3308\n",
      "Baseline Loss: 2.8236 | Actual Loss: 0.6447\n",
      "Baseline Loss: 2.7768 | Actual Loss: 0.7788\n",
      "Baseline Loss: 2.9732 | Actual Loss: 1.1632\n",
      "Baseline Loss: 2.8065 | Actual Loss: 0.5871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 22/1000 [00:12<09:06,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7921 | Actual Loss: 1.6286\n",
      "Baseline Loss: 2.8961 | Actual Loss: 0.6941\n",
      "Baseline Loss: 2.5472 | Actual Loss: 0.8413\n",
      "Baseline Loss: 2.8420 | Actual Loss: 1.1538\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.4627\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.7880\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.6519\n",
      "Epoch 22/1000: Train Loss: 0.8842, Val Loss: 1.0141\n",
      "Baseline Loss: 2.8200 | Actual Loss: 1.3855\n",
      "Baseline Loss: 2.8226 | Actual Loss: 1.0046\n",
      "Baseline Loss: 2.8338 | Actual Loss: 1.3556\n",
      "Baseline Loss: 2.8260 | Actual Loss: 0.9724\n",
      "Baseline Loss: 2.8425 | Actual Loss: 0.9967\n",
      "Baseline Loss: 2.8152 | Actual Loss: 0.9505\n",
      "Baseline Loss: 2.8479 | Actual Loss: 1.1913\n",
      "Baseline Loss: 2.8236 | Actual Loss: 1.1684\n",
      "Baseline Loss: 2.8326 | Actual Loss: 0.7243\n",
      "Baseline Loss: 2.7712 | Actual Loss: 0.6612\n",
      "Baseline Loss: 2.8618 | Actual Loss: 0.4000\n",
      "Baseline Loss: 2.8855 | Actual Loss: 0.7903\n",
      "Baseline Loss: 2.8003 | Actual Loss: 0.9429\n",
      "Baseline Loss: 2.7836 | Actual Loss: 0.8439\n",
      "Baseline Loss: 2.7584 | Actual Loss: 0.6069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 23/1000 [00:13<09:23,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.4819 | Actual Loss: 1.4817\n",
      "Baseline Loss: 2.8420 | Actual Loss: 1.0440\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.1674\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.7031\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.6228\n",
      "Epoch 23/1000: Train Loss: 0.9673, Val Loss: 0.8843\n",
      "New best validation loss: 0.8843\n",
      "Baseline Loss: 2.8210 | Actual Loss: 0.9368\n",
      "Baseline Loss: 2.8666 | Actual Loss: 0.6802\n",
      "Baseline Loss: 2.7894 | Actual Loss: 0.7391\n",
      "Baseline Loss: 2.8524 | Actual Loss: 0.9986\n",
      "Baseline Loss: 2.8830 | Actual Loss: 1.0541\n",
      "Baseline Loss: 2.8461 | Actual Loss: 0.7276\n",
      "Baseline Loss: 2.8813 | Actual Loss: 0.7587\n",
      "Baseline Loss: 2.8457 | Actual Loss: 0.7169\n",
      "Baseline Loss: 2.7775 | Actual Loss: 1.1880\n",
      "Baseline Loss: 2.8090 | Actual Loss: 0.4812\n",
      "Baseline Loss: 2.7522 | Actual Loss: 0.9699\n",
      "Baseline Loss: 2.7510 | Actual Loss: 0.8147\n",
      "Baseline Loss: 2.8501 | Actual Loss: 0.7789\n",
      "Baseline Loss: 2.8031 | Actual Loss: 0.7778\n",
      "Baseline Loss: 2.8364 | Actual Loss: 1.2095\n",
      "Baseline Loss: 2.6384 | Actual Loss: 0.3423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 24/1000 [00:13<09:30,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8420 | Actual Loss: 1.2230\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.0401\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.6944\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.6415\n",
      "Epoch 24/1000: Train Loss: 0.8234, Val Loss: 0.8997\n",
      "Baseline Loss: 2.7807 | Actual Loss: 0.6035\n",
      "Baseline Loss: 2.7617 | Actual Loss: 0.8706\n",
      "Baseline Loss: 2.7857 | Actual Loss: 0.9988\n",
      "Baseline Loss: 2.7728 | Actual Loss: 1.3484\n",
      "Baseline Loss: 2.8135 | Actual Loss: 0.6347\n",
      "Baseline Loss: 2.8477 | Actual Loss: 0.5900\n",
      "Baseline Loss: 2.8502 | Actual Loss: 0.7541\n",
      "Baseline Loss: 2.8497 | Actual Loss: 0.7946\n",
      "Baseline Loss: 2.8253 | Actual Loss: 1.1939\n",
      "Baseline Loss: 2.7910 | Actual Loss: 0.8956\n",
      "Baseline Loss: 2.8215 | Actual Loss: 0.5953\n",
      "Baseline Loss: 2.8560 | Actual Loss: 0.4950\n",
      "Baseline Loss: 2.8397 | Actual Loss: 0.9262\n",
      "Baseline Loss: 2.8825 | Actual Loss: 0.6176\n",
      "Baseline Loss: 2.8249 | Actual Loss: 1.9675\n",
      "Baseline Loss: 2.5637 | Actual Loss: 1.4619\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.9163\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.1217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▎         | 25/1000 [00:14<09:32,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8632 | Actual Loss: 0.6740\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.8336\n",
      "Epoch 25/1000: Train Loss: 0.9217, Val Loss: 0.8864\n",
      "Baseline Loss: 2.8074 | Actual Loss: 1.3533\n",
      "Baseline Loss: 2.8486 | Actual Loss: 0.4361\n",
      "Baseline Loss: 2.8886 | Actual Loss: 0.5224\n",
      "Baseline Loss: 2.8134 | Actual Loss: 0.8504\n",
      "Baseline Loss: 2.7862 | Actual Loss: 0.7997\n",
      "Baseline Loss: 2.7921 | Actual Loss: 1.0532\n",
      "Baseline Loss: 2.8164 | Actual Loss: 0.8673\n",
      "Baseline Loss: 2.8869 | Actual Loss: 1.0354\n",
      "Baseline Loss: 2.8617 | Actual Loss: 0.6737\n",
      "Baseline Loss: 2.8519 | Actual Loss: 1.3447\n",
      "Baseline Loss: 2.8440 | Actual Loss: 0.8579\n",
      "Baseline Loss: 2.8339 | Actual Loss: 0.9989\n",
      "Baseline Loss: 2.8895 | Actual Loss: 0.6803\n",
      "Baseline Loss: 2.8457 | Actual Loss: 0.8143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 26/1000 [00:14<09:18,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7726 | Actual Loss: 0.7331\n",
      "Baseline Loss: 2.5212 | Actual Loss: 0.6645\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.7438\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.0388\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.6780\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.5822\n",
      "Epoch 26/1000: Train Loss: 0.8553, Val Loss: 0.7607\n",
      "New best validation loss: 0.7607\n",
      "Baseline Loss: 2.8658 | Actual Loss: 0.5455\n",
      "Baseline Loss: 2.7745 | Actual Loss: 0.6966\n",
      "Baseline Loss: 2.8842 | Actual Loss: 0.7514\n",
      "Baseline Loss: 2.8568 | Actual Loss: 1.4282\n",
      "Baseline Loss: 2.8827 | Actual Loss: 1.1289\n",
      "Baseline Loss: 2.7841 | Actual Loss: 0.8278\n",
      "Baseline Loss: 2.8821 | Actual Loss: 0.7277\n",
      "Baseline Loss: 2.8587 | Actual Loss: 0.8425\n",
      "Baseline Loss: 2.8019 | Actual Loss: 0.7472\n",
      "Baseline Loss: 2.8850 | Actual Loss: 1.0342\n",
      "Baseline Loss: 2.8251 | Actual Loss: 0.3978\n",
      "Baseline Loss: 2.8338 | Actual Loss: 0.7534\n",
      "Baseline Loss: 2.8102 | Actual Loss: 0.9645\n",
      "Baseline Loss: 2.8697 | Actual Loss: 0.9135\n",
      "Baseline Loss: 2.7405 | Actual Loss: 1.1444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 27/1000 [00:15<09:30,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5377 | Actual Loss: 0.4160\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.9272\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.3589\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.6497\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.5963\n",
      "Epoch 27/1000: Train Loss: 0.8325, Val Loss: 0.8830\n",
      "Baseline Loss: 2.7737 | Actual Loss: 1.6262\n",
      "Baseline Loss: 2.8352 | Actual Loss: 0.6869\n",
      "Baseline Loss: 2.7526 | Actual Loss: 0.8249\n",
      "Baseline Loss: 2.9304 | Actual Loss: 0.7779\n",
      "Baseline Loss: 2.7926 | Actual Loss: 0.6966\n",
      "Baseline Loss: 2.9084 | Actual Loss: 0.6619\n",
      "Baseline Loss: 2.9259 | Actual Loss: 1.7910\n",
      "Baseline Loss: 2.8751 | Actual Loss: 0.6995\n",
      "Baseline Loss: 2.7810 | Actual Loss: 0.5053\n",
      "Baseline Loss: 2.7828 | Actual Loss: 0.8389\n",
      "Baseline Loss: 2.8919 | Actual Loss: 0.6454\n",
      "Baseline Loss: 2.8117 | Actual Loss: 0.7833\n",
      "Baseline Loss: 2.7974 | Actual Loss: 1.5738\n",
      "Baseline Loss: 2.8276 | Actual Loss: 0.6261\n",
      "Baseline Loss: 2.8061 | Actual Loss: 1.6807\n",
      "Baseline Loss: 2.5171 | Actual Loss: 2.0370\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.9527\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.8977\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.7476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 28/1000 [00:16<09:21,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7147 | Actual Loss: 0.5464\n",
      "Epoch 28/1000: Train Loss: 1.0285, Val Loss: 0.7861\n",
      "Baseline Loss: 2.8713 | Actual Loss: 0.8838\n",
      "Baseline Loss: 2.8237 | Actual Loss: 0.5212\n",
      "Baseline Loss: 2.7706 | Actual Loss: 0.7945\n",
      "Baseline Loss: 2.7997 | Actual Loss: 0.7361\n",
      "Baseline Loss: 2.8716 | Actual Loss: 0.8251\n",
      "Baseline Loss: 2.7883 | Actual Loss: 0.9599\n",
      "Baseline Loss: 2.8637 | Actual Loss: 0.9296\n",
      "Baseline Loss: 2.8402 | Actual Loss: 0.8752\n",
      "Baseline Loss: 2.8484 | Actual Loss: 0.7041\n",
      "Baseline Loss: 2.8298 | Actual Loss: 0.5501\n",
      "Baseline Loss: 2.8086 | Actual Loss: 0.7355\n",
      "Baseline Loss: 2.8307 | Actual Loss: 0.7200\n",
      "Baseline Loss: 2.9059 | Actual Loss: 1.8879\n",
      "Baseline Loss: 2.8205 | Actual Loss: 0.6714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 29/1000 [00:16<09:10,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7562 | Actual Loss: 0.6187\n",
      "Baseline Loss: 2.5092 | Actual Loss: 0.2713\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.8951\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.9066\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.5153\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4550\n",
      "Epoch 29/1000: Train Loss: 0.7928, Val Loss: 0.6930\n",
      "New best validation loss: 0.6930\n",
      "Baseline Loss: 2.8381 | Actual Loss: 0.5833\n",
      "Baseline Loss: 2.8832 | Actual Loss: 0.7631\n",
      "Baseline Loss: 2.7978 | Actual Loss: 1.4639\n",
      "Baseline Loss: 2.8196 | Actual Loss: 1.1640\n",
      "Baseline Loss: 2.8270 | Actual Loss: 0.7014\n",
      "Baseline Loss: 2.9000 | Actual Loss: 0.5722\n",
      "Baseline Loss: 2.7756 | Actual Loss: 0.6873\n",
      "Baseline Loss: 2.8546 | Actual Loss: 0.6239\n",
      "Baseline Loss: 2.8182 | Actual Loss: 0.7709\n",
      "Baseline Loss: 2.8191 | Actual Loss: 0.7363\n",
      "Baseline Loss: 2.8779 | Actual Loss: 0.5232\n",
      "Baseline Loss: 2.8781 | Actual Loss: 0.7648\n",
      "Baseline Loss: 2.7880 | Actual Loss: 0.8265\n",
      "Baseline Loss: 2.7677 | Actual Loss: 1.3554\n",
      "Baseline Loss: 2.8217 | Actual Loss: 1.8972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 30/1000 [00:17<09:15,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.4501 | Actual Loss: 0.5972\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.8919\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.0133\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.8631\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.6775\n",
      "Epoch 30/1000: Train Loss: 0.8769, Val Loss: 0.8615\n",
      "Baseline Loss: 2.8279 | Actual Loss: 0.6529\n",
      "Baseline Loss: 2.8327 | Actual Loss: 0.5501\n",
      "Baseline Loss: 2.8509 | Actual Loss: 0.5515\n",
      "Baseline Loss: 2.8010 | Actual Loss: 1.7878\n",
      "Baseline Loss: 2.7932 | Actual Loss: 0.6619\n",
      "Baseline Loss: 2.8026 | Actual Loss: 1.0442\n",
      "Baseline Loss: 2.7936 | Actual Loss: 0.6047\n",
      "Baseline Loss: 2.8188 | Actual Loss: 0.7760\n",
      "Baseline Loss: 2.8098 | Actual Loss: 0.8292\n",
      "Baseline Loss: 2.9083 | Actual Loss: 0.8617\n",
      "Baseline Loss: 2.8602 | Actual Loss: 0.5942\n",
      "Baseline Loss: 2.8210 | Actual Loss: 0.6905\n",
      "Baseline Loss: 2.8679 | Actual Loss: 0.7892\n",
      "Baseline Loss: 2.7612 | Actual Loss: 0.8076\n",
      "Baseline Loss: 2.8409 | Actual Loss: 0.8305\n",
      "Baseline Loss: 2.4486 | Actual Loss: 0.6685\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.9501\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.4102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 31/1000 [00:17<09:23,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8632 | Actual Loss: 0.8774\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.8338\n",
      "Epoch 31/1000: Train Loss: 0.7938, Val Loss: 1.0179\n",
      "Baseline Loss: 2.8270 | Actual Loss: 1.5882\n",
      "Baseline Loss: 2.8773 | Actual Loss: 0.5773\n",
      "Baseline Loss: 2.8138 | Actual Loss: 1.1001\n",
      "Baseline Loss: 2.9252 | Actual Loss: 0.7912\n",
      "Baseline Loss: 2.8852 | Actual Loss: 0.9649\n",
      "Baseline Loss: 2.8058 | Actual Loss: 0.9044\n",
      "Baseline Loss: 2.8575 | Actual Loss: 0.7288\n",
      "Baseline Loss: 2.7761 | Actual Loss: 1.0040\n",
      "Baseline Loss: 2.7816 | Actual Loss: 0.9537\n",
      "Baseline Loss: 2.8035 | Actual Loss: 0.7619\n",
      "Baseline Loss: 2.7888 | Actual Loss: 0.8860\n",
      "Baseline Loss: 2.8375 | Actual Loss: 0.7811\n",
      "Baseline Loss: 2.7910 | Actual Loss: 0.9051\n",
      "Baseline Loss: 2.7881 | Actual Loss: 0.8308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 32/1000 [00:18<09:05,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8578 | Actual Loss: 0.6250\n",
      "Baseline Loss: 2.5538 | Actual Loss: 0.8069\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.7336\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.2700\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.6809\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.6893\n",
      "Epoch 32/1000: Train Loss: 0.8881, Val Loss: 0.8434\n",
      "Baseline Loss: 2.8458 | Actual Loss: 0.7614\n",
      "Baseline Loss: 2.7526 | Actual Loss: 0.3844\n",
      "Baseline Loss: 2.8349 | Actual Loss: 1.1138\n",
      "Baseline Loss: 2.8174 | Actual Loss: 1.1979\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.8611\n",
      "Baseline Loss: 2.8205 | Actual Loss: 0.7541\n",
      "Baseline Loss: 2.9064 | Actual Loss: 0.7340\n",
      "Baseline Loss: 2.8253 | Actual Loss: 0.9200\n",
      "Baseline Loss: 2.8428 | Actual Loss: 0.8403\n",
      "Baseline Loss: 2.7827 | Actual Loss: 0.5171\n",
      "Baseline Loss: 2.7649 | Actual Loss: 0.5924\n",
      "Baseline Loss: 2.8047 | Actual Loss: 0.4782\n",
      "Baseline Loss: 2.8182 | Actual Loss: 0.7388\n",
      "Baseline Loss: 2.7896 | Actual Loss: 2.0338\n",
      "Baseline Loss: 2.8444 | Actual Loss: 0.7485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 33/1000 [00:18<09:17,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6278 | Actual Loss: 0.1545\n",
      "Baseline Loss: 2.8420 | Actual Loss: 1.0251\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.8865\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.6219\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.6896\n",
      "Epoch 33/1000: Train Loss: 0.8019, Val Loss: 0.8058\n",
      "Baseline Loss: 2.7505 | Actual Loss: 0.8024\n",
      "Baseline Loss: 2.8108 | Actual Loss: 0.7254\n",
      "Baseline Loss: 2.8277 | Actual Loss: 1.3002\n",
      "Baseline Loss: 2.7961 | Actual Loss: 0.9263\n",
      "Baseline Loss: 2.7501 | Actual Loss: 0.8664\n",
      "Baseline Loss: 2.7740 | Actual Loss: 0.4556\n",
      "Baseline Loss: 2.8048 | Actual Loss: 0.9178\n",
      "Baseline Loss: 2.8149 | Actual Loss: 0.4478\n",
      "Baseline Loss: 2.7489 | Actual Loss: 0.7033\n",
      "Baseline Loss: 2.9957 | Actual Loss: 0.8371\n",
      "Baseline Loss: 2.7264 | Actual Loss: 0.6494\n",
      "Baseline Loss: 2.8273 | Actual Loss: 1.3629\n",
      "Baseline Loss: 2.8445 | Actual Loss: 0.4363\n",
      "Baseline Loss: 2.8753 | Actual Loss: 0.9461\n",
      "Baseline Loss: 2.8844 | Actual Loss: 0.9292\n",
      "Baseline Loss: 2.7250 | Actual Loss: 0.2238\n",
      "Baseline Loss: 2.8420 | Actual Loss: 1.0947\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.0102\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.6218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 34/1000 [00:19<09:03,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7147 | Actual Loss: 0.4531\n",
      "Epoch 34/1000: Train Loss: 0.7831, Val Loss: 0.7950\n",
      "Baseline Loss: 2.8520 | Actual Loss: 1.2682\n",
      "Baseline Loss: 2.7979 | Actual Loss: 0.6453\n",
      "Baseline Loss: 2.7925 | Actual Loss: 0.2398\n",
      "Baseline Loss: 2.8561 | Actual Loss: 0.5768\n",
      "Baseline Loss: 2.8096 | Actual Loss: 0.9281\n",
      "Baseline Loss: 2.7746 | Actual Loss: 0.5839\n",
      "Baseline Loss: 2.7804 | Actual Loss: 0.8473\n",
      "Baseline Loss: 2.8530 | Actual Loss: 0.9377\n",
      "Baseline Loss: 2.7523 | Actual Loss: 0.7732\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.5675\n",
      "Baseline Loss: 2.9163 | Actual Loss: 0.7026\n",
      "Baseline Loss: 2.8318 | Actual Loss: 0.5830\n",
      "Baseline Loss: 2.8288 | Actual Loss: 0.4897\n",
      "Baseline Loss: 2.9030 | Actual Loss: 0.6095\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.8416\n",
      "Baseline Loss: 2.4996 | Actual Loss: 1.0461\n",
      "Baseline Loss: 2.8420 | Actual Loss: 1.1371\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.0201\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.4727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 35/1000 [00:20<09:18,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7147 | Actual Loss: 0.5390\n",
      "Epoch 35/1000: Train Loss: 0.7275, Val Loss: 0.7922\n",
      "Baseline Loss: 2.8244 | Actual Loss: 0.8413\n",
      "Baseline Loss: 2.8900 | Actual Loss: 1.1972\n",
      "Baseline Loss: 2.7916 | Actual Loss: 0.9628\n",
      "Baseline Loss: 2.8905 | Actual Loss: 0.8668\n",
      "Baseline Loss: 2.8157 | Actual Loss: 0.8971\n",
      "Baseline Loss: 2.9237 | Actual Loss: 0.7062\n",
      "Baseline Loss: 2.8015 | Actual Loss: 0.9334\n",
      "Baseline Loss: 2.7865 | Actual Loss: 0.8029\n",
      "Baseline Loss: 2.8563 | Actual Loss: 1.1185\n",
      "Baseline Loss: 2.8143 | Actual Loss: 0.7771\n",
      "Baseline Loss: 2.7845 | Actual Loss: 0.4172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 36/1000 [00:20<09:25,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8421 | Actual Loss: 0.5732\n",
      "Baseline Loss: 2.8509 | Actual Loss: 0.8399\n",
      "Baseline Loss: 2.7978 | Actual Loss: 0.9977\n",
      "Baseline Loss: 2.8651 | Actual Loss: 0.4985\n",
      "Baseline Loss: 2.5797 | Actual Loss: 0.4550\n",
      "Baseline Loss: 2.8420 | Actual Loss: 1.0070\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.1893\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.4731\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4795\n",
      "Epoch 36/1000: Train Loss: 0.8053, Val Loss: 0.7872\n",
      "Baseline Loss: 2.8546 | Actual Loss: 0.5783\n",
      "Baseline Loss: 2.9346 | Actual Loss: 0.7702\n",
      "Baseline Loss: 2.8711 | Actual Loss: 0.6988\n",
      "Baseline Loss: 2.8716 | Actual Loss: 0.6042\n",
      "Baseline Loss: 2.8411 | Actual Loss: 0.6933\n",
      "Baseline Loss: 2.9921 | Actual Loss: 1.0859\n",
      "Baseline Loss: 2.8143 | Actual Loss: 0.7580\n",
      "Baseline Loss: 2.8343 | Actual Loss: 0.6763\n",
      "Baseline Loss: 2.7868 | Actual Loss: 1.0114\n",
      "Baseline Loss: 2.8009 | Actual Loss: 0.4491\n",
      "Baseline Loss: 2.8035 | Actual Loss: 0.6246\n",
      "Baseline Loss: 2.7602 | Actual Loss: 0.7640\n",
      "Baseline Loss: 2.7659 | Actual Loss: 0.6900\n",
      "Baseline Loss: 2.7902 | Actual Loss: 0.7381\n",
      "Baseline Loss: 2.8409 | Actual Loss: 0.9151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 37/1000 [00:21<09:34,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.4678 | Actual Loss: 0.3737\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.9766\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.2607\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.5235\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.7576\n",
      "Epoch 37/1000: Train Loss: 0.7144, Val Loss: 0.8796\n",
      "Baseline Loss: 2.8520 | Actual Loss: 0.3791\n",
      "Baseline Loss: 2.8264 | Actual Loss: 0.6351\n",
      "Baseline Loss: 2.7771 | Actual Loss: 0.9094\n",
      "Baseline Loss: 2.8196 | Actual Loss: 0.7790\n",
      "Baseline Loss: 2.8440 | Actual Loss: 0.7549\n",
      "Baseline Loss: 2.8477 | Actual Loss: 0.4723\n",
      "Baseline Loss: 2.7883 | Actual Loss: 0.7920\n",
      "Baseline Loss: 2.8683 | Actual Loss: 0.6421\n",
      "Baseline Loss: 2.8137 | Actual Loss: 0.6377\n",
      "Baseline Loss: 2.8484 | Actual Loss: 0.8028\n",
      "Baseline Loss: 2.8030 | Actual Loss: 0.6693\n",
      "Baseline Loss: 2.8586 | Actual Loss: 0.4747\n",
      "Baseline Loss: 2.8225 | Actual Loss: 1.0116\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.6576\n",
      "Baseline Loss: 2.8246 | Actual Loss: 0.9532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 38/1000 [00:21<09:09,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5502 | Actual Loss: 0.6289\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.8146\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.6925\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.4821\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.5093\n",
      "Epoch 38/1000: Train Loss: 0.7000, Val Loss: 0.8746\n",
      "Baseline Loss: 2.7607 | Actual Loss: 0.9490\n",
      "Baseline Loss: 2.7923 | Actual Loss: 0.6264\n",
      "Baseline Loss: 2.8578 | Actual Loss: 0.5192\n",
      "Baseline Loss: 2.8941 | Actual Loss: 0.5072\n",
      "Baseline Loss: 2.8029 | Actual Loss: 0.8850\n",
      "Baseline Loss: 2.8447 | Actual Loss: 1.0109\n",
      "Baseline Loss: 2.8480 | Actual Loss: 0.9226\n",
      "Baseline Loss: 2.8329 | Actual Loss: 0.2296\n",
      "Baseline Loss: 2.8636 | Actual Loss: 0.1787\n",
      "Baseline Loss: 2.8211 | Actual Loss: 1.0302\n",
      "Baseline Loss: 2.8143 | Actual Loss: 0.9340\n",
      "Baseline Loss: 2.7966 | Actual Loss: 0.3969\n",
      "Baseline Loss: 2.7882 | Actual Loss: 0.5205\n",
      "Baseline Loss: 2.8599 | Actual Loss: 0.4830\n",
      "Baseline Loss: 2.8563 | Actual Loss: 0.7076\n",
      "Baseline Loss: 2.5800 | Actual Loss: 0.4988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 39/1000 [00:22<09:17,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8420 | Actual Loss: 0.8982\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.0833\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.6772\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4016\n",
      "Epoch 39/1000: Train Loss: 0.6500, Val Loss: 0.7651\n",
      "Baseline Loss: 2.7745 | Actual Loss: 0.5198\n",
      "Baseline Loss: 2.8327 | Actual Loss: 0.6954\n",
      "Baseline Loss: 2.8254 | Actual Loss: 0.7049\n",
      "Baseline Loss: 2.7911 | Actual Loss: 0.4616\n",
      "Baseline Loss: 2.8363 | Actual Loss: 0.9717\n",
      "Baseline Loss: 2.8131 | Actual Loss: 0.5677\n",
      "Baseline Loss: 2.8057 | Actual Loss: 1.1688\n",
      "Baseline Loss: 2.8372 | Actual Loss: 0.5287\n",
      "Baseline Loss: 2.8264 | Actual Loss: 0.6535\n",
      "Baseline Loss: 2.8083 | Actual Loss: 0.7995\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.5784\n",
      "Baseline Loss: 2.8947 | Actual Loss: 0.3065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 40/1000 [00:22<09:02,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8587 | Actual Loss: 1.2767\n",
      "Baseline Loss: 2.7729 | Actual Loss: 1.1556\n",
      "Baseline Loss: 2.8236 | Actual Loss: 0.8174\n",
      "Baseline Loss: 2.5288 | Actual Loss: 0.5576\n",
      "Baseline Loss: 2.8420 | Actual Loss: 1.0137\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.8966\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.6309\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4431\n",
      "Epoch 40/1000: Train Loss: 0.7353, Val Loss: 0.7460\n",
      "Baseline Loss: 2.8503 | Actual Loss: 0.4422\n",
      "Baseline Loss: 2.8502 | Actual Loss: 0.5953\n",
      "Baseline Loss: 2.7665 | Actual Loss: 0.6360\n",
      "Baseline Loss: 2.8404 | Actual Loss: 0.8051\n",
      "Baseline Loss: 2.8313 | Actual Loss: 0.6426\n",
      "Baseline Loss: 2.8093 | Actual Loss: 0.7245\n",
      "Baseline Loss: 2.8013 | Actual Loss: 0.6166\n",
      "Baseline Loss: 2.8335 | Actual Loss: 1.6808\n",
      "Baseline Loss: 2.8249 | Actual Loss: 0.4121\n",
      "Baseline Loss: 2.8565 | Actual Loss: 0.5319\n",
      "Baseline Loss: 2.8069 | Actual Loss: 0.9109\n",
      "Baseline Loss: 2.7952 | Actual Loss: 0.9293\n",
      "Baseline Loss: 2.8197 | Actual Loss: 0.5148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 41/1000 [00:23<09:08,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8547 | Actual Loss: 0.5239\n",
      "Baseline Loss: 2.7880 | Actual Loss: 2.8649\n",
      "Baseline Loss: 2.6013 | Actual Loss: 0.7267\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.7842\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.5735\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.5118\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.3117\n",
      "Epoch 41/1000: Train Loss: 0.8474, Val Loss: 0.7953\n",
      "Baseline Loss: 2.8971 | Actual Loss: 0.5852\n",
      "Baseline Loss: 2.7612 | Actual Loss: 1.9317\n",
      "Baseline Loss: 2.8020 | Actual Loss: 0.4959\n",
      "Baseline Loss: 2.8525 | Actual Loss: 0.2792\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.6350\n",
      "Baseline Loss: 2.8217 | Actual Loss: 0.5186\n",
      "Baseline Loss: 2.8096 | Actual Loss: 0.6326\n",
      "Baseline Loss: 2.8526 | Actual Loss: 0.4844\n",
      "Baseline Loss: 2.9616 | Actual Loss: 0.7538\n",
      "Baseline Loss: 2.8624 | Actual Loss: 0.5578\n",
      "Baseline Loss: 2.8018 | Actual Loss: 0.7164\n",
      "Baseline Loss: 2.7991 | Actual Loss: 0.4418\n",
      "Baseline Loss: 2.8312 | Actual Loss: 0.7375\n",
      "Baseline Loss: 2.7775 | Actual Loss: 0.6113\n",
      "Baseline Loss: 2.7734 | Actual Loss: 1.0497\n",
      "Baseline Loss: 2.6012 | Actual Loss: 3.1868\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.7438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 42/1000 [00:24<09:15,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7887 | Actual Loss: 1.4158\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.6672\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4666\n",
      "Epoch 42/1000: Train Loss: 0.8511, Val Loss: 0.8234\n",
      "Baseline Loss: 2.7829 | Actual Loss: 0.6122\n",
      "Baseline Loss: 2.8114 | Actual Loss: 0.7394\n",
      "Baseline Loss: 2.8858 | Actual Loss: 0.7503\n",
      "Baseline Loss: 2.8941 | Actual Loss: 0.7311\n",
      "Baseline Loss: 2.8068 | Actual Loss: 1.1741\n",
      "Baseline Loss: 2.7481 | Actual Loss: 1.0457\n",
      "Baseline Loss: 2.8286 | Actual Loss: 0.8559\n",
      "Baseline Loss: 2.8979 | Actual Loss: 0.5299\n",
      "Baseline Loss: 2.8512 | Actual Loss: 0.5544\n",
      "Baseline Loss: 2.8135 | Actual Loss: 0.6997\n",
      "Baseline Loss: 2.8075 | Actual Loss: 0.8244\n",
      "Baseline Loss: 2.8020 | Actual Loss: 0.6326\n",
      "Baseline Loss: 2.7672 | Actual Loss: 0.6533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 43/1000 [00:24<08:54,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8123 | Actual Loss: 0.4310\n",
      "Baseline Loss: 2.8265 | Actual Loss: 0.6634\n",
      "Baseline Loss: 2.6720 | Actual Loss: 0.7788\n",
      "Baseline Loss: 2.8420 | Actual Loss: 1.0167\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.4686\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.4939\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.6341\n",
      "Epoch 43/1000: Train Loss: 0.7298, Val Loss: 0.9033\n",
      "Baseline Loss: 2.8842 | Actual Loss: 0.6835\n",
      "Baseline Loss: 2.8953 | Actual Loss: 0.2688\n",
      "Baseline Loss: 2.8651 | Actual Loss: 0.7867\n",
      "Baseline Loss: 2.7836 | Actual Loss: 0.5075\n",
      "Baseline Loss: 2.8038 | Actual Loss: 0.5431\n",
      "Baseline Loss: 2.8301 | Actual Loss: 1.3267\n",
      "Baseline Loss: 2.7868 | Actual Loss: 0.5447\n",
      "Baseline Loss: 2.8751 | Actual Loss: 0.6465\n",
      "Baseline Loss: 2.8483 | Actual Loss: 0.4028\n",
      "Baseline Loss: 2.8138 | Actual Loss: 1.2296\n",
      "Baseline Loss: 2.8068 | Actual Loss: 0.6579\n",
      "Baseline Loss: 2.7866 | Actual Loss: 0.5683\n",
      "Baseline Loss: 2.8271 | Actual Loss: 0.7656\n",
      "Baseline Loss: 2.7959 | Actual Loss: 1.0802\n",
      "Baseline Loss: 2.9040 | Actual Loss: 1.3751\n",
      "Baseline Loss: 2.6473 | Actual Loss: 0.5723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 44/1000 [00:25<09:03,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8420 | Actual Loss: 1.0378\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.7971\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.4084\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4525\n",
      "Epoch 44/1000: Train Loss: 0.7475, Val Loss: 0.6739\n",
      "New best validation loss: 0.6739\n",
      "Baseline Loss: 2.7638 | Actual Loss: 1.1485\n",
      "Baseline Loss: 2.8048 | Actual Loss: 0.4289\n",
      "Baseline Loss: 2.7877 | Actual Loss: 0.6842\n",
      "Baseline Loss: 2.8059 | Actual Loss: 0.5953\n",
      "Baseline Loss: 2.8525 | Actual Loss: 0.7014\n",
      "Baseline Loss: 2.8586 | Actual Loss: 0.7448\n",
      "Baseline Loss: 2.8343 | Actual Loss: 0.8529\n",
      "Baseline Loss: 2.7806 | Actual Loss: 0.4054\n",
      "Baseline Loss: 2.8169 | Actual Loss: 0.6904\n",
      "Baseline Loss: 2.7925 | Actual Loss: 0.4933\n",
      "Baseline Loss: 2.8225 | Actual Loss: 0.6176\n",
      "Baseline Loss: 2.9520 | Actual Loss: 0.5146\n",
      "Baseline Loss: 2.8795 | Actual Loss: 0.9664\n",
      "Baseline Loss: 2.8196 | Actual Loss: 0.6993\n",
      "Baseline Loss: 2.8390 | Actual Loss: 0.3317\n",
      "Baseline Loss: 2.5207 | Actual Loss: 0.9358\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.8486\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.1411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 45/1000 [00:25<09:04,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8632 | Actual Loss: 0.5175\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4574\n",
      "Epoch 45/1000: Train Loss: 0.6757, Val Loss: 0.7411\n",
      "Baseline Loss: 2.7812 | Actual Loss: 0.2537\n",
      "Baseline Loss: 2.8157 | Actual Loss: 0.9468\n",
      "Baseline Loss: 2.8508 | Actual Loss: 0.6440\n",
      "Baseline Loss: 2.7902 | Actual Loss: 1.0620\n",
      "Baseline Loss: 2.7195 | Actual Loss: 0.5574\n",
      "Baseline Loss: 2.7661 | Actual Loss: 0.5672\n",
      "Baseline Loss: 2.8952 | Actual Loss: 0.7444\n",
      "Baseline Loss: 2.7680 | Actual Loss: 0.7853\n",
      "Baseline Loss: 2.7883 | Actual Loss: 0.6795\n",
      "Baseline Loss: 2.8591 | Actual Loss: 0.6058\n",
      "Baseline Loss: 2.7925 | Actual Loss: 0.7579\n",
      "Baseline Loss: 2.8229 | Actual Loss: 0.6117\n",
      "Baseline Loss: 2.8883 | Actual Loss: 3.0349\n",
      "Baseline Loss: 2.8829 | Actual Loss: 0.9879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 46/1000 [00:26<08:42,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8130 | Actual Loss: 0.7380\n",
      "Baseline Loss: 2.6129 | Actual Loss: 0.1850\n",
      "Baseline Loss: 2.8420 | Actual Loss: 1.0270\n",
      "Baseline Loss: 2.7887 | Actual Loss: 2.1257\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.7466\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4733\n",
      "Epoch 46/1000: Train Loss: 0.8226, Val Loss: 1.0932\n",
      "Baseline Loss: 2.8791 | Actual Loss: 0.7595\n",
      "Baseline Loss: 2.8302 | Actual Loss: 0.6648\n",
      "Baseline Loss: 2.8805 | Actual Loss: 0.5906\n",
      "Baseline Loss: 2.8326 | Actual Loss: 1.1870\n",
      "Baseline Loss: 2.8497 | Actual Loss: 0.6564\n",
      "Baseline Loss: 2.8043 | Actual Loss: 0.5028\n",
      "Baseline Loss: 2.8889 | Actual Loss: 0.3288\n",
      "Baseline Loss: 2.8638 | Actual Loss: 1.3836\n",
      "Baseline Loss: 2.8077 | Actual Loss: 0.8871\n",
      "Baseline Loss: 2.7483 | Actual Loss: 0.5314\n",
      "Baseline Loss: 2.8194 | Actual Loss: 0.3833\n",
      "Baseline Loss: 2.8991 | Actual Loss: 0.7174\n",
      "Baseline Loss: 2.7934 | Actual Loss: 0.5120\n",
      "Baseline Loss: 2.8558 | Actual Loss: 1.1671\n",
      "Baseline Loss: 2.7825 | Actual Loss: 0.6145\n",
      "Baseline Loss: 2.5987 | Actual Loss: 0.4064\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.9256\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.9635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 47/1000 [00:26<09:01,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8632 | Actual Loss: 0.5132\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4040\n",
      "Epoch 47/1000: Train Loss: 0.7058, Val Loss: 0.9515\n",
      "Baseline Loss: 2.7974 | Actual Loss: 0.5891\n",
      "Baseline Loss: 2.7590 | Actual Loss: 0.6427\n",
      "Baseline Loss: 2.7584 | Actual Loss: 0.5076\n",
      "Baseline Loss: 2.7755 | Actual Loss: 0.7976\n",
      "Baseline Loss: 2.8454 | Actual Loss: 0.5964\n",
      "Baseline Loss: 2.8850 | Actual Loss: 0.6924\n",
      "Baseline Loss: 2.8955 | Actual Loss: 0.8889\n",
      "Baseline Loss: 2.7279 | Actual Loss: 0.7404\n",
      "Baseline Loss: 2.8251 | Actual Loss: 0.9030\n",
      "Baseline Loss: 2.8176 | Actual Loss: 0.4439\n",
      "Baseline Loss: 2.8502 | Actual Loss: 0.1938\n",
      "Baseline Loss: 2.9036 | Actual Loss: 0.6197\n",
      "Baseline Loss: 2.7656 | Actual Loss: 0.5924\n",
      "Baseline Loss: 2.8366 | Actual Loss: 0.5723\n",
      "Baseline Loss: 2.8100 | Actual Loss: 0.6347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 48/1000 [00:27<08:46,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.4683 | Actual Loss: 0.3563\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.9147\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.8474\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.4442\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4002\n",
      "Epoch 48/1000: Train Loss: 0.6107, Val Loss: 0.6516\n",
      "New best validation loss: 0.6516\n",
      "Baseline Loss: 2.8569 | Actual Loss: 0.6298\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.8305\n",
      "Baseline Loss: 2.8996 | Actual Loss: 0.5549\n",
      "Baseline Loss: 2.8162 | Actual Loss: 0.7667\n",
      "Baseline Loss: 2.7842 | Actual Loss: 0.6317\n",
      "Baseline Loss: 2.8796 | Actual Loss: 0.7195\n",
      "Baseline Loss: 2.8244 | Actual Loss: 0.8135\n",
      "Baseline Loss: 2.7733 | Actual Loss: 0.4805\n",
      "Baseline Loss: 2.7956 | Actual Loss: 2.8442\n",
      "Baseline Loss: 2.7672 | Actual Loss: 0.8397\n",
      "Baseline Loss: 2.8766 | Actual Loss: 1.8643\n",
      "Baseline Loss: 2.7670 | Actual Loss: 2.7319\n",
      "Baseline Loss: 2.8406 | Actual Loss: 0.9378\n",
      "Baseline Loss: 2.7724 | Actual Loss: 2.1553\n",
      "Baseline Loss: 2.7909 | Actual Loss: 0.8187\n",
      "Baseline Loss: 2.8348 | Actual Loss: 2.6950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 49/1000 [00:27<08:50,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8420 | Actual Loss: 0.9514\n",
      "Baseline Loss: 2.7887 | Actual Loss: 2.1441\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.5793\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.6305\n",
      "Epoch 49/1000: Train Loss: 1.2696, Val Loss: 1.0763\n",
      "Baseline Loss: 2.8888 | Actual Loss: 1.9758\n",
      "Baseline Loss: 2.8096 | Actual Loss: 0.2928\n",
      "Baseline Loss: 2.7733 | Actual Loss: 0.7259\n",
      "Baseline Loss: 2.9035 | Actual Loss: 0.4428\n",
      "Baseline Loss: 2.8539 | Actual Loss: 0.3166\n",
      "Baseline Loss: 2.7864 | Actual Loss: 0.6211\n",
      "Baseline Loss: 2.8293 | Actual Loss: 1.0369\n",
      "Baseline Loss: 2.7994 | Actual Loss: 0.7316\n",
      "Baseline Loss: 2.8217 | Actual Loss: 0.4477\n",
      "Baseline Loss: 2.7633 | Actual Loss: 0.8013\n",
      "Baseline Loss: 2.8290 | Actual Loss: 0.6221\n",
      "Baseline Loss: 2.8479 | Actual Loss: 0.3335\n",
      "Baseline Loss: 2.9082 | Actual Loss: 0.5577\n",
      "Baseline Loss: 2.8016 | Actual Loss: 0.6185\n",
      "Baseline Loss: 2.8060 | Actual Loss: 0.7076\n",
      "Baseline Loss: 2.4362 | Actual Loss: 0.7466\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.8417\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.6260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 50/1000 [00:28<09:12,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8632 | Actual Loss: 0.4158\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.9707\n",
      "Epoch 50/1000: Train Loss: 0.6862, Val Loss: 0.9636\n",
      "Baseline Loss: 2.7927 | Actual Loss: 2.3545\n",
      "Baseline Loss: 2.8793 | Actual Loss: 0.7121\n",
      "Baseline Loss: 2.7753 | Actual Loss: 0.6683\n",
      "Baseline Loss: 2.8812 | Actual Loss: 0.8982\n",
      "Baseline Loss: 2.9146 | Actual Loss: 1.7205\n",
      "Baseline Loss: 2.8264 | Actual Loss: 0.7225\n",
      "Baseline Loss: 2.8224 | Actual Loss: 0.7162\n",
      "Baseline Loss: 2.7599 | Actual Loss: 0.5626\n",
      "Baseline Loss: 2.8753 | Actual Loss: 0.3604\n",
      "Baseline Loss: 2.8076 | Actual Loss: 0.4567\n",
      "Baseline Loss: 2.8791 | Actual Loss: 0.2778\n",
      "Baseline Loss: 2.8835 | Actual Loss: 2.6610\n",
      "Baseline Loss: 2.8665 | Actual Loss: 0.7526\n",
      "Baseline Loss: 2.7239 | Actual Loss: 0.4856\n",
      "Baseline Loss: 2.8289 | Actual Loss: 0.7476\n",
      "Baseline Loss: 2.5114 | Actual Loss: 0.3943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 51/1000 [00:29<09:08,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8420 | Actual Loss: 0.8953\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.8732\n",
      "Baseline Loss: 2.8632 | Actual Loss: 1.0115\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.8859\n",
      "Epoch 51/1000: Train Loss: 0.9057, Val Loss: 1.1665\n",
      "Baseline Loss: 2.8035 | Actual Loss: 0.2824\n",
      "Baseline Loss: 2.7237 | Actual Loss: 0.3989\n",
      "Baseline Loss: 2.8174 | Actual Loss: 0.5093\n",
      "Baseline Loss: 2.8784 | Actual Loss: 0.7661\n",
      "Baseline Loss: 2.8508 | Actual Loss: 1.0720\n",
      "Baseline Loss: 2.7799 | Actual Loss: 0.2166\n",
      "Baseline Loss: 2.8708 | Actual Loss: 0.4128\n",
      "Baseline Loss: 2.8740 | Actual Loss: 0.5480\n",
      "Baseline Loss: 2.8970 | Actual Loss: 0.8645\n",
      "Baseline Loss: 2.8061 | Actual Loss: 0.3315\n",
      "Baseline Loss: 2.8768 | Actual Loss: 0.5040\n",
      "Baseline Loss: 2.8937 | Actual Loss: 0.4600\n",
      "Baseline Loss: 2.8508 | Actual Loss: 0.6623\n",
      "Baseline Loss: 2.8143 | Actual Loss: 0.3268\n",
      "Baseline Loss: 2.8034 | Actual Loss: 0.6275\n",
      "Baseline Loss: 2.5020 | Actual Loss: 0.9826\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.6832\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.7963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 52/1000 [00:29<08:48,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8632 | Actual Loss: 0.3999\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.5957\n",
      "Epoch 52/1000: Train Loss: 0.5603, Val Loss: 0.8688\n",
      "Baseline Loss: 2.8620 | Actual Loss: 0.9521\n",
      "Baseline Loss: 2.8150 | Actual Loss: 0.4227\n",
      "Baseline Loss: 2.8096 | Actual Loss: 0.5022\n",
      "Baseline Loss: 2.8439 | Actual Loss: 1.7891\n",
      "Baseline Loss: 2.7974 | Actual Loss: 0.4051\n",
      "Baseline Loss: 2.7948 | Actual Loss: 0.9687\n",
      "Baseline Loss: 2.7721 | Actual Loss: 0.4592\n",
      "Baseline Loss: 2.7783 | Actual Loss: 0.7409\n",
      "Baseline Loss: 2.8842 | Actual Loss: 0.3781\n",
      "Baseline Loss: 2.8248 | Actual Loss: 2.4834\n",
      "Baseline Loss: 2.9094 | Actual Loss: 0.2749\n",
      "Baseline Loss: 2.8217 | Actual Loss: 1.0610\n",
      "Baseline Loss: 2.7759 | Actual Loss: 2.1134\n",
      "Baseline Loss: 2.8358 | Actual Loss: 0.4197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 53/1000 [00:30<09:01,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7946 | Actual Loss: 2.3592\n",
      "Baseline Loss: 2.4545 | Actual Loss: 0.3752\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.6758\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.9129\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.5145\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.3762\n",
      "Epoch 53/1000: Train Loss: 0.9816, Val Loss: 0.6198\n",
      "New best validation loss: 0.6198\n",
      "Baseline Loss: 2.7743 | Actual Loss: 0.5699\n",
      "Baseline Loss: 2.8057 | Actual Loss: 0.5548\n",
      "Baseline Loss: 2.7927 | Actual Loss: 1.0262\n",
      "Baseline Loss: 2.8104 | Actual Loss: 0.4126\n",
      "Baseline Loss: 2.8633 | Actual Loss: 0.4212\n",
      "Baseline Loss: 2.8176 | Actual Loss: 0.9429\n",
      "Baseline Loss: 2.8569 | Actual Loss: 0.6237\n",
      "Baseline Loss: 2.8060 | Actual Loss: 0.4683\n",
      "Baseline Loss: 2.8780 | Actual Loss: 0.5558\n",
      "Baseline Loss: 2.7694 | Actual Loss: 0.5265\n",
      "Baseline Loss: 2.8513 | Actual Loss: 0.6005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 54/1000 [00:30<08:38,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7921 | Actual Loss: 0.5063\n",
      "Baseline Loss: 2.8069 | Actual Loss: 0.8945\n",
      "Baseline Loss: 2.9362 | Actual Loss: 0.7509\n",
      "Baseline Loss: 2.8789 | Actual Loss: 0.3841\n",
      "Baseline Loss: 2.5033 | Actual Loss: 0.6019\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.8398\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.4350\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.5546\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.7152\n",
      "Epoch 54/1000: Train Loss: 0.6150, Val Loss: 0.8861\n",
      "Baseline Loss: 2.8734 | Actual Loss: 1.1291\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.3074\n",
      "Baseline Loss: 2.8294 | Actual Loss: 0.6974\n",
      "Baseline Loss: 2.8512 | Actual Loss: 0.5485\n",
      "Baseline Loss: 2.8076 | Actual Loss: 0.8833\n",
      "Baseline Loss: 2.8314 | Actual Loss: 0.7888\n",
      "Baseline Loss: 2.8757 | Actual Loss: 0.5582\n",
      "Baseline Loss: 2.8366 | Actual Loss: 0.7074\n",
      "Baseline Loss: 2.7035 | Actual Loss: 0.4556\n",
      "Baseline Loss: 2.8180 | Actual Loss: 0.2966\n",
      "Baseline Loss: 2.8368 | Actual Loss: 0.3499\n",
      "Baseline Loss: 2.8262 | Actual Loss: 0.8085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 55/1000 [00:31<08:53,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8080 | Actual Loss: 0.4067\n",
      "Baseline Loss: 2.8699 | Actual Loss: 1.0471\n",
      "Baseline Loss: 2.8052 | Actual Loss: 0.8765\n",
      "Baseline Loss: 2.6185 | Actual Loss: 0.5798\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.6799\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.3358\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.4379\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.6730\n",
      "Epoch 55/1000: Train Loss: 0.6526, Val Loss: 0.7816\n",
      "Baseline Loss: 2.9029 | Actual Loss: 0.5555\n",
      "Baseline Loss: 2.8089 | Actual Loss: 0.6390\n",
      "Baseline Loss: 2.7876 | Actual Loss: 0.5246\n",
      "Baseline Loss: 2.8836 | Actual Loss: 1.3697\n",
      "Baseline Loss: 2.8366 | Actual Loss: 0.8770\n",
      "Baseline Loss: 2.8411 | Actual Loss: 0.4916\n",
      "Baseline Loss: 2.7966 | Actual Loss: 0.6870\n",
      "Baseline Loss: 2.8071 | Actual Loss: 0.6271\n",
      "Baseline Loss: 2.8831 | Actual Loss: 0.6274\n",
      "Baseline Loss: 2.7813 | Actual Loss: 0.6665\n",
      "Baseline Loss: 2.8461 | Actual Loss: 0.6613\n",
      "Baseline Loss: 2.8462 | Actual Loss: 0.2394\n",
      "Baseline Loss: 2.7966 | Actual Loss: 0.6890\n",
      "Baseline Loss: 2.7875 | Actual Loss: 0.3877\n",
      "Baseline Loss: 2.8188 | Actual Loss: 0.3833\n",
      "Baseline Loss: 2.4162 | Actual Loss: 2.1404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 56/1000 [00:31<08:55,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8420 | Actual Loss: 0.8253\n",
      "Baseline Loss: 2.7887 | Actual Loss: 2.3911\n",
      "Baseline Loss: 2.8632 | Actual Loss: 2.0879\n",
      "Baseline Loss: 2.7147 | Actual Loss: 1.4522\n",
      "Epoch 56/1000: Train Loss: 0.7229, Val Loss: 1.6891\n",
      "Baseline Loss: 2.8919 | Actual Loss: 1.3507\n",
      "Baseline Loss: 2.7931 | Actual Loss: 2.6312\n",
      "Baseline Loss: 2.9147 | Actual Loss: 2.7763\n",
      "Baseline Loss: 2.8013 | Actual Loss: 0.6818\n",
      "Baseline Loss: 2.8537 | Actual Loss: 1.3654\n",
      "Baseline Loss: 2.7370 | Actual Loss: 0.5075\n",
      "Baseline Loss: 2.7909 | Actual Loss: 2.4415\n",
      "Baseline Loss: 2.8492 | Actual Loss: 1.8027\n",
      "Baseline Loss: 2.7998 | Actual Loss: 0.3979\n",
      "Baseline Loss: 2.9155 | Actual Loss: 0.6779\n",
      "Baseline Loss: 2.8050 | Actual Loss: 0.5414\n",
      "Baseline Loss: 2.7865 | Actual Loss: 0.5765\n",
      "Baseline Loss: 2.8015 | Actual Loss: 2.4640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 57/1000 [00:32<08:36,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9168 | Actual Loss: 0.5729\n",
      "Baseline Loss: 2.8127 | Actual Loss: 0.4183\n",
      "Baseline Loss: 2.5583 | Actual Loss: 0.7517\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.7951\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.1944\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.5504\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4491\n",
      "Epoch 57/1000: Train Loss: 1.2474, Val Loss: 0.7473\n",
      "Baseline Loss: 2.7823 | Actual Loss: 0.6080\n",
      "Baseline Loss: 2.7993 | Actual Loss: 0.8155\n",
      "Baseline Loss: 2.7994 | Actual Loss: 0.4468\n",
      "Baseline Loss: 2.7780 | Actual Loss: 0.4497\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.4604\n",
      "Baseline Loss: 2.8792 | Actual Loss: 0.7258\n",
      "Baseline Loss: 2.8887 | Actual Loss: 1.0742\n",
      "Baseline Loss: 2.8110 | Actual Loss: 0.3647\n",
      "Baseline Loss: 2.8165 | Actual Loss: 0.3579\n",
      "Baseline Loss: 2.7682 | Actual Loss: 0.5717\n",
      "Baseline Loss: 2.7877 | Actual Loss: 0.5167\n",
      "Baseline Loss: 2.8586 | Actual Loss: 1.4070\n",
      "Baseline Loss: 2.8800 | Actual Loss: 0.9272\n",
      "Baseline Loss: 2.8414 | Actual Loss: 0.8274\n",
      "Baseline Loss: 2.7420 | Actual Loss: 0.8280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 58/1000 [00:33<08:41,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5890 | Actual Loss: 2.4905\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.6824\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.7653\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2979\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.6558\n",
      "Epoch 58/1000: Train Loss: 0.8045, Val Loss: 0.8504\n",
      "Baseline Loss: 2.8525 | Actual Loss: 0.7788\n",
      "Baseline Loss: 2.8250 | Actual Loss: 0.7295\n",
      "Baseline Loss: 2.8458 | Actual Loss: 0.5925\n",
      "Baseline Loss: 2.8041 | Actual Loss: 0.7668\n",
      "Baseline Loss: 2.8895 | Actual Loss: 0.2529\n",
      "Baseline Loss: 2.8643 | Actual Loss: 0.4872\n",
      "Baseline Loss: 2.9361 | Actual Loss: 1.0075\n",
      "Baseline Loss: 2.7330 | Actual Loss: 0.4000\n",
      "Baseline Loss: 2.8379 | Actual Loss: 0.9773\n",
      "Baseline Loss: 2.8818 | Actual Loss: 0.5074\n",
      "Baseline Loss: 2.7968 | Actual Loss: 2.1954\n",
      "Baseline Loss: 2.8390 | Actual Loss: 0.8647\n",
      "Baseline Loss: 2.8025 | Actual Loss: 0.7660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 59/1000 [00:33<08:50,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7916 | Actual Loss: 0.8501\n",
      "Baseline Loss: 2.8128 | Actual Loss: 0.4036\n",
      "Baseline Loss: 2.5262 | Actual Loss: 0.9054\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.7768\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.6436\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.5237\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4428\n",
      "Epoch 59/1000: Train Loss: 0.7803, Val Loss: 0.5967\n",
      "New best validation loss: 0.5967\n",
      "Baseline Loss: 2.7792 | Actual Loss: 0.5087\n",
      "Baseline Loss: 2.7940 | Actual Loss: 0.9477\n",
      "Baseline Loss: 2.8443 | Actual Loss: 0.6919\n",
      "Baseline Loss: 2.8029 | Actual Loss: 1.2461\n",
      "Baseline Loss: 2.8604 | Actual Loss: 0.7985\n",
      "Baseline Loss: 2.8282 | Actual Loss: 0.3743\n",
      "Baseline Loss: 2.8711 | Actual Loss: 2.4872\n",
      "Baseline Loss: 2.8258 | Actual Loss: 0.4993\n",
      "Baseline Loss: 2.8473 | Actual Loss: 0.9918\n",
      "Baseline Loss: 2.7987 | Actual Loss: 2.2082\n",
      "Baseline Loss: 2.8483 | Actual Loss: 1.1596\n",
      "Baseline Loss: 2.8043 | Actual Loss: 0.8218\n",
      "Baseline Loss: 2.8133 | Actual Loss: 0.3561\n",
      "Baseline Loss: 2.8407 | Actual Loss: 0.4729\n",
      "Baseline Loss: 2.8611 | Actual Loss: 0.4753\n",
      "Baseline Loss: 2.4956 | Actual Loss: 0.3198\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.6275\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.4224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 60/1000 [00:34<08:39,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8632 | Actual Loss: 0.3160\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4438\n",
      "Epoch 60/1000: Train Loss: 0.8975, Val Loss: 0.4524\n",
      "New best validation loss: 0.4524\n",
      "Baseline Loss: 2.8210 | Actual Loss: 0.2995\n",
      "Baseline Loss: 2.7969 | Actual Loss: 0.5867\n",
      "Baseline Loss: 2.8689 | Actual Loss: 0.5567\n",
      "Baseline Loss: 2.8397 | Actual Loss: 1.1753\n",
      "Baseline Loss: 2.7851 | Actual Loss: 0.7588\n",
      "Baseline Loss: 2.8190 | Actual Loss: 0.5600\n",
      "Baseline Loss: 2.7757 | Actual Loss: 0.2551\n",
      "Baseline Loss: 2.8398 | Actual Loss: 0.6579\n",
      "Baseline Loss: 2.9041 | Actual Loss: 0.5828\n",
      "Baseline Loss: 2.7888 | Actual Loss: 0.6331\n",
      "Baseline Loss: 2.8188 | Actual Loss: 0.4458\n",
      "Baseline Loss: 2.8452 | Actual Loss: 0.6940\n",
      "Baseline Loss: 2.8052 | Actual Loss: 0.4435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 61/1000 [00:34<08:48,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8104 | Actual Loss: 0.4384\n",
      "Baseline Loss: 2.8108 | Actual Loss: 0.8777\n",
      "Baseline Loss: 2.4974 | Actual Loss: 0.1664\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.7186\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.5820\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.5050\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4279\n",
      "Epoch 61/1000: Train Loss: 0.5707, Val Loss: 0.5584\n",
      "Baseline Loss: 2.7710 | Actual Loss: 0.8895\n",
      "Baseline Loss: 2.7132 | Actual Loss: 0.7076\n",
      "Baseline Loss: 2.8384 | Actual Loss: 0.5202\n",
      "Baseline Loss: 2.8117 | Actual Loss: 0.6619\n",
      "Baseline Loss: 2.8351 | Actual Loss: 0.2217\n",
      "Baseline Loss: 2.7964 | Actual Loss: 0.5779\n",
      "Baseline Loss: 2.8534 | Actual Loss: 2.0009\n",
      "Baseline Loss: 2.8062 | Actual Loss: 0.6258\n",
      "Baseline Loss: 2.8647 | Actual Loss: 0.7341\n",
      "Baseline Loss: 2.8686 | Actual Loss: 1.3462\n",
      "Baseline Loss: 2.7859 | Actual Loss: 0.4020\n",
      "Baseline Loss: 2.8311 | Actual Loss: 0.8579\n",
      "Baseline Loss: 2.8140 | Actual Loss: 0.7769\n",
      "Baseline Loss: 2.9108 | Actual Loss: 0.4905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 62/1000 [00:35<08:59,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8032 | Actual Loss: 0.4273\n",
      "Baseline Loss: 2.6182 | Actual Loss: 0.1440\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.9396\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.0066\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.3569\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4311\n",
      "Epoch 62/1000: Train Loss: 0.7115, Val Loss: 0.6835\n",
      "Baseline Loss: 2.8394 | Actual Loss: 0.5560\n",
      "Baseline Loss: 2.7310 | Actual Loss: 0.9727\n",
      "Baseline Loss: 2.8874 | Actual Loss: 1.5085\n",
      "Baseline Loss: 2.8124 | Actual Loss: 0.6039\n",
      "Baseline Loss: 2.8994 | Actual Loss: 1.2776\n",
      "Baseline Loss: 2.7540 | Actual Loss: 0.5255\n",
      "Baseline Loss: 2.7788 | Actual Loss: 1.1563\n",
      "Baseline Loss: 2.8629 | Actual Loss: 0.9231\n",
      "Baseline Loss: 2.8151 | Actual Loss: 0.7680\n",
      "Baseline Loss: 2.8382 | Actual Loss: 0.5806\n",
      "Baseline Loss: 2.8427 | Actual Loss: 0.2494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 63/1000 [00:35<08:39,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8190 | Actual Loss: 0.3234\n",
      "Baseline Loss: 2.8435 | Actual Loss: 0.4166\n",
      "Baseline Loss: 2.8560 | Actual Loss: 0.5008\n",
      "Baseline Loss: 2.8325 | Actual Loss: 1.4304\n",
      "Baseline Loss: 2.6436 | Actual Loss: 0.2137\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.9045\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.4883\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.3312\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.5673\n",
      "Epoch 63/1000: Train Loss: 0.7504, Val Loss: 0.8228\n",
      "Baseline Loss: 2.9008 | Actual Loss: 0.9823\n",
      "Baseline Loss: 2.8624 | Actual Loss: 0.7878\n",
      "Baseline Loss: 2.7834 | Actual Loss: 0.3873\n",
      "Baseline Loss: 2.8508 | Actual Loss: 0.4433\n",
      "Baseline Loss: 2.8096 | Actual Loss: 1.1273\n",
      "Baseline Loss: 2.8875 | Actual Loss: 1.3158\n",
      "Baseline Loss: 2.7979 | Actual Loss: 0.6048\n",
      "Baseline Loss: 2.8740 | Actual Loss: 0.3398\n",
      "Baseline Loss: 2.8010 | Actual Loss: 0.4284\n",
      "Baseline Loss: 2.7845 | Actual Loss: 0.5369\n",
      "Baseline Loss: 2.7743 | Actual Loss: 0.4713\n",
      "Baseline Loss: 2.8338 | Actual Loss: 0.7508\n",
      "Baseline Loss: 2.8069 | Actual Loss: 0.9812\n",
      "Baseline Loss: 2.8176 | Actual Loss: 0.4451\n",
      "Baseline Loss: 2.8948 | Actual Loss: 0.5599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 64/1000 [00:36<08:41,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.4663 | Actual Loss: 0.1280\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.7050\n",
      "Baseline Loss: 2.7887 | Actual Loss: 2.5612\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.3721\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.5306\n",
      "Epoch 64/1000: Train Loss: 0.6431, Val Loss: 1.0422\n",
      "Baseline Loss: 2.8243 | Actual Loss: 2.4160\n",
      "Baseline Loss: 2.8677 | Actual Loss: 0.3583\n",
      "Baseline Loss: 2.8159 | Actual Loss: 0.3601\n",
      "Baseline Loss: 2.9252 | Actual Loss: 0.3535\n",
      "Baseline Loss: 2.8070 | Actual Loss: 0.4970\n",
      "Baseline Loss: 2.7530 | Actual Loss: 0.4347\n",
      "Baseline Loss: 2.7875 | Actual Loss: 1.9924\n",
      "Baseline Loss: 2.8588 | Actual Loss: 0.1747\n",
      "Baseline Loss: 2.9191 | Actual Loss: 0.9587\n",
      "Baseline Loss: 2.8325 | Actual Loss: 0.4380\n",
      "Baseline Loss: 2.8639 | Actual Loss: 0.3980\n",
      "Baseline Loss: 2.7558 | Actual Loss: 0.5193\n",
      "Baseline Loss: 2.7804 | Actual Loss: 0.7770\n",
      "Baseline Loss: 2.7987 | Actual Loss: 0.8200\n",
      "Baseline Loss: 2.8433 | Actual Loss: 0.3037\n",
      "Baseline Loss: 2.6236 | Actual Loss: 2.6315\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.6947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 65/1000 [00:37<08:51,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7887 | Actual Loss: 0.9450\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.3672\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.2647\n",
      "Epoch 65/1000: Train Loss: 0.8396, Val Loss: 0.5679\n",
      "Baseline Loss: 2.7559 | Actual Loss: 0.4822\n",
      "Baseline Loss: 2.8245 | Actual Loss: 0.3331\n",
      "Baseline Loss: 2.7838 | Actual Loss: 0.6071\n",
      "Baseline Loss: 2.9015 | Actual Loss: 0.4532\n",
      "Baseline Loss: 2.9514 | Actual Loss: 2.7247\n",
      "Baseline Loss: 2.9039 | Actual Loss: 0.3493\n",
      "Baseline Loss: 2.7379 | Actual Loss: 0.6099\n",
      "Baseline Loss: 2.7658 | Actual Loss: 0.3185\n",
      "Baseline Loss: 2.8399 | Actual Loss: 0.4218\n",
      "Baseline Loss: 2.8609 | Actual Loss: 0.6076\n",
      "Baseline Loss: 2.7954 | Actual Loss: 0.7242\n",
      "Baseline Loss: 2.9334 | Actual Loss: 0.4647\n",
      "Baseline Loss: 2.7870 | Actual Loss: 2.7326\n",
      "Baseline Loss: 2.8550 | Actual Loss: 0.3048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 66/1000 [00:37<08:39,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7916 | Actual Loss: 0.4181\n",
      "Baseline Loss: 2.4427 | Actual Loss: 0.1515\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.7932\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.1348\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.4129\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.3063\n",
      "Epoch 66/1000: Train Loss: 0.7315, Val Loss: 0.6618\n",
      "Baseline Loss: 2.8468 | Actual Loss: 2.5297\n",
      "Baseline Loss: 2.8461 | Actual Loss: 0.4192\n",
      "Baseline Loss: 2.8044 | Actual Loss: 0.7022\n",
      "Baseline Loss: 2.7896 | Actual Loss: 0.6072\n",
      "Baseline Loss: 2.7964 | Actual Loss: 0.3782\n",
      "Baseline Loss: 2.7938 | Actual Loss: 0.7878\n",
      "Baseline Loss: 2.8458 | Actual Loss: 0.7483\n",
      "Baseline Loss: 2.7974 | Actual Loss: 0.3861\n",
      "Baseline Loss: 2.7959 | Actual Loss: 0.3849\n",
      "Baseline Loss: 2.8615 | Actual Loss: 0.7430\n",
      "Baseline Loss: 2.8335 | Actual Loss: 0.1105\n",
      "Baseline Loss: 2.8304 | Actual Loss: 0.2979\n",
      "Baseline Loss: 2.8628 | Actual Loss: 1.0383\n",
      "Baseline Loss: 2.8208 | Actual Loss: 0.5736\n",
      "Baseline Loss: 2.7437 | Actual Loss: 0.2332\n",
      "Baseline Loss: 2.6391 | Actual Loss: 0.6835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 67/1000 [00:38<08:48,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8420 | Actual Loss: 0.8437\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.8688\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.6937\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.3508\n",
      "Epoch 67/1000: Train Loss: 0.6640, Val Loss: 0.6893\n",
      "Baseline Loss: 2.8751 | Actual Loss: 0.8180\n",
      "Baseline Loss: 2.8311 | Actual Loss: 0.8036\n",
      "Baseline Loss: 2.7976 | Actual Loss: 0.5953\n",
      "Baseline Loss: 2.7930 | Actual Loss: 0.4825\n",
      "Baseline Loss: 2.8486 | Actual Loss: 0.6767\n",
      "Baseline Loss: 2.7672 | Actual Loss: 0.7172\n",
      "Baseline Loss: 2.8650 | Actual Loss: 0.2905\n",
      "Baseline Loss: 2.8741 | Actual Loss: 0.2057\n",
      "Baseline Loss: 2.8254 | Actual Loss: 0.4974\n",
      "Baseline Loss: 2.7731 | Actual Loss: 0.4813\n",
      "Baseline Loss: 2.7993 | Actual Loss: 0.9499\n",
      "Baseline Loss: 2.8138 | Actual Loss: 0.4105\n",
      "Baseline Loss: 2.9251 | Actual Loss: 2.8711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 68/1000 [00:38<08:38,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8730 | Actual Loss: 0.4086\n",
      "Baseline Loss: 2.8197 | Actual Loss: 1.2344\n",
      "Baseline Loss: 2.5239 | Actual Loss: 0.1923\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.7247\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.8528\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.3104\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.5507\n",
      "Epoch 68/1000: Train Loss: 0.7272, Val Loss: 0.8597\n",
      "Baseline Loss: 2.8190 | Actual Loss: 0.4091\n",
      "Baseline Loss: 2.7330 | Actual Loss: 0.8481\n",
      "Baseline Loss: 2.8460 | Actual Loss: 0.6120\n",
      "Baseline Loss: 2.8378 | Actual Loss: 0.7185\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.2347\n",
      "Baseline Loss: 2.8458 | Actual Loss: 0.7500\n",
      "Baseline Loss: 2.7808 | Actual Loss: 0.5007\n",
      "Baseline Loss: 2.8363 | Actual Loss: 0.6313\n",
      "Baseline Loss: 2.8644 | Actual Loss: 0.5249\n",
      "Baseline Loss: 2.8716 | Actual Loss: 0.5104\n",
      "Baseline Loss: 2.8567 | Actual Loss: 0.4547\n",
      "Baseline Loss: 2.7610 | Actual Loss: 0.2942\n",
      "Baseline Loss: 2.8088 | Actual Loss: 1.4335\n",
      "Baseline Loss: 2.8508 | Actual Loss: 1.0055\n",
      "Baseline Loss: 2.8727 | Actual Loss: 0.7825\n",
      "Baseline Loss: 2.4143 | Actual Loss: 0.6219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 69/1000 [00:39<08:51,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8420 | Actual Loss: 0.6555\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.9536\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.3342\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4259\n",
      "Epoch 69/1000: Train Loss: 0.6458, Val Loss: 0.5923\n",
      "Baseline Loss: 2.8636 | Actual Loss: 0.5914\n",
      "Baseline Loss: 2.7946 | Actual Loss: 0.3938\n",
      "Baseline Loss: 2.9104 | Actual Loss: 0.2886\n",
      "Baseline Loss: 2.7644 | Actual Loss: 0.5945\n",
      "Baseline Loss: 2.7876 | Actual Loss: 0.4995\n",
      "Baseline Loss: 2.8581 | Actual Loss: 0.5109\n",
      "Baseline Loss: 2.7917 | Actual Loss: 0.8674\n",
      "Baseline Loss: 2.7871 | Actual Loss: 0.1991\n",
      "Baseline Loss: 2.8387 | Actual Loss: 0.5343\n",
      "Baseline Loss: 2.9199 | Actual Loss: 0.4708\n",
      "Baseline Loss: 2.8657 | Actual Loss: 0.9776\n",
      "Baseline Loss: 2.7670 | Actual Loss: 0.2136\n",
      "Baseline Loss: 2.8220 | Actual Loss: 0.8571\n",
      "Baseline Loss: 2.8405 | Actual Loss: 1.0625\n",
      "Baseline Loss: 2.7761 | Actual Loss: 1.1285\n",
      "Baseline Loss: 2.5439 | Actual Loss: 2.5759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 70/1000 [00:39<09:10,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8420 | Actual Loss: 0.6680\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.7579\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.3723\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.3623\n",
      "Epoch 70/1000: Train Loss: 0.7353, Val Loss: 0.5401\n",
      "Baseline Loss: 2.8081 | Actual Loss: 0.6776\n",
      "Baseline Loss: 2.8249 | Actual Loss: 0.5888\n",
      "Baseline Loss: 2.8162 | Actual Loss: 0.2462\n",
      "Baseline Loss: 2.7871 | Actual Loss: 0.4158\n",
      "Baseline Loss: 2.7945 | Actual Loss: 0.2918\n",
      "Baseline Loss: 2.7932 | Actual Loss: 0.6189\n",
      "Baseline Loss: 2.8643 | Actual Loss: 0.8030\n",
      "Baseline Loss: 2.9005 | Actual Loss: 0.7972\n",
      "Baseline Loss: 2.8001 | Actual Loss: 0.3352\n",
      "Baseline Loss: 2.8748 | Actual Loss: 0.2825\n",
      "Baseline Loss: 2.8052 | Actual Loss: 0.6284\n",
      "Baseline Loss: 2.7784 | Actual Loss: 0.8116\n",
      "Baseline Loss: 2.8024 | Actual Loss: 0.3975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 71/1000 [00:40<08:52,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8312 | Actual Loss: 0.5104\n",
      "Baseline Loss: 2.8092 | Actual Loss: 0.8502\n",
      "Baseline Loss: 2.5562 | Actual Loss: 2.4994\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.7490\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.8046\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2600\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4974\n",
      "Epoch 71/1000: Train Loss: 0.6721, Val Loss: 0.8277\n",
      "Baseline Loss: 2.7559 | Actual Loss: 2.5450\n",
      "Baseline Loss: 2.7715 | Actual Loss: 0.8140\n",
      "Baseline Loss: 2.9157 | Actual Loss: 2.7739\n",
      "Baseline Loss: 2.8162 | Actual Loss: 0.5708\n",
      "Baseline Loss: 2.8387 | Actual Loss: 0.8615\n",
      "Baseline Loss: 2.7806 | Actual Loss: 0.2264\n",
      "Baseline Loss: 2.8378 | Actual Loss: 1.3909\n",
      "Baseline Loss: 2.8781 | Actual Loss: 0.5152\n",
      "Baseline Loss: 2.8692 | Actual Loss: 1.4827\n",
      "Baseline Loss: 2.8021 | Actual Loss: 0.5699\n",
      "Baseline Loss: 2.7716 | Actual Loss: 0.8687\n",
      "Baseline Loss: 2.8348 | Actual Loss: 0.3042\n",
      "Baseline Loss: 2.7874 | Actual Loss: 0.1967\n",
      "Baseline Loss: 2.8270 | Actual Loss: 0.2253\n",
      "Baseline Loss: 2.7990 | Actual Loss: 0.3740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 72/1000 [00:41<08:56,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5686 | Actual Loss: 2.2285\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.7531\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.5575\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.5050\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.3415\n",
      "Epoch 72/1000: Train Loss: 0.9967, Val Loss: 0.5393\n",
      "Baseline Loss: 2.8967 | Actual Loss: 0.1428\n",
      "Baseline Loss: 2.7753 | Actual Loss: 0.7099\n",
      "Baseline Loss: 2.8133 | Actual Loss: 0.3602\n",
      "Baseline Loss: 2.9429 | Actual Loss: 0.5702\n",
      "Baseline Loss: 2.8155 | Actual Loss: 0.2298\n",
      "Baseline Loss: 2.9094 | Actual Loss: 0.4568\n",
      "Baseline Loss: 2.7875 | Actual Loss: 0.5149\n",
      "Baseline Loss: 2.8080 | Actual Loss: 0.4523\n",
      "Baseline Loss: 2.8586 | Actual Loss: 0.6100\n",
      "Baseline Loss: 2.7552 | Actual Loss: 2.6150\n",
      "Baseline Loss: 2.7650 | Actual Loss: 2.5702\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.2019\n",
      "Baseline Loss: 2.8157 | Actual Loss: 0.4050\n",
      "Baseline Loss: 2.8690 | Actual Loss: 0.5092\n",
      "Baseline Loss: 2.8931 | Actual Loss: 0.5121\n",
      "Baseline Loss: 2.7238 | Actual Loss: 2.7779\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.8173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 73/1000 [00:41<09:05,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7887 | Actual Loss: 2.3467\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1864\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.7095\n",
      "Epoch 73/1000: Train Loss: 0.8524, Val Loss: 1.0150\n",
      "Baseline Loss: 2.8223 | Actual Loss: 0.6531\n",
      "Baseline Loss: 2.8309 | Actual Loss: 0.7007\n",
      "Baseline Loss: 2.7930 | Actual Loss: 0.5483\n",
      "Baseline Loss: 2.8165 | Actual Loss: 2.1677\n",
      "Baseline Loss: 2.8613 | Actual Loss: 0.6547\n",
      "Baseline Loss: 2.8337 | Actual Loss: 0.6907\n",
      "Baseline Loss: 2.8450 | Actual Loss: 1.8960\n",
      "Baseline Loss: 2.7977 | Actual Loss: 0.3918\n",
      "Baseline Loss: 2.7753 | Actual Loss: 0.4024\n",
      "Baseline Loss: 2.7765 | Actual Loss: 0.3752\n",
      "Baseline Loss: 2.7803 | Actual Loss: 0.5354\n",
      "Baseline Loss: 2.8573 | Actual Loss: 0.5876\n",
      "Baseline Loss: 2.7801 | Actual Loss: 0.4958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 74/1000 [00:42<08:47,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8434 | Actual Loss: 0.5678\n",
      "Baseline Loss: 2.9430 | Actual Loss: 0.6833\n",
      "Baseline Loss: 2.7421 | Actual Loss: 0.3927\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5605\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.0952\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.3140\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.3408\n",
      "Epoch 74/1000: Train Loss: 0.7340, Val Loss: 0.5776\n",
      "Baseline Loss: 2.7501 | Actual Loss: 0.6957\n",
      "Baseline Loss: 2.7881 | Actual Loss: 0.6620\n",
      "Baseline Loss: 2.9019 | Actual Loss: 0.3563\n",
      "Baseline Loss: 2.7729 | Actual Loss: 0.7618\n",
      "Baseline Loss: 2.9140 | Actual Loss: 1.7046\n",
      "Baseline Loss: 2.7782 | Actual Loss: 0.4790\n",
      "Baseline Loss: 2.8538 | Actual Loss: 0.5754\n",
      "Baseline Loss: 2.8721 | Actual Loss: 0.4133\n",
      "Baseline Loss: 2.8540 | Actual Loss: 1.8241\n",
      "Baseline Loss: 2.8522 | Actual Loss: 0.5161\n",
      "Baseline Loss: 2.8924 | Actual Loss: 0.4057\n",
      "Baseline Loss: 2.8202 | Actual Loss: 3.0033\n",
      "Baseline Loss: 2.7836 | Actual Loss: 2.0342\n",
      "Baseline Loss: 2.8343 | Actual Loss: 0.2861\n",
      "Baseline Loss: 2.8233 | Actual Loss: 1.1303\n",
      "Baseline Loss: 2.4304 | Actual Loss: 2.0836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 75/1000 [00:42<08:58,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8420 | Actual Loss: 0.7217\n",
      "Baseline Loss: 2.7887 | Actual Loss: 2.1493\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.3807\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.6135\n",
      "Epoch 75/1000: Train Loss: 1.0582, Val Loss: 0.9663\n",
      "Baseline Loss: 2.8032 | Actual Loss: 1.0879\n",
      "Baseline Loss: 2.8193 | Actual Loss: 0.3210\n",
      "Baseline Loss: 2.8198 | Actual Loss: 0.4177\n",
      "Baseline Loss: 2.8001 | Actual Loss: 0.3468\n",
      "Baseline Loss: 2.9006 | Actual Loss: 0.6368\n",
      "Baseline Loss: 2.8408 | Actual Loss: 0.3773\n",
      "Baseline Loss: 2.8197 | Actual Loss: 2.3296\n",
      "Baseline Loss: 2.9244 | Actual Loss: 2.1943\n",
      "Baseline Loss: 2.8130 | Actual Loss: 0.5615\n",
      "Baseline Loss: 2.8299 | Actual Loss: 0.7264\n",
      "Baseline Loss: 2.7846 | Actual Loss: 0.3501\n",
      "Baseline Loss: 2.8961 | Actual Loss: 0.3623\n",
      "Baseline Loss: 2.8055 | Actual Loss: 0.4286\n",
      "Baseline Loss: 2.8271 | Actual Loss: 0.6439\n",
      "Baseline Loss: 2.8104 | Actual Loss: 0.5716\n",
      "Baseline Loss: 2.4314 | Actual Loss: 0.3825\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.6149\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.7165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 76/1000 [00:43<09:06,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8632 | Actual Loss: 0.3997\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.6308\n",
      "Epoch 76/1000: Train Loss: 0.7336, Val Loss: 0.5905\n",
      "Baseline Loss: 2.8389 | Actual Loss: 0.5848\n",
      "Baseline Loss: 2.8332 | Actual Loss: 0.4097\n",
      "Baseline Loss: 2.7488 | Actual Loss: 0.2936\n",
      "Baseline Loss: 2.8292 | Actual Loss: 2.2314\n",
      "Baseline Loss: 2.7981 | Actual Loss: 0.4062\n",
      "Baseline Loss: 2.8707 | Actual Loss: 0.4075\n",
      "Baseline Loss: 2.8349 | Actual Loss: 0.2730\n",
      "Baseline Loss: 2.8357 | Actual Loss: 0.7341\n",
      "Baseline Loss: 2.8074 | Actual Loss: 0.8341\n",
      "Baseline Loss: 2.8200 | Actual Loss: 0.1897\n",
      "Baseline Loss: 2.8288 | Actual Loss: 0.7900\n",
      "Baseline Loss: 2.7392 | Actual Loss: 0.7704\n",
      "Baseline Loss: 2.8016 | Actual Loss: 1.1148\n",
      "Baseline Loss: 2.8324 | Actual Loss: 0.4733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 77/1000 [00:43<08:48,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8385 | Actual Loss: 0.3114\n",
      "Baseline Loss: 2.5883 | Actual Loss: 0.2674\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.6822\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.8588\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1820\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.5661\n",
      "Epoch 77/1000: Train Loss: 0.6307, Val Loss: 0.5723\n",
      "Baseline Loss: 2.8067 | Actual Loss: 0.8729\n",
      "Baseline Loss: 2.8277 | Actual Loss: 0.3482\n",
      "Baseline Loss: 2.8657 | Actual Loss: 0.1508\n",
      "Baseline Loss: 2.7919 | Actual Loss: 1.1607\n",
      "Baseline Loss: 2.8592 | Actual Loss: 0.7379\n",
      "Baseline Loss: 2.8145 | Actual Loss: 0.3567\n",
      "Baseline Loss: 2.7849 | Actual Loss: 0.1664\n",
      "Baseline Loss: 2.8812 | Actual Loss: 0.4764\n",
      "Baseline Loss: 2.8137 | Actual Loss: 0.4337\n",
      "Baseline Loss: 2.7672 | Actual Loss: 0.7593\n",
      "Baseline Loss: 2.8116 | Actual Loss: 0.1921\n",
      "Baseline Loss: 2.8939 | Actual Loss: 0.2296\n",
      "Baseline Loss: 2.7978 | Actual Loss: 0.4561\n",
      "Baseline Loss: 2.8875 | Actual Loss: 0.4407\n",
      "Baseline Loss: 2.7793 | Actual Loss: 0.6487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 78/1000 [00:44<09:00,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6381 | Actual Loss: 3.2474\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.6597\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.5499\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1918\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4159\n",
      "Epoch 78/1000: Train Loss: 0.6673, Val Loss: 0.4543\n",
      "Baseline Loss: 2.8255 | Actual Loss: 0.4130\n",
      "Baseline Loss: 2.7793 | Actual Loss: 0.4108\n",
      "Baseline Loss: 2.7690 | Actual Loss: 0.3255\n",
      "Baseline Loss: 2.8995 | Actual Loss: 0.8301\n",
      "Baseline Loss: 2.7843 | Actual Loss: 0.7475\n",
      "Baseline Loss: 2.8958 | Actual Loss: 0.8746\n",
      "Baseline Loss: 2.7927 | Actual Loss: 0.6934\n",
      "Baseline Loss: 2.8609 | Actual Loss: 0.5866\n",
      "Baseline Loss: 2.7984 | Actual Loss: 0.5865\n",
      "Baseline Loss: 2.7757 | Actual Loss: 0.8009\n",
      "Baseline Loss: 2.8757 | Actual Loss: 0.5735\n",
      "Baseline Loss: 2.8393 | Actual Loss: 0.4453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 79/1000 [00:45<08:43,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7982 | Actual Loss: 0.5520\n",
      "Baseline Loss: 2.8202 | Actual Loss: 0.4538\n",
      "Baseline Loss: 2.7695 | Actual Loss: 0.5977\n",
      "Baseline Loss: 2.4752 | Actual Loss: 0.3625\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.7879\n",
      "Baseline Loss: 2.7887 | Actual Loss: 2.6882\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2356\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.6270\n",
      "Epoch 79/1000: Train Loss: 0.5784, Val Loss: 1.0847\n",
      "Baseline Loss: 2.8451 | Actual Loss: 0.8293\n",
      "Baseline Loss: 2.8184 | Actual Loss: 0.3844\n",
      "Baseline Loss: 2.8369 | Actual Loss: 0.3648\n",
      "Baseline Loss: 2.7939 | Actual Loss: 0.3969\n",
      "Baseline Loss: 2.7846 | Actual Loss: 0.6999\n",
      "Baseline Loss: 2.7593 | Actual Loss: 1.4825\n",
      "Baseline Loss: 2.8496 | Actual Loss: 0.6493\n",
      "Baseline Loss: 2.8629 | Actual Loss: 1.0595\n",
      "Baseline Loss: 2.9440 | Actual Loss: 0.7555\n",
      "Baseline Loss: 2.7370 | Actual Loss: 0.7500\n",
      "Baseline Loss: 2.8068 | Actual Loss: 0.3487\n",
      "Baseline Loss: 2.8540 | Actual Loss: 0.2102\n",
      "Baseline Loss: 2.8113 | Actual Loss: 0.5301\n",
      "Baseline Loss: 2.7812 | Actual Loss: 0.2628\n",
      "Baseline Loss: 2.8238 | Actual Loss: 0.6093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 80/1000 [00:45<08:59,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5643 | Actual Loss: 0.3009\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.6834\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.7857\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1877\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.3644\n",
      "Epoch 80/1000: Train Loss: 0.6021, Val Loss: 0.5053\n",
      "Baseline Loss: 2.9119 | Actual Loss: 2.4845\n",
      "Baseline Loss: 2.8680 | Actual Loss: 0.5575\n",
      "Baseline Loss: 2.8150 | Actual Loss: 0.7945\n",
      "Baseline Loss: 2.8468 | Actual Loss: 0.5801\n",
      "Baseline Loss: 2.8579 | Actual Loss: 0.1893\n",
      "Baseline Loss: 2.8362 | Actual Loss: 0.9101\n",
      "Baseline Loss: 2.8186 | Actual Loss: 0.2876\n",
      "Baseline Loss: 2.7863 | Actual Loss: 0.4636\n",
      "Baseline Loss: 2.7861 | Actual Loss: 0.6192\n",
      "Baseline Loss: 2.8326 | Actual Loss: 1.2261\n",
      "Baseline Loss: 2.7955 | Actual Loss: 0.5444\n",
      "Baseline Loss: 2.8487 | Actual Loss: 0.3873\n",
      "Baseline Loss: 2.8262 | Actual Loss: 0.3252\n",
      "Baseline Loss: 2.7821 | Actual Loss: 0.5726\n",
      "Baseline Loss: 2.7979 | Actual Loss: 0.2945\n",
      "Baseline Loss: 2.7427 | Actual Loss: 1.2105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 81/1000 [00:46<09:08,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8420 | Actual Loss: 0.6474\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.7989\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2963\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4484\n",
      "Epoch 81/1000: Train Loss: 0.7154, Val Loss: 0.7977\n",
      "Baseline Loss: 2.8018 | Actual Loss: 0.2583\n",
      "Baseline Loss: 2.8870 | Actual Loss: 1.6174\n",
      "Baseline Loss: 2.8363 | Actual Loss: 0.1081\n",
      "Baseline Loss: 2.8429 | Actual Loss: 0.4469\n",
      "Baseline Loss: 2.8234 | Actual Loss: 0.3636\n",
      "Baseline Loss: 2.8879 | Actual Loss: 0.6825\n",
      "Baseline Loss: 2.8190 | Actual Loss: 0.7609\n",
      "Baseline Loss: 2.8391 | Actual Loss: 0.4866\n",
      "Baseline Loss: 2.7611 | Actual Loss: 0.4117\n",
      "Baseline Loss: 2.8746 | Actual Loss: 0.7749\n",
      "Baseline Loss: 2.8006 | Actual Loss: 0.6776\n",
      "Baseline Loss: 2.7860 | Actual Loss: 0.3893\n",
      "Baseline Loss: 2.7810 | Actual Loss: 0.9456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 82/1000 [00:46<08:49,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8491 | Actual Loss: 0.5905\n",
      "Baseline Loss: 2.8306 | Actual Loss: 0.2203\n",
      "Baseline Loss: 2.5309 | Actual Loss: 0.2449\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.6058\n",
      "Baseline Loss: 2.7887 | Actual Loss: 2.3944\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1789\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4160\n",
      "Epoch 82/1000: Train Loss: 0.5612, Val Loss: 0.8988\n",
      "Baseline Loss: 2.7743 | Actual Loss: 0.5849\n",
      "Baseline Loss: 2.7987 | Actual Loss: 0.3467\n",
      "Baseline Loss: 2.8557 | Actual Loss: 0.2472\n",
      "Baseline Loss: 2.8460 | Actual Loss: 2.7497\n",
      "Baseline Loss: 2.8510 | Actual Loss: 0.6079\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.2865\n",
      "Baseline Loss: 2.8532 | Actual Loss: 0.4543\n",
      "Baseline Loss: 2.7592 | Actual Loss: 0.3946\n",
      "Baseline Loss: 2.8494 | Actual Loss: 0.8183\n",
      "Baseline Loss: 2.8860 | Actual Loss: 0.6149\n",
      "Baseline Loss: 2.7589 | Actual Loss: 0.6374\n",
      "Baseline Loss: 2.8100 | Actual Loss: 0.4425\n",
      "Baseline Loss: 2.9101 | Actual Loss: 0.4962\n",
      "Baseline Loss: 2.8115 | Actual Loss: 0.2270\n",
      "Baseline Loss: 2.8047 | Actual Loss: 0.4408\n",
      "Baseline Loss: 2.5017 | Actual Loss: 0.2461\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.6331\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.8745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 83/1000 [00:47<08:54,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8632 | Actual Loss: 0.1466\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4603\n",
      "Epoch 83/1000: Train Loss: 0.5997, Val Loss: 0.7787\n",
      "Baseline Loss: 2.7603 | Actual Loss: 0.6633\n",
      "Baseline Loss: 2.8766 | Actual Loss: 0.2244\n",
      "Baseline Loss: 2.8627 | Actual Loss: 0.5308\n",
      "Baseline Loss: 2.7739 | Actual Loss: 0.7662\n",
      "Baseline Loss: 2.8622 | Actual Loss: 0.2516\n",
      "Baseline Loss: 2.8120 | Actual Loss: 0.4146\n",
      "Baseline Loss: 2.8251 | Actual Loss: 1.8293\n",
      "Baseline Loss: 2.8399 | Actual Loss: 0.1683\n",
      "Baseline Loss: 2.7823 | Actual Loss: 0.3848\n",
      "Baseline Loss: 2.8525 | Actual Loss: 0.3886\n",
      "Baseline Loss: 2.8404 | Actual Loss: 0.5743\n",
      "Baseline Loss: 2.8327 | Actual Loss: 0.9093\n",
      "Baseline Loss: 2.8271 | Actual Loss: 0.1918\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.8266\n",
      "Baseline Loss: 2.8010 | Actual Loss: 0.2043\n",
      "Baseline Loss: 2.4633 | Actual Loss: 0.3740\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.6332\n",
      "Baseline Loss: 2.7887 | Actual Loss: 2.3929\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.4352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 84/1000 [00:48<09:01,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7147 | Actual Loss: 0.4505\n",
      "Epoch 84/1000: Train Loss: 0.5439, Val Loss: 0.9779\n",
      "Baseline Loss: 2.8392 | Actual Loss: 1.0409\n",
      "Baseline Loss: 2.9874 | Actual Loss: 0.2310\n",
      "Baseline Loss: 2.7544 | Actual Loss: 1.1057\n",
      "Baseline Loss: 2.8301 | Actual Loss: 0.2667\n",
      "Baseline Loss: 2.9001 | Actual Loss: 0.4486\n",
      "Baseline Loss: 2.8231 | Actual Loss: 0.3870\n",
      "Baseline Loss: 2.8277 | Actual Loss: 0.3261\n",
      "Baseline Loss: 2.8427 | Actual Loss: 0.6023\n",
      "Baseline Loss: 2.8026 | Actual Loss: 0.4393\n",
      "Baseline Loss: 2.8295 | Actual Loss: 0.2853\n",
      "Baseline Loss: 2.8040 | Actual Loss: 0.4769\n",
      "Baseline Loss: 2.8211 | Actual Loss: 0.1613\n",
      "Baseline Loss: 2.8137 | Actual Loss: 0.4447\n",
      "Baseline Loss: 2.8412 | Actual Loss: 0.2949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 85/1000 [00:48<09:06,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8344 | Actual Loss: 0.4076\n",
      "Baseline Loss: 2.5274 | Actual Loss: 0.5292\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.7695\n",
      "Baseline Loss: 2.7887 | Actual Loss: 2.5363\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2679\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.5334\n",
      "Epoch 85/1000: Train Loss: 0.4655, Val Loss: 1.0268\n",
      "Baseline Loss: 2.9361 | Actual Loss: 0.3728\n",
      "Baseline Loss: 2.7260 | Actual Loss: 0.2961\n",
      "Baseline Loss: 2.7689 | Actual Loss: 1.0277\n",
      "Baseline Loss: 2.8133 | Actual Loss: 0.3848\n",
      "Baseline Loss: 2.8823 | Actual Loss: 2.1579\n",
      "Baseline Loss: 2.8559 | Actual Loss: 0.3941\n",
      "Baseline Loss: 2.7920 | Actual Loss: 0.4796\n",
      "Baseline Loss: 2.8250 | Actual Loss: 0.6195\n",
      "Baseline Loss: 2.8311 | Actual Loss: 0.3961\n",
      "Baseline Loss: 2.8916 | Actual Loss: 1.2347\n",
      "Baseline Loss: 2.7750 | Actual Loss: 0.5640\n",
      "Baseline Loss: 2.8048 | Actual Loss: 0.6881\n",
      "Baseline Loss: 2.8197 | Actual Loss: 1.5817\n",
      "Baseline Loss: 2.8586 | Actual Loss: 0.4933\n",
      "Baseline Loss: 2.8273 | Actual Loss: 0.6042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▊         | 86/1000 [00:49<08:47,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.4678 | Actual Loss: 0.1418\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.6001\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.5042\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.3510\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.3730\n",
      "Epoch 86/1000: Train Loss: 0.7148, Val Loss: 0.4571\n",
      "Baseline Loss: 2.8699 | Actual Loss: 0.1661\n",
      "Baseline Loss: 2.8589 | Actual Loss: 0.5752\n",
      "Baseline Loss: 2.7849 | Actual Loss: 0.3609\n",
      "Baseline Loss: 2.7977 | Actual Loss: 0.4879\n",
      "Baseline Loss: 2.8824 | Actual Loss: 1.0647\n",
      "Baseline Loss: 2.8269 | Actual Loss: 1.0810\n",
      "Baseline Loss: 2.8022 | Actual Loss: 0.4454\n",
      "Baseline Loss: 2.8449 | Actual Loss: 0.5885\n",
      "Baseline Loss: 2.8429 | Actual Loss: 0.5982\n",
      "Baseline Loss: 2.9188 | Actual Loss: 0.7480\n",
      "Baseline Loss: 2.7535 | Actual Loss: 0.6339\n",
      "Baseline Loss: 2.8357 | Actual Loss: 0.3722\n",
      "Baseline Loss: 2.7441 | Actual Loss: 0.7156\n",
      "Baseline Loss: 2.7909 | Actual Loss: 0.1746\n",
      "Baseline Loss: 2.8713 | Actual Loss: 0.5714\n",
      "Baseline Loss: 2.6520 | Actual Loss: 0.2547\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5813\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.9634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▊         | 87/1000 [00:49<08:45,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8632 | Actual Loss: 0.2624\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.3218\n",
      "Epoch 87/1000: Train Loss: 0.5524, Val Loss: 0.5322\n",
      "Baseline Loss: 2.8265 | Actual Loss: 0.9078\n",
      "Baseline Loss: 2.8546 | Actual Loss: 0.4865\n",
      "Baseline Loss: 2.8766 | Actual Loss: 0.4694\n",
      "Baseline Loss: 2.7257 | Actual Loss: 0.3160\n",
      "Baseline Loss: 2.8458 | Actual Loss: 0.5730\n",
      "Baseline Loss: 2.7873 | Actual Loss: 0.5661\n",
      "Baseline Loss: 2.7685 | Actual Loss: 0.4488\n",
      "Baseline Loss: 2.8245 | Actual Loss: 1.9997\n",
      "Baseline Loss: 2.8206 | Actual Loss: 0.5419\n",
      "Baseline Loss: 2.8823 | Actual Loss: 0.4720\n",
      "Baseline Loss: 2.8199 | Actual Loss: 0.5189\n",
      "Baseline Loss: 2.7851 | Actual Loss: 0.1799\n",
      "Baseline Loss: 2.7562 | Actual Loss: 0.2716\n",
      "Baseline Loss: 2.8624 | Actual Loss: 0.2709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 88/1000 [00:50<08:48,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8045 | Actual Loss: 0.2679\n",
      "Baseline Loss: 2.5383 | Actual Loss: 0.1248\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5349\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.9518\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1679\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4856\n",
      "Epoch 88/1000: Train Loss: 0.5260, Val Loss: 0.5350\n",
      "Baseline Loss: 2.8577 | Actual Loss: 0.4075\n",
      "Baseline Loss: 2.8047 | Actual Loss: 0.3335\n",
      "Baseline Loss: 2.8581 | Actual Loss: 0.5601\n",
      "Baseline Loss: 2.8888 | Actual Loss: 0.1873\n",
      "Baseline Loss: 2.8597 | Actual Loss: 2.3692\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.4664\n",
      "Baseline Loss: 2.8860 | Actual Loss: 0.3952\n",
      "Baseline Loss: 2.7812 | Actual Loss: 0.6277\n",
      "Baseline Loss: 2.8069 | Actual Loss: 0.3436\n",
      "Baseline Loss: 2.8879 | Actual Loss: 0.3512\n",
      "Baseline Loss: 2.7819 | Actual Loss: 0.7692\n",
      "Baseline Loss: 2.8443 | Actual Loss: 0.3430\n",
      "Baseline Loss: 2.7707 | Actual Loss: 2.5605\n",
      "Baseline Loss: 2.7868 | Actual Loss: 0.3309\n",
      "Baseline Loss: 2.7716 | Actual Loss: 0.1392\n",
      "Baseline Loss: 2.5074 | Actual Loss: 0.6348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 89/1000 [00:50<08:27,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8420 | Actual Loss: 0.6043\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.9459\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1440\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.6024\n",
      "Epoch 89/1000: Train Loss: 0.6762, Val Loss: 0.5741\n",
      "Baseline Loss: 2.8449 | Actual Loss: 1.0725\n",
      "Baseline Loss: 2.7930 | Actual Loss: 2.5504\n",
      "Baseline Loss: 2.8220 | Actual Loss: 0.3712\n",
      "Baseline Loss: 2.8024 | Actual Loss: 0.2456\n",
      "Baseline Loss: 2.8524 | Actual Loss: 0.4299\n",
      "Baseline Loss: 2.8983 | Actual Loss: 0.8389\n",
      "Baseline Loss: 2.8543 | Actual Loss: 0.4401\n",
      "Baseline Loss: 2.7902 | Actual Loss: 0.2568\n",
      "Baseline Loss: 2.7975 | Actual Loss: 0.3027\n",
      "Baseline Loss: 2.8019 | Actual Loss: 0.2283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 90/1000 [00:51<08:30,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8464 | Actual Loss: 0.6109\n",
      "Baseline Loss: 2.8219 | Actual Loss: 0.2552\n",
      "Baseline Loss: 2.8058 | Actual Loss: 0.5687\n",
      "Baseline Loss: 2.8972 | Actual Loss: 2.7528\n",
      "Baseline Loss: 2.7605 | Actual Loss: 0.4071\n",
      "Baseline Loss: 2.6838 | Actual Loss: 0.4588\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.6707\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.2506\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1664\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4073\n",
      "Epoch 90/1000: Train Loss: 0.7369, Val Loss: 0.6237\n",
      "Baseline Loss: 2.8379 | Actual Loss: 0.9810\n",
      "Baseline Loss: 2.7658 | Actual Loss: 0.4077\n",
      "Baseline Loss: 2.8248 | Actual Loss: 0.4292\n",
      "Baseline Loss: 2.7915 | Actual Loss: 0.3967\n",
      "Baseline Loss: 2.8856 | Actual Loss: 1.2861\n",
      "Baseline Loss: 2.8484 | Actual Loss: 0.2388\n",
      "Baseline Loss: 2.8022 | Actual Loss: 0.3496\n",
      "Baseline Loss: 2.7919 | Actual Loss: 0.4701\n",
      "Baseline Loss: 2.8638 | Actual Loss: 0.0752\n",
      "Baseline Loss: 2.7927 | Actual Loss: 0.7505\n",
      "Baseline Loss: 2.8977 | Actual Loss: 0.1396\n",
      "Baseline Loss: 2.8362 | Actual Loss: 0.6253\n",
      "Baseline Loss: 2.8761 | Actual Loss: 0.2706\n",
      "Baseline Loss: 2.7633 | Actual Loss: 0.2734\n",
      "Baseline Loss: 2.8348 | Actual Loss: 0.3374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 91/1000 [00:52<08:49,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5701 | Actual Loss: 2.3693\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.6047\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.4282\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1209\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4308\n",
      "Epoch 91/1000: Train Loss: 0.5875, Val Loss: 0.3961\n",
      "New best validation loss: 0.3961\n",
      "Baseline Loss: 2.8127 | Actual Loss: 0.7179\n",
      "Baseline Loss: 2.8261 | Actual Loss: 0.3084\n",
      "Baseline Loss: 2.7305 | Actual Loss: 0.1648\n",
      "Baseline Loss: 2.9045 | Actual Loss: 0.2233\n",
      "Baseline Loss: 2.8988 | Actual Loss: 0.4351\n",
      "Baseline Loss: 2.7985 | Actual Loss: 0.8091\n",
      "Baseline Loss: 2.8385 | Actual Loss: 0.2914\n",
      "Baseline Loss: 2.8457 | Actual Loss: 0.3499\n",
      "Baseline Loss: 2.8306 | Actual Loss: 0.5723\n",
      "Baseline Loss: 2.8886 | Actual Loss: 2.6872\n",
      "Baseline Loss: 2.8037 | Actual Loss: 0.5443\n",
      "Baseline Loss: 2.8288 | Actual Loss: 0.6045\n",
      "Baseline Loss: 2.7806 | Actual Loss: 0.2406\n",
      "Baseline Loss: 2.8592 | Actual Loss: 0.4870\n",
      "Baseline Loss: 2.7947 | Actual Loss: 2.7749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 92/1000 [00:52<08:31,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5323 | Actual Loss: 2.3072\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5596\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.1953\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2071\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4385\n",
      "Epoch 92/1000: Train Loss: 0.8449, Val Loss: 0.6001\n",
      "Baseline Loss: 2.8837 | Actual Loss: 0.2920\n",
      "Baseline Loss: 2.7969 | Actual Loss: 0.4973\n",
      "Baseline Loss: 2.8251 | Actual Loss: 0.5181\n",
      "Baseline Loss: 2.8142 | Actual Loss: 0.8647\n",
      "Baseline Loss: 2.9444 | Actual Loss: 0.4637\n",
      "Baseline Loss: 2.7466 | Actual Loss: 0.7106\n",
      "Baseline Loss: 2.8581 | Actual Loss: 0.2639\n",
      "Baseline Loss: 2.8921 | Actual Loss: 0.2766\n",
      "Baseline Loss: 2.8484 | Actual Loss: 2.7582\n",
      "Baseline Loss: 2.8107 | Actual Loss: 0.4916\n",
      "Baseline Loss: 2.8171 | Actual Loss: 0.5430\n",
      "Baseline Loss: 2.8889 | Actual Loss: 0.3700\n",
      "Baseline Loss: 2.7477 | Actual Loss: 0.5793\n",
      "Baseline Loss: 2.8210 | Actual Loss: 0.6532\n",
      "Baseline Loss: 2.7720 | Actual Loss: 0.2853\n",
      "Baseline Loss: 2.4015 | Actual Loss: 3.2638\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 93/1000 [00:53<08:39,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7887 | Actual Loss: 0.4724\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1919\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4501\n",
      "Epoch 93/1000: Train Loss: 0.8020, Val Loss: 0.4241\n",
      "Baseline Loss: 2.9262 | Actual Loss: 0.3354\n",
      "Baseline Loss: 2.8262 | Actual Loss: 0.2524\n",
      "Baseline Loss: 2.8156 | Actual Loss: 0.5382\n",
      "Baseline Loss: 2.8438 | Actual Loss: 2.9552\n",
      "Baseline Loss: 2.8458 | Actual Loss: 0.2114\n",
      "Baseline Loss: 2.8809 | Actual Loss: 1.4439\n",
      "Baseline Loss: 2.8236 | Actual Loss: 0.3466\n",
      "Baseline Loss: 2.8547 | Actual Loss: 0.2336\n",
      "Baseline Loss: 2.8136 | Actual Loss: 0.5198\n",
      "Baseline Loss: 2.8416 | Actual Loss: 0.4303\n",
      "Baseline Loss: 2.7269 | Actual Loss: 1.1568\n",
      "Baseline Loss: 2.7804 | Actual Loss: 1.4527\n",
      "Baseline Loss: 2.8160 | Actual Loss: 0.5711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 94/1000 [00:53<08:27,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8983 | Actual Loss: 0.2119\n",
      "Baseline Loss: 2.8198 | Actual Loss: 2.5507\n",
      "Baseline Loss: 2.4895 | Actual Loss: 0.7521\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5169\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.5531\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1418\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.3499\n",
      "Epoch 94/1000: Train Loss: 0.8726, Val Loss: 0.6404\n",
      "Baseline Loss: 2.9690 | Actual Loss: 0.1265\n",
      "Baseline Loss: 2.7828 | Actual Loss: 0.5083\n",
      "Baseline Loss: 2.8054 | Actual Loss: 0.5500\n",
      "Baseline Loss: 2.8701 | Actual Loss: 0.3252\n",
      "Baseline Loss: 2.8023 | Actual Loss: 2.7536\n",
      "Baseline Loss: 2.8940 | Actual Loss: 0.5111\n",
      "Baseline Loss: 2.8202 | Actual Loss: 0.4683\n",
      "Baseline Loss: 2.8893 | Actual Loss: 0.3101\n",
      "Baseline Loss: 2.7863 | Actual Loss: 0.8506\n",
      "Baseline Loss: 2.9029 | Actual Loss: 0.2591\n",
      "Baseline Loss: 2.7955 | Actual Loss: 0.4395\n",
      "Baseline Loss: 2.7690 | Actual Loss: 1.7641\n",
      "Baseline Loss: 2.8059 | Actual Loss: 0.4923\n",
      "Baseline Loss: 2.8014 | Actual Loss: 0.6982\n",
      "Baseline Loss: 2.8362 | Actual Loss: 0.2198\n",
      "Baseline Loss: 2.4463 | Actual Loss: 2.8066\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.6203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 95/1000 [00:54<08:36,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7887 | Actual Loss: 0.5766\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2421\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.3299\n",
      "Epoch 95/1000: Train Loss: 0.8177, Val Loss: 0.4422\n",
      "Baseline Loss: 2.8935 | Actual Loss: 0.6942\n",
      "Baseline Loss: 2.7988 | Actual Loss: 0.8483\n",
      "Baseline Loss: 2.8559 | Actual Loss: 0.6069\n",
      "Baseline Loss: 2.8279 | Actual Loss: 0.2663\n",
      "Baseline Loss: 2.8649 | Actual Loss: 0.5165\n",
      "Baseline Loss: 2.8086 | Actual Loss: 0.5390\n",
      "Baseline Loss: 2.8668 | Actual Loss: 0.2273\n",
      "Baseline Loss: 2.7837 | Actual Loss: 0.3251\n",
      "Baseline Loss: 2.7860 | Actual Loss: 0.2275\n",
      "Baseline Loss: 2.7900 | Actual Loss: 0.2409\n",
      "Baseline Loss: 2.7655 | Actual Loss: 0.2349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 96/1000 [00:54<08:35,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8260 | Actual Loss: 0.2262\n",
      "Baseline Loss: 2.8677 | Actual Loss: 0.1970\n",
      "Baseline Loss: 2.8392 | Actual Loss: 0.3087\n",
      "Baseline Loss: 2.8080 | Actual Loss: 0.6681\n",
      "Baseline Loss: 2.4545 | Actual Loss: 0.6608\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5360\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.9572\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1968\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.2024\n",
      "Epoch 96/1000: Train Loss: 0.4242, Val Loss: 0.4731\n",
      "Baseline Loss: 2.7557 | Actual Loss: 0.4738\n",
      "Baseline Loss: 2.8113 | Actual Loss: 0.2816\n",
      "Baseline Loss: 2.7846 | Actual Loss: 0.2897\n",
      "Baseline Loss: 2.8633 | Actual Loss: 0.2959\n",
      "Baseline Loss: 2.8584 | Actual Loss: 0.4413\n",
      "Baseline Loss: 2.8074 | Actual Loss: 0.2186\n",
      "Baseline Loss: 2.8613 | Actual Loss: 0.1376\n",
      "Baseline Loss: 2.7865 | Actual Loss: 3.1227\n",
      "Baseline Loss: 2.8079 | Actual Loss: 0.3890\n",
      "Baseline Loss: 2.8543 | Actual Loss: 0.4211\n",
      "Baseline Loss: 2.8786 | Actual Loss: 0.8430\n",
      "Baseline Loss: 2.8029 | Actual Loss: 2.7472\n",
      "Baseline Loss: 2.8086 | Actual Loss: 1.1754\n",
      "Baseline Loss: 2.8592 | Actual Loss: 0.2770\n",
      "Baseline Loss: 2.8168 | Actual Loss: 0.4274\n",
      "Baseline Loss: 2.6986 | Actual Loss: 2.2171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 97/1000 [00:55<08:21,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8420 | Actual Loss: 0.5246\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.3316\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.3277\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.2674\n",
      "Epoch 97/1000: Train Loss: 0.8599, Val Loss: 0.6128\n",
      "Baseline Loss: 2.8165 | Actual Loss: 0.2627\n",
      "Baseline Loss: 2.8644 | Actual Loss: 0.8542\n",
      "Baseline Loss: 2.7883 | Actual Loss: 0.4759\n",
      "Baseline Loss: 2.9258 | Actual Loss: 0.1914\n",
      "Baseline Loss: 2.7719 | Actual Loss: 0.4875\n",
      "Baseline Loss: 2.8201 | Actual Loss: 0.4651\n",
      "Baseline Loss: 2.7816 | Actual Loss: 0.1717\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.4334\n",
      "Baseline Loss: 2.8405 | Actual Loss: 0.4580\n",
      "Baseline Loss: 2.7457 | Actual Loss: 0.5299\n",
      "Baseline Loss: 2.8602 | Actual Loss: 0.3848\n",
      "Baseline Loss: 2.8490 | Actual Loss: 0.5652\n",
      "Baseline Loss: 2.8248 | Actual Loss: 0.6224\n",
      "Baseline Loss: 2.8326 | Actual Loss: 0.9195\n",
      "Baseline Loss: 2.9319 | Actual Loss: 0.3673\n",
      "Baseline Loss: 2.6073 | Actual Loss: 2.5563\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5816\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.3040\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 98/1000 [00:55<08:29,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7147 | Actual Loss: 0.2789\n",
      "Epoch 98/1000: Train Loss: 0.6091, Val Loss: 0.5766\n",
      "Baseline Loss: 2.8535 | Actual Loss: 0.4067\n",
      "Baseline Loss: 2.7646 | Actual Loss: 0.3836\n",
      "Baseline Loss: 2.8039 | Actual Loss: 0.4269\n",
      "Baseline Loss: 2.7818 | Actual Loss: 0.2306\n",
      "Baseline Loss: 2.8241 | Actual Loss: 0.3335\n",
      "Baseline Loss: 2.7484 | Actual Loss: 0.8944\n",
      "Baseline Loss: 2.9450 | Actual Loss: 0.7585\n",
      "Baseline Loss: 2.8036 | Actual Loss: 0.3989\n",
      "Baseline Loss: 2.8146 | Actual Loss: 0.5915\n",
      "Baseline Loss: 2.7994 | Actual Loss: 0.1994\n",
      "Baseline Loss: 2.7731 | Actual Loss: 2.1023\n",
      "Baseline Loss: 2.8273 | Actual Loss: 0.5163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 99/1000 [00:56<08:38,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8841 | Actual Loss: 0.1664\n",
      "Baseline Loss: 2.8787 | Actual Loss: 0.4763\n",
      "Baseline Loss: 2.8669 | Actual Loss: 1.3512\n",
      "Baseline Loss: 2.5350 | Actual Loss: 0.1684\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5266\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.9806\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1575\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.2412\n",
      "Epoch 99/1000: Train Loss: 0.5878, Val Loss: 0.4765\n",
      "Baseline Loss: 2.8305 | Actual Loss: 0.3912\n",
      "Baseline Loss: 2.8758 | Actual Loss: 2.3463\n",
      "Baseline Loss: 2.8344 | Actual Loss: 0.4834\n",
      "Baseline Loss: 2.7827 | Actual Loss: 0.2538\n",
      "Baseline Loss: 2.8741 | Actual Loss: 0.5228\n",
      "Baseline Loss: 2.8583 | Actual Loss: 1.1406\n",
      "Baseline Loss: 2.7716 | Actual Loss: 1.1401\n",
      "Baseline Loss: 2.8314 | Actual Loss: 0.4261\n",
      "Baseline Loss: 2.8319 | Actual Loss: 3.0684\n",
      "Baseline Loss: 2.8492 | Actual Loss: 1.4199\n",
      "Baseline Loss: 2.8196 | Actual Loss: 0.2513\n",
      "Baseline Loss: 2.8384 | Actual Loss: 0.0850\n",
      "Baseline Loss: 2.8304 | Actual Loss: 0.1980\n",
      "Baseline Loss: 2.7845 | Actual Loss: 0.5781\n",
      "Baseline Loss: 2.8481 | Actual Loss: 0.4057\n",
      "Baseline Loss: 2.5613 | Actual Loss: 2.3692\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 100/1000 [00:57<08:49,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7887 | Actual Loss: 1.6794\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2562\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.3223\n",
      "Epoch 100/1000: Train Loss: 0.9425, Val Loss: 0.6980\n",
      "Baseline Loss: 2.8145 | Actual Loss: 0.5997\n",
      "Baseline Loss: 2.8031 | Actual Loss: 0.6235\n",
      "Baseline Loss: 2.8032 | Actual Loss: 0.3784\n",
      "Baseline Loss: 2.7999 | Actual Loss: 0.4832\n",
      "Baseline Loss: 2.8367 | Actual Loss: 0.3155\n",
      "Baseline Loss: 2.9482 | Actual Loss: 0.3245\n",
      "Baseline Loss: 2.8109 | Actual Loss: 0.2362\n",
      "Baseline Loss: 2.8311 | Actual Loss: 0.1872\n",
      "Baseline Loss: 2.7604 | Actual Loss: 0.3044\n",
      "Baseline Loss: 2.8212 | Actual Loss: 0.4667\n",
      "Baseline Loss: 2.8356 | Actual Loss: 0.6274\n",
      "Baseline Loss: 2.7923 | Actual Loss: 2.6805\n",
      "Baseline Loss: 2.8287 | Actual Loss: 0.2216\n",
      "Baseline Loss: 2.8351 | Actual Loss: 0.1952\n",
      "Baseline Loss: 2.8539 | Actual Loss: 0.4738\n",
      "Baseline Loss: 2.6532 | Actual Loss: 3.0660\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5524\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.3746\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 101/1000 [00:57<08:22,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7147 | Actual Loss: 0.4549\n",
      "Epoch 101/1000: Train Loss: 0.6990, Val Loss: 0.6556\n",
      "Baseline Loss: 2.7636 | Actual Loss: 0.2903\n",
      "Baseline Loss: 2.8419 | Actual Loss: 0.3978\n",
      "Baseline Loss: 2.8081 | Actual Loss: 0.4231\n",
      "Baseline Loss: 2.8421 | Actual Loss: 0.3806\n",
      "Baseline Loss: 2.8191 | Actual Loss: 0.7214\n",
      "Baseline Loss: 2.7760 | Actual Loss: 0.2220\n",
      "Baseline Loss: 2.9784 | Actual Loss: 0.2629\n",
      "Baseline Loss: 2.7614 | Actual Loss: 2.4414\n",
      "Baseline Loss: 2.8391 | Actual Loss: 0.2704\n",
      "Baseline Loss: 2.8195 | Actual Loss: 3.0647\n",
      "Baseline Loss: 2.8546 | Actual Loss: 0.3604\n",
      "Baseline Loss: 2.8243 | Actual Loss: 0.1366\n",
      "Baseline Loss: 2.9041 | Actual Loss: 0.2421\n",
      "Baseline Loss: 2.8340 | Actual Loss: 1.9667\n",
      "Baseline Loss: 2.7854 | Actual Loss: 0.1801\n",
      "Baseline Loss: 2.4735 | Actual Loss: 2.6834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 102/1000 [00:58<08:29,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8420 | Actual Loss: 0.6727\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.3575\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1313\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4361\n",
      "Epoch 102/1000: Train Loss: 0.8777, Val Loss: 0.6494\n",
      "Baseline Loss: 2.7789 | Actual Loss: 0.4735\n",
      "Baseline Loss: 2.8776 | Actual Loss: 0.6768\n",
      "Baseline Loss: 2.7830 | Actual Loss: 0.1973\n",
      "Baseline Loss: 2.8006 | Actual Loss: 0.1909\n",
      "Baseline Loss: 2.7683 | Actual Loss: 0.2126\n",
      "Baseline Loss: 2.8277 | Actual Loss: 0.5495\n",
      "Baseline Loss: 2.8619 | Actual Loss: 2.3010\n",
      "Baseline Loss: 2.8437 | Actual Loss: 0.5632\n",
      "Baseline Loss: 2.8750 | Actual Loss: 0.3369\n",
      "Baseline Loss: 2.8618 | Actual Loss: 0.5750\n",
      "Baseline Loss: 2.8710 | Actual Loss: 0.2354\n",
      "Baseline Loss: 2.7889 | Actual Loss: 0.3957\n",
      "Baseline Loss: 2.9035 | Actual Loss: 0.3995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 103/1000 [00:58<08:17,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8003 | Actual Loss: 0.8303\n",
      "Baseline Loss: 2.8410 | Actual Loss: 0.7001\n",
      "Baseline Loss: 2.4907 | Actual Loss: 0.1561\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.6199\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.0415\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2368\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.2993\n",
      "Epoch 103/1000: Train Loss: 0.5496, Val Loss: 0.5494\n",
      "Baseline Loss: 2.8344 | Actual Loss: 1.2920\n",
      "Baseline Loss: 2.8084 | Actual Loss: 0.6678\n",
      "Baseline Loss: 2.8692 | Actual Loss: 0.6360\n",
      "Baseline Loss: 2.7915 | Actual Loss: 0.1991\n",
      "Baseline Loss: 2.7526 | Actual Loss: 0.3699\n",
      "Baseline Loss: 2.8325 | Actual Loss: 0.3914\n",
      "Baseline Loss: 2.8639 | Actual Loss: 0.9714\n",
      "Baseline Loss: 2.8399 | Actual Loss: 2.5122\n",
      "Baseline Loss: 2.8387 | Actual Loss: 0.3894\n",
      "Baseline Loss: 2.8837 | Actual Loss: 0.5385\n",
      "Baseline Loss: 2.8545 | Actual Loss: 0.5555\n",
      "Baseline Loss: 2.7894 | Actual Loss: 0.4797\n",
      "Baseline Loss: 2.8254 | Actual Loss: 0.5095\n",
      "Baseline Loss: 2.7646 | Actual Loss: 0.2336\n",
      "Baseline Loss: 2.7947 | Actual Loss: 0.5306\n",
      "Baseline Loss: 2.4601 | Actual Loss: 0.5360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 104/1000 [00:59<08:25,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8420 | Actual Loss: 0.6318\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.6496\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2678\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.3337\n",
      "Epoch 104/1000: Train Loss: 0.6758, Val Loss: 0.7207\n",
      "Baseline Loss: 2.8147 | Actual Loss: 0.5822\n",
      "Baseline Loss: 2.8139 | Actual Loss: 0.5004\n",
      "Baseline Loss: 2.7718 | Actual Loss: 0.2234\n",
      "Baseline Loss: 2.9014 | Actual Loss: 0.5906\n",
      "Baseline Loss: 2.8304 | Actual Loss: 0.3658\n",
      "Baseline Loss: 2.8592 | Actual Loss: 0.6083\n",
      "Baseline Loss: 2.7933 | Actual Loss: 2.5366\n",
      "Baseline Loss: 2.8554 | Actual Loss: 2.7695\n",
      "Baseline Loss: 2.8622 | Actual Loss: 0.5079\n",
      "Baseline Loss: 2.8665 | Actual Loss: 0.5484\n",
      "Baseline Loss: 2.8475 | Actual Loss: 2.6753\n",
      "Baseline Loss: 2.7907 | Actual Loss: 0.2388\n",
      "Baseline Loss: 2.8030 | Actual Loss: 0.3175\n",
      "Baseline Loss: 2.8184 | Actual Loss: 0.9589\n",
      "Baseline Loss: 2.7706 | Actual Loss: 1.7296\n",
      "Baseline Loss: 2.4392 | Actual Loss: 2.3150\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.6598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 105/1000 [00:59<08:34,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7887 | Actual Loss: 1.0650\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2410\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4539\n",
      "Epoch 105/1000: Train Loss: 1.0918, Val Loss: 0.6049\n",
      "Baseline Loss: 2.8301 | Actual Loss: 0.4006\n",
      "Baseline Loss: 2.8606 | Actual Loss: 0.2376\n",
      "Baseline Loss: 2.8432 | Actual Loss: 0.3267\n",
      "Baseline Loss: 2.8374 | Actual Loss: 0.4561\n",
      "Baseline Loss: 2.8324 | Actual Loss: 0.2274\n",
      "Baseline Loss: 2.8337 | Actual Loss: 2.5830\n",
      "Baseline Loss: 2.9098 | Actual Loss: 0.2550\n",
      "Baseline Loss: 2.7860 | Actual Loss: 0.5480\n",
      "Baseline Loss: 2.8376 | Actual Loss: 2.8763\n",
      "Baseline Loss: 2.8157 | Actual Loss: 0.6897\n",
      "Baseline Loss: 2.8018 | Actual Loss: 2.7095\n",
      "Baseline Loss: 2.7661 | Actual Loss: 0.3139\n",
      "Baseline Loss: 2.8146 | Actual Loss: 0.3261\n",
      "Baseline Loss: 2.7669 | Actual Loss: 0.6005\n",
      "Baseline Loss: 2.8235 | Actual Loss: 0.4012\n",
      "Baseline Loss: 2.5474 | Actual Loss: 0.1331\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.4972\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.4839\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 106/1000 [01:00<08:42,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7147 | Actual Loss: 0.4610\n",
      "Epoch 106/1000: Train Loss: 0.8178, Val Loss: 0.4254\n",
      "Baseline Loss: 2.8473 | Actual Loss: 0.8247\n",
      "Baseline Loss: 2.8113 | Actual Loss: 0.4612\n",
      "Baseline Loss: 2.7896 | Actual Loss: 0.8680\n",
      "Baseline Loss: 2.8466 | Actual Loss: 0.2214\n",
      "Baseline Loss: 2.7424 | Actual Loss: 0.4315\n",
      "Baseline Loss: 2.8874 | Actual Loss: 0.4766\n",
      "Baseline Loss: 2.7921 | Actual Loss: 0.5140\n",
      "Baseline Loss: 2.8403 | Actual Loss: 0.2443\n",
      "Baseline Loss: 2.8089 | Actual Loss: 0.6745\n",
      "Baseline Loss: 2.8713 | Actual Loss: 2.7834\n",
      "Baseline Loss: 2.8178 | Actual Loss: 1.3503\n",
      "Baseline Loss: 2.8374 | Actual Loss: 0.3621\n",
      "Baseline Loss: 2.8360 | Actual Loss: 0.7124\n",
      "Baseline Loss: 2.7675 | Actual Loss: 0.3651\n",
      "Baseline Loss: 2.8158 | Actual Loss: 0.5102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 107/1000 [01:01<08:21,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6761 | Actual Loss: 2.1197\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5553\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.3496\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1657\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4747\n",
      "Epoch 107/1000: Train Loss: 0.8075, Val Loss: 0.3863\n",
      "New best validation loss: 0.3863\n",
      "Baseline Loss: 2.7882 | Actual Loss: 0.3798\n",
      "Baseline Loss: 2.8790 | Actual Loss: 0.7049\n",
      "Baseline Loss: 2.8090 | Actual Loss: 0.4895\n",
      "Baseline Loss: 2.7854 | Actual Loss: 2.8549\n",
      "Baseline Loss: 2.8546 | Actual Loss: 0.3350\n",
      "Baseline Loss: 2.7591 | Actual Loss: 0.4674\n",
      "Baseline Loss: 2.8620 | Actual Loss: 0.1990\n",
      "Baseline Loss: 2.8792 | Actual Loss: 0.5422\n",
      "Baseline Loss: 2.7818 | Actual Loss: 0.1323\n",
      "Baseline Loss: 2.8203 | Actual Loss: 0.2756\n",
      "Baseline Loss: 2.8096 | Actual Loss: 0.3437\n",
      "Baseline Loss: 2.8917 | Actual Loss: 0.5060\n",
      "Baseline Loss: 2.8452 | Actual Loss: 2.7192\n",
      "Baseline Loss: 2.8279 | Actual Loss: 0.5061\n",
      "Baseline Loss: 2.8772 | Actual Loss: 0.1880\n",
      "Baseline Loss: 2.6339 | Actual Loss: 0.1705\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 108/1000 [01:01<08:27,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7887 | Actual Loss: 2.4332\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1686\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4623\n",
      "Epoch 108/1000: Train Loss: 0.6759, Val Loss: 0.9037\n",
      "Baseline Loss: 2.8032 | Actual Loss: 0.2486\n",
      "Baseline Loss: 2.8971 | Actual Loss: 0.5265\n",
      "Baseline Loss: 2.8451 | Actual Loss: 0.2428\n",
      "Baseline Loss: 2.9080 | Actual Loss: 0.4800\n",
      "Baseline Loss: 2.7917 | Actual Loss: 0.2226\n",
      "Baseline Loss: 2.7621 | Actual Loss: 0.8424\n",
      "Baseline Loss: 2.7939 | Actual Loss: 0.0812\n",
      "Baseline Loss: 2.9228 | Actual Loss: 0.2445\n",
      "Baseline Loss: 2.8001 | Actual Loss: 0.2318\n",
      "Baseline Loss: 2.7816 | Actual Loss: 0.1541\n",
      "Baseline Loss: 2.8306 | Actual Loss: 0.3132\n",
      "Baseline Loss: 2.7667 | Actual Loss: 0.2726\n",
      "Baseline Loss: 2.8817 | Actual Loss: 0.3540\n",
      "Baseline Loss: 2.8446 | Actual Loss: 1.9338\n",
      "Baseline Loss: 2.8012 | Actual Loss: 0.4342\n",
      "Baseline Loss: 2.4999 | Actual Loss: 2.3241\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.6277\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.9766\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 109/1000 [01:02<08:38,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7147 | Actual Loss: 0.4065\n",
      "Epoch 109/1000: Train Loss: 0.5566, Val Loss: 0.5389\n",
      "Baseline Loss: 2.8714 | Actual Loss: 0.2656\n",
      "Baseline Loss: 2.7777 | Actual Loss: 0.6257\n",
      "Baseline Loss: 2.8185 | Actual Loss: 2.6008\n",
      "Baseline Loss: 2.8501 | Actual Loss: 0.1234\n",
      "Baseline Loss: 2.7837 | Actual Loss: 0.3442\n",
      "Baseline Loss: 2.8202 | Actual Loss: 0.6169\n",
      "Baseline Loss: 2.8976 | Actual Loss: 2.6896\n",
      "Baseline Loss: 2.7898 | Actual Loss: 0.2634\n",
      "Baseline Loss: 2.8030 | Actual Loss: 0.2885\n",
      "Baseline Loss: 2.8038 | Actual Loss: 0.8696\n",
      "Baseline Loss: 2.7919 | Actual Loss: 0.2493\n",
      "Baseline Loss: 2.8426 | Actual Loss: 0.3223\n",
      "Baseline Loss: 2.8470 | Actual Loss: 0.3966\n",
      "Baseline Loss: 2.7987 | Actual Loss: 0.2418\n",
      "Baseline Loss: 2.8337 | Actual Loss: 0.2617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 110/1000 [01:02<08:21,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5559 | Actual Loss: 0.3952\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.6067\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.6751\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2011\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4632\n",
      "Epoch 110/1000: Train Loss: 0.6597, Val Loss: 0.7366\n",
      "Baseline Loss: 2.8203 | Actual Loss: 0.6448\n",
      "Baseline Loss: 2.8821 | Actual Loss: 0.8809\n",
      "Baseline Loss: 2.8855 | Actual Loss: 0.2124\n",
      "Baseline Loss: 2.8364 | Actual Loss: 0.2481\n",
      "Baseline Loss: 2.8851 | Actual Loss: 0.5751\n",
      "Baseline Loss: 2.8315 | Actual Loss: 1.2490\n",
      "Baseline Loss: 2.8290 | Actual Loss: 1.0359\n",
      "Baseline Loss: 2.8189 | Actual Loss: 0.2514\n",
      "Baseline Loss: 2.7930 | Actual Loss: 0.4006\n",
      "Baseline Loss: 2.7895 | Actual Loss: 0.2064\n",
      "Baseline Loss: 2.8449 | Actual Loss: 0.3022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 111/1000 [01:03<08:30,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8580 | Actual Loss: 0.4038\n",
      "Baseline Loss: 2.7763 | Actual Loss: 0.1564\n",
      "Baseline Loss: 2.8060 | Actual Loss: 0.6124\n",
      "Baseline Loss: 2.8260 | Actual Loss: 0.6002\n",
      "Baseline Loss: 2.6433 | Actual Loss: 0.1087\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.6395\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.0174\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1869\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4301\n",
      "Epoch 111/1000: Train Loss: 0.4930, Val Loss: 0.5685\n",
      "Baseline Loss: 2.8427 | Actual Loss: 0.8546\n",
      "Baseline Loss: 2.8418 | Actual Loss: 2.9376\n",
      "Baseline Loss: 2.8044 | Actual Loss: 0.3439\n",
      "Baseline Loss: 2.8387 | Actual Loss: 0.2410\n",
      "Baseline Loss: 2.8110 | Actual Loss: 0.5768\n",
      "Baseline Loss: 2.7433 | Actual Loss: 0.3502\n",
      "Baseline Loss: 2.8754 | Actual Loss: 0.4511\n",
      "Baseline Loss: 2.8477 | Actual Loss: 0.2713\n",
      "Baseline Loss: 2.7799 | Actual Loss: 2.0510\n",
      "Baseline Loss: 2.8123 | Actual Loss: 0.2407\n",
      "Baseline Loss: 2.8294 | Actual Loss: 0.1743\n",
      "Baseline Loss: 2.8463 | Actual Loss: 0.3051\n",
      "Baseline Loss: 2.7691 | Actual Loss: 0.7137\n",
      "Baseline Loss: 2.8235 | Actual Loss: 1.9779\n",
      "Baseline Loss: 2.8273 | Actual Loss: 0.3544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 112/1000 [01:03<08:16,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5516 | Actual Loss: 0.3050\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5563\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.0748\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.3729\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.3364\n",
      "Epoch 112/1000: Train Loss: 0.7593, Val Loss: 0.5851\n",
      "Baseline Loss: 2.8385 | Actual Loss: 0.2977\n",
      "Baseline Loss: 2.8706 | Actual Loss: 0.4788\n",
      "Baseline Loss: 2.8007 | Actual Loss: 1.8334\n",
      "Baseline Loss: 2.8011 | Actual Loss: 0.6972\n",
      "Baseline Loss: 2.8046 | Actual Loss: 0.8946\n",
      "Baseline Loss: 2.8668 | Actual Loss: 0.7212\n",
      "Baseline Loss: 2.8175 | Actual Loss: 0.3714\n",
      "Baseline Loss: 2.8461 | Actual Loss: 0.7496\n",
      "Baseline Loss: 2.7639 | Actual Loss: 0.2328\n",
      "Baseline Loss: 2.8390 | Actual Loss: 0.6581\n",
      "Baseline Loss: 2.8260 | Actual Loss: 0.4030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█▏        | 113/1000 [01:04<08:21,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9072 | Actual Loss: 0.3496\n",
      "Baseline Loss: 2.7959 | Actual Loss: 0.2215\n",
      "Baseline Loss: 2.8832 | Actual Loss: 0.2349\n",
      "Baseline Loss: 2.8282 | Actual Loss: 0.5688\n",
      "Baseline Loss: 2.5975 | Actual Loss: 0.2463\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.6370\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.2325\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1374\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4428\n",
      "Epoch 113/1000: Train Loss: 0.5599, Val Loss: 0.6124\n",
      "Baseline Loss: 2.9081 | Actual Loss: 0.2962\n",
      "Baseline Loss: 2.8495 | Actual Loss: 0.3123\n",
      "Baseline Loss: 2.8168 | Actual Loss: 2.4621\n",
      "Baseline Loss: 2.9091 | Actual Loss: 0.6644\n",
      "Baseline Loss: 2.7946 | Actual Loss: 2.4436\n",
      "Baseline Loss: 2.7288 | Actual Loss: 0.3808\n",
      "Baseline Loss: 2.8182 | Actual Loss: 0.3945\n",
      "Baseline Loss: 2.8860 | Actual Loss: 0.2558\n",
      "Baseline Loss: 2.8288 | Actual Loss: 2.7630\n",
      "Baseline Loss: 2.7839 | Actual Loss: 0.2887\n",
      "Baseline Loss: 2.8874 | Actual Loss: 0.2382\n",
      "Baseline Loss: 2.8427 | Actual Loss: 0.2414\n",
      "Baseline Loss: 2.8029 | Actual Loss: 0.2880\n",
      "Baseline Loss: 2.7987 | Actual Loss: 0.1503\n",
      "Baseline Loss: 2.8695 | Actual Loss: 0.2012\n",
      "Baseline Loss: 2.5573 | Actual Loss: 0.1150\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█▏        | 114/1000 [01:05<08:27,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7887 | Actual Loss: 1.4623\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1791\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.3288\n",
      "Epoch 114/1000: Train Loss: 0.7185, Val Loss: 0.6270\n",
      "Baseline Loss: 2.8127 | Actual Loss: 0.4028\n",
      "Baseline Loss: 2.8357 | Actual Loss: 0.3907\n",
      "Baseline Loss: 2.8692 | Actual Loss: 0.6484\n",
      "Baseline Loss: 2.7681 | Actual Loss: 0.2680\n",
      "Baseline Loss: 2.7822 | Actual Loss: 0.2467\n",
      "Baseline Loss: 2.8366 | Actual Loss: 0.1756\n",
      "Baseline Loss: 2.8159 | Actual Loss: 0.4598\n",
      "Baseline Loss: 2.7800 | Actual Loss: 0.3314\n",
      "Baseline Loss: 2.8917 | Actual Loss: 0.3783\n",
      "Baseline Loss: 2.9267 | Actual Loss: 0.5563\n",
      "Baseline Loss: 2.7367 | Actual Loss: 0.2610\n",
      "Baseline Loss: 2.8681 | Actual Loss: 0.7538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 115/1000 [01:05<08:10,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8406 | Actual Loss: 0.4595\n",
      "Baseline Loss: 2.8523 | Actual Loss: 0.6336\n",
      "Baseline Loss: 2.8164 | Actual Loss: 1.3296\n",
      "Baseline Loss: 2.4904 | Actual Loss: 0.3899\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5347\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.7999\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2147\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.3160\n",
      "Epoch 115/1000: Train Loss: 0.4803, Val Loss: 0.7163\n",
      "Baseline Loss: 2.7505 | Actual Loss: 0.3375\n",
      "Baseline Loss: 2.8776 | Actual Loss: 0.3873\n",
      "Baseline Loss: 2.8381 | Actual Loss: 2.7115\n",
      "Baseline Loss: 2.8364 | Actual Loss: 0.1749\n",
      "Baseline Loss: 2.8209 | Actual Loss: 2.3657\n",
      "Baseline Loss: 2.8071 | Actual Loss: 0.3224\n",
      "Baseline Loss: 2.8219 | Actual Loss: 0.2217\n",
      "Baseline Loss: 2.7871 | Actual Loss: 0.3927\n",
      "Baseline Loss: 2.8212 | Actual Loss: 0.4736\n",
      "Baseline Loss: 2.9235 | Actual Loss: 0.7393\n",
      "Baseline Loss: 2.8338 | Actual Loss: 0.5739\n",
      "Baseline Loss: 2.8368 | Actual Loss: 0.4890\n",
      "Baseline Loss: 2.8182 | Actual Loss: 0.7732\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.3149\n",
      "Baseline Loss: 2.8440 | Actual Loss: 0.2519\n",
      "Baseline Loss: 2.3895 | Actual Loss: 0.1857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 116/1000 [01:06<08:21,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8420 | Actual Loss: 0.6134\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.3910\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2629\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.2242\n",
      "Epoch 116/1000: Train Loss: 0.6697, Val Loss: 0.3729\n",
      "New best validation loss: 0.3729\n",
      "Baseline Loss: 2.8049 | Actual Loss: 0.3814\n",
      "Baseline Loss: 2.8163 | Actual Loss: 1.0322\n",
      "Baseline Loss: 2.8273 | Actual Loss: 0.4720\n",
      "Baseline Loss: 2.8385 | Actual Loss: 0.2935\n",
      "Baseline Loss: 2.8090 | Actual Loss: 0.3906\n",
      "Baseline Loss: 2.8343 | Actual Loss: 0.5002\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.4899\n",
      "Baseline Loss: 2.7482 | Actual Loss: 0.2486\n",
      "Baseline Loss: 2.9428 | Actual Loss: 0.5846\n",
      "Baseline Loss: 2.8111 | Actual Loss: 0.6324\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.6109\n",
      "Baseline Loss: 2.7888 | Actual Loss: 0.5217\n",
      "Baseline Loss: 2.8059 | Actual Loss: 0.2105\n",
      "Baseline Loss: 2.8301 | Actual Loss: 0.4254\n",
      "Baseline Loss: 2.8295 | Actual Loss: 0.6939\n",
      "Baseline Loss: 2.5757 | Actual Loss: 0.1363\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5618\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.5393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 117/1000 [01:06<08:30,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8632 | Actual Loss: 0.3344\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4896\n",
      "Epoch 117/1000: Train Loss: 0.4765, Val Loss: 0.4813\n",
      "Baseline Loss: 2.8629 | Actual Loss: 0.5046\n",
      "Baseline Loss: 2.8086 | Actual Loss: 0.3688\n",
      "Baseline Loss: 2.8654 | Actual Loss: 0.5335\n",
      "Baseline Loss: 2.9064 | Actual Loss: 0.4807\n",
      "Baseline Loss: 2.8671 | Actual Loss: 0.3388\n",
      "Baseline Loss: 2.8256 | Actual Loss: 0.1966\n",
      "Baseline Loss: 2.7860 | Actual Loss: 0.4146\n",
      "Baseline Loss: 2.8219 | Actual Loss: 0.6773\n",
      "Baseline Loss: 2.8561 | Actual Loss: 0.2384\n",
      "Baseline Loss: 2.8087 | Actual Loss: 1.1821\n",
      "Baseline Loss: 2.8606 | Actual Loss: 0.4718\n",
      "Baseline Loss: 2.8244 | Actual Loss: 2.8473\n",
      "Baseline Loss: 2.8500 | Actual Loss: 0.3211\n",
      "Baseline Loss: 2.7798 | Actual Loss: 0.1323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 118/1000 [01:07<08:09,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7813 | Actual Loss: 0.5178\n",
      "Baseline Loss: 2.5451 | Actual Loss: 0.2531\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5040\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.0004\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2561\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4151\n",
      "Epoch 118/1000: Train Loss: 0.5924, Val Loss: 0.5439\n",
      "Baseline Loss: 2.7875 | Actual Loss: 1.8842\n",
      "Baseline Loss: 2.9399 | Actual Loss: 0.3475\n",
      "Baseline Loss: 2.7399 | Actual Loss: 0.1322\n",
      "Baseline Loss: 2.8437 | Actual Loss: 0.4246\n",
      "Baseline Loss: 2.8084 | Actual Loss: 0.5178\n",
      "Baseline Loss: 2.8384 | Actual Loss: 0.3923\n",
      "Baseline Loss: 2.8000 | Actual Loss: 0.2290\n",
      "Baseline Loss: 2.8624 | Actual Loss: 0.3533\n",
      "Baseline Loss: 2.8427 | Actual Loss: 0.2870\n",
      "Baseline Loss: 2.9125 | Actual Loss: 0.7486\n",
      "Baseline Loss: 2.8140 | Actual Loss: 0.6534\n",
      "Baseline Loss: 2.7933 | Actual Loss: 0.5802\n",
      "Baseline Loss: 2.7583 | Actual Loss: 0.7636\n",
      "Baseline Loss: 2.7495 | Actual Loss: 0.5786\n",
      "Baseline Loss: 2.8242 | Actual Loss: 0.2893\n",
      "Baseline Loss: 2.6171 | Actual Loss: 0.2582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 119/1000 [01:07<08:22,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8420 | Actual Loss: 0.6095\n",
      "Baseline Loss: 2.7887 | Actual Loss: 2.1542\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2812\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4058\n",
      "Epoch 119/1000: Train Loss: 0.5275, Val Loss: 0.8627\n",
      "Baseline Loss: 2.8253 | Actual Loss: 0.2454\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.4352\n",
      "Baseline Loss: 2.8064 | Actual Loss: 0.3068\n",
      "Baseline Loss: 2.8067 | Actual Loss: 0.0954\n",
      "Baseline Loss: 2.7771 | Actual Loss: 0.0792\n",
      "Baseline Loss: 2.8569 | Actual Loss: 1.4004\n",
      "Baseline Loss: 2.8051 | Actual Loss: 0.5087\n",
      "Baseline Loss: 2.8537 | Actual Loss: 0.6178\n",
      "Baseline Loss: 2.8279 | Actual Loss: 0.6071\n",
      "Baseline Loss: 2.7630 | Actual Loss: 0.3652\n",
      "Baseline Loss: 2.8860 | Actual Loss: 0.5770\n",
      "Baseline Loss: 2.8423 | Actual Loss: 2.3927\n",
      "Baseline Loss: 2.7885 | Actual Loss: 0.5748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 120/1000 [01:08<08:00,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7614 | Actual Loss: 0.5386\n",
      "Baseline Loss: 2.8663 | Actual Loss: 0.2758\n",
      "Baseline Loss: 2.5496 | Actual Loss: 0.2703\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.4959\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.0587\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1405\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4499\n",
      "Epoch 120/1000: Train Loss: 0.5806, Val Loss: 0.5362\n",
      "Baseline Loss: 2.8387 | Actual Loss: 0.4567\n",
      "Baseline Loss: 2.8149 | Actual Loss: 0.4911\n",
      "Baseline Loss: 2.8144 | Actual Loss: 0.2223\n",
      "Baseline Loss: 2.8467 | Actual Loss: 0.2663\n",
      "Baseline Loss: 2.8824 | Actual Loss: 0.5361\n",
      "Baseline Loss: 2.8262 | Actual Loss: 0.8259\n",
      "Baseline Loss: 2.7565 | Actual Loss: 0.1725\n",
      "Baseline Loss: 2.7924 | Actual Loss: 0.4753\n",
      "Baseline Loss: 2.7868 | Actual Loss: 0.5787\n",
      "Baseline Loss: 2.9288 | Actual Loss: 0.4856\n",
      "Baseline Loss: 2.7972 | Actual Loss: 0.5316\n",
      "Baseline Loss: 2.7879 | Actual Loss: 0.2266\n",
      "Baseline Loss: 2.8250 | Actual Loss: 0.3522\n",
      "Baseline Loss: 2.8601 | Actual Loss: 0.5463\n",
      "Baseline Loss: 2.8062 | Actual Loss: 0.4339\n",
      "Baseline Loss: 2.6815 | Actual Loss: 0.2981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 121/1000 [01:09<08:09,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8420 | Actual Loss: 0.5744\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.8644\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1761\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.2828\n",
      "Epoch 121/1000: Train Loss: 0.4312, Val Loss: 0.7244\n",
      "Baseline Loss: 2.8021 | Actual Loss: 0.2985\n",
      "Baseline Loss: 2.8263 | Actual Loss: 0.0753\n",
      "Baseline Loss: 2.8501 | Actual Loss: 0.5048\n",
      "Baseline Loss: 2.8254 | Actual Loss: 0.4833\n",
      "Baseline Loss: 2.8114 | Actual Loss: 0.2581\n",
      "Baseline Loss: 2.9052 | Actual Loss: 0.2449\n",
      "Baseline Loss: 2.7930 | Actual Loss: 0.4325\n",
      "Baseline Loss: 2.7771 | Actual Loss: 0.8693\n",
      "Baseline Loss: 2.8378 | Actual Loss: 0.2186\n",
      "Baseline Loss: 2.8348 | Actual Loss: 0.2543\n",
      "Baseline Loss: 2.7808 | Actual Loss: 1.2202\n",
      "Baseline Loss: 2.7910 | Actual Loss: 0.3661\n",
      "Baseline Loss: 2.7969 | Actual Loss: 0.3970\n",
      "Baseline Loss: 2.8454 | Actual Loss: 0.5324\n",
      "Baseline Loss: 2.8378 | Actual Loss: 1.0581\n",
      "Baseline Loss: 2.6932 | Actual Loss: 3.3487\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5369\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.7829\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.3545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 122/1000 [01:09<08:22,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7147 | Actual Loss: 0.3197\n",
      "Epoch 122/1000: Train Loss: 0.6601, Val Loss: 0.4985\n",
      "Baseline Loss: 2.8575 | Actual Loss: 0.4006\n",
      "Baseline Loss: 2.8324 | Actual Loss: 2.5891\n",
      "Baseline Loss: 2.7854 | Actual Loss: 0.3107\n",
      "Baseline Loss: 2.8588 | Actual Loss: 0.6778\n",
      "Baseline Loss: 2.7788 | Actual Loss: 0.3534\n",
      "Baseline Loss: 2.8351 | Actual Loss: 0.2000\n",
      "Baseline Loss: 2.8368 | Actual Loss: 0.6042\n",
      "Baseline Loss: 2.8364 | Actual Loss: 0.5091\n",
      "Baseline Loss: 2.8507 | Actual Loss: 0.3580\n",
      "Baseline Loss: 2.8121 | Actual Loss: 0.7042\n",
      "Baseline Loss: 2.8487 | Actual Loss: 0.3042\n",
      "Baseline Loss: 2.8865 | Actual Loss: 0.8787\n",
      "Baseline Loss: 2.8559 | Actual Loss: 0.3768\n",
      "Baseline Loss: 2.8032 | Actual Loss: 0.5807\n",
      "Baseline Loss: 2.7960 | Actual Loss: 0.3229\n",
      "Baseline Loss: 2.4735 | Actual Loss: 0.1336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 123/1000 [01:10<08:03,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8420 | Actual Loss: 0.5563\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.6806\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1612\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4395\n",
      "Epoch 123/1000: Train Loss: 0.5815, Val Loss: 0.7094\n",
      "Baseline Loss: 2.7937 | Actual Loss: 0.6620\n",
      "Baseline Loss: 2.8063 | Actual Loss: 0.2420\n",
      "Baseline Loss: 2.7358 | Actual Loss: 0.6393\n",
      "Baseline Loss: 2.8495 | Actual Loss: 0.1520\n",
      "Baseline Loss: 2.8500 | Actual Loss: 0.4421\n",
      "Baseline Loss: 2.8164 | Actual Loss: 0.5158\n",
      "Baseline Loss: 2.8777 | Actual Loss: 0.2464\n",
      "Baseline Loss: 2.8361 | Actual Loss: 0.7198\n",
      "Baseline Loss: 2.7854 | Actual Loss: 2.7722\n",
      "Baseline Loss: 2.8713 | Actual Loss: 0.5025\n",
      "Baseline Loss: 2.8400 | Actual Loss: 0.3583\n",
      "Baseline Loss: 2.7423 | Actual Loss: 0.2798\n",
      "Baseline Loss: 2.7741 | Actual Loss: 0.4905\n",
      "Baseline Loss: 2.8541 | Actual Loss: 2.7542\n",
      "Baseline Loss: 2.8421 | Actual Loss: 0.4553\n",
      "Baseline Loss: 2.7250 | Actual Loss: 0.1007\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5540\n",
      "Baseline Loss: 2.7887 | Actual Loss: 2.5089\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 124/1000 [01:10<08:11,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7147 | Actual Loss: 0.3998\n",
      "Epoch 124/1000: Train Loss: 0.7083, Val Loss: 0.9143\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.2353\n",
      "Baseline Loss: 2.8483 | Actual Loss: 0.3361\n",
      "Baseline Loss: 2.8504 | Actual Loss: 0.2775\n",
      "Baseline Loss: 2.8182 | Actual Loss: 0.2605\n",
      "Baseline Loss: 2.7875 | Actual Loss: 0.1457\n",
      "Baseline Loss: 2.7865 | Actual Loss: 0.2037\n",
      "Baseline Loss: 2.8989 | Actual Loss: 0.8788\n",
      "Baseline Loss: 2.8524 | Actual Loss: 0.3586\n",
      "Baseline Loss: 2.8311 | Actual Loss: 0.3647\n",
      "Baseline Loss: 2.7719 | Actual Loss: 0.5480\n",
      "Baseline Loss: 2.8110 | Actual Loss: 0.9147\n",
      "Baseline Loss: 2.8824 | Actual Loss: 0.1256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▎        | 125/1000 [01:11<08:17,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7977 | Actual Loss: 0.2704\n",
      "Baseline Loss: 2.8104 | Actual Loss: 0.4455\n",
      "Baseline Loss: 2.8937 | Actual Loss: 0.2767\n",
      "Baseline Loss: 2.5552 | Actual Loss: 0.7850\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5518\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.8504\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2950\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.3607\n",
      "Epoch 125/1000: Train Loss: 0.4017, Val Loss: 0.5145\n",
      "Baseline Loss: 2.8965 | Actual Loss: 0.6268\n",
      "Baseline Loss: 2.7853 | Actual Loss: 0.3155\n",
      "Baseline Loss: 2.8415 | Actual Loss: 0.4000\n",
      "Baseline Loss: 2.8216 | Actual Loss: 0.3135\n",
      "Baseline Loss: 2.8520 | Actual Loss: 0.3396\n",
      "Baseline Loss: 2.7937 | Actual Loss: 0.4461\n",
      "Baseline Loss: 2.7536 | Actual Loss: 0.5374\n",
      "Baseline Loss: 2.8249 | Actual Loss: 0.3791\n",
      "Baseline Loss: 2.8078 | Actual Loss: 0.1166\n",
      "Baseline Loss: 2.8127 | Actual Loss: 0.2842\n",
      "Baseline Loss: 2.8455 | Actual Loss: 0.8829\n",
      "Baseline Loss: 2.8275 | Actual Loss: 0.6022\n",
      "Baseline Loss: 2.8637 | Actual Loss: 0.2055\n",
      "Baseline Loss: 2.8696 | Actual Loss: 0.2520\n",
      "Baseline Loss: 2.8263 | Actual Loss: 0.5760\n",
      "Baseline Loss: 2.4448 | Actual Loss: 0.0982\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5657\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.4530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 126/1000 [01:11<07:56,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8632 | Actual Loss: 0.2708\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4447\n",
      "Epoch 126/1000: Train Loss: 0.3985, Val Loss: 0.6835\n",
      "Baseline Loss: 2.7842 | Actual Loss: 0.5126\n",
      "Baseline Loss: 2.7739 | Actual Loss: 0.4821\n",
      "Baseline Loss: 2.8051 | Actual Loss: 0.4576\n",
      "Baseline Loss: 2.8270 | Actual Loss: 0.2309\n",
      "Baseline Loss: 2.9093 | Actual Loss: 0.5190\n",
      "Baseline Loss: 2.7390 | Actual Loss: 0.2225\n",
      "Baseline Loss: 2.7871 | Actual Loss: 0.4213\n",
      "Baseline Loss: 2.7958 | Actual Loss: 0.2630\n",
      "Baseline Loss: 2.8169 | Actual Loss: 0.1001\n",
      "Baseline Loss: 2.8255 | Actual Loss: 0.6899\n",
      "Baseline Loss: 2.9069 | Actual Loss: 0.9724\n",
      "Baseline Loss: 2.8410 | Actual Loss: 0.6089\n",
      "Baseline Loss: 2.8223 | Actual Loss: 2.8706\n",
      "Baseline Loss: 2.8481 | Actual Loss: 0.8873\n",
      "Baseline Loss: 2.8298 | Actual Loss: 1.5089\n",
      "Baseline Loss: 2.6679 | Actual Loss: 0.0297\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5731\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.6523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 127/1000 [01:12<08:12,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8632 | Actual Loss: 0.1490\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.2821\n",
      "Epoch 127/1000: Train Loss: 0.6736, Val Loss: 0.4141\n",
      "Baseline Loss: 2.8432 | Actual Loss: 0.2452\n",
      "Baseline Loss: 2.8446 | Actual Loss: 0.2053\n",
      "Baseline Loss: 2.8574 | Actual Loss: 0.4873\n",
      "Baseline Loss: 2.8065 | Actual Loss: 0.7933\n",
      "Baseline Loss: 2.9086 | Actual Loss: 0.3288\n",
      "Baseline Loss: 2.8790 | Actual Loss: 0.3948\n",
      "Baseline Loss: 2.7979 | Actual Loss: 0.6068\n",
      "Baseline Loss: 2.8437 | Actual Loss: 0.4901\n",
      "Baseline Loss: 2.6994 | Actual Loss: 2.5892\n",
      "Baseline Loss: 2.8215 | Actual Loss: 0.5119\n",
      "Baseline Loss: 2.7731 | Actual Loss: 2.1956\n",
      "Baseline Loss: 2.8130 | Actual Loss: 0.4055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 128/1000 [01:12<08:15,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8485 | Actual Loss: 2.0766\n",
      "Baseline Loss: 2.8002 | Actual Loss: 0.6350\n",
      "Baseline Loss: 2.8147 | Actual Loss: 0.4686\n",
      "Baseline Loss: 2.5547 | Actual Loss: 0.1021\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5158\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.3782\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1458\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.2568\n",
      "Epoch 128/1000: Train Loss: 0.7835, Val Loss: 0.5742\n",
      "Baseline Loss: 2.8548 | Actual Loss: 0.2297\n",
      "Baseline Loss: 2.8471 | Actual Loss: 0.4617\n",
      "Baseline Loss: 2.8518 | Actual Loss: 0.4579\n",
      "Baseline Loss: 2.7923 | Actual Loss: 0.1271\n",
      "Baseline Loss: 2.7923 | Actual Loss: 0.1381\n",
      "Baseline Loss: 2.8464 | Actual Loss: 0.6758\n",
      "Baseline Loss: 2.8936 | Actual Loss: 0.4282\n",
      "Baseline Loss: 2.8231 | Actual Loss: 0.5558\n",
      "Baseline Loss: 2.8149 | Actual Loss: 0.5127\n",
      "Baseline Loss: 2.8200 | Actual Loss: 0.4183\n",
      "Baseline Loss: 2.7973 | Actual Loss: 0.2962\n",
      "Baseline Loss: 2.8403 | Actual Loss: 0.1745\n",
      "Baseline Loss: 2.7988 | Actual Loss: 2.4762\n",
      "Baseline Loss: 2.8415 | Actual Loss: 0.7845\n",
      "Baseline Loss: 2.8071 | Actual Loss: 0.3027\n",
      "Baseline Loss: 2.4947 | Actual Loss: 2.7097\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5637\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.8740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 129/1000 [01:13<07:55,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8632 | Actual Loss: 0.1953\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.2480\n",
      "Epoch 129/1000: Train Loss: 0.6718, Val Loss: 0.4702\n",
      "Baseline Loss: 2.8121 | Actual Loss: 0.2678\n",
      "Baseline Loss: 2.8931 | Actual Loss: 0.8102\n",
      "Baseline Loss: 2.8552 | Actual Loss: 0.9148\n",
      "Baseline Loss: 2.8298 | Actual Loss: 0.4972\n",
      "Baseline Loss: 2.8248 | Actual Loss: 0.7711\n",
      "Baseline Loss: 2.8255 | Actual Loss: 0.7784\n",
      "Baseline Loss: 2.8016 | Actual Loss: 0.4316\n",
      "Baseline Loss: 2.8590 | Actual Loss: 0.5662\n",
      "Baseline Loss: 2.8817 | Actual Loss: 0.0817\n",
      "Baseline Loss: 2.8007 | Actual Loss: 0.6007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 130/1000 [01:14<08:03,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8432 | Actual Loss: 0.2872\n",
      "Baseline Loss: 2.9243 | Actual Loss: 0.2356\n",
      "Baseline Loss: 2.8066 | Actual Loss: 0.5408\n",
      "Baseline Loss: 2.8429 | Actual Loss: 0.2958\n",
      "Baseline Loss: 2.7620 | Actual Loss: 2.7500\n",
      "Baseline Loss: 2.3800 | Actual Loss: 0.1421\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.6666\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.3319\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1243\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.3970\n",
      "Epoch 130/1000: Train Loss: 0.6232, Val Loss: 0.6300\n",
      "Baseline Loss: 2.8222 | Actual Loss: 0.6474\n",
      "Baseline Loss: 2.8118 | Actual Loss: 0.2393\n",
      "Baseline Loss: 2.8745 | Actual Loss: 0.2380\n",
      "Baseline Loss: 2.7823 | Actual Loss: 0.5105\n",
      "Baseline Loss: 2.8307 | Actual Loss: 0.4211\n",
      "Baseline Loss: 2.8176 | Actual Loss: 0.5973\n",
      "Baseline Loss: 2.8332 | Actual Loss: 2.5580\n",
      "Baseline Loss: 2.8277 | Actual Loss: 0.1572\n",
      "Baseline Loss: 2.8438 | Actual Loss: 0.5633\n",
      "Baseline Loss: 2.8468 | Actual Loss: 0.5295\n",
      "Baseline Loss: 2.8262 | Actual Loss: 0.3446\n",
      "Baseline Loss: 2.8047 | Actual Loss: 0.5631\n",
      "Baseline Loss: 2.7704 | Actual Loss: 0.1612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 131/1000 [01:14<08:15,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9583 | Actual Loss: 0.2868\n",
      "Baseline Loss: 2.7846 | Actual Loss: 0.5128\n",
      "Baseline Loss: 2.5708 | Actual Loss: 2.6109\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.6654\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.5257\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1697\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4604\n",
      "Epoch 131/1000: Train Loss: 0.6838, Val Loss: 0.7053\n",
      "Baseline Loss: 2.9221 | Actual Loss: 0.7883\n",
      "Baseline Loss: 2.7857 | Actual Loss: 0.5588\n",
      "Baseline Loss: 2.8536 | Actual Loss: 0.1402\n",
      "Baseline Loss: 2.8411 | Actual Loss: 0.1631\n",
      "Baseline Loss: 2.8611 | Actual Loss: 0.5809\n",
      "Baseline Loss: 2.8172 | Actual Loss: 0.4200\n",
      "Baseline Loss: 2.7411 | Actual Loss: 0.3462\n",
      "Baseline Loss: 2.8497 | Actual Loss: 1.9630\n",
      "Baseline Loss: 2.8392 | Actual Loss: 2.6870\n",
      "Baseline Loss: 2.8346 | Actual Loss: 0.1321\n",
      "Baseline Loss: 2.8298 | Actual Loss: 0.5546\n",
      "Baseline Loss: 2.8543 | Actual Loss: 0.2545\n",
      "Baseline Loss: 2.9181 | Actual Loss: 1.1053\n",
      "Baseline Loss: 2.7394 | Actual Loss: 0.2303\n",
      "Baseline Loss: 2.8299 | Actual Loss: 0.6423\n",
      "Baseline Loss: 2.5173 | Actual Loss: 2.6878\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.6293\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.2154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 132/1000 [01:15<07:56,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8632 | Actual Loss: 0.1419\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.5639\n",
      "Epoch 132/1000: Train Loss: 0.8284, Val Loss: 0.6376\n",
      "Baseline Loss: 2.8102 | Actual Loss: 2.6522\n",
      "Baseline Loss: 2.8089 | Actual Loss: 2.4135\n",
      "Baseline Loss: 2.8324 | Actual Loss: 0.4047\n",
      "Baseline Loss: 2.8807 | Actual Loss: 0.2259\n",
      "Baseline Loss: 2.8984 | Actual Loss: 0.4273\n",
      "Baseline Loss: 2.9022 | Actual Loss: 0.4327\n",
      "Baseline Loss: 2.7761 | Actual Loss: 0.2028\n",
      "Baseline Loss: 2.8392 | Actual Loss: 0.1688\n",
      "Baseline Loss: 2.7870 | Actual Loss: 0.1745\n",
      "Baseline Loss: 2.8257 | Actual Loss: 0.2774\n",
      "Baseline Loss: 2.8163 | Actual Loss: 0.4310\n",
      "Baseline Loss: 2.7966 | Actual Loss: 0.1041\n",
      "Baseline Loss: 2.8292 | Actual Loss: 0.5575\n",
      "Baseline Loss: 2.8264 | Actual Loss: 0.8749\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.3126\n",
      "Baseline Loss: 2.5027 | Actual Loss: 0.6743\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.6981\n",
      "Baseline Loss: 2.7887 | Actual Loss: 2.5807\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 133/1000 [01:15<08:09,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7147 | Actual Loss: 0.4566\n",
      "Epoch 133/1000: Train Loss: 0.6459, Val Loss: 0.9997\n",
      "Baseline Loss: 2.8427 | Actual Loss: 0.4867\n",
      "Baseline Loss: 2.8413 | Actual Loss: 0.3261\n",
      "Baseline Loss: 2.8177 | Actual Loss: 3.0305\n",
      "Baseline Loss: 2.8090 | Actual Loss: 0.2573\n",
      "Baseline Loss: 2.8200 | Actual Loss: 0.4134\n",
      "Baseline Loss: 2.8496 | Actual Loss: 1.0178\n",
      "Baseline Loss: 2.8192 | Actual Loss: 0.2652\n",
      "Baseline Loss: 2.8528 | Actual Loss: 0.4002\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3602\n",
      "Baseline Loss: 2.7843 | Actual Loss: 2.9882\n",
      "Baseline Loss: 2.8848 | Actual Loss: 0.7602\n",
      "Baseline Loss: 2.8437 | Actual Loss: 2.4233\n",
      "Baseline Loss: 2.7672 | Actual Loss: 0.2265\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.1457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 134/1000 [01:16<08:17,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8106 | Actual Loss: 0.2446\n",
      "Baseline Loss: 2.4968 | Actual Loss: 0.2543\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5636\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.4312\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1803\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4181\n",
      "Epoch 134/1000: Train Loss: 0.8500, Val Loss: 0.6483\n",
      "Baseline Loss: 2.7720 | Actual Loss: 0.7088\n",
      "Baseline Loss: 2.9076 | Actual Loss: 0.3134\n",
      "Baseline Loss: 2.8728 | Actual Loss: 0.3470\n",
      "Baseline Loss: 2.8866 | Actual Loss: 0.4028\n",
      "Baseline Loss: 2.8393 | Actual Loss: 0.1329\n",
      "Baseline Loss: 2.8370 | Actual Loss: 0.2702\n",
      "Baseline Loss: 2.7697 | Actual Loss: 2.4027\n",
      "Baseline Loss: 2.8825 | Actual Loss: 0.9179\n",
      "Baseline Loss: 2.7769 | Actual Loss: 2.5742\n",
      "Baseline Loss: 2.8219 | Actual Loss: 0.2246\n",
      "Baseline Loss: 2.8006 | Actual Loss: 0.1730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▎        | 135/1000 [01:16<07:57,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8144 | Actual Loss: 0.1245\n",
      "Baseline Loss: 2.8074 | Actual Loss: 0.3382\n",
      "Baseline Loss: 2.7495 | Actual Loss: 0.6084\n",
      "Baseline Loss: 2.8338 | Actual Loss: 0.1508\n",
      "Baseline Loss: 2.4686 | Actual Loss: 0.1321\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5481\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.1038\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.3375\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4594\n",
      "Epoch 135/1000: Train Loss: 0.6139, Val Loss: 0.6122\n",
      "Baseline Loss: 2.8639 | Actual Loss: 0.6781\n",
      "Baseline Loss: 2.7834 | Actual Loss: 0.4623\n",
      "Baseline Loss: 2.8228 | Actual Loss: 0.2545\n",
      "Baseline Loss: 2.7388 | Actual Loss: 0.3095\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.4599\n",
      "Baseline Loss: 2.7794 | Actual Loss: 0.4954\n",
      "Baseline Loss: 2.8220 | Actual Loss: 0.1775\n",
      "Baseline Loss: 2.8490 | Actual Loss: 0.2604\n",
      "Baseline Loss: 2.8817 | Actual Loss: 0.3482\n",
      "Baseline Loss: 2.8152 | Actual Loss: 0.2386\n",
      "Baseline Loss: 2.8306 | Actual Loss: 0.2961\n",
      "Baseline Loss: 2.8514 | Actual Loss: 0.3679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▎        | 136/1000 [01:17<07:59,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8614 | Actual Loss: 0.4626\n",
      "Baseline Loss: 2.7818 | Actual Loss: 0.8059\n",
      "Baseline Loss: 2.8917 | Actual Loss: 0.5154\n",
      "Baseline Loss: 2.5732 | Actual Loss: 2.0093\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5197\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.4196\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.3491\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4509\n",
      "Epoch 136/1000: Train Loss: 0.5088, Val Loss: 0.4348\n",
      "Baseline Loss: 2.8068 | Actual Loss: 0.3273\n",
      "Baseline Loss: 2.8635 | Actual Loss: 0.5608\n",
      "Baseline Loss: 2.8432 | Actual Loss: 0.3662\n",
      "Baseline Loss: 2.8405 | Actual Loss: 0.2738\n",
      "Baseline Loss: 2.7745 | Actual Loss: 0.4676\n",
      "Baseline Loss: 2.8571 | Actual Loss: 0.6386\n",
      "Baseline Loss: 2.7752 | Actual Loss: 0.2483\n",
      "Baseline Loss: 2.8201 | Actual Loss: 0.2103\n",
      "Baseline Loss: 2.8351 | Actual Loss: 0.2143\n",
      "Baseline Loss: 2.8647 | Actual Loss: 0.4173\n",
      "Baseline Loss: 2.8289 | Actual Loss: 0.3303\n",
      "Baseline Loss: 2.8190 | Actual Loss: 0.6078\n",
      "Baseline Loss: 2.7886 | Actual Loss: 0.6012\n",
      "Baseline Loss: 2.7897 | Actual Loss: 0.5109\n",
      "Baseline Loss: 2.7824 | Actual Loss: 0.2191\n",
      "Baseline Loss: 2.6566 | Actual Loss: 0.5441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▎        | 137/1000 [01:18<08:14,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8420 | Actual Loss: 0.5895\n",
      "Baseline Loss: 2.7887 | Actual Loss: 2.6373\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1964\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4696\n",
      "Epoch 137/1000: Train Loss: 0.4086, Val Loss: 0.9732\n",
      "Baseline Loss: 2.8073 | Actual Loss: 0.3464\n",
      "Baseline Loss: 2.8124 | Actual Loss: 0.3525\n",
      "Baseline Loss: 2.8490 | Actual Loss: 0.4662\n",
      "Baseline Loss: 2.8689 | Actual Loss: 0.2203\n",
      "Baseline Loss: 2.8219 | Actual Loss: 1.2515\n",
      "Baseline Loss: 2.8591 | Actual Loss: 2.5141\n",
      "Baseline Loss: 2.9146 | Actual Loss: 0.4496\n",
      "Baseline Loss: 2.7663 | Actual Loss: 0.2550\n",
      "Baseline Loss: 2.9021 | Actual Loss: 0.6633\n",
      "Baseline Loss: 2.7952 | Actual Loss: 0.4319\n",
      "Baseline Loss: 2.8450 | Actual Loss: 0.3699\n",
      "Baseline Loss: 2.8443 | Actual Loss: 0.3797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 138/1000 [01:18<07:52,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8123 | Actual Loss: 0.2141\n",
      "Baseline Loss: 2.8372 | Actual Loss: 0.8148\n",
      "Baseline Loss: 2.7688 | Actual Loss: 0.9358\n",
      "Baseline Loss: 2.6003 | Actual Loss: 0.2794\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5663\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.9293\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2444\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4520\n",
      "Epoch 138/1000: Train Loss: 0.6215, Val Loss: 0.5480\n",
      "Baseline Loss: 2.8715 | Actual Loss: 0.2162\n",
      "Baseline Loss: 2.8251 | Actual Loss: 0.5269\n",
      "Baseline Loss: 2.8265 | Actual Loss: 0.5459\n",
      "Baseline Loss: 2.7851 | Actual Loss: 0.9656\n",
      "Baseline Loss: 2.8287 | Actual Loss: 0.3853\n",
      "Baseline Loss: 2.7720 | Actual Loss: 0.4765\n",
      "Baseline Loss: 2.8485 | Actual Loss: 0.2665\n",
      "Baseline Loss: 2.7744 | Actual Loss: 0.2714\n",
      "Baseline Loss: 2.8742 | Actual Loss: 0.4151\n",
      "Baseline Loss: 2.8235 | Actual Loss: 0.4899\n",
      "Baseline Loss: 2.7890 | Actual Loss: 0.2576\n",
      "Baseline Loss: 2.7677 | Actual Loss: 1.2744\n",
      "Baseline Loss: 2.8943 | Actual Loss: 0.4835\n",
      "Baseline Loss: 2.8578 | Actual Loss: 0.4532\n",
      "Baseline Loss: 2.7992 | Actual Loss: 0.3736\n",
      "Baseline Loss: 2.5297 | Actual Loss: 0.1549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 139/1000 [01:19<07:59,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8420 | Actual Loss: 0.4987\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.5627\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2722\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.2836\n",
      "Epoch 139/1000: Train Loss: 0.4723, Val Loss: 0.4043\n",
      "Baseline Loss: 2.8080 | Actual Loss: 0.2894\n",
      "Baseline Loss: 2.8628 | Actual Loss: 0.4532\n",
      "Baseline Loss: 2.7903 | Actual Loss: 0.5534\n",
      "Baseline Loss: 2.8073 | Actual Loss: 0.3700\n",
      "Baseline Loss: 2.7943 | Actual Loss: 0.2332\n",
      "Baseline Loss: 2.8555 | Actual Loss: 0.3629\n",
      "Baseline Loss: 2.8028 | Actual Loss: 2.8482\n",
      "Baseline Loss: 2.8368 | Actual Loss: 0.2961\n",
      "Baseline Loss: 2.8324 | Actual Loss: 1.7606\n",
      "Baseline Loss: 2.8165 | Actual Loss: 2.4714\n",
      "Baseline Loss: 2.9025 | Actual Loss: 0.3941\n",
      "Baseline Loss: 2.8008 | Actual Loss: 0.1435\n",
      "Baseline Loss: 2.8237 | Actual Loss: 0.2180\n",
      "Baseline Loss: 2.8331 | Actual Loss: 0.1902\n",
      "Baseline Loss: 2.9064 | Actual Loss: 0.2744\n",
      "Baseline Loss: 2.5051 | Actual Loss: 0.0938\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.6811\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.2264\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 140/1000 [01:19<08:09,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7147 | Actual Loss: 0.4343\n",
      "Epoch 140/1000: Train Loss: 0.6845, Val Loss: 0.6347\n",
      "Baseline Loss: 2.8506 | Actual Loss: 0.1426\n",
      "Baseline Loss: 2.8484 | Actual Loss: 0.1645\n",
      "Baseline Loss: 2.7626 | Actual Loss: 0.3775\n",
      "Baseline Loss: 2.7980 | Actual Loss: 0.1620\n",
      "Baseline Loss: 2.8411 | Actual Loss: 0.1776\n",
      "Baseline Loss: 2.8174 | Actual Loss: 2.1713\n",
      "Baseline Loss: 2.8025 | Actual Loss: 0.7302\n",
      "Baseline Loss: 2.8419 | Actual Loss: 0.1371\n",
      "Baseline Loss: 2.7966 | Actual Loss: 0.2230\n",
      "Baseline Loss: 2.8433 | Actual Loss: 0.4793\n",
      "Baseline Loss: 2.8417 | Actual Loss: 0.3319\n",
      "Baseline Loss: 2.8339 | Actual Loss: 0.4318\n",
      "Baseline Loss: 2.8241 | Actual Loss: 0.3296\n",
      "Baseline Loss: 2.8109 | Actual Loss: 0.8838\n",
      "Baseline Loss: 2.8208 | Actual Loss: 0.2941\n",
      "Baseline Loss: 2.5772 | Actual Loss: 1.1135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 141/1000 [01:20<07:47,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8420 | Actual Loss: 0.5180\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.2154\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1286\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.3811\n",
      "Epoch 141/1000: Train Loss: 0.5094, Val Loss: 0.5608\n",
      "Baseline Loss: 2.9277 | Actual Loss: 0.2771\n",
      "Baseline Loss: 2.7862 | Actual Loss: 0.2814\n",
      "Baseline Loss: 2.8548 | Actual Loss: 0.3285\n",
      "Baseline Loss: 2.8264 | Actual Loss: 0.4243\n",
      "Baseline Loss: 2.8644 | Actual Loss: 0.9051\n",
      "Baseline Loss: 2.9281 | Actual Loss: 0.2669\n",
      "Baseline Loss: 2.8136 | Actual Loss: 0.2184\n",
      "Baseline Loss: 2.8572 | Actual Loss: 0.1556\n",
      "Baseline Loss: 2.7997 | Actual Loss: 0.3033\n",
      "Baseline Loss: 2.7806 | Actual Loss: 0.3014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 142/1000 [01:20<07:55,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8219 | Actual Loss: 0.4291\n",
      "Baseline Loss: 2.7642 | Actual Loss: 0.2623\n",
      "Baseline Loss: 2.7982 | Actual Loss: 0.5492\n",
      "Baseline Loss: 2.8211 | Actual Loss: 0.2505\n",
      "Baseline Loss: 2.7822 | Actual Loss: 0.3436\n",
      "Baseline Loss: 2.4950 | Actual Loss: 0.5621\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.6017\n",
      "Baseline Loss: 2.7887 | Actual Loss: 2.5135\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.3052\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.2091\n",
      "Epoch 142/1000: Train Loss: 0.3662, Val Loss: 0.9074\n",
      "Baseline Loss: 2.8179 | Actual Loss: 2.3952\n",
      "Baseline Loss: 2.8843 | Actual Loss: 0.5611\n",
      "Baseline Loss: 2.8790 | Actual Loss: 0.6262\n",
      "Baseline Loss: 2.7525 | Actual Loss: 0.1864\n",
      "Baseline Loss: 2.7656 | Actual Loss: 0.4936\n",
      "Baseline Loss: 2.8209 | Actual Loss: 0.1704\n",
      "Baseline Loss: 2.8124 | Actual Loss: 2.3877\n",
      "Baseline Loss: 2.7418 | Actual Loss: 0.2577\n",
      "Baseline Loss: 2.8084 | Actual Loss: 2.6715\n",
      "Baseline Loss: 2.7758 | Actual Loss: 0.5345\n",
      "Baseline Loss: 2.9097 | Actual Loss: 0.1427\n",
      "Baseline Loss: 2.9008 | Actual Loss: 0.1372\n",
      "Baseline Loss: 2.9188 | Actual Loss: 1.3718\n",
      "Baseline Loss: 2.8486 | Actual Loss: 0.3186\n",
      "Baseline Loss: 2.8198 | Actual Loss: 0.4545\n",
      "Baseline Loss: 2.5201 | Actual Loss: 0.1362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 143/1000 [01:21<08:02,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8420 | Actual Loss: 0.5554\n",
      "Baseline Loss: 2.7887 | Actual Loss: 2.5848\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2388\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4135\n",
      "Epoch 143/1000: Train Loss: 0.8028, Val Loss: 0.9481\n",
      "Baseline Loss: 2.8387 | Actual Loss: 0.3752\n",
      "Baseline Loss: 2.8110 | Actual Loss: 0.5492\n",
      "Baseline Loss: 2.8312 | Actual Loss: 0.6445\n",
      "Baseline Loss: 2.8649 | Actual Loss: 0.3673\n",
      "Baseline Loss: 2.8493 | Actual Loss: 0.4240\n",
      "Baseline Loss: 2.8117 | Actual Loss: 0.3186\n",
      "Baseline Loss: 2.8330 | Actual Loss: 0.9004\n",
      "Baseline Loss: 2.8654 | Actual Loss: 0.3287\n",
      "Baseline Loss: 2.8651 | Actual Loss: 0.3675\n",
      "Baseline Loss: 2.8479 | Actual Loss: 0.4929\n",
      "Baseline Loss: 2.8104 | Actual Loss: 0.5194\n",
      "Baseline Loss: 2.8225 | Actual Loss: 0.3653\n",
      "Baseline Loss: 2.7863 | Actual Loss: 0.5833\n",
      "Baseline Loss: 2.8955 | Actual Loss: 0.4848\n",
      "Baseline Loss: 2.7860 | Actual Loss: 0.3132\n",
      "Baseline Loss: 2.4956 | Actual Loss: 2.4602\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5363\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.5155\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 144/1000 [01:21<07:46,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7147 | Actual Loss: 0.3947\n",
      "Epoch 144/1000: Train Loss: 0.5934, Val Loss: 0.6603\n",
      "Baseline Loss: 2.8230 | Actual Loss: 0.4951\n",
      "Baseline Loss: 2.8905 | Actual Loss: 0.2475\n",
      "Baseline Loss: 2.8450 | Actual Loss: 1.0369\n",
      "Baseline Loss: 2.8069 | Actual Loss: 2.4255\n",
      "Baseline Loss: 2.8668 | Actual Loss: 0.3700\n",
      "Baseline Loss: 2.7623 | Actual Loss: 0.4461\n",
      "Baseline Loss: 2.8037 | Actual Loss: 0.3760\n",
      "Baseline Loss: 2.8220 | Actual Loss: 0.1547\n",
      "Baseline Loss: 2.8506 | Actual Loss: 0.8515\n",
      "Baseline Loss: 2.7925 | Actual Loss: 0.2427\n",
      "Baseline Loss: 2.7661 | Actual Loss: 0.3373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 145/1000 [01:22<07:55,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7925 | Actual Loss: 0.6265\n",
      "Baseline Loss: 2.8846 | Actual Loss: 0.5991\n",
      "Baseline Loss: 2.7696 | Actual Loss: 0.4861\n",
      "Baseline Loss: 2.8093 | Actual Loss: 0.5206\n",
      "Baseline Loss: 2.6520 | Actual Loss: 0.2448\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.6622\n",
      "Baseline Loss: 2.7887 | Actual Loss: 2.3749\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2752\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4262\n",
      "Epoch 145/1000: Train Loss: 0.5913, Val Loss: 0.9346\n",
      "Baseline Loss: 2.8408 | Actual Loss: 0.2256\n",
      "Baseline Loss: 2.7715 | Actual Loss: 0.2170\n",
      "Baseline Loss: 2.8626 | Actual Loss: 0.2466\n",
      "Baseline Loss: 2.7694 | Actual Loss: 0.2696\n",
      "Baseline Loss: 2.8480 | Actual Loss: 0.8631\n",
      "Baseline Loss: 2.8786 | Actual Loss: 0.4475\n",
      "Baseline Loss: 2.8771 | Actual Loss: 0.8768\n",
      "Baseline Loss: 2.8038 | Actual Loss: 1.4603\n",
      "Baseline Loss: 2.8167 | Actual Loss: 0.4132\n",
      "Baseline Loss: 2.8379 | Actual Loss: 0.5096\n",
      "Baseline Loss: 2.8300 | Actual Loss: 0.3667\n",
      "Baseline Loss: 2.7453 | Actual Loss: 0.4778\n",
      "Baseline Loss: 2.8409 | Actual Loss: 0.4040\n",
      "Baseline Loss: 2.8288 | Actual Loss: 2.6836\n",
      "Baseline Loss: 2.8339 | Actual Loss: 0.5024\n",
      "Baseline Loss: 2.4651 | Actual Loss: 0.1006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 146/1000 [01:22<07:48,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8420 | Actual Loss: 0.6238\n",
      "Baseline Loss: 2.7887 | Actual Loss: 2.0567\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1499\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.2703\n",
      "Epoch 146/1000: Train Loss: 0.6290, Val Loss: 0.7752\n",
      "Baseline Loss: 2.7857 | Actual Loss: 0.7083\n",
      "Baseline Loss: 2.8038 | Actual Loss: 0.5132\n",
      "Baseline Loss: 2.9012 | Actual Loss: 0.5795\n",
      "Baseline Loss: 2.8023 | Actual Loss: 0.1825\n",
      "Baseline Loss: 2.8120 | Actual Loss: 0.1359\n",
      "Baseline Loss: 2.7793 | Actual Loss: 0.9434\n",
      "Baseline Loss: 2.7996 | Actual Loss: 0.2815\n",
      "Baseline Loss: 2.8558 | Actual Loss: 0.2306\n",
      "Baseline Loss: 2.8434 | Actual Loss: 0.3075\n",
      "Baseline Loss: 2.8267 | Actual Loss: 0.2592\n",
      "Baseline Loss: 2.8253 | Actual Loss: 0.4211\n",
      "Baseline Loss: 2.8014 | Actual Loss: 0.2947\n",
      "Baseline Loss: 2.8910 | Actual Loss: 0.3906\n",
      "Baseline Loss: 2.8029 | Actual Loss: 0.3628\n",
      "Baseline Loss: 2.8089 | Actual Loss: 0.1230\n",
      "Baseline Loss: 2.5095 | Actual Loss: 0.1405\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5920\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.7175\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 147/1000 [01:23<07:56,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7147 | Actual Loss: 0.4186\n",
      "Epoch 147/1000: Train Loss: 0.3671, Val Loss: 0.5018\n",
      "Baseline Loss: 2.8163 | Actual Loss: 1.0216\n",
      "Baseline Loss: 2.8319 | Actual Loss: 0.1291\n",
      "Baseline Loss: 2.8313 | Actual Loss: 0.4654\n",
      "Baseline Loss: 2.8446 | Actual Loss: 0.5394\n",
      "Baseline Loss: 2.8477 | Actual Loss: 1.3772\n",
      "Baseline Loss: 2.7785 | Actual Loss: 0.5173\n",
      "Baseline Loss: 2.8922 | Actual Loss: 0.8998\n",
      "Baseline Loss: 2.7297 | Actual Loss: 0.4975\n",
      "Baseline Loss: 2.8197 | Actual Loss: 0.2866\n",
      "Baseline Loss: 2.8283 | Actual Loss: 0.1808\n",
      "Baseline Loss: 2.8937 | Actual Loss: 0.8255\n",
      "Baseline Loss: 2.9037 | Actual Loss: 0.2505\n",
      "Baseline Loss: 2.8916 | Actual Loss: 0.3428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 148/1000 [01:24<08:03,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7515 | Actual Loss: 0.2313\n",
      "Baseline Loss: 2.8103 | Actual Loss: 0.4164\n",
      "Baseline Loss: 2.4843 | Actual Loss: 0.2586\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5316\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.8011\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1757\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.7036\n",
      "Epoch 148/1000: Train Loss: 0.5150, Val Loss: 0.8030\n",
      "Baseline Loss: 2.9008 | Actual Loss: 0.3741\n",
      "Baseline Loss: 2.8235 | Actual Loss: 0.3493\n",
      "Baseline Loss: 2.8232 | Actual Loss: 0.3614\n",
      "Baseline Loss: 2.8647 | Actual Loss: 0.4808\n",
      "Baseline Loss: 2.8287 | Actual Loss: 0.2642\n",
      "Baseline Loss: 2.8427 | Actual Loss: 0.5479\n",
      "Baseline Loss: 2.8153 | Actual Loss: 0.2339\n",
      "Baseline Loss: 2.7721 | Actual Loss: 0.2600\n",
      "Baseline Loss: 2.7899 | Actual Loss: 0.2929\n",
      "Baseline Loss: 2.8673 | Actual Loss: 0.2194\n",
      "Baseline Loss: 2.7965 | Actual Loss: 0.4026\n",
      "Baseline Loss: 2.8941 | Actual Loss: 0.2589\n",
      "Baseline Loss: 2.8507 | Actual Loss: 0.3223\n",
      "Baseline Loss: 2.7494 | Actual Loss: 0.2807\n",
      "Baseline Loss: 2.8604 | Actual Loss: 0.9274\n",
      "Baseline Loss: 2.4190 | Actual Loss: 0.4284\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5432\n",
      "Baseline Loss: 2.7887 | Actual Loss: 2.2796\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 149/1000 [01:24<07:46,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7147 | Actual Loss: 0.2673\n",
      "Epoch 149/1000: Train Loss: 0.3753, Val Loss: 0.8096\n",
      "Baseline Loss: 2.7508 | Actual Loss: 0.3124\n",
      "Baseline Loss: 2.7927 | Actual Loss: 0.3208\n",
      "Baseline Loss: 2.8082 | Actual Loss: 0.3844\n",
      "Baseline Loss: 2.8633 | Actual Loss: 0.5458\n",
      "Baseline Loss: 2.8468 | Actual Loss: 0.3849\n",
      "Baseline Loss: 2.8468 | Actual Loss: 0.2374\n",
      "Baseline Loss: 2.8370 | Actual Loss: 0.3847\n",
      "Baseline Loss: 2.8501 | Actual Loss: 0.2308\n",
      "Baseline Loss: 2.8149 | Actual Loss: 0.6519\n",
      "Baseline Loss: 2.8046 | Actual Loss: 0.3830\n",
      "Baseline Loss: 2.7965 | Actual Loss: 1.9556\n",
      "Baseline Loss: 2.8305 | Actual Loss: 1.6144\n",
      "Baseline Loss: 2.8932 | Actual Loss: 0.9598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 150/1000 [01:25<08:01,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8233 | Actual Loss: 0.5498\n",
      "Baseline Loss: 2.7677 | Actual Loss: 0.2248\n",
      "Baseline Loss: 2.6440 | Actual Loss: 0.2581\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5738\n",
      "Baseline Loss: 2.7887 | Actual Loss: 2.6957\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1585\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4518\n",
      "Epoch 150/1000: Train Loss: 0.5874, Val Loss: 0.9700\n",
      "Baseline Loss: 2.8646 | Actual Loss: 0.2721\n",
      "Baseline Loss: 2.7618 | Actual Loss: 0.1985\n",
      "Baseline Loss: 2.7533 | Actual Loss: 0.1472\n",
      "Baseline Loss: 2.8409 | Actual Loss: 0.2408\n",
      "Baseline Loss: 2.8750 | Actual Loss: 0.6696\n",
      "Baseline Loss: 2.8402 | Actual Loss: 0.6283\n",
      "Baseline Loss: 2.7817 | Actual Loss: 2.3945\n",
      "Baseline Loss: 2.8146 | Actual Loss: 0.4347\n",
      "Baseline Loss: 2.8018 | Actual Loss: 0.2176\n",
      "Baseline Loss: 2.8685 | Actual Loss: 0.3616\n",
      "Baseline Loss: 2.8449 | Actual Loss: 0.6536\n",
      "Baseline Loss: 2.8083 | Actual Loss: 0.3961\n",
      "Baseline Loss: 2.8606 | Actual Loss: 0.2979\n",
      "Baseline Loss: 2.8158 | Actual Loss: 2.1153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 151/1000 [01:25<08:11,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8094 | Actual Loss: 0.1964\n",
      "Baseline Loss: 2.5406 | Actual Loss: 2.3816\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5907\n",
      "Baseline Loss: 2.7887 | Actual Loss: 2.2475\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2573\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.3290\n",
      "Epoch 151/1000: Train Loss: 0.7254, Val Loss: 0.8561\n",
      "Baseline Loss: 2.8355 | Actual Loss: 0.3435\n",
      "Baseline Loss: 2.8542 | Actual Loss: 1.0925\n",
      "Baseline Loss: 2.8931 | Actual Loss: 0.4219\n",
      "Baseline Loss: 2.8830 | Actual Loss: 2.3778\n",
      "Baseline Loss: 2.8000 | Actual Loss: 0.2271\n",
      "Baseline Loss: 2.7537 | Actual Loss: 0.6604\n",
      "Baseline Loss: 2.8100 | Actual Loss: 0.2526\n",
      "Baseline Loss: 2.8123 | Actual Loss: 0.2744\n",
      "Baseline Loss: 2.8148 | Actual Loss: 2.5546\n",
      "Baseline Loss: 2.7805 | Actual Loss: 0.3433\n",
      "Baseline Loss: 2.8711 | Actual Loss: 0.6236\n",
      "Baseline Loss: 2.8510 | Actual Loss: 0.1291\n",
      "Baseline Loss: 2.8843 | Actual Loss: 0.2262\n",
      "Baseline Loss: 2.8522 | Actual Loss: 0.3041\n",
      "Baseline Loss: 2.8225 | Actual Loss: 1.0340\n",
      "Baseline Loss: 2.6000 | Actual Loss: 0.8397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 152/1000 [01:26<08:25,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8420 | Actual Loss: 0.5258\n",
      "Baseline Loss: 2.7887 | Actual Loss: 2.4222\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2563\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.2471\n",
      "Epoch 152/1000: Train Loss: 0.7316, Val Loss: 0.8628\n",
      "Baseline Loss: 2.8722 | Actual Loss: 0.2086\n",
      "Baseline Loss: 2.8210 | Actual Loss: 0.3011\n",
      "Baseline Loss: 2.8155 | Actual Loss: 0.4651\n",
      "Baseline Loss: 2.8446 | Actual Loss: 0.2114\n",
      "Baseline Loss: 2.8691 | Actual Loss: 0.5646\n",
      "Baseline Loss: 2.8843 | Actual Loss: 0.7752\n",
      "Baseline Loss: 2.7200 | Actual Loss: 0.3135\n",
      "Baseline Loss: 2.8022 | Actual Loss: 0.3462\n",
      "Baseline Loss: 2.8778 | Actual Loss: 0.1869\n",
      "Baseline Loss: 2.8034 | Actual Loss: 0.9088\n",
      "Baseline Loss: 2.8462 | Actual Loss: 0.1354\n",
      "Baseline Loss: 2.8784 | Actual Loss: 0.2220\n",
      "Baseline Loss: 2.7970 | Actual Loss: 1.1041\n",
      "Baseline Loss: 2.7586 | Actual Loss: 0.3293\n",
      "Baseline Loss: 2.9112 | Actual Loss: 0.2114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 153/1000 [01:27<08:38,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5747 | Actual Loss: 0.1052\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5110\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.2884\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1464\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4421\n",
      "Epoch 153/1000: Train Loss: 0.3993, Val Loss: 0.5970\n",
      "Baseline Loss: 2.7933 | Actual Loss: 2.5065\n",
      "Baseline Loss: 2.8909 | Actual Loss: 0.2346\n",
      "Baseline Loss: 2.8948 | Actual Loss: 0.2102\n",
      "Baseline Loss: 2.8301 | Actual Loss: 2.8614\n",
      "Baseline Loss: 2.8215 | Actual Loss: 0.2130\n",
      "Baseline Loss: 2.8623 | Actual Loss: 0.1355\n",
      "Baseline Loss: 2.7511 | Actual Loss: 2.5477\n",
      "Baseline Loss: 2.7940 | Actual Loss: 0.4099\n",
      "Baseline Loss: 2.8287 | Actual Loss: 0.2678\n",
      "Baseline Loss: 2.8307 | Actual Loss: 0.4168\n",
      "Baseline Loss: 2.8245 | Actual Loss: 0.3689\n",
      "Baseline Loss: 2.8264 | Actual Loss: 0.6960\n",
      "Baseline Loss: 2.8366 | Actual Loss: 0.5001\n",
      "Baseline Loss: 2.8704 | Actual Loss: 0.4109\n",
      "Baseline Loss: 2.8235 | Actual Loss: 0.4669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 154/1000 [01:27<08:56,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5058 | Actual Loss: 0.2069\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5802\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.9136\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2130\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.3701\n",
      "Epoch 154/1000: Train Loss: 0.7783, Val Loss: 0.5192\n",
      "Baseline Loss: 2.7709 | Actual Loss: 1.0017\n",
      "Baseline Loss: 2.8721 | Actual Loss: 0.5046\n",
      "Baseline Loss: 2.7793 | Actual Loss: 0.2950\n",
      "Baseline Loss: 2.7682 | Actual Loss: 0.1933\n",
      "Baseline Loss: 2.8248 | Actual Loss: 0.2449\n",
      "Baseline Loss: 2.8217 | Actual Loss: 0.2718\n",
      "Baseline Loss: 2.8820 | Actual Loss: 0.1715\n",
      "Baseline Loss: 2.8580 | Actual Loss: 0.3905\n",
      "Baseline Loss: 2.9498 | Actual Loss: 0.4165\n",
      "Baseline Loss: 2.8816 | Actual Loss: 0.2455\n",
      "Baseline Loss: 2.8077 | Actual Loss: 0.2196\n",
      "Baseline Loss: 2.8222 | Actual Loss: 1.0394\n",
      "Baseline Loss: 2.8158 | Actual Loss: 0.3648\n",
      "Baseline Loss: 2.8053 | Actual Loss: 0.3513\n",
      "Baseline Loss: 2.8574 | Actual Loss: 0.4783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 155/1000 [01:28<08:36,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5139 | Actual Loss: 0.2282\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5404\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.2472\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1550\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4913\n",
      "Epoch 155/1000: Train Loss: 0.4011, Val Loss: 0.6085\n",
      "Baseline Loss: 2.8123 | Actual Loss: 0.4087\n",
      "Baseline Loss: 2.7860 | Actual Loss: 0.2024\n",
      "Baseline Loss: 2.8563 | Actual Loss: 2.4496\n",
      "Baseline Loss: 2.8917 | Actual Loss: 0.3916\n",
      "Baseline Loss: 2.7714 | Actual Loss: 0.4701\n",
      "Baseline Loss: 2.8558 | Actual Loss: 1.9550\n",
      "Baseline Loss: 2.9030 | Actual Loss: 0.4668\n",
      "Baseline Loss: 2.7925 | Actual Loss: 0.5322\n",
      "Baseline Loss: 2.7911 | Actual Loss: 0.2283\n",
      "Baseline Loss: 2.8495 | Actual Loss: 0.6911\n",
      "Baseline Loss: 2.8889 | Actual Loss: 2.7199\n",
      "Baseline Loss: 2.8020 | Actual Loss: 0.2172\n",
      "Baseline Loss: 2.8358 | Actual Loss: 0.5354\n",
      "Baseline Loss: 2.7701 | Actual Loss: 0.1280\n",
      "Baseline Loss: 2.8175 | Actual Loss: 0.2746\n",
      "Baseline Loss: 2.5571 | Actual Loss: 0.0807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 156/1000 [01:29<08:52,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8420 | Actual Loss: 0.5997\n",
      "Baseline Loss: 2.7887 | Actual Loss: 2.7646\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.3128\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.5264\n",
      "Epoch 156/1000: Train Loss: 0.7345, Val Loss: 1.0509\n",
      "Baseline Loss: 2.8760 | Actual Loss: 0.6369\n",
      "Baseline Loss: 2.8014 | Actual Loss: 0.3948\n",
      "Baseline Loss: 2.7902 | Actual Loss: 2.1506\n",
      "Baseline Loss: 2.8129 | Actual Loss: 0.2692\n",
      "Baseline Loss: 2.8104 | Actual Loss: 3.0464\n",
      "Baseline Loss: 2.8111 | Actual Loss: 0.5830\n",
      "Baseline Loss: 2.7926 | Actual Loss: 2.6160\n",
      "Baseline Loss: 2.9212 | Actual Loss: 0.7766\n",
      "Baseline Loss: 2.8300 | Actual Loss: 0.2123\n",
      "Baseline Loss: 2.8397 | Actual Loss: 0.3824\n",
      "Baseline Loss: 2.8234 | Actual Loss: 0.6946\n",
      "Baseline Loss: 2.7603 | Actual Loss: 0.1979\n",
      "Baseline Loss: 2.8596 | Actual Loss: 0.4622\n",
      "Baseline Loss: 2.8622 | Actual Loss: 2.5329\n",
      "Baseline Loss: 2.7976 | Actual Loss: 0.2744\n",
      "Baseline Loss: 2.5791 | Actual Loss: 2.6847\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.6030\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.4205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 157/1000 [01:29<08:46,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8632 | Actual Loss: 0.2613\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.2898\n",
      "Epoch 157/1000: Train Loss: 1.1197, Val Loss: 0.6437\n",
      "Baseline Loss: 2.7950 | Actual Loss: 0.1252\n",
      "Baseline Loss: 2.8554 | Actual Loss: 0.2619\n",
      "Baseline Loss: 2.8701 | Actual Loss: 0.3563\n",
      "Baseline Loss: 2.8433 | Actual Loss: 0.2140\n",
      "Baseline Loss: 2.7804 | Actual Loss: 1.0074\n",
      "Baseline Loss: 2.7650 | Actual Loss: 0.2393\n",
      "Baseline Loss: 2.8673 | Actual Loss: 0.9046\n",
      "Baseline Loss: 2.8319 | Actual Loss: 0.7446\n",
      "Baseline Loss: 2.8257 | Actual Loss: 0.3543\n",
      "Baseline Loss: 2.8736 | Actual Loss: 0.5814\n",
      "Baseline Loss: 2.8190 | Actual Loss: 0.9846\n",
      "Baseline Loss: 2.7778 | Actual Loss: 0.2977\n",
      "Baseline Loss: 2.8071 | Actual Loss: 0.3829\n",
      "Baseline Loss: 2.7675 | Actual Loss: 0.5476\n",
      "Baseline Loss: 2.8787 | Actual Loss: 0.2330\n",
      "Baseline Loss: 2.5138 | Actual Loss: 0.1647\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5006\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.9655\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 158/1000 [01:30<08:48,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7147 | Actual Loss: 0.5114\n",
      "Epoch 158/1000: Train Loss: 0.4625, Val Loss: 0.5341\n",
      "Baseline Loss: 2.7437 | Actual Loss: 0.4926\n",
      "Baseline Loss: 2.9132 | Actual Loss: 2.6145\n",
      "Baseline Loss: 2.7846 | Actual Loss: 0.2928\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.4608\n",
      "Baseline Loss: 2.8072 | Actual Loss: 0.1581\n",
      "Baseline Loss: 2.8860 | Actual Loss: 0.6104\n",
      "Baseline Loss: 2.9136 | Actual Loss: 0.1630\n",
      "Baseline Loss: 2.8622 | Actual Loss: 1.3271\n",
      "Baseline Loss: 2.7604 | Actual Loss: 0.2596\n",
      "Baseline Loss: 2.8188 | Actual Loss: 0.3462\n",
      "Baseline Loss: 2.8428 | Actual Loss: 0.1258\n",
      "Baseline Loss: 2.7943 | Actual Loss: 0.5302\n",
      "Baseline Loss: 2.8857 | Actual Loss: 0.3217\n",
      "Baseline Loss: 2.8032 | Actual Loss: 0.3983\n",
      "Baseline Loss: 2.7992 | Actual Loss: 0.1281\n",
      "Baseline Loss: 2.6986 | Actual Loss: 0.1072\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.7095\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.4997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 159/1000 [01:30<08:58,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8632 | Actual Loss: 0.2661\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4734\n",
      "Epoch 159/1000: Train Loss: 0.5210, Val Loss: 0.7372\n",
      "Baseline Loss: 2.8355 | Actual Loss: 0.5150\n",
      "Baseline Loss: 2.8630 | Actual Loss: 0.3258\n",
      "Baseline Loss: 2.7763 | Actual Loss: 0.3737\n",
      "Baseline Loss: 2.8355 | Actual Loss: 0.6594\n",
      "Baseline Loss: 2.8496 | Actual Loss: 0.2388\n",
      "Baseline Loss: 2.8311 | Actual Loss: 0.1678\n",
      "Baseline Loss: 2.8217 | Actual Loss: 2.1072\n",
      "Baseline Loss: 2.7991 | Actual Loss: 0.3455\n",
      "Baseline Loss: 2.8154 | Actual Loss: 0.3093\n",
      "Baseline Loss: 2.8691 | Actual Loss: 0.2288\n",
      "Baseline Loss: 2.7593 | Actual Loss: 0.3625\n",
      "Baseline Loss: 2.8390 | Actual Loss: 0.2991\n",
      "Baseline Loss: 2.8798 | Actual Loss: 0.6149\n",
      "Baseline Loss: 2.9120 | Actual Loss: 0.6455\n",
      "Baseline Loss: 2.8062 | Actual Loss: 0.2334\n",
      "Baseline Loss: 2.5404 | Actual Loss: 0.3637\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.4938\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.5577\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 160/1000 [01:31<08:52,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7147 | Actual Loss: 0.2232\n",
      "Epoch 160/1000: Train Loss: 0.4869, Val Loss: 0.3588\n",
      "New best validation loss: 0.3588\n",
      "Baseline Loss: 2.8102 | Actual Loss: 0.2655\n",
      "Baseline Loss: 2.8209 | Actual Loss: 0.5010\n",
      "Baseline Loss: 2.7630 | Actual Loss: 3.0485\n",
      "Baseline Loss: 2.9209 | Actual Loss: 0.5055\n",
      "Baseline Loss: 2.8271 | Actual Loss: 0.2306\n",
      "Baseline Loss: 2.8054 | Actual Loss: 0.3619\n",
      "Baseline Loss: 2.7507 | Actual Loss: 0.2520\n",
      "Baseline Loss: 2.8189 | Actual Loss: 0.4376\n",
      "Baseline Loss: 2.8954 | Actual Loss: 2.5632\n",
      "Baseline Loss: 2.8874 | Actual Loss: 0.1349\n",
      "Baseline Loss: 2.8015 | Actual Loss: 0.4689\n",
      "Baseline Loss: 2.7833 | Actual Loss: 0.1946\n",
      "Baseline Loss: 2.7670 | Actual Loss: 0.3485\n",
      "Baseline Loss: 2.7968 | Actual Loss: 1.8874\n",
      "Baseline Loss: 2.8393 | Actual Loss: 0.1233\n",
      "Baseline Loss: 2.5928 | Actual Loss: 1.5610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 161/1000 [01:32<09:03,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8420 | Actual Loss: 0.6557\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.6752\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2740\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4071\n",
      "Epoch 161/1000: Train Loss: 0.8053, Val Loss: 0.7530\n",
      "Baseline Loss: 2.7959 | Actual Loss: 0.2822\n",
      "Baseline Loss: 2.8388 | Actual Loss: 0.9098\n",
      "Baseline Loss: 2.7807 | Actual Loss: 0.3415\n",
      "Baseline Loss: 2.8331 | Actual Loss: 0.9675\n",
      "Baseline Loss: 2.8634 | Actual Loss: 0.3449\n",
      "Baseline Loss: 2.8670 | Actual Loss: 0.4902\n",
      "Baseline Loss: 2.8626 | Actual Loss: 0.1227\n",
      "Baseline Loss: 2.7847 | Actual Loss: 0.2182\n",
      "Baseline Loss: 2.7702 | Actual Loss: 0.2268\n",
      "Baseline Loss: 2.8510 | Actual Loss: 1.4406\n",
      "Baseline Loss: 2.8010 | Actual Loss: 0.3297\n",
      "Baseline Loss: 2.8239 | Actual Loss: 0.4740\n",
      "Baseline Loss: 2.8411 | Actual Loss: 2.6994\n",
      "Baseline Loss: 2.8226 | Actual Loss: 0.2270\n",
      "Baseline Loss: 2.7738 | Actual Loss: 0.6127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 162/1000 [01:32<09:10,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5466 | Actual Loss: 0.0570\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5937\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.2961\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1321\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.3945\n",
      "Epoch 162/1000: Train Loss: 0.6090, Val Loss: 0.3541\n",
      "New best validation loss: 0.3541\n",
      "Baseline Loss: 2.7762 | Actual Loss: 0.3887\n",
      "Baseline Loss: 2.8953 | Actual Loss: 0.1534\n",
      "Baseline Loss: 2.8236 | Actual Loss: 0.2939\n",
      "Baseline Loss: 2.8261 | Actual Loss: 0.6593\n",
      "Baseline Loss: 2.8503 | Actual Loss: 1.2507\n",
      "Baseline Loss: 2.8092 | Actual Loss: 0.3914\n",
      "Baseline Loss: 2.8073 | Actual Loss: 0.3932\n",
      "Baseline Loss: 2.7858 | Actual Loss: 0.6902\n",
      "Baseline Loss: 2.8766 | Actual Loss: 0.7903\n",
      "Baseline Loss: 2.8016 | Actual Loss: 0.2257\n",
      "Baseline Loss: 2.8386 | Actual Loss: 0.2567\n",
      "Baseline Loss: 2.8480 | Actual Loss: 0.4596\n",
      "Baseline Loss: 2.7993 | Actual Loss: 0.5351\n",
      "Baseline Loss: 2.7994 | Actual Loss: 0.6295\n",
      "Baseline Loss: 2.8280 | Actual Loss: 0.4017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▋        | 163/1000 [01:33<08:56,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5513 | Actual Loss: 0.1113\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5917\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.5907\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.3140\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.2553\n",
      "Epoch 163/1000: Train Loss: 0.4769, Val Loss: 0.4379\n",
      "Baseline Loss: 2.8704 | Actual Loss: 0.4071\n",
      "Baseline Loss: 2.8335 | Actual Loss: 0.2069\n",
      "Baseline Loss: 2.8405 | Actual Loss: 0.2410\n",
      "Baseline Loss: 2.7944 | Actual Loss: 0.5761\n",
      "Baseline Loss: 2.8451 | Actual Loss: 0.2012\n",
      "Baseline Loss: 2.8571 | Actual Loss: 0.1657\n",
      "Baseline Loss: 2.7538 | Actual Loss: 0.2425\n",
      "Baseline Loss: 2.8523 | Actual Loss: 0.2321\n",
      "Baseline Loss: 2.7845 | Actual Loss: 1.5599\n",
      "Baseline Loss: 2.8117 | Actual Loss: 0.7731\n",
      "Baseline Loss: 2.8660 | Actual Loss: 0.2293\n",
      "Baseline Loss: 2.8168 | Actual Loss: 0.2091\n",
      "Baseline Loss: 2.8093 | Actual Loss: 0.4817\n",
      "Baseline Loss: 2.7716 | Actual Loss: 0.2863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▋        | 164/1000 [01:34<09:06,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7943 | Actual Loss: 0.2563\n",
      "Baseline Loss: 2.6200 | Actual Loss: 0.1677\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5870\n",
      "Baseline Loss: 2.7887 | Actual Loss: 2.5226\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1923\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.2752\n",
      "Epoch 164/1000: Train Loss: 0.3897, Val Loss: 0.8943\n",
      "Baseline Loss: 2.7799 | Actual Loss: 0.2435\n",
      "Baseline Loss: 2.8914 | Actual Loss: 1.9952\n",
      "Baseline Loss: 2.8409 | Actual Loss: 0.9150\n",
      "Baseline Loss: 2.8140 | Actual Loss: 1.0689\n",
      "Baseline Loss: 2.7464 | Actual Loss: 0.3164\n",
      "Baseline Loss: 2.9023 | Actual Loss: 0.3663\n",
      "Baseline Loss: 2.8775 | Actual Loss: 0.2759\n",
      "Baseline Loss: 2.9045 | Actual Loss: 0.2262\n",
      "Baseline Loss: 2.8074 | Actual Loss: 0.4155\n",
      "Baseline Loss: 2.8025 | Actual Loss: 0.6853\n",
      "Baseline Loss: 2.8384 | Actual Loss: 0.5338\n",
      "Baseline Loss: 2.8995 | Actual Loss: 1.1785\n",
      "Baseline Loss: 2.7537 | Actual Loss: 0.8634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▋        | 165/1000 [01:34<09:09,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9097 | Actual Loss: 0.4455\n",
      "Baseline Loss: 2.8045 | Actual Loss: 0.3413\n",
      "Baseline Loss: 2.4461 | Actual Loss: 0.1958\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5859\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.2561\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1924\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4291\n",
      "Epoch 165/1000: Train Loss: 0.6291, Val Loss: 0.6159\n",
      "Baseline Loss: 2.8354 | Actual Loss: 0.8415\n",
      "Baseline Loss: 2.8021 | Actual Loss: 0.3548\n",
      "Baseline Loss: 2.8447 | Actual Loss: 0.5978\n",
      "Baseline Loss: 2.8122 | Actual Loss: 0.4702\n",
      "Baseline Loss: 2.8171 | Actual Loss: 0.3618\n",
      "Baseline Loss: 2.8385 | Actual Loss: 1.2126\n",
      "Baseline Loss: 2.8337 | Actual Loss: 0.2900\n",
      "Baseline Loss: 2.7617 | Actual Loss: 0.9690\n",
      "Baseline Loss: 2.7894 | Actual Loss: 0.9068\n",
      "Baseline Loss: 2.8075 | Actual Loss: 0.7187\n",
      "Baseline Loss: 2.8578 | Actual Loss: 0.4568\n",
      "Baseline Loss: 2.8864 | Actual Loss: 0.4065\n",
      "Baseline Loss: 2.7750 | Actual Loss: 0.3776\n",
      "Baseline Loss: 2.7676 | Actual Loss: 0.3166\n",
      "Baseline Loss: 2.8810 | Actual Loss: 0.2357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 166/1000 [01:35<08:56,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5480 | Actual Loss: 0.2881\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5400\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.9910\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2701\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4105\n",
      "Epoch 166/1000: Train Loss: 0.5503, Val Loss: 0.5529\n",
      "Baseline Loss: 2.7848 | Actual Loss: 0.6130\n",
      "Baseline Loss: 2.9036 | Actual Loss: 0.8508\n",
      "Baseline Loss: 2.7712 | Actual Loss: 0.3065\n",
      "Baseline Loss: 2.8481 | Actual Loss: 0.2945\n",
      "Baseline Loss: 2.8302 | Actual Loss: 2.7361\n",
      "Baseline Loss: 2.8734 | Actual Loss: 0.3732\n",
      "Baseline Loss: 2.8315 | Actual Loss: 2.3217\n",
      "Baseline Loss: 2.7883 | Actual Loss: 0.9908\n",
      "Baseline Loss: 2.7473 | Actual Loss: 0.5164\n",
      "Baseline Loss: 2.9407 | Actual Loss: 0.4539\n",
      "Baseline Loss: 2.8699 | Actual Loss: 0.3248\n",
      "Baseline Loss: 2.8463 | Actual Loss: 0.2970\n",
      "Baseline Loss: 2.7966 | Actual Loss: 0.0868\n",
      "Baseline Loss: 2.8597 | Actual Loss: 0.2485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 167/1000 [01:36<09:04,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8255 | Actual Loss: 0.3924\n",
      "Baseline Loss: 2.4855 | Actual Loss: 2.2579\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5292\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.8783\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1893\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4206\n",
      "Epoch 167/1000: Train Loss: 0.8165, Val Loss: 0.5043\n",
      "Baseline Loss: 2.8062 | Actual Loss: 0.2845\n",
      "Baseline Loss: 2.7992 | Actual Loss: 0.0938\n",
      "Baseline Loss: 2.7917 | Actual Loss: 0.6055\n",
      "Baseline Loss: 2.8070 | Actual Loss: 0.3907\n",
      "Baseline Loss: 2.8649 | Actual Loss: 0.1696\n",
      "Baseline Loss: 2.8364 | Actual Loss: 0.1594\n",
      "Baseline Loss: 2.8612 | Actual Loss: 0.5825\n",
      "Baseline Loss: 2.7921 | Actual Loss: 0.2477\n",
      "Baseline Loss: 2.8446 | Actual Loss: 0.5563\n",
      "Baseline Loss: 2.8098 | Actual Loss: 0.1274\n",
      "Baseline Loss: 2.8103 | Actual Loss: 0.2187\n",
      "Baseline Loss: 2.8736 | Actual Loss: 0.2012\n",
      "Baseline Loss: 2.9267 | Actual Loss: 0.2978\n",
      "Baseline Loss: 2.8554 | Actual Loss: 0.3409\n",
      "Baseline Loss: 2.8442 | Actual Loss: 0.2345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 168/1000 [01:36<09:06,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.4333 | Actual Loss: 0.3551\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5705\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.8666\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2546\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.3413\n",
      "Epoch 168/1000: Train Loss: 0.3041, Val Loss: 0.7583\n",
      "Baseline Loss: 2.8806 | Actual Loss: 0.6595\n",
      "Baseline Loss: 2.8461 | Actual Loss: 2.9393\n",
      "Baseline Loss: 2.8461 | Actual Loss: 0.3593\n",
      "Baseline Loss: 2.8088 | Actual Loss: 0.3515\n",
      "Baseline Loss: 2.8994 | Actual Loss: 0.2722\n",
      "Baseline Loss: 2.7925 | Actual Loss: 0.4080\n",
      "Baseline Loss: 2.7421 | Actual Loss: 0.4980\n",
      "Baseline Loss: 2.8767 | Actual Loss: 0.2123\n",
      "Baseline Loss: 2.8592 | Actual Loss: 0.2534\n",
      "Baseline Loss: 2.7829 | Actual Loss: 0.3243\n",
      "Baseline Loss: 2.7617 | Actual Loss: 0.4512\n",
      "Baseline Loss: 2.8355 | Actual Loss: 0.2070\n",
      "Baseline Loss: 2.7996 | Actual Loss: 0.4245\n",
      "Baseline Loss: 2.7988 | Actual Loss: 0.3129\n",
      "Baseline Loss: 2.8613 | Actual Loss: 2.8074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 169/1000 [01:37<08:53,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.4162 | Actual Loss: 0.2446\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.4946\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.5617\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.3719\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4666\n",
      "Epoch 169/1000: Train Loss: 0.6704, Val Loss: 0.7237\n",
      "Baseline Loss: 2.8561 | Actual Loss: 2.7699\n",
      "Baseline Loss: 2.8464 | Actual Loss: 0.2626\n",
      "Baseline Loss: 2.8605 | Actual Loss: 0.2308\n",
      "Baseline Loss: 2.8780 | Actual Loss: 0.1688\n",
      "Baseline Loss: 2.7992 | Actual Loss: 2.7366\n",
      "Baseline Loss: 2.7756 | Actual Loss: 0.4757\n",
      "Baseline Loss: 2.7468 | Actual Loss: 0.4301\n",
      "Baseline Loss: 2.8953 | Actual Loss: 0.2084\n",
      "Baseline Loss: 2.8004 | Actual Loss: 0.1235\n",
      "Baseline Loss: 2.8333 | Actual Loss: 2.3632\n",
      "Baseline Loss: 2.8677 | Actual Loss: 0.4682\n",
      "Baseline Loss: 2.8184 | Actual Loss: 0.3850\n",
      "Baseline Loss: 2.7856 | Actual Loss: 0.2144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 170/1000 [01:38<09:08,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8715 | Actual Loss: 0.4749\n",
      "Baseline Loss: 2.8967 | Actual Loss: 0.2776\n",
      "Baseline Loss: 2.6227 | Actual Loss: 0.3529\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5722\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.5307\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2472\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.2587\n",
      "Epoch 170/1000: Train Loss: 0.7464, Val Loss: 0.6522\n",
      "Baseline Loss: 2.8084 | Actual Loss: 0.1450\n",
      "Baseline Loss: 2.8630 | Actual Loss: 0.2285\n",
      "Baseline Loss: 2.8595 | Actual Loss: 0.4440\n",
      "Baseline Loss: 2.8211 | Actual Loss: 1.3744\n",
      "Baseline Loss: 2.9684 | Actual Loss: 0.2863\n",
      "Baseline Loss: 2.7769 | Actual Loss: 0.4041\n",
      "Baseline Loss: 2.7613 | Actual Loss: 0.6798\n",
      "Baseline Loss: 2.7952 | Actual Loss: 0.5411\n",
      "Baseline Loss: 2.8574 | Actual Loss: 0.5508\n",
      "Baseline Loss: 2.8056 | Actual Loss: 0.3379\n",
      "Baseline Loss: 2.8043 | Actual Loss: 0.1140\n",
      "Baseline Loss: 2.8236 | Actual Loss: 0.2420\n",
      "Baseline Loss: 2.7888 | Actual Loss: 0.2403\n",
      "Baseline Loss: 2.8767 | Actual Loss: 0.6728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 171/1000 [01:38<09:15,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8434 | Actual Loss: 0.4596\n",
      "Baseline Loss: 2.5361 | Actual Loss: 0.2587\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5961\n",
      "Baseline Loss: 2.7887 | Actual Loss: 2.7098\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2220\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.3148\n",
      "Epoch 171/1000: Train Loss: 0.4362, Val Loss: 0.9607\n",
      "Baseline Loss: 2.7746 | Actual Loss: 0.9571\n",
      "Baseline Loss: 2.7625 | Actual Loss: 0.2773\n",
      "Baseline Loss: 2.8464 | Actual Loss: 0.5606\n",
      "Baseline Loss: 2.8573 | Actual Loss: 0.6295\n",
      "Baseline Loss: 2.8204 | Actual Loss: 0.1346\n",
      "Baseline Loss: 2.8040 | Actual Loss: 0.3731\n",
      "Baseline Loss: 2.8029 | Actual Loss: 2.3753\n",
      "Baseline Loss: 2.8302 | Actual Loss: 0.1263\n",
      "Baseline Loss: 2.8029 | Actual Loss: 0.2193\n",
      "Baseline Loss: 2.8123 | Actual Loss: 0.4399\n",
      "Baseline Loss: 2.9555 | Actual Loss: 0.4841\n",
      "Baseline Loss: 2.7716 | Actual Loss: 0.6089\n",
      "Baseline Loss: 2.8237 | Actual Loss: 1.1115\n",
      "Baseline Loss: 2.8532 | Actual Loss: 0.4440\n",
      "Baseline Loss: 2.8437 | Actual Loss: 1.1887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 172/1000 [01:39<08:59,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6070 | Actual Loss: 0.2010\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5807\n",
      "Baseline Loss: 2.7887 | Actual Loss: 2.8009\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2453\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4544\n",
      "Epoch 172/1000: Train Loss: 0.6332, Val Loss: 1.0203\n",
      "Baseline Loss: 2.7474 | Actual Loss: 2.5615\n",
      "Baseline Loss: 2.8017 | Actual Loss: 0.2766\n",
      "Baseline Loss: 2.7996 | Actual Loss: 0.6118\n",
      "Baseline Loss: 2.8146 | Actual Loss: 0.3031\n",
      "Baseline Loss: 2.8740 | Actual Loss: 0.2852\n",
      "Baseline Loss: 2.9216 | Actual Loss: 0.2116\n",
      "Baseline Loss: 2.8583 | Actual Loss: 0.2631\n",
      "Baseline Loss: 2.8557 | Actual Loss: 0.3189\n",
      "Baseline Loss: 2.8121 | Actual Loss: 0.4934\n",
      "Baseline Loss: 2.8145 | Actual Loss: 0.5629\n",
      "Baseline Loss: 2.7518 | Actual Loss: 0.4993\n",
      "Baseline Loss: 2.8004 | Actual Loss: 0.7288\n",
      "Baseline Loss: 2.8624 | Actual Loss: 0.4521\n",
      "Baseline Loss: 2.8348 | Actual Loss: 0.4553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 173/1000 [01:40<09:02,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7744 | Actual Loss: 0.2589\n",
      "Baseline Loss: 2.5547 | Actual Loss: 0.2434\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5574\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.3723\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1965\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4059\n",
      "Epoch 173/1000: Train Loss: 0.5329, Val Loss: 0.3830\n",
      "Baseline Loss: 2.8788 | Actual Loss: 0.3781\n",
      "Baseline Loss: 2.7648 | Actual Loss: 0.2485\n",
      "Baseline Loss: 2.8164 | Actual Loss: 0.2019\n",
      "Baseline Loss: 2.8584 | Actual Loss: 0.1530\n",
      "Baseline Loss: 2.7942 | Actual Loss: 2.7362\n",
      "Baseline Loss: 2.8144 | Actual Loss: 0.3090\n",
      "Baseline Loss: 2.9058 | Actual Loss: 0.5428\n",
      "Baseline Loss: 2.7854 | Actual Loss: 0.8485\n",
      "Baseline Loss: 2.8260 | Actual Loss: 0.2036\n",
      "Baseline Loss: 2.8564 | Actual Loss: 0.4497\n",
      "Baseline Loss: 2.7948 | Actual Loss: 0.3831\n",
      "Baseline Loss: 2.8651 | Actual Loss: 0.2966\n",
      "Baseline Loss: 2.7709 | Actual Loss: 0.2001\n",
      "Baseline Loss: 2.8493 | Actual Loss: 0.5437\n",
      "Baseline Loss: 2.8552 | Actual Loss: 2.4334\n",
      "Baseline Loss: 2.5714 | Actual Loss: 0.0848\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 174/1000 [01:40<08:58,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7887 | Actual Loss: 0.8057\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2077\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4214\n",
      "Epoch 174/1000: Train Loss: 0.6258, Val Loss: 0.5023\n",
      "Baseline Loss: 2.8344 | Actual Loss: 0.4250\n",
      "Baseline Loss: 2.8083 | Actual Loss: 0.4761\n",
      "Baseline Loss: 2.7827 | Actual Loss: 0.1655\n",
      "Baseline Loss: 2.8779 | Actual Loss: 2.6133\n",
      "Baseline Loss: 2.7991 | Actual Loss: 0.3775\n",
      "Baseline Loss: 2.8782 | Actual Loss: 0.3074\n",
      "Baseline Loss: 2.8522 | Actual Loss: 0.4373\n",
      "Baseline Loss: 2.8186 | Actual Loss: 0.5498\n",
      "Baseline Loss: 2.7511 | Actual Loss: 0.1795\n",
      "Baseline Loss: 2.8771 | Actual Loss: 0.5580\n",
      "Baseline Loss: 2.7799 | Actual Loss: 0.3717\n",
      "Baseline Loss: 2.8851 | Actual Loss: 0.5491\n",
      "Baseline Loss: 2.8809 | Actual Loss: 0.4899\n",
      "Baseline Loss: 2.7485 | Actual Loss: 0.4397\n",
      "Baseline Loss: 2.7714 | Actual Loss: 0.2593\n",
      "Baseline Loss: 2.6673 | Actual Loss: 0.3343\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5619\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.4772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 175/1000 [01:41<08:46,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8632 | Actual Loss: 0.2438\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4374\n",
      "Epoch 175/1000: Train Loss: 0.5333, Val Loss: 0.6801\n",
      "Baseline Loss: 2.8382 | Actual Loss: 0.3048\n",
      "Baseline Loss: 2.8587 | Actual Loss: 0.3730\n",
      "Baseline Loss: 2.7970 | Actual Loss: 2.3118\n",
      "Baseline Loss: 2.8307 | Actual Loss: 2.7027\n",
      "Baseline Loss: 2.7382 | Actual Loss: 0.5705\n",
      "Baseline Loss: 2.8689 | Actual Loss: 0.2232\n",
      "Baseline Loss: 2.7842 | Actual Loss: 0.6071\n",
      "Baseline Loss: 2.8580 | Actual Loss: 0.8138\n",
      "Baseline Loss: 2.7732 | Actual Loss: 0.0803\n",
      "Baseline Loss: 2.7986 | Actual Loss: 0.5364\n",
      "Baseline Loss: 2.8800 | Actual Loss: 0.3607\n",
      "Baseline Loss: 2.8182 | Actual Loss: 0.3643\n",
      "Baseline Loss: 2.8893 | Actual Loss: 0.9657\n",
      "Baseline Loss: 2.8174 | Actual Loss: 0.2449\n",
      "Baseline Loss: 2.8111 | Actual Loss: 0.3868\n",
      "Baseline Loss: 2.6004 | Actual Loss: 0.1137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 176/1000 [01:42<08:56,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8420 | Actual Loss: 0.5237\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.5645\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2199\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4400\n",
      "Epoch 176/1000: Train Loss: 0.6850, Val Loss: 0.4370\n",
      "Baseline Loss: 2.7571 | Actual Loss: 0.2168\n",
      "Baseline Loss: 2.8481 | Actual Loss: 0.4089\n",
      "Baseline Loss: 2.7937 | Actual Loss: 0.2764\n",
      "Baseline Loss: 2.8464 | Actual Loss: 0.2762\n",
      "Baseline Loss: 2.8016 | Actual Loss: 0.6656\n",
      "Baseline Loss: 2.8254 | Actual Loss: 0.7661\n",
      "Baseline Loss: 2.8609 | Actual Loss: 0.7470\n",
      "Baseline Loss: 2.8200 | Actual Loss: 0.5087\n",
      "Baseline Loss: 2.8971 | Actual Loss: 1.0537\n",
      "Baseline Loss: 2.8452 | Actual Loss: 0.9420\n",
      "Baseline Loss: 2.8234 | Actual Loss: 0.1225\n",
      "Baseline Loss: 2.8460 | Actual Loss: 0.4304\n",
      "Baseline Loss: 2.8078 | Actual Loss: 0.1676\n",
      "Baseline Loss: 2.8261 | Actual Loss: 2.2497\n",
      "Baseline Loss: 2.8429 | Actual Loss: 0.5426\n",
      "Baseline Loss: 2.5950 | Actual Loss: 3.1041\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5484\n",
      "Baseline Loss: 2.7887 | Actual Loss: 2.4258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 177/1000 [01:42<08:40,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8632 | Actual Loss: 0.2184\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4781\n",
      "Epoch 177/1000: Train Loss: 0.7799, Val Loss: 0.9177\n",
      "Baseline Loss: 2.8237 | Actual Loss: 0.1575\n",
      "Baseline Loss: 2.7477 | Actual Loss: 0.6159\n",
      "Baseline Loss: 2.8822 | Actual Loss: 0.7536\n",
      "Baseline Loss: 2.8184 | Actual Loss: 0.3961\n",
      "Baseline Loss: 2.8295 | Actual Loss: 0.2026\n",
      "Baseline Loss: 2.8080 | Actual Loss: 0.5645\n",
      "Baseline Loss: 2.8113 | Actual Loss: 0.4952\n",
      "Baseline Loss: 2.8237 | Actual Loss: 0.6336\n",
      "Baseline Loss: 2.8159 | Actual Loss: 0.2208\n",
      "Baseline Loss: 2.8151 | Actual Loss: 0.6052\n",
      "Baseline Loss: 2.8455 | Actual Loss: 0.2396\n",
      "Baseline Loss: 2.8273 | Actual Loss: 0.1969\n",
      "Baseline Loss: 2.8428 | Actual Loss: 0.3044\n",
      "Baseline Loss: 2.8315 | Actual Loss: 2.5554\n",
      "Baseline Loss: 2.8857 | Actual Loss: 0.1834\n",
      "Baseline Loss: 2.4696 | Actual Loss: 0.0800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 178/1000 [01:43<08:49,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8420 | Actual Loss: 0.5379\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.5290\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2305\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.5642\n",
      "Epoch 178/1000: Train Loss: 0.5128, Val Loss: 0.7154\n",
      "Baseline Loss: 2.8786 | Actual Loss: 0.2914\n",
      "Baseline Loss: 2.8421 | Actual Loss: 0.3881\n",
      "Baseline Loss: 2.7543 | Actual Loss: 2.3773\n",
      "Baseline Loss: 2.8354 | Actual Loss: 0.5164\n",
      "Baseline Loss: 2.8026 | Actual Loss: 0.5802\n",
      "Baseline Loss: 2.7383 | Actual Loss: 0.4010\n",
      "Baseline Loss: 2.8540 | Actual Loss: 0.2090\n",
      "Baseline Loss: 2.7942 | Actual Loss: 0.5083\n",
      "Baseline Loss: 2.8116 | Actual Loss: 0.5069\n",
      "Baseline Loss: 2.8683 | Actual Loss: 0.6290\n",
      "Baseline Loss: 2.7996 | Actual Loss: 0.7297\n",
      "Baseline Loss: 2.7612 | Actual Loss: 0.4702\n",
      "Baseline Loss: 2.8454 | Actual Loss: 0.3498\n",
      "Baseline Loss: 2.8623 | Actual Loss: 0.6094\n",
      "Baseline Loss: 2.9416 | Actual Loss: 0.1404\n",
      "Baseline Loss: 2.5631 | Actual Loss: 0.2232\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5691\n",
      "Baseline Loss: 2.7887 | Actual Loss: 2.6257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 179/1000 [01:43<08:49,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8632 | Actual Loss: 0.3160\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.3724\n",
      "Epoch 179/1000: Train Loss: 0.5581, Val Loss: 0.9708\n",
      "Baseline Loss: 2.8243 | Actual Loss: 3.1835\n",
      "Baseline Loss: 2.7536 | Actual Loss: 0.3572\n",
      "Baseline Loss: 2.7353 | Actual Loss: 0.3904\n",
      "Baseline Loss: 2.8534 | Actual Loss: 0.2665\n",
      "Baseline Loss: 2.8329 | Actual Loss: 0.3552\n",
      "Baseline Loss: 2.7769 | Actual Loss: 0.2593\n",
      "Baseline Loss: 2.9072 | Actual Loss: 0.3388\n",
      "Baseline Loss: 2.8226 | Actual Loss: 2.6467\n",
      "Baseline Loss: 2.8686 | Actual Loss: 0.3799\n",
      "Baseline Loss: 2.7954 | Actual Loss: 0.3127\n",
      "Baseline Loss: 2.8579 | Actual Loss: 0.6120\n",
      "Baseline Loss: 2.8983 | Actual Loss: 0.3514\n",
      "Baseline Loss: 2.7658 | Actual Loss: 0.1354\n",
      "Baseline Loss: 2.8728 | Actual Loss: 0.8528\n",
      "Baseline Loss: 2.7988 | Actual Loss: 0.2403\n",
      "Baseline Loss: 2.3717 | Actual Loss: 0.4879\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.6416\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.4813\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 180/1000 [01:44<08:58,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7147 | Actual Loss: 0.2241\n",
      "Epoch 180/1000: Train Loss: 0.6981, Val Loss: 0.4013\n",
      "Baseline Loss: 2.8049 | Actual Loss: 0.5865\n",
      "Baseline Loss: 2.7434 | Actual Loss: 2.6597\n",
      "Baseline Loss: 2.8504 | Actual Loss: 0.5235\n",
      "Baseline Loss: 2.8125 | Actual Loss: 1.1930\n",
      "Baseline Loss: 2.8348 | Actual Loss: 0.6843\n",
      "Baseline Loss: 2.8309 | Actual Loss: 0.2873\n",
      "Baseline Loss: 2.8885 | Actual Loss: 0.3563\n",
      "Baseline Loss: 2.8451 | Actual Loss: 0.3190\n",
      "Baseline Loss: 2.7762 | Actual Loss: 0.5188\n",
      "Baseline Loss: 2.8480 | Actual Loss: 0.2414\n",
      "Baseline Loss: 2.7875 | Actual Loss: 0.3507\n",
      "Baseline Loss: 2.8665 | Actual Loss: 0.2779\n",
      "Baseline Loss: 2.8495 | Actual Loss: 0.2627\n",
      "Baseline Loss: 2.7950 | Actual Loss: 0.5172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 181/1000 [01:45<08:35,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8343 | Actual Loss: 0.2561\n",
      "Baseline Loss: 2.4807 | Actual Loss: 2.1698\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5450\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.8918\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.3424\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4405\n",
      "Epoch 181/1000: Train Loss: 0.7003, Val Loss: 0.5549\n",
      "Baseline Loss: 2.8128 | Actual Loss: 0.4961\n",
      "Baseline Loss: 2.8122 | Actual Loss: 0.2844\n",
      "Baseline Loss: 2.8519 | Actual Loss: 0.5739\n",
      "Baseline Loss: 2.8726 | Actual Loss: 0.2065\n",
      "Baseline Loss: 2.8687 | Actual Loss: 0.2089\n",
      "Baseline Loss: 2.8421 | Actual Loss: 0.3766\n",
      "Baseline Loss: 2.8012 | Actual Loss: 0.2209\n",
      "Baseline Loss: 2.8247 | Actual Loss: 0.4883\n",
      "Baseline Loss: 2.8408 | Actual Loss: 0.2319\n",
      "Baseline Loss: 2.7444 | Actual Loss: 0.2573\n",
      "Baseline Loss: 2.8408 | Actual Loss: 0.2308\n",
      "Baseline Loss: 2.7988 | Actual Loss: 0.5410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 182/1000 [01:45<08:41,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8256 | Actual Loss: 0.3186\n",
      "Baseline Loss: 2.7515 | Actual Loss: 0.4285\n",
      "Baseline Loss: 2.7970 | Actual Loss: 1.5896\n",
      "Baseline Loss: 2.4128 | Actual Loss: 0.0974\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5486\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.1521\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2243\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.5089\n",
      "Epoch 182/1000: Train Loss: 0.4094, Val Loss: 0.6085\n",
      "Baseline Loss: 2.8540 | Actual Loss: 0.2178\n",
      "Baseline Loss: 2.8135 | Actual Loss: 1.3593\n",
      "Baseline Loss: 2.8577 | Actual Loss: 0.2882\n",
      "Baseline Loss: 2.7881 | Actual Loss: 0.3851\n",
      "Baseline Loss: 2.7739 | Actual Loss: 0.2184\n",
      "Baseline Loss: 2.8526 | Actual Loss: 0.7257\n",
      "Baseline Loss: 2.8621 | Actual Loss: 0.1077\n",
      "Baseline Loss: 2.8137 | Actual Loss: 0.3346\n",
      "Baseline Loss: 2.8184 | Actual Loss: 2.4134\n",
      "Baseline Loss: 2.8068 | Actual Loss: 0.7170\n",
      "Baseline Loss: 2.7966 | Actual Loss: 0.2603\n",
      "Baseline Loss: 2.8163 | Actual Loss: 0.3372\n",
      "Baseline Loss: 2.7922 | Actual Loss: 0.5201\n",
      "Baseline Loss: 2.8205 | Actual Loss: 0.8476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 183/1000 [01:46<08:33,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.9362 | Actual Loss: 0.4864\n",
      "Baseline Loss: 2.5794 | Actual Loss: 0.0820\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5205\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.0410\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1922\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4089\n",
      "Epoch 183/1000: Train Loss: 0.5813, Val Loss: 0.5406\n",
      "Baseline Loss: 2.8804 | Actual Loss: 0.1170\n",
      "Baseline Loss: 2.9225 | Actual Loss: 0.4748\n",
      "Baseline Loss: 2.8399 | Actual Loss: 1.1171\n",
      "Baseline Loss: 2.7928 | Actual Loss: 0.5078\n",
      "Baseline Loss: 2.7630 | Actual Loss: 0.4478\n",
      "Baseline Loss: 2.7943 | Actual Loss: 0.9516\n",
      "Baseline Loss: 2.7652 | Actual Loss: 0.5483\n",
      "Baseline Loss: 2.7821 | Actual Loss: 0.2733\n",
      "Baseline Loss: 2.8497 | Actual Loss: 0.3809\n",
      "Baseline Loss: 2.7674 | Actual Loss: 0.1285\n",
      "Baseline Loss: 2.8702 | Actual Loss: 0.5869\n",
      "Baseline Loss: 2.8755 | Actual Loss: 0.4862\n",
      "Baseline Loss: 2.8552 | Actual Loss: 0.5449\n",
      "Baseline Loss: 2.8478 | Actual Loss: 0.5087\n",
      "Baseline Loss: 2.8330 | Actual Loss: 0.4158\n",
      "Baseline Loss: 2.5760 | Actual Loss: 0.0769\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.4863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 184/1000 [01:47<08:47,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7887 | Actual Loss: 2.4067\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2618\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.3153\n",
      "Epoch 184/1000: Train Loss: 0.4729, Val Loss: 0.8675\n",
      "Baseline Loss: 2.8072 | Actual Loss: 0.2635\n",
      "Baseline Loss: 2.8778 | Actual Loss: 0.2506\n",
      "Baseline Loss: 2.8083 | Actual Loss: 0.3029\n",
      "Baseline Loss: 2.8458 | Actual Loss: 0.4935\n",
      "Baseline Loss: 2.9563 | Actual Loss: 0.3107\n",
      "Baseline Loss: 2.8020 | Actual Loss: 0.3660\n",
      "Baseline Loss: 2.7731 | Actual Loss: 0.5333\n",
      "Baseline Loss: 2.8946 | Actual Loss: 0.5739\n",
      "Baseline Loss: 2.8345 | Actual Loss: 0.3571\n",
      "Baseline Loss: 2.7993 | Actual Loss: 0.2679\n",
      "Baseline Loss: 2.8398 | Actual Loss: 0.1438\n",
      "Baseline Loss: 2.8028 | Actual Loss: 0.5847\n",
      "Baseline Loss: 2.7644 | Actual Loss: 1.3494\n",
      "Baseline Loss: 2.8029 | Actual Loss: 0.5484\n",
      "Baseline Loss: 2.8518 | Actual Loss: 2.7307\n",
      "Baseline Loss: 2.4849 | Actual Loss: 0.3886\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.6062\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.2500\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 185/1000 [01:47<08:39,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7147 | Actual Loss: 0.4852\n",
      "Epoch 185/1000: Train Loss: 0.5916, Val Loss: 0.6452\n",
      "Baseline Loss: 2.8295 | Actual Loss: 0.9500\n",
      "Baseline Loss: 2.7690 | Actual Loss: 0.5869\n",
      "Baseline Loss: 2.7953 | Actual Loss: 1.2017\n",
      "Baseline Loss: 2.7921 | Actual Loss: 0.5731\n",
      "Baseline Loss: 2.8192 | Actual Loss: 0.2597\n",
      "Baseline Loss: 2.8208 | Actual Loss: 0.2111\n",
      "Baseline Loss: 2.7782 | Actual Loss: 0.2553\n",
      "Baseline Loss: 2.9423 | Actual Loss: 0.3400\n",
      "Baseline Loss: 2.8031 | Actual Loss: 0.5321\n",
      "Baseline Loss: 2.8605 | Actual Loss: 2.7847\n",
      "Baseline Loss: 2.7408 | Actual Loss: 0.4884\n",
      "Baseline Loss: 2.7690 | Actual Loss: 0.1395\n",
      "Baseline Loss: 2.8302 | Actual Loss: 0.3513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▊        | 186/1000 [01:48<08:31,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8831 | Actual Loss: 3.2140\n",
      "Baseline Loss: 2.8387 | Actual Loss: 0.1966\n",
      "Baseline Loss: 2.6143 | Actual Loss: 0.2651\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.6281\n",
      "Baseline Loss: 2.7887 | Actual Loss: 2.7278\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.3652\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4939\n",
      "Epoch 186/1000: Train Loss: 0.7718, Val Loss: 1.0538\n",
      "Baseline Loss: 2.8665 | Actual Loss: 0.2467\n",
      "Baseline Loss: 2.7790 | Actual Loss: 0.3460\n",
      "Baseline Loss: 2.8128 | Actual Loss: 0.3080\n",
      "Baseline Loss: 2.8934 | Actual Loss: 0.2852\n",
      "Baseline Loss: 2.8753 | Actual Loss: 2.7294\n",
      "Baseline Loss: 2.8402 | Actual Loss: 0.6417\n",
      "Baseline Loss: 2.8406 | Actual Loss: 0.3054\n",
      "Baseline Loss: 2.7715 | Actual Loss: 0.5539\n",
      "Baseline Loss: 2.8600 | Actual Loss: 0.2657\n",
      "Baseline Loss: 2.8600 | Actual Loss: 0.2971\n",
      "Baseline Loss: 2.7758 | Actual Loss: 0.8142\n",
      "Baseline Loss: 2.8162 | Actual Loss: 0.6150\n",
      "Baseline Loss: 2.8375 | Actual Loss: 0.9268\n",
      "Baseline Loss: 2.7980 | Actual Loss: 0.3018\n",
      "Baseline Loss: 2.7664 | Actual Loss: 0.2872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▊        | 187/1000 [01:49<08:37,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.4828 | Actual Loss: 0.1394\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5489\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.0671\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2860\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4359\n",
      "Epoch 187/1000: Train Loss: 0.5665, Val Loss: 0.5845\n",
      "Baseline Loss: 2.8676 | Actual Loss: 0.1176\n",
      "Baseline Loss: 2.8004 | Actual Loss: 0.6633\n",
      "Baseline Loss: 2.8326 | Actual Loss: 0.4116\n",
      "Baseline Loss: 2.8206 | Actual Loss: 0.5551\n",
      "Baseline Loss: 2.8642 | Actual Loss: 2.8740\n",
      "Baseline Loss: 2.8202 | Actual Loss: 0.6671\n",
      "Baseline Loss: 2.8820 | Actual Loss: 0.4593\n",
      "Baseline Loss: 2.8094 | Actual Loss: 2.4367\n",
      "Baseline Loss: 2.8622 | Actual Loss: 0.2331\n",
      "Baseline Loss: 2.7921 | Actual Loss: 0.2986\n",
      "Baseline Loss: 2.8766 | Actual Loss: 0.5347\n",
      "Baseline Loss: 2.8406 | Actual Loss: 0.1913\n",
      "Baseline Loss: 2.7541 | Actual Loss: 0.5878\n",
      "Baseline Loss: 2.8150 | Actual Loss: 0.3776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 188/1000 [01:49<08:43,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8429 | Actual Loss: 0.3931\n",
      "Baseline Loss: 2.3922 | Actual Loss: 2.3907\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5369\n",
      "Baseline Loss: 2.7887 | Actual Loss: 2.5364\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1500\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.3854\n",
      "Epoch 188/1000: Train Loss: 0.8245, Val Loss: 0.9022\n",
      "Baseline Loss: 2.7917 | Actual Loss: 0.3708\n",
      "Baseline Loss: 2.8373 | Actual Loss: 0.2079\n",
      "Baseline Loss: 2.8479 | Actual Loss: 2.5196\n",
      "Baseline Loss: 2.8044 | Actual Loss: 0.2270\n",
      "Baseline Loss: 2.8692 | Actual Loss: 0.4889\n",
      "Baseline Loss: 2.7078 | Actual Loss: 0.1370\n",
      "Baseline Loss: 2.9467 | Actual Loss: 0.5375\n",
      "Baseline Loss: 2.7836 | Actual Loss: 0.2956\n",
      "Baseline Loss: 2.7957 | Actual Loss: 0.3009\n",
      "Baseline Loss: 2.8764 | Actual Loss: 0.2551\n",
      "Baseline Loss: 2.8138 | Actual Loss: 0.4317\n",
      "Baseline Loss: 2.7926 | Actual Loss: 0.4894\n",
      "Baseline Loss: 2.9240 | Actual Loss: 2.5622\n",
      "Baseline Loss: 2.8025 | Actual Loss: 1.0027\n",
      "Baseline Loss: 2.9031 | Actual Loss: 0.2326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 189/1000 [01:50<08:34,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5571 | Actual Loss: 0.5362\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5058\n",
      "Baseline Loss: 2.7887 | Actual Loss: 2.5878\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2661\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4140\n",
      "Epoch 189/1000: Train Loss: 0.6622, Val Loss: 0.9434\n",
      "Baseline Loss: 2.7606 | Actual Loss: 0.4766\n",
      "Baseline Loss: 2.7971 | Actual Loss: 0.3583\n",
      "Baseline Loss: 2.8844 | Actual Loss: 0.5482\n",
      "Baseline Loss: 2.7982 | Actual Loss: 0.4070\n",
      "Baseline Loss: 2.8434 | Actual Loss: 0.2164\n",
      "Baseline Loss: 2.7729 | Actual Loss: 2.5756\n",
      "Baseline Loss: 2.8212 | Actual Loss: 0.4402\n",
      "Baseline Loss: 2.8391 | Actual Loss: 2.6424\n",
      "Baseline Loss: 2.8414 | Actual Loss: 2.5589\n",
      "Baseline Loss: 2.8363 | Actual Loss: 0.2052\n",
      "Baseline Loss: 2.7943 | Actual Loss: 0.4939\n",
      "Baseline Loss: 2.9020 | Actual Loss: 0.2696\n",
      "Baseline Loss: 2.9218 | Actual Loss: 0.5772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 190/1000 [01:50<08:45,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7251 | Actual Loss: 0.6029\n",
      "Baseline Loss: 2.7758 | Actual Loss: 0.1575\n",
      "Baseline Loss: 2.5341 | Actual Loss: 2.1704\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5970\n",
      "Baseline Loss: 2.7887 | Actual Loss: 2.5930\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2854\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.3244\n",
      "Epoch 190/1000: Train Loss: 0.9188, Val Loss: 0.9500\n",
      "Baseline Loss: 2.8032 | Actual Loss: 0.5362\n",
      "Baseline Loss: 2.8426 | Actual Loss: 0.3758\n",
      "Baseline Loss: 2.8101 | Actual Loss: 0.3455\n",
      "Baseline Loss: 2.8132 | Actual Loss: 0.1460\n",
      "Baseline Loss: 2.7592 | Actual Loss: 0.3072\n",
      "Baseline Loss: 2.7639 | Actual Loss: 0.4806\n",
      "Baseline Loss: 2.8096 | Actual Loss: 0.2148\n",
      "Baseline Loss: 2.8528 | Actual Loss: 0.2208\n",
      "Baseline Loss: 2.7656 | Actual Loss: 0.1355\n",
      "Baseline Loss: 2.8901 | Actual Loss: 0.3585\n",
      "Baseline Loss: 2.9250 | Actual Loss: 0.4395\n",
      "Baseline Loss: 2.9096 | Actual Loss: 0.8116\n",
      "Baseline Loss: 2.7990 | Actual Loss: 2.9326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 191/1000 [01:51<08:46,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8267 | Actual Loss: 0.5551\n",
      "Baseline Loss: 2.7725 | Actual Loss: 0.2649\n",
      "Baseline Loss: 2.5775 | Actual Loss: 2.5374\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5159\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.9152\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.3000\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4239\n",
      "Epoch 191/1000: Train Loss: 0.6664, Val Loss: 0.7887\n",
      "Baseline Loss: 2.8043 | Actual Loss: 0.2664\n",
      "Baseline Loss: 2.8618 | Actual Loss: 0.4983\n",
      "Baseline Loss: 2.8719 | Actual Loss: 0.4075\n",
      "Baseline Loss: 2.8013 | Actual Loss: 0.8029\n",
      "Baseline Loss: 2.8608 | Actual Loss: 0.2749\n",
      "Baseline Loss: 2.8262 | Actual Loss: 0.3080\n",
      "Baseline Loss: 2.8114 | Actual Loss: 2.5098\n",
      "Baseline Loss: 2.8578 | Actual Loss: 2.4614\n",
      "Baseline Loss: 2.8309 | Actual Loss: 0.3654\n",
      "Baseline Loss: 2.8747 | Actual Loss: 0.5433\n",
      "Baseline Loss: 2.8251 | Actual Loss: 0.5201\n",
      "Baseline Loss: 2.7864 | Actual Loss: 0.2593\n",
      "Baseline Loss: 2.7858 | Actual Loss: 2.3664\n",
      "Baseline Loss: 2.7768 | Actual Loss: 0.3295\n",
      "Baseline Loss: 2.8484 | Actual Loss: 0.1226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 192/1000 [01:52<08:36,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6354 | Actual Loss: 0.0892\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.6193\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.0264\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.3104\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.3882\n",
      "Epoch 192/1000: Train Loss: 0.7578, Val Loss: 0.5861\n",
      "Baseline Loss: 2.8579 | Actual Loss: 0.0941\n",
      "Baseline Loss: 2.8624 | Actual Loss: 0.2496\n",
      "Baseline Loss: 2.8393 | Actual Loss: 0.3661\n",
      "Baseline Loss: 2.8263 | Actual Loss: 0.2039\n",
      "Baseline Loss: 2.7916 | Actual Loss: 0.5004\n",
      "Baseline Loss: 2.7688 | Actual Loss: 0.4490\n",
      "Baseline Loss: 2.8685 | Actual Loss: 0.2327\n",
      "Baseline Loss: 2.8623 | Actual Loss: 2.4888\n",
      "Baseline Loss: 2.8197 | Actual Loss: 0.9123\n",
      "Baseline Loss: 2.8510 | Actual Loss: 0.5350\n",
      "Baseline Loss: 2.8421 | Actual Loss: 0.4428\n",
      "Baseline Loss: 2.8405 | Actual Loss: 0.4279\n",
      "Baseline Loss: 2.8388 | Actual Loss: 0.5097\n",
      "Baseline Loss: 2.8368 | Actual Loss: 0.4050\n",
      "Baseline Loss: 2.8390 | Actual Loss: 0.5855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 193/1000 [01:52<08:36,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5033 | Actual Loss: 0.1894\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.6306\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.9380\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1872\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.3470\n",
      "Epoch 193/1000: Train Loss: 0.5370, Val Loss: 0.5257\n",
      "Baseline Loss: 2.8675 | Actual Loss: 1.0826\n",
      "Baseline Loss: 2.8344 | Actual Loss: 1.9585\n",
      "Baseline Loss: 2.8032 | Actual Loss: 0.2103\n",
      "Baseline Loss: 2.9633 | Actual Loss: 0.6862\n",
      "Baseline Loss: 2.8185 | Actual Loss: 0.3484\n",
      "Baseline Loss: 2.7720 | Actual Loss: 0.4958\n",
      "Baseline Loss: 2.8790 | Actual Loss: 0.2285\n",
      "Baseline Loss: 2.8079 | Actual Loss: 0.6329\n",
      "Baseline Loss: 2.8380 | Actual Loss: 0.5105\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.3680\n",
      "Baseline Loss: 2.7912 | Actual Loss: 0.3445\n",
      "Baseline Loss: 2.8339 | Actual Loss: 0.5942\n",
      "Baseline Loss: 2.7744 | Actual Loss: 0.7987\n",
      "Baseline Loss: 2.8454 | Actual Loss: 0.4715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 194/1000 [01:53<08:46,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8906 | Actual Loss: 0.1273\n",
      "Baseline Loss: 2.5350 | Actual Loss: 0.0567\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5460\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.9477\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1253\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.3359\n",
      "Epoch 194/1000: Train Loss: 0.5572, Val Loss: 0.4887\n",
      "Baseline Loss: 2.8970 | Actual Loss: 0.5293\n",
      "Baseline Loss: 2.7875 | Actual Loss: 0.2204\n",
      "Baseline Loss: 2.7921 | Actual Loss: 2.1604\n",
      "Baseline Loss: 2.8541 | Actual Loss: 0.5172\n",
      "Baseline Loss: 2.7932 | Actual Loss: 0.4377\n",
      "Baseline Loss: 2.8022 | Actual Loss: 0.2245\n",
      "Baseline Loss: 2.8889 | Actual Loss: 0.3352\n",
      "Baseline Loss: 2.8772 | Actual Loss: 0.2185\n",
      "Baseline Loss: 2.7594 | Actual Loss: 0.4311\n",
      "Baseline Loss: 2.8224 | Actual Loss: 0.4101\n",
      "Baseline Loss: 2.7568 | Actual Loss: 0.7334\n",
      "Baseline Loss: 2.8433 | Actual Loss: 0.5813\n",
      "Baseline Loss: 2.8313 | Actual Loss: 0.3859\n",
      "Baseline Loss: 2.8234 | Actual Loss: 0.4517\n",
      "Baseline Loss: 2.8000 | Actual Loss: 0.3655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 195/1000 [01:54<08:35,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5210 | Actual Loss: 0.2590\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5537\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.6494\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1450\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4355\n",
      "Epoch 195/1000: Train Loss: 0.5163, Val Loss: 0.4459\n",
      "Baseline Loss: 2.8212 | Actual Loss: 0.3696\n",
      "Baseline Loss: 2.9476 | Actual Loss: 0.7696\n",
      "Baseline Loss: 2.8662 | Actual Loss: 0.2022\n",
      "Baseline Loss: 2.8918 | Actual Loss: 0.2320\n",
      "Baseline Loss: 2.7981 | Actual Loss: 0.9950\n",
      "Baseline Loss: 2.7947 | Actual Loss: 0.3099\n",
      "Baseline Loss: 2.8302 | Actual Loss: 0.1502\n",
      "Baseline Loss: 2.7313 | Actual Loss: 0.3110\n",
      "Baseline Loss: 2.7830 | Actual Loss: 0.5431\n",
      "Baseline Loss: 2.7391 | Actual Loss: 0.9568\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.1523\n",
      "Baseline Loss: 2.8113 | Actual Loss: 0.5104\n",
      "Baseline Loss: 2.9070 | Actual Loss: 0.7876\n",
      "Baseline Loss: 2.8304 | Actual Loss: 0.1579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 196/1000 [01:54<08:42,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7735 | Actual Loss: 0.1466\n",
      "Baseline Loss: 2.6467 | Actual Loss: 0.1176\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5489\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.2148\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2394\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4263\n",
      "Epoch 196/1000: Train Loss: 0.4195, Val Loss: 0.6073\n",
      "Baseline Loss: 2.8375 | Actual Loss: 0.2858\n",
      "Baseline Loss: 2.8503 | Actual Loss: 0.3096\n",
      "Baseline Loss: 2.8298 | Actual Loss: 0.5610\n",
      "Baseline Loss: 2.8453 | Actual Loss: 0.4323\n",
      "Baseline Loss: 2.8595 | Actual Loss: 0.4570\n",
      "Baseline Loss: 2.8386 | Actual Loss: 1.6416\n",
      "Baseline Loss: 2.7943 | Actual Loss: 2.4931\n",
      "Baseline Loss: 2.8447 | Actual Loss: 1.0956\n",
      "Baseline Loss: 2.8516 | Actual Loss: 0.2871\n",
      "Baseline Loss: 2.7977 | Actual Loss: 0.3650\n",
      "Baseline Loss: 2.8378 | Actual Loss: 0.2789\n",
      "Baseline Loss: 2.7759 | Actual Loss: 0.3828\n",
      "Baseline Loss: 2.8770 | Actual Loss: 0.2379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 197/1000 [01:55<08:35,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7586 | Actual Loss: 0.4156\n",
      "Baseline Loss: 2.7959 | Actual Loss: 0.3678\n",
      "Baseline Loss: 2.5607 | Actual Loss: 2.1732\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5902\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.9583\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2803\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4799\n",
      "Epoch 197/1000: Train Loss: 0.7365, Val Loss: 0.8272\n",
      "Baseline Loss: 2.7989 | Actual Loss: 1.2684\n",
      "Baseline Loss: 2.8135 | Actual Loss: 0.2558\n",
      "Baseline Loss: 2.9075 | Actual Loss: 1.0324\n",
      "Baseline Loss: 2.8185 | Actual Loss: 0.1696\n",
      "Baseline Loss: 2.8209 | Actual Loss: 0.1570\n",
      "Baseline Loss: 2.8860 | Actual Loss: 0.4395\n",
      "Baseline Loss: 2.7834 | Actual Loss: 0.4383\n",
      "Baseline Loss: 2.8351 | Actual Loss: 0.8839\n",
      "Baseline Loss: 2.7687 | Actual Loss: 0.1799\n",
      "Baseline Loss: 2.8210 | Actual Loss: 0.2879\n",
      "Baseline Loss: 2.8229 | Actual Loss: 0.4457\n",
      "Baseline Loss: 2.8577 | Actual Loss: 0.1764\n",
      "Baseline Loss: 2.7750 | Actual Loss: 0.3958\n",
      "Baseline Loss: 2.8817 | Actual Loss: 0.2873\n",
      "Baseline Loss: 2.8825 | Actual Loss: 1.4564\n",
      "Baseline Loss: 2.6067 | Actual Loss: 0.5603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 198/1000 [01:56<08:27,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8420 | Actual Loss: 0.5773\n",
      "Baseline Loss: 2.7887 | Actual Loss: 2.6085\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2366\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.3776\n",
      "Epoch 198/1000: Train Loss: 0.5272, Val Loss: 0.9500\n",
      "Baseline Loss: 2.7807 | Actual Loss: 0.4745\n",
      "Baseline Loss: 2.7825 | Actual Loss: 0.3729\n",
      "Baseline Loss: 2.8127 | Actual Loss: 0.3680\n",
      "Baseline Loss: 2.7830 | Actual Loss: 0.2285\n",
      "Baseline Loss: 2.7626 | Actual Loss: 0.3710\n",
      "Baseline Loss: 2.8273 | Actual Loss: 0.2480\n",
      "Baseline Loss: 2.8293 | Actual Loss: 0.4057\n",
      "Baseline Loss: 2.8552 | Actual Loss: 0.5699\n",
      "Baseline Loss: 2.7787 | Actual Loss: 0.2706\n",
      "Baseline Loss: 2.7905 | Actual Loss: 0.4774\n",
      "Baseline Loss: 2.8264 | Actual Loss: 1.8333\n",
      "Baseline Loss: 2.8788 | Actual Loss: 0.4987\n",
      "Baseline Loss: 2.8708 | Actual Loss: 0.3523\n",
      "Baseline Loss: 2.8342 | Actual Loss: 0.1500\n",
      "Baseline Loss: 2.8794 | Actual Loss: 0.5059\n",
      "Baseline Loss: 2.5463 | Actual Loss: 2.5387\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.6085\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.8194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 199/1000 [01:56<08:31,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8632 | Actual Loss: 0.2387\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.3936\n",
      "Epoch 199/1000: Train Loss: 0.6041, Val Loss: 0.5150\n",
      "Baseline Loss: 2.7896 | Actual Loss: 1.1168\n",
      "Baseline Loss: 2.7977 | Actual Loss: 0.3261\n",
      "Baseline Loss: 2.8633 | Actual Loss: 0.0801\n",
      "Baseline Loss: 2.8211 | Actual Loss: 0.2691\n",
      "Baseline Loss: 2.7959 | Actual Loss: 0.4186\n",
      "Baseline Loss: 2.7842 | Actual Loss: 0.1165\n",
      "Baseline Loss: 2.8223 | Actual Loss: 0.5397\n",
      "Baseline Loss: 2.8084 | Actual Loss: 0.3936\n",
      "Baseline Loss: 2.8776 | Actual Loss: 0.6007\n",
      "Baseline Loss: 2.8117 | Actual Loss: 0.2977\n",
      "Baseline Loss: 2.8524 | Actual Loss: 0.5095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 200/1000 [01:57<08:28,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8123 | Actual Loss: 0.6017\n",
      "Baseline Loss: 2.8181 | Actual Loss: 0.5213\n",
      "Baseline Loss: 2.9070 | Actual Loss: 0.1828\n",
      "Baseline Loss: 2.8443 | Actual Loss: 0.5085\n",
      "Baseline Loss: 2.5209 | Actual Loss: 0.1494\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5242\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.4846\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.3157\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.3601\n",
      "Epoch 200/1000: Train Loss: 0.4145, Val Loss: 0.6711\n",
      "Baseline Loss: 2.8512 | Actual Loss: 0.6807\n",
      "Baseline Loss: 2.8426 | Actual Loss: 0.2043\n",
      "Baseline Loss: 2.8537 | Actual Loss: 0.5440\n",
      "Baseline Loss: 2.8706 | Actual Loss: 0.1105\n",
      "Baseline Loss: 2.8388 | Actual Loss: 0.2252\n",
      "Baseline Loss: 2.8234 | Actual Loss: 1.0760\n",
      "Baseline Loss: 2.8058 | Actual Loss: 0.3066\n",
      "Baseline Loss: 2.8047 | Actual Loss: 0.4160\n",
      "Baseline Loss: 2.8680 | Actual Loss: 1.3608\n",
      "Baseline Loss: 2.8586 | Actual Loss: 0.6400\n",
      "Baseline Loss: 2.7498 | Actual Loss: 0.3359\n",
      "Baseline Loss: 2.7914 | Actual Loss: 0.1280\n",
      "Baseline Loss: 2.8628 | Actual Loss: 0.2964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 201/1000 [01:57<08:21,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7976 | Actual Loss: 0.9859\n",
      "Baseline Loss: 2.7738 | Actual Loss: 0.5248\n",
      "Baseline Loss: 2.4348 | Actual Loss: 0.0936\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5437\n",
      "Baseline Loss: 2.7887 | Actual Loss: 2.7938\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1385\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4897\n",
      "Epoch 201/1000: Train Loss: 0.4955, Val Loss: 0.9914\n",
      "Baseline Loss: 2.8623 | Actual Loss: 2.2943\n",
      "Baseline Loss: 2.7968 | Actual Loss: 0.2028\n",
      "Baseline Loss: 2.8669 | Actual Loss: 2.2823\n",
      "Baseline Loss: 2.8473 | Actual Loss: 0.4671\n",
      "Baseline Loss: 2.8931 | Actual Loss: 0.2297\n",
      "Baseline Loss: 2.8368 | Actual Loss: 0.5176\n",
      "Baseline Loss: 2.7984 | Actual Loss: 0.3436\n",
      "Baseline Loss: 2.8832 | Actual Loss: 0.2776\n",
      "Baseline Loss: 2.8116 | Actual Loss: 0.5607\n",
      "Baseline Loss: 2.7814 | Actual Loss: 0.3661\n",
      "Baseline Loss: 2.8014 | Actual Loss: 0.2705\n",
      "Baseline Loss: 2.7863 | Actual Loss: 0.8797\n",
      "Baseline Loss: 2.8618 | Actual Loss: 0.1622\n",
      "Baseline Loss: 2.8596 | Actual Loss: 0.4605\n",
      "Baseline Loss: 2.8391 | Actual Loss: 0.3436\n",
      "Baseline Loss: 2.4258 | Actual Loss: 2.0858\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.7071\n",
      "Baseline Loss: 2.7887 | Actual Loss: 0.7516\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 202/1000 [01:58<08:31,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7147 | Actual Loss: 0.3343\n",
      "Epoch 202/1000: Train Loss: 0.7340, Val Loss: 0.4902\n",
      "Baseline Loss: 2.8132 | Actual Loss: 2.7966\n",
      "Baseline Loss: 2.8270 | Actual Loss: 0.1208\n",
      "Baseline Loss: 2.7676 | Actual Loss: 0.5188\n",
      "Baseline Loss: 2.8617 | Actual Loss: 0.8774\n",
      "Baseline Loss: 2.8194 | Actual Loss: 0.6358\n",
      "Baseline Loss: 2.8834 | Actual Loss: 0.5377\n",
      "Baseline Loss: 2.8298 | Actual Loss: 0.3250\n",
      "Baseline Loss: 2.8842 | Actual Loss: 0.3144\n",
      "Baseline Loss: 2.7676 | Actual Loss: 0.1138\n",
      "Baseline Loss: 2.7958 | Actual Loss: 0.3051\n",
      "Baseline Loss: 2.7744 | Actual Loss: 0.3940\n",
      "Baseline Loss: 2.7876 | Actual Loss: 0.4668\n",
      "Baseline Loss: 2.8440 | Actual Loss: 0.2225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 203/1000 [01:59<08:26,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8331 | Actual Loss: 0.5205\n",
      "Baseline Loss: 2.8187 | Actual Loss: 0.5093\n",
      "Baseline Loss: 2.5415 | Actual Loss: 2.6471\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.6491\n",
      "Baseline Loss: 2.7887 | Actual Loss: 2.8584\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.2511\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.3613\n",
      "Epoch 203/1000: Train Loss: 0.7066, Val Loss: 1.0300\n",
      "Baseline Loss: 2.8265 | Actual Loss: 2.6068\n",
      "Baseline Loss: 2.7772 | Actual Loss: 0.2876\n",
      "Baseline Loss: 2.8430 | Actual Loss: 2.7390\n",
      "Baseline Loss: 2.8302 | Actual Loss: 0.6589\n",
      "Baseline Loss: 2.7993 | Actual Loss: 0.6248\n",
      "Baseline Loss: 2.7986 | Actual Loss: 0.2144\n",
      "Baseline Loss: 2.9214 | Actual Loss: 0.2568\n",
      "Baseline Loss: 2.9261 | Actual Loss: 0.2282\n",
      "Baseline Loss: 2.7724 | Actual Loss: 0.4041\n",
      "Baseline Loss: 2.7875 | Actual Loss: 0.1612\n",
      "Baseline Loss: 2.7953 | Actual Loss: 0.7670\n",
      "Baseline Loss: 2.8338 | Actual Loss: 0.6024\n",
      "Baseline Loss: 2.8337 | Actual Loss: 0.4315\n",
      "Baseline Loss: 2.8325 | Actual Loss: 0.4119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 204/1000 [01:59<08:14,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8385 | Actual Loss: 0.2768\n",
      "Baseline Loss: 2.4864 | Actual Loss: 0.2452\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.6271\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.6985\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1115\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4410\n",
      "Epoch 204/1000: Train Loss: 0.6823, Val Loss: 0.7195\n",
      "Baseline Loss: 2.8531 | Actual Loss: 0.6500\n",
      "Baseline Loss: 2.7903 | Actual Loss: 0.5347\n",
      "Baseline Loss: 2.8468 | Actual Loss: 2.6470\n",
      "Baseline Loss: 2.8828 | Actual Loss: 0.5128\n",
      "Baseline Loss: 2.8052 | Actual Loss: 0.2259\n",
      "Baseline Loss: 2.8350 | Actual Loss: 0.3898\n",
      "Baseline Loss: 2.8111 | Actual Loss: 0.3179\n",
      "Baseline Loss: 2.8580 | Actual Loss: 0.2363\n",
      "Baseline Loss: 2.8547 | Actual Loss: 0.2559\n",
      "Baseline Loss: 2.7854 | Actual Loss: 0.5684\n",
      "Baseline Loss: 2.7960 | Actual Loss: 0.6135\n",
      "Baseline Loss: 2.8764 | Actual Loss: 0.2160\n",
      "Baseline Loss: 2.7975 | Actual Loss: 0.4345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 205/1000 [02:00<08:31,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8006 | Actual Loss: 0.5909\n",
      "Baseline Loss: 2.8930 | Actual Loss: 0.6241\n",
      "Baseline Loss: 2.4006 | Actual Loss: 0.0842\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.6316\n",
      "Baseline Loss: 2.7887 | Actual Loss: 2.4635\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1868\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4600\n",
      "Epoch 205/1000: Train Loss: 0.5564, Val Loss: 0.9354\n",
      "Baseline Loss: 2.8900 | Actual Loss: 0.2976\n",
      "Baseline Loss: 2.8237 | Actual Loss: 0.2173\n",
      "Baseline Loss: 2.7964 | Actual Loss: 0.6286\n",
      "Baseline Loss: 2.7751 | Actual Loss: 0.2946\n",
      "Baseline Loss: 2.7987 | Actual Loss: 0.3539\n",
      "Baseline Loss: 2.7913 | Actual Loss: 2.0205\n",
      "Baseline Loss: 2.8338 | Actual Loss: 0.2171\n",
      "Baseline Loss: 2.7410 | Actual Loss: 0.3697\n",
      "Baseline Loss: 2.8174 | Actual Loss: 0.1638\n",
      "Baseline Loss: 2.8997 | Actual Loss: 0.9577\n",
      "Baseline Loss: 2.7625 | Actual Loss: 0.2698\n",
      "Baseline Loss: 2.8459 | Actual Loss: 0.4691\n",
      "Baseline Loss: 2.8830 | Actual Loss: 0.3770\n",
      "Baseline Loss: 2.7952 | Actual Loss: 0.6373\n",
      "Baseline Loss: 2.8504 | Actual Loss: 0.3568\n",
      "Baseline Loss: 2.5538 | Actual Loss: 2.0835\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.6134\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.0858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 206/1000 [02:01<08:39,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8632 | Actual Loss: 0.2599\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.3489\n",
      "Epoch 206/1000: Train Loss: 0.6072, Val Loss: 0.5770\n",
      "Baseline Loss: 2.9076 | Actual Loss: 0.2304\n",
      "Baseline Loss: 2.7634 | Actual Loss: 0.4755\n",
      "Baseline Loss: 2.8409 | Actual Loss: 0.3569\n",
      "Baseline Loss: 2.8057 | Actual Loss: 0.1364\n",
      "Baseline Loss: 2.8145 | Actual Loss: 0.3197\n",
      "Baseline Loss: 2.8835 | Actual Loss: 0.1246\n",
      "Baseline Loss: 2.7924 | Actual Loss: 0.2188\n",
      "Baseline Loss: 2.7526 | Actual Loss: 0.3549\n",
      "Baseline Loss: 2.8531 | Actual Loss: 0.3910\n",
      "Baseline Loss: 2.8712 | Actual Loss: 2.8014\n",
      "Baseline Loss: 2.8078 | Actual Loss: 0.3327\n",
      "Baseline Loss: 2.8704 | Actual Loss: 0.5740\n",
      "Baseline Loss: 2.8218 | Actual Loss: 0.4854\n",
      "Baseline Loss: 2.8874 | Actual Loss: 0.8703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 207/1000 [02:01<08:16,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7971 | Actual Loss: 0.3781\n",
      "Baseline Loss: 2.5943 | Actual Loss: 0.0482\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5337\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.1615\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.3237\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4020\n",
      "Epoch 207/1000: Train Loss: 0.5061, Val Loss: 0.6052\n",
      "Baseline Loss: 2.8160 | Actual Loss: 0.6505\n",
      "Baseline Loss: 2.8069 | Actual Loss: 0.2309\n",
      "Baseline Loss: 2.8145 | Actual Loss: 0.7814\n",
      "Baseline Loss: 2.7944 | Actual Loss: 0.3659\n",
      "Baseline Loss: 2.8975 | Actual Loss: 0.2431\n",
      "Baseline Loss: 2.8427 | Actual Loss: 0.2603\n",
      "Baseline Loss: 2.8479 | Actual Loss: 1.0806\n",
      "Baseline Loss: 2.9045 | Actual Loss: 0.5613\n",
      "Baseline Loss: 2.8012 | Actual Loss: 0.8258\n",
      "Baseline Loss: 2.8434 | Actual Loss: 0.2778\n",
      "Baseline Loss: 2.9055 | Actual Loss: 0.2354\n",
      "Baseline Loss: 2.7792 | Actual Loss: 0.5675\n",
      "Baseline Loss: 2.8415 | Actual Loss: 2.8913\n",
      "Baseline Loss: 2.8060 | Actual Loss: 0.3498\n",
      "Baseline Loss: 2.7407 | Actual Loss: 0.5097\n",
      "Baseline Loss: 2.4822 | Actual Loss: 0.2610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 208/1000 [02:02<08:15,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8420 | Actual Loss: 0.5874\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.4230\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1225\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4640\n",
      "Epoch 208/1000: Train Loss: 0.6308, Val Loss: 0.6492\n",
      "Baseline Loss: 2.8513 | Actual Loss: 0.8126\n",
      "Baseline Loss: 2.7999 | Actual Loss: 0.4405\n",
      "Baseline Loss: 2.7918 | Actual Loss: 1.3710\n",
      "Baseline Loss: 2.8693 | Actual Loss: 1.0113\n",
      "Baseline Loss: 2.8354 | Actual Loss: 0.1915\n",
      "Baseline Loss: 2.7942 | Actual Loss: 0.5553\n",
      "Baseline Loss: 2.8553 | Actual Loss: 0.5249\n",
      "Baseline Loss: 2.8587 | Actual Loss: 0.3833\n",
      "Baseline Loss: 2.7807 | Actual Loss: 0.1465\n",
      "Baseline Loss: 2.8362 | Actual Loss: 0.3081\n",
      "Baseline Loss: 2.8186 | Actual Loss: 0.6576\n",
      "Baseline Loss: 2.8995 | Actual Loss: 0.2087\n",
      "Baseline Loss: 2.8570 | Actual Loss: 0.4227\n",
      "Baseline Loss: 2.8163 | Actual Loss: 0.6283\n",
      "Baseline Loss: 2.8335 | Actual Loss: 0.3766\n",
      "Baseline Loss: 2.4633 | Actual Loss: 0.1116\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5449\n",
      "Baseline Loss: 2.7887 | Actual Loss: 2.4708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 209/1000 [02:03<08:10,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8632 | Actual Loss: 0.2427\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.5012\n",
      "Epoch 209/1000: Train Loss: 0.5094, Val Loss: 0.9399\n",
      "Baseline Loss: 2.8085 | Actual Loss: 0.3881\n",
      "Baseline Loss: 2.9420 | Actual Loss: 3.3909\n",
      "Baseline Loss: 2.7793 | Actual Loss: 0.7041\n",
      "Baseline Loss: 2.7645 | Actual Loss: 0.5851\n",
      "Baseline Loss: 2.8728 | Actual Loss: 0.6208\n",
      "Baseline Loss: 2.8305 | Actual Loss: 0.3006\n",
      "Baseline Loss: 2.8276 | Actual Loss: 2.5433\n",
      "Baseline Loss: 2.8138 | Actual Loss: 0.2465\n",
      "Baseline Loss: 2.8287 | Actual Loss: 0.4586\n",
      "Baseline Loss: 2.8507 | Actual Loss: 0.2519\n",
      "Baseline Loss: 2.7970 | Actual Loss: 0.3750\n",
      "Baseline Loss: 2.7999 | Actual Loss: 0.3005\n",
      "Baseline Loss: 2.7933 | Actual Loss: 0.2267\n",
      "Baseline Loss: 2.8889 | Actual Loss: 0.7599\n",
      "Baseline Loss: 2.9050 | Actual Loss: 0.3220\n",
      "Baseline Loss: 2.5164 | Actual Loss: 0.6426\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5758\n",
      "Baseline Loss: 2.7887 | Actual Loss: 2.0841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 210/1000 [02:03<08:19,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8632 | Actual Loss: 0.1442\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4652\n",
      "Epoch 210/1000: Train Loss: 0.7573, Val Loss: 0.8173\n",
      "Baseline Loss: 2.8639 | Actual Loss: 0.2780\n",
      "Baseline Loss: 2.8352 | Actual Loss: 0.7297\n",
      "Baseline Loss: 2.8260 | Actual Loss: 0.5628\n",
      "Baseline Loss: 2.8148 | Actual Loss: 0.2558\n",
      "Baseline Loss: 2.8372 | Actual Loss: 0.1210\n",
      "Baseline Loss: 2.8758 | Actual Loss: 0.4959\n",
      "Baseline Loss: 2.8519 | Actual Loss: 0.2807\n",
      "Baseline Loss: 2.8650 | Actual Loss: 0.9264\n",
      "Baseline Loss: 2.8462 | Actual Loss: 2.6719\n",
      "Baseline Loss: 2.7444 | Actual Loss: 0.2683\n",
      "Baseline Loss: 2.8404 | Actual Loss: 0.2591\n",
      "Baseline Loss: 2.8645 | Actual Loss: 0.6574\n",
      "Baseline Loss: 2.8417 | Actual Loss: 0.9607\n",
      "Baseline Loss: 2.8028 | Actual Loss: 0.4355\n",
      "Baseline Loss: 2.8456 | Actual Loss: 0.7504\n",
      "Baseline Loss: 2.5132 | Actual Loss: 0.0491\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.6573\n",
      "Baseline Loss: 2.7887 | Actual Loss: 1.0681\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 211/1000 [02:04<08:19,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7147 | Actual Loss: 0.4712\n",
      "Epoch 211/1000: Train Loss: 0.6064, Val Loss: 0.5868\n",
      "Baseline Loss: 2.8466 | Actual Loss: 0.2642\n",
      "Baseline Loss: 2.8194 | Actual Loss: 0.1454\n",
      "Baseline Loss: 2.8561 | Actual Loss: 0.3871\n",
      "Baseline Loss: 2.8469 | Actual Loss: 0.3124\n",
      "Baseline Loss: 2.7701 | Actual Loss: 0.6407\n",
      "Baseline Loss: 2.8095 | Actual Loss: 0.4860\n",
      "Baseline Loss: 2.8370 | Actual Loss: 0.2254\n",
      "Baseline Loss: 2.8132 | Actual Loss: 0.3512\n",
      "Baseline Loss: 2.8040 | Actual Loss: 2.1579\n",
      "Baseline Loss: 2.8570 | Actual Loss: 0.1332\n",
      "Baseline Loss: 2.8948 | Actual Loss: 0.2292\n",
      "Baseline Loss: 2.7390 | Actual Loss: 0.4335\n",
      "Baseline Loss: 2.8225 | Actual Loss: 2.5071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 211/1000 [02:04<07:47,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8647 | Actual Loss: 0.3278\n",
      "Baseline Loss: 2.8156 | Actual Loss: 0.2331\n",
      "Baseline Loss: 2.3829 | Actual Loss: 0.0450\n",
      "Baseline Loss: 2.8420 | Actual Loss: 0.5608\n",
      "Baseline Loss: 2.7887 | Actual Loss: 2.4507\n",
      "Baseline Loss: 2.8632 | Actual Loss: 0.1668\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.4703\n",
      "Epoch 212/1000: Train Loss: 0.5549, Val Loss: 0.9121\n",
      "\n",
      "Early stopping at epoch 212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.35409507900476456"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devices = [\"cuda\" if torch.cuda.is_available() else \"cpu\"]\n",
    "model7 = GNNModelWithNewLoss(\n",
    "        num_node_features=data_list[0].x.shape[1],\n",
    "        num_edge_features=data_list[0].edge_attr.shape[1],\n",
    "        num_global_features=data_list[0].global_features.shape[1],\n",
    "        cov_num= 9,\n",
    "        hidden_dim=512,\n",
    "        dropout_rate=0.1,\n",
    "        property_index= 0,\n",
    "        save_path= 'premodels_new/9/0' \n",
    "    ).to(devices[0])\n",
    "\n",
    "model7.train_model(\n",
    "    data_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc31e0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training will be saved to: premodels_new/9/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6981 | Actual Loss: 2.6462\n",
      "Baseline Loss: 2.6974 | Actual Loss: 2.6556\n",
      "Baseline Loss: 2.6979 | Actual Loss: 2.6458\n",
      "Baseline Loss: 2.6595 | Actual Loss: 2.6295\n",
      "Baseline Loss: 2.6476 | Actual Loss: 2.6228\n",
      "Baseline Loss: 2.6365 | Actual Loss: 2.6250\n",
      "Baseline Loss: 2.6558 | Actual Loss: 2.6243\n",
      "Baseline Loss: 2.6532 | Actual Loss: 2.5882\n",
      "Baseline Loss: 2.6740 | Actual Loss: 2.6476\n",
      "Baseline Loss: 2.6702 | Actual Loss: 2.6267\n",
      "Baseline Loss: 2.6946 | Actual Loss: 2.6673\n",
      "Baseline Loss: 2.6809 | Actual Loss: 2.6127\n",
      "Baseline Loss: 2.7064 | Actual Loss: 2.6721\n",
      "Baseline Loss: 2.6669 | Actual Loss: 2.6130\n",
      "Baseline Loss: 2.6974 | Actual Loss: 2.6483\n",
      "Baseline Loss: 2.2227 | Actual Loss: 2.2097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 1/1000 [00:00<11:50,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7315 | Actual Loss: 2.7084\n",
      "Baseline Loss: 2.6435 | Actual Loss: 2.5623\n",
      "Baseline Loss: 2.7015 | Actual Loss: 2.7073\n",
      "Baseline Loss: 2.5568 | Actual Loss: 2.5291\n",
      "Epoch 1/1000: Train Loss: 2.6084, Val Loss: 2.6268\n",
      "New best validation loss: 2.6268\n",
      "Baseline Loss: 2.6913 | Actual Loss: 2.6641\n",
      "Baseline Loss: 2.6920 | Actual Loss: 2.6093\n",
      "Baseline Loss: 2.6858 | Actual Loss: 2.6277\n",
      "Baseline Loss: 2.6812 | Actual Loss: 2.6523\n",
      "Baseline Loss: 2.6774 | Actual Loss: 2.6061\n",
      "Baseline Loss: 2.6654 | Actual Loss: 2.5985\n",
      "Baseline Loss: 2.6990 | Actual Loss: 2.6479\n",
      "Baseline Loss: 2.6886 | Actual Loss: 2.5221\n",
      "Baseline Loss: 2.6697 | Actual Loss: 2.5958\n",
      "Baseline Loss: 2.6648 | Actual Loss: 2.5510\n",
      "Baseline Loss: 2.6865 | Actual Loss: 2.6286\n",
      "Baseline Loss: 2.7038 | Actual Loss: 2.5585\n",
      "Baseline Loss: 2.6520 | Actual Loss: 2.5103\n",
      "Baseline Loss: 2.7144 | Actual Loss: 2.6452\n",
      "Baseline Loss: 2.6624 | Actual Loss: 2.5205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 2/1000 [00:01<11:34,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2555 | Actual Loss: 2.1290\n",
      "Baseline Loss: 2.7315 | Actual Loss: 2.6787\n",
      "Baseline Loss: 2.6435 | Actual Loss: 2.5146\n",
      "Baseline Loss: 2.7015 | Actual Loss: 2.5735\n",
      "Baseline Loss: 2.5568 | Actual Loss: 2.3747\n",
      "Epoch 2/1000: Train Loss: 2.5667, Val Loss: 2.5354\n",
      "New best validation loss: 2.5354\n",
      "Baseline Loss: 2.7194 | Actual Loss: 2.5785\n",
      "Baseline Loss: 2.6419 | Actual Loss: 2.5157\n",
      "Baseline Loss: 2.6740 | Actual Loss: 2.5050\n",
      "Baseline Loss: 2.6739 | Actual Loss: 2.5219\n",
      "Baseline Loss: 2.6699 | Actual Loss: 2.5028\n",
      "Baseline Loss: 2.6563 | Actual Loss: 2.4201\n",
      "Baseline Loss: 2.6644 | Actual Loss: 2.4024\n",
      "Baseline Loss: 2.6957 | Actual Loss: 2.4760\n",
      "Baseline Loss: 2.6794 | Actual Loss: 2.5106\n",
      "Baseline Loss: 2.6740 | Actual Loss: 2.3654\n",
      "Baseline Loss: 2.7009 | Actual Loss: 2.3692\n",
      "Baseline Loss: 2.6495 | Actual Loss: 2.4211\n",
      "Baseline Loss: 2.6420 | Actual Loss: 2.3713\n",
      "Baseline Loss: 2.6406 | Actual Loss: 2.3715\n",
      "Baseline Loss: 2.6558 | Actual Loss: 2.2590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 3/1000 [00:02<11:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2587 | Actual Loss: 1.8745\n",
      "Baseline Loss: 2.7315 | Actual Loss: 2.3508\n",
      "Baseline Loss: 2.6435 | Actual Loss: 2.2243\n",
      "Baseline Loss: 2.7015 | Actual Loss: 2.2196\n",
      "Baseline Loss: 2.5568 | Actual Loss: 2.1332\n",
      "Epoch 3/1000: Train Loss: 2.4041, Val Loss: 2.2320\n",
      "New best validation loss: 2.2320\n",
      "Baseline Loss: 2.7008 | Actual Loss: 2.3959\n",
      "Baseline Loss: 2.7017 | Actual Loss: 2.2838\n",
      "Baseline Loss: 2.6474 | Actual Loss: 2.1901\n",
      "Baseline Loss: 2.6633 | Actual Loss: 2.2151\n",
      "Baseline Loss: 2.6814 | Actual Loss: 2.0753\n",
      "Baseline Loss: 2.6595 | Actual Loss: 2.0373\n",
      "Baseline Loss: 2.6618 | Actual Loss: 2.0797\n",
      "Baseline Loss: 2.6579 | Actual Loss: 1.9648\n",
      "Baseline Loss: 2.7042 | Actual Loss: 1.9475\n",
      "Baseline Loss: 2.6476 | Actual Loss: 2.0813\n",
      "Baseline Loss: 2.6851 | Actual Loss: 1.8105\n",
      "Baseline Loss: 2.7035 | Actual Loss: 1.9426\n",
      "Baseline Loss: 2.6471 | Actual Loss: 1.9312\n",
      "Baseline Loss: 2.6900 | Actual Loss: 1.9163\n",
      "Baseline Loss: 2.6753 | Actual Loss: 1.6570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 4/1000 [00:02<11:06,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2723 | Actual Loss: 1.4565\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.6464\n",
      "Baseline Loss: 2.6435 | Actual Loss: 1.6409\n",
      "Baseline Loss: 2.7015 | Actual Loss: 1.7896\n",
      "Baseline Loss: 2.5568 | Actual Loss: 1.6120\n",
      "Epoch 4/1000: Train Loss: 1.9990, Val Loss: 1.6722\n",
      "New best validation loss: 1.6722\n",
      "Baseline Loss: 2.6781 | Actual Loss: 1.6889\n",
      "Baseline Loss: 2.6880 | Actual Loss: 1.7780\n",
      "Baseline Loss: 2.6692 | Actual Loss: 1.6804\n",
      "Baseline Loss: 2.6702 | Actual Loss: 1.3777\n",
      "Baseline Loss: 2.6626 | Actual Loss: 1.6623\n",
      "Baseline Loss: 2.6666 | Actual Loss: 1.7010\n",
      "Baseline Loss: 2.6784 | Actual Loss: 1.6346\n",
      "Baseline Loss: 2.6509 | Actual Loss: 1.4915\n",
      "Baseline Loss: 2.6506 | Actual Loss: 1.0814\n",
      "Baseline Loss: 2.6961 | Actual Loss: 1.4004\n",
      "Baseline Loss: 2.6324 | Actual Loss: 1.4435\n",
      "Baseline Loss: 2.6646 | Actual Loss: 1.3600\n",
      "Baseline Loss: 2.6540 | Actual Loss: 1.5568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 5/1000 [00:03<11:12,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6751 | Actual Loss: 1.4977\n",
      "Baseline Loss: 2.7006 | Actual Loss: 1.4470\n",
      "Baseline Loss: 2.2764 | Actual Loss: 1.4785\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.5004\n",
      "Baseline Loss: 2.6435 | Actual Loss: 1.2148\n",
      "Baseline Loss: 2.7015 | Actual Loss: 1.3437\n",
      "Baseline Loss: 2.5568 | Actual Loss: 1.4749\n",
      "Epoch 5/1000: Train Loss: 1.5175, Val Loss: 1.3835\n",
      "New best validation loss: 1.3835\n",
      "Baseline Loss: 2.6956 | Actual Loss: 1.4868\n",
      "Baseline Loss: 2.6476 | Actual Loss: 1.1361\n",
      "Baseline Loss: 2.7174 | Actual Loss: 1.3092\n",
      "Baseline Loss: 2.6745 | Actual Loss: 1.2929\n",
      "Baseline Loss: 2.7021 | Actual Loss: 1.3089\n",
      "Baseline Loss: 2.6676 | Actual Loss: 0.9865\n",
      "Baseline Loss: 2.6324 | Actual Loss: 1.2323\n",
      "Baseline Loss: 2.6249 | Actual Loss: 1.2920\n",
      "Baseline Loss: 2.6968 | Actual Loss: 1.1392\n",
      "Baseline Loss: 2.6759 | Actual Loss: 1.5143\n",
      "Baseline Loss: 2.6724 | Actual Loss: 1.4052\n",
      "Baseline Loss: 2.6624 | Actual Loss: 1.0719\n",
      "Baseline Loss: 2.6749 | Actual Loss: 1.0303\n",
      "Baseline Loss: 2.7146 | Actual Loss: 1.6167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 6/1000 [00:03<10:49,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7230 | Actual Loss: 1.6091\n",
      "Baseline Loss: 2.2942 | Actual Loss: 1.1309\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.4444\n",
      "Baseline Loss: 2.6435 | Actual Loss: 1.2500\n",
      "Baseline Loss: 2.7015 | Actual Loss: 1.4665\n",
      "Baseline Loss: 2.5568 | Actual Loss: 1.3377\n",
      "Epoch 6/1000: Train Loss: 1.2851, Val Loss: 1.3747\n",
      "New best validation loss: 1.3747\n",
      "Baseline Loss: 2.7094 | Actual Loss: 1.3886\n",
      "Baseline Loss: 2.6956 | Actual Loss: 1.3343\n",
      "Baseline Loss: 2.6677 | Actual Loss: 0.9828\n",
      "Baseline Loss: 2.6601 | Actual Loss: 1.3480\n",
      "Baseline Loss: 2.6920 | Actual Loss: 1.1335\n",
      "Baseline Loss: 2.6468 | Actual Loss: 1.2990\n",
      "Baseline Loss: 2.7028 | Actual Loss: 0.9535\n",
      "Baseline Loss: 2.6915 | Actual Loss: 1.3363\n",
      "Baseline Loss: 2.7129 | Actual Loss: 1.7401\n",
      "Baseline Loss: 2.6913 | Actual Loss: 1.3064\n",
      "Baseline Loss: 2.6540 | Actual Loss: 1.5622\n",
      "Baseline Loss: 2.7011 | Actual Loss: 0.9510\n",
      "Baseline Loss: 2.6864 | Actual Loss: 1.1169\n",
      "Baseline Loss: 2.6330 | Actual Loss: 1.1434\n",
      "Baseline Loss: 2.6663 | Actual Loss: 1.1118\n",
      "Baseline Loss: 2.2378 | Actual Loss: 0.9020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 7/1000 [00:04<10:49,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7315 | Actual Loss: 1.2814\n",
      "Baseline Loss: 2.6435 | Actual Loss: 1.2364\n",
      "Baseline Loss: 2.7015 | Actual Loss: 1.1691\n",
      "Baseline Loss: 2.5568 | Actual Loss: 1.1576\n",
      "Epoch 7/1000: Train Loss: 1.2256, Val Loss: 1.2111\n",
      "New best validation loss: 1.2111\n",
      "Baseline Loss: 2.6691 | Actual Loss: 1.2689\n",
      "Baseline Loss: 2.6655 | Actual Loss: 1.4702\n",
      "Baseline Loss: 2.6580 | Actual Loss: 1.1912\n",
      "Baseline Loss: 2.6609 | Actual Loss: 1.5519\n",
      "Baseline Loss: 2.6819 | Actual Loss: 1.2436\n",
      "Baseline Loss: 2.6399 | Actual Loss: 1.3577\n",
      "Baseline Loss: 2.6676 | Actual Loss: 1.1296\n",
      "Baseline Loss: 2.6894 | Actual Loss: 1.1256\n",
      "Baseline Loss: 2.6981 | Actual Loss: 1.6555\n",
      "Baseline Loss: 2.6608 | Actual Loss: 1.1275\n",
      "Baseline Loss: 2.7029 | Actual Loss: 1.0289\n",
      "Baseline Loss: 2.6388 | Actual Loss: 1.1494\n",
      "Baseline Loss: 2.7052 | Actual Loss: 1.2063\n",
      "Baseline Loss: 2.6744 | Actual Loss: 1.0212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 8/1000 [00:05<10:48,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6717 | Actual Loss: 1.0094\n",
      "Baseline Loss: 2.2794 | Actual Loss: 1.0005\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.3275\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.8915\n",
      "Baseline Loss: 2.7015 | Actual Loss: 1.2494\n",
      "Baseline Loss: 2.5568 | Actual Loss: 1.2144\n",
      "Epoch 8/1000: Train Loss: 1.2211, Val Loss: 1.1707\n",
      "New best validation loss: 1.1707\n",
      "Baseline Loss: 2.6580 | Actual Loss: 1.1999\n",
      "Baseline Loss: 2.7019 | Actual Loss: 1.4050\n",
      "Baseline Loss: 2.7008 | Actual Loss: 1.2120\n",
      "Baseline Loss: 2.6569 | Actual Loss: 1.4371\n",
      "Baseline Loss: 2.6615 | Actual Loss: 1.4921\n",
      "Baseline Loss: 2.6855 | Actual Loss: 1.3103\n",
      "Baseline Loss: 2.6786 | Actual Loss: 1.4504\n",
      "Baseline Loss: 2.6487 | Actual Loss: 0.9109\n",
      "Baseline Loss: 2.6731 | Actual Loss: 1.3221\n",
      "Baseline Loss: 2.6481 | Actual Loss: 1.2640\n",
      "Baseline Loss: 2.6582 | Actual Loss: 1.0405\n",
      "Baseline Loss: 2.6668 | Actual Loss: 1.0538\n",
      "Baseline Loss: 2.6935 | Actual Loss: 1.0324\n",
      "Baseline Loss: 2.6932 | Actual Loss: 1.2199\n",
      "Baseline Loss: 2.6562 | Actual Loss: 1.2613\n",
      "Baseline Loss: 2.2289 | Actual Loss: 2.0062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 9/1000 [00:05<10:33,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7315 | Actual Loss: 1.1370\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.8551\n",
      "Baseline Loss: 2.7015 | Actual Loss: 1.2922\n",
      "Baseline Loss: 2.5568 | Actual Loss: 1.2161\n",
      "Epoch 9/1000: Train Loss: 1.2886, Val Loss: 1.1251\n",
      "New best validation loss: 1.1251\n",
      "Baseline Loss: 2.6584 | Actual Loss: 1.2829\n",
      "Baseline Loss: 2.6797 | Actual Loss: 1.1892\n",
      "Baseline Loss: 2.6584 | Actual Loss: 0.8502\n",
      "Baseline Loss: 2.6725 | Actual Loss: 0.9395\n",
      "Baseline Loss: 2.6799 | Actual Loss: 1.1043\n",
      "Baseline Loss: 2.6759 | Actual Loss: 1.2422\n",
      "Baseline Loss: 2.6501 | Actual Loss: 1.0988\n",
      "Baseline Loss: 2.6951 | Actual Loss: 0.9927\n",
      "Baseline Loss: 2.6907 | Actual Loss: 1.2713\n",
      "Baseline Loss: 2.6727 | Actual Loss: 0.9419\n",
      "Baseline Loss: 2.6654 | Actual Loss: 1.1834\n",
      "Baseline Loss: 2.6363 | Actual Loss: 1.1089\n",
      "Baseline Loss: 2.6923 | Actual Loss: 1.3111\n",
      "Baseline Loss: 2.6783 | Actual Loss: 1.6200\n",
      "Baseline Loss: 2.7136 | Actual Loss: 1.2815\n",
      "Baseline Loss: 2.2741 | Actual Loss: 1.1356\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.3293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 10/1000 [00:06<10:31,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6435 | Actual Loss: 0.8381\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.9413\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.7564\n",
      "Epoch 10/1000: Train Loss: 1.1596, Val Loss: 0.9663\n",
      "New best validation loss: 0.9663\n",
      "Baseline Loss: 2.6832 | Actual Loss: 1.0483\n",
      "Baseline Loss: 2.6833 | Actual Loss: 1.0910\n",
      "Baseline Loss: 2.6741 | Actual Loss: 0.9033\n",
      "Baseline Loss: 2.6847 | Actual Loss: 1.2687\n",
      "Baseline Loss: 2.6514 | Actual Loss: 0.9663\n",
      "Baseline Loss: 2.6623 | Actual Loss: 1.0994\n",
      "Baseline Loss: 2.6715 | Actual Loss: 1.1265\n",
      "Baseline Loss: 2.7009 | Actual Loss: 1.1303\n",
      "Baseline Loss: 2.6769 | Actual Loss: 1.1486\n",
      "Baseline Loss: 2.6861 | Actual Loss: 1.1647\n",
      "Baseline Loss: 2.6454 | Actual Loss: 0.8688\n",
      "Baseline Loss: 2.6737 | Actual Loss: 1.5781\n",
      "Baseline Loss: 2.6480 | Actual Loss: 0.9373\n",
      "Baseline Loss: 2.6839 | Actual Loss: 0.7914\n",
      "Baseline Loss: 2.6821 | Actual Loss: 1.0976\n",
      "Baseline Loss: 2.2517 | Actual Loss: 0.6951\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.2097\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.9307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 11/1000 [00:07<10:24,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7015 | Actual Loss: 0.8958\n",
      "Baseline Loss: 2.5568 | Actual Loss: 1.1315\n",
      "Epoch 11/1000: Train Loss: 1.0572, Val Loss: 1.0419\n",
      "Baseline Loss: 2.7164 | Actual Loss: 1.1206\n",
      "Baseline Loss: 2.6802 | Actual Loss: 1.1487\n",
      "Baseline Loss: 2.6555 | Actual Loss: 1.0262\n",
      "Baseline Loss: 2.6728 | Actual Loss: 0.9600\n",
      "Baseline Loss: 2.6507 | Actual Loss: 0.8209\n",
      "Baseline Loss: 2.6789 | Actual Loss: 1.1068\n",
      "Baseline Loss: 2.6528 | Actual Loss: 1.1054\n",
      "Baseline Loss: 2.6780 | Actual Loss: 0.8418\n",
      "Baseline Loss: 2.6372 | Actual Loss: 0.8960\n",
      "Baseline Loss: 2.7066 | Actual Loss: 0.8803\n",
      "Baseline Loss: 2.6585 | Actual Loss: 1.2662\n",
      "Baseline Loss: 2.6712 | Actual Loss: 0.6964\n",
      "Baseline Loss: 2.6715 | Actual Loss: 1.0819\n",
      "Baseline Loss: 2.6618 | Actual Loss: 0.8483\n",
      "Baseline Loss: 2.7064 | Actual Loss: 1.2746\n",
      "Baseline Loss: 2.2687 | Actual Loss: 0.7529\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.4843\n",
      "Baseline Loss: 2.6435 | Actual Loss: 1.0616\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.6450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 12/1000 [00:07<10:39,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5568 | Actual Loss: 0.8971\n",
      "Epoch 12/1000: Train Loss: 0.9892, Val Loss: 1.0220\n",
      "Baseline Loss: 2.7097 | Actual Loss: 1.6393\n",
      "Baseline Loss: 2.6567 | Actual Loss: 1.0871\n",
      "Baseline Loss: 2.6693 | Actual Loss: 0.7683\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.8205\n",
      "Baseline Loss: 2.6695 | Actual Loss: 0.8666\n",
      "Baseline Loss: 2.6953 | Actual Loss: 0.8576\n",
      "Baseline Loss: 2.6492 | Actual Loss: 0.9993\n",
      "Baseline Loss: 2.6733 | Actual Loss: 0.7844\n",
      "Baseline Loss: 2.6526 | Actual Loss: 1.1508\n",
      "Baseline Loss: 2.6493 | Actual Loss: 0.6391\n",
      "Baseline Loss: 2.6672 | Actual Loss: 0.8268\n",
      "Baseline Loss: 2.6562 | Actual Loss: 1.1081\n",
      "Baseline Loss: 2.7282 | Actual Loss: 1.0262\n",
      "Baseline Loss: 2.6948 | Actual Loss: 1.3379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏         | 13/1000 [00:08<10:12,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6462 | Actual Loss: 0.8606\n",
      "Baseline Loss: 2.2975 | Actual Loss: 0.7753\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.2271\n",
      "Baseline Loss: 2.6435 | Actual Loss: 1.0497\n",
      "Baseline Loss: 2.7015 | Actual Loss: 1.1234\n",
      "Baseline Loss: 2.5568 | Actual Loss: 1.3279\n",
      "Epoch 13/1000: Train Loss: 0.9717, Val Loss: 1.1820\n",
      "Baseline Loss: 2.6875 | Actual Loss: 1.4111\n",
      "Baseline Loss: 2.6747 | Actual Loss: 1.0616\n",
      "Baseline Loss: 2.6762 | Actual Loss: 1.2208\n",
      "Baseline Loss: 2.6430 | Actual Loss: 0.7388\n",
      "Baseline Loss: 2.6681 | Actual Loss: 1.0080\n",
      "Baseline Loss: 2.7050 | Actual Loss: 1.2122\n",
      "Baseline Loss: 2.6648 | Actual Loss: 0.8488\n",
      "Baseline Loss: 2.7045 | Actual Loss: 0.9817\n",
      "Baseline Loss: 2.7208 | Actual Loss: 0.8573\n",
      "Baseline Loss: 2.6643 | Actual Loss: 0.7796\n",
      "Baseline Loss: 2.7071 | Actual Loss: 0.7182\n",
      "Baseline Loss: 2.6659 | Actual Loss: 0.7331\n",
      "Baseline Loss: 2.6479 | Actual Loss: 0.7831\n",
      "Baseline Loss: 2.6417 | Actual Loss: 1.0322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏         | 14/1000 [00:09<10:28,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6443 | Actual Loss: 1.0510\n",
      "Baseline Loss: 2.3062 | Actual Loss: 0.4900\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.5926\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.7415\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.5443\n",
      "Baseline Loss: 2.5568 | Actual Loss: 1.0090\n",
      "Epoch 14/1000: Train Loss: 0.9330, Val Loss: 0.9718\n",
      "Baseline Loss: 2.6760 | Actual Loss: 0.8440\n",
      "Baseline Loss: 2.6259 | Actual Loss: 1.0473\n",
      "Baseline Loss: 2.6585 | Actual Loss: 0.7994\n",
      "Baseline Loss: 2.6753 | Actual Loss: 1.3666\n",
      "Baseline Loss: 2.6735 | Actual Loss: 1.2048\n",
      "Baseline Loss: 2.6953 | Actual Loss: 1.0070\n",
      "Baseline Loss: 2.6697 | Actual Loss: 0.7325\n",
      "Baseline Loss: 2.6815 | Actual Loss: 1.0346\n",
      "Baseline Loss: 2.6531 | Actual Loss: 1.2675\n",
      "Baseline Loss: 2.6783 | Actual Loss: 1.0323\n",
      "Baseline Loss: 2.6567 | Actual Loss: 0.8124\n",
      "Baseline Loss: 2.6948 | Actual Loss: 1.0184\n",
      "Baseline Loss: 2.6851 | Actual Loss: 0.8696\n",
      "Baseline Loss: 2.7145 | Actual Loss: 1.2690\n",
      "Baseline Loss: 2.6933 | Actual Loss: 1.0190\n",
      "Baseline Loss: 2.2753 | Actual Loss: 0.3124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 15/1000 [00:09<10:37,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7315 | Actual Loss: 0.8290\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.8714\n",
      "Baseline Loss: 2.7015 | Actual Loss: 1.0731\n",
      "Baseline Loss: 2.5568 | Actual Loss: 1.0027\n",
      "Epoch 15/1000: Train Loss: 0.9773, Val Loss: 0.9440\n",
      "New best validation loss: 0.9440\n",
      "Baseline Loss: 2.6429 | Actual Loss: 1.4503\n",
      "Baseline Loss: 2.6484 | Actual Loss: 0.6842\n",
      "Baseline Loss: 2.6590 | Actual Loss: 1.0953\n",
      "Baseline Loss: 2.6649 | Actual Loss: 1.3843\n",
      "Baseline Loss: 2.6933 | Actual Loss: 0.6314\n",
      "Baseline Loss: 2.7115 | Actual Loss: 1.0819\n",
      "Baseline Loss: 2.6259 | Actual Loss: 0.9284\n",
      "Baseline Loss: 2.7241 | Actual Loss: 0.9723\n",
      "Baseline Loss: 2.7021 | Actual Loss: 1.1837\n",
      "Baseline Loss: 2.6788 | Actual Loss: 1.2625\n",
      "Baseline Loss: 2.6705 | Actual Loss: 1.2888\n",
      "Baseline Loss: 2.6749 | Actual Loss: 1.0420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 16/1000 [00:10<10:08,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6652 | Actual Loss: 1.0369\n",
      "Baseline Loss: 2.6295 | Actual Loss: 0.9308\n",
      "Baseline Loss: 2.6880 | Actual Loss: 0.6700\n",
      "Baseline Loss: 2.3135 | Actual Loss: 0.8189\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.4564\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.5044\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.4275\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.8838\n",
      "Epoch 16/1000: Train Loss: 1.0289, Val Loss: 0.8180\n",
      "New best validation loss: 0.8180\n",
      "Baseline Loss: 2.6934 | Actual Loss: 1.2384\n",
      "Baseline Loss: 2.6725 | Actual Loss: 0.6258\n",
      "Baseline Loss: 2.6568 | Actual Loss: 2.3208\n",
      "Baseline Loss: 2.6823 | Actual Loss: 1.9189\n",
      "Baseline Loss: 2.7159 | Actual Loss: 1.6500\n",
      "Baseline Loss: 2.6631 | Actual Loss: 1.8352\n",
      "Baseline Loss: 2.6527 | Actual Loss: 1.4165\n",
      "Baseline Loss: 2.6857 | Actual Loss: 1.3463\n",
      "Baseline Loss: 2.6625 | Actual Loss: 0.7996\n",
      "Baseline Loss: 2.6536 | Actual Loss: 1.0221\n",
      "Baseline Loss: 2.6557 | Actual Loss: 0.9575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 17/1000 [00:10<10:17,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6668 | Actual Loss: 1.0941\n",
      "Baseline Loss: 2.6679 | Actual Loss: 0.9882\n",
      "Baseline Loss: 2.7222 | Actual Loss: 1.2255\n",
      "Baseline Loss: 2.6659 | Actual Loss: 1.0687\n",
      "Baseline Loss: 2.2882 | Actual Loss: 0.9269\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.0409\n",
      "Baseline Loss: 2.6435 | Actual Loss: 1.0453\n",
      "Baseline Loss: 2.7015 | Actual Loss: 1.1037\n",
      "Baseline Loss: 2.5568 | Actual Loss: 1.2322\n",
      "Epoch 17/1000: Train Loss: 1.2772, Val Loss: 1.1055\n",
      "Baseline Loss: 2.6762 | Actual Loss: 1.0396\n",
      "Baseline Loss: 2.6514 | Actual Loss: 0.8481\n",
      "Baseline Loss: 2.6942 | Actual Loss: 0.8299\n",
      "Baseline Loss: 2.6757 | Actual Loss: 0.9070\n",
      "Baseline Loss: 2.7187 | Actual Loss: 0.9339\n",
      "Baseline Loss: 2.7051 | Actual Loss: 1.0016\n",
      "Baseline Loss: 2.6475 | Actual Loss: 1.1429\n",
      "Baseline Loss: 2.6802 | Actual Loss: 1.0946\n",
      "Baseline Loss: 2.6533 | Actual Loss: 2.4811\n",
      "Baseline Loss: 2.6432 | Actual Loss: 1.0639\n",
      "Baseline Loss: 2.6767 | Actual Loss: 1.0823\n",
      "Baseline Loss: 2.6789 | Actual Loss: 2.2809\n",
      "Baseline Loss: 2.6563 | Actual Loss: 0.8905\n",
      "Baseline Loss: 2.6612 | Actual Loss: 0.8444\n",
      "Baseline Loss: 2.6956 | Actual Loss: 1.2348\n",
      "Baseline Loss: 2.3074 | Actual Loss: 0.3157\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.4064\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.7575\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.5395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 18/1000 [00:11<10:27,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5568 | Actual Loss: 0.9312\n",
      "Epoch 18/1000: Train Loss: 1.1245, Val Loss: 0.9087\n",
      "Baseline Loss: 2.6859 | Actual Loss: 0.6010\n",
      "Baseline Loss: 2.6198 | Actual Loss: 0.7664\n",
      "Baseline Loss: 2.6768 | Actual Loss: 1.5035\n",
      "Baseline Loss: 2.6820 | Actual Loss: 0.6674\n",
      "Baseline Loss: 2.6368 | Actual Loss: 0.6517\n",
      "Baseline Loss: 2.6789 | Actual Loss: 1.7589\n",
      "Baseline Loss: 2.7004 | Actual Loss: 0.7678\n",
      "Baseline Loss: 2.6646 | Actual Loss: 0.9062\n",
      "Baseline Loss: 2.6632 | Actual Loss: 1.2549\n",
      "Baseline Loss: 2.6597 | Actual Loss: 0.6270\n",
      "Baseline Loss: 2.7041 | Actual Loss: 0.8571\n",
      "Baseline Loss: 2.6711 | Actual Loss: 0.8163\n",
      "Baseline Loss: 2.6520 | Actual Loss: 1.0369\n",
      "Baseline Loss: 2.6512 | Actual Loss: 1.1982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 19/1000 [00:12<10:01,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6799 | Actual Loss: 0.6434\n",
      "Baseline Loss: 2.2844 | Actual Loss: 0.3151\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9674\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.8340\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.8870\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.7243\n",
      "Epoch 19/1000: Train Loss: 0.8982, Val Loss: 0.8532\n",
      "Baseline Loss: 2.6188 | Actual Loss: 0.9990\n",
      "Baseline Loss: 2.7174 | Actual Loss: 0.7384\n",
      "Baseline Loss: 2.6465 | Actual Loss: 0.7757\n",
      "Baseline Loss: 2.6870 | Actual Loss: 0.5937\n",
      "Baseline Loss: 2.6445 | Actual Loss: 0.9535\n",
      "Baseline Loss: 2.6380 | Actual Loss: 0.9103\n",
      "Baseline Loss: 2.6909 | Actual Loss: 0.9129\n",
      "Baseline Loss: 2.6720 | Actual Loss: 1.0566\n",
      "Baseline Loss: 2.6585 | Actual Loss: 1.0238\n",
      "Baseline Loss: 2.6827 | Actual Loss: 1.0314\n",
      "Baseline Loss: 2.6811 | Actual Loss: 0.8217\n",
      "Baseline Loss: 2.6673 | Actual Loss: 1.7005\n",
      "Baseline Loss: 2.6695 | Actual Loss: 0.6502\n",
      "Baseline Loss: 2.7018 | Actual Loss: 0.9511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 20/1000 [00:12<10:25,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7064 | Actual Loss: 0.6831\n",
      "Baseline Loss: 2.2981 | Actual Loss: 2.1829\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.0109\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.7166\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.6726\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.7814\n",
      "Epoch 20/1000: Train Loss: 0.9990, Val Loss: 0.7954\n",
      "New best validation loss: 0.7954\n",
      "Baseline Loss: 2.6392 | Actual Loss: 0.5101\n",
      "Baseline Loss: 2.6685 | Actual Loss: 0.9133\n",
      "Baseline Loss: 2.6813 | Actual Loss: 1.1525\n",
      "Baseline Loss: 2.6870 | Actual Loss: 1.2741\n",
      "Baseline Loss: 2.6997 | Actual Loss: 0.7919\n",
      "Baseline Loss: 2.6688 | Actual Loss: 1.5936\n",
      "Baseline Loss: 2.6810 | Actual Loss: 1.3191\n",
      "Baseline Loss: 2.6941 | Actual Loss: 0.7542\n",
      "Baseline Loss: 2.6624 | Actual Loss: 0.9256\n",
      "Baseline Loss: 2.6308 | Actual Loss: 0.7018\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.8719\n",
      "Baseline Loss: 2.6607 | Actual Loss: 0.6408\n",
      "Baseline Loss: 2.6781 | Actual Loss: 1.3478\n",
      "Baseline Loss: 2.6920 | Actual Loss: 1.1414\n",
      "Baseline Loss: 2.7066 | Actual Loss: 1.5904\n",
      "Baseline Loss: 2.2930 | Actual Loss: 0.6687\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.0145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 21/1000 [00:13<09:56,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6435 | Actual Loss: 0.9586\n",
      "Baseline Loss: 2.7015 | Actual Loss: 1.1062\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.9802\n",
      "Epoch 21/1000: Train Loss: 1.0123, Val Loss: 1.0149\n",
      "Baseline Loss: 2.6896 | Actual Loss: 0.9588\n",
      "Baseline Loss: 2.6876 | Actual Loss: 0.9345\n",
      "Baseline Loss: 2.6505 | Actual Loss: 1.2817\n",
      "Baseline Loss: 2.6388 | Actual Loss: 1.0550\n",
      "Baseline Loss: 2.6935 | Actual Loss: 1.1187\n",
      "Baseline Loss: 2.6439 | Actual Loss: 0.9534\n",
      "Baseline Loss: 2.6822 | Actual Loss: 0.7414\n",
      "Baseline Loss: 2.6394 | Actual Loss: 0.7563\n",
      "Baseline Loss: 2.6769 | Actual Loss: 0.9768\n",
      "Baseline Loss: 2.6621 | Actual Loss: 0.8457\n",
      "Baseline Loss: 2.6979 | Actual Loss: 1.4555\n",
      "Baseline Loss: 2.6902 | Actual Loss: 1.1023\n",
      "Baseline Loss: 2.6930 | Actual Loss: 1.1850\n",
      "Baseline Loss: 2.6463 | Actual Loss: 2.2308\n",
      "Baseline Loss: 2.7201 | Actual Loss: 1.4727\n",
      "Baseline Loss: 2.2570 | Actual Loss: 0.4470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 22/1000 [00:14<10:02,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7315 | Actual Loss: 1.3740\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.5854\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.7801\n",
      "Baseline Loss: 2.5568 | Actual Loss: 1.1274\n",
      "Epoch 22/1000: Train Loss: 1.0947, Val Loss: 0.9667\n",
      "Baseline Loss: 2.6617 | Actual Loss: 1.1238\n",
      "Baseline Loss: 2.6597 | Actual Loss: 1.2524\n",
      "Baseline Loss: 2.7070 | Actual Loss: 0.8119\n",
      "Baseline Loss: 2.6790 | Actual Loss: 0.8897\n",
      "Baseline Loss: 2.6604 | Actual Loss: 1.0412\n",
      "Baseline Loss: 2.6467 | Actual Loss: 1.0885\n",
      "Baseline Loss: 2.6624 | Actual Loss: 0.8391\n",
      "Baseline Loss: 2.7001 | Actual Loss: 0.8727\n",
      "Baseline Loss: 2.6827 | Actual Loss: 2.1499\n",
      "Baseline Loss: 2.6627 | Actual Loss: 0.8285\n",
      "Baseline Loss: 2.6659 | Actual Loss: 1.2395\n",
      "Baseline Loss: 2.6521 | Actual Loss: 0.8502\n",
      "Baseline Loss: 2.6791 | Actual Loss: 1.0365\n",
      "Baseline Loss: 2.6856 | Actual Loss: 0.6891\n",
      "Baseline Loss: 2.6834 | Actual Loss: 0.7643\n",
      "Baseline Loss: 2.2918 | Actual Loss: 0.8816\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.2295\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.8381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 23/1000 [00:14<10:23,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7015 | Actual Loss: 0.9812\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.8328\n",
      "Epoch 23/1000: Train Loss: 1.0224, Val Loss: 0.9704\n",
      "Baseline Loss: 2.6799 | Actual Loss: 0.8881\n",
      "Baseline Loss: 2.6980 | Actual Loss: 1.1179\n",
      "Baseline Loss: 2.6774 | Actual Loss: 0.8079\n",
      "Baseline Loss: 2.6848 | Actual Loss: 1.0214\n",
      "Baseline Loss: 2.6677 | Actual Loss: 0.7947\n",
      "Baseline Loss: 2.6393 | Actual Loss: 0.8805\n",
      "Baseline Loss: 2.6445 | Actual Loss: 0.9950\n",
      "Baseline Loss: 2.6742 | Actual Loss: 0.7466\n",
      "Baseline Loss: 2.6463 | Actual Loss: 0.6602\n",
      "Baseline Loss: 2.6531 | Actual Loss: 1.1544\n",
      "Baseline Loss: 2.6669 | Actual Loss: 0.3126\n",
      "Baseline Loss: 2.6843 | Actual Loss: 0.9241\n",
      "Baseline Loss: 2.6859 | Actual Loss: 0.7729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 24/1000 [00:15<09:57,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7120 | Actual Loss: 0.8885\n",
      "Baseline Loss: 2.6998 | Actual Loss: 2.0725\n",
      "Baseline Loss: 2.2704 | Actual Loss: 1.0852\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.3491\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.6153\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.5599\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.9493\n",
      "Epoch 24/1000: Train Loss: 0.9452, Val Loss: 0.8684\n",
      "Baseline Loss: 2.6777 | Actual Loss: 1.1171\n",
      "Baseline Loss: 2.6535 | Actual Loss: 0.6633\n",
      "Baseline Loss: 2.6485 | Actual Loss: 0.7624\n",
      "Baseline Loss: 2.6936 | Actual Loss: 1.8603\n",
      "Baseline Loss: 2.6768 | Actual Loss: 0.7025\n",
      "Baseline Loss: 2.6986 | Actual Loss: 1.5279\n",
      "Baseline Loss: 2.6851 | Actual Loss: 0.8021\n",
      "Baseline Loss: 2.7013 | Actual Loss: 0.3705\n",
      "Baseline Loss: 2.6609 | Actual Loss: 0.6721\n",
      "Baseline Loss: 2.6824 | Actual Loss: 1.4551\n",
      "Baseline Loss: 2.6721 | Actual Loss: 1.0004\n",
      "Baseline Loss: 2.6821 | Actual Loss: 0.6966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▎         | 25/1000 [00:15<10:03,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6468 | Actual Loss: 0.9024\n",
      "Baseline Loss: 2.6329 | Actual Loss: 1.0992\n",
      "Baseline Loss: 2.6675 | Actual Loss: 0.5497\n",
      "Baseline Loss: 2.2144 | Actual Loss: 0.6651\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.5738\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.8260\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.6498\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.8815\n",
      "Epoch 25/1000: Train Loss: 0.9279, Val Loss: 0.9828\n",
      "Baseline Loss: 2.6902 | Actual Loss: 1.2216\n",
      "Baseline Loss: 2.6791 | Actual Loss: 1.8358\n",
      "Baseline Loss: 2.7366 | Actual Loss: 0.7743\n",
      "Baseline Loss: 2.6612 | Actual Loss: 0.9608\n",
      "Baseline Loss: 2.6231 | Actual Loss: 0.8063\n",
      "Baseline Loss: 2.6246 | Actual Loss: 0.9658\n",
      "Baseline Loss: 2.6641 | Actual Loss: 0.7163\n",
      "Baseline Loss: 2.6480 | Actual Loss: 0.8570\n",
      "Baseline Loss: 2.6728 | Actual Loss: 0.7406\n",
      "Baseline Loss: 2.7007 | Actual Loss: 1.2344\n",
      "Baseline Loss: 2.6287 | Actual Loss: 0.7753\n",
      "Baseline Loss: 2.6928 | Actual Loss: 1.1905\n",
      "Baseline Loss: 2.7102 | Actual Loss: 1.7025\n",
      "Baseline Loss: 2.6880 | Actual Loss: 0.6329\n",
      "Baseline Loss: 2.6747 | Actual Loss: 0.5357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 26/1000 [00:16<09:55,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2554 | Actual Loss: 1.4047\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.3114\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.7552\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3173\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.9069\n",
      "Epoch 26/1000: Train Loss: 1.0222, Val Loss: 0.8227\n",
      "Baseline Loss: 2.6871 | Actual Loss: 0.5231\n",
      "Baseline Loss: 2.6952 | Actual Loss: 1.1754\n",
      "Baseline Loss: 2.6932 | Actual Loss: 0.9032\n",
      "Baseline Loss: 2.6725 | Actual Loss: 0.5978\n",
      "Baseline Loss: 2.6534 | Actual Loss: 0.9694\n",
      "Baseline Loss: 2.6641 | Actual Loss: 1.0263\n",
      "Baseline Loss: 2.6642 | Actual Loss: 0.9607\n",
      "Baseline Loss: 2.6577 | Actual Loss: 0.7294\n",
      "Baseline Loss: 2.7135 | Actual Loss: 1.3668\n",
      "Baseline Loss: 2.6343 | Actual Loss: 0.7661\n",
      "Baseline Loss: 2.6576 | Actual Loss: 0.6675\n",
      "Baseline Loss: 2.6538 | Actual Loss: 1.2440\n",
      "Baseline Loss: 2.7039 | Actual Loss: 0.6231\n",
      "Baseline Loss: 2.6689 | Actual Loss: 0.3417\n",
      "Baseline Loss: 2.6779 | Actual Loss: 0.8383\n",
      "Baseline Loss: 2.3508 | Actual Loss: 2.1571\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9988\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.8520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 27/1000 [00:17<10:00,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7015 | Actual Loss: 0.7393\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.9538\n",
      "Epoch 27/1000: Train Loss: 0.9306, Val Loss: 0.8860\n",
      "Baseline Loss: 2.6733 | Actual Loss: 0.9276\n",
      "Baseline Loss: 2.6931 | Actual Loss: 0.8368\n",
      "Baseline Loss: 2.6410 | Actual Loss: 0.6763\n",
      "Baseline Loss: 2.6350 | Actual Loss: 1.0866\n",
      "Baseline Loss: 2.7076 | Actual Loss: 0.9501\n",
      "Baseline Loss: 2.6917 | Actual Loss: 0.9938\n",
      "Baseline Loss: 2.6329 | Actual Loss: 1.0404\n",
      "Baseline Loss: 2.7317 | Actual Loss: 0.7909\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.9957\n",
      "Baseline Loss: 2.6524 | Actual Loss: 0.7804\n",
      "Baseline Loss: 2.6520 | Actual Loss: 0.6679\n",
      "Baseline Loss: 2.6683 | Actual Loss: 1.3137\n",
      "Baseline Loss: 2.7119 | Actual Loss: 1.5531\n",
      "Baseline Loss: 2.6626 | Actual Loss: 2.3291\n",
      "Baseline Loss: 2.7029 | Actual Loss: 0.5762\n",
      "Baseline Loss: 2.2151 | Actual Loss: 1.6750\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.2719\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.7387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 28/1000 [00:17<10:19,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7015 | Actual Loss: 0.6561\n",
      "Baseline Loss: 2.5568 | Actual Loss: 1.0666\n",
      "Epoch 28/1000: Train Loss: 1.0746, Val Loss: 0.9333\n",
      "Baseline Loss: 2.6544 | Actual Loss: 1.8850\n",
      "Baseline Loss: 2.6534 | Actual Loss: 0.8884\n",
      "Baseline Loss: 2.6597 | Actual Loss: 1.1710\n",
      "Baseline Loss: 2.6899 | Actual Loss: 0.9762\n",
      "Baseline Loss: 2.6955 | Actual Loss: 1.0557\n",
      "Baseline Loss: 2.6793 | Actual Loss: 0.8634\n",
      "Baseline Loss: 2.6892 | Actual Loss: 0.8065\n",
      "Baseline Loss: 2.6652 | Actual Loss: 0.9603\n",
      "Baseline Loss: 2.6665 | Actual Loss: 1.3349\n",
      "Baseline Loss: 2.6703 | Actual Loss: 0.9184\n",
      "Baseline Loss: 2.6610 | Actual Loss: 1.1090\n",
      "Baseline Loss: 2.6664 | Actual Loss: 1.0146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 29/1000 [00:18<10:05,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6661 | Actual Loss: 0.9614\n",
      "Baseline Loss: 2.7191 | Actual Loss: 0.7649\n",
      "Baseline Loss: 2.6848 | Actual Loss: 0.6453\n",
      "Baseline Loss: 2.2698 | Actual Loss: 0.4449\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.5612\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.5128\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.6321\n",
      "Baseline Loss: 2.5568 | Actual Loss: 1.0932\n",
      "Epoch 29/1000: Train Loss: 0.9875, Val Loss: 0.9498\n",
      "Baseline Loss: 2.6688 | Actual Loss: 1.5916\n",
      "Baseline Loss: 2.6707 | Actual Loss: 2.2033\n",
      "Baseline Loss: 2.6494 | Actual Loss: 0.8110\n",
      "Baseline Loss: 2.6626 | Actual Loss: 0.9537\n",
      "Baseline Loss: 2.6675 | Actual Loss: 1.1600\n",
      "Baseline Loss: 2.6505 | Actual Loss: 0.8336\n",
      "Baseline Loss: 2.7106 | Actual Loss: 0.7236\n",
      "Baseline Loss: 2.7238 | Actual Loss: 1.4271\n",
      "Baseline Loss: 2.7072 | Actual Loss: 1.6324\n",
      "Baseline Loss: 2.7204 | Actual Loss: 0.6078\n",
      "Baseline Loss: 2.6579 | Actual Loss: 0.7347\n",
      "Baseline Loss: 2.6517 | Actual Loss: 0.8254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 30/1000 [00:19<10:14,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6445 | Actual Loss: 0.8460\n",
      "Baseline Loss: 2.6578 | Actual Loss: 0.8581\n",
      "Baseline Loss: 2.6872 | Actual Loss: 0.8228\n",
      "Baseline Loss: 2.2471 | Actual Loss: 0.4492\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.2812\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.7575\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.6588\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.9061\n",
      "Epoch 30/1000: Train Loss: 1.0300, Val Loss: 0.9009\n",
      "Baseline Loss: 2.6691 | Actual Loss: 0.8920\n",
      "Baseline Loss: 2.6958 | Actual Loss: 0.7025\n",
      "Baseline Loss: 2.6797 | Actual Loss: 1.5614\n",
      "Baseline Loss: 2.6796 | Actual Loss: 0.7555\n",
      "Baseline Loss: 2.6741 | Actual Loss: 1.0363\n",
      "Baseline Loss: 2.6614 | Actual Loss: 0.6448\n",
      "Baseline Loss: 2.6647 | Actual Loss: 1.1053\n",
      "Baseline Loss: 2.6511 | Actual Loss: 0.5315\n",
      "Baseline Loss: 2.6632 | Actual Loss: 0.7884\n",
      "Baseline Loss: 2.6746 | Actual Loss: 1.4139\n",
      "Baseline Loss: 2.6657 | Actual Loss: 0.7109\n",
      "Baseline Loss: 2.6783 | Actual Loss: 0.5527\n",
      "Baseline Loss: 2.6708 | Actual Loss: 0.8764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 31/1000 [00:19<10:05,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6322 | Actual Loss: 0.6136\n",
      "Baseline Loss: 2.7357 | Actual Loss: 0.8822\n",
      "Baseline Loss: 2.2492 | Actual Loss: 0.6729\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9552\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.8298\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.6998\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.7662\n",
      "Epoch 31/1000: Train Loss: 0.8588, Val Loss: 0.8127\n",
      "Baseline Loss: 2.6673 | Actual Loss: 1.0796\n",
      "Baseline Loss: 2.7076 | Actual Loss: 0.6086\n",
      "Baseline Loss: 2.6756 | Actual Loss: 1.0952\n",
      "Baseline Loss: 2.7152 | Actual Loss: 0.8016\n",
      "Baseline Loss: 2.6374 | Actual Loss: 0.4941\n",
      "Baseline Loss: 2.6629 | Actual Loss: 0.8095\n",
      "Baseline Loss: 2.6771 | Actual Loss: 1.1674\n",
      "Baseline Loss: 2.6646 | Actual Loss: 0.7833\n",
      "Baseline Loss: 2.6618 | Actual Loss: 0.8106\n",
      "Baseline Loss: 2.6995 | Actual Loss: 0.9291\n",
      "Baseline Loss: 2.6723 | Actual Loss: 0.7296\n",
      "Baseline Loss: 2.6448 | Actual Loss: 0.7641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 32/1000 [00:20<10:15,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6926 | Actual Loss: 0.9615\n",
      "Baseline Loss: 2.6437 | Actual Loss: 1.2011\n",
      "Baseline Loss: 2.6983 | Actual Loss: 1.1201\n",
      "Baseline Loss: 2.2153 | Actual Loss: 0.6481\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.0700\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.8156\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.8220\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.7966\n",
      "Epoch 32/1000: Train Loss: 0.8752, Val Loss: 0.8760\n",
      "Baseline Loss: 2.6504 | Actual Loss: 0.6498\n",
      "Baseline Loss: 2.6586 | Actual Loss: 0.9556\n",
      "Baseline Loss: 2.6614 | Actual Loss: 0.6304\n",
      "Baseline Loss: 2.6905 | Actual Loss: 0.9853\n",
      "Baseline Loss: 2.6632 | Actual Loss: 1.2770\n",
      "Baseline Loss: 2.6705 | Actual Loss: 0.7814\n",
      "Baseline Loss: 2.6469 | Actual Loss: 1.4269\n",
      "Baseline Loss: 2.6988 | Actual Loss: 0.8481\n",
      "Baseline Loss: 2.6830 | Actual Loss: 0.9955\n",
      "Baseline Loss: 2.6795 | Actual Loss: 0.6889\n",
      "Baseline Loss: 2.6818 | Actual Loss: 0.3826\n",
      "Baseline Loss: 2.6956 | Actual Loss: 1.0207\n",
      "Baseline Loss: 2.6634 | Actual Loss: 0.8906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 33/1000 [00:21<10:29,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6871 | Actual Loss: 0.8991\n",
      "Baseline Loss: 2.6678 | Actual Loss: 0.9433\n",
      "Baseline Loss: 2.2462 | Actual Loss: 0.5943\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.1648\n",
      "Baseline Loss: 2.6435 | Actual Loss: 1.0030\n",
      "Baseline Loss: 2.7015 | Actual Loss: 1.1303\n",
      "Baseline Loss: 2.5568 | Actual Loss: 1.0481\n",
      "Epoch 33/1000: Train Loss: 0.8731, Val Loss: 1.0866\n",
      "Baseline Loss: 2.6782 | Actual Loss: 0.9686\n",
      "Baseline Loss: 2.6736 | Actual Loss: 1.2224\n",
      "Baseline Loss: 2.6884 | Actual Loss: 0.8887\n",
      "Baseline Loss: 2.6941 | Actual Loss: 0.7256\n",
      "Baseline Loss: 2.6601 | Actual Loss: 0.8519\n",
      "Baseline Loss: 2.7111 | Actual Loss: 1.0382\n",
      "Baseline Loss: 2.6458 | Actual Loss: 0.9209\n",
      "Baseline Loss: 2.6485 | Actual Loss: 0.8018\n",
      "Baseline Loss: 2.6685 | Actual Loss: 0.5579\n",
      "Baseline Loss: 2.6756 | Actual Loss: 0.9245\n",
      "Baseline Loss: 2.6697 | Actual Loss: 1.2650\n",
      "Baseline Loss: 2.6736 | Actual Loss: 2.0531\n",
      "Baseline Loss: 2.6526 | Actual Loss: 2.4782\n",
      "Baseline Loss: 2.6562 | Actual Loss: 0.8681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 34/1000 [00:21<10:17,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6878 | Actual Loss: 0.8120\n",
      "Baseline Loss: 2.2535 | Actual Loss: 0.3637\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.1974\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.5325\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.6925\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.8553\n",
      "Epoch 34/1000: Train Loss: 1.0463, Val Loss: 0.8194\n",
      "Baseline Loss: 2.6200 | Actual Loss: 1.1169\n",
      "Baseline Loss: 2.6388 | Actual Loss: 1.0098\n",
      "Baseline Loss: 2.6895 | Actual Loss: 0.7710\n",
      "Baseline Loss: 2.6641 | Actual Loss: 1.0756\n",
      "Baseline Loss: 2.6565 | Actual Loss: 0.4120\n",
      "Baseline Loss: 2.7144 | Actual Loss: 0.7614\n",
      "Baseline Loss: 2.6728 | Actual Loss: 0.6407\n",
      "Baseline Loss: 2.6832 | Actual Loss: 0.8103\n",
      "Baseline Loss: 2.6444 | Actual Loss: 0.8268\n",
      "Baseline Loss: 2.6741 | Actual Loss: 0.9547\n",
      "Baseline Loss: 2.7083 | Actual Loss: 1.0383\n",
      "Baseline Loss: 2.7548 | Actual Loss: 0.6489\n",
      "Baseline Loss: 2.6664 | Actual Loss: 0.6946\n",
      "Baseline Loss: 2.6691 | Actual Loss: 0.7862\n",
      "Baseline Loss: 2.6865 | Actual Loss: 0.7510\n",
      "Baseline Loss: 2.2652 | Actual Loss: 1.6598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 35/1000 [00:22<10:18,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7315 | Actual Loss: 1.1344\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.6573\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.4365\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.7826\n",
      "Epoch 35/1000: Train Loss: 0.8724, Val Loss: 0.7527\n",
      "New best validation loss: 0.7527\n",
      "Baseline Loss: 2.6579 | Actual Loss: 0.7283\n",
      "Baseline Loss: 2.7193 | Actual Loss: 0.7328\n",
      "Baseline Loss: 2.6705 | Actual Loss: 0.5926\n",
      "Baseline Loss: 2.7006 | Actual Loss: 0.8064\n",
      "Baseline Loss: 2.6843 | Actual Loss: 1.0613\n",
      "Baseline Loss: 2.6683 | Actual Loss: 1.2160\n",
      "Baseline Loss: 2.6815 | Actual Loss: 0.7796\n",
      "Baseline Loss: 2.6988 | Actual Loss: 0.8094\n",
      "Baseline Loss: 2.6653 | Actual Loss: 0.2558\n",
      "Baseline Loss: 2.6760 | Actual Loss: 0.6527\n",
      "Baseline Loss: 2.6425 | Actual Loss: 0.7792\n",
      "Baseline Loss: 2.6608 | Actual Loss: 0.6515\n",
      "Baseline Loss: 2.6827 | Actual Loss: 0.8172\n",
      "Baseline Loss: 2.6756 | Actual Loss: 0.7622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 36/1000 [00:22<10:18,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6719 | Actual Loss: 1.0410\n",
      "Baseline Loss: 2.3646 | Actual Loss: 0.3758\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9911\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.8514\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.8321\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.8372\n",
      "Epoch 36/1000: Train Loss: 0.7539, Val Loss: 0.8780\n",
      "Baseline Loss: 2.6649 | Actual Loss: 0.4122\n",
      "Baseline Loss: 2.6626 | Actual Loss: 0.8817\n",
      "Baseline Loss: 2.6733 | Actual Loss: 0.8130\n",
      "Baseline Loss: 2.6652 | Actual Loss: 0.8026\n",
      "Baseline Loss: 2.6657 | Actual Loss: 0.7925\n",
      "Baseline Loss: 2.6487 | Actual Loss: 0.4984\n",
      "Baseline Loss: 2.6747 | Actual Loss: 0.7334\n",
      "Baseline Loss: 2.6625 | Actual Loss: 1.4972\n",
      "Baseline Loss: 2.6631 | Actual Loss: 0.9639\n",
      "Baseline Loss: 2.6608 | Actual Loss: 0.7456\n",
      "Baseline Loss: 2.6560 | Actual Loss: 0.7429\n",
      "Baseline Loss: 2.6935 | Actual Loss: 0.8138\n",
      "Baseline Loss: 2.7138 | Actual Loss: 0.6116\n",
      "Baseline Loss: 2.7009 | Actual Loss: 0.7008\n",
      "Baseline Loss: 2.6799 | Actual Loss: 1.0623\n",
      "Baseline Loss: 2.2924 | Actual Loss: 0.8881\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.0215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 37/1000 [00:23<10:08,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6435 | Actual Loss: 0.7278\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.6610\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.8183\n",
      "Epoch 37/1000: Train Loss: 0.8100, Val Loss: 0.8072\n",
      "Baseline Loss: 2.7156 | Actual Loss: 0.9422\n",
      "Baseline Loss: 2.6924 | Actual Loss: 0.4684\n",
      "Baseline Loss: 2.6552 | Actual Loss: 0.8178\n",
      "Baseline Loss: 2.7181 | Actual Loss: 1.1138\n",
      "Baseline Loss: 2.6533 | Actual Loss: 0.4271\n",
      "Baseline Loss: 2.6655 | Actual Loss: 0.7347\n",
      "Baseline Loss: 2.6614 | Actual Loss: 0.4627\n",
      "Baseline Loss: 2.6611 | Actual Loss: 1.4762\n",
      "Baseline Loss: 2.6413 | Actual Loss: 0.5080\n",
      "Baseline Loss: 2.6836 | Actual Loss: 1.0560\n",
      "Baseline Loss: 2.6905 | Actual Loss: 0.8563\n",
      "Baseline Loss: 2.6369 | Actual Loss: 0.7336\n",
      "Baseline Loss: 2.6557 | Actual Loss: 0.3323\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.5466\n",
      "Baseline Loss: 2.6775 | Actual Loss: 0.5832\n",
      "Baseline Loss: 2.2269 | Actual Loss: 0.7345\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.7918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 38/1000 [00:24<10:13,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6435 | Actual Loss: 0.7763\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.5872\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.7529\n",
      "Epoch 38/1000: Train Loss: 0.7371, Val Loss: 0.7271\n",
      "New best validation loss: 0.7271\n",
      "Baseline Loss: 2.6404 | Actual Loss: 0.6506\n",
      "Baseline Loss: 2.7013 | Actual Loss: 0.8603\n",
      "Baseline Loss: 2.6805 | Actual Loss: 0.6317\n",
      "Baseline Loss: 2.6827 | Actual Loss: 0.6487\n",
      "Baseline Loss: 2.6579 | Actual Loss: 1.6200\n",
      "Baseline Loss: 2.6880 | Actual Loss: 0.8402\n",
      "Baseline Loss: 2.6702 | Actual Loss: 0.9477\n",
      "Baseline Loss: 2.6559 | Actual Loss: 0.6901\n",
      "Baseline Loss: 2.7097 | Actual Loss: 0.4968\n",
      "Baseline Loss: 2.6676 | Actual Loss: 0.9050\n",
      "Baseline Loss: 2.6808 | Actual Loss: 0.6504\n",
      "Baseline Loss: 2.6383 | Actual Loss: 1.9509\n",
      "Baseline Loss: 2.6367 | Actual Loss: 1.3718\n",
      "Baseline Loss: 2.6494 | Actual Loss: 0.6443\n",
      "Baseline Loss: 2.6719 | Actual Loss: 0.4525\n",
      "Baseline Loss: 2.2844 | Actual Loss: 0.4953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 39/1000 [00:24<10:16,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7315 | Actual Loss: 1.1774\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.5014\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.4798\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.8985\n",
      "Epoch 39/1000: Train Loss: 0.8660, Val Loss: 0.7643\n",
      "Baseline Loss: 2.6779 | Actual Loss: 0.8914\n",
      "Baseline Loss: 2.6858 | Actual Loss: 0.8621\n",
      "Baseline Loss: 2.7066 | Actual Loss: 2.1897\n",
      "Baseline Loss: 2.6797 | Actual Loss: 1.3887\n",
      "Baseline Loss: 2.6541 | Actual Loss: 1.4399\n",
      "Baseline Loss: 2.6637 | Actual Loss: 0.4570\n",
      "Baseline Loss: 2.6324 | Actual Loss: 0.9480\n",
      "Baseline Loss: 2.6769 | Actual Loss: 0.6852\n",
      "Baseline Loss: 2.6501 | Actual Loss: 1.3962\n",
      "Baseline Loss: 2.6767 | Actual Loss: 1.0837\n",
      "Baseline Loss: 2.6717 | Actual Loss: 1.0361\n",
      "Baseline Loss: 2.6930 | Actual Loss: 1.3312\n",
      "Baseline Loss: 2.7003 | Actual Loss: 1.1280\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5712\n",
      "Baseline Loss: 2.6777 | Actual Loss: 0.6629\n",
      "Baseline Loss: 2.2295 | Actual Loss: 0.3296\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.1720\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.7574\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.5811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 40/1000 [00:25<10:23,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5568 | Actual Loss: 0.8767\n",
      "Epoch 40/1000: Train Loss: 1.0251, Val Loss: 0.8468\n",
      "Baseline Loss: 2.6769 | Actual Loss: 0.6458\n",
      "Baseline Loss: 2.6897 | Actual Loss: 0.6467\n",
      "Baseline Loss: 2.6572 | Actual Loss: 0.5688\n",
      "Baseline Loss: 2.6701 | Actual Loss: 0.8887\n",
      "Baseline Loss: 2.6362 | Actual Loss: 0.9557\n",
      "Baseline Loss: 2.6799 | Actual Loss: 0.4301\n",
      "Baseline Loss: 2.6757 | Actual Loss: 0.9284\n",
      "Baseline Loss: 2.6709 | Actual Loss: 0.5740\n",
      "Baseline Loss: 2.6815 | Actual Loss: 2.2182\n",
      "Baseline Loss: 2.6454 | Actual Loss: 2.8510\n",
      "Baseline Loss: 2.6545 | Actual Loss: 0.5972\n",
      "Baseline Loss: 2.6730 | Actual Loss: 0.9544\n",
      "Baseline Loss: 2.7281 | Actual Loss: 2.1629\n",
      "Baseline Loss: 2.6900 | Actual Loss: 1.2803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 41/1000 [00:26<09:55,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6743 | Actual Loss: 1.0639\n",
      "Baseline Loss: 2.2762 | Actual Loss: 2.1062\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.1329\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4431\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.2456\n",
      "Baseline Loss: 2.5568 | Actual Loss: 1.2338\n",
      "Epoch 41/1000: Train Loss: 1.1795, Val Loss: 0.7638\n",
      "Baseline Loss: 2.6511 | Actual Loss: 0.6720\n",
      "Baseline Loss: 2.7155 | Actual Loss: 0.9702\n",
      "Baseline Loss: 2.6680 | Actual Loss: 0.7176\n",
      "Baseline Loss: 2.7284 | Actual Loss: 0.8524\n",
      "Baseline Loss: 2.6954 | Actual Loss: 0.7184\n",
      "Baseline Loss: 2.6381 | Actual Loss: 0.9341\n",
      "Baseline Loss: 2.6398 | Actual Loss: 1.5626\n",
      "Baseline Loss: 2.6736 | Actual Loss: 0.5840\n",
      "Baseline Loss: 2.6481 | Actual Loss: 0.8144\n",
      "Baseline Loss: 2.6776 | Actual Loss: 0.7933\n",
      "Baseline Loss: 2.6666 | Actual Loss: 0.7218\n",
      "Baseline Loss: 2.6714 | Actual Loss: 0.6870\n",
      "Baseline Loss: 2.6793 | Actual Loss: 0.6481\n",
      "Baseline Loss: 2.6763 | Actual Loss: 0.9380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 42/1000 [00:26<10:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6962 | Actual Loss: 0.8461\n",
      "Baseline Loss: 2.2806 | Actual Loss: 0.4906\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9140\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.8866\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.9558\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.9511\n",
      "Epoch 42/1000: Train Loss: 0.8094, Val Loss: 0.9269\n",
      "Baseline Loss: 2.6587 | Actual Loss: 0.6965\n",
      "Baseline Loss: 2.7069 | Actual Loss: 0.8735\n",
      "Baseline Loss: 2.6845 | Actual Loss: 0.5257\n",
      "Baseline Loss: 2.7240 | Actual Loss: 0.7580\n",
      "Baseline Loss: 2.6636 | Actual Loss: 0.6156\n",
      "Baseline Loss: 2.6638 | Actual Loss: 2.1498\n",
      "Baseline Loss: 2.6810 | Actual Loss: 1.7969\n",
      "Baseline Loss: 2.6430 | Actual Loss: 0.5867\n",
      "Baseline Loss: 2.6402 | Actual Loss: 0.4650\n",
      "Baseline Loss: 2.6425 | Actual Loss: 0.7894\n",
      "Baseline Loss: 2.6969 | Actual Loss: 1.2685\n",
      "Baseline Loss: 2.6804 | Actual Loss: 0.7847\n",
      "Baseline Loss: 2.6806 | Actual Loss: 1.1145\n",
      "Baseline Loss: 2.6889 | Actual Loss: 0.4362\n",
      "Baseline Loss: 2.6671 | Actual Loss: 0.5797\n",
      "Baseline Loss: 2.2425 | Actual Loss: 0.5424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 43/1000 [00:27<10:05,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7315 | Actual Loss: 1.2061\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.6122\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.8183\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.7080\n",
      "Epoch 43/1000: Train Loss: 0.8739, Val Loss: 0.8362\n",
      "Baseline Loss: 2.6559 | Actual Loss: 0.6923\n",
      "Baseline Loss: 2.6756 | Actual Loss: 0.9145\n",
      "Baseline Loss: 2.7272 | Actual Loss: 2.3147\n",
      "Baseline Loss: 2.6334 | Actual Loss: 1.1287\n",
      "Baseline Loss: 2.6301 | Actual Loss: 1.3114\n",
      "Baseline Loss: 2.6743 | Actual Loss: 0.5029\n",
      "Baseline Loss: 2.6830 | Actual Loss: 0.7223\n",
      "Baseline Loss: 2.7222 | Actual Loss: 0.5195\n",
      "Baseline Loss: 2.6481 | Actual Loss: 1.0322\n",
      "Baseline Loss: 2.6774 | Actual Loss: 1.0558\n",
      "Baseline Loss: 2.6815 | Actual Loss: 1.4631\n",
      "Baseline Loss: 2.6916 | Actual Loss: 0.7562\n",
      "Baseline Loss: 2.6431 | Actual Loss: 0.8214\n",
      "Baseline Loss: 2.6803 | Actual Loss: 0.7323\n",
      "Baseline Loss: 2.6802 | Actual Loss: 0.8624\n",
      "Baseline Loss: 2.2689 | Actual Loss: 0.3706\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9744\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.7469\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.7798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 44/1000 [00:27<09:45,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5568 | Actual Loss: 0.8028\n",
      "Epoch 44/1000: Train Loss: 0.9500, Val Loss: 0.8260\n",
      "Baseline Loss: 2.7147 | Actual Loss: 0.6557\n",
      "Baseline Loss: 2.6517 | Actual Loss: 0.9574\n",
      "Baseline Loss: 2.7196 | Actual Loss: 0.9796\n",
      "Baseline Loss: 2.6433 | Actual Loss: 0.6127\n",
      "Baseline Loss: 2.6499 | Actual Loss: 0.7247\n",
      "Baseline Loss: 2.6553 | Actual Loss: 0.5644\n",
      "Baseline Loss: 2.6328 | Actual Loss: 0.7264\n",
      "Baseline Loss: 2.6675 | Actual Loss: 0.9630\n",
      "Baseline Loss: 2.6701 | Actual Loss: 0.6582\n",
      "Baseline Loss: 2.6460 | Actual Loss: 1.0838\n",
      "Baseline Loss: 2.7044 | Actual Loss: 0.6290\n",
      "Baseline Loss: 2.6656 | Actual Loss: 0.6488\n",
      "Baseline Loss: 2.6730 | Actual Loss: 0.8237\n",
      "Baseline Loss: 2.7032 | Actual Loss: 0.9574\n",
      "Baseline Loss: 2.6653 | Actual Loss: 1.8202\n",
      "Baseline Loss: 2.2386 | Actual Loss: 0.3648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 45/1000 [00:28<10:06,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7315 | Actual Loss: 1.1024\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3959\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.5769\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.8056\n",
      "Epoch 45/1000: Train Loss: 0.8231, Val Loss: 0.7202\n",
      "New best validation loss: 0.7202\n",
      "Baseline Loss: 2.6676 | Actual Loss: 1.8111\n",
      "Baseline Loss: 2.6526 | Actual Loss: 0.5002\n",
      "Baseline Loss: 2.6741 | Actual Loss: 0.8298\n",
      "Baseline Loss: 2.6867 | Actual Loss: 0.7668\n",
      "Baseline Loss: 2.6599 | Actual Loss: 0.6251\n",
      "Baseline Loss: 2.6961 | Actual Loss: 1.0714\n",
      "Baseline Loss: 2.6404 | Actual Loss: 0.6459\n",
      "Baseline Loss: 2.6641 | Actual Loss: 2.0185\n",
      "Baseline Loss: 2.7009 | Actual Loss: 0.5785\n",
      "Baseline Loss: 2.6639 | Actual Loss: 1.0342\n",
      "Baseline Loss: 2.6918 | Actual Loss: 0.9669\n",
      "Baseline Loss: 2.6692 | Actual Loss: 0.6614\n",
      "Baseline Loss: 2.6588 | Actual Loss: 0.6372\n",
      "Baseline Loss: 2.6708 | Actual Loss: 1.0779\n",
      "Baseline Loss: 2.6844 | Actual Loss: 0.9670\n",
      "Baseline Loss: 2.2492 | Actual Loss: 0.6700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 46/1000 [00:29<10:06,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7315 | Actual Loss: 0.8430\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.8367\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.7373\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.8748\n",
      "Epoch 46/1000: Train Loss: 0.9289, Val Loss: 0.8230\n",
      "Baseline Loss: 2.6683 | Actual Loss: 0.3700\n",
      "Baseline Loss: 2.6492 | Actual Loss: 0.5551\n",
      "Baseline Loss: 2.6780 | Actual Loss: 0.8934\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.8118\n",
      "Baseline Loss: 2.6499 | Actual Loss: 1.1575\n",
      "Baseline Loss: 2.7128 | Actual Loss: 0.8061\n",
      "Baseline Loss: 2.6551 | Actual Loss: 0.6409\n",
      "Baseline Loss: 2.6697 | Actual Loss: 0.5728\n",
      "Baseline Loss: 2.6751 | Actual Loss: 0.7988\n",
      "Baseline Loss: 2.6669 | Actual Loss: 0.9072\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.7175\n",
      "Baseline Loss: 2.6823 | Actual Loss: 1.0309\n",
      "Baseline Loss: 2.6704 | Actual Loss: 0.4371\n",
      "Baseline Loss: 2.6448 | Actual Loss: 0.6487\n",
      "Baseline Loss: 2.6932 | Actual Loss: 2.1844\n",
      "Baseline Loss: 2.3169 | Actual Loss: 0.2896\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9750\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3925\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.2536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 47/1000 [00:29<09:51,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5568 | Actual Loss: 0.7058\n",
      "Epoch 47/1000: Train Loss: 0.8014, Val Loss: 0.5817\n",
      "New best validation loss: 0.5817\n",
      "Baseline Loss: 2.6576 | Actual Loss: 2.6516\n",
      "Baseline Loss: 2.6496 | Actual Loss: 0.4458\n",
      "Baseline Loss: 2.6441 | Actual Loss: 0.9567\n",
      "Baseline Loss: 2.6880 | Actual Loss: 0.4577\n",
      "Baseline Loss: 2.6806 | Actual Loss: 0.7412\n",
      "Baseline Loss: 2.6548 | Actual Loss: 0.4291\n",
      "Baseline Loss: 2.6732 | Actual Loss: 1.6769\n",
      "Baseline Loss: 2.6846 | Actual Loss: 0.6633\n",
      "Baseline Loss: 2.6844 | Actual Loss: 0.6588\n",
      "Baseline Loss: 2.6600 | Actual Loss: 0.4316\n",
      "Baseline Loss: 2.6849 | Actual Loss: 0.8540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 48/1000 [00:30<09:53,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6533 | Actual Loss: 0.6801\n",
      "Baseline Loss: 2.6485 | Actual Loss: 0.7146\n",
      "Baseline Loss: 2.6763 | Actual Loss: 1.0179\n",
      "Baseline Loss: 2.6845 | Actual Loss: 0.6655\n",
      "Baseline Loss: 2.2404 | Actual Loss: 0.6701\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.8629\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.6151\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.6271\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.7490\n",
      "Epoch 48/1000: Train Loss: 0.8572, Val Loss: 0.7135\n",
      "Baseline Loss: 2.6692 | Actual Loss: 0.8489\n",
      "Baseline Loss: 2.6909 | Actual Loss: 0.6052\n",
      "Baseline Loss: 2.7070 | Actual Loss: 0.9007\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.6015\n",
      "Baseline Loss: 2.6864 | Actual Loss: 0.6899\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.3769\n",
      "Baseline Loss: 2.7024 | Actual Loss: 1.6373\n",
      "Baseline Loss: 2.6416 | Actual Loss: 0.7355\n",
      "Baseline Loss: 2.6526 | Actual Loss: 0.6031\n",
      "Baseline Loss: 2.6654 | Actual Loss: 0.9782\n",
      "Baseline Loss: 2.6727 | Actual Loss: 0.6354\n",
      "Baseline Loss: 2.6669 | Actual Loss: 0.6883\n",
      "Baseline Loss: 2.6869 | Actual Loss: 0.8986\n",
      "Baseline Loss: 2.7088 | Actual Loss: 0.9277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 49/1000 [00:31<09:42,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6398 | Actual Loss: 0.9127\n",
      "Baseline Loss: 2.2345 | Actual Loss: 0.5887\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.8078\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.7386\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.5196\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.6839\n",
      "Epoch 49/1000: Train Loss: 0.7893, Val Loss: 0.6875\n",
      "Baseline Loss: 2.6637 | Actual Loss: 0.4727\n",
      "Baseline Loss: 2.6482 | Actual Loss: 0.8746\n",
      "Baseline Loss: 2.6637 | Actual Loss: 0.7395\n",
      "Baseline Loss: 2.7107 | Actual Loss: 0.4124\n",
      "Baseline Loss: 2.6402 | Actual Loss: 0.7942\n",
      "Baseline Loss: 2.6921 | Actual Loss: 0.6732\n",
      "Baseline Loss: 2.6761 | Actual Loss: 0.6195\n",
      "Baseline Loss: 2.6575 | Actual Loss: 0.4248\n",
      "Baseline Loss: 2.6702 | Actual Loss: 1.9616\n",
      "Baseline Loss: 2.6539 | Actual Loss: 0.7654\n",
      "Baseline Loss: 2.6854 | Actual Loss: 1.1480\n",
      "Baseline Loss: 2.7150 | Actual Loss: 0.9869\n",
      "Baseline Loss: 2.6429 | Actual Loss: 0.5139\n",
      "Baseline Loss: 2.6772 | Actual Loss: 0.8451\n",
      "Baseline Loss: 2.6864 | Actual Loss: 0.5901\n",
      "Baseline Loss: 2.3053 | Actual Loss: 0.6302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 50/1000 [00:31<09:52,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7315 | Actual Loss: 1.0835\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.7104\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.6839\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.7212\n",
      "Epoch 50/1000: Train Loss: 0.7783, Val Loss: 0.7997\n",
      "Baseline Loss: 2.6499 | Actual Loss: 0.8426\n",
      "Baseline Loss: 2.6445 | Actual Loss: 0.9852\n",
      "Baseline Loss: 2.6406 | Actual Loss: 0.8088\n",
      "Baseline Loss: 2.7041 | Actual Loss: 0.6597\n",
      "Baseline Loss: 2.7078 | Actual Loss: 0.4949\n",
      "Baseline Loss: 2.6727 | Actual Loss: 0.5999\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.8398\n",
      "Baseline Loss: 2.6660 | Actual Loss: 0.6992\n",
      "Baseline Loss: 2.6523 | Actual Loss: 0.7997\n",
      "Baseline Loss: 2.6631 | Actual Loss: 0.8375\n",
      "Baseline Loss: 2.6967 | Actual Loss: 0.6383\n",
      "Baseline Loss: 2.6791 | Actual Loss: 0.9501\n",
      "Baseline Loss: 2.6506 | Actual Loss: 0.5670\n",
      "Baseline Loss: 2.6591 | Actual Loss: 0.9990\n",
      "Baseline Loss: 2.7286 | Actual Loss: 0.4128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 51/1000 [00:32<09:59,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2354 | Actual Loss: 0.4087\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.8391\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.5387\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.5792\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.7341\n",
      "Epoch 51/1000: Train Loss: 0.7215, Val Loss: 0.6728\n",
      "Baseline Loss: 2.6780 | Actual Loss: 0.6429\n",
      "Baseline Loss: 2.6625 | Actual Loss: 0.8522\n",
      "Baseline Loss: 2.7045 | Actual Loss: 0.7533\n",
      "Baseline Loss: 2.6692 | Actual Loss: 0.4842\n",
      "Baseline Loss: 2.6582 | Actual Loss: 0.5095\n",
      "Baseline Loss: 2.6669 | Actual Loss: 0.5936\n",
      "Baseline Loss: 2.6443 | Actual Loss: 1.3176\n",
      "Baseline Loss: 2.6872 | Actual Loss: 0.5407\n",
      "Baseline Loss: 2.6923 | Actual Loss: 1.3051\n",
      "Baseline Loss: 2.7022 | Actual Loss: 0.5753\n",
      "Baseline Loss: 2.6298 | Actual Loss: 0.6468\n",
      "Baseline Loss: 2.6815 | Actual Loss: 0.5979\n",
      "Baseline Loss: 2.6200 | Actual Loss: 0.8390\n",
      "Baseline Loss: 2.6715 | Actual Loss: 0.9422\n",
      "Baseline Loss: 2.6558 | Actual Loss: 0.7094\n",
      "Baseline Loss: 2.3050 | Actual Loss: 0.3435\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.8200\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.7867\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.6514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 52/1000 [00:32<09:38,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5568 | Actual Loss: 1.0641\n",
      "Epoch 52/1000: Train Loss: 0.7283, Val Loss: 0.8305\n",
      "Baseline Loss: 2.6427 | Actual Loss: 0.8446\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.3418\n",
      "Baseline Loss: 2.6682 | Actual Loss: 0.7567\n",
      "Baseline Loss: 2.6789 | Actual Loss: 0.4985\n",
      "Baseline Loss: 2.6709 | Actual Loss: 0.1976\n",
      "Baseline Loss: 2.6944 | Actual Loss: 0.5881\n",
      "Baseline Loss: 2.6458 | Actual Loss: 0.8568\n",
      "Baseline Loss: 2.6521 | Actual Loss: 0.7153\n",
      "Baseline Loss: 2.6557 | Actual Loss: 1.1978\n",
      "Baseline Loss: 2.7016 | Actual Loss: 0.4584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 53/1000 [00:33<09:37,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6787 | Actual Loss: 0.5787\n",
      "Baseline Loss: 2.7367 | Actual Loss: 0.8887\n",
      "Baseline Loss: 2.6691 | Actual Loss: 0.8170\n",
      "Baseline Loss: 2.6668 | Actual Loss: 1.4638\n",
      "Baseline Loss: 2.6884 | Actual Loss: 0.9732\n",
      "Baseline Loss: 2.2815 | Actual Loss: 0.2721\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.3659\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4129\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.5862\n",
      "Baseline Loss: 2.5568 | Actual Loss: 1.1305\n",
      "Epoch 53/1000: Train Loss: 0.7156, Val Loss: 0.8739\n",
      "Baseline Loss: 2.6524 | Actual Loss: 0.6620\n",
      "Baseline Loss: 2.6778 | Actual Loss: 0.9766\n",
      "Baseline Loss: 2.6662 | Actual Loss: 0.9172\n",
      "Baseline Loss: 2.7253 | Actual Loss: 0.9280\n",
      "Baseline Loss: 2.6469 | Actual Loss: 1.1500\n",
      "Baseline Loss: 2.6736 | Actual Loss: 0.8555\n",
      "Baseline Loss: 2.6548 | Actual Loss: 1.0426\n",
      "Baseline Loss: 2.6686 | Actual Loss: 0.6825\n",
      "Baseline Loss: 2.6931 | Actual Loss: 0.9291\n",
      "Baseline Loss: 2.6909 | Actual Loss: 0.8473\n",
      "Baseline Loss: 2.6699 | Actual Loss: 1.0233\n",
      "Baseline Loss: 2.7114 | Actual Loss: 0.5020\n",
      "Baseline Loss: 2.6563 | Actual Loss: 0.7356\n",
      "Baseline Loss: 2.6248 | Actual Loss: 0.5750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 54/1000 [00:34<09:34,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6926 | Actual Loss: 1.0798\n",
      "Baseline Loss: 2.1957 | Actual Loss: 1.8920\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.3264\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3986\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.4552\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.8339\n",
      "Epoch 54/1000: Train Loss: 0.9249, Val Loss: 0.7535\n",
      "Baseline Loss: 2.6796 | Actual Loss: 0.6827\n",
      "Baseline Loss: 2.6515 | Actual Loss: 0.5721\n",
      "Baseline Loss: 2.6745 | Actual Loss: 2.4185\n",
      "Baseline Loss: 2.6892 | Actual Loss: 0.8135\n",
      "Baseline Loss: 2.6700 | Actual Loss: 1.7064\n",
      "Baseline Loss: 2.6790 | Actual Loss: 0.5022\n",
      "Baseline Loss: 2.7263 | Actual Loss: 1.1309\n",
      "Baseline Loss: 2.6553 | Actual Loss: 0.6476\n",
      "Baseline Loss: 2.6746 | Actual Loss: 0.7489\n",
      "Baseline Loss: 2.6966 | Actual Loss: 1.0866\n",
      "Baseline Loss: 2.6432 | Actual Loss: 0.8104\n",
      "Baseline Loss: 2.6778 | Actual Loss: 0.7061\n",
      "Baseline Loss: 2.6719 | Actual Loss: 0.6560\n",
      "Baseline Loss: 2.6885 | Actual Loss: 0.8294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 55/1000 [00:34<09:41,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6264 | Actual Loss: 0.6619\n",
      "Baseline Loss: 2.2395 | Actual Loss: 0.5864\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.0395\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.6273\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.4379\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.6547\n",
      "Epoch 55/1000: Train Loss: 0.9100, Val Loss: 0.6898\n",
      "Baseline Loss: 2.6460 | Actual Loss: 0.3300\n",
      "Baseline Loss: 2.6344 | Actual Loss: 0.4306\n",
      "Baseline Loss: 2.6761 | Actual Loss: 1.7354\n",
      "Baseline Loss: 2.6671 | Actual Loss: 0.7842\n",
      "Baseline Loss: 2.6600 | Actual Loss: 0.6522\n",
      "Baseline Loss: 2.6657 | Actual Loss: 0.4681\n",
      "Baseline Loss: 2.7044 | Actual Loss: 0.5184\n",
      "Baseline Loss: 2.6658 | Actual Loss: 0.9240\n",
      "Baseline Loss: 2.7278 | Actual Loss: 0.7061\n",
      "Baseline Loss: 2.6815 | Actual Loss: 1.3973\n",
      "Baseline Loss: 2.6681 | Actual Loss: 0.5491\n",
      "Baseline Loss: 2.6659 | Actual Loss: 0.5499\n",
      "Baseline Loss: 2.7013 | Actual Loss: 0.2762\n",
      "Baseline Loss: 2.7065 | Actual Loss: 1.2417\n",
      "Baseline Loss: 2.6564 | Actual Loss: 0.4037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 56/1000 [00:35<09:57,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2301 | Actual Loss: 2.0980\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.1095\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4954\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3385\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.7150\n",
      "Epoch 56/1000: Train Loss: 0.8166, Val Loss: 0.6646\n",
      "Baseline Loss: 2.6909 | Actual Loss: 0.6667\n",
      "Baseline Loss: 2.6590 | Actual Loss: 0.3181\n",
      "Baseline Loss: 2.6243 | Actual Loss: 0.8202\n",
      "Baseline Loss: 2.6685 | Actual Loss: 0.4955\n",
      "Baseline Loss: 2.6698 | Actual Loss: 0.8355\n",
      "Baseline Loss: 2.6749 | Actual Loss: 0.8185\n",
      "Baseline Loss: 2.6681 | Actual Loss: 0.8235\n",
      "Baseline Loss: 2.6708 | Actual Loss: 0.6983\n",
      "Baseline Loss: 2.6568 | Actual Loss: 0.2075\n",
      "Baseline Loss: 2.6872 | Actual Loss: 0.9636\n",
      "Baseline Loss: 2.6913 | Actual Loss: 0.9959\n",
      "Baseline Loss: 2.6685 | Actual Loss: 0.9046\n",
      "Baseline Loss: 2.7058 | Actual Loss: 0.8140\n",
      "Baseline Loss: 2.6326 | Actual Loss: 0.8908\n",
      "Baseline Loss: 2.7618 | Actual Loss: 0.7400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 57/1000 [00:35<09:37,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.3750 | Actual Loss: 0.4413\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.0657\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.9842\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.9508\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.9829\n",
      "Epoch 57/1000: Train Loss: 0.7146, Val Loss: 0.9959\n",
      "Baseline Loss: 2.6987 | Actual Loss: 1.1651\n",
      "Baseline Loss: 2.6539 | Actual Loss: 0.8304\n",
      "Baseline Loss: 2.6700 | Actual Loss: 1.0518\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.5657\n",
      "Baseline Loss: 2.6695 | Actual Loss: 0.7993\n",
      "Baseline Loss: 2.7369 | Actual Loss: 0.6799\n",
      "Baseline Loss: 2.6566 | Actual Loss: 0.4384\n",
      "Baseline Loss: 2.7113 | Actual Loss: 0.7680\n",
      "Baseline Loss: 2.6343 | Actual Loss: 1.3775\n",
      "Baseline Loss: 2.6445 | Actual Loss: 0.8334\n",
      "Baseline Loss: 2.6563 | Actual Loss: 0.9395\n",
      "Baseline Loss: 2.6761 | Actual Loss: 0.5137\n",
      "Baseline Loss: 2.6591 | Actual Loss: 0.7076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 58/1000 [00:36<09:40,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6946 | Actual Loss: 0.4182\n",
      "Baseline Loss: 2.6974 | Actual Loss: 0.8008\n",
      "Baseline Loss: 2.3231 | Actual Loss: 1.8240\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.0835\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3813\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3550\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.7757\n",
      "Epoch 58/1000: Train Loss: 0.8571, Val Loss: 0.6489\n",
      "Baseline Loss: 2.6813 | Actual Loss: 0.4893\n",
      "Baseline Loss: 2.6706 | Actual Loss: 1.2227\n",
      "Baseline Loss: 2.6961 | Actual Loss: 0.5316\n",
      "Baseline Loss: 2.6567 | Actual Loss: 1.1293\n",
      "Baseline Loss: 2.6794 | Actual Loss: 0.4333\n",
      "Baseline Loss: 2.6980 | Actual Loss: 0.7355\n",
      "Baseline Loss: 2.7037 | Actual Loss: 0.7463\n",
      "Baseline Loss: 2.6517 | Actual Loss: 0.9316\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.7767\n",
      "Baseline Loss: 2.6838 | Actual Loss: 0.1915\n",
      "Baseline Loss: 2.6352 | Actual Loss: 0.9286\n",
      "Baseline Loss: 2.6579 | Actual Loss: 0.9422\n",
      "Baseline Loss: 2.6697 | Actual Loss: 0.8753\n",
      "Baseline Loss: 2.6956 | Actual Loss: 0.6607\n",
      "Baseline Loss: 2.6931 | Actual Loss: 3.3940\n",
      "Baseline Loss: 2.2288 | Actual Loss: 0.8450\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.8525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 59/1000 [00:37<09:31,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6435 | Actual Loss: 0.8574\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.7228\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.8115\n",
      "Epoch 59/1000: Train Loss: 0.9271, Val Loss: 0.8110\n",
      "Baseline Loss: 2.6751 | Actual Loss: 0.8152\n",
      "Baseline Loss: 2.6775 | Actual Loss: 0.4755\n",
      "Baseline Loss: 2.6612 | Actual Loss: 0.8738\n",
      "Baseline Loss: 2.6721 | Actual Loss: 1.0786\n",
      "Baseline Loss: 2.6461 | Actual Loss: 1.0022\n",
      "Baseline Loss: 2.6606 | Actual Loss: 0.3975\n",
      "Baseline Loss: 2.6934 | Actual Loss: 1.1185\n",
      "Baseline Loss: 2.6756 | Actual Loss: 0.8456\n",
      "Baseline Loss: 2.6669 | Actual Loss: 2.4931\n",
      "Baseline Loss: 2.6695 | Actual Loss: 0.2214\n",
      "Baseline Loss: 2.6630 | Actual Loss: 0.8008\n",
      "Baseline Loss: 2.6593 | Actual Loss: 0.6301\n",
      "Baseline Loss: 2.6742 | Actual Loss: 0.8896\n",
      "Baseline Loss: 2.6576 | Actual Loss: 1.3271\n",
      "Baseline Loss: 2.7125 | Actual Loss: 0.5550\n",
      "Baseline Loss: 2.2065 | Actual Loss: 0.4784\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.7861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 60/1000 [00:37<09:44,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6435 | Actual Loss: 0.6107\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.5496\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.8316\n",
      "Epoch 60/1000: Train Loss: 0.8751, Val Loss: 0.6945\n",
      "Baseline Loss: 2.6915 | Actual Loss: 0.8931\n",
      "Baseline Loss: 2.6808 | Actual Loss: 0.3971\n",
      "Baseline Loss: 2.6797 | Actual Loss: 0.7155\n",
      "Baseline Loss: 2.6667 | Actual Loss: 0.5833\n",
      "Baseline Loss: 2.6807 | Actual Loss: 0.4788\n",
      "Baseline Loss: 2.6572 | Actual Loss: 0.5975\n",
      "Baseline Loss: 2.6987 | Actual Loss: 0.3733\n",
      "Baseline Loss: 2.6786 | Actual Loss: 1.1201\n",
      "Baseline Loss: 2.6796 | Actual Loss: 0.5682\n",
      "Baseline Loss: 2.6906 | Actual Loss: 1.2018\n",
      "Baseline Loss: 2.6536 | Actual Loss: 0.6847\n",
      "Baseline Loss: 2.7056 | Actual Loss: 0.6517\n",
      "Baseline Loss: 2.6443 | Actual Loss: 0.4026\n",
      "Baseline Loss: 2.6522 | Actual Loss: 0.4873\n",
      "Baseline Loss: 2.6812 | Actual Loss: 1.5169\n",
      "Baseline Loss: 2.2603 | Actual Loss: 0.3607\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.7706\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.6385\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 61/1000 [00:38<09:39,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5568 | Actual Loss: 0.6101\n",
      "Epoch 61/1000: Train Loss: 0.6895, Val Loss: 0.6038\n",
      "Baseline Loss: 2.6997 | Actual Loss: 1.2225\n",
      "Baseline Loss: 2.6510 | Actual Loss: 0.6110\n",
      "Baseline Loss: 2.7083 | Actual Loss: 1.0296\n",
      "Baseline Loss: 2.6412 | Actual Loss: 0.6911\n",
      "Baseline Loss: 2.6730 | Actual Loss: 0.3478\n",
      "Baseline Loss: 2.6430 | Actual Loss: 0.6112\n",
      "Baseline Loss: 2.6681 | Actual Loss: 0.6962\n",
      "Baseline Loss: 2.6393 | Actual Loss: 0.9521\n",
      "Baseline Loss: 2.6942 | Actual Loss: 0.4726\n",
      "Baseline Loss: 2.6431 | Actual Loss: 0.6793\n",
      "Baseline Loss: 2.6931 | Actual Loss: 0.4931\n",
      "Baseline Loss: 2.6750 | Actual Loss: 0.4182\n",
      "Baseline Loss: 2.6586 | Actual Loss: 0.5124\n",
      "Baseline Loss: 2.6887 | Actual Loss: 0.9327\n",
      "Baseline Loss: 2.7150 | Actual Loss: 1.0630\n",
      "Baseline Loss: 2.2900 | Actual Loss: 2.3760\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.0495\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.5861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 62/1000 [00:39<09:51,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7015 | Actual Loss: 0.4947\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.7973\n",
      "Epoch 62/1000: Train Loss: 0.8193, Val Loss: 0.7319\n",
      "Baseline Loss: 2.6535 | Actual Loss: 0.4893\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.7333\n",
      "Baseline Loss: 2.7016 | Actual Loss: 2.1020\n",
      "Baseline Loss: 2.6378 | Actual Loss: 0.6551\n",
      "Baseline Loss: 2.7070 | Actual Loss: 2.5798\n",
      "Baseline Loss: 2.6605 | Actual Loss: 1.1181\n",
      "Baseline Loss: 2.7047 | Actual Loss: 0.9166\n",
      "Baseline Loss: 2.6923 | Actual Loss: 0.6350\n",
      "Baseline Loss: 2.6672 | Actual Loss: 0.8167\n",
      "Baseline Loss: 2.6315 | Actual Loss: 0.5429\n",
      "Baseline Loss: 2.7045 | Actual Loss: 1.1907\n",
      "Baseline Loss: 2.6539 | Actual Loss: 0.7439\n",
      "Baseline Loss: 2.6630 | Actual Loss: 1.2130\n",
      "Baseline Loss: 2.6520 | Actual Loss: 0.6837\n",
      "Baseline Loss: 2.7052 | Actual Loss: 0.5318\n",
      "Baseline Loss: 2.2836 | Actual Loss: 0.4955\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.8435\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.7036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 63/1000 [00:39<09:53,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7015 | Actual Loss: 0.6281\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.7226\n",
      "Epoch 63/1000: Train Loss: 0.9655, Val Loss: 0.7245\n",
      "Baseline Loss: 2.6641 | Actual Loss: 0.5223\n",
      "Baseline Loss: 2.6909 | Actual Loss: 1.0210\n",
      "Baseline Loss: 2.6674 | Actual Loss: 1.0595\n",
      "Baseline Loss: 2.6631 | Actual Loss: 0.4596\n",
      "Baseline Loss: 2.6347 | Actual Loss: 0.4912\n",
      "Baseline Loss: 2.6513 | Actual Loss: 0.4446\n",
      "Baseline Loss: 2.6618 | Actual Loss: 0.8463\n",
      "Baseline Loss: 2.6618 | Actual Loss: 2.4669\n",
      "Baseline Loss: 2.7223 | Actual Loss: 1.3469\n",
      "Baseline Loss: 2.6859 | Actual Loss: 0.8424\n",
      "Baseline Loss: 2.6664 | Actual Loss: 0.9947\n",
      "Baseline Loss: 2.6975 | Actual Loss: 0.9363\n",
      "Baseline Loss: 2.7032 | Actual Loss: 0.8753\n",
      "Baseline Loss: 2.6708 | Actual Loss: 0.7154\n",
      "Baseline Loss: 2.6888 | Actual Loss: 0.9274\n",
      "Baseline Loss: 2.2105 | Actual Loss: 0.4295\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.8643\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.6808\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.7011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 64/1000 [00:40<09:46,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5568 | Actual Loss: 0.8267\n",
      "Epoch 64/1000: Train Loss: 0.8987, Val Loss: 0.7682\n",
      "Baseline Loss: 2.6650 | Actual Loss: 0.5551\n",
      "Baseline Loss: 2.6598 | Actual Loss: 0.8032\n",
      "Baseline Loss: 2.6822 | Actual Loss: 0.3147\n",
      "Baseline Loss: 2.7048 | Actual Loss: 0.6272\n",
      "Baseline Loss: 2.6723 | Actual Loss: 2.4282\n",
      "Baseline Loss: 2.6484 | Actual Loss: 0.5179\n",
      "Baseline Loss: 2.6590 | Actual Loss: 0.7961\n",
      "Baseline Loss: 2.6917 | Actual Loss: 2.5416\n",
      "Baseline Loss: 2.6952 | Actual Loss: 2.6625\n",
      "Baseline Loss: 2.7188 | Actual Loss: 2.6600\n",
      "Baseline Loss: 2.6653 | Actual Loss: 2.6458\n",
      "Baseline Loss: 2.6951 | Actual Loss: 2.5382\n",
      "Baseline Loss: 2.6697 | Actual Loss: 2.7626\n",
      "Baseline Loss: 2.6597 | Actual Loss: 2.7567\n",
      "Baseline Loss: 2.6872 | Actual Loss: 2.5913\n",
      "Baseline Loss: 2.2408 | Actual Loss: 1.9876\n",
      "Baseline Loss: 2.7315 | Actual Loss: 2.4342\n",
      "Baseline Loss: 2.6435 | Actual Loss: 2.5986\n",
      "Baseline Loss: 2.7015 | Actual Loss: 2.6554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 65/1000 [00:41<09:54,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5568 | Actual Loss: 2.4631\n",
      "Epoch 65/1000: Train Loss: 1.8243, Val Loss: 2.5379\n",
      "Baseline Loss: 2.7188 | Actual Loss: 2.7990\n",
      "Baseline Loss: 2.7516 | Actual Loss: 2.4792\n",
      "Baseline Loss: 2.6440 | Actual Loss: 2.6870\n",
      "Baseline Loss: 2.6868 | Actual Loss: 2.6378\n",
      "Baseline Loss: 2.6651 | Actual Loss: 1.5698\n",
      "Baseline Loss: 2.6890 | Actual Loss: 2.4615\n",
      "Baseline Loss: 2.6904 | Actual Loss: 2.5164\n",
      "Baseline Loss: 2.6768 | Actual Loss: 2.4354\n",
      "Baseline Loss: 2.6279 | Actual Loss: 1.7660\n",
      "Baseline Loss: 2.6793 | Actual Loss: 2.1340\n",
      "Baseline Loss: 2.6519 | Actual Loss: 1.5948\n",
      "Baseline Loss: 2.6707 | Actual Loss: 0.5994\n",
      "Baseline Loss: 2.6454 | Actual Loss: 0.9699\n",
      "Baseline Loss: 2.6610 | Actual Loss: 0.6222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 66/1000 [00:41<09:36,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6526 | Actual Loss: 0.6078\n",
      "Baseline Loss: 2.2699 | Actual Loss: 0.4764\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9314\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.7368\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.7663\n",
      "Baseline Loss: 2.5568 | Actual Loss: 1.1206\n",
      "Epoch 66/1000: Train Loss: 1.7723, Val Loss: 0.8888\n",
      "Baseline Loss: 2.6742 | Actual Loss: 0.4682\n",
      "Baseline Loss: 2.6769 | Actual Loss: 0.8601\n",
      "Baseline Loss: 2.6622 | Actual Loss: 0.9045\n",
      "Baseline Loss: 2.6526 | Actual Loss: 0.3726\n",
      "Baseline Loss: 2.6711 | Actual Loss: 0.8174\n",
      "Baseline Loss: 2.6889 | Actual Loss: 0.3211\n",
      "Baseline Loss: 2.7095 | Actual Loss: 0.8782\n",
      "Baseline Loss: 2.6678 | Actual Loss: 0.7674\n",
      "Baseline Loss: 2.6601 | Actual Loss: 0.7009\n",
      "Baseline Loss: 2.7076 | Actual Loss: 0.5287\n",
      "Baseline Loss: 2.6848 | Actual Loss: 0.5156\n",
      "Baseline Loss: 2.6740 | Actual Loss: 2.6582\n",
      "Baseline Loss: 2.6528 | Actual Loss: 2.1261\n",
      "Baseline Loss: 2.7032 | Actual Loss: 1.8925\n",
      "Baseline Loss: 2.6514 | Actual Loss: 1.1222\n",
      "Baseline Loss: 2.3511 | Actual Loss: 0.2218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 67/1000 [00:42<09:40,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7315 | Actual Loss: 1.8608\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4431\n",
      "Baseline Loss: 2.7015 | Actual Loss: 1.3779\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.8902\n",
      "Epoch 67/1000: Train Loss: 0.9472, Val Loss: 1.1430\n",
      "Baseline Loss: 2.6863 | Actual Loss: 0.8814\n",
      "Baseline Loss: 2.6734 | Actual Loss: 0.7812\n",
      "Baseline Loss: 2.6505 | Actual Loss: 0.5883\n",
      "Baseline Loss: 2.6622 | Actual Loss: 1.2468\n",
      "Baseline Loss: 2.6679 | Actual Loss: 2.2672\n",
      "Baseline Loss: 2.6885 | Actual Loss: 0.5421\n",
      "Baseline Loss: 2.6563 | Actual Loss: 0.5610\n",
      "Baseline Loss: 2.6426 | Actual Loss: 1.2653\n",
      "Baseline Loss: 2.6368 | Actual Loss: 0.9460\n",
      "Baseline Loss: 2.6710 | Actual Loss: 0.5896\n",
      "Baseline Loss: 2.6808 | Actual Loss: 1.0450\n",
      "Baseline Loss: 2.6956 | Actual Loss: 1.2993\n",
      "Baseline Loss: 2.6789 | Actual Loss: 0.7870\n",
      "Baseline Loss: 2.6878 | Actual Loss: 0.6793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 68/1000 [00:42<10:03,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6728 | Actual Loss: 0.4578\n",
      "Baseline Loss: 2.3403 | Actual Loss: 0.4293\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.6812\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.5943\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.6413\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.7204\n",
      "Epoch 68/1000: Train Loss: 0.8979, Val Loss: 0.6593\n",
      "Baseline Loss: 2.6575 | Actual Loss: 0.5932\n",
      "Baseline Loss: 2.6557 | Actual Loss: 1.3802\n",
      "Baseline Loss: 2.6747 | Actual Loss: 0.7988\n",
      "Baseline Loss: 2.6606 | Actual Loss: 0.5361\n",
      "Baseline Loss: 2.6815 | Actual Loss: 0.6688\n",
      "Baseline Loss: 2.6992 | Actual Loss: 0.4007\n",
      "Baseline Loss: 2.6933 | Actual Loss: 0.6702\n",
      "Baseline Loss: 2.6552 | Actual Loss: 0.8988\n",
      "Baseline Loss: 2.6938 | Actual Loss: 0.7984\n",
      "Baseline Loss: 2.7089 | Actual Loss: 0.9216\n",
      "Baseline Loss: 2.6517 | Actual Loss: 0.7265\n",
      "Baseline Loss: 2.6627 | Actual Loss: 0.8180\n",
      "Baseline Loss: 2.6359 | Actual Loss: 0.7670\n",
      "Baseline Loss: 2.6235 | Actual Loss: 0.4173\n",
      "Baseline Loss: 2.6952 | Actual Loss: 0.6803\n",
      "Baseline Loss: 2.3329 | Actual Loss: 0.6667\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.6602\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.6086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 69/1000 [00:43<09:36,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7015 | Actual Loss: 0.4276\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.7565\n",
      "Epoch 69/1000: Train Loss: 0.7339, Val Loss: 0.6132\n",
      "Baseline Loss: 2.7301 | Actual Loss: 0.3588\n",
      "Baseline Loss: 2.7188 | Actual Loss: 0.6175\n",
      "Baseline Loss: 2.6480 | Actual Loss: 0.4641\n",
      "Baseline Loss: 2.6539 | Actual Loss: 0.4862\n",
      "Baseline Loss: 2.6446 | Actual Loss: 0.4380\n",
      "Baseline Loss: 2.6729 | Actual Loss: 2.2784\n",
      "Baseline Loss: 2.6782 | Actual Loss: 0.6749\n",
      "Baseline Loss: 2.6868 | Actual Loss: 1.8977\n",
      "Baseline Loss: 2.6628 | Actual Loss: 2.3965\n",
      "Baseline Loss: 2.6885 | Actual Loss: 2.4682\n",
      "Baseline Loss: 2.7021 | Actual Loss: 0.6196\n",
      "Baseline Loss: 2.6467 | Actual Loss: 0.4748\n",
      "Baseline Loss: 2.6625 | Actual Loss: 0.6417\n",
      "Baseline Loss: 2.6649 | Actual Loss: 0.7214\n",
      "Baseline Loss: 2.6810 | Actual Loss: 0.3996\n",
      "Baseline Loss: 2.2624 | Actual Loss: 0.5955\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.8311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 70/1000 [00:44<09:40,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6435 | Actual Loss: 0.6693\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.6117\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.6513\n",
      "Epoch 70/1000: Train Loss: 0.9708, Val Loss: 0.6909\n",
      "Baseline Loss: 2.6343 | Actual Loss: 0.7018\n",
      "Baseline Loss: 2.6733 | Actual Loss: 0.7482\n",
      "Baseline Loss: 2.6646 | Actual Loss: 0.7450\n",
      "Baseline Loss: 2.6864 | Actual Loss: 0.4209\n",
      "Baseline Loss: 2.6900 | Actual Loss: 0.8845\n",
      "Baseline Loss: 2.6658 | Actual Loss: 0.7221\n",
      "Baseline Loss: 2.6595 | Actual Loss: 0.4604\n",
      "Baseline Loss: 2.7035 | Actual Loss: 0.8800\n",
      "Baseline Loss: 2.6834 | Actual Loss: 1.0123\n",
      "Baseline Loss: 2.6689 | Actual Loss: 0.7264\n",
      "Baseline Loss: 2.7143 | Actual Loss: 0.6922\n",
      "Baseline Loss: 2.6639 | Actual Loss: 1.6875\n",
      "Baseline Loss: 2.6450 | Actual Loss: 0.6767\n",
      "Baseline Loss: 2.6441 | Actual Loss: 1.9265\n",
      "Baseline Loss: 2.7000 | Actual Loss: 0.8053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 71/1000 [00:44<10:05,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2681 | Actual Loss: 0.5021\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9294\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4886\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.1801\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.7056\n",
      "Epoch 71/1000: Train Loss: 0.8495, Val Loss: 0.5759\n",
      "New best validation loss: 0.5759\n",
      "Baseline Loss: 2.6672 | Actual Loss: 0.8577\n",
      "Baseline Loss: 2.7067 | Actual Loss: 0.2380\n",
      "Baseline Loss: 2.6355 | Actual Loss: 1.1950\n",
      "Baseline Loss: 2.6782 | Actual Loss: 0.4528\n",
      "Baseline Loss: 2.6949 | Actual Loss: 0.8167\n",
      "Baseline Loss: 2.6512 | Actual Loss: 1.9146\n",
      "Baseline Loss: 2.6812 | Actual Loss: 1.2963\n",
      "Baseline Loss: 2.6842 | Actual Loss: 1.6656\n",
      "Baseline Loss: 2.6749 | Actual Loss: 2.4960\n",
      "Baseline Loss: 2.7132 | Actual Loss: 0.3835\n",
      "Baseline Loss: 2.6303 | Actual Loss: 1.0067\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.8747\n",
      "Baseline Loss: 2.7175 | Actual Loss: 0.6740\n",
      "Baseline Loss: 2.6811 | Actual Loss: 0.7282\n",
      "Baseline Loss: 2.6836 | Actual Loss: 0.9038\n",
      "Baseline Loss: 2.2178 | Actual Loss: 0.3484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 72/1000 [00:45<10:03,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7315 | Actual Loss: 0.8542\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.8047\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.9619\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.7970\n",
      "Epoch 72/1000: Train Loss: 0.9907, Val Loss: 0.8545\n",
      "Baseline Loss: 2.6494 | Actual Loss: 0.9267\n",
      "Baseline Loss: 2.6538 | Actual Loss: 0.7583\n",
      "Baseline Loss: 2.6677 | Actual Loss: 0.6749\n",
      "Baseline Loss: 2.7472 | Actual Loss: 0.6681\n",
      "Baseline Loss: 2.6987 | Actual Loss: 0.9196\n",
      "Baseline Loss: 2.6431 | Actual Loss: 0.7186\n",
      "Baseline Loss: 2.6653 | Actual Loss: 0.8842\n",
      "Baseline Loss: 2.6698 | Actual Loss: 1.0841\n",
      "Baseline Loss: 2.7128 | Actual Loss: 0.7627\n",
      "Baseline Loss: 2.6885 | Actual Loss: 0.9020\n",
      "Baseline Loss: 2.6709 | Actual Loss: 0.7333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 73/1000 [00:46<09:29,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6228 | Actual Loss: 1.2156\n",
      "Baseline Loss: 2.6480 | Actual Loss: 0.8611\n",
      "Baseline Loss: 2.6978 | Actual Loss: 0.6529\n",
      "Baseline Loss: 2.6504 | Actual Loss: 0.7491\n",
      "Baseline Loss: 2.2560 | Actual Loss: 0.4323\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.8434\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.5595\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.2403\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.7145\n",
      "Epoch 73/1000: Train Loss: 0.8090, Val Loss: 0.5894\n",
      "Baseline Loss: 2.7503 | Actual Loss: 0.8503\n",
      "Baseline Loss: 2.6714 | Actual Loss: 0.3293\n",
      "Baseline Loss: 2.7110 | Actual Loss: 2.4386\n",
      "Baseline Loss: 2.7303 | Actual Loss: 2.3709\n",
      "Baseline Loss: 2.6438 | Actual Loss: 0.7515\n",
      "Baseline Loss: 2.6666 | Actual Loss: 0.6806\n",
      "Baseline Loss: 2.6692 | Actual Loss: 0.6752\n",
      "Baseline Loss: 2.6354 | Actual Loss: 0.9210\n",
      "Baseline Loss: 2.6672 | Actual Loss: 0.4495\n",
      "Baseline Loss: 2.6620 | Actual Loss: 0.8005\n",
      "Baseline Loss: 2.6680 | Actual Loss: 0.8401\n",
      "Baseline Loss: 2.6691 | Actual Loss: 2.2785\n",
      "Baseline Loss: 2.6301 | Actual Loss: 0.7913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 74/1000 [00:46<09:53,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6784 | Actual Loss: 0.6481\n",
      "Baseline Loss: 2.6582 | Actual Loss: 0.2997\n",
      "Baseline Loss: 2.2526 | Actual Loss: 1.8366\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.1782\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4570\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.5223\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.8009\n",
      "Epoch 74/1000: Train Loss: 1.0601, Val Loss: 0.7396\n",
      "Baseline Loss: 2.7001 | Actual Loss: 0.7869\n",
      "Baseline Loss: 2.6675 | Actual Loss: 0.4151\n",
      "Baseline Loss: 2.6929 | Actual Loss: 0.7622\n",
      "Baseline Loss: 2.6889 | Actual Loss: 0.6289\n",
      "Baseline Loss: 2.6718 | Actual Loss: 0.9861\n",
      "Baseline Loss: 2.6790 | Actual Loss: 0.6749\n",
      "Baseline Loss: 2.6828 | Actual Loss: 0.6115\n",
      "Baseline Loss: 2.6972 | Actual Loss: 0.6877\n",
      "Baseline Loss: 2.6687 | Actual Loss: 0.8946\n",
      "Baseline Loss: 2.6690 | Actual Loss: 0.6606\n",
      "Baseline Loss: 2.6853 | Actual Loss: 1.6707\n",
      "Baseline Loss: 2.6617 | Actual Loss: 0.3993\n",
      "Baseline Loss: 2.6507 | Actual Loss: 0.4769\n",
      "Baseline Loss: 2.6647 | Actual Loss: 0.6532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 75/1000 [00:47<09:52,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6420 | Actual Loss: 0.4916\n",
      "Baseline Loss: 2.3601 | Actual Loss: 0.7306\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9604\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4258\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.4451\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.6976\n",
      "Epoch 75/1000: Train Loss: 0.7207, Val Loss: 0.6322\n",
      "Baseline Loss: 2.6941 | Actual Loss: 0.8563\n",
      "Baseline Loss: 2.6779 | Actual Loss: 0.6255\n",
      "Baseline Loss: 2.6609 | Actual Loss: 0.5470\n",
      "Baseline Loss: 2.6773 | Actual Loss: 1.1959\n",
      "Baseline Loss: 2.6566 | Actual Loss: 0.6083\n",
      "Baseline Loss: 2.7287 | Actual Loss: 0.6045\n",
      "Baseline Loss: 2.6710 | Actual Loss: 0.7169\n",
      "Baseline Loss: 2.6688 | Actual Loss: 0.8486\n",
      "Baseline Loss: 2.6756 | Actual Loss: 1.4620\n",
      "Baseline Loss: 2.6760 | Actual Loss: 0.2723\n",
      "Baseline Loss: 2.6811 | Actual Loss: 0.6256\n",
      "Baseline Loss: 2.6541 | Actual Loss: 0.5320\n",
      "Baseline Loss: 2.6909 | Actual Loss: 0.3397\n",
      "Baseline Loss: 2.6882 | Actual Loss: 1.3397\n",
      "Baseline Loss: 2.6760 | Actual Loss: 0.8269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 76/1000 [00:47<09:43,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2166 | Actual Loss: 0.2407\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.6885\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.6474\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.5383\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.7835\n",
      "Epoch 76/1000: Train Loss: 0.7276, Val Loss: 0.6644\n",
      "Baseline Loss: 2.6461 | Actual Loss: 0.7047\n",
      "Baseline Loss: 2.7180 | Actual Loss: 1.0645\n",
      "Baseline Loss: 2.6996 | Actual Loss: 0.5326\n",
      "Baseline Loss: 2.6585 | Actual Loss: 0.6077\n",
      "Baseline Loss: 2.6620 | Actual Loss: 0.7583\n",
      "Baseline Loss: 2.6933 | Actual Loss: 0.9171\n",
      "Baseline Loss: 2.6972 | Actual Loss: 1.0658\n",
      "Baseline Loss: 2.6567 | Actual Loss: 0.4479\n",
      "Baseline Loss: 2.6651 | Actual Loss: 0.4838\n",
      "Baseline Loss: 2.6767 | Actual Loss: 0.3795\n",
      "Baseline Loss: 2.6637 | Actual Loss: 0.6346\n",
      "Baseline Loss: 2.6583 | Actual Loss: 0.4762\n",
      "Baseline Loss: 2.6517 | Actual Loss: 0.8705\n",
      "Baseline Loss: 2.6979 | Actual Loss: 0.9522\n",
      "Baseline Loss: 2.6466 | Actual Loss: 0.8582\n",
      "Baseline Loss: 2.2744 | Actual Loss: 1.1144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 77/1000 [00:48<09:55,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7315 | Actual Loss: 1.0805\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4740\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3377\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.5572\n",
      "Epoch 77/1000: Train Loss: 0.7417, Val Loss: 0.6123\n",
      "Baseline Loss: 2.6611 | Actual Loss: 0.9104\n",
      "Baseline Loss: 2.6826 | Actual Loss: 2.1816\n",
      "Baseline Loss: 2.6740 | Actual Loss: 0.3839\n",
      "Baseline Loss: 2.6782 | Actual Loss: 0.8962\n",
      "Baseline Loss: 2.6555 | Actual Loss: 0.5393\n",
      "Baseline Loss: 2.7121 | Actual Loss: 1.3497\n",
      "Baseline Loss: 2.6782 | Actual Loss: 0.4842\n",
      "Baseline Loss: 2.6978 | Actual Loss: 0.8832\n",
      "Baseline Loss: 2.7157 | Actual Loss: 0.7569\n",
      "Baseline Loss: 2.6586 | Actual Loss: 0.7555\n",
      "Baseline Loss: 2.6875 | Actual Loss: 0.3941\n",
      "Baseline Loss: 2.6402 | Actual Loss: 0.5443\n",
      "Baseline Loss: 2.6528 | Actual Loss: 0.7327\n",
      "Baseline Loss: 2.6906 | Actual Loss: 0.7824\n",
      "Baseline Loss: 2.6744 | Actual Loss: 0.5662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 78/1000 [00:49<09:55,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2791 | Actual Loss: 1.8111\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.3291\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.5340\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.2567\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.6723\n",
      "Epoch 78/1000: Train Loss: 0.8732, Val Loss: 0.6980\n",
      "Baseline Loss: 2.6756 | Actual Loss: 0.7179\n",
      "Baseline Loss: 2.6712 | Actual Loss: 0.8435\n",
      "Baseline Loss: 2.6370 | Actual Loss: 0.3968\n",
      "Baseline Loss: 2.6472 | Actual Loss: 0.4297\n",
      "Baseline Loss: 2.7100 | Actual Loss: 1.4913\n",
      "Baseline Loss: 2.6765 | Actual Loss: 0.4240\n",
      "Baseline Loss: 2.6305 | Actual Loss: 0.6695\n",
      "Baseline Loss: 2.6949 | Actual Loss: 0.6317\n",
      "Baseline Loss: 2.7166 | Actual Loss: 0.6727\n",
      "Baseline Loss: 2.7215 | Actual Loss: 0.5832\n",
      "Baseline Loss: 2.6724 | Actual Loss: 0.8338\n",
      "Baseline Loss: 2.7116 | Actual Loss: 0.3359\n",
      "Baseline Loss: 2.6727 | Actual Loss: 0.7702\n",
      "Baseline Loss: 2.6590 | Actual Loss: 1.0452\n",
      "Baseline Loss: 2.6433 | Actual Loss: 1.2715\n",
      "Baseline Loss: 2.2249 | Actual Loss: 0.3541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 79/1000 [00:49<09:45,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7315 | Actual Loss: 0.9783\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.7528\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.7979\n",
      "Baseline Loss: 2.5568 | Actual Loss: 1.1474\n",
      "Epoch 79/1000: Train Loss: 0.7169, Val Loss: 0.9191\n",
      "Baseline Loss: 2.7137 | Actual Loss: 0.7392\n",
      "Baseline Loss: 2.6558 | Actual Loss: 0.9160\n",
      "Baseline Loss: 2.6882 | Actual Loss: 0.9860\n",
      "Baseline Loss: 2.6752 | Actual Loss: 0.6768\n",
      "Baseline Loss: 2.6554 | Actual Loss: 0.9073\n",
      "Baseline Loss: 2.6757 | Actual Loss: 0.5161\n",
      "Baseline Loss: 2.6205 | Actual Loss: 0.6446\n",
      "Baseline Loss: 2.7059 | Actual Loss: 1.0265\n",
      "Baseline Loss: 2.6657 | Actual Loss: 0.4112\n",
      "Baseline Loss: 2.6530 | Actual Loss: 1.0333\n",
      "Baseline Loss: 2.6664 | Actual Loss: 0.2528\n",
      "Baseline Loss: 2.6805 | Actual Loss: 1.4385\n",
      "Baseline Loss: 2.6802 | Actual Loss: 1.2060\n",
      "Baseline Loss: 2.6623 | Actual Loss: 0.3037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 80/1000 [00:50<10:04,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6724 | Actual Loss: 0.6878\n",
      "Baseline Loss: 2.2543 | Actual Loss: 0.1598\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9221\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.5565\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3875\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.6345\n",
      "Epoch 80/1000: Train Loss: 0.7441, Val Loss: 0.6252\n",
      "Baseline Loss: 2.6769 | Actual Loss: 1.0896\n",
      "Baseline Loss: 2.6811 | Actual Loss: 0.4045\n",
      "Baseline Loss: 2.7173 | Actual Loss: 0.9588\n",
      "Baseline Loss: 2.6526 | Actual Loss: 0.7576\n",
      "Baseline Loss: 2.6633 | Actual Loss: 0.6585\n",
      "Baseline Loss: 2.6404 | Actual Loss: 0.8408\n",
      "Baseline Loss: 2.6685 | Actual Loss: 1.0877\n",
      "Baseline Loss: 2.6955 | Actual Loss: 0.6945\n",
      "Baseline Loss: 2.6529 | Actual Loss: 0.7168\n",
      "Baseline Loss: 2.6661 | Actual Loss: 1.5059\n",
      "Baseline Loss: 2.6898 | Actual Loss: 0.1927\n",
      "Baseline Loss: 2.6695 | Actual Loss: 0.7766\n",
      "Baseline Loss: 2.7053 | Actual Loss: 0.7697\n",
      "Baseline Loss: 2.6841 | Actual Loss: 0.9587\n",
      "Baseline Loss: 2.6450 | Actual Loss: 0.2633\n",
      "Baseline Loss: 2.3279 | Actual Loss: 0.5412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 81/1000 [00:51<10:10,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7315 | Actual Loss: 0.8019\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.5330\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.5430\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.7516\n",
      "Epoch 81/1000: Train Loss: 0.7635, Val Loss: 0.6574\n",
      "Baseline Loss: 2.6041 | Actual Loss: 0.4269\n",
      "Baseline Loss: 2.6829 | Actual Loss: 0.3283\n",
      "Baseline Loss: 2.6987 | Actual Loss: 0.7464\n",
      "Baseline Loss: 2.6616 | Actual Loss: 0.8237\n",
      "Baseline Loss: 2.6842 | Actual Loss: 0.9336\n",
      "Baseline Loss: 2.6935 | Actual Loss: 0.7612\n",
      "Baseline Loss: 2.6932 | Actual Loss: 0.9137\n",
      "Baseline Loss: 2.6666 | Actual Loss: 0.8051\n",
      "Baseline Loss: 2.7031 | Actual Loss: 0.8467\n",
      "Baseline Loss: 2.6395 | Actual Loss: 0.5876\n",
      "Baseline Loss: 2.6480 | Actual Loss: 0.9291\n",
      "Baseline Loss: 2.6784 | Actual Loss: 0.5557\n",
      "Baseline Loss: 2.6883 | Actual Loss: 0.7971\n",
      "Baseline Loss: 2.6731 | Actual Loss: 0.7338\n",
      "Baseline Loss: 2.6915 | Actual Loss: 0.2608\n",
      "Baseline Loss: 2.2582 | Actual Loss: 0.9420\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9529\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.5518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 82/1000 [00:51<09:54,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7015 | Actual Loss: 0.5110\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.6494\n",
      "Epoch 82/1000: Train Loss: 0.7120, Val Loss: 0.6663\n",
      "Baseline Loss: 2.6455 | Actual Loss: 0.4782\n",
      "Baseline Loss: 2.6427 | Actual Loss: 0.8812\n",
      "Baseline Loss: 2.6915 | Actual Loss: 1.0566\n",
      "Baseline Loss: 2.7667 | Actual Loss: 1.5164\n",
      "Baseline Loss: 2.6582 | Actual Loss: 0.7619\n",
      "Baseline Loss: 2.6759 | Actual Loss: 0.7877\n",
      "Baseline Loss: 2.6613 | Actual Loss: 0.6341\n",
      "Baseline Loss: 2.7060 | Actual Loss: 0.6084\n",
      "Baseline Loss: 2.6646 | Actual Loss: 0.8618\n",
      "Baseline Loss: 2.6479 | Actual Loss: 0.4080\n",
      "Baseline Loss: 2.6517 | Actual Loss: 0.3551\n",
      "Baseline Loss: 2.6863 | Actual Loss: 1.3950\n",
      "Baseline Loss: 2.6939 | Actual Loss: 0.6573\n",
      "Baseline Loss: 2.6731 | Actual Loss: 0.4773\n",
      "Baseline Loss: 2.6867 | Actual Loss: 0.3618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 83/1000 [00:52<10:08,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2942 | Actual Loss: 0.9298\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.0574\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.5781\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.5067\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.9738\n",
      "Epoch 83/1000: Train Loss: 0.7607, Val Loss: 0.7790\n",
      "Baseline Loss: 2.6654 | Actual Loss: 0.8955\n",
      "Baseline Loss: 2.6872 | Actual Loss: 0.1774\n",
      "Baseline Loss: 2.6521 | Actual Loss: 0.5966\n",
      "Baseline Loss: 2.7058 | Actual Loss: 0.8488\n",
      "Baseline Loss: 2.6766 | Actual Loss: 0.6840\n",
      "Baseline Loss: 2.6485 | Actual Loss: 2.4045\n",
      "Baseline Loss: 2.6652 | Actual Loss: 0.5766\n",
      "Baseline Loss: 2.6491 | Actual Loss: 0.4419\n",
      "Baseline Loss: 2.6864 | Actual Loss: 1.0763\n",
      "Baseline Loss: 2.6533 | Actual Loss: 1.6642\n",
      "Baseline Loss: 2.6942 | Actual Loss: 2.6080\n",
      "Baseline Loss: 2.6815 | Actual Loss: 1.1771\n",
      "Baseline Loss: 2.6719 | Actual Loss: 0.3918\n",
      "Baseline Loss: 2.7047 | Actual Loss: 0.4247\n",
      "Baseline Loss: 2.7228 | Actual Loss: 0.8557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 84/1000 [00:53<09:42,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2529 | Actual Loss: 0.2146\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.1185\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.5785\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.2847\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.9434\n",
      "Epoch 84/1000: Train Loss: 0.9399, Val Loss: 0.7313\n",
      "Baseline Loss: 2.6852 | Actual Loss: 0.7384\n",
      "Baseline Loss: 2.7235 | Actual Loss: 0.8807\n",
      "Baseline Loss: 2.6775 | Actual Loss: 0.6603\n",
      "Baseline Loss: 2.6637 | Actual Loss: 0.6687\n",
      "Baseline Loss: 2.6676 | Actual Loss: 0.7042\n",
      "Baseline Loss: 2.6436 | Actual Loss: 0.8240\n",
      "Baseline Loss: 2.6735 | Actual Loss: 0.8456\n",
      "Baseline Loss: 2.6520 | Actual Loss: 0.9177\n",
      "Baseline Loss: 2.6436 | Actual Loss: 0.8040\n",
      "Baseline Loss: 2.6973 | Actual Loss: 0.9783\n",
      "Baseline Loss: 2.6709 | Actual Loss: 0.8270\n",
      "Baseline Loss: 2.6808 | Actual Loss: 0.9371\n",
      "Baseline Loss: 2.6478 | Actual Loss: 0.7211\n",
      "Baseline Loss: 2.6746 | Actual Loss: 1.2819\n",
      "Baseline Loss: 2.6996 | Actual Loss: 0.6422\n",
      "Baseline Loss: 2.2906 | Actual Loss: 0.1701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 85/1000 [00:53<09:53,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7315 | Actual Loss: 0.7714\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.6804\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.5023\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.9963\n",
      "Epoch 85/1000: Train Loss: 0.7876, Val Loss: 0.7376\n",
      "Baseline Loss: 2.6884 | Actual Loss: 1.0072\n",
      "Baseline Loss: 2.7044 | Actual Loss: 0.6577\n",
      "Baseline Loss: 2.6647 | Actual Loss: 1.0865\n",
      "Baseline Loss: 2.7170 | Actual Loss: 1.0820\n",
      "Baseline Loss: 2.6627 | Actual Loss: 0.4133\n",
      "Baseline Loss: 2.6691 | Actual Loss: 1.6348\n",
      "Baseline Loss: 2.6481 | Actual Loss: 0.9201\n",
      "Baseline Loss: 2.6842 | Actual Loss: 0.8926\n",
      "Baseline Loss: 2.6994 | Actual Loss: 0.5176\n",
      "Baseline Loss: 2.6574 | Actual Loss: 1.1150\n",
      "Baseline Loss: 2.6836 | Actual Loss: 0.5080\n",
      "Baseline Loss: 2.6749 | Actual Loss: 0.6075\n",
      "Baseline Loss: 2.6635 | Actual Loss: 0.5044\n",
      "Baseline Loss: 2.6630 | Actual Loss: 0.5620\n",
      "Baseline Loss: 2.6864 | Actual Loss: 0.8539\n",
      "Baseline Loss: 2.2641 | Actual Loss: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▊         | 86/1000 [00:54<09:58,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7315 | Actual Loss: 0.7536\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.5493\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.5626\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.9281\n",
      "Epoch 86/1000: Train Loss: 0.8002, Val Loss: 0.6984\n",
      "Baseline Loss: 2.6799 | Actual Loss: 0.5935\n",
      "Baseline Loss: 2.7020 | Actual Loss: 0.6569\n",
      "Baseline Loss: 2.6525 | Actual Loss: 0.6106\n",
      "Baseline Loss: 2.7084 | Actual Loss: 0.6905\n",
      "Baseline Loss: 2.6666 | Actual Loss: 0.7628\n",
      "Baseline Loss: 2.6573 | Actual Loss: 0.7480\n",
      "Baseline Loss: 2.7100 | Actual Loss: 0.9241\n",
      "Baseline Loss: 2.6441 | Actual Loss: 0.6935\n",
      "Baseline Loss: 2.6668 | Actual Loss: 0.6390\n",
      "Baseline Loss: 2.6968 | Actual Loss: 1.2569\n",
      "Baseline Loss: 2.6494 | Actual Loss: 1.1305\n",
      "Baseline Loss: 2.6775 | Actual Loss: 0.9442\n",
      "Baseline Loss: 2.6399 | Actual Loss: 0.7310\n",
      "Baseline Loss: 2.6752 | Actual Loss: 0.6372\n",
      "Baseline Loss: 2.7034 | Actual Loss: 0.5641\n",
      "Baseline Loss: 2.2166 | Actual Loss: 0.5766\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.0952\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4107\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.4060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▊         | 87/1000 [00:55<09:30,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5568 | Actual Loss: 0.6141\n",
      "Epoch 87/1000: Train Loss: 0.7600, Val Loss: 0.6315\n",
      "Baseline Loss: 2.6524 | Actual Loss: 0.5808\n",
      "Baseline Loss: 2.6594 | Actual Loss: 0.7773\n",
      "Baseline Loss: 2.7146 | Actual Loss: 0.5471\n",
      "Baseline Loss: 2.6911 | Actual Loss: 0.4666\n",
      "Baseline Loss: 2.6791 | Actual Loss: 1.0490\n",
      "Baseline Loss: 2.6564 | Actual Loss: 0.7464\n",
      "Baseline Loss: 2.6793 | Actual Loss: 0.4812\n",
      "Baseline Loss: 2.7011 | Actual Loss: 2.4455\n",
      "Baseline Loss: 2.6641 | Actual Loss: 0.6594\n",
      "Baseline Loss: 2.6923 | Actual Loss: 0.9003\n",
      "Baseline Loss: 2.6550 | Actual Loss: 1.8640\n",
      "Baseline Loss: 2.6920 | Actual Loss: 2.2363\n",
      "Baseline Loss: 2.6611 | Actual Loss: 0.6727\n",
      "Baseline Loss: 2.6830 | Actual Loss: 0.6834\n",
      "Baseline Loss: 2.6747 | Actual Loss: 0.7166\n",
      "Baseline Loss: 2.2367 | Actual Loss: 0.3603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 88/1000 [00:55<09:52,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7315 | Actual Loss: 0.8719\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.5424\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.5227\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.9180\n",
      "Epoch 88/1000: Train Loss: 0.9492, Val Loss: 0.7138\n",
      "Baseline Loss: 2.6582 | Actual Loss: 0.4413\n",
      "Baseline Loss: 2.6853 | Actual Loss: 1.0928\n",
      "Baseline Loss: 2.6966 | Actual Loss: 0.8127\n",
      "Baseline Loss: 2.7090 | Actual Loss: 0.3290\n",
      "Baseline Loss: 2.6394 | Actual Loss: 0.6211\n",
      "Baseline Loss: 2.7082 | Actual Loss: 1.1733\n",
      "Baseline Loss: 2.6646 | Actual Loss: 0.8274\n",
      "Baseline Loss: 2.6892 | Actual Loss: 0.1758\n",
      "Baseline Loss: 2.6491 | Actual Loss: 0.8434\n",
      "Baseline Loss: 2.6551 | Actual Loss: 1.0227\n",
      "Baseline Loss: 2.6734 | Actual Loss: 0.5942\n",
      "Baseline Loss: 2.6642 | Actual Loss: 0.8140\n",
      "Baseline Loss: 2.6956 | Actual Loss: 0.6761\n",
      "Baseline Loss: 2.6510 | Actual Loss: 0.7750\n",
      "Baseline Loss: 2.6739 | Actual Loss: 0.5625\n",
      "Baseline Loss: 2.3169 | Actual Loss: 0.4373\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.0242\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.5373\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 89/1000 [00:56<09:27,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5568 | Actual Loss: 0.4147\n",
      "Epoch 89/1000: Train Loss: 0.6999, Val Loss: 0.5843\n",
      "Baseline Loss: 2.6480 | Actual Loss: 0.6746\n",
      "Baseline Loss: 2.6510 | Actual Loss: 0.5295\n",
      "Baseline Loss: 2.6421 | Actual Loss: 0.6819\n",
      "Baseline Loss: 2.6116 | Actual Loss: 0.7086\n",
      "Baseline Loss: 2.6930 | Actual Loss: 0.5210\n",
      "Baseline Loss: 2.7102 | Actual Loss: 0.9026\n",
      "Baseline Loss: 2.6668 | Actual Loss: 0.3952\n",
      "Baseline Loss: 2.6660 | Actual Loss: 0.6251\n",
      "Baseline Loss: 2.6903 | Actual Loss: 0.6311\n",
      "Baseline Loss: 2.6684 | Actual Loss: 0.4931\n",
      "Baseline Loss: 2.6730 | Actual Loss: 1.2095\n",
      "Baseline Loss: 2.6359 | Actual Loss: 0.4146\n",
      "Baseline Loss: 2.6563 | Actual Loss: 0.9688\n",
      "Baseline Loss: 2.7077 | Actual Loss: 0.2713\n",
      "Baseline Loss: 2.6595 | Actual Loss: 0.3950\n",
      "Baseline Loss: 2.3609 | Actual Loss: 0.5840\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.0164\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.6173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 90/1000 [00:56<09:30,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7015 | Actual Loss: 0.2395\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.4512\n",
      "Epoch 90/1000: Train Loss: 0.6254, Val Loss: 0.5811\n",
      "Baseline Loss: 2.7008 | Actual Loss: 0.1656\n",
      "Baseline Loss: 2.6339 | Actual Loss: 0.3810\n",
      "Baseline Loss: 2.6870 | Actual Loss: 2.5674\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.5281\n",
      "Baseline Loss: 2.6732 | Actual Loss: 0.4771\n",
      "Baseline Loss: 2.6470 | Actual Loss: 1.4543\n",
      "Baseline Loss: 2.6761 | Actual Loss: 0.6767\n",
      "Baseline Loss: 2.6796 | Actual Loss: 0.4495\n",
      "Baseline Loss: 2.6710 | Actual Loss: 0.2829\n",
      "Baseline Loss: 2.6430 | Actual Loss: 0.3152\n",
      "Baseline Loss: 2.6639 | Actual Loss: 0.7380\n",
      "Baseline Loss: 2.6805 | Actual Loss: 0.6577\n",
      "Baseline Loss: 2.6773 | Actual Loss: 2.1055\n",
      "Baseline Loss: 2.7051 | Actual Loss: 0.6866\n",
      "Baseline Loss: 2.6539 | Actual Loss: 0.7010\n",
      "Baseline Loss: 2.3526 | Actual Loss: 0.3982\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9459\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.5630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 91/1000 [00:57<09:45,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7015 | Actual Loss: 0.3711\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.7405\n",
      "Epoch 91/1000: Train Loss: 0.7866, Val Loss: 0.6551\n",
      "Baseline Loss: 2.6741 | Actual Loss: 0.2210\n",
      "Baseline Loss: 2.7132 | Actual Loss: 0.3773\n",
      "Baseline Loss: 2.6860 | Actual Loss: 1.0195\n",
      "Baseline Loss: 2.6843 | Actual Loss: 0.6143\n",
      "Baseline Loss: 2.6655 | Actual Loss: 0.3791\n",
      "Baseline Loss: 2.6482 | Actual Loss: 0.5183\n",
      "Baseline Loss: 2.6934 | Actual Loss: 0.7251\n",
      "Baseline Loss: 2.6164 | Actual Loss: 0.2562\n",
      "Baseline Loss: 2.6698 | Actual Loss: 0.6238\n",
      "Baseline Loss: 2.6807 | Actual Loss: 0.8423\n",
      "Baseline Loss: 2.6753 | Actual Loss: 0.6274\n",
      "Baseline Loss: 2.6880 | Actual Loss: 0.8621\n",
      "Baseline Loss: 2.6802 | Actual Loss: 1.5044\n",
      "Baseline Loss: 2.6685 | Actual Loss: 0.8860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 92/1000 [00:58<09:18,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6502 | Actual Loss: 1.2101\n",
      "Baseline Loss: 2.2942 | Actual Loss: 0.4530\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.0091\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.6093\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.2704\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.6147\n",
      "Epoch 92/1000: Train Loss: 0.6950, Val Loss: 0.6259\n",
      "Baseline Loss: 2.7030 | Actual Loss: 0.6763\n",
      "Baseline Loss: 2.6414 | Actual Loss: 0.7406\n",
      "Baseline Loss: 2.7079 | Actual Loss: 1.0337\n",
      "Baseline Loss: 2.6901 | Actual Loss: 0.9261\n",
      "Baseline Loss: 2.6612 | Actual Loss: 0.6484\n",
      "Baseline Loss: 2.6817 | Actual Loss: 0.6314\n",
      "Baseline Loss: 2.6623 | Actual Loss: 0.6049\n",
      "Baseline Loss: 2.7085 | Actual Loss: 0.4361\n",
      "Baseline Loss: 2.6909 | Actual Loss: 2.5102\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.5418\n",
      "Baseline Loss: 2.6675 | Actual Loss: 0.6464\n",
      "Baseline Loss: 2.6397 | Actual Loss: 1.0356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 93/1000 [00:58<09:24,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6765 | Actual Loss: 2.7103\n",
      "Baseline Loss: 2.6582 | Actual Loss: 0.7216\n",
      "Baseline Loss: 2.6707 | Actual Loss: 0.4431\n",
      "Baseline Loss: 2.2452 | Actual Loss: 0.1057\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9774\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.6578\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.4295\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.7217\n",
      "Epoch 93/1000: Train Loss: 0.9008, Val Loss: 0.6966\n",
      "Baseline Loss: 2.6904 | Actual Loss: 0.5827\n",
      "Baseline Loss: 2.6636 | Actual Loss: 0.8016\n",
      "Baseline Loss: 2.6671 | Actual Loss: 0.4538\n",
      "Baseline Loss: 2.6751 | Actual Loss: 0.4213\n",
      "Baseline Loss: 2.6793 | Actual Loss: 0.5496\n",
      "Baseline Loss: 2.6994 | Actual Loss: 0.8937\n",
      "Baseline Loss: 2.6603 | Actual Loss: 0.5479\n",
      "Baseline Loss: 2.6625 | Actual Loss: 1.0134\n",
      "Baseline Loss: 2.6400 | Actual Loss: 0.4169\n",
      "Baseline Loss: 2.6975 | Actual Loss: 0.6699\n",
      "Baseline Loss: 2.6686 | Actual Loss: 0.6959\n",
      "Baseline Loss: 2.6901 | Actual Loss: 0.7403\n",
      "Baseline Loss: 2.6484 | Actual Loss: 1.3863\n",
      "Baseline Loss: 2.7063 | Actual Loss: 0.5637\n",
      "Baseline Loss: 2.6386 | Actual Loss: 0.9302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 94/1000 [00:59<09:04,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.3122 | Actual Loss: 2.3495\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9729\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.6009\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.5209\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.7073\n",
      "Epoch 94/1000: Train Loss: 0.8135, Val Loss: 0.7005\n",
      "Baseline Loss: 2.6587 | Actual Loss: 0.5551\n",
      "Baseline Loss: 2.6855 | Actual Loss: 0.6316\n",
      "Baseline Loss: 2.6697 | Actual Loss: 0.6747\n",
      "Baseline Loss: 2.6618 | Actual Loss: 0.5507\n",
      "Baseline Loss: 2.6493 | Actual Loss: 0.9430\n",
      "Baseline Loss: 2.7138 | Actual Loss: 0.4662\n",
      "Baseline Loss: 2.6614 | Actual Loss: 0.6036\n",
      "Baseline Loss: 2.6454 | Actual Loss: 0.7841\n",
      "Baseline Loss: 2.7416 | Actual Loss: 0.2394\n",
      "Baseline Loss: 2.7079 | Actual Loss: 0.4291\n",
      "Baseline Loss: 2.6813 | Actual Loss: 0.6134\n",
      "Baseline Loss: 2.6937 | Actual Loss: 0.4313\n",
      "Baseline Loss: 2.6361 | Actual Loss: 2.1503\n",
      "Baseline Loss: 2.6317 | Actual Loss: 0.6226\n",
      "Baseline Loss: 2.7282 | Actual Loss: 0.6003\n",
      "Baseline Loss: 2.2791 | Actual Loss: 0.5661\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.0225\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.5599\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.4080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 95/1000 [01:00<09:09,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5568 | Actual Loss: 0.4880\n",
      "Epoch 95/1000: Train Loss: 0.6788, Val Loss: 0.6196\n",
      "Baseline Loss: 2.7033 | Actual Loss: 0.8218\n",
      "Baseline Loss: 2.6410 | Actual Loss: 0.3137\n",
      "Baseline Loss: 2.7114 | Actual Loss: 0.3235\n",
      "Baseline Loss: 2.6584 | Actual Loss: 0.7912\n",
      "Baseline Loss: 2.6863 | Actual Loss: 0.9932\n",
      "Baseline Loss: 2.7024 | Actual Loss: 1.0669\n",
      "Baseline Loss: 2.7114 | Actual Loss: 0.3647\n",
      "Baseline Loss: 2.6713 | Actual Loss: 0.9992\n",
      "Baseline Loss: 2.6629 | Actual Loss: 0.9914\n",
      "Baseline Loss: 2.6981 | Actual Loss: 0.3152\n",
      "Baseline Loss: 2.6547 | Actual Loss: 0.9371\n",
      "Baseline Loss: 2.6541 | Actual Loss: 0.4181\n",
      "Baseline Loss: 2.6874 | Actual Loss: 0.4803\n",
      "Baseline Loss: 2.6677 | Actual Loss: 1.1939\n",
      "Baseline Loss: 2.6471 | Actual Loss: 1.2406\n",
      "Baseline Loss: 2.2177 | Actual Loss: 0.3089\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.8987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 96/1000 [01:00<09:32,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6435 | Actual Loss: 0.6059\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.6185\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.9323\n",
      "Epoch 96/1000: Train Loss: 0.7225, Val Loss: 0.7638\n",
      "Baseline Loss: 2.6456 | Actual Loss: 1.1175\n",
      "Baseline Loss: 2.6999 | Actual Loss: 0.4433\n",
      "Baseline Loss: 2.7059 | Actual Loss: 0.4894\n",
      "Baseline Loss: 2.6585 | Actual Loss: 0.6900\n",
      "Baseline Loss: 2.6646 | Actual Loss: 0.5581\n",
      "Baseline Loss: 2.6516 | Actual Loss: 0.6105\n",
      "Baseline Loss: 2.6980 | Actual Loss: 0.8823\n",
      "Baseline Loss: 2.6772 | Actual Loss: 0.4174\n",
      "Baseline Loss: 2.6556 | Actual Loss: 0.1615\n",
      "Baseline Loss: 2.6687 | Actual Loss: 0.2817\n",
      "Baseline Loss: 2.6508 | Actual Loss: 0.6260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 97/1000 [01:01<09:10,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6736 | Actual Loss: 0.5625\n",
      "Baseline Loss: 2.6865 | Actual Loss: 0.3380\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.9148\n",
      "Baseline Loss: 2.6835 | Actual Loss: 1.2316\n",
      "Baseline Loss: 2.2765 | Actual Loss: 0.1750\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.0316\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.5389\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3320\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.8633\n",
      "Epoch 97/1000: Train Loss: 0.5937, Val Loss: 0.6914\n",
      "Baseline Loss: 2.7013 | Actual Loss: 0.2369\n",
      "Baseline Loss: 2.6832 | Actual Loss: 0.5077\n",
      "Baseline Loss: 2.6934 | Actual Loss: 0.6049\n",
      "Baseline Loss: 2.6810 | Actual Loss: 0.5184\n",
      "Baseline Loss: 2.6958 | Actual Loss: 0.9019\n",
      "Baseline Loss: 2.6559 | Actual Loss: 0.7511\n",
      "Baseline Loss: 2.6363 | Actual Loss: 0.9207\n",
      "Baseline Loss: 2.7059 | Actual Loss: 0.4276\n",
      "Baseline Loss: 2.6488 | Actual Loss: 0.5452\n",
      "Baseline Loss: 2.6401 | Actual Loss: 1.0740\n",
      "Baseline Loss: 2.6672 | Actual Loss: 1.1599\n",
      "Baseline Loss: 2.6850 | Actual Loss: 0.5110\n",
      "Baseline Loss: 2.6702 | Actual Loss: 1.2260\n",
      "Baseline Loss: 2.6778 | Actual Loss: 0.4340\n",
      "Baseline Loss: 2.6731 | Actual Loss: 1.1895\n",
      "Baseline Loss: 2.2909 | Actual Loss: 0.4375\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.8851\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.5467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 98/1000 [01:01<09:30,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7015 | Actual Loss: 0.3581\n",
      "Baseline Loss: 2.5568 | Actual Loss: 1.0540\n",
      "Epoch 98/1000: Train Loss: 0.7154, Val Loss: 0.7110\n",
      "Baseline Loss: 2.6615 | Actual Loss: 0.6848\n",
      "Baseline Loss: 2.6742 | Actual Loss: 1.1578\n",
      "Baseline Loss: 2.7052 | Actual Loss: 0.6528\n",
      "Baseline Loss: 2.6900 | Actual Loss: 0.5156\n",
      "Baseline Loss: 2.6802 | Actual Loss: 0.6410\n",
      "Baseline Loss: 2.6813 | Actual Loss: 0.3666\n",
      "Baseline Loss: 2.6635 | Actual Loss: 0.7121\n",
      "Baseline Loss: 2.6942 | Actual Loss: 2.8240\n",
      "Baseline Loss: 2.6564 | Actual Loss: 0.6083\n",
      "Baseline Loss: 2.6292 | Actual Loss: 0.5318\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.2837\n",
      "Baseline Loss: 2.6811 | Actual Loss: 0.5296\n",
      "Baseline Loss: 2.6932 | Actual Loss: 0.6416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 99/1000 [01:02<09:40,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6605 | Actual Loss: 0.9342\n",
      "Baseline Loss: 2.6491 | Actual Loss: 0.4971\n",
      "Baseline Loss: 2.2800 | Actual Loss: 0.2805\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.0033\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.5406\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3267\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.4510\n",
      "Epoch 99/1000: Train Loss: 0.7413, Val Loss: 0.5804\n",
      "Baseline Loss: 2.6521 | Actual Loss: 0.6832\n",
      "Baseline Loss: 2.6793 | Actual Loss: 0.6286\n",
      "Baseline Loss: 2.6637 | Actual Loss: 0.4201\n",
      "Baseline Loss: 2.6668 | Actual Loss: 0.7247\n",
      "Baseline Loss: 2.6379 | Actual Loss: 0.5175\n",
      "Baseline Loss: 2.6789 | Actual Loss: 0.7889\n",
      "Baseline Loss: 2.6773 | Actual Loss: 0.7878\n",
      "Baseline Loss: 2.6904 | Actual Loss: 0.9227\n",
      "Baseline Loss: 2.6483 | Actual Loss: 1.2047\n",
      "Baseline Loss: 2.6993 | Actual Loss: 0.6536\n",
      "Baseline Loss: 2.6370 | Actual Loss: 0.6177\n",
      "Baseline Loss: 2.6738 | Actual Loss: 0.8429\n",
      "Baseline Loss: 2.6843 | Actual Loss: 0.6062\n",
      "Baseline Loss: 2.7499 | Actual Loss: 0.7342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 100/1000 [01:03<09:07,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6636 | Actual Loss: 1.6073\n",
      "Baseline Loss: 2.3233 | Actual Loss: 0.2853\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.7372\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.5312\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.2362\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.8501\n",
      "Epoch 100/1000: Train Loss: 0.7516, Val Loss: 0.5887\n",
      "Baseline Loss: 2.6832 | Actual Loss: 0.2633\n",
      "Baseline Loss: 2.6784 | Actual Loss: 0.6529\n",
      "Baseline Loss: 2.6671 | Actual Loss: 0.4480\n",
      "Baseline Loss: 2.7063 | Actual Loss: 0.7551\n",
      "Baseline Loss: 2.7012 | Actual Loss: 0.6646\n",
      "Baseline Loss: 2.7022 | Actual Loss: 2.2735\n",
      "Baseline Loss: 2.6789 | Actual Loss: 0.4930\n",
      "Baseline Loss: 2.6299 | Actual Loss: 0.2410\n",
      "Baseline Loss: 2.6555 | Actual Loss: 0.5231\n",
      "Baseline Loss: 2.6718 | Actual Loss: 0.7118\n",
      "Baseline Loss: 2.6900 | Actual Loss: 0.7941\n",
      "Baseline Loss: 2.7000 | Actual Loss: 1.3261\n",
      "Baseline Loss: 2.6515 | Actual Loss: 1.2358\n",
      "Baseline Loss: 2.6859 | Actual Loss: 0.4135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 101/1000 [01:03<09:28,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6510 | Actual Loss: 0.5501\n",
      "Baseline Loss: 2.2823 | Actual Loss: 2.0772\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9551\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.5269\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3514\n",
      "Baseline Loss: 2.5568 | Actual Loss: 1.0195\n",
      "Epoch 101/1000: Train Loss: 0.8389, Val Loss: 0.7132\n",
      "Baseline Loss: 2.6855 | Actual Loss: 0.4172\n",
      "Baseline Loss: 2.7084 | Actual Loss: 0.8435\n",
      "Baseline Loss: 2.6856 | Actual Loss: 0.5366\n",
      "Baseline Loss: 2.6731 | Actual Loss: 0.5678\n",
      "Baseline Loss: 2.6752 | Actual Loss: 0.4810\n",
      "Baseline Loss: 2.6685 | Actual Loss: 1.0210\n",
      "Baseline Loss: 2.6331 | Actual Loss: 0.9825\n",
      "Baseline Loss: 2.6597 | Actual Loss: 0.4560\n",
      "Baseline Loss: 2.7236 | Actual Loss: 1.2883\n",
      "Baseline Loss: 2.6378 | Actual Loss: 2.4294\n",
      "Baseline Loss: 2.6689 | Actual Loss: 0.9147\n",
      "Baseline Loss: 2.6650 | Actual Loss: 0.1497\n",
      "Baseline Loss: 2.6804 | Actual Loss: 0.4279\n",
      "Baseline Loss: 2.7303 | Actual Loss: 0.6001\n",
      "Baseline Loss: 2.6650 | Actual Loss: 0.5366\n",
      "Baseline Loss: 2.2915 | Actual Loss: 1.1026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 102/1000 [01:04<09:29,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7315 | Actual Loss: 0.7683\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.5680\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3736\n",
      "Baseline Loss: 2.5568 | Actual Loss: 1.0017\n",
      "Epoch 102/1000: Train Loss: 0.7972, Val Loss: 0.6779\n",
      "Baseline Loss: 2.6526 | Actual Loss: 1.0402\n",
      "Baseline Loss: 2.6619 | Actual Loss: 2.0638\n",
      "Baseline Loss: 2.6475 | Actual Loss: 0.3488\n",
      "Baseline Loss: 2.6556 | Actual Loss: 0.5414\n",
      "Baseline Loss: 2.7289 | Actual Loss: 0.8213\n",
      "Baseline Loss: 2.6845 | Actual Loss: 0.5972\n",
      "Baseline Loss: 2.6342 | Actual Loss: 0.3689\n",
      "Baseline Loss: 2.6237 | Actual Loss: 0.7677\n",
      "Baseline Loss: 2.7016 | Actual Loss: 0.3668\n",
      "Baseline Loss: 2.6705 | Actual Loss: 0.3361\n",
      "Baseline Loss: 2.6813 | Actual Loss: 0.5364\n",
      "Baseline Loss: 2.6222 | Actual Loss: 0.1950\n",
      "Baseline Loss: 2.7019 | Actual Loss: 0.7546\n",
      "Baseline Loss: 2.6771 | Actual Loss: 0.7614\n",
      "Baseline Loss: 2.6608 | Actual Loss: 0.8802\n",
      "Baseline Loss: 2.3439 | Actual Loss: 1.9635\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9909\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.5293\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.4574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 103/1000 [01:05<09:29,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5568 | Actual Loss: 0.7689\n",
      "Epoch 103/1000: Train Loss: 0.7715, Val Loss: 0.6866\n",
      "Baseline Loss: 2.6959 | Actual Loss: 0.6681\n",
      "Baseline Loss: 2.6847 | Actual Loss: 0.8972\n",
      "Baseline Loss: 2.6901 | Actual Loss: 0.7056\n",
      "Baseline Loss: 2.7103 | Actual Loss: 1.4449\n",
      "Baseline Loss: 2.6787 | Actual Loss: 0.4207\n",
      "Baseline Loss: 2.6553 | Actual Loss: 0.3312\n",
      "Baseline Loss: 2.6849 | Actual Loss: 1.0228\n",
      "Baseline Loss: 2.6614 | Actual Loss: 0.6974\n",
      "Baseline Loss: 2.6562 | Actual Loss: 0.7806\n",
      "Baseline Loss: 2.6749 | Actual Loss: 0.4033\n",
      "Baseline Loss: 2.6672 | Actual Loss: 1.0614\n",
      "Baseline Loss: 2.6466 | Actual Loss: 0.3705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 104/1000 [01:05<09:19,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6575 | Actual Loss: 1.1032\n",
      "Baseline Loss: 2.7046 | Actual Loss: 1.1898\n",
      "Baseline Loss: 2.6772 | Actual Loss: 0.8664\n",
      "Baseline Loss: 2.2376 | Actual Loss: 0.5162\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.0983\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.5075\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3152\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.5121\n",
      "Epoch 104/1000: Train Loss: 0.7799, Val Loss: 0.6083\n",
      "Baseline Loss: 2.6926 | Actual Loss: 0.7296\n",
      "Baseline Loss: 2.6613 | Actual Loss: 0.9752\n",
      "Baseline Loss: 2.6376 | Actual Loss: 0.5600\n",
      "Baseline Loss: 2.6699 | Actual Loss: 0.4860\n",
      "Baseline Loss: 2.7115 | Actual Loss: 0.5373\n",
      "Baseline Loss: 2.6878 | Actual Loss: 0.6996\n",
      "Baseline Loss: 2.6621 | Actual Loss: 0.5722\n",
      "Baseline Loss: 2.6571 | Actual Loss: 2.2731\n",
      "Baseline Loss: 2.6378 | Actual Loss: 0.3845\n",
      "Baseline Loss: 2.6635 | Actual Loss: 0.5076\n",
      "Baseline Loss: 2.6808 | Actual Loss: 2.9551\n",
      "Baseline Loss: 2.6630 | Actual Loss: 0.6653\n",
      "Baseline Loss: 2.6754 | Actual Loss: 0.6244\n",
      "Baseline Loss: 2.6827 | Actual Loss: 0.5120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 105/1000 [01:06<09:27,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7000 | Actual Loss: 0.6054\n",
      "Baseline Loss: 2.3008 | Actual Loss: 1.2961\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9688\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.5156\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.2785\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.6918\n",
      "Epoch 105/1000: Train Loss: 0.8990, Val Loss: 0.6137\n",
      "Baseline Loss: 2.6877 | Actual Loss: 0.5139\n",
      "Baseline Loss: 2.6909 | Actual Loss: 0.4320\n",
      "Baseline Loss: 2.6780 | Actual Loss: 2.5475\n",
      "Baseline Loss: 2.6490 | Actual Loss: 0.6972\n",
      "Baseline Loss: 2.6660 | Actual Loss: 0.6958\n",
      "Baseline Loss: 2.6499 | Actual Loss: 0.6219\n",
      "Baseline Loss: 2.6563 | Actual Loss: 0.6460\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.8005\n",
      "Baseline Loss: 2.6217 | Actual Loss: 0.3358\n",
      "Baseline Loss: 2.6593 | Actual Loss: 0.8392\n",
      "Baseline Loss: 2.6635 | Actual Loss: 0.7240\n",
      "Baseline Loss: 2.6733 | Actual Loss: 1.7166\n",
      "Baseline Loss: 2.6569 | Actual Loss: 1.1168\n",
      "Baseline Loss: 2.7039 | Actual Loss: 0.4045\n",
      "Baseline Loss: 2.6691 | Actual Loss: 0.3262\n",
      "Baseline Loss: 2.3711 | Actual Loss: 0.3989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 106/1000 [01:07<09:38,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7315 | Actual Loss: 0.9855\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.5217\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3925\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.9642\n",
      "Epoch 106/1000: Train Loss: 0.8011, Val Loss: 0.7160\n",
      "Baseline Loss: 2.6701 | Actual Loss: 0.6970\n",
      "Baseline Loss: 2.6293 | Actual Loss: 0.3442\n",
      "Baseline Loss: 2.7019 | Actual Loss: 0.6672\n",
      "Baseline Loss: 2.6712 | Actual Loss: 0.7708\n",
      "Baseline Loss: 2.6513 | Actual Loss: 0.3939\n",
      "Baseline Loss: 2.6503 | Actual Loss: 0.9099\n",
      "Baseline Loss: 2.6968 | Actual Loss: 0.6692\n",
      "Baseline Loss: 2.6974 | Actual Loss: 0.5461\n",
      "Baseline Loss: 2.6242 | Actual Loss: 0.9720\n",
      "Baseline Loss: 2.6588 | Actual Loss: 0.2692\n",
      "Baseline Loss: 2.6883 | Actual Loss: 0.6054\n",
      "Baseline Loss: 2.6736 | Actual Loss: 0.6037\n",
      "Baseline Loss: 2.6541 | Actual Loss: 0.6322\n",
      "Baseline Loss: 2.6608 | Actual Loss: 0.5213\n",
      "Baseline Loss: 2.7073 | Actual Loss: 0.4246\n",
      "Baseline Loss: 2.2768 | Actual Loss: 0.1072\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.0332\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.5349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 107/1000 [01:07<09:14,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7015 | Actual Loss: 0.3696\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.4219\n",
      "Epoch 107/1000: Train Loss: 0.5709, Val Loss: 0.5899\n",
      "Baseline Loss: 2.6973 | Actual Loss: 0.9185\n",
      "Baseline Loss: 2.7082 | Actual Loss: 2.3279\n",
      "Baseline Loss: 2.7060 | Actual Loss: 0.6014\n",
      "Baseline Loss: 2.6798 | Actual Loss: 0.3884\n",
      "Baseline Loss: 2.6986 | Actual Loss: 0.3989\n",
      "Baseline Loss: 2.6433 | Actual Loss: 0.5042\n",
      "Baseline Loss: 2.6973 | Actual Loss: 0.7123\n",
      "Baseline Loss: 2.6404 | Actual Loss: 0.8263\n",
      "Baseline Loss: 2.6631 | Actual Loss: 0.6270\n",
      "Baseline Loss: 2.6877 | Actual Loss: 1.0317\n",
      "Baseline Loss: 2.6472 | Actual Loss: 0.2484\n",
      "Baseline Loss: 2.6951 | Actual Loss: 2.5019\n",
      "Baseline Loss: 2.6624 | Actual Loss: 0.9072\n",
      "Baseline Loss: 2.6482 | Actual Loss: 0.5806\n",
      "Baseline Loss: 2.6418 | Actual Loss: 0.7650\n",
      "Baseline Loss: 2.2794 | Actual Loss: 0.5139\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.0105\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.5632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 108/1000 [01:08<09:24,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7015 | Actual Loss: 0.3628\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.8677\n",
      "Epoch 108/1000: Train Loss: 0.8659, Val Loss: 0.7010\n",
      "Baseline Loss: 2.6497 | Actual Loss: 1.3474\n",
      "Baseline Loss: 2.6849 | Actual Loss: 2.0856\n",
      "Baseline Loss: 2.6827 | Actual Loss: 0.3166\n",
      "Baseline Loss: 2.6723 | Actual Loss: 0.4692\n",
      "Baseline Loss: 2.7082 | Actual Loss: 0.4994\n",
      "Baseline Loss: 2.6445 | Actual Loss: 1.2236\n",
      "Baseline Loss: 2.6467 | Actual Loss: 0.5435\n",
      "Baseline Loss: 2.6667 | Actual Loss: 0.7054\n",
      "Baseline Loss: 2.6581 | Actual Loss: 0.3817\n",
      "Baseline Loss: 2.7095 | Actual Loss: 0.4994\n",
      "Baseline Loss: 2.6849 | Actual Loss: 0.6936\n",
      "Baseline Loss: 2.7051 | Actual Loss: 0.7833\n",
      "Baseline Loss: 2.6794 | Actual Loss: 0.3973\n",
      "Baseline Loss: 2.6975 | Actual Loss: 0.7655\n",
      "Baseline Loss: 2.6860 | Actual Loss: 0.7665\n",
      "Baseline Loss: 2.2172 | Actual Loss: 0.2697\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.0098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 109/1000 [01:08<09:35,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6435 | Actual Loss: 0.5603\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3851\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.5164\n",
      "Epoch 109/1000: Train Loss: 0.7342, Val Loss: 0.6179\n",
      "Baseline Loss: 2.7024 | Actual Loss: 0.4270\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.4025\n",
      "Baseline Loss: 2.7214 | Actual Loss: 0.4323\n",
      "Baseline Loss: 2.6953 | Actual Loss: 0.4866\n",
      "Baseline Loss: 2.6564 | Actual Loss: 0.4506\n",
      "Baseline Loss: 2.7057 | Actual Loss: 0.3784\n",
      "Baseline Loss: 2.6973 | Actual Loss: 0.3909\n",
      "Baseline Loss: 2.6518 | Actual Loss: 0.9436\n",
      "Baseline Loss: 2.6108 | Actual Loss: 0.7443\n",
      "Baseline Loss: 2.6858 | Actual Loss: 0.9264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 110/1000 [01:09<09:07,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6703 | Actual Loss: 0.4891\n",
      "Baseline Loss: 2.6841 | Actual Loss: 0.7909\n",
      "Baseline Loss: 2.6367 | Actual Loss: 1.0061\n",
      "Baseline Loss: 2.6827 | Actual Loss: 0.7854\n",
      "Baseline Loss: 2.6798 | Actual Loss: 0.7053\n",
      "Baseline Loss: 2.2844 | Actual Loss: 1.9844\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9764\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.5092\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3703\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.8880\n",
      "Epoch 110/1000: Train Loss: 0.7090, Val Loss: 0.6860\n",
      "Baseline Loss: 2.6818 | Actual Loss: 1.4304\n",
      "Baseline Loss: 2.6731 | Actual Loss: 0.3666\n",
      "Baseline Loss: 2.6571 | Actual Loss: 0.7124\n",
      "Baseline Loss: 2.6966 | Actual Loss: 0.7646\n",
      "Baseline Loss: 2.6849 | Actual Loss: 0.6681\n",
      "Baseline Loss: 2.6436 | Actual Loss: 1.0395\n",
      "Baseline Loss: 2.6569 | Actual Loss: 0.7018\n",
      "Baseline Loss: 2.6822 | Actual Loss: 0.6508\n",
      "Baseline Loss: 2.6785 | Actual Loss: 0.8808\n",
      "Baseline Loss: 2.6982 | Actual Loss: 0.5999\n",
      "Baseline Loss: 2.6593 | Actual Loss: 0.5480\n",
      "Baseline Loss: 2.6467 | Actual Loss: 2.7131\n",
      "Baseline Loss: 2.6838 | Actual Loss: 0.4802\n",
      "Baseline Loss: 2.6552 | Actual Loss: 0.8801\n",
      "Baseline Loss: 2.6603 | Actual Loss: 1.1612\n",
      "Baseline Loss: 2.2892 | Actual Loss: 1.7505\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.0722\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.5203\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.2228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 111/1000 [01:10<09:23,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5568 | Actual Loss: 0.8296\n",
      "Epoch 111/1000: Train Loss: 0.9592, Val Loss: 0.6612\n",
      "Baseline Loss: 2.6623 | Actual Loss: 0.9023\n",
      "Baseline Loss: 2.6691 | Actual Loss: 0.3990\n",
      "Baseline Loss: 2.7133 | Actual Loss: 0.6159\n",
      "Baseline Loss: 2.6540 | Actual Loss: 2.0419\n",
      "Baseline Loss: 2.7066 | Actual Loss: 0.5785\n",
      "Baseline Loss: 2.7012 | Actual Loss: 0.4156\n",
      "Baseline Loss: 2.6811 | Actual Loss: 0.3159\n",
      "Baseline Loss: 2.6534 | Actual Loss: 0.6725\n",
      "Baseline Loss: 2.6883 | Actual Loss: 0.6582\n",
      "Baseline Loss: 2.6275 | Actual Loss: 2.2286\n",
      "Baseline Loss: 2.6879 | Actual Loss: 0.6979\n",
      "Baseline Loss: 2.6612 | Actual Loss: 0.5407\n",
      "Baseline Loss: 2.6687 | Actual Loss: 1.9617\n",
      "Baseline Loss: 2.6720 | Actual Loss: 0.6709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 112/1000 [01:10<09:04,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6387 | Actual Loss: 0.4564\n",
      "Baseline Loss: 2.3370 | Actual Loss: 0.1279\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.0865\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.5284\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.2213\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.8558\n",
      "Epoch 112/1000: Train Loss: 0.8302, Val Loss: 0.6730\n",
      "Baseline Loss: 2.6555 | Actual Loss: 1.2017\n",
      "Baseline Loss: 2.6647 | Actual Loss: 0.7348\n",
      "Baseline Loss: 2.6320 | Actual Loss: 2.5701\n",
      "Baseline Loss: 2.6395 | Actual Loss: 0.6232\n",
      "Baseline Loss: 2.6847 | Actual Loss: 2.3504\n",
      "Baseline Loss: 2.6734 | Actual Loss: 0.5984\n",
      "Baseline Loss: 2.6841 | Actual Loss: 0.5058\n",
      "Baseline Loss: 2.7005 | Actual Loss: 0.4951\n",
      "Baseline Loss: 2.7031 | Actual Loss: 1.1920\n",
      "Baseline Loss: 2.7032 | Actual Loss: 0.4104\n",
      "Baseline Loss: 2.6715 | Actual Loss: 0.7555\n",
      "Baseline Loss: 2.7363 | Actual Loss: 0.5794\n",
      "Baseline Loss: 2.6557 | Actual Loss: 0.3853\n",
      "Baseline Loss: 2.6626 | Actual Loss: 0.5797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█▏        | 113/1000 [01:11<09:21,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6622 | Actual Loss: 0.6371\n",
      "Baseline Loss: 2.2806 | Actual Loss: 0.3754\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.8189\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.5142\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.4854\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.9855\n",
      "Epoch 113/1000: Train Loss: 0.8746, Val Loss: 0.7010\n",
      "Baseline Loss: 2.6941 | Actual Loss: 2.2166\n",
      "Baseline Loss: 2.7057 | Actual Loss: 0.2843\n",
      "Baseline Loss: 2.7159 | Actual Loss: 0.5894\n",
      "Baseline Loss: 2.6717 | Actual Loss: 0.5287\n",
      "Baseline Loss: 2.6221 | Actual Loss: 0.7475\n",
      "Baseline Loss: 2.6514 | Actual Loss: 0.5768\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4542\n",
      "Baseline Loss: 2.6837 | Actual Loss: 1.0293\n",
      "Baseline Loss: 2.6757 | Actual Loss: 1.0512\n",
      "Baseline Loss: 2.6270 | Actual Loss: 0.7336\n",
      "Baseline Loss: 2.6756 | Actual Loss: 0.3998\n",
      "Baseline Loss: 2.6525 | Actual Loss: 0.9049\n",
      "Baseline Loss: 2.7193 | Actual Loss: 0.3030\n",
      "Baseline Loss: 2.6885 | Actual Loss: 1.2241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█▏        | 114/1000 [01:12<09:31,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7043 | Actual Loss: 0.2640\n",
      "Baseline Loss: 2.2537 | Actual Loss: 0.4974\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9450\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4490\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3202\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.9234\n",
      "Epoch 114/1000: Train Loss: 0.7378, Val Loss: 0.6594\n",
      "Baseline Loss: 2.6689 | Actual Loss: 0.3415\n",
      "Baseline Loss: 2.6604 | Actual Loss: 0.8972\n",
      "Baseline Loss: 2.6945 | Actual Loss: 1.1367\n",
      "Baseline Loss: 2.6705 | Actual Loss: 0.6323\n",
      "Baseline Loss: 2.6560 | Actual Loss: 0.2381\n",
      "Baseline Loss: 2.6974 | Actual Loss: 0.5553\n",
      "Baseline Loss: 2.6869 | Actual Loss: 1.0875\n",
      "Baseline Loss: 2.6693 | Actual Loss: 0.4269\n",
      "Baseline Loss: 2.6658 | Actual Loss: 0.7454\n",
      "Baseline Loss: 2.6592 | Actual Loss: 0.4168\n",
      "Baseline Loss: 2.7007 | Actual Loss: 0.8604\n",
      "Baseline Loss: 2.6425 | Actual Loss: 0.5637\n",
      "Baseline Loss: 2.7161 | Actual Loss: 2.4323\n",
      "Baseline Loss: 2.6793 | Actual Loss: 0.2360\n",
      "Baseline Loss: 2.7120 | Actual Loss: 0.6223\n",
      "Baseline Loss: 2.2498 | Actual Loss: 2.3236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 115/1000 [01:12<09:02,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7315 | Actual Loss: 1.0595\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.5165\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.4986\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.5805\n",
      "Epoch 115/1000: Train Loss: 0.8448, Val Loss: 0.6638\n",
      "Baseline Loss: 2.6660 | Actual Loss: 0.7510\n",
      "Baseline Loss: 2.6809 | Actual Loss: 2.5999\n",
      "Baseline Loss: 2.6819 | Actual Loss: 2.1791\n",
      "Baseline Loss: 2.7350 | Actual Loss: 0.6031\n",
      "Baseline Loss: 2.6707 | Actual Loss: 0.7539\n",
      "Baseline Loss: 2.6424 | Actual Loss: 0.4884\n",
      "Baseline Loss: 2.6386 | Actual Loss: 0.3853\n",
      "Baseline Loss: 2.6730 | Actual Loss: 0.6574\n",
      "Baseline Loss: 2.6725 | Actual Loss: 0.6063\n",
      "Baseline Loss: 2.6610 | Actual Loss: 0.3076\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.8322\n",
      "Baseline Loss: 2.6584 | Actual Loss: 2.7431\n",
      "Baseline Loss: 2.6492 | Actual Loss: 0.6561\n",
      "Baseline Loss: 2.6796 | Actual Loss: 0.2320\n",
      "Baseline Loss: 2.6478 | Actual Loss: 0.2923\n",
      "Baseline Loss: 2.2853 | Actual Loss: 0.3240\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.0030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 116/1000 [01:13<09:19,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6435 | Actual Loss: 0.5097\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.4391\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.7868\n",
      "Epoch 116/1000: Train Loss: 0.9007, Val Loss: 0.6846\n",
      "Baseline Loss: 2.6919 | Actual Loss: 0.6991\n",
      "Baseline Loss: 2.7014 | Actual Loss: 3.5075\n",
      "Baseline Loss: 2.6743 | Actual Loss: 0.5063\n",
      "Baseline Loss: 2.6334 | Actual Loss: 0.1954\n",
      "Baseline Loss: 2.6811 | Actual Loss: 0.3268\n",
      "Baseline Loss: 2.6830 | Actual Loss: 0.6436\n",
      "Baseline Loss: 2.7189 | Actual Loss: 0.7411\n",
      "Baseline Loss: 2.6606 | Actual Loss: 0.9554\n",
      "Baseline Loss: 2.6456 | Actual Loss: 0.5155\n",
      "Baseline Loss: 2.6768 | Actual Loss: 0.3624\n",
      "Baseline Loss: 2.6754 | Actual Loss: 0.7087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 117/1000 [01:13<09:00,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6367 | Actual Loss: 0.3106\n",
      "Baseline Loss: 2.6514 | Actual Loss: 0.3514\n",
      "Baseline Loss: 2.6883 | Actual Loss: 0.4539\n",
      "Baseline Loss: 2.6621 | Actual Loss: 1.1460\n",
      "Baseline Loss: 2.2419 | Actual Loss: 0.3305\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.0955\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4169\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3188\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.9510\n",
      "Epoch 117/1000: Train Loss: 0.7346, Val Loss: 0.6955\n",
      "Baseline Loss: 2.6706 | Actual Loss: 0.5033\n",
      "Baseline Loss: 2.6833 | Actual Loss: 0.4957\n",
      "Baseline Loss: 2.6565 | Actual Loss: 0.8259\n",
      "Baseline Loss: 2.7271 | Actual Loss: 0.9728\n",
      "Baseline Loss: 2.7090 | Actual Loss: 0.5572\n",
      "Baseline Loss: 2.6787 | Actual Loss: 0.7138\n",
      "Baseline Loss: 2.6961 | Actual Loss: 0.3738\n",
      "Baseline Loss: 2.6647 | Actual Loss: 0.2354\n",
      "Baseline Loss: 2.6862 | Actual Loss: 0.5178\n",
      "Baseline Loss: 2.6566 | Actual Loss: 0.5373\n",
      "Baseline Loss: 2.6557 | Actual Loss: 0.6829\n",
      "Baseline Loss: 2.6656 | Actual Loss: 0.5634\n",
      "Baseline Loss: 2.6849 | Actual Loss: 1.0336\n",
      "Baseline Loss: 2.6792 | Actual Loss: 0.3952\n",
      "Baseline Loss: 2.6971 | Actual Loss: 0.4737\n",
      "Baseline Loss: 2.2002 | Actual Loss: 0.3996\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.6889\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.5206\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.4716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 118/1000 [01:14<09:21,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5568 | Actual Loss: 0.6079\n",
      "Epoch 118/1000: Train Loss: 0.5801, Val Loss: 0.5723\n",
      "New best validation loss: 0.5723\n",
      "Baseline Loss: 2.7293 | Actual Loss: 0.3654\n",
      "Baseline Loss: 2.6815 | Actual Loss: 0.4546\n",
      "Baseline Loss: 2.6604 | Actual Loss: 0.5617\n",
      "Baseline Loss: 2.6712 | Actual Loss: 0.5723\n",
      "Baseline Loss: 2.6576 | Actual Loss: 1.3596\n",
      "Baseline Loss: 2.6513 | Actual Loss: 0.6860\n",
      "Baseline Loss: 2.6300 | Actual Loss: 0.6571\n",
      "Baseline Loss: 2.6928 | Actual Loss: 0.3985\n",
      "Baseline Loss: 2.6868 | Actual Loss: 0.3984\n",
      "Baseline Loss: 2.6685 | Actual Loss: 0.1338\n",
      "Baseline Loss: 2.6717 | Actual Loss: 0.6084\n",
      "Baseline Loss: 2.6691 | Actual Loss: 1.1275\n",
      "Baseline Loss: 2.6956 | Actual Loss: 0.5711\n",
      "Baseline Loss: 2.6597 | Actual Loss: 0.5400\n",
      "Baseline Loss: 2.6855 | Actual Loss: 0.6321\n",
      "Baseline Loss: 2.3541 | Actual Loss: 1.9536\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.0117\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.5295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 119/1000 [01:15<09:22,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7015 | Actual Loss: 0.3195\n",
      "Baseline Loss: 2.5568 | Actual Loss: 1.1748\n",
      "Epoch 119/1000: Train Loss: 0.6888, Val Loss: 0.7588\n",
      "Baseline Loss: 2.6673 | Actual Loss: 1.6147\n",
      "Baseline Loss: 2.6414 | Actual Loss: 2.5723\n",
      "Baseline Loss: 2.6553 | Actual Loss: 0.6092\n",
      "Baseline Loss: 2.6895 | Actual Loss: 0.5868\n",
      "Baseline Loss: 2.6494 | Actual Loss: 0.9719\n",
      "Baseline Loss: 2.6385 | Actual Loss: 0.7492\n",
      "Baseline Loss: 2.6532 | Actual Loss: 0.3387\n",
      "Baseline Loss: 2.7050 | Actual Loss: 0.6692\n",
      "Baseline Loss: 2.7054 | Actual Loss: 0.5872\n",
      "Baseline Loss: 2.6370 | Actual Loss: 0.8935\n",
      "Baseline Loss: 2.6841 | Actual Loss: 0.3687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 120/1000 [01:15<08:59,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6899 | Actual Loss: 1.0024\n",
      "Baseline Loss: 2.7103 | Actual Loss: 0.4104\n",
      "Baseline Loss: 2.6593 | Actual Loss: 0.7053\n",
      "Baseline Loss: 2.6714 | Actual Loss: 1.0749\n",
      "Baseline Loss: 2.2981 | Actual Loss: 0.0586\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9401\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.5101\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3938\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.9307\n",
      "Epoch 120/1000: Train Loss: 0.8258, Val Loss: 0.6937\n",
      "Baseline Loss: 2.6953 | Actual Loss: 0.5733\n",
      "Baseline Loss: 2.6725 | Actual Loss: 0.9999\n",
      "Baseline Loss: 2.6872 | Actual Loss: 0.7933\n",
      "Baseline Loss: 2.6746 | Actual Loss: 0.5861\n",
      "Baseline Loss: 2.6703 | Actual Loss: 0.9314\n",
      "Baseline Loss: 2.6728 | Actual Loss: 0.6292\n",
      "Baseline Loss: 2.6818 | Actual Loss: 0.2813\n",
      "Baseline Loss: 2.7126 | Actual Loss: 0.5343\n",
      "Baseline Loss: 2.6789 | Actual Loss: 0.5543\n",
      "Baseline Loss: 2.6248 | Actual Loss: 0.5197\n",
      "Baseline Loss: 2.7154 | Actual Loss: 0.5776\n",
      "Baseline Loss: 2.6724 | Actual Loss: 0.5619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 121/1000 [01:16<09:07,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6607 | Actual Loss: 0.9196\n",
      "Baseline Loss: 2.6586 | Actual Loss: 0.2580\n",
      "Baseline Loss: 2.6595 | Actual Loss: 0.2949\n",
      "Baseline Loss: 2.2541 | Actual Loss: 0.2520\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.8416\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.5449\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.4249\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.9797\n",
      "Epoch 121/1000: Train Loss: 0.5792, Val Loss: 0.6978\n",
      "Baseline Loss: 2.6702 | Actual Loss: 2.4151\n",
      "Baseline Loss: 2.6969 | Actual Loss: 0.9115\n",
      "Baseline Loss: 2.6634 | Actual Loss: 0.6910\n",
      "Baseline Loss: 2.6537 | Actual Loss: 0.4182\n",
      "Baseline Loss: 2.6432 | Actual Loss: 0.6605\n",
      "Baseline Loss: 2.6711 | Actual Loss: 0.3641\n",
      "Baseline Loss: 2.7141 | Actual Loss: 0.9172\n",
      "Baseline Loss: 2.6665 | Actual Loss: 0.2491\n",
      "Baseline Loss: 2.6938 | Actual Loss: 0.8178\n",
      "Baseline Loss: 2.6915 | Actual Loss: 0.3267\n",
      "Baseline Loss: 2.6427 | Actual Loss: 1.0024\n",
      "Baseline Loss: 2.6461 | Actual Loss: 0.5503\n",
      "Baseline Loss: 2.7100 | Actual Loss: 0.2118\n",
      "Baseline Loss: 2.6616 | Actual Loss: 0.5767\n",
      "Baseline Loss: 2.6840 | Actual Loss: 2.5974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 122/1000 [01:16<08:55,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2194 | Actual Loss: 0.1454\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.0074\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4333\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.2709\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.6821\n",
      "Epoch 122/1000: Train Loss: 0.8035, Val Loss: 0.5984\n",
      "Baseline Loss: 2.6310 | Actual Loss: 0.5163\n",
      "Baseline Loss: 2.6492 | Actual Loss: 2.2875\n",
      "Baseline Loss: 2.6329 | Actual Loss: 0.4383\n",
      "Baseline Loss: 2.6719 | Actual Loss: 2.3459\n",
      "Baseline Loss: 2.7224 | Actual Loss: 0.9410\n",
      "Baseline Loss: 2.6899 | Actual Loss: 0.2484\n",
      "Baseline Loss: 2.7007 | Actual Loss: 0.6715\n",
      "Baseline Loss: 2.6894 | Actual Loss: 0.6049\n",
      "Baseline Loss: 2.6729 | Actual Loss: 0.7189\n",
      "Baseline Loss: 2.6977 | Actual Loss: 0.5210\n",
      "Baseline Loss: 2.6686 | Actual Loss: 0.2608\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.6387\n",
      "Baseline Loss: 2.6607 | Actual Loss: 0.4447\n",
      "Baseline Loss: 2.6446 | Actual Loss: 0.2843\n",
      "Baseline Loss: 2.6733 | Actual Loss: 1.3353\n",
      "Baseline Loss: 2.2637 | Actual Loss: 0.6066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 123/1000 [01:17<09:04,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7315 | Actual Loss: 1.1455\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4672\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.2522\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.5120\n",
      "Epoch 123/1000: Train Loss: 0.8040, Val Loss: 0.5942\n",
      "Baseline Loss: 2.6683 | Actual Loss: 0.6919\n",
      "Baseline Loss: 2.6786 | Actual Loss: 0.3134\n",
      "Baseline Loss: 2.6927 | Actual Loss: 0.9863\n",
      "Baseline Loss: 2.6609 | Actual Loss: 0.9385\n",
      "Baseline Loss: 2.6488 | Actual Loss: 0.4457\n",
      "Baseline Loss: 2.6743 | Actual Loss: 0.3183\n",
      "Baseline Loss: 2.6274 | Actual Loss: 0.4626\n",
      "Baseline Loss: 2.6721 | Actual Loss: 0.4838\n",
      "Baseline Loss: 2.7256 | Actual Loss: 0.6477\n",
      "Baseline Loss: 2.6513 | Actual Loss: 0.2513\n",
      "Baseline Loss: 2.6687 | Actual Loss: 0.3775\n",
      "Baseline Loss: 2.7089 | Actual Loss: 2.5080\n",
      "Baseline Loss: 2.6639 | Actual Loss: 0.5530\n",
      "Baseline Loss: 2.7063 | Actual Loss: 0.6510\n",
      "Baseline Loss: 2.6469 | Actual Loss: 0.3635\n",
      "Baseline Loss: 2.3535 | Actual Loss: 1.4230\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.0559\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3521\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.2083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 124/1000 [01:18<09:00,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5568 | Actual Loss: 0.5053\n",
      "Epoch 124/1000: Train Loss: 0.7135, Val Loss: 0.5304\n",
      "New best validation loss: 0.5304\n",
      "Baseline Loss: 2.6635 | Actual Loss: 0.6139\n",
      "Baseline Loss: 2.6703 | Actual Loss: 0.1365\n",
      "Baseline Loss: 2.6673 | Actual Loss: 0.3912\n",
      "Baseline Loss: 2.6769 | Actual Loss: 0.5382\n",
      "Baseline Loss: 2.6424 | Actual Loss: 0.8285\n",
      "Baseline Loss: 2.7133 | Actual Loss: 0.3197\n",
      "Baseline Loss: 2.6442 | Actual Loss: 1.2962\n",
      "Baseline Loss: 2.6448 | Actual Loss: 0.9151\n",
      "Baseline Loss: 2.6741 | Actual Loss: 0.4493\n",
      "Baseline Loss: 2.6946 | Actual Loss: 0.4152\n",
      "Baseline Loss: 2.6823 | Actual Loss: 0.7579\n",
      "Baseline Loss: 2.7217 | Actual Loss: 0.6675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▎        | 125/1000 [01:18<09:04,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6351 | Actual Loss: 0.7467\n",
      "Baseline Loss: 2.6793 | Actual Loss: 0.5383\n",
      "Baseline Loss: 2.6810 | Actual Loss: 0.6921\n",
      "Baseline Loss: 2.2632 | Actual Loss: 0.2848\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9148\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.5135\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.2257\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.4846\n",
      "Epoch 125/1000: Train Loss: 0.5994, Val Loss: 0.5346\n",
      "Baseline Loss: 2.6648 | Actual Loss: 0.4323\n",
      "Baseline Loss: 2.6625 | Actual Loss: 0.5617\n",
      "Baseline Loss: 2.6861 | Actual Loss: 1.0725\n",
      "Baseline Loss: 2.6994 | Actual Loss: 0.4876\n",
      "Baseline Loss: 2.6889 | Actual Loss: 1.8001\n",
      "Baseline Loss: 2.6830 | Actual Loss: 0.2187\n",
      "Baseline Loss: 2.7076 | Actual Loss: 0.2740\n",
      "Baseline Loss: 2.6733 | Actual Loss: 0.3077\n",
      "Baseline Loss: 2.6758 | Actual Loss: 2.4531\n",
      "Baseline Loss: 2.6757 | Actual Loss: 0.4669\n",
      "Baseline Loss: 2.6683 | Actual Loss: 3.2424\n",
      "Baseline Loss: 2.6499 | Actual Loss: 0.7192\n",
      "Baseline Loss: 2.6726 | Actual Loss: 0.7029\n",
      "Baseline Loss: 2.7038 | Actual Loss: 0.6301\n",
      "Baseline Loss: 2.6392 | Actual Loss: 0.6240\n",
      "Baseline Loss: 2.1856 | Actual Loss: 0.6060\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.0367\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 126/1000 [01:19<09:21,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7015 | Actual Loss: 0.2180\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.5807\n",
      "Epoch 126/1000: Train Loss: 0.9124, Val Loss: 0.5478\n",
      "Baseline Loss: 2.6402 | Actual Loss: 0.4923\n",
      "Baseline Loss: 2.6896 | Actual Loss: 1.2114\n",
      "Baseline Loss: 2.6810 | Actual Loss: 1.0648\n",
      "Baseline Loss: 2.6544 | Actual Loss: 0.5026\n",
      "Baseline Loss: 2.7056 | Actual Loss: 2.6012\n",
      "Baseline Loss: 2.6616 | Actual Loss: 0.5881\n",
      "Baseline Loss: 2.6843 | Actual Loss: 0.4347\n",
      "Baseline Loss: 2.6578 | Actual Loss: 0.9764\n",
      "Baseline Loss: 2.6620 | Actual Loss: 0.4148\n",
      "Baseline Loss: 2.6656 | Actual Loss: 0.2925\n",
      "Baseline Loss: 2.7094 | Actual Loss: 0.5932\n",
      "Baseline Loss: 2.6401 | Actual Loss: 0.1385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 127/1000 [01:20<09:12,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7221 | Actual Loss: 0.3476\n",
      "Baseline Loss: 2.6528 | Actual Loss: 0.6673\n",
      "Baseline Loss: 2.6869 | Actual Loss: 0.7294\n",
      "Baseline Loss: 2.2936 | Actual Loss: 0.3689\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.8362\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3191\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3098\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.7523\n",
      "Epoch 127/1000: Train Loss: 0.7140, Val Loss: 0.5544\n",
      "Baseline Loss: 2.6542 | Actual Loss: 0.3213\n",
      "Baseline Loss: 2.6830 | Actual Loss: 0.5043\n",
      "Baseline Loss: 2.6489 | Actual Loss: 0.4358\n",
      "Baseline Loss: 2.6394 | Actual Loss: 0.3754\n",
      "Baseline Loss: 2.6613 | Actual Loss: 0.2820\n",
      "Baseline Loss: 2.7396 | Actual Loss: 0.2698\n",
      "Baseline Loss: 2.6538 | Actual Loss: 0.3282\n",
      "Baseline Loss: 2.6830 | Actual Loss: 1.1105\n",
      "Baseline Loss: 2.7164 | Actual Loss: 0.5128\n",
      "Baseline Loss: 2.6782 | Actual Loss: 0.7151\n",
      "Baseline Loss: 2.7047 | Actual Loss: 0.9827\n",
      "Baseline Loss: 2.6977 | Actual Loss: 0.1536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 128/1000 [01:20<09:12,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6556 | Actual Loss: 0.6470\n",
      "Baseline Loss: 2.6669 | Actual Loss: 0.2301\n",
      "Baseline Loss: 2.6399 | Actual Loss: 0.9989\n",
      "Baseline Loss: 2.2294 | Actual Loss: 0.2470\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9259\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4969\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.4283\n",
      "Baseline Loss: 2.5568 | Actual Loss: 1.0073\n",
      "Epoch 128/1000: Train Loss: 0.5072, Val Loss: 0.7146\n",
      "Baseline Loss: 2.6728 | Actual Loss: 0.4094\n",
      "Baseline Loss: 2.6659 | Actual Loss: 0.8416\n",
      "Baseline Loss: 2.6616 | Actual Loss: 0.9229\n",
      "Baseline Loss: 2.6321 | Actual Loss: 0.3191\n",
      "Baseline Loss: 2.6754 | Actual Loss: 0.2215\n",
      "Baseline Loss: 2.7299 | Actual Loss: 1.0844\n",
      "Baseline Loss: 2.6039 | Actual Loss: 1.4230\n",
      "Baseline Loss: 2.6855 | Actual Loss: 0.8422\n",
      "Baseline Loss: 2.6573 | Actual Loss: 0.6742\n",
      "Baseline Loss: 2.6579 | Actual Loss: 0.5302\n",
      "Baseline Loss: 2.7081 | Actual Loss: 0.3458\n",
      "Baseline Loss: 2.6575 | Actual Loss: 0.2340\n",
      "Baseline Loss: 2.7088 | Actual Loss: 1.4891\n",
      "Baseline Loss: 2.6484 | Actual Loss: 0.3646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 129/1000 [01:21<08:50,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7022 | Actual Loss: 0.1696\n",
      "Baseline Loss: 2.3724 | Actual Loss: 2.6309\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.7640\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.5246\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.4956\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.5592\n",
      "Epoch 129/1000: Train Loss: 0.7814, Val Loss: 0.5858\n",
      "Baseline Loss: 2.6544 | Actual Loss: 0.5353\n",
      "Baseline Loss: 2.6558 | Actual Loss: 0.6238\n",
      "Baseline Loss: 2.6574 | Actual Loss: 0.4891\n",
      "Baseline Loss: 2.6866 | Actual Loss: 1.9772\n",
      "Baseline Loss: 2.6650 | Actual Loss: 0.1703\n",
      "Baseline Loss: 2.6803 | Actual Loss: 0.7022\n",
      "Baseline Loss: 2.6826 | Actual Loss: 0.5481\n",
      "Baseline Loss: 2.6685 | Actual Loss: 1.3014\n",
      "Baseline Loss: 2.6856 | Actual Loss: 0.6694\n",
      "Baseline Loss: 2.7086 | Actual Loss: 0.4017\n",
      "Baseline Loss: 2.6490 | Actual Loss: 0.3794\n",
      "Baseline Loss: 2.7053 | Actual Loss: 0.4589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 130/1000 [01:22<09:16,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6594 | Actual Loss: 0.5922\n",
      "Baseline Loss: 2.6563 | Actual Loss: 0.5202\n",
      "Baseline Loss: 2.6486 | Actual Loss: 0.9278\n",
      "Baseline Loss: 2.3089 | Actual Loss: 0.4604\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.7287\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.5532\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.5423\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.9663\n",
      "Epoch 130/1000: Train Loss: 0.6723, Val Loss: 0.6976\n",
      "Baseline Loss: 2.6478 | Actual Loss: 0.8395\n",
      "Baseline Loss: 2.7601 | Actual Loss: 0.8478\n",
      "Baseline Loss: 2.6552 | Actual Loss: 0.6127\n",
      "Baseline Loss: 2.6913 | Actual Loss: 0.6010\n",
      "Baseline Loss: 2.6475 | Actual Loss: 0.4074\n",
      "Baseline Loss: 2.6705 | Actual Loss: 0.7015\n",
      "Baseline Loss: 2.7041 | Actual Loss: 0.6431\n",
      "Baseline Loss: 2.6586 | Actual Loss: 0.3076\n",
      "Baseline Loss: 2.6893 | Actual Loss: 0.6477\n",
      "Baseline Loss: 2.6797 | Actual Loss: 0.5684\n",
      "Baseline Loss: 2.7096 | Actual Loss: 1.0123\n",
      "Baseline Loss: 2.6548 | Actual Loss: 0.4447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 131/1000 [01:22<09:14,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6519 | Actual Loss: 0.9458\n",
      "Baseline Loss: 2.6810 | Actual Loss: 0.7405\n",
      "Baseline Loss: 2.6660 | Actual Loss: 0.5810\n",
      "Baseline Loss: 2.2754 | Actual Loss: 0.2823\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.6938\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.5581\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.5543\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.9923\n",
      "Epoch 131/1000: Train Loss: 0.6365, Val Loss: 0.6996\n",
      "Baseline Loss: 2.6376 | Actual Loss: 0.7355\n",
      "Baseline Loss: 2.6582 | Actual Loss: 0.7497\n",
      "Baseline Loss: 2.6518 | Actual Loss: 0.4087\n",
      "Baseline Loss: 2.6528 | Actual Loss: 0.4785\n",
      "Baseline Loss: 2.7058 | Actual Loss: 0.7836\n",
      "Baseline Loss: 2.6732 | Actual Loss: 0.5622\n",
      "Baseline Loss: 2.6877 | Actual Loss: 0.4822\n",
      "Baseline Loss: 2.7290 | Actual Loss: 0.4832\n",
      "Baseline Loss: 2.6259 | Actual Loss: 1.1279\n",
      "Baseline Loss: 2.6767 | Actual Loss: 0.4024\n",
      "Baseline Loss: 2.6649 | Actual Loss: 0.7478\n",
      "Baseline Loss: 2.7016 | Actual Loss: 1.4074\n",
      "Baseline Loss: 2.6671 | Actual Loss: 0.5689\n",
      "Baseline Loss: 2.7057 | Actual Loss: 0.2448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 132/1000 [01:23<09:16,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6579 | Actual Loss: 0.2555\n",
      "Baseline Loss: 2.2470 | Actual Loss: 0.3163\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.0080\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4769\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.4606\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.6240\n",
      "Epoch 132/1000: Train Loss: 0.6097, Val Loss: 0.6424\n",
      "Baseline Loss: 2.6740 | Actual Loss: 0.3827\n",
      "Baseline Loss: 2.7551 | Actual Loss: 0.6981\n",
      "Baseline Loss: 2.6506 | Actual Loss: 0.7775\n",
      "Baseline Loss: 2.6796 | Actual Loss: 1.1244\n",
      "Baseline Loss: 2.6449 | Actual Loss: 0.9796\n",
      "Baseline Loss: 2.6921 | Actual Loss: 0.3071\n",
      "Baseline Loss: 2.6966 | Actual Loss: 0.5326\n",
      "Baseline Loss: 2.6427 | Actual Loss: 0.5881\n",
      "Baseline Loss: 2.6793 | Actual Loss: 0.6731\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.5236\n",
      "Baseline Loss: 2.6504 | Actual Loss: 0.5586\n",
      "Baseline Loss: 2.6731 | Actual Loss: 2.5777\n",
      "Baseline Loss: 2.6372 | Actual Loss: 0.4539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 133/1000 [01:23<09:07,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6947 | Actual Loss: 0.4407\n",
      "Baseline Loss: 2.6761 | Actual Loss: 0.3846\n",
      "Baseline Loss: 2.3129 | Actual Loss: 0.3563\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.0509\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4889\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3704\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.7793\n",
      "Epoch 133/1000: Train Loss: 0.7099, Val Loss: 0.6724\n",
      "Baseline Loss: 2.6500 | Actual Loss: 0.7423\n",
      "Baseline Loss: 2.6727 | Actual Loss: 0.5985\n",
      "Baseline Loss: 2.6571 | Actual Loss: 0.3761\n",
      "Baseline Loss: 2.6925 | Actual Loss: 0.7143\n",
      "Baseline Loss: 2.6782 | Actual Loss: 0.4999\n",
      "Baseline Loss: 2.6839 | Actual Loss: 0.4264\n",
      "Baseline Loss: 2.6708 | Actual Loss: 0.4569\n",
      "Baseline Loss: 2.6866 | Actual Loss: 0.6760\n",
      "Baseline Loss: 2.6353 | Actual Loss: 0.8372\n",
      "Baseline Loss: 2.6824 | Actual Loss: 0.2217\n",
      "Baseline Loss: 2.6808 | Actual Loss: 1.2521\n",
      "Baseline Loss: 2.7108 | Actual Loss: 0.8185\n",
      "Baseline Loss: 2.6572 | Actual Loss: 0.6021\n",
      "Baseline Loss: 2.6646 | Actual Loss: 0.8898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 134/1000 [01:24<09:11,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7216 | Actual Loss: 0.2391\n",
      "Baseline Loss: 2.2395 | Actual Loss: 0.4315\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.8606\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4833\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.4491\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.8813\n",
      "Epoch 134/1000: Train Loss: 0.6114, Val Loss: 0.6686\n",
      "Baseline Loss: 2.6828 | Actual Loss: 0.6806\n",
      "Baseline Loss: 2.6919 | Actual Loss: 0.4465\n",
      "Baseline Loss: 2.6140 | Actual Loss: 0.7076\n",
      "Baseline Loss: 2.6712 | Actual Loss: 0.7464\n",
      "Baseline Loss: 2.6324 | Actual Loss: 2.5267\n",
      "Baseline Loss: 2.6665 | Actual Loss: 0.4491\n",
      "Baseline Loss: 2.6547 | Actual Loss: 0.2472\n",
      "Baseline Loss: 2.6725 | Actual Loss: 0.6015\n",
      "Baseline Loss: 2.6862 | Actual Loss: 0.2770\n",
      "Baseline Loss: 2.6536 | Actual Loss: 0.5515\n",
      "Baseline Loss: 2.6949 | Actual Loss: 0.3592\n",
      "Baseline Loss: 2.6675 | Actual Loss: 2.0072\n",
      "Baseline Loss: 2.7109 | Actual Loss: 0.9366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▎        | 135/1000 [01:25<09:10,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6932 | Actual Loss: 0.7233\n",
      "Baseline Loss: 2.7081 | Actual Loss: 0.7958\n",
      "Baseline Loss: 2.2879 | Actual Loss: 0.4672\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.7313\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4280\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.5157\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.7014\n",
      "Epoch 135/1000: Train Loss: 0.7827, Val Loss: 0.5941\n",
      "Baseline Loss: 2.6949 | Actual Loss: 0.5414\n",
      "Baseline Loss: 2.6813 | Actual Loss: 0.3169\n",
      "Baseline Loss: 2.6849 | Actual Loss: 0.2967\n",
      "Baseline Loss: 2.6616 | Actual Loss: 0.2673\n",
      "Baseline Loss: 2.7070 | Actual Loss: 0.9091\n",
      "Baseline Loss: 2.6741 | Actual Loss: 0.4355\n",
      "Baseline Loss: 2.6806 | Actual Loss: 0.8566\n",
      "Baseline Loss: 2.6300 | Actual Loss: 0.4435\n",
      "Baseline Loss: 2.6750 | Actual Loss: 0.5965\n",
      "Baseline Loss: 2.6509 | Actual Loss: 0.8751\n",
      "Baseline Loss: 2.6603 | Actual Loss: 0.2829\n",
      "Baseline Loss: 2.6565 | Actual Loss: 3.0496\n",
      "Baseline Loss: 2.6418 | Actual Loss: 0.6306\n",
      "Baseline Loss: 2.6847 | Actual Loss: 0.8029\n",
      "Baseline Loss: 2.6999 | Actual Loss: 0.5327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▎        | 136/1000 [01:25<09:23,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2308 | Actual Loss: 0.1517\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9016\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4222\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.5596\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.9317\n",
      "Epoch 136/1000: Train Loss: 0.6868, Val Loss: 0.7038\n",
      "Baseline Loss: 2.6252 | Actual Loss: 1.2644\n",
      "Baseline Loss: 2.6885 | Actual Loss: 0.9774\n",
      "Baseline Loss: 2.6645 | Actual Loss: 2.2280\n",
      "Baseline Loss: 2.6660 | Actual Loss: 0.6420\n",
      "Baseline Loss: 2.6749 | Actual Loss: 0.7877\n",
      "Baseline Loss: 2.6723 | Actual Loss: 0.3536\n",
      "Baseline Loss: 2.6808 | Actual Loss: 0.6218\n",
      "Baseline Loss: 2.6456 | Actual Loss: 0.2883\n",
      "Baseline Loss: 2.6265 | Actual Loss: 0.4737\n",
      "Baseline Loss: 2.6639 | Actual Loss: 0.6355\n",
      "Baseline Loss: 2.6584 | Actual Loss: 0.6679\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3693\n",
      "Baseline Loss: 2.7028 | Actual Loss: 0.3387\n",
      "Baseline Loss: 2.6961 | Actual Loss: 0.2226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▎        | 137/1000 [01:26<09:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6632 | Actual Loss: 0.3563\n",
      "Baseline Loss: 2.3735 | Actual Loss: 1.8290\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9959\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4603\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.4042\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.5905\n",
      "Epoch 137/1000: Train Loss: 0.7535, Val Loss: 0.6127\n",
      "Baseline Loss: 2.6817 | Actual Loss: 0.3857\n",
      "Baseline Loss: 2.6668 | Actual Loss: 0.9047\n",
      "Baseline Loss: 2.6507 | Actual Loss: 0.5057\n",
      "Baseline Loss: 2.6562 | Actual Loss: 0.4480\n",
      "Baseline Loss: 2.6813 | Actual Loss: 0.5419\n",
      "Baseline Loss: 2.6570 | Actual Loss: 0.5624\n",
      "Baseline Loss: 2.6640 | Actual Loss: 0.2057\n",
      "Baseline Loss: 2.6401 | Actual Loss: 0.2947\n",
      "Baseline Loss: 2.6793 | Actual Loss: 0.2261\n",
      "Baseline Loss: 2.6695 | Actual Loss: 1.0480\n",
      "Baseline Loss: 2.6525 | Actual Loss: 0.4906\n",
      "Baseline Loss: 2.7186 | Actual Loss: 0.6195\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4959\n",
      "Baseline Loss: 2.6911 | Actual Loss: 1.6280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 138/1000 [01:27<09:14,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7271 | Actual Loss: 0.4642\n",
      "Baseline Loss: 2.3218 | Actual Loss: 0.0583\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.8392\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4938\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3608\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.6298\n",
      "Epoch 138/1000: Train Loss: 0.5550, Val Loss: 0.5809\n",
      "Baseline Loss: 2.6833 | Actual Loss: 0.7481\n",
      "Baseline Loss: 2.6786 | Actual Loss: 0.4967\n",
      "Baseline Loss: 2.6626 | Actual Loss: 0.8516\n",
      "Baseline Loss: 2.6827 | Actual Loss: 2.0873\n",
      "Baseline Loss: 2.6753 | Actual Loss: 0.4046\n",
      "Baseline Loss: 2.6698 | Actual Loss: 0.4596\n",
      "Baseline Loss: 2.6548 | Actual Loss: 0.3896\n",
      "Baseline Loss: 2.6886 | Actual Loss: 0.1565\n",
      "Baseline Loss: 2.6328 | Actual Loss: 0.5084\n",
      "Baseline Loss: 2.6717 | Actual Loss: 0.6695\n",
      "Baseline Loss: 2.6875 | Actual Loss: 0.2944\n",
      "Baseline Loss: 2.6486 | Actual Loss: 0.4487\n",
      "Baseline Loss: 2.6591 | Actual Loss: 0.8834\n",
      "Baseline Loss: 2.6416 | Actual Loss: 0.4179\n",
      "Baseline Loss: 2.7121 | Actual Loss: 0.3260\n",
      "Baseline Loss: 2.2725 | Actual Loss: 1.2285\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 139/1000 [01:27<09:15,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6435 | Actual Loss: 0.4498\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.4052\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.8114\n",
      "Epoch 139/1000: Train Loss: 0.6482, Val Loss: 0.6491\n",
      "Baseline Loss: 2.6558 | Actual Loss: 0.5708\n",
      "Baseline Loss: 2.7100 | Actual Loss: 0.2226\n",
      "Baseline Loss: 2.7109 | Actual Loss: 0.5402\n",
      "Baseline Loss: 2.7028 | Actual Loss: 0.3697\n",
      "Baseline Loss: 2.6982 | Actual Loss: 0.6678\n",
      "Baseline Loss: 2.6517 | Actual Loss: 0.4006\n",
      "Baseline Loss: 2.6692 | Actual Loss: 0.7550\n",
      "Baseline Loss: 2.6203 | Actual Loss: 0.4854\n",
      "Baseline Loss: 2.6578 | Actual Loss: 0.7114\n",
      "Baseline Loss: 2.6729 | Actual Loss: 0.5408\n",
      "Baseline Loss: 2.6601 | Actual Loss: 0.4266\n",
      "Baseline Loss: 2.6547 | Actual Loss: 0.8748\n",
      "Baseline Loss: 2.6810 | Actual Loss: 0.4059\n",
      "Baseline Loss: 2.6739 | Actual Loss: 0.4561\n",
      "Baseline Loss: 2.6838 | Actual Loss: 0.6404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 140/1000 [01:28<08:55,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2537 | Actual Loss: 0.1937\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.8253\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3980\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3566\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.7418\n",
      "Epoch 140/1000: Train Loss: 0.5164, Val Loss: 0.5804\n",
      "Baseline Loss: 2.6569 | Actual Loss: 0.5894\n",
      "Baseline Loss: 2.6760 | Actual Loss: 0.6108\n",
      "Baseline Loss: 2.6941 | Actual Loss: 0.4137\n",
      "Baseline Loss: 2.7066 | Actual Loss: 0.1258\n",
      "Baseline Loss: 2.6675 | Actual Loss: 0.6992\n",
      "Baseline Loss: 2.6639 | Actual Loss: 0.4221\n",
      "Baseline Loss: 2.6240 | Actual Loss: 1.0424\n",
      "Baseline Loss: 2.6227 | Actual Loss: 0.1512\n",
      "Baseline Loss: 2.6750 | Actual Loss: 0.2419\n",
      "Baseline Loss: 2.7040 | Actual Loss: 0.4449\n",
      "Baseline Loss: 2.6582 | Actual Loss: 0.6334\n",
      "Baseline Loss: 2.6462 | Actual Loss: 0.5935\n",
      "Baseline Loss: 2.6848 | Actual Loss: 1.0839\n",
      "Baseline Loss: 2.7026 | Actual Loss: 0.5930\n",
      "Baseline Loss: 2.7112 | Actual Loss: 0.5206\n",
      "Baseline Loss: 2.2348 | Actual Loss: 0.4599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 141/1000 [01:29<09:04,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7315 | Actual Loss: 1.0477\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3636\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3369\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.5719\n",
      "Epoch 141/1000: Train Loss: 0.5391, Val Loss: 0.5800\n",
      "Baseline Loss: 2.7169 | Actual Loss: 0.4124\n",
      "Baseline Loss: 2.6395 | Actual Loss: 0.5388\n",
      "Baseline Loss: 2.7139 | Actual Loss: 0.8362\n",
      "Baseline Loss: 2.6484 | Actual Loss: 0.7661\n",
      "Baseline Loss: 2.6786 | Actual Loss: 0.1365\n",
      "Baseline Loss: 2.6739 | Actual Loss: 0.8508\n",
      "Baseline Loss: 2.6618 | Actual Loss: 0.7194\n",
      "Baseline Loss: 2.6682 | Actual Loss: 0.2239\n",
      "Baseline Loss: 2.7098 | Actual Loss: 0.4517\n",
      "Baseline Loss: 2.7065 | Actual Loss: 0.6104\n",
      "Baseline Loss: 2.6467 | Actual Loss: 0.7577\n",
      "Baseline Loss: 2.6898 | Actual Loss: 0.6049\n",
      "Baseline Loss: 2.7065 | Actual Loss: 0.6488\n",
      "Baseline Loss: 2.6605 | Actual Loss: 0.6942\n",
      "Baseline Loss: 2.6401 | Actual Loss: 0.5294\n",
      "Baseline Loss: 2.2786 | Actual Loss: 0.1183\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9834\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4559\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 142/1000 [01:29<09:08,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5568 | Actual Loss: 0.4602\n",
      "Epoch 142/1000: Train Loss: 0.5562, Val Loss: 0.5670\n",
      "Baseline Loss: 2.6952 | Actual Loss: 0.6700\n",
      "Baseline Loss: 2.6919 | Actual Loss: 0.2032\n",
      "Baseline Loss: 2.6839 | Actual Loss: 0.2531\n",
      "Baseline Loss: 2.6571 | Actual Loss: 0.7202\n",
      "Baseline Loss: 2.6881 | Actual Loss: 0.3819\n",
      "Baseline Loss: 2.6582 | Actual Loss: 0.6333\n",
      "Baseline Loss: 2.6689 | Actual Loss: 0.1310\n",
      "Baseline Loss: 2.6485 | Actual Loss: 0.3712\n",
      "Baseline Loss: 2.6814 | Actual Loss: 0.7990\n",
      "Baseline Loss: 2.6759 | Actual Loss: 0.4151\n",
      "Baseline Loss: 2.7014 | Actual Loss: 1.2676\n",
      "Baseline Loss: 2.7153 | Actual Loss: 1.2353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 143/1000 [01:30<08:47,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6950 | Actual Loss: 0.4919\n",
      "Baseline Loss: 2.6296 | Actual Loss: 0.8856\n",
      "Baseline Loss: 2.6745 | Actual Loss: 0.5638\n",
      "Baseline Loss: 2.2915 | Actual Loss: 0.3224\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9384\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4359\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.4069\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.5878\n",
      "Epoch 143/1000: Train Loss: 0.5840, Val Loss: 0.5923\n",
      "Baseline Loss: 2.7067 | Actual Loss: 0.6901\n",
      "Baseline Loss: 2.6610 | Actual Loss: 0.4773\n",
      "Baseline Loss: 2.6220 | Actual Loss: 0.6155\n",
      "Baseline Loss: 2.6789 | Actual Loss: 2.4351\n",
      "Baseline Loss: 2.6590 | Actual Loss: 0.6354\n",
      "Baseline Loss: 2.6805 | Actual Loss: 0.2316\n",
      "Baseline Loss: 2.6930 | Actual Loss: 0.6434\n",
      "Baseline Loss: 2.6693 | Actual Loss: 0.6991\n",
      "Baseline Loss: 2.6957 | Actual Loss: 0.5061\n",
      "Baseline Loss: 2.6785 | Actual Loss: 0.8897\n",
      "Baseline Loss: 2.7047 | Actual Loss: 0.3887\n",
      "Baseline Loss: 2.6862 | Actual Loss: 0.4410\n",
      "Baseline Loss: 2.6979 | Actual Loss: 0.5063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 144/1000 [01:30<08:57,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6614 | Actual Loss: 0.7407\n",
      "Baseline Loss: 2.6387 | Actual Loss: 0.3910\n",
      "Baseline Loss: 2.3041 | Actual Loss: 1.0717\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.7838\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4398\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.4163\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.9725\n",
      "Epoch 144/1000: Train Loss: 0.7102, Val Loss: 0.6531\n",
      "Baseline Loss: 2.7002 | Actual Loss: 1.0658\n",
      "Baseline Loss: 2.6567 | Actual Loss: 0.5686\n",
      "Baseline Loss: 2.6899 | Actual Loss: 1.1253\n",
      "Baseline Loss: 2.6448 | Actual Loss: 0.5608\n",
      "Baseline Loss: 2.7005 | Actual Loss: 0.5576\n",
      "Baseline Loss: 2.6659 | Actual Loss: 0.0920\n",
      "Baseline Loss: 2.6928 | Actual Loss: 0.6309\n",
      "Baseline Loss: 2.6806 | Actual Loss: 0.8434\n",
      "Baseline Loss: 2.6654 | Actual Loss: 0.7671\n",
      "Baseline Loss: 2.6797 | Actual Loss: 0.5616\n",
      "Baseline Loss: 2.6770 | Actual Loss: 0.3009\n",
      "Baseline Loss: 2.6687 | Actual Loss: 0.4418\n",
      "Baseline Loss: 2.6585 | Actual Loss: 0.3750\n",
      "Baseline Loss: 2.6551 | Actual Loss: 0.1959\n",
      "Baseline Loss: 2.6517 | Actual Loss: 0.3556\n",
      "Baseline Loss: 2.2624 | Actual Loss: 0.8991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 145/1000 [01:31<08:43,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7315 | Actual Loss: 1.0335\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4843\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.4393\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.6761\n",
      "Epoch 145/1000: Train Loss: 0.5838, Val Loss: 0.6583\n",
      "Baseline Loss: 2.6633 | Actual Loss: 0.2795\n",
      "Baseline Loss: 2.6716 | Actual Loss: 0.4025\n",
      "Baseline Loss: 2.6624 | Actual Loss: 0.5315\n",
      "Baseline Loss: 2.6879 | Actual Loss: 0.3923\n",
      "Baseline Loss: 2.6973 | Actual Loss: 0.3410\n",
      "Baseline Loss: 2.6605 | Actual Loss: 0.6458\n",
      "Baseline Loss: 2.6575 | Actual Loss: 1.2956\n",
      "Baseline Loss: 2.6735 | Actual Loss: 0.5961\n",
      "Baseline Loss: 2.7062 | Actual Loss: 0.8765\n",
      "Baseline Loss: 2.7131 | Actual Loss: 0.5068\n",
      "Baseline Loss: 2.6676 | Actual Loss: 0.4405\n",
      "Baseline Loss: 2.6493 | Actual Loss: 0.5901\n",
      "Baseline Loss: 2.7011 | Actual Loss: 0.4756\n",
      "Baseline Loss: 2.7145 | Actual Loss: 0.4248\n",
      "Baseline Loss: 2.6224 | Actual Loss: 0.8505\n",
      "Baseline Loss: 2.2809 | Actual Loss: 0.4701\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.6793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 146/1000 [01:32<08:46,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6435 | Actual Loss: 0.5394\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.4419\n",
      "Baseline Loss: 2.5568 | Actual Loss: 1.0409\n",
      "Epoch 146/1000: Train Loss: 0.5700, Val Loss: 0.6754\n",
      "Baseline Loss: 2.6647 | Actual Loss: 0.6251\n",
      "Baseline Loss: 2.6818 | Actual Loss: 0.2978\n",
      "Baseline Loss: 2.6869 | Actual Loss: 0.7094\n",
      "Baseline Loss: 2.6571 | Actual Loss: 0.9065\n",
      "Baseline Loss: 2.6602 | Actual Loss: 0.6814\n",
      "Baseline Loss: 2.6620 | Actual Loss: 0.6459\n",
      "Baseline Loss: 2.6824 | Actual Loss: 0.5885\n",
      "Baseline Loss: 2.6468 | Actual Loss: 0.3093\n",
      "Baseline Loss: 2.6745 | Actual Loss: 0.9920\n",
      "Baseline Loss: 2.6572 | Actual Loss: 0.3688\n",
      "Baseline Loss: 2.6615 | Actual Loss: 0.7812\n",
      "Baseline Loss: 2.6839 | Actual Loss: 0.4194\n",
      "Baseline Loss: 2.6948 | Actual Loss: 0.4920\n",
      "Baseline Loss: 2.6727 | Actual Loss: 0.4676\n",
      "Baseline Loss: 2.6782 | Actual Loss: 0.8432\n",
      "Baseline Loss: 2.2993 | Actual Loss: 0.2887\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.6982\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.5371\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 147/1000 [01:32<08:43,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5568 | Actual Loss: 0.6112\n",
      "Epoch 147/1000: Train Loss: 0.5886, Val Loss: 0.5613\n",
      "Baseline Loss: 2.6608 | Actual Loss: 0.2586\n",
      "Baseline Loss: 2.6697 | Actual Loss: 0.7186\n",
      "Baseline Loss: 2.6580 | Actual Loss: 0.7424\n",
      "Baseline Loss: 2.6714 | Actual Loss: 0.5449\n",
      "Baseline Loss: 2.6761 | Actual Loss: 0.3951\n",
      "Baseline Loss: 2.6813 | Actual Loss: 0.7015\n",
      "Baseline Loss: 2.7052 | Actual Loss: 0.2724\n",
      "Baseline Loss: 2.6559 | Actual Loss: 0.8436\n",
      "Baseline Loss: 2.6529 | Actual Loss: 0.6214\n",
      "Baseline Loss: 2.6912 | Actual Loss: 0.7582\n",
      "Baseline Loss: 2.7159 | Actual Loss: 0.2026\n",
      "Baseline Loss: 2.6394 | Actual Loss: 0.4917\n",
      "Baseline Loss: 2.6542 | Actual Loss: 0.2819\n",
      "Baseline Loss: 2.6633 | Actual Loss: 0.5319\n",
      "Baseline Loss: 2.6791 | Actual Loss: 0.5519\n",
      "Baseline Loss: 2.2275 | Actual Loss: 0.1499\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.7095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 148/1000 [01:33<09:01,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6435 | Actual Loss: 0.3550\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3002\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.5039\n",
      "Epoch 148/1000: Train Loss: 0.5042, Val Loss: 0.4672\n",
      "New best validation loss: 0.4672\n",
      "Baseline Loss: 2.6540 | Actual Loss: 0.4457\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.6090\n",
      "Baseline Loss: 2.6786 | Actual Loss: 0.3693\n",
      "Baseline Loss: 2.6635 | Actual Loss: 2.3202\n",
      "Baseline Loss: 2.6437 | Actual Loss: 0.4877\n",
      "Baseline Loss: 2.6824 | Actual Loss: 0.5068\n",
      "Baseline Loss: 2.6430 | Actual Loss: 0.6425\n",
      "Baseline Loss: 2.6652 | Actual Loss: 0.5738\n",
      "Baseline Loss: 2.6948 | Actual Loss: 0.5049\n",
      "Baseline Loss: 2.7051 | Actual Loss: 0.8262\n",
      "Baseline Loss: 2.6771 | Actual Loss: 0.2661\n",
      "Baseline Loss: 2.6604 | Actual Loss: 0.6447\n",
      "Baseline Loss: 2.6928 | Actual Loss: 0.4080\n",
      "Baseline Loss: 2.6684 | Actual Loss: 0.5926\n",
      "Baseline Loss: 2.6749 | Actual Loss: 0.4274\n",
      "Baseline Loss: 2.2382 | Actual Loss: 0.2480\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.0833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 149/1000 [01:34<08:59,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6435 | Actual Loss: 0.3132\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3641\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.5165\n",
      "Epoch 149/1000: Train Loss: 0.6171, Val Loss: 0.5693\n",
      "Baseline Loss: 2.6489 | Actual Loss: 0.5370\n",
      "Baseline Loss: 2.6929 | Actual Loss: 0.5148\n",
      "Baseline Loss: 2.6584 | Actual Loss: 0.3444\n",
      "Baseline Loss: 2.7133 | Actual Loss: 0.5439\n",
      "Baseline Loss: 2.6761 | Actual Loss: 0.2031\n",
      "Baseline Loss: 2.6686 | Actual Loss: 0.5721\n",
      "Baseline Loss: 2.6745 | Actual Loss: 0.3595\n",
      "Baseline Loss: 2.6691 | Actual Loss: 0.9526\n",
      "Baseline Loss: 2.6557 | Actual Loss: 0.5045\n",
      "Baseline Loss: 2.6823 | Actual Loss: 0.2184\n",
      "Baseline Loss: 2.6778 | Actual Loss: 1.8790\n",
      "Baseline Loss: 2.6854 | Actual Loss: 0.3389\n",
      "Baseline Loss: 2.6646 | Actual Loss: 1.1754\n",
      "Baseline Loss: 2.6784 | Actual Loss: 0.2665\n",
      "Baseline Loss: 2.6848 | Actual Loss: 0.3284\n",
      "Baseline Loss: 2.2838 | Actual Loss: 0.3799\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.0042\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 150/1000 [01:34<08:53,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7015 | Actual Loss: 0.3563\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.5202\n",
      "Epoch 150/1000: Train Loss: 0.5699, Val Loss: 0.5472\n",
      "Baseline Loss: 2.6495 | Actual Loss: 1.1320\n",
      "Baseline Loss: 2.6367 | Actual Loss: 0.4548\n",
      "Baseline Loss: 2.6713 | Actual Loss: 0.5325\n",
      "Baseline Loss: 2.7168 | Actual Loss: 0.5977\n",
      "Baseline Loss: 2.6802 | Actual Loss: 0.8679\n",
      "Baseline Loss: 2.6963 | Actual Loss: 0.5319\n",
      "Baseline Loss: 2.6686 | Actual Loss: 0.2581\n",
      "Baseline Loss: 2.6425 | Actual Loss: 0.5394\n",
      "Baseline Loss: 2.6679 | Actual Loss: 0.5341\n",
      "Baseline Loss: 2.6705 | Actual Loss: 1.0406\n",
      "Baseline Loss: 2.6662 | Actual Loss: 0.1435\n",
      "Baseline Loss: 2.6658 | Actual Loss: 0.5814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 151/1000 [01:35<08:53,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6847 | Actual Loss: 0.6715\n",
      "Baseline Loss: 2.6781 | Actual Loss: 0.2884\n",
      "Baseline Loss: 2.6665 | Actual Loss: 0.2921\n",
      "Baseline Loss: 2.2894 | Actual Loss: 0.2595\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.1227\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4677\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3924\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.8941\n",
      "Epoch 151/1000: Train Loss: 0.5453, Val Loss: 0.7192\n",
      "Baseline Loss: 2.6906 | Actual Loss: 0.5872\n",
      "Baseline Loss: 2.6876 | Actual Loss: 1.3794\n",
      "Baseline Loss: 2.6972 | Actual Loss: 0.2526\n",
      "Baseline Loss: 2.6347 | Actual Loss: 0.7580\n",
      "Baseline Loss: 2.6497 | Actual Loss: 0.5892\n",
      "Baseline Loss: 2.6376 | Actual Loss: 0.2521\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.5543\n",
      "Baseline Loss: 2.6232 | Actual Loss: 0.7482\n",
      "Baseline Loss: 2.6650 | Actual Loss: 0.8348\n",
      "Baseline Loss: 2.6455 | Actual Loss: 1.1640\n",
      "Baseline Loss: 2.6624 | Actual Loss: 0.2964\n",
      "Baseline Loss: 2.7301 | Actual Loss: 0.6615\n",
      "Baseline Loss: 2.6819 | Actual Loss: 0.6137\n",
      "Baseline Loss: 2.7318 | Actual Loss: 0.3663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 152/1000 [01:35<08:38,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6551 | Actual Loss: 0.9472\n",
      "Baseline Loss: 2.2927 | Actual Loss: 1.8080\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.0280\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3532\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3583\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.8590\n",
      "Epoch 152/1000: Train Loss: 0.7383, Val Loss: 0.6496\n",
      "Baseline Loss: 2.6764 | Actual Loss: 0.6698\n",
      "Baseline Loss: 2.6769 | Actual Loss: 0.6548\n",
      "Baseline Loss: 2.6835 | Actual Loss: 1.7229\n",
      "Baseline Loss: 2.6314 | Actual Loss: 0.8887\n",
      "Baseline Loss: 2.6796 | Actual Loss: 0.4594\n",
      "Baseline Loss: 2.6249 | Actual Loss: 1.9204\n",
      "Baseline Loss: 2.7541 | Actual Loss: 0.3565\n",
      "Baseline Loss: 2.7053 | Actual Loss: 0.3725\n",
      "Baseline Loss: 2.6618 | Actual Loss: 0.7154\n",
      "Baseline Loss: 2.6470 | Actual Loss: 0.6772\n",
      "Baseline Loss: 2.6981 | Actual Loss: 0.2616\n",
      "Baseline Loss: 2.6698 | Actual Loss: 0.4447\n",
      "Baseline Loss: 2.6706 | Actual Loss: 0.8684\n",
      "Baseline Loss: 2.6681 | Actual Loss: 0.5247\n",
      "Baseline Loss: 2.6983 | Actual Loss: 2.2449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 153/1000 [01:36<08:52,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.3620 | Actual Loss: 0.2005\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.1077\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.2161\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3858\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.7596\n",
      "Epoch 153/1000: Train Loss: 0.8114, Val Loss: 0.6173\n",
      "Baseline Loss: 2.6987 | Actual Loss: 0.6466\n",
      "Baseline Loss: 2.6468 | Actual Loss: 0.3170\n",
      "Baseline Loss: 2.6460 | Actual Loss: 0.3117\n",
      "Baseline Loss: 2.6904 | Actual Loss: 0.4313\n",
      "Baseline Loss: 2.6479 | Actual Loss: 0.3938\n",
      "Baseline Loss: 2.6953 | Actual Loss: 0.4187\n",
      "Baseline Loss: 2.6977 | Actual Loss: 2.2110\n",
      "Baseline Loss: 2.7195 | Actual Loss: 1.5104\n",
      "Baseline Loss: 2.6821 | Actual Loss: 2.4143\n",
      "Baseline Loss: 2.6837 | Actual Loss: 0.6456\n",
      "Baseline Loss: 2.6646 | Actual Loss: 0.5640\n",
      "Baseline Loss: 2.7039 | Actual Loss: 0.5224\n",
      "Baseline Loss: 2.7066 | Actual Loss: 0.3387\n",
      "Baseline Loss: 2.6688 | Actual Loss: 0.7603\n",
      "Baseline Loss: 2.6573 | Actual Loss: 0.6411\n",
      "Baseline Loss: 2.2705 | Actual Loss: 0.1198\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.0829\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3402\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 154/1000 [01:37<08:37,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5568 | Actual Loss: 0.4301\n",
      "Epoch 154/1000: Train Loss: 0.7654, Val Loss: 0.5617\n",
      "Baseline Loss: 2.6994 | Actual Loss: 0.5925\n",
      "Baseline Loss: 2.6572 | Actual Loss: 2.4443\n",
      "Baseline Loss: 2.6599 | Actual Loss: 0.1433\n",
      "Baseline Loss: 2.6669 | Actual Loss: 0.4958\n",
      "Baseline Loss: 2.6784 | Actual Loss: 0.4437\n",
      "Baseline Loss: 2.6940 | Actual Loss: 1.0662\n",
      "Baseline Loss: 2.6784 | Actual Loss: 0.3878\n",
      "Baseline Loss: 2.6555 | Actual Loss: 0.3307\n",
      "Baseline Loss: 2.7057 | Actual Loss: 0.2468\n",
      "Baseline Loss: 2.6647 | Actual Loss: 0.5689\n",
      "Baseline Loss: 2.6430 | Actual Loss: 0.4114\n",
      "Baseline Loss: 2.6632 | Actual Loss: 0.5749\n",
      "Baseline Loss: 2.6609 | Actual Loss: 0.6745\n",
      "Baseline Loss: 2.6533 | Actual Loss: 0.6388\n",
      "Baseline Loss: 2.6482 | Actual Loss: 0.4792\n",
      "Baseline Loss: 2.2939 | Actual Loss: 0.4557\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.7631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 155/1000 [01:37<08:54,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6435 | Actual Loss: 0.4374\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.2747\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.4389\n",
      "Epoch 155/1000: Train Loss: 0.6221, Val Loss: 0.4785\n",
      "Baseline Loss: 2.7394 | Actual Loss: 0.2267\n",
      "Baseline Loss: 2.6382 | Actual Loss: 0.3837\n",
      "Baseline Loss: 2.6898 | Actual Loss: 1.1516\n",
      "Baseline Loss: 2.6782 | Actual Loss: 0.5178\n",
      "Baseline Loss: 2.6927 | Actual Loss: 0.4589\n",
      "Baseline Loss: 2.6720 | Actual Loss: 0.5879\n",
      "Baseline Loss: 2.6340 | Actual Loss: 0.3942\n",
      "Baseline Loss: 2.6568 | Actual Loss: 0.3968\n",
      "Baseline Loss: 2.6589 | Actual Loss: 0.7064\n",
      "Baseline Loss: 2.6287 | Actual Loss: 0.7669\n",
      "Baseline Loss: 2.6899 | Actual Loss: 0.6365\n",
      "Baseline Loss: 2.6720 | Actual Loss: 1.2331\n",
      "Baseline Loss: 2.6721 | Actual Loss: 1.2183\n",
      "Baseline Loss: 2.6788 | Actual Loss: 0.7057\n",
      "Baseline Loss: 2.7169 | Actual Loss: 0.7642\n",
      "Baseline Loss: 2.2969 | Actual Loss: 2.1946\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9822\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 156/1000 [01:38<09:02,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7015 | Actual Loss: 0.3463\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.3936\n",
      "Epoch 156/1000: Train Loss: 0.7715, Val Loss: 0.5081\n",
      "Baseline Loss: 2.7378 | Actual Loss: 0.5001\n",
      "Baseline Loss: 2.6389 | Actual Loss: 0.1918\n",
      "Baseline Loss: 2.6707 | Actual Loss: 0.1798\n",
      "Baseline Loss: 2.6637 | Actual Loss: 0.2960\n",
      "Baseline Loss: 2.6341 | Actual Loss: 0.7375\n",
      "Baseline Loss: 2.6616 | Actual Loss: 0.4104\n",
      "Baseline Loss: 2.7059 | Actual Loss: 1.2974\n",
      "Baseline Loss: 2.6562 | Actual Loss: 0.3847\n",
      "Baseline Loss: 2.6829 | Actual Loss: 0.3761\n",
      "Baseline Loss: 2.6577 | Actual Loss: 2.2489\n",
      "Baseline Loss: 2.7035 | Actual Loss: 0.5634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 157/1000 [01:39<08:45,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7033 | Actual Loss: 0.7212\n",
      "Baseline Loss: 2.7039 | Actual Loss: 0.7788\n",
      "Baseline Loss: 2.6584 | Actual Loss: 0.7261\n",
      "Baseline Loss: 2.6962 | Actual Loss: 2.8056\n",
      "Baseline Loss: 2.2871 | Actual Loss: 0.3285\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.0243\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3799\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3320\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.6962\n",
      "Epoch 157/1000: Train Loss: 0.7841, Val Loss: 0.6081\n",
      "Baseline Loss: 2.6769 | Actual Loss: 0.5297\n",
      "Baseline Loss: 2.6442 | Actual Loss: 0.2970\n",
      "Baseline Loss: 2.6989 | Actual Loss: 0.3286\n",
      "Baseline Loss: 2.6879 | Actual Loss: 0.3144\n",
      "Baseline Loss: 2.6810 | Actual Loss: 0.5414\n",
      "Baseline Loss: 2.6698 | Actual Loss: 0.5945\n",
      "Baseline Loss: 2.6831 | Actual Loss: 0.5221\n",
      "Baseline Loss: 2.6499 | Actual Loss: 0.4672\n",
      "Baseline Loss: 2.6835 | Actual Loss: 0.2586\n",
      "Baseline Loss: 2.6948 | Actual Loss: 0.9776\n",
      "Baseline Loss: 2.6986 | Actual Loss: 0.4635\n",
      "Baseline Loss: 2.6913 | Actual Loss: 0.3200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 158/1000 [01:39<08:54,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6783 | Actual Loss: 0.9015\n",
      "Baseline Loss: 2.6724 | Actual Loss: 0.8430\n",
      "Baseline Loss: 2.6439 | Actual Loss: 0.4972\n",
      "Baseline Loss: 2.2801 | Actual Loss: 0.4330\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9568\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3185\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.4295\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.6821\n",
      "Epoch 158/1000: Train Loss: 0.5181, Val Loss: 0.5967\n",
      "Baseline Loss: 2.7043 | Actual Loss: 0.1838\n",
      "Baseline Loss: 2.6574 | Actual Loss: 0.3974\n",
      "Baseline Loss: 2.6688 | Actual Loss: 0.7309\n",
      "Baseline Loss: 2.6438 | Actual Loss: 1.9088\n",
      "Baseline Loss: 2.6713 | Actual Loss: 0.8898\n",
      "Baseline Loss: 2.6718 | Actual Loss: 0.5787\n",
      "Baseline Loss: 2.6962 | Actual Loss: 0.4446\n",
      "Baseline Loss: 2.6461 | Actual Loss: 0.4059\n",
      "Baseline Loss: 2.6610 | Actual Loss: 0.3455\n",
      "Baseline Loss: 2.6710 | Actual Loss: 0.4142\n",
      "Baseline Loss: 2.6780 | Actual Loss: 0.5918\n",
      "Baseline Loss: 2.6635 | Actual Loss: 0.4602\n",
      "Baseline Loss: 2.6431 | Actual Loss: 0.5247\n",
      "Baseline Loss: 2.6915 | Actual Loss: 0.3566\n",
      "Baseline Loss: 2.6877 | Actual Loss: 0.5375\n",
      "Baseline Loss: 2.3390 | Actual Loss: 0.1390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 159/1000 [01:40<08:39,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7315 | Actual Loss: 1.1343\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4287\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3684\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.5147\n",
      "Epoch 159/1000: Train Loss: 0.5569, Val Loss: 0.6115\n",
      "Baseline Loss: 2.6395 | Actual Loss: 0.3606\n",
      "Baseline Loss: 2.6808 | Actual Loss: 0.9593\n",
      "Baseline Loss: 2.6614 | Actual Loss: 0.4081\n",
      "Baseline Loss: 2.6979 | Actual Loss: 0.3690\n",
      "Baseline Loss: 2.6979 | Actual Loss: 0.8908\n",
      "Baseline Loss: 2.6780 | Actual Loss: 0.5880\n",
      "Baseline Loss: 2.6688 | Actual Loss: 2.3989\n",
      "Baseline Loss: 2.6800 | Actual Loss: 0.7244\n",
      "Baseline Loss: 2.6658 | Actual Loss: 0.5277\n",
      "Baseline Loss: 2.6551 | Actual Loss: 0.4567\n",
      "Baseline Loss: 2.6488 | Actual Loss: 0.2826\n",
      "Baseline Loss: 2.6890 | Actual Loss: 0.3663\n",
      "Baseline Loss: 2.6946 | Actual Loss: 2.1676\n",
      "Baseline Loss: 2.6707 | Actual Loss: 0.6688\n",
      "Baseline Loss: 2.6684 | Actual Loss: 0.5671\n",
      "Baseline Loss: 2.3183 | Actual Loss: 0.1076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 160/1000 [01:40<08:48,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7315 | Actual Loss: 1.7018\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3503\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3959\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.5485\n",
      "Epoch 160/1000: Train Loss: 0.7402, Val Loss: 0.7491\n",
      "Baseline Loss: 2.6521 | Actual Loss: 0.6290\n",
      "Baseline Loss: 2.6558 | Actual Loss: 0.2399\n",
      "Baseline Loss: 2.6571 | Actual Loss: 0.3112\n",
      "Baseline Loss: 2.6410 | Actual Loss: 0.4356\n",
      "Baseline Loss: 2.6736 | Actual Loss: 0.5335\n",
      "Baseline Loss: 2.7078 | Actual Loss: 2.1672\n",
      "Baseline Loss: 2.6926 | Actual Loss: 0.1230\n",
      "Baseline Loss: 2.6739 | Actual Loss: 0.3885\n",
      "Baseline Loss: 2.6733 | Actual Loss: 0.8261\n",
      "Baseline Loss: 2.6884 | Actual Loss: 1.9421\n",
      "Baseline Loss: 2.6862 | Actual Loss: 0.2954\n",
      "Baseline Loss: 2.6962 | Actual Loss: 0.4663\n",
      "Baseline Loss: 2.6796 | Actual Loss: 0.9888\n",
      "Baseline Loss: 2.6557 | Actual Loss: 0.7150\n",
      "Baseline Loss: 2.6448 | Actual Loss: 0.3292\n",
      "Baseline Loss: 2.2868 | Actual Loss: 0.1187\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.1221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 161/1000 [01:41<08:47,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6435 | Actual Loss: 0.3392\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.4192\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.4638\n",
      "Epoch 161/1000: Train Loss: 0.6568, Val Loss: 0.5861\n",
      "Baseline Loss: 2.6660 | Actual Loss: 0.4526\n",
      "Baseline Loss: 2.7109 | Actual Loss: 0.6587\n",
      "Baseline Loss: 2.6436 | Actual Loss: 0.3996\n",
      "Baseline Loss: 2.6603 | Actual Loss: 0.4937\n",
      "Baseline Loss: 2.6793 | Actual Loss: 0.2788\n",
      "Baseline Loss: 2.6655 | Actual Loss: 0.6241\n",
      "Baseline Loss: 2.6811 | Actual Loss: 0.5255\n",
      "Baseline Loss: 2.6808 | Actual Loss: 0.2528\n",
      "Baseline Loss: 2.6852 | Actual Loss: 0.4288\n",
      "Baseline Loss: 2.6726 | Actual Loss: 0.4439\n",
      "Baseline Loss: 2.6797 | Actual Loss: 0.2540\n",
      "Baseline Loss: 2.7102 | Actual Loss: 0.5307\n",
      "Baseline Loss: 2.6762 | Actual Loss: 0.6778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 162/1000 [01:42<08:36,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6906 | Actual Loss: 0.7112\n",
      "Baseline Loss: 2.6370 | Actual Loss: 0.5043\n",
      "Baseline Loss: 2.3177 | Actual Loss: 0.3969\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9917\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3496\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3900\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.4627\n",
      "Epoch 162/1000: Train Loss: 0.4771, Val Loss: 0.5485\n",
      "Baseline Loss: 2.6975 | Actual Loss: 0.2712\n",
      "Baseline Loss: 2.6517 | Actual Loss: 0.3850\n",
      "Baseline Loss: 2.6778 | Actual Loss: 0.4204\n",
      "Baseline Loss: 2.7024 | Actual Loss: 0.5698\n",
      "Baseline Loss: 2.6723 | Actual Loss: 0.6163\n",
      "Baseline Loss: 2.6795 | Actual Loss: 0.6869\n",
      "Baseline Loss: 2.6627 | Actual Loss: 0.4223\n",
      "Baseline Loss: 2.6557 | Actual Loss: 0.9189\n",
      "Baseline Loss: 2.7057 | Actual Loss: 0.2152\n",
      "Baseline Loss: 2.6769 | Actual Loss: 0.7293\n",
      "Baseline Loss: 2.6389 | Actual Loss: 0.5559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▋        | 163/1000 [01:42<08:44,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6574 | Actual Loss: 0.3917\n",
      "Baseline Loss: 2.6961 | Actual Loss: 0.4490\n",
      "Baseline Loss: 2.6569 | Actual Loss: 0.6216\n",
      "Baseline Loss: 2.6919 | Actual Loss: 0.2701\n",
      "Baseline Loss: 2.3554 | Actual Loss: 0.7216\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.0375\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3202\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.4294\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.4951\n",
      "Epoch 163/1000: Train Loss: 0.5153, Val Loss: 0.5705\n",
      "Baseline Loss: 2.7097 | Actual Loss: 0.3109\n",
      "Baseline Loss: 2.7059 | Actual Loss: 0.3492\n",
      "Baseline Loss: 2.6919 | Actual Loss: 0.2987\n",
      "Baseline Loss: 2.6828 | Actual Loss: 0.4792\n",
      "Baseline Loss: 2.6949 | Actual Loss: 0.2405\n",
      "Baseline Loss: 2.6525 | Actual Loss: 0.1220\n",
      "Baseline Loss: 2.6808 | Actual Loss: 0.7655\n",
      "Baseline Loss: 2.6918 | Actual Loss: 0.9383\n",
      "Baseline Loss: 2.6475 | Actual Loss: 0.6177\n",
      "Baseline Loss: 2.6443 | Actual Loss: 0.8088\n",
      "Baseline Loss: 2.6691 | Actual Loss: 0.5228\n",
      "Baseline Loss: 2.7038 | Actual Loss: 0.5893\n",
      "Baseline Loss: 2.6498 | Actual Loss: 1.7884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▋        | 164/1000 [01:43<08:48,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6194 | Actual Loss: 0.3840\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.2688\n",
      "Baseline Loss: 2.3183 | Actual Loss: 0.1158\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.0048\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4062\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3713\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.5420\n",
      "Epoch 164/1000: Train Loss: 0.5375, Val Loss: 0.5811\n",
      "Baseline Loss: 2.6843 | Actual Loss: 0.5246\n",
      "Baseline Loss: 2.6710 | Actual Loss: 0.9698\n",
      "Baseline Loss: 2.7217 | Actual Loss: 0.2695\n",
      "Baseline Loss: 2.6667 | Actual Loss: 0.3791\n",
      "Baseline Loss: 2.6554 | Actual Loss: 0.2396\n",
      "Baseline Loss: 2.6781 | Actual Loss: 0.5131\n",
      "Baseline Loss: 2.6926 | Actual Loss: 1.2153\n",
      "Baseline Loss: 2.6540 | Actual Loss: 0.2871\n",
      "Baseline Loss: 2.6889 | Actual Loss: 0.5186\n",
      "Baseline Loss: 2.6780 | Actual Loss: 0.4605\n",
      "Baseline Loss: 2.6569 | Actual Loss: 0.9526\n",
      "Baseline Loss: 2.6562 | Actual Loss: 0.5968\n",
      "Baseline Loss: 2.6787 | Actual Loss: 0.5400\n",
      "Baseline Loss: 2.6923 | Actual Loss: 0.5502\n",
      "Baseline Loss: 2.6553 | Actual Loss: 0.3923\n",
      "Baseline Loss: 2.3044 | Actual Loss: 0.8578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▋        | 165/1000 [01:44<08:36,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7315 | Actual Loss: 1.0734\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4509\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3701\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.4420\n",
      "Epoch 165/1000: Train Loss: 0.5792, Val Loss: 0.5841\n",
      "Baseline Loss: 2.6546 | Actual Loss: 0.4793\n",
      "Baseline Loss: 2.6550 | Actual Loss: 0.2439\n",
      "Baseline Loss: 2.6679 | Actual Loss: 0.6000\n",
      "Baseline Loss: 2.6362 | Actual Loss: 0.3342\n",
      "Baseline Loss: 2.7176 | Actual Loss: 0.2122\n",
      "Baseline Loss: 2.7052 | Actual Loss: 0.2390\n",
      "Baseline Loss: 2.6528 | Actual Loss: 0.3564\n",
      "Baseline Loss: 2.6864 | Actual Loss: 1.7159\n",
      "Baseline Loss: 2.6673 | Actual Loss: 0.7737\n",
      "Baseline Loss: 2.6951 | Actual Loss: 0.6114\n",
      "Baseline Loss: 2.6495 | Actual Loss: 0.7828\n",
      "Baseline Loss: 2.6836 | Actual Loss: 0.4465\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3075\n",
      "Baseline Loss: 2.6709 | Actual Loss: 0.9296\n",
      "Baseline Loss: 2.6769 | Actual Loss: 0.2925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 166/1000 [01:44<08:41,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2912 | Actual Loss: 0.2399\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.2587\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.2169\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3936\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.4349\n",
      "Epoch 166/1000: Train Loss: 0.5353, Val Loss: 0.5761\n",
      "Baseline Loss: 2.6646 | Actual Loss: 0.3409\n",
      "Baseline Loss: 2.6948 | Actual Loss: 0.3067\n",
      "Baseline Loss: 2.6695 | Actual Loss: 0.4087\n",
      "Baseline Loss: 2.6823 | Actual Loss: 0.6998\n",
      "Baseline Loss: 2.6720 | Actual Loss: 0.5733\n",
      "Baseline Loss: 2.6413 | Actual Loss: 0.5177\n",
      "Baseline Loss: 2.6737 | Actual Loss: 0.6806\n",
      "Baseline Loss: 2.6750 | Actual Loss: 0.4156\n",
      "Baseline Loss: 2.6541 | Actual Loss: 0.6682\n",
      "Baseline Loss: 2.6805 | Actual Loss: 0.3978\n",
      "Baseline Loss: 2.6598 | Actual Loss: 0.7599\n",
      "Baseline Loss: 2.6703 | Actual Loss: 0.3862\n",
      "Baseline Loss: 2.6453 | Actual Loss: 2.5990\n",
      "Baseline Loss: 2.6860 | Actual Loss: 0.4962\n",
      "Baseline Loss: 2.6847 | Actual Loss: 0.6381\n",
      "Baseline Loss: 2.2801 | Actual Loss: 1.0563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 167/1000 [01:45<08:48,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7315 | Actual Loss: 1.1337\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3445\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3617\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.4862\n",
      "Epoch 167/1000: Train Loss: 0.6841, Val Loss: 0.5815\n",
      "Baseline Loss: 2.6602 | Actual Loss: 0.3389\n",
      "Baseline Loss: 2.6439 | Actual Loss: 0.5041\n",
      "Baseline Loss: 2.6834 | Actual Loss: 0.6495\n",
      "Baseline Loss: 2.6416 | Actual Loss: 0.6119\n",
      "Baseline Loss: 2.6746 | Actual Loss: 0.3492\n",
      "Baseline Loss: 2.6509 | Actual Loss: 0.1789\n",
      "Baseline Loss: 2.7067 | Actual Loss: 0.6968\n",
      "Baseline Loss: 2.6903 | Actual Loss: 0.5509\n",
      "Baseline Loss: 2.6632 | Actual Loss: 0.3856\n",
      "Baseline Loss: 2.7292 | Actual Loss: 0.8203\n",
      "Baseline Loss: 2.6976 | Actual Loss: 0.6793\n",
      "Baseline Loss: 2.7046 | Actual Loss: 0.5590\n",
      "Baseline Loss: 2.6266 | Actual Loss: 0.6526\n",
      "Baseline Loss: 2.6615 | Actual Loss: 0.5996\n",
      "Baseline Loss: 2.6536 | Actual Loss: 0.4988\n",
      "Baseline Loss: 2.2714 | Actual Loss: 0.7949\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.8637\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.5776\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 168/1000 [01:46<08:59,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5568 | Actual Loss: 0.7241\n",
      "Epoch 168/1000: Train Loss: 0.5544, Val Loss: 0.6227\n",
      "Baseline Loss: 2.6431 | Actual Loss: 1.5144\n",
      "Baseline Loss: 2.6814 | Actual Loss: 0.8382\n",
      "Baseline Loss: 2.6698 | Actual Loss: 0.4873\n",
      "Baseline Loss: 2.6932 | Actual Loss: 0.3793\n",
      "Baseline Loss: 2.6843 | Actual Loss: 0.0850\n",
      "Baseline Loss: 2.6549 | Actual Loss: 0.5272\n",
      "Baseline Loss: 2.6913 | Actual Loss: 0.2730\n",
      "Baseline Loss: 2.6585 | Actual Loss: 1.1238\n",
      "Baseline Loss: 2.6769 | Actual Loss: 0.4776\n",
      "Baseline Loss: 2.6781 | Actual Loss: 0.6104\n",
      "Baseline Loss: 2.6740 | Actual Loss: 0.2755\n",
      "Baseline Loss: 2.6613 | Actual Loss: 0.5999\n",
      "Baseline Loss: 2.6722 | Actual Loss: 0.5045\n",
      "Baseline Loss: 2.6677 | Actual Loss: 0.2931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 169/1000 [01:46<08:39,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6995 | Actual Loss: 0.5912\n",
      "Baseline Loss: 2.2669 | Actual Loss: 0.5398\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9473\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3565\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3005\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.4423\n",
      "Epoch 169/1000: Train Loss: 0.5700, Val Loss: 0.5117\n",
      "Baseline Loss: 2.6934 | Actual Loss: 0.4326\n",
      "Baseline Loss: 2.6569 | Actual Loss: 0.1554\n",
      "Baseline Loss: 2.6785 | Actual Loss: 0.5693\n",
      "Baseline Loss: 2.6833 | Actual Loss: 0.2418\n",
      "Baseline Loss: 2.6932 | Actual Loss: 0.2743\n",
      "Baseline Loss: 2.6930 | Actual Loss: 0.2779\n",
      "Baseline Loss: 2.6720 | Actual Loss: 0.6706\n",
      "Baseline Loss: 2.7376 | Actual Loss: 0.7855\n",
      "Baseline Loss: 2.6781 | Actual Loss: 0.7767\n",
      "Baseline Loss: 2.6450 | Actual Loss: 1.1848\n",
      "Baseline Loss: 2.6550 | Actual Loss: 0.2816\n",
      "Baseline Loss: 2.6597 | Actual Loss: 0.5528\n",
      "Baseline Loss: 2.6819 | Actual Loss: 0.5409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 170/1000 [01:47<08:44,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6473 | Actual Loss: 0.3308\n",
      "Baseline Loss: 2.7296 | Actual Loss: 0.6132\n",
      "Baseline Loss: 2.2629 | Actual Loss: 1.9587\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.0232\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.2903\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3153\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.6689\n",
      "Epoch 170/1000: Train Loss: 0.6029, Val Loss: 0.5744\n",
      "Baseline Loss: 2.7039 | Actual Loss: 1.0495\n",
      "Baseline Loss: 2.6644 | Actual Loss: 0.3078\n",
      "Baseline Loss: 2.6413 | Actual Loss: 0.2046\n",
      "Baseline Loss: 2.6711 | Actual Loss: 0.2276\n",
      "Baseline Loss: 2.7114 | Actual Loss: 0.3902\n",
      "Baseline Loss: 2.6330 | Actual Loss: 0.4908\n",
      "Baseline Loss: 2.7217 | Actual Loss: 0.2397\n",
      "Baseline Loss: 2.6666 | Actual Loss: 0.4547\n",
      "Baseline Loss: 2.6729 | Actual Loss: 0.7281\n",
      "Baseline Loss: 2.6887 | Actual Loss: 0.9672\n",
      "Baseline Loss: 2.6906 | Actual Loss: 0.4236\n",
      "Baseline Loss: 2.6702 | Actual Loss: 2.1683\n",
      "Baseline Loss: 2.7067 | Actual Loss: 0.3671\n",
      "Baseline Loss: 2.6768 | Actual Loss: 0.9770\n",
      "Baseline Loss: 2.6962 | Actual Loss: 0.6469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 171/1000 [01:47<08:58,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2317 | Actual Loss: 0.4597\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9928\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.2850\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.2939\n",
      "Baseline Loss: 2.5568 | Actual Loss: 1.0405\n",
      "Epoch 171/1000: Train Loss: 0.6314, Val Loss: 0.6531\n",
      "Baseline Loss: 2.6842 | Actual Loss: 0.2382\n",
      "Baseline Loss: 2.7185 | Actual Loss: 0.2585\n",
      "Baseline Loss: 2.6744 | Actual Loss: 0.5238\n",
      "Baseline Loss: 2.6423 | Actual Loss: 0.5263\n",
      "Baseline Loss: 2.6791 | Actual Loss: 2.3614\n",
      "Baseline Loss: 2.7169 | Actual Loss: 0.2655\n",
      "Baseline Loss: 2.6631 | Actual Loss: 0.5198\n",
      "Baseline Loss: 2.6305 | Actual Loss: 0.5808\n",
      "Baseline Loss: 2.7001 | Actual Loss: 0.4431\n",
      "Baseline Loss: 2.6780 | Actual Loss: 0.4872\n",
      "Baseline Loss: 2.6508 | Actual Loss: 0.2456\n",
      "Baseline Loss: 2.6690 | Actual Loss: 0.5449\n",
      "Baseline Loss: 2.6478 | Actual Loss: 0.2014\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.4014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 172/1000 [01:48<08:36,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6843 | Actual Loss: 0.6043\n",
      "Baseline Loss: 2.2447 | Actual Loss: 0.1265\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9342\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.2584\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3678\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.7538\n",
      "Epoch 172/1000: Train Loss: 0.5205, Val Loss: 0.5786\n",
      "Baseline Loss: 2.6609 | Actual Loss: 2.2011\n",
      "Baseline Loss: 2.6870 | Actual Loss: 0.7533\n",
      "Baseline Loss: 2.6447 | Actual Loss: 1.5164\n",
      "Baseline Loss: 2.6937 | Actual Loss: 0.4181\n",
      "Baseline Loss: 2.6886 | Actual Loss: 0.3599\n",
      "Baseline Loss: 2.6799 | Actual Loss: 0.1966\n",
      "Baseline Loss: 2.6999 | Actual Loss: 0.4538\n",
      "Baseline Loss: 2.6659 | Actual Loss: 0.4368\n",
      "Baseline Loss: 2.6237 | Actual Loss: 0.3414\n",
      "Baseline Loss: 2.6682 | Actual Loss: 0.4897\n",
      "Baseline Loss: 2.6219 | Actual Loss: 0.4664\n",
      "Baseline Loss: 2.7077 | Actual Loss: 0.5719\n",
      "Baseline Loss: 2.6648 | Actual Loss: 1.0247\n",
      "Baseline Loss: 2.6774 | Actual Loss: 0.4430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 173/1000 [01:49<08:50,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6800 | Actual Loss: 1.3059\n",
      "Baseline Loss: 2.2645 | Actual Loss: 0.3789\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.0174\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3840\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3653\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.4983\n",
      "Epoch 173/1000: Train Loss: 0.7099, Val Loss: 0.5662\n",
      "Baseline Loss: 2.6773 | Actual Loss: 0.6713\n",
      "Baseline Loss: 2.6796 | Actual Loss: 1.2601\n",
      "Baseline Loss: 2.6940 | Actual Loss: 0.5736\n",
      "Baseline Loss: 2.6703 | Actual Loss: 0.5593\n",
      "Baseline Loss: 2.6989 | Actual Loss: 0.2796\n",
      "Baseline Loss: 2.7113 | Actual Loss: 0.2993\n",
      "Baseline Loss: 2.6432 | Actual Loss: 0.4104\n",
      "Baseline Loss: 2.7047 | Actual Loss: 0.4900\n",
      "Baseline Loss: 2.6395 | Actual Loss: 0.1692\n",
      "Baseline Loss: 2.6763 | Actual Loss: 0.8907\n",
      "Baseline Loss: 2.6509 | Actual Loss: 0.4445\n",
      "Baseline Loss: 2.6814 | Actual Loss: 0.4158\n",
      "Baseline Loss: 2.6658 | Actual Loss: 0.8978\n",
      "Baseline Loss: 2.6689 | Actual Loss: 0.8747\n",
      "Baseline Loss: 2.6845 | Actual Loss: 0.7558\n",
      "Baseline Loss: 2.2661 | Actual Loss: 1.3489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 174/1000 [01:49<08:58,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7315 | Actual Loss: 0.9017\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3952\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3661\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.6000\n",
      "Epoch 174/1000: Train Loss: 0.6463, Val Loss: 0.5658\n",
      "Baseline Loss: 2.6512 | Actual Loss: 2.4202\n",
      "Baseline Loss: 2.7200 | Actual Loss: 1.4883\n",
      "Baseline Loss: 2.7070 | Actual Loss: 0.3166\n",
      "Baseline Loss: 2.6327 | Actual Loss: 0.2380\n",
      "Baseline Loss: 2.6762 | Actual Loss: 0.5493\n",
      "Baseline Loss: 2.6948 | Actual Loss: 0.7644\n",
      "Baseline Loss: 2.6678 | Actual Loss: 2.7924\n",
      "Baseline Loss: 2.6642 | Actual Loss: 0.5604\n",
      "Baseline Loss: 2.6756 | Actual Loss: 0.6304\n",
      "Baseline Loss: 2.6804 | Actual Loss: 0.3102\n",
      "Baseline Loss: 2.6374 | Actual Loss: 1.2017\n",
      "Baseline Loss: 2.6709 | Actual Loss: 0.5596\n",
      "Baseline Loss: 2.6808 | Actual Loss: 0.5323\n",
      "Baseline Loss: 2.6681 | Actual Loss: 0.8552\n",
      "Baseline Loss: 2.6954 | Actual Loss: 0.6184\n",
      "Baseline Loss: 2.2412 | Actual Loss: 1.9491\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.7661\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4626\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 175/1000 [01:50<08:30,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5568 | Actual Loss: 0.6305\n",
      "Epoch 175/1000: Train Loss: 0.9867, Val Loss: 0.5535\n",
      "Baseline Loss: 2.6896 | Actual Loss: 0.3212\n",
      "Baseline Loss: 2.6293 | Actual Loss: 0.3257\n",
      "Baseline Loss: 2.6743 | Actual Loss: 0.5147\n",
      "Baseline Loss: 2.6598 | Actual Loss: 1.2385\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.7482\n",
      "Baseline Loss: 2.6691 | Actual Loss: 0.7097\n",
      "Baseline Loss: 2.6815 | Actual Loss: 0.5070\n",
      "Baseline Loss: 2.7182 | Actual Loss: 0.6523\n",
      "Baseline Loss: 2.6594 | Actual Loss: 0.7702\n",
      "Baseline Loss: 2.6741 | Actual Loss: 0.4605\n",
      "Baseline Loss: 2.6934 | Actual Loss: 0.4288\n",
      "Baseline Loss: 2.7053 | Actual Loss: 1.2374\n",
      "Baseline Loss: 2.6288 | Actual Loss: 0.5905\n",
      "Baseline Loss: 2.6379 | Actual Loss: 0.3962\n",
      "Baseline Loss: 2.6695 | Actual Loss: 0.2095\n",
      "Baseline Loss: 2.3029 | Actual Loss: 0.2371\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9702\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 176/1000 [01:51<08:44,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7015 | Actual Loss: 0.3845\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.7779\n",
      "Epoch 176/1000: Train Loss: 0.5842, Val Loss: 0.6167\n",
      "Baseline Loss: 2.6678 | Actual Loss: 0.7255\n",
      "Baseline Loss: 2.6860 | Actual Loss: 0.6218\n",
      "Baseline Loss: 2.6627 | Actual Loss: 0.6681\n",
      "Baseline Loss: 2.6857 | Actual Loss: 0.8728\n",
      "Baseline Loss: 2.6929 | Actual Loss: 0.3417\n",
      "Baseline Loss: 2.6855 | Actual Loss: 1.0926\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3797\n",
      "Baseline Loss: 2.6921 | Actual Loss: 0.5552\n",
      "Baseline Loss: 2.6826 | Actual Loss: 0.5211\n",
      "Baseline Loss: 2.6702 | Actual Loss: 0.6590\n",
      "Baseline Loss: 2.6464 | Actual Loss: 0.4631\n",
      "Baseline Loss: 2.6757 | Actual Loss: 0.2831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 177/1000 [01:51<08:25,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6863 | Actual Loss: 2.3019\n",
      "Baseline Loss: 2.6938 | Actual Loss: 0.4531\n",
      "Baseline Loss: 2.6629 | Actual Loss: 0.4937\n",
      "Baseline Loss: 2.2154 | Actual Loss: 1.0845\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.7841\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3963\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3616\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.7168\n",
      "Epoch 177/1000: Train Loss: 0.7198, Val Loss: 0.5647\n",
      "Baseline Loss: 2.7138 | Actual Loss: 0.4551\n",
      "Baseline Loss: 2.7292 | Actual Loss: 0.4133\n",
      "Baseline Loss: 2.6621 | Actual Loss: 0.6090\n",
      "Baseline Loss: 2.7008 | Actual Loss: 1.3137\n",
      "Baseline Loss: 2.7057 | Actual Loss: 0.5006\n",
      "Baseline Loss: 2.6574 | Actual Loss: 0.5933\n",
      "Baseline Loss: 2.6676 | Actual Loss: 1.3564\n",
      "Baseline Loss: 2.6594 | Actual Loss: 2.2246\n",
      "Baseline Loss: 2.6547 | Actual Loss: 0.4669\n",
      "Baseline Loss: 2.6439 | Actual Loss: 0.1799\n",
      "Baseline Loss: 2.6843 | Actual Loss: 1.9494\n",
      "Baseline Loss: 2.6714 | Actual Loss: 0.3429\n",
      "Baseline Loss: 2.6897 | Actual Loss: 0.7069\n",
      "Baseline Loss: 2.6736 | Actual Loss: 0.4437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 178/1000 [01:52<08:42,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6783 | Actual Loss: 0.1798\n",
      "Baseline Loss: 2.2722 | Actual Loss: 0.8087\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9691\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3344\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3715\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.7364\n",
      "Epoch 178/1000: Train Loss: 0.7840, Val Loss: 0.6028\n",
      "Baseline Loss: 2.6522 | Actual Loss: 0.5508\n",
      "Baseline Loss: 2.6413 | Actual Loss: 0.5171\n",
      "Baseline Loss: 2.6879 | Actual Loss: 0.5974\n",
      "Baseline Loss: 2.6539 | Actual Loss: 0.2606\n",
      "Baseline Loss: 2.6441 | Actual Loss: 1.2164\n",
      "Baseline Loss: 2.6718 | Actual Loss: 2.2930\n",
      "Baseline Loss: 2.6610 | Actual Loss: 0.9782\n",
      "Baseline Loss: 2.7280 | Actual Loss: 0.5525\n",
      "Baseline Loss: 2.6840 | Actual Loss: 0.8463\n",
      "Baseline Loss: 2.6913 | Actual Loss: 0.8612\n",
      "Baseline Loss: 2.6660 | Actual Loss: 0.5703\n",
      "Baseline Loss: 2.7081 | Actual Loss: 0.7261\n",
      "Baseline Loss: 2.7042 | Actual Loss: 0.5975\n",
      "Baseline Loss: 2.6565 | Actual Loss: 0.3032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 179/1000 [01:52<08:50,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6935 | Actual Loss: 0.5031\n",
      "Baseline Loss: 2.2655 | Actual Loss: 2.3584\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9530\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4480\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3981\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.5270\n",
      "Epoch 179/1000: Train Loss: 0.8582, Val Loss: 0.5815\n",
      "Baseline Loss: 2.6928 | Actual Loss: 0.6149\n",
      "Baseline Loss: 2.6673 | Actual Loss: 0.3422\n",
      "Baseline Loss: 2.6941 | Actual Loss: 0.6450\n",
      "Baseline Loss: 2.6531 | Actual Loss: 1.0174\n",
      "Baseline Loss: 2.6711 | Actual Loss: 1.4516\n",
      "Baseline Loss: 2.6780 | Actual Loss: 0.7806\n",
      "Baseline Loss: 2.6686 | Actual Loss: 0.4604\n",
      "Baseline Loss: 2.7098 | Actual Loss: 0.8281\n",
      "Baseline Loss: 2.6710 | Actual Loss: 0.5864\n",
      "Baseline Loss: 2.6661 | Actual Loss: 0.5723\n",
      "Baseline Loss: 2.6562 | Actual Loss: 0.3396\n",
      "Baseline Loss: 2.6879 | Actual Loss: 0.7328\n",
      "Baseline Loss: 2.6820 | Actual Loss: 0.5842\n",
      "Baseline Loss: 2.6424 | Actual Loss: 0.7051\n",
      "Baseline Loss: 2.6682 | Actual Loss: 0.5188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 180/1000 [01:53<08:24,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.3068 | Actual Loss: 0.9368\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9635\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4658\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.4216\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.6232\n",
      "Epoch 180/1000: Train Loss: 0.6948, Val Loss: 0.6185\n",
      "Baseline Loss: 2.7086 | Actual Loss: 2.0096\n",
      "Baseline Loss: 2.7274 | Actual Loss: 0.4440\n",
      "Baseline Loss: 2.6628 | Actual Loss: 1.1260\n",
      "Baseline Loss: 2.6883 | Actual Loss: 0.2094\n",
      "Baseline Loss: 2.6394 | Actual Loss: 0.4451\n",
      "Baseline Loss: 2.6651 | Actual Loss: 0.6412\n",
      "Baseline Loss: 2.6472 | Actual Loss: 0.6500\n",
      "Baseline Loss: 2.6906 | Actual Loss: 0.2175\n",
      "Baseline Loss: 2.6229 | Actual Loss: 0.4485\n",
      "Baseline Loss: 2.7243 | Actual Loss: 0.8152\n",
      "Baseline Loss: 2.6747 | Actual Loss: 0.1777\n",
      "Baseline Loss: 2.6538 | Actual Loss: 0.5556\n",
      "Baseline Loss: 2.6741 | Actual Loss: 0.6806\n",
      "Baseline Loss: 2.6763 | Actual Loss: 0.8779\n",
      "Baseline Loss: 2.6718 | Actual Loss: 0.4978\n",
      "Baseline Loss: 2.2745 | Actual Loss: 0.4743\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.8957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 181/1000 [01:54<08:37,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6435 | Actual Loss: 0.5097\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3809\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.6106\n",
      "Epoch 181/1000: Train Loss: 0.6419, Val Loss: 0.5992\n",
      "Baseline Loss: 2.6681 | Actual Loss: 0.6774\n",
      "Baseline Loss: 2.7000 | Actual Loss: 1.0314\n",
      "Baseline Loss: 2.6489 | Actual Loss: 0.4744\n",
      "Baseline Loss: 2.6912 | Actual Loss: 0.3570\n",
      "Baseline Loss: 2.6603 | Actual Loss: 0.4363\n",
      "Baseline Loss: 2.6821 | Actual Loss: 0.6229\n",
      "Baseline Loss: 2.7006 | Actual Loss: 0.8428\n",
      "Baseline Loss: 2.6632 | Actual Loss: 0.5925\n",
      "Baseline Loss: 2.6567 | Actual Loss: 0.3610\n",
      "Baseline Loss: 2.6753 | Actual Loss: 0.4305\n",
      "Baseline Loss: 2.7155 | Actual Loss: 0.1445\n",
      "Baseline Loss: 2.6763 | Actual Loss: 0.5324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 182/1000 [01:54<08:19,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6636 | Actual Loss: 1.0657\n",
      "Baseline Loss: 2.6581 | Actual Loss: 0.8402\n",
      "Baseline Loss: 2.6482 | Actual Loss: 0.3822\n",
      "Baseline Loss: 2.2175 | Actual Loss: 0.0661\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9396\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4622\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3771\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.4743\n",
      "Epoch 182/1000: Train Loss: 0.5536, Val Loss: 0.5633\n",
      "Baseline Loss: 2.6574 | Actual Loss: 0.4223\n",
      "Baseline Loss: 2.6705 | Actual Loss: 0.4067\n",
      "Baseline Loss: 2.6875 | Actual Loss: 0.5767\n",
      "Baseline Loss: 2.6756 | Actual Loss: 0.3166\n",
      "Baseline Loss: 2.6726 | Actual Loss: 0.3463\n",
      "Baseline Loss: 2.6673 | Actual Loss: 0.6479\n",
      "Baseline Loss: 2.6791 | Actual Loss: 0.7200\n",
      "Baseline Loss: 2.7123 | Actual Loss: 0.4028\n",
      "Baseline Loss: 2.6834 | Actual Loss: 0.7790\n",
      "Baseline Loss: 2.6876 | Actual Loss: 0.6464\n",
      "Baseline Loss: 2.6939 | Actual Loss: 1.1511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 183/1000 [01:55<08:24,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6438 | Actual Loss: 0.6030\n",
      "Baseline Loss: 2.6751 | Actual Loss: 0.1738\n",
      "Baseline Loss: 2.6444 | Actual Loss: 0.3264\n",
      "Baseline Loss: 2.6820 | Actual Loss: 1.3452\n",
      "Baseline Loss: 2.2584 | Actual Loss: 0.2554\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.8259\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4382\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.4011\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.4813\n",
      "Epoch 183/1000: Train Loss: 0.5700, Val Loss: 0.5366\n",
      "Baseline Loss: 2.6673 | Actual Loss: 0.3033\n",
      "Baseline Loss: 2.6595 | Actual Loss: 0.4679\n",
      "Baseline Loss: 2.6635 | Actual Loss: 0.6393\n",
      "Baseline Loss: 2.6919 | Actual Loss: 0.5160\n",
      "Baseline Loss: 2.6468 | Actual Loss: 0.6711\n",
      "Baseline Loss: 2.6682 | Actual Loss: 0.2836\n",
      "Baseline Loss: 2.6962 | Actual Loss: 1.2849\n",
      "Baseline Loss: 2.7018 | Actual Loss: 0.5886\n",
      "Baseline Loss: 2.6550 | Actual Loss: 0.7272\n",
      "Baseline Loss: 2.6772 | Actual Loss: 0.7205\n",
      "Baseline Loss: 2.6707 | Actual Loss: 0.4625\n",
      "Baseline Loss: 2.6810 | Actual Loss: 0.8605\n",
      "Baseline Loss: 2.6392 | Actual Loss: 0.5702\n",
      "Baseline Loss: 2.6663 | Actual Loss: 0.3061\n",
      "Baseline Loss: 2.6707 | Actual Loss: 0.6764\n",
      "Baseline Loss: 2.3347 | Actual Loss: 0.1247\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.8770\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.2552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 184/1000 [01:56<08:44,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7015 | Actual Loss: 0.3695\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.5999\n",
      "Epoch 184/1000: Train Loss: 0.5752, Val Loss: 0.5254\n",
      "Baseline Loss: 2.6609 | Actual Loss: 1.8338\n",
      "Baseline Loss: 2.6824 | Actual Loss: 0.3362\n",
      "Baseline Loss: 2.6648 | Actual Loss: 0.8329\n",
      "Baseline Loss: 2.6339 | Actual Loss: 0.5238\n",
      "Baseline Loss: 2.7102 | Actual Loss: 0.6995\n",
      "Baseline Loss: 2.6679 | Actual Loss: 0.2741\n",
      "Baseline Loss: 2.7246 | Actual Loss: 1.2834\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.9288\n",
      "Baseline Loss: 2.6905 | Actual Loss: 0.4115\n",
      "Baseline Loss: 2.6955 | Actual Loss: 0.5902\n",
      "Baseline Loss: 2.6370 | Actual Loss: 2.4413\n",
      "Baseline Loss: 2.6077 | Actual Loss: 0.9899\n",
      "Baseline Loss: 2.6329 | Actual Loss: 0.5799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 185/1000 [01:56<08:25,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6636 | Actual Loss: 0.1293\n",
      "Baseline Loss: 2.6628 | Actual Loss: 0.2014\n",
      "Baseline Loss: 2.3245 | Actual Loss: 1.9267\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9298\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3749\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.2945\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.5412\n",
      "Epoch 185/1000: Train Loss: 0.8739, Val Loss: 0.5351\n",
      "Baseline Loss: 2.7025 | Actual Loss: 0.2545\n",
      "Baseline Loss: 2.6734 | Actual Loss: 0.4477\n",
      "Baseline Loss: 2.6871 | Actual Loss: 0.5871\n",
      "Baseline Loss: 2.6626 | Actual Loss: 0.9041\n",
      "Baseline Loss: 2.6612 | Actual Loss: 0.5208\n",
      "Baseline Loss: 2.6618 | Actual Loss: 0.3554\n",
      "Baseline Loss: 2.6516 | Actual Loss: 0.3626\n",
      "Baseline Loss: 2.6630 | Actual Loss: 0.7395\n",
      "Baseline Loss: 2.7110 | Actual Loss: 0.3218\n",
      "Baseline Loss: 2.6420 | Actual Loss: 0.5682\n",
      "Baseline Loss: 2.6855 | Actual Loss: 0.6496\n",
      "Baseline Loss: 2.6792 | Actual Loss: 0.5828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▊        | 186/1000 [01:57<08:33,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6842 | Actual Loss: 0.3619\n",
      "Baseline Loss: 2.6720 | Actual Loss: 0.4371\n",
      "Baseline Loss: 2.6753 | Actual Loss: 0.4754\n",
      "Baseline Loss: 2.2969 | Actual Loss: 2.4138\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9635\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4070\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.4349\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.7506\n",
      "Epoch 186/1000: Train Loss: 0.6239, Val Loss: 0.6390\n",
      "Baseline Loss: 2.6669 | Actual Loss: 0.4887\n",
      "Baseline Loss: 2.6473 | Actual Loss: 0.4728\n",
      "Baseline Loss: 2.6580 | Actual Loss: 0.6216\n",
      "Baseline Loss: 2.7101 | Actual Loss: 0.5263\n",
      "Baseline Loss: 2.6698 | Actual Loss: 0.8776\n",
      "Baseline Loss: 2.6502 | Actual Loss: 0.0835\n",
      "Baseline Loss: 2.6342 | Actual Loss: 1.1567\n",
      "Baseline Loss: 2.6742 | Actual Loss: 0.9362\n",
      "Baseline Loss: 2.6867 | Actual Loss: 0.2542\n",
      "Baseline Loss: 2.7334 | Actual Loss: 0.2025\n",
      "Baseline Loss: 2.6725 | Actual Loss: 0.4930\n",
      "Baseline Loss: 2.6939 | Actual Loss: 0.5422\n",
      "Baseline Loss: 2.6486 | Actual Loss: 0.6430\n",
      "Baseline Loss: 2.6620 | Actual Loss: 2.7042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▊        | 187/1000 [01:57<08:28,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6542 | Actual Loss: 0.6343\n",
      "Baseline Loss: 2.2818 | Actual Loss: 0.4919\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.8589\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3465\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3350\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.5870\n",
      "Epoch 187/1000: Train Loss: 0.6955, Val Loss: 0.5318\n",
      "Baseline Loss: 2.6521 | Actual Loss: 1.3808\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.2975\n",
      "Baseline Loss: 2.6845 | Actual Loss: 0.5250\n",
      "Baseline Loss: 2.6584 | Actual Loss: 0.8560\n",
      "Baseline Loss: 2.6942 | Actual Loss: 0.9783\n",
      "Baseline Loss: 2.6405 | Actual Loss: 0.4369\n",
      "Baseline Loss: 2.7321 | Actual Loss: 1.8231\n",
      "Baseline Loss: 2.6797 | Actual Loss: 0.4421\n",
      "Baseline Loss: 2.6485 | Actual Loss: 0.5412\n",
      "Baseline Loss: 2.6688 | Actual Loss: 0.3264\n",
      "Baseline Loss: 2.6492 | Actual Loss: 0.3574\n",
      "Baseline Loss: 2.6808 | Actual Loss: 0.7966\n",
      "Baseline Loss: 2.6885 | Actual Loss: 0.2974\n",
      "Baseline Loss: 2.6672 | Actual Loss: 0.4193\n",
      "Baseline Loss: 2.7008 | Actual Loss: 0.4651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 188/1000 [01:58<08:30,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.3110 | Actual Loss: 0.4821\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9871\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4305\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.4178\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.7560\n",
      "Epoch 188/1000: Train Loss: 0.6516, Val Loss: 0.6478\n",
      "Baseline Loss: 2.6850 | Actual Loss: 0.4300\n",
      "Baseline Loss: 2.6909 | Actual Loss: 0.9312\n",
      "Baseline Loss: 2.6800 | Actual Loss: 0.3075\n",
      "Baseline Loss: 2.6772 | Actual Loss: 0.4440\n",
      "Baseline Loss: 2.7014 | Actual Loss: 1.0019\n",
      "Baseline Loss: 2.6724 | Actual Loss: 0.4866\n",
      "Baseline Loss: 2.6926 | Actual Loss: 1.0435\n",
      "Baseline Loss: 2.6619 | Actual Loss: 0.5940\n",
      "Baseline Loss: 2.6951 | Actual Loss: 0.2735\n",
      "Baseline Loss: 2.6652 | Actual Loss: 0.6473\n",
      "Baseline Loss: 2.6711 | Actual Loss: 0.3868\n",
      "Baseline Loss: 2.6419 | Actual Loss: 0.4222\n",
      "Baseline Loss: 2.6616 | Actual Loss: 0.4266\n",
      "Baseline Loss: 2.6711 | Actual Loss: 0.3402\n",
      "Baseline Loss: 2.6648 | Actual Loss: 0.7781\n",
      "Baseline Loss: 2.2464 | Actual Loss: 0.8094\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.0304\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4227\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 189/1000 [01:59<08:18,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5568 | Actual Loss: 0.4278\n",
      "Epoch 189/1000: Train Loss: 0.5827, Val Loss: 0.5583\n",
      "Baseline Loss: 2.7223 | Actual Loss: 0.5080\n",
      "Baseline Loss: 2.6610 | Actual Loss: 0.3181\n",
      "Baseline Loss: 2.6389 | Actual Loss: 0.4954\n",
      "Baseline Loss: 2.6804 | Actual Loss: 0.2340\n",
      "Baseline Loss: 2.6656 | Actual Loss: 0.6057\n",
      "Baseline Loss: 2.6588 | Actual Loss: 0.4569\n",
      "Baseline Loss: 2.6817 | Actual Loss: 0.6762\n",
      "Baseline Loss: 2.6915 | Actual Loss: 0.6421\n",
      "Baseline Loss: 2.6283 | Actual Loss: 0.1860\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.6106\n",
      "Baseline Loss: 2.6712 | Actual Loss: 0.6207\n",
      "Baseline Loss: 2.6696 | Actual Loss: 0.5680\n",
      "Baseline Loss: 2.6558 | Actual Loss: 1.0741\n",
      "Baseline Loss: 2.6551 | Actual Loss: 2.4767\n",
      "Baseline Loss: 2.7199 | Actual Loss: 0.4654\n",
      "Baseline Loss: 2.3053 | Actual Loss: 0.4048\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.8724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 190/1000 [01:59<08:31,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6435 | Actual Loss: 0.2734\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.2782\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.8034\n",
      "Epoch 190/1000: Train Loss: 0.6464, Val Loss: 0.5568\n",
      "Baseline Loss: 2.6929 | Actual Loss: 0.4252\n",
      "Baseline Loss: 2.6425 | Actual Loss: 0.4977\n",
      "Baseline Loss: 2.6800 | Actual Loss: 0.4340\n",
      "Baseline Loss: 2.6498 | Actual Loss: 0.6613\n",
      "Baseline Loss: 2.6570 | Actual Loss: 0.6282\n",
      "Baseline Loss: 2.7096 | Actual Loss: 0.4122\n",
      "Baseline Loss: 2.6350 | Actual Loss: 0.9148\n",
      "Baseline Loss: 2.7109 | Actual Loss: 0.6062\n",
      "Baseline Loss: 2.6846 | Actual Loss: 0.2892\n",
      "Baseline Loss: 2.6608 | Actual Loss: 1.8814\n",
      "Baseline Loss: 2.6552 | Actual Loss: 0.6829\n",
      "Baseline Loss: 2.6957 | Actual Loss: 0.3012\n",
      "Baseline Loss: 2.7232 | Actual Loss: 0.2533\n",
      "Baseline Loss: 2.7098 | Actual Loss: 0.7215\n",
      "Baseline Loss: 2.6915 | Actual Loss: 0.7460\n",
      "Baseline Loss: 2.2673 | Actual Loss: 0.9190\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.7677\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.2318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 191/1000 [02:00<08:44,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7015 | Actual Loss: 0.2707\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.5163\n",
      "Epoch 191/1000: Train Loss: 0.6484, Val Loss: 0.4466\n",
      "New best validation loss: 0.4466\n",
      "Baseline Loss: 2.6780 | Actual Loss: 0.6960\n",
      "Baseline Loss: 2.6987 | Actual Loss: 0.4241\n",
      "Baseline Loss: 2.6829 | Actual Loss: 0.5646\n",
      "Baseline Loss: 2.7024 | Actual Loss: 0.7012\n",
      "Baseline Loss: 2.6320 | Actual Loss: 0.2962\n",
      "Baseline Loss: 2.6418 | Actual Loss: 0.6000\n",
      "Baseline Loss: 2.6255 | Actual Loss: 1.9431\n",
      "Baseline Loss: 2.6665 | Actual Loss: 0.3935\n",
      "Baseline Loss: 2.7020 | Actual Loss: 0.2180\n",
      "Baseline Loss: 2.6599 | Actual Loss: 0.5795\n",
      "Baseline Loss: 2.7490 | Actual Loss: 0.5352\n",
      "Baseline Loss: 2.6767 | Actual Loss: 0.2101\n",
      "Baseline Loss: 2.6813 | Actual Loss: 0.7741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 192/1000 [02:01<08:25,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6219 | Actual Loss: 0.2858\n",
      "Baseline Loss: 2.6845 | Actual Loss: 0.5381\n",
      "Baseline Loss: 2.2835 | Actual Loss: 0.1040\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.8225\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3605\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3053\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.9667\n",
      "Epoch 192/1000: Train Loss: 0.5540, Val Loss: 0.6137\n",
      "Baseline Loss: 2.6610 | Actual Loss: 1.6914\n",
      "Baseline Loss: 2.6414 | Actual Loss: 0.6414\n",
      "Baseline Loss: 2.6892 | Actual Loss: 0.3678\n",
      "Baseline Loss: 2.6642 | Actual Loss: 0.6004\n",
      "Baseline Loss: 2.6806 | Actual Loss: 2.1030\n",
      "Baseline Loss: 2.6815 | Actual Loss: 0.3668\n",
      "Baseline Loss: 2.6827 | Actual Loss: 2.7354\n",
      "Baseline Loss: 2.6734 | Actual Loss: 0.6594\n",
      "Baseline Loss: 2.6458 | Actual Loss: 0.4340\n",
      "Baseline Loss: 2.6521 | Actual Loss: 0.5670\n",
      "Baseline Loss: 2.6828 | Actual Loss: 0.8874\n",
      "Baseline Loss: 2.6615 | Actual Loss: 0.4227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 193/1000 [02:01<08:37,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6532 | Actual Loss: 0.2726\n",
      "Baseline Loss: 2.6761 | Actual Loss: 0.8062\n",
      "Baseline Loss: 2.7039 | Actual Loss: 0.6848\n",
      "Baseline Loss: 2.2993 | Actual Loss: 0.2732\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9115\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4000\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3478\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.6400\n",
      "Epoch 193/1000: Train Loss: 0.8446, Val Loss: 0.5748\n",
      "Baseline Loss: 2.6637 | Actual Loss: 0.5768\n",
      "Baseline Loss: 2.6776 | Actual Loss: 0.2897\n",
      "Baseline Loss: 2.6355 | Actual Loss: 0.3671\n",
      "Baseline Loss: 2.6386 | Actual Loss: 1.1507\n",
      "Baseline Loss: 2.6909 | Actual Loss: 0.5559\n",
      "Baseline Loss: 2.6802 | Actual Loss: 0.8653\n",
      "Baseline Loss: 2.7053 | Actual Loss: 0.4029\n",
      "Baseline Loss: 2.6841 | Actual Loss: 0.7337\n",
      "Baseline Loss: 2.7282 | Actual Loss: 0.8069\n",
      "Baseline Loss: 2.6463 | Actual Loss: 0.4558\n",
      "Baseline Loss: 2.6915 | Actual Loss: 0.2853\n",
      "Baseline Loss: 2.6449 | Actual Loss: 2.1490\n",
      "Baseline Loss: 2.6550 | Actual Loss: 1.3891\n",
      "Baseline Loss: 2.7094 | Actual Loss: 0.3359\n",
      "Baseline Loss: 2.6705 | Actual Loss: 0.2456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 194/1000 [02:02<08:19,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2071 | Actual Loss: 0.6084\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9445\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4356\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3843\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.4828\n",
      "Epoch 194/1000: Train Loss: 0.7011, Val Loss: 0.5618\n",
      "Baseline Loss: 2.7400 | Actual Loss: 2.4274\n",
      "Baseline Loss: 2.6676 | Actual Loss: 0.4922\n",
      "Baseline Loss: 2.6865 | Actual Loss: 0.9964\n",
      "Baseline Loss: 2.6427 | Actual Loss: 0.8002\n",
      "Baseline Loss: 2.6949 | Actual Loss: 2.1351\n",
      "Baseline Loss: 2.6562 | Actual Loss: 0.4036\n",
      "Baseline Loss: 2.6319 | Actual Loss: 0.4355\n",
      "Baseline Loss: 2.6834 | Actual Loss: 0.4366\n",
      "Baseline Loss: 2.6946 | Actual Loss: 1.5871\n",
      "Baseline Loss: 2.6551 | Actual Loss: 0.6925\n",
      "Baseline Loss: 2.6488 | Actual Loss: 0.5242\n",
      "Baseline Loss: 2.6346 | Actual Loss: 0.5537\n",
      "Baseline Loss: 2.6709 | Actual Loss: 0.3557\n",
      "Baseline Loss: 2.6973 | Actual Loss: 0.2968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 195/1000 [02:02<08:26,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6685 | Actual Loss: 0.5729\n",
      "Baseline Loss: 2.3071 | Actual Loss: 0.0471\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9977\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.2808\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.2950\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.4637\n",
      "Epoch 195/1000: Train Loss: 0.7973, Val Loss: 0.5093\n",
      "Baseline Loss: 2.6532 | Actual Loss: 2.4469\n",
      "Baseline Loss: 2.7218 | Actual Loss: 0.4018\n",
      "Baseline Loss: 2.7483 | Actual Loss: 0.0835\n",
      "Baseline Loss: 2.6624 | Actual Loss: 0.3590\n",
      "Baseline Loss: 2.6488 | Actual Loss: 0.4377\n",
      "Baseline Loss: 2.6348 | Actual Loss: 0.5912\n",
      "Baseline Loss: 2.6805 | Actual Loss: 0.3811\n",
      "Baseline Loss: 2.6508 | Actual Loss: 0.9295\n",
      "Baseline Loss: 2.6596 | Actual Loss: 0.5343\n",
      "Baseline Loss: 2.6766 | Actual Loss: 0.4369\n",
      "Baseline Loss: 2.6510 | Actual Loss: 0.3570\n",
      "Baseline Loss: 2.6557 | Actual Loss: 0.5780\n",
      "Baseline Loss: 2.6795 | Actual Loss: 0.7475\n",
      "Baseline Loss: 2.7131 | Actual Loss: 0.7690\n",
      "Baseline Loss: 2.6688 | Actual Loss: 0.6677\n",
      "Baseline Loss: 2.2999 | Actual Loss: 0.4990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 196/1000 [02:03<08:33,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7315 | Actual Loss: 0.9248\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4299\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3554\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.4664\n",
      "Epoch 196/1000: Train Loss: 0.6388, Val Loss: 0.5441\n",
      "Baseline Loss: 2.6466 | Actual Loss: 0.3494\n",
      "Baseline Loss: 2.6911 | Actual Loss: 1.2602\n",
      "Baseline Loss: 2.6666 | Actual Loss: 0.4676\n",
      "Baseline Loss: 2.6976 | Actual Loss: 0.3082\n",
      "Baseline Loss: 2.6919 | Actual Loss: 0.5499\n",
      "Baseline Loss: 2.6965 | Actual Loss: 0.6016\n",
      "Baseline Loss: 2.6445 | Actual Loss: 0.5876\n",
      "Baseline Loss: 2.6687 | Actual Loss: 0.2412\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.3049\n",
      "Baseline Loss: 2.6599 | Actual Loss: 0.7936\n",
      "Baseline Loss: 2.6630 | Actual Loss: 0.3929\n",
      "Baseline Loss: 2.6502 | Actual Loss: 1.0151\n",
      "Baseline Loss: 2.6534 | Actual Loss: 1.1518\n",
      "Baseline Loss: 2.7077 | Actual Loss: 0.4327\n",
      "Baseline Loss: 2.6820 | Actual Loss: 0.5861\n",
      "Baseline Loss: 2.2621 | Actual Loss: 0.2643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 197/1000 [02:04<08:36,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7315 | Actual Loss: 1.0431\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3919\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.4121\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.5382\n",
      "Epoch 197/1000: Train Loss: 0.5817, Val Loss: 0.5963\n",
      "Baseline Loss: 2.6600 | Actual Loss: 0.5609\n",
      "Baseline Loss: 2.7006 | Actual Loss: 0.3652\n",
      "Baseline Loss: 2.6658 | Actual Loss: 0.5977\n",
      "Baseline Loss: 2.6630 | Actual Loss: 0.4772\n",
      "Baseline Loss: 2.6818 | Actual Loss: 0.2882\n",
      "Baseline Loss: 2.6659 | Actual Loss: 0.4634\n",
      "Baseline Loss: 2.6765 | Actual Loss: 0.7646\n",
      "Baseline Loss: 2.6346 | Actual Loss: 0.8488\n",
      "Baseline Loss: 2.6933 | Actual Loss: 0.4128\n",
      "Baseline Loss: 2.7112 | Actual Loss: 0.2701\n",
      "Baseline Loss: 2.6662 | Actual Loss: 0.3711\n",
      "Baseline Loss: 2.6618 | Actual Loss: 0.4205\n",
      "Baseline Loss: 2.6704 | Actual Loss: 0.5619\n",
      "Baseline Loss: 2.6862 | Actual Loss: 0.5218\n",
      "Baseline Loss: 2.6945 | Actual Loss: 0.5033\n",
      "Baseline Loss: 2.3062 | Actual Loss: 1.8226\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9783\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 198/1000 [02:04<08:28,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7015 | Actual Loss: 0.3454\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.6212\n",
      "Epoch 198/1000: Train Loss: 0.5781, Val Loss: 0.5646\n",
      "Baseline Loss: 2.6671 | Actual Loss: 0.3315\n",
      "Baseline Loss: 2.6656 | Actual Loss: 0.5681\n",
      "Baseline Loss: 2.6729 | Actual Loss: 0.2390\n",
      "Baseline Loss: 2.6729 | Actual Loss: 0.3521\n",
      "Baseline Loss: 2.6715 | Actual Loss: 1.4335\n",
      "Baseline Loss: 2.6817 | Actual Loss: 0.4497\n",
      "Baseline Loss: 2.7045 | Actual Loss: 0.3240\n",
      "Baseline Loss: 2.6648 | Actual Loss: 0.5212\n",
      "Baseline Loss: 2.7025 | Actual Loss: 0.4288\n",
      "Baseline Loss: 2.6914 | Actual Loss: 0.5690\n",
      "Baseline Loss: 2.6756 | Actual Loss: 1.2278\n",
      "Baseline Loss: 2.6984 | Actual Loss: 0.6158\n",
      "Baseline Loss: 2.6827 | Actual Loss: 0.6897\n",
      "Baseline Loss: 2.6559 | Actual Loss: 0.3647\n",
      "Baseline Loss: 2.6601 | Actual Loss: 0.4744\n",
      "Baseline Loss: 2.2376 | Actual Loss: 0.3106\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9142\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3596\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|█▉        | 199/1000 [02:05<08:24,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5568 | Actual Loss: 0.4909\n",
      "Epoch 199/1000: Train Loss: 0.5562, Val Loss: 0.5273\n",
      "Baseline Loss: 2.6739 | Actual Loss: 1.0715\n",
      "Baseline Loss: 2.6941 | Actual Loss: 0.4333\n",
      "Baseline Loss: 2.6642 | Actual Loss: 0.7683\n",
      "Baseline Loss: 2.6402 | Actual Loss: 0.5684\n",
      "Baseline Loss: 2.7261 | Actual Loss: 0.4277\n",
      "Baseline Loss: 2.6960 | Actual Loss: 0.4622\n",
      "Baseline Loss: 2.6621 | Actual Loss: 0.6931\n",
      "Baseline Loss: 2.6832 | Actual Loss: 0.3783\n",
      "Baseline Loss: 2.6761 | Actual Loss: 0.2595\n",
      "Baseline Loss: 2.6290 | Actual Loss: 0.3080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 200/1000 [02:06<08:25,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6736 | Actual Loss: 0.4409\n",
      "Baseline Loss: 2.6473 | Actual Loss: 0.2515\n",
      "Baseline Loss: 2.6634 | Actual Loss: 0.6732\n",
      "Baseline Loss: 2.6565 | Actual Loss: 0.7749\n",
      "Baseline Loss: 2.6809 | Actual Loss: 0.9739\n",
      "Baseline Loss: 2.2836 | Actual Loss: 0.5178\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9915\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4743\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3153\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.8334\n",
      "Epoch 200/1000: Train Loss: 0.5627, Val Loss: 0.6536\n",
      "Baseline Loss: 2.6890 | Actual Loss: 0.2662\n",
      "Baseline Loss: 2.6860 | Actual Loss: 0.4964\n",
      "Baseline Loss: 2.6491 | Actual Loss: 0.5406\n",
      "Baseline Loss: 2.7446 | Actual Loss: 0.2123\n",
      "Baseline Loss: 2.6727 | Actual Loss: 0.3305\n",
      "Baseline Loss: 2.6363 | Actual Loss: 0.4055\n",
      "Baseline Loss: 2.6752 | Actual Loss: 2.1986\n",
      "Baseline Loss: 2.6646 | Actual Loss: 0.7160\n",
      "Baseline Loss: 2.6652 | Actual Loss: 0.5661\n",
      "Baseline Loss: 2.7014 | Actual Loss: 1.9507\n",
      "Baseline Loss: 2.6617 | Actual Loss: 1.4226\n",
      "Baseline Loss: 2.6918 | Actual Loss: 0.4875\n",
      "Baseline Loss: 2.7073 | Actual Loss: 0.7145\n",
      "Baseline Loss: 2.6406 | Actual Loss: 0.6404\n",
      "Baseline Loss: 2.6549 | Actual Loss: 1.1782\n",
      "Baseline Loss: 2.2685 | Actual Loss: 0.6387\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 201/1000 [02:06<08:37,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6435 | Actual Loss: 0.3479\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3286\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.4630\n",
      "Epoch 201/1000: Train Loss: 0.7978, Val Loss: 0.5277\n",
      "Baseline Loss: 2.6806 | Actual Loss: 2.4727\n",
      "Baseline Loss: 2.6511 | Actual Loss: 0.6644\n",
      "Baseline Loss: 2.6863 | Actual Loss: 0.5058\n",
      "Baseline Loss: 2.6555 | Actual Loss: 0.4637\n",
      "Baseline Loss: 2.6577 | Actual Loss: 0.3089\n",
      "Baseline Loss: 2.7238 | Actual Loss: 0.1917\n",
      "Baseline Loss: 2.6438 | Actual Loss: 0.9904\n",
      "Baseline Loss: 2.6720 | Actual Loss: 0.1704\n",
      "Baseline Loss: 2.6829 | Actual Loss: 0.5845\n",
      "Baseline Loss: 2.6911 | Actual Loss: 0.6028\n",
      "Baseline Loss: 2.6581 | Actual Loss: 0.4544\n",
      "Baseline Loss: 2.6650 | Actual Loss: 0.7370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 202/1000 [02:07<08:17,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6580 | Actual Loss: 0.4403\n",
      "Baseline Loss: 2.6865 | Actual Loss: 0.5525\n",
      "Baseline Loss: 2.6570 | Actual Loss: 0.9201\n",
      "Baseline Loss: 2.2380 | Actual Loss: 0.0945\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9753\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3791\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.4473\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.4883\n",
      "Epoch 202/1000: Train Loss: 0.6346, Val Loss: 0.5725\n",
      "Baseline Loss: 2.6643 | Actual Loss: 0.7615\n",
      "Baseline Loss: 2.6593 | Actual Loss: 0.2752\n",
      "Baseline Loss: 2.6885 | Actual Loss: 0.3568\n",
      "Baseline Loss: 2.6204 | Actual Loss: 1.8723\n",
      "Baseline Loss: 2.6580 | Actual Loss: 0.4914\n",
      "Baseline Loss: 2.6947 | Actual Loss: 0.9889\n",
      "Baseline Loss: 2.6342 | Actual Loss: 1.2586\n",
      "Baseline Loss: 2.7207 | Actual Loss: 0.6862\n",
      "Baseline Loss: 2.6868 | Actual Loss: 0.3948\n",
      "Baseline Loss: 2.7077 | Actual Loss: 0.4981\n",
      "Baseline Loss: 2.6610 | Actual Loss: 0.2919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 203/1000 [02:08<08:19,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6148 | Actual Loss: 0.6568\n",
      "Baseline Loss: 2.7083 | Actual Loss: 0.4084\n",
      "Baseline Loss: 2.7067 | Actual Loss: 0.3095\n",
      "Baseline Loss: 2.6696 | Actual Loss: 0.9948\n",
      "Baseline Loss: 2.2880 | Actual Loss: 0.4804\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9347\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.5064\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3693\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.6096\n",
      "Epoch 203/1000: Train Loss: 0.6704, Val Loss: 0.6050\n",
      "Baseline Loss: 2.6594 | Actual Loss: 0.3687\n",
      "Baseline Loss: 2.7046 | Actual Loss: 0.5494\n",
      "Baseline Loss: 2.6836 | Actual Loss: 0.4077\n",
      "Baseline Loss: 2.6712 | Actual Loss: 0.3497\n",
      "Baseline Loss: 2.6782 | Actual Loss: 0.3521\n",
      "Baseline Loss: 2.6999 | Actual Loss: 0.2451\n",
      "Baseline Loss: 2.6779 | Actual Loss: 0.2740\n",
      "Baseline Loss: 2.6497 | Actual Loss: 0.6788\n",
      "Baseline Loss: 2.6864 | Actual Loss: 2.1338\n",
      "Baseline Loss: 2.6692 | Actual Loss: 1.1495\n",
      "Baseline Loss: 2.6775 | Actual Loss: 0.2964\n",
      "Baseline Loss: 2.6823 | Actual Loss: 0.4640\n",
      "Baseline Loss: 2.6698 | Actual Loss: 0.5920\n",
      "Baseline Loss: 2.6379 | Actual Loss: 0.4356\n",
      "Baseline Loss: 2.6910 | Actual Loss: 1.9962\n",
      "Baseline Loss: 2.2829 | Actual Loss: 2.2316\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.0034\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4101\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.4281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 204/1000 [02:08<08:32,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5568 | Actual Loss: 0.5375\n",
      "Epoch 204/1000: Train Loss: 0.7828, Val Loss: 0.5948\n",
      "Baseline Loss: 2.6741 | Actual Loss: 0.3813\n",
      "Baseline Loss: 2.6386 | Actual Loss: 0.5260\n",
      "Baseline Loss: 2.6880 | Actual Loss: 0.5425\n",
      "Baseline Loss: 2.6766 | Actual Loss: 0.5121\n",
      "Baseline Loss: 2.6473 | Actual Loss: 0.5868\n",
      "Baseline Loss: 2.6988 | Actual Loss: 0.2911\n",
      "Baseline Loss: 2.6740 | Actual Loss: 0.2332\n",
      "Baseline Loss: 2.6724 | Actual Loss: 0.4174\n",
      "Baseline Loss: 2.6546 | Actual Loss: 0.4579\n",
      "Baseline Loss: 2.6897 | Actual Loss: 0.3403\n",
      "Baseline Loss: 2.6459 | Actual Loss: 0.6171\n",
      "Baseline Loss: 2.6874 | Actual Loss: 0.5624\n",
      "Baseline Loss: 2.6976 | Actual Loss: 0.3318\n",
      "Baseline Loss: 2.6759 | Actual Loss: 0.7766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 205/1000 [02:09<08:13,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7075 | Actual Loss: 0.4873\n",
      "Baseline Loss: 2.3005 | Actual Loss: 0.2909\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9038\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3485\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3016\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.4835\n",
      "Epoch 205/1000: Train Loss: 0.4597, Val Loss: 0.5094\n",
      "Baseline Loss: 2.7206 | Actual Loss: 0.4118\n",
      "Baseline Loss: 2.6374 | Actual Loss: 0.7802\n",
      "Baseline Loss: 2.6547 | Actual Loss: 0.1331\n",
      "Baseline Loss: 2.6593 | Actual Loss: 0.9404\n",
      "Baseline Loss: 2.7009 | Actual Loss: 0.4082\n",
      "Baseline Loss: 2.6256 | Actual Loss: 0.4283\n",
      "Baseline Loss: 2.6615 | Actual Loss: 0.7831\n",
      "Baseline Loss: 2.6691 | Actual Loss: 0.5388\n",
      "Baseline Loss: 2.6838 | Actual Loss: 0.2252\n",
      "Baseline Loss: 2.7047 | Actual Loss: 0.8336\n",
      "Baseline Loss: 2.7191 | Actual Loss: 0.3628\n",
      "Baseline Loss: 2.6972 | Actual Loss: 0.3652\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3865\n",
      "Baseline Loss: 2.6826 | Actual Loss: 0.5484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 206/1000 [02:09<08:16,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6780 | Actual Loss: 0.3731\n",
      "Baseline Loss: 2.2251 | Actual Loss: 0.1297\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9061\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.2702\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3537\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.6393\n",
      "Epoch 206/1000: Train Loss: 0.4780, Val Loss: 0.5423\n",
      "Baseline Loss: 2.6561 | Actual Loss: 1.4081\n",
      "Baseline Loss: 2.6499 | Actual Loss: 0.6055\n",
      "Baseline Loss: 2.6689 | Actual Loss: 0.6592\n",
      "Baseline Loss: 2.6590 | Actual Loss: 0.5776\n",
      "Baseline Loss: 2.6660 | Actual Loss: 0.4521\n",
      "Baseline Loss: 2.6871 | Actual Loss: 0.5041\n",
      "Baseline Loss: 2.6877 | Actual Loss: 0.4452\n",
      "Baseline Loss: 2.6616 | Actual Loss: 2.2450\n",
      "Baseline Loss: 2.6698 | Actual Loss: 2.5374\n",
      "Baseline Loss: 2.6588 | Actual Loss: 0.3881\n",
      "Baseline Loss: 2.6933 | Actual Loss: 0.5101\n",
      "Baseline Loss: 2.7025 | Actual Loss: 0.2668\n",
      "Baseline Loss: 2.6933 | Actual Loss: 0.2169\n",
      "Baseline Loss: 2.6941 | Actual Loss: 0.3362\n",
      "Baseline Loss: 2.6448 | Actual Loss: 0.5848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 207/1000 [02:10<08:11,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.2427 | Actual Loss: 1.4953\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.8656\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.2594\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.2870\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.4446\n",
      "Epoch 207/1000: Train Loss: 0.8270, Val Loss: 0.4642\n",
      "Baseline Loss: 2.6743 | Actual Loss: 0.3952\n",
      "Baseline Loss: 2.6546 | Actual Loss: 0.1726\n",
      "Baseline Loss: 2.6752 | Actual Loss: 0.3853\n",
      "Baseline Loss: 2.6897 | Actual Loss: 0.4585\n",
      "Baseline Loss: 2.6694 | Actual Loss: 0.7689\n",
      "Baseline Loss: 2.7039 | Actual Loss: 2.3094\n",
      "Baseline Loss: 2.6688 | Actual Loss: 0.7131\n",
      "Baseline Loss: 2.6614 | Actual Loss: 0.8197\n",
      "Baseline Loss: 2.6743 | Actual Loss: 0.2880\n",
      "Baseline Loss: 2.6650 | Actual Loss: 2.0693\n",
      "Baseline Loss: 2.6472 | Actual Loss: 0.5362\n",
      "Baseline Loss: 2.6574 | Actual Loss: 0.5135\n",
      "Baseline Loss: 2.7018 | Actual Loss: 0.3617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 208/1000 [02:11<08:24,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6847 | Actual Loss: 0.1631\n",
      "Baseline Loss: 2.7133 | Actual Loss: 1.0727\n",
      "Baseline Loss: 2.2464 | Actual Loss: 0.3586\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9856\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3775\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3717\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.5207\n",
      "Epoch 208/1000: Train Loss: 0.7116, Val Loss: 0.5639\n",
      "Baseline Loss: 2.7172 | Actual Loss: 0.4171\n",
      "Baseline Loss: 2.6849 | Actual Loss: 0.4962\n",
      "Baseline Loss: 2.6412 | Actual Loss: 0.7726\n",
      "Baseline Loss: 2.6784 | Actual Loss: 2.3388\n",
      "Baseline Loss: 2.6432 | Actual Loss: 0.3439\n",
      "Baseline Loss: 2.6650 | Actual Loss: 0.9880\n",
      "Baseline Loss: 2.6509 | Actual Loss: 0.7826\n",
      "Baseline Loss: 2.6680 | Actual Loss: 0.2075\n",
      "Baseline Loss: 2.7168 | Actual Loss: 0.4130\n",
      "Baseline Loss: 2.6923 | Actual Loss: 0.5264\n",
      "Baseline Loss: 2.6408 | Actual Loss: 0.3351\n",
      "Baseline Loss: 2.6665 | Actual Loss: 0.4776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 209/1000 [02:11<08:35,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6663 | Actual Loss: 0.3409\n",
      "Baseline Loss: 2.6907 | Actual Loss: 0.9476\n",
      "Baseline Loss: 2.6912 | Actual Loss: 0.2474\n",
      "Baseline Loss: 2.1960 | Actual Loss: 0.9301\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.8937\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3860\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.4022\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.5650\n",
      "Epoch 209/1000: Train Loss: 0.6603, Val Loss: 0.5617\n",
      "Baseline Loss: 2.6487 | Actual Loss: 0.7425\n",
      "Baseline Loss: 2.6420 | Actual Loss: 0.2953\n",
      "Baseline Loss: 2.6688 | Actual Loss: 0.3847\n",
      "Baseline Loss: 2.6404 | Actual Loss: 0.6458\n",
      "Baseline Loss: 2.6958 | Actual Loss: 0.9838\n",
      "Baseline Loss: 2.6615 | Actual Loss: 0.5184\n",
      "Baseline Loss: 2.6954 | Actual Loss: 0.2140\n",
      "Baseline Loss: 2.6793 | Actual Loss: 0.5667\n",
      "Baseline Loss: 2.6551 | Actual Loss: 0.4998\n",
      "Baseline Loss: 2.6562 | Actual Loss: 0.8211\n",
      "Baseline Loss: 2.6514 | Actual Loss: 0.7671\n",
      "Baseline Loss: 2.6394 | Actual Loss: 0.3818\n",
      "Baseline Loss: 2.7136 | Actual Loss: 2.0700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 210/1000 [02:12<08:24,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6992 | Actual Loss: 0.4681\n",
      "Baseline Loss: 2.6692 | Actual Loss: 0.6917\n",
      "Baseline Loss: 2.3208 | Actual Loss: 0.3384\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.7641\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.2612\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.2826\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.7145\n",
      "Epoch 210/1000: Train Loss: 0.6493, Val Loss: 0.5056\n",
      "Baseline Loss: 2.6927 | Actual Loss: 0.9249\n",
      "Baseline Loss: 2.6936 | Actual Loss: 0.2710\n",
      "Baseline Loss: 2.6828 | Actual Loss: 0.5324\n",
      "Baseline Loss: 2.6715 | Actual Loss: 0.6307\n",
      "Baseline Loss: 2.6760 | Actual Loss: 1.1214\n",
      "Baseline Loss: 2.6450 | Actual Loss: 0.4944\n",
      "Baseline Loss: 2.6764 | Actual Loss: 0.6366\n",
      "Baseline Loss: 2.6662 | Actual Loss: 0.6087\n",
      "Baseline Loss: 2.6973 | Actual Loss: 0.8360\n",
      "Baseline Loss: 2.6545 | Actual Loss: 0.1970\n",
      "Baseline Loss: 2.6407 | Actual Loss: 0.6324\n",
      "Baseline Loss: 2.6999 | Actual Loss: 0.8773\n",
      "Baseline Loss: 2.6911 | Actual Loss: 0.4009\n",
      "Baseline Loss: 2.6898 | Actual Loss: 2.6556\n",
      "Baseline Loss: 2.6694 | Actual Loss: 0.3051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 211/1000 [02:13<08:23,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.1951 | Actual Loss: 0.4814\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.0560\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.5304\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3973\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.4050\n",
      "Epoch 211/1000: Train Loss: 0.7254, Val Loss: 0.5972\n",
      "Baseline Loss: 2.6761 | Actual Loss: 0.5712\n",
      "Baseline Loss: 2.6823 | Actual Loss: 0.3137\n",
      "Baseline Loss: 2.6480 | Actual Loss: 0.5009\n",
      "Baseline Loss: 2.6722 | Actual Loss: 0.3168\n",
      "Baseline Loss: 2.7128 | Actual Loss: 0.9982\n",
      "Baseline Loss: 2.7037 | Actual Loss: 0.9646\n",
      "Baseline Loss: 2.6555 | Actual Loss: 0.4967\n",
      "Baseline Loss: 2.6954 | Actual Loss: 0.4681\n",
      "Baseline Loss: 2.6810 | Actual Loss: 0.4308\n",
      "Baseline Loss: 2.6544 | Actual Loss: 0.3791\n",
      "Baseline Loss: 2.6598 | Actual Loss: 0.6328\n",
      "Baseline Loss: 2.6363 | Actual Loss: 0.1274\n",
      "Baseline Loss: 2.6917 | Actual Loss: 0.6098\n",
      "Baseline Loss: 2.6324 | Actual Loss: 0.4529\n",
      "Baseline Loss: 2.6985 | Actual Loss: 0.7373\n",
      "Baseline Loss: 2.3329 | Actual Loss: 0.2309\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9306\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3069\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.2915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 212/1000 [02:13<08:10,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5568 | Actual Loss: 0.4081\n",
      "Epoch 212/1000: Train Loss: 0.5144, Val Loss: 0.4843\n",
      "Baseline Loss: 2.6424 | Actual Loss: 1.1240\n",
      "Baseline Loss: 2.6948 | Actual Loss: 0.8187\n",
      "Baseline Loss: 2.6518 | Actual Loss: 0.9754\n",
      "Baseline Loss: 2.6561 | Actual Loss: 0.5152\n",
      "Baseline Loss: 2.7090 | Actual Loss: 0.4748\n",
      "Baseline Loss: 2.6493 | Actual Loss: 0.3443\n",
      "Baseline Loss: 2.6677 | Actual Loss: 0.3765\n",
      "Baseline Loss: 2.6652 | Actual Loss: 0.2690\n",
      "Baseline Loss: 2.6687 | Actual Loss: 0.5326\n",
      "Baseline Loss: 2.6681 | Actual Loss: 0.5641\n",
      "Baseline Loss: 2.7075 | Actual Loss: 2.6166\n",
      "Baseline Loss: 2.6662 | Actual Loss: 0.4948\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.2612\n",
      "Baseline Loss: 2.6699 | Actual Loss: 1.4896\n",
      "Baseline Loss: 2.6771 | Actual Loss: 0.6660\n",
      "Baseline Loss: 2.2710 | Actual Loss: 0.4704\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██▏       | 213/1000 [02:14<08:19,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6435 | Actual Loss: 0.3540\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3837\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.6025\n",
      "Epoch 213/1000: Train Loss: 0.7496, Val Loss: 0.5648\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.5918\n",
      "Baseline Loss: 2.6775 | Actual Loss: 0.5424\n",
      "Baseline Loss: 2.6856 | Actual Loss: 0.1859\n",
      "Baseline Loss: 2.6416 | Actual Loss: 0.3758\n",
      "Baseline Loss: 2.6455 | Actual Loss: 0.4525\n",
      "Baseline Loss: 2.6740 | Actual Loss: 0.6365\n",
      "Baseline Loss: 2.6825 | Actual Loss: 0.4226\n",
      "Baseline Loss: 2.6753 | Actual Loss: 1.0759\n",
      "Baseline Loss: 2.6603 | Actual Loss: 0.7952\n",
      "Baseline Loss: 2.6473 | Actual Loss: 0.2918\n",
      "Baseline Loss: 2.6427 | Actual Loss: 0.5695\n",
      "Baseline Loss: 2.6808 | Actual Loss: 0.4024\n",
      "Baseline Loss: 2.6567 | Actual Loss: 2.1921\n",
      "Baseline Loss: 2.6721 | Actual Loss: 0.7894\n",
      "Baseline Loss: 2.6862 | Actual Loss: 0.4792\n",
      "Baseline Loss: 2.3736 | Actual Loss: 2.1678\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9279\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██▏       | 214/1000 [02:15<08:26,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7015 | Actual Loss: 0.4246\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.8800\n",
      "Epoch 214/1000: Train Loss: 0.7482, Val Loss: 0.6430\n",
      "Baseline Loss: 2.6644 | Actual Loss: 1.5572\n",
      "Baseline Loss: 2.6695 | Actual Loss: 0.4048\n",
      "Baseline Loss: 2.6681 | Actual Loss: 0.5110\n",
      "Baseline Loss: 2.6904 | Actual Loss: 0.4179\n",
      "Baseline Loss: 2.6855 | Actual Loss: 0.4791\n",
      "Baseline Loss: 2.6695 | Actual Loss: 0.9054\n",
      "Baseline Loss: 2.7064 | Actual Loss: 0.1653\n",
      "Baseline Loss: 2.6693 | Actual Loss: 0.3723\n",
      "Baseline Loss: 2.6932 | Actual Loss: 0.4159\n",
      "Baseline Loss: 2.6680 | Actual Loss: 0.5782\n",
      "Baseline Loss: 2.6649 | Actual Loss: 0.4621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 215/1000 [02:15<08:14,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6680 | Actual Loss: 0.4748\n",
      "Baseline Loss: 2.6721 | Actual Loss: 0.2838\n",
      "Baseline Loss: 2.6673 | Actual Loss: 0.1526\n",
      "Baseline Loss: 2.6755 | Actual Loss: 0.6130\n",
      "Baseline Loss: 2.2522 | Actual Loss: 0.4975\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.7364\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3357\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3941\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.4597\n",
      "Epoch 215/1000: Train Loss: 0.5182, Val Loss: 0.4815\n",
      "Baseline Loss: 2.6633 | Actual Loss: 0.6946\n",
      "Baseline Loss: 2.6795 | Actual Loss: 0.5320\n",
      "Baseline Loss: 2.6433 | Actual Loss: 0.6640\n",
      "Baseline Loss: 2.6658 | Actual Loss: 0.3195\n",
      "Baseline Loss: 2.6670 | Actual Loss: 0.2656\n",
      "Baseline Loss: 2.6573 | Actual Loss: 1.4467\n",
      "Baseline Loss: 2.7229 | Actual Loss: 0.9873\n",
      "Baseline Loss: 2.6076 | Actual Loss: 0.7258\n",
      "Baseline Loss: 2.6868 | Actual Loss: 0.3344\n",
      "Baseline Loss: 2.6841 | Actual Loss: 0.4938\n",
      "Baseline Loss: 2.6766 | Actual Loss: 0.3103\n",
      "Baseline Loss: 2.7053 | Actual Loss: 0.7792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 216/1000 [02:16<08:15,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6736 | Actual Loss: 0.7466\n",
      "Baseline Loss: 2.6611 | Actual Loss: 0.3476\n",
      "Baseline Loss: 2.6793 | Actual Loss: 0.6771\n",
      "Baseline Loss: 2.3038 | Actual Loss: 0.5788\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9747\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.2733\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.4125\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.5623\n",
      "Epoch 216/1000: Train Loss: 0.6189, Val Loss: 0.5557\n",
      "Baseline Loss: 2.6571 | Actual Loss: 0.6087\n",
      "Baseline Loss: 2.6868 | Actual Loss: 0.2279\n",
      "Baseline Loss: 2.6482 | Actual Loss: 2.4611\n",
      "Baseline Loss: 2.7131 | Actual Loss: 0.8145\n",
      "Baseline Loss: 2.6361 | Actual Loss: 0.2375\n",
      "Baseline Loss: 2.7195 | Actual Loss: 2.6744\n",
      "Baseline Loss: 2.7137 | Actual Loss: 0.3066\n",
      "Baseline Loss: 2.6659 | Actual Loss: 0.4662\n",
      "Baseline Loss: 2.6633 | Actual Loss: 2.0574\n",
      "Baseline Loss: 2.6576 | Actual Loss: 0.4292\n",
      "Baseline Loss: 2.6834 | Actual Loss: 0.1874\n",
      "Baseline Loss: 2.6450 | Actual Loss: 0.2930\n",
      "Baseline Loss: 2.6821 | Actual Loss: 0.7673\n",
      "Baseline Loss: 2.6737 | Actual Loss: 0.4940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 217/1000 [02:16<08:02,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6520 | Actual Loss: 1.2677\n",
      "Baseline Loss: 2.4147 | Actual Loss: 0.2824\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.0601\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4457\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3817\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.5003\n",
      "Epoch 217/1000: Train Loss: 0.8485, Val Loss: 0.5970\n",
      "Baseline Loss: 2.6829 | Actual Loss: 0.4115\n",
      "Baseline Loss: 2.7128 | Actual Loss: 0.8360\n",
      "Baseline Loss: 2.6996 | Actual Loss: 0.4375\n",
      "Baseline Loss: 2.6579 | Actual Loss: 0.2259\n",
      "Baseline Loss: 2.6585 | Actual Loss: 0.7428\n",
      "Baseline Loss: 2.7140 | Actual Loss: 0.3243\n",
      "Baseline Loss: 2.6381 | Actual Loss: 2.4690\n",
      "Baseline Loss: 2.6279 | Actual Loss: 0.1259\n",
      "Baseline Loss: 2.6746 | Actual Loss: 0.7852\n",
      "Baseline Loss: 2.6810 | Actual Loss: 0.8093\n",
      "Baseline Loss: 2.6904 | Actual Loss: 0.3324\n",
      "Baseline Loss: 2.6775 | Actual Loss: 1.0018\n",
      "Baseline Loss: 2.6829 | Actual Loss: 0.1258\n",
      "Baseline Loss: 2.6959 | Actual Loss: 0.5968\n",
      "Baseline Loss: 2.6613 | Actual Loss: 0.3808\n",
      "Baseline Loss: 2.2548 | Actual Loss: 0.1933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 218/1000 [02:17<08:15,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7315 | Actual Loss: 1.0041\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4590\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3521\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.6465\n",
      "Epoch 218/1000: Train Loss: 0.6124, Val Loss: 0.6154\n",
      "Baseline Loss: 2.7051 | Actual Loss: 0.8729\n",
      "Baseline Loss: 2.6603 | Actual Loss: 0.8883\n",
      "Baseline Loss: 2.6982 | Actual Loss: 0.5866\n",
      "Baseline Loss: 2.6711 | Actual Loss: 0.3473\n",
      "Baseline Loss: 2.6888 | Actual Loss: 0.6183\n",
      "Baseline Loss: 2.6782 | Actual Loss: 2.3668\n",
      "Baseline Loss: 2.6903 | Actual Loss: 0.3917\n",
      "Baseline Loss: 2.6948 | Actual Loss: 0.2489\n",
      "Baseline Loss: 2.6837 | Actual Loss: 0.5186\n",
      "Baseline Loss: 2.6635 | Actual Loss: 0.4308\n",
      "Baseline Loss: 2.6760 | Actual Loss: 0.2926\n",
      "Baseline Loss: 2.6408 | Actual Loss: 0.4779\n",
      "Baseline Loss: 2.6723 | Actual Loss: 0.5645\n",
      "Baseline Loss: 2.6627 | Actual Loss: 0.1797\n",
      "Baseline Loss: 2.6887 | Actual Loss: 0.5549\n",
      "Baseline Loss: 2.2933 | Actual Loss: 0.3048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 219/1000 [02:18<08:15,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7315 | Actual Loss: 0.8821\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3843\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3917\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.7420\n",
      "Epoch 219/1000: Train Loss: 0.6028, Val Loss: 0.6000\n",
      "Baseline Loss: 2.6487 | Actual Loss: 0.8124\n",
      "Baseline Loss: 2.6907 | Actual Loss: 1.7961\n",
      "Baseline Loss: 2.6974 | Actual Loss: 0.6728\n",
      "Baseline Loss: 2.6575 | Actual Loss: 0.3965\n",
      "Baseline Loss: 2.6322 | Actual Loss: 0.5618\n",
      "Baseline Loss: 2.6676 | Actual Loss: 0.2225\n",
      "Baseline Loss: 2.6731 | Actual Loss: 0.5866\n",
      "Baseline Loss: 2.6631 | Actual Loss: 0.2733\n",
      "Baseline Loss: 2.7140 | Actual Loss: 0.6179\n",
      "Baseline Loss: 2.6624 | Actual Loss: 0.2974\n",
      "Baseline Loss: 2.6646 | Actual Loss: 0.6915\n",
      "Baseline Loss: 2.6974 | Actual Loss: 0.3905\n",
      "Baseline Loss: 2.6977 | Actual Loss: 0.7391\n",
      "Baseline Loss: 2.6788 | Actual Loss: 0.9558\n",
      "Baseline Loss: 2.6521 | Actual Loss: 0.4101\n",
      "Baseline Loss: 2.2693 | Actual Loss: 0.2564\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 220/1000 [02:18<08:08,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6435 | Actual Loss: 0.3737\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.4475\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.5249\n",
      "Epoch 220/1000: Train Loss: 0.6050, Val Loss: 0.5697\n",
      "Baseline Loss: 2.6946 | Actual Loss: 0.5497\n",
      "Baseline Loss: 2.6723 | Actual Loss: 0.5601\n",
      "Baseline Loss: 2.6643 | Actual Loss: 0.4892\n",
      "Baseline Loss: 2.6869 | Actual Loss: 0.5821\n",
      "Baseline Loss: 2.6805 | Actual Loss: 0.2603\n",
      "Baseline Loss: 2.6475 | Actual Loss: 2.0950\n",
      "Baseline Loss: 2.6668 | Actual Loss: 1.1523\n",
      "Baseline Loss: 2.6869 | Actual Loss: 0.4594\n",
      "Baseline Loss: 2.6502 | Actual Loss: 0.2599\n",
      "Baseline Loss: 2.7034 | Actual Loss: 0.5636\n",
      "Baseline Loss: 2.7191 | Actual Loss: 0.9295\n",
      "Baseline Loss: 2.6452 | Actual Loss: 0.3310\n",
      "Baseline Loss: 2.6905 | Actual Loss: 0.6330\n",
      "Baseline Loss: 2.6545 | Actual Loss: 0.4345\n",
      "Baseline Loss: 2.6468 | Actual Loss: 0.2053\n",
      "Baseline Loss: 2.2323 | Actual Loss: 1.0761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 221/1000 [02:19<08:16,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7315 | Actual Loss: 0.9906\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3220\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3843\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.8700\n",
      "Epoch 221/1000: Train Loss: 0.6613, Val Loss: 0.6417\n",
      "Baseline Loss: 2.6340 | Actual Loss: 0.5664\n",
      "Baseline Loss: 2.7180 | Actual Loss: 0.3665\n",
      "Baseline Loss: 2.6449 | Actual Loss: 0.7045\n",
      "Baseline Loss: 2.6868 | Actual Loss: 0.3049\n",
      "Baseline Loss: 2.6561 | Actual Loss: 0.5337\n",
      "Baseline Loss: 2.6757 | Actual Loss: 0.8129\n",
      "Baseline Loss: 2.6888 | Actual Loss: 0.5344\n",
      "Baseline Loss: 2.6674 | Actual Loss: 0.4713\n",
      "Baseline Loss: 2.6450 | Actual Loss: 0.9881\n",
      "Baseline Loss: 2.6725 | Actual Loss: 2.9457\n",
      "Baseline Loss: 2.6763 | Actual Loss: 0.7486\n",
      "Baseline Loss: 2.7107 | Actual Loss: 0.4953\n",
      "Baseline Loss: 2.6591 | Actual Loss: 0.1732\n",
      "Baseline Loss: 2.6648 | Actual Loss: 0.4623\n",
      "Baseline Loss: 2.6962 | Actual Loss: 0.3522\n",
      "Baseline Loss: 2.2666 | Actual Loss: 1.9901\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 222/1000 [02:20<08:15,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6435 | Actual Loss: 0.2503\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.2376\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.5356\n",
      "Epoch 222/1000: Train Loss: 0.7781, Val Loss: 0.4935\n",
      "Baseline Loss: 2.6692 | Actual Loss: 0.2740\n",
      "Baseline Loss: 2.6692 | Actual Loss: 0.4954\n",
      "Baseline Loss: 2.6882 | Actual Loss: 0.5272\n",
      "Baseline Loss: 2.6536 | Actual Loss: 0.3406\n",
      "Baseline Loss: 2.6530 | Actual Loss: 0.7238\n",
      "Baseline Loss: 2.6630 | Actual Loss: 0.4174\n",
      "Baseline Loss: 2.6536 | Actual Loss: 0.2712\n",
      "Baseline Loss: 2.6660 | Actual Loss: 0.6535\n",
      "Baseline Loss: 2.6693 | Actual Loss: 0.8314\n",
      "Baseline Loss: 2.7284 | Actual Loss: 0.6443\n",
      "Baseline Loss: 2.7253 | Actual Loss: 0.6230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 223/1000 [02:20<08:07,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6422 | Actual Loss: 0.4439\n",
      "Baseline Loss: 2.6462 | Actual Loss: 0.1932\n",
      "Baseline Loss: 2.6814 | Actual Loss: 0.3079\n",
      "Baseline Loss: 2.6564 | Actual Loss: 0.6325\n",
      "Baseline Loss: 2.2320 | Actual Loss: 0.4006\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9361\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.2971\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3979\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.5933\n",
      "Epoch 223/1000: Train Loss: 0.4863, Val Loss: 0.5561\n",
      "Baseline Loss: 2.6545 | Actual Loss: 0.7089\n",
      "Baseline Loss: 2.6373 | Actual Loss: 0.4447\n",
      "Baseline Loss: 2.7327 | Actual Loss: 0.4033\n",
      "Baseline Loss: 2.6677 | Actual Loss: 0.6670\n",
      "Baseline Loss: 2.6361 | Actual Loss: 2.4452\n",
      "Baseline Loss: 2.6550 | Actual Loss: 0.7108\n",
      "Baseline Loss: 2.6739 | Actual Loss: 2.1417\n",
      "Baseline Loss: 2.6614 | Actual Loss: 0.2916\n",
      "Baseline Loss: 2.7078 | Actual Loss: 0.5163\n",
      "Baseline Loss: 2.6549 | Actual Loss: 0.7494\n",
      "Baseline Loss: 2.6885 | Actual Loss: 0.1477\n",
      "Baseline Loss: 2.6773 | Actual Loss: 0.4977\n",
      "Baseline Loss: 2.6721 | Actual Loss: 1.0034\n",
      "Baseline Loss: 2.6729 | Actual Loss: 0.2577\n",
      "Baseline Loss: 2.6841 | Actual Loss: 0.5433\n",
      "Baseline Loss: 2.2719 | Actual Loss: 0.1293\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 224/1000 [02:21<08:16,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6435 | Actual Loss: 0.3748\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3764\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.7318\n",
      "Epoch 224/1000: Train Loss: 0.7286, Val Loss: 0.6043\n",
      "Baseline Loss: 2.6682 | Actual Loss: 0.5980\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.3324\n",
      "Baseline Loss: 2.6814 | Actual Loss: 0.6839\n",
      "Baseline Loss: 2.6522 | Actual Loss: 0.4312\n",
      "Baseline Loss: 2.6596 | Actual Loss: 0.4313\n",
      "Baseline Loss: 2.6501 | Actual Loss: 0.6565\n",
      "Baseline Loss: 2.6787 | Actual Loss: 0.4061\n",
      "Baseline Loss: 2.6653 | Actual Loss: 1.0093\n",
      "Baseline Loss: 2.6509 | Actual Loss: 0.2166\n",
      "Baseline Loss: 2.6783 | Actual Loss: 0.4090\n",
      "Baseline Loss: 2.6832 | Actual Loss: 0.6199\n",
      "Baseline Loss: 2.6382 | Actual Loss: 2.9530\n",
      "Baseline Loss: 2.6592 | Actual Loss: 0.5061\n",
      "Baseline Loss: 2.6559 | Actual Loss: 2.8733\n",
      "Baseline Loss: 2.6827 | Actual Loss: 0.5992\n",
      "Baseline Loss: 2.2699 | Actual Loss: 1.9338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▎       | 225/1000 [02:22<08:27,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7315 | Actual Loss: 0.8357\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4353\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3419\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.4685\n",
      "Epoch 225/1000: Train Loss: 0.9162, Val Loss: 0.5203\n",
      "Baseline Loss: 2.7060 | Actual Loss: 0.4272\n",
      "Baseline Loss: 2.7020 | Actual Loss: 0.2685\n",
      "Baseline Loss: 2.6737 | Actual Loss: 0.1636\n",
      "Baseline Loss: 2.6598 | Actual Loss: 0.5444\n",
      "Baseline Loss: 2.6378 | Actual Loss: 2.2984\n",
      "Baseline Loss: 2.6803 | Actual Loss: 0.7372\n",
      "Baseline Loss: 2.6363 | Actual Loss: 0.5656\n",
      "Baseline Loss: 2.6724 | Actual Loss: 0.5316\n",
      "Baseline Loss: 2.6942 | Actual Loss: 0.4548\n",
      "Baseline Loss: 2.7047 | Actual Loss: 0.3762\n",
      "Baseline Loss: 2.6580 | Actual Loss: 0.6959\n",
      "Baseline Loss: 2.6821 | Actual Loss: 0.7231\n",
      "Baseline Loss: 2.6565 | Actual Loss: 0.4843\n",
      "Baseline Loss: 2.6845 | Actual Loss: 0.3066\n",
      "Baseline Loss: 2.6660 | Actual Loss: 0.4906\n",
      "Baseline Loss: 2.2845 | Actual Loss: 1.3346\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.8752\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4408\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.4279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 226/1000 [02:22<08:31,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5568 | Actual Loss: 0.6361\n",
      "Epoch 226/1000: Train Loss: 0.6502, Val Loss: 0.5950\n",
      "Baseline Loss: 2.6778 | Actual Loss: 0.6991\n",
      "Baseline Loss: 2.6451 | Actual Loss: 1.0816\n",
      "Baseline Loss: 2.7229 | Actual Loss: 0.6612\n",
      "Baseline Loss: 2.6624 | Actual Loss: 0.4658\n",
      "Baseline Loss: 2.6932 | Actual Loss: 0.8026\n",
      "Baseline Loss: 2.6399 | Actual Loss: 0.2542\n",
      "Baseline Loss: 2.6888 | Actual Loss: 0.2438\n",
      "Baseline Loss: 2.6639 | Actual Loss: 0.7667\n",
      "Baseline Loss: 2.6949 | Actual Loss: 0.8770\n",
      "Baseline Loss: 2.6439 | Actual Loss: 0.5416\n",
      "Baseline Loss: 2.6783 | Actual Loss: 0.5020\n",
      "Baseline Loss: 2.6579 | Actual Loss: 0.9908\n",
      "Baseline Loss: 2.7061 | Actual Loss: 0.4648\n",
      "Baseline Loss: 2.6787 | Actual Loss: 0.4133\n",
      "Baseline Loss: 2.6631 | Actual Loss: 0.4365\n",
      "Baseline Loss: 2.2569 | Actual Loss: 0.6297\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9295\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.2671\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.2772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 227/1000 [02:23<08:19,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5568 | Actual Loss: 0.4529\n",
      "Epoch 227/1000: Train Loss: 0.6144, Val Loss: 0.4817\n",
      "Baseline Loss: 2.6659 | Actual Loss: 0.3443\n",
      "Baseline Loss: 2.6908 | Actual Loss: 0.2202\n",
      "Baseline Loss: 2.6876 | Actual Loss: 0.4687\n",
      "Baseline Loss: 2.6619 | Actual Loss: 0.3581\n",
      "Baseline Loss: 2.6802 | Actual Loss: 0.3116\n",
      "Baseline Loss: 2.6825 | Actual Loss: 0.2761\n",
      "Baseline Loss: 2.6916 | Actual Loss: 0.2515\n",
      "Baseline Loss: 2.6819 | Actual Loss: 0.3638\n",
      "Baseline Loss: 2.6527 | Actual Loss: 0.6181\n",
      "Baseline Loss: 2.6629 | Actual Loss: 0.4654\n",
      "Baseline Loss: 2.6496 | Actual Loss: 0.3883\n",
      "Baseline Loss: 2.6875 | Actual Loss: 0.9980\n",
      "Baseline Loss: 2.6586 | Actual Loss: 1.3443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 228/1000 [02:23<08:16,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6673 | Actual Loss: 0.5478\n",
      "Baseline Loss: 2.6956 | Actual Loss: 0.6686\n",
      "Baseline Loss: 2.2981 | Actual Loss: 0.3568\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.8775\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3797\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3334\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.4445\n",
      "Epoch 228/1000: Train Loss: 0.4989, Val Loss: 0.5088\n",
      "Baseline Loss: 2.6762 | Actual Loss: 0.5312\n",
      "Baseline Loss: 2.6683 | Actual Loss: 0.4428\n",
      "Baseline Loss: 2.6805 | Actual Loss: 0.4440\n",
      "Baseline Loss: 2.6593 | Actual Loss: 0.3554\n",
      "Baseline Loss: 2.6895 | Actual Loss: 0.7991\n",
      "Baseline Loss: 2.6488 | Actual Loss: 0.2682\n",
      "Baseline Loss: 2.7121 | Actual Loss: 0.1442\n",
      "Baseline Loss: 2.6678 | Actual Loss: 2.2637\n",
      "Baseline Loss: 2.7146 | Actual Loss: 0.9569\n",
      "Baseline Loss: 2.6865 | Actual Loss: 0.5759\n",
      "Baseline Loss: 2.6584 | Actual Loss: 0.5575\n",
      "Baseline Loss: 2.6787 | Actual Loss: 0.6418\n",
      "Baseline Loss: 2.6662 | Actual Loss: 0.5113\n",
      "Baseline Loss: 2.6393 | Actual Loss: 0.4095\n",
      "Baseline Loss: 2.6600 | Actual Loss: 0.2806\n",
      "Baseline Loss: 2.2426 | Actual Loss: 0.5209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 229/1000 [02:24<08:24,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7315 | Actual Loss: 0.8111\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.5083\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3668\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.7728\n",
      "Epoch 229/1000: Train Loss: 0.6064, Val Loss: 0.6147\n",
      "Baseline Loss: 2.6411 | Actual Loss: 0.2427\n",
      "Baseline Loss: 2.6517 | Actual Loss: 0.8493\n",
      "Baseline Loss: 2.6714 | Actual Loss: 1.3457\n",
      "Baseline Loss: 2.7001 | Actual Loss: 0.1887\n",
      "Baseline Loss: 2.6701 | Actual Loss: 0.2751\n",
      "Baseline Loss: 2.6731 | Actual Loss: 0.7475\n",
      "Baseline Loss: 2.6778 | Actual Loss: 0.6673\n",
      "Baseline Loss: 2.6972 | Actual Loss: 0.4755\n",
      "Baseline Loss: 2.6450 | Actual Loss: 0.5950\n",
      "Baseline Loss: 2.6618 | Actual Loss: 0.6661\n",
      "Baseline Loss: 2.7088 | Actual Loss: 0.3285\n",
      "Baseline Loss: 2.6709 | Actual Loss: 0.2565\n",
      "Baseline Loss: 2.6557 | Actual Loss: 0.3221\n",
      "Baseline Loss: 2.6459 | Actual Loss: 0.4468\n",
      "Baseline Loss: 2.6654 | Actual Loss: 0.5341\n",
      "Baseline Loss: 2.3065 | Actual Loss: 0.2678\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.7389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 230/1000 [02:25<08:05,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6435 | Actual Loss: 0.3128\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.4317\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.5964\n",
      "Epoch 230/1000: Train Loss: 0.5130, Val Loss: 0.5199\n",
      "Baseline Loss: 2.7060 | Actual Loss: 0.4412\n",
      "Baseline Loss: 2.6800 | Actual Loss: 0.8963\n",
      "Baseline Loss: 2.6672 | Actual Loss: 2.5156\n",
      "Baseline Loss: 2.7204 | Actual Loss: 0.5969\n",
      "Baseline Loss: 2.6750 | Actual Loss: 0.2478\n",
      "Baseline Loss: 2.6517 | Actual Loss: 0.8281\n",
      "Baseline Loss: 2.6520 | Actual Loss: 0.4621\n",
      "Baseline Loss: 2.6609 | Actual Loss: 0.8122\n",
      "Baseline Loss: 2.6441 | Actual Loss: 0.6311\n",
      "Baseline Loss: 2.6603 | Actual Loss: 0.8059\n",
      "Baseline Loss: 2.6621 | Actual Loss: 0.2337\n",
      "Baseline Loss: 2.6443 | Actual Loss: 0.3577\n",
      "Baseline Loss: 2.6701 | Actual Loss: 0.4055\n",
      "Baseline Loss: 2.7065 | Actual Loss: 0.2330\n",
      "Baseline Loss: 2.6705 | Actual Loss: 0.4274\n",
      "Baseline Loss: 2.2467 | Actual Loss: 2.0208\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.8959\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 231/1000 [02:25<08:12,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7015 | Actual Loss: 0.4331\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.4812\n",
      "Epoch 231/1000: Train Loss: 0.7447, Val Loss: 0.5639\n",
      "Baseline Loss: 2.6554 | Actual Loss: 0.4871\n",
      "Baseline Loss: 2.6752 | Actual Loss: 0.5444\n",
      "Baseline Loss: 2.6742 | Actual Loss: 0.5631\n",
      "Baseline Loss: 2.6430 | Actual Loss: 0.3676\n",
      "Baseline Loss: 2.6564 | Actual Loss: 0.4549\n",
      "Baseline Loss: 2.7532 | Actual Loss: 0.5727\n",
      "Baseline Loss: 2.6397 | Actual Loss: 1.6434\n",
      "Baseline Loss: 2.6523 | Actual Loss: 0.7371\n",
      "Baseline Loss: 2.6662 | Actual Loss: 0.6236\n",
      "Baseline Loss: 2.6904 | Actual Loss: 0.3858\n",
      "Baseline Loss: 2.6984 | Actual Loss: 0.6992\n",
      "Baseline Loss: 2.6789 | Actual Loss: 2.6926\n",
      "Baseline Loss: 2.6973 | Actual Loss: 0.4480\n",
      "Baseline Loss: 2.6424 | Actual Loss: 0.4945\n",
      "Baseline Loss: 2.7056 | Actual Loss: 1.0998\n",
      "Baseline Loss: 2.2653 | Actual Loss: 1.6842\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 232/1000 [02:26<08:20,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6435 | Actual Loss: 0.3874\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.4216\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.6654\n",
      "Epoch 232/1000: Train Loss: 0.8436, Val Loss: 0.6169\n",
      "Baseline Loss: 2.7129 | Actual Loss: 0.9106\n",
      "Baseline Loss: 2.6558 | Actual Loss: 0.6574\n",
      "Baseline Loss: 2.6856 | Actual Loss: 0.4138\n",
      "Baseline Loss: 2.6451 | Actual Loss: 0.4078\n",
      "Baseline Loss: 2.6536 | Actual Loss: 0.5732\n",
      "Baseline Loss: 2.6379 | Actual Loss: 0.2722\n",
      "Baseline Loss: 2.6792 | Actual Loss: 2.2398\n",
      "Baseline Loss: 2.7088 | Actual Loss: 0.4123\n",
      "Baseline Loss: 2.6632 | Actual Loss: 0.9484\n",
      "Baseline Loss: 2.6743 | Actual Loss: 0.5716\n",
      "Baseline Loss: 2.6775 | Actual Loss: 0.2965\n",
      "Baseline Loss: 2.6485 | Actual Loss: 0.6947\n",
      "Baseline Loss: 2.6788 | Actual Loss: 0.4671\n",
      "Baseline Loss: 2.6527 | Actual Loss: 0.4633\n",
      "Baseline Loss: 2.6883 | Actual Loss: 0.7838\n",
      "Baseline Loss: 2.2295 | Actual Loss: 0.2114\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.0292\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 233/1000 [02:27<08:09,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7015 | Actual Loss: 0.3629\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.4062\n",
      "Epoch 233/1000: Train Loss: 0.6452, Val Loss: 0.5376\n",
      "Baseline Loss: 2.6191 | Actual Loss: 0.5217\n",
      "Baseline Loss: 2.7079 | Actual Loss: 0.3585\n",
      "Baseline Loss: 2.6817 | Actual Loss: 0.3213\n",
      "Baseline Loss: 2.6555 | Actual Loss: 0.5737\n",
      "Baseline Loss: 2.6510 | Actual Loss: 0.6818\n",
      "Baseline Loss: 2.6740 | Actual Loss: 0.7078\n",
      "Baseline Loss: 2.6753 | Actual Loss: 0.7031\n",
      "Baseline Loss: 2.6937 | Actual Loss: 0.6087\n",
      "Baseline Loss: 2.7181 | Actual Loss: 0.5212\n",
      "Baseline Loss: 2.6575 | Actual Loss: 0.5495\n",
      "Baseline Loss: 2.6707 | Actual Loss: 0.8565\n",
      "Baseline Loss: 2.6522 | Actual Loss: 0.3654\n",
      "Baseline Loss: 2.6780 | Actual Loss: 0.4392\n",
      "Baseline Loss: 2.7033 | Actual Loss: 2.4261\n",
      "Baseline Loss: 2.7113 | Actual Loss: 0.9907\n",
      "Baseline Loss: 2.2626 | Actual Loss: 0.2219\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.8599\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 234/1000 [02:27<08:08,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7015 | Actual Loss: 0.3566\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.4537\n",
      "Epoch 234/1000: Train Loss: 0.6779, Val Loss: 0.4979\n",
      "Baseline Loss: 2.6854 | Actual Loss: 0.6001\n",
      "Baseline Loss: 2.6925 | Actual Loss: 0.2647\n",
      "Baseline Loss: 2.6752 | Actual Loss: 0.5067\n",
      "Baseline Loss: 2.6528 | Actual Loss: 2.3247\n",
      "Baseline Loss: 2.6448 | Actual Loss: 0.5012\n",
      "Baseline Loss: 2.6749 | Actual Loss: 0.6276\n",
      "Baseline Loss: 2.6861 | Actual Loss: 0.4043\n",
      "Baseline Loss: 2.6191 | Actual Loss: 1.9751\n",
      "Baseline Loss: 2.6524 | Actual Loss: 0.2745\n",
      "Baseline Loss: 2.6645 | Actual Loss: 0.4291\n",
      "Baseline Loss: 2.6577 | Actual Loss: 0.3082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██▎       | 235/1000 [02:28<07:49,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7273 | Actual Loss: 0.6708\n",
      "Baseline Loss: 2.6890 | Actual Loss: 1.0053\n",
      "Baseline Loss: 2.6691 | Actual Loss: 0.3450\n",
      "Baseline Loss: 2.7412 | Actual Loss: 0.6538\n",
      "Baseline Loss: 2.3258 | Actual Loss: 1.7879\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9866\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4306\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.4423\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.7188\n",
      "Epoch 235/1000: Train Loss: 0.7924, Val Loss: 0.6446\n",
      "Baseline Loss: 2.6821 | Actual Loss: 0.3889\n",
      "Baseline Loss: 2.6787 | Actual Loss: 0.5013\n",
      "Baseline Loss: 2.6438 | Actual Loss: 0.5189\n",
      "Baseline Loss: 2.6498 | Actual Loss: 0.5370\n",
      "Baseline Loss: 2.6726 | Actual Loss: 0.8690\n",
      "Baseline Loss: 2.6622 | Actual Loss: 0.4800\n",
      "Baseline Loss: 2.6971 | Actual Loss: 0.4855\n",
      "Baseline Loss: 2.6353 | Actual Loss: 0.8448\n",
      "Baseline Loss: 2.6934 | Actual Loss: 0.2989\n",
      "Baseline Loss: 2.6591 | Actual Loss: 0.6558\n",
      "Baseline Loss: 2.6613 | Actual Loss: 0.5689\n",
      "Baseline Loss: 2.6853 | Actual Loss: 0.3523\n",
      "Baseline Loss: 2.6457 | Actual Loss: 0.1477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██▎       | 236/1000 [02:29<08:01,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7045 | Actual Loss: 0.5685\n",
      "Baseline Loss: 2.6815 | Actual Loss: 0.4514\n",
      "Baseline Loss: 2.2663 | Actual Loss: 1.0242\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.8003\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3489\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3597\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.4327\n",
      "Epoch 236/1000: Train Loss: 0.5433, Val Loss: 0.4854\n",
      "Baseline Loss: 2.6449 | Actual Loss: 0.5869\n",
      "Baseline Loss: 2.6522 | Actual Loss: 2.8975\n",
      "Baseline Loss: 2.7174 | Actual Loss: 0.5027\n",
      "Baseline Loss: 2.6560 | Actual Loss: 0.7537\n",
      "Baseline Loss: 2.6639 | Actual Loss: 0.2375\n",
      "Baseline Loss: 2.7741 | Actual Loss: 0.5160\n",
      "Baseline Loss: 2.7103 | Actual Loss: 0.5733\n",
      "Baseline Loss: 2.6641 | Actual Loss: 2.3217\n",
      "Baseline Loss: 2.6684 | Actual Loss: 0.2545\n",
      "Baseline Loss: 2.6758 | Actual Loss: 0.4517\n",
      "Baseline Loss: 2.6336 | Actual Loss: 0.8021\n",
      "Baseline Loss: 2.6974 | Actual Loss: 2.4518\n",
      "Baseline Loss: 2.6518 | Actual Loss: 0.3533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██▎       | 237/1000 [02:29<08:10,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7061 | Actual Loss: 0.3061\n",
      "Baseline Loss: 2.6530 | Actual Loss: 0.6314\n",
      "Baseline Loss: 2.3258 | Actual Loss: 2.1437\n",
      "Baseline Loss: 2.7315 | Actual Loss: 1.0293\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.4305\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3674\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.7164\n",
      "Epoch 237/1000: Train Loss: 0.9865, Val Loss: 0.6359\n",
      "Baseline Loss: 2.6776 | Actual Loss: 0.4803\n",
      "Baseline Loss: 2.6772 | Actual Loss: 0.7708\n",
      "Baseline Loss: 2.6743 | Actual Loss: 0.6000\n",
      "Baseline Loss: 2.6918 | Actual Loss: 0.3221\n",
      "Baseline Loss: 2.7079 | Actual Loss: 0.3231\n",
      "Baseline Loss: 2.6975 | Actual Loss: 0.6055\n",
      "Baseline Loss: 2.6334 | Actual Loss: 1.0628\n",
      "Baseline Loss: 2.6847 | Actual Loss: 2.0780\n",
      "Baseline Loss: 2.6227 | Actual Loss: 0.3960\n",
      "Baseline Loss: 2.6425 | Actual Loss: 0.4129\n",
      "Baseline Loss: 2.6979 | Actual Loss: 0.4564\n",
      "Baseline Loss: 2.7065 | Actual Loss: 0.5787\n",
      "Baseline Loss: 2.6526 | Actual Loss: 0.5138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██▍       | 238/1000 [02:30<08:02,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6540 | Actual Loss: 0.4812\n",
      "Baseline Loss: 2.6511 | Actual Loss: 0.6059\n",
      "Baseline Loss: 2.3023 | Actual Loss: 0.0991\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9752\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3483\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.1745\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.7388\n",
      "Epoch 238/1000: Train Loss: 0.6117, Val Loss: 0.5592\n",
      "Baseline Loss: 2.6803 | Actual Loss: 0.3507\n",
      "Baseline Loss: 2.6778 | Actual Loss: 0.3642\n",
      "Baseline Loss: 2.6858 | Actual Loss: 0.7729\n",
      "Baseline Loss: 2.6627 | Actual Loss: 0.5450\n",
      "Baseline Loss: 2.6832 | Actual Loss: 0.7353\n",
      "Baseline Loss: 2.6344 | Actual Loss: 0.2685\n",
      "Baseline Loss: 2.6205 | Actual Loss: 0.4630\n",
      "Baseline Loss: 2.6762 | Actual Loss: 0.8092\n",
      "Baseline Loss: 2.6708 | Actual Loss: 0.6812\n",
      "Baseline Loss: 2.7024 | Actual Loss: 0.5119\n",
      "Baseline Loss: 2.6712 | Actual Loss: 0.9364\n",
      "Baseline Loss: 2.6603 | Actual Loss: 0.4291\n",
      "Baseline Loss: 2.6960 | Actual Loss: 0.6876\n",
      "Baseline Loss: 2.6747 | Actual Loss: 2.3563\n",
      "Baseline Loss: 2.6529 | Actual Loss: 0.5766\n",
      "Baseline Loss: 2.2948 | Actual Loss: 2.2948\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██▍       | 239/1000 [02:31<08:08,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.6435 | Actual Loss: 0.2715\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.3489\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.6103\n",
      "Epoch 239/1000: Train Loss: 0.7989, Val Loss: 0.5393\n",
      "Baseline Loss: 2.6838 | Actual Loss: 2.5255\n",
      "Baseline Loss: 2.6775 | Actual Loss: 0.2796\n",
      "Baseline Loss: 2.6380 | Actual Loss: 0.7946\n",
      "Baseline Loss: 2.6468 | Actual Loss: 0.4122\n",
      "Baseline Loss: 2.6751 | Actual Loss: 0.3056\n",
      "Baseline Loss: 2.7154 | Actual Loss: 0.5776\n",
      "Baseline Loss: 2.6306 | Actual Loss: 0.2323\n",
      "Baseline Loss: 2.6333 | Actual Loss: 0.5866\n",
      "Baseline Loss: 2.6520 | Actual Loss: 0.5446\n",
      "Baseline Loss: 2.6895 | Actual Loss: 0.4012\n",
      "Baseline Loss: 2.6723 | Actual Loss: 0.4074\n",
      "Baseline Loss: 2.6618 | Actual Loss: 0.4926\n",
      "Baseline Loss: 2.7368 | Actual Loss: 0.0969\n",
      "Baseline Loss: 2.7292 | Actual Loss: 1.5075\n",
      "Baseline Loss: 2.6939 | Actual Loss: 0.4041\n",
      "Baseline Loss: 2.2567 | Actual Loss: 0.5528\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.8161\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3051\n",
      "Baseline Loss: 2.7015 | Actual Loss: 0.2563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██▍       | 240/1000 [02:31<07:52,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.5568 | Actual Loss: 0.4597\n",
      "Epoch 240/1000: Train Loss: 0.6326, Val Loss: 0.4593\n",
      "Baseline Loss: 2.6777 | Actual Loss: 0.7331\n",
      "Baseline Loss: 2.6665 | Actual Loss: 0.6603\n",
      "Baseline Loss: 2.6795 | Actual Loss: 0.2961\n",
      "Baseline Loss: 2.7076 | Actual Loss: 2.4159\n",
      "Baseline Loss: 2.6807 | Actual Loss: 0.6945\n",
      "Baseline Loss: 2.6756 | Actual Loss: 0.4687\n",
      "Baseline Loss: 2.6985 | Actual Loss: 0.3598\n",
      "Baseline Loss: 2.7067 | Actual Loss: 0.5156\n",
      "Baseline Loss: 2.6240 | Actual Loss: 0.4228\n",
      "Baseline Loss: 2.6682 | Actual Loss: 0.2244\n",
      "Baseline Loss: 2.6708 | Actual Loss: 0.3265\n",
      "Baseline Loss: 2.6766 | Actual Loss: 1.0056\n",
      "Baseline Loss: 2.7109 | Actual Loss: 1.2360\n",
      "Baseline Loss: 2.6891 | Actual Loss: 0.5628\n",
      "Baseline Loss: 2.6512 | Actual Loss: 0.4802\n",
      "Baseline Loss: 2.2540 | Actual Loss: 1.8464\n",
      "Baseline Loss: 2.7315 | Actual Loss: 0.9757\n",
      "Baseline Loss: 2.6435 | Actual Loss: 0.3256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██▍       | 240/1000 [02:32<08:02,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.7015 | Actual Loss: 0.3924\n",
      "Baseline Loss: 2.5568 | Actual Loss: 0.5895\n",
      "Epoch 241/1000: Train Loss: 0.7655, Val Loss: 0.5708\n",
      "\n",
      "Early stopping at epoch 241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4466364122927189"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devices = [\"cuda\" if torch.cuda.is_available() else \"cpu\"]\n",
    "model8 = GNNModelWithNewLoss(\n",
    "        num_node_features=data_list[0].x.shape[1],\n",
    "        num_edge_features=data_list[0].edge_attr.shape[1],\n",
    "        num_global_features=data_list[0].global_features.shape[1],\n",
    "        cov_num= 9,\n",
    "        hidden_dim=512,\n",
    "        dropout_rate=0.1,\n",
    "        property_index= 1,\n",
    "        save_path= 'premodels_new/9/1' \n",
    "    ).to(devices[0])\n",
    "\n",
    "model8.train_model(\n",
    "    data_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "364f6bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training will be saved to: premodels_new/9/9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5656 | Actual Loss: 3.5843\n",
      "Baseline Loss: 3.4924 | Actual Loss: 3.4487\n",
      "Baseline Loss: 3.4137 | Actual Loss: 3.3405\n",
      "Baseline Loss: 3.5884 | Actual Loss: 3.5573\n",
      "Baseline Loss: 3.6774 | Actual Loss: 3.6303\n",
      "Baseline Loss: 3.7835 | Actual Loss: 3.7654\n",
      "Baseline Loss: 3.4061 | Actual Loss: 3.4250\n",
      "Baseline Loss: 3.4891 | Actual Loss: 3.3753\n",
      "Baseline Loss: 3.4610 | Actual Loss: 3.3943\n",
      "Baseline Loss: 3.4660 | Actual Loss: 3.4154\n",
      "Baseline Loss: 3.4586 | Actual Loss: 3.3649\n",
      "Baseline Loss: 3.3643 | Actual Loss: 3.3921\n",
      "Baseline Loss: 3.5966 | Actual Loss: 3.4889\n",
      "Baseline Loss: 3.5834 | Actual Loss: 3.5083\n",
      "Baseline Loss: 3.4578 | Actual Loss: 3.4904\n",
      "Baseline Loss: 3.2041 | Actual Loss: 3.1487\n",
      "Baseline Loss: 3.6276 | Actual Loss: 3.5070\n",
      "Baseline Loss: 3.3852 | Actual Loss: 3.2249\n",
      "Baseline Loss: 3.6360 | Actual Loss: 3.6037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 1/1000 [00:00<11:21,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.2186 | Actual Loss: 3.1367\n",
      "Epoch 1/1000: Train Loss: 3.4581, Val Loss: 3.3681\n",
      "New best validation loss: 3.3681\n",
      "Baseline Loss: 3.3203 | Actual Loss: 3.1794\n",
      "Baseline Loss: 3.5541 | Actual Loss: 3.4529\n",
      "Baseline Loss: 3.5285 | Actual Loss: 3.3906\n",
      "Baseline Loss: 3.7367 | Actual Loss: 3.6337\n",
      "Baseline Loss: 3.3608 | Actual Loss: 3.2164\n",
      "Baseline Loss: 3.7471 | Actual Loss: 3.6247\n",
      "Baseline Loss: 3.5129 | Actual Loss: 3.4327\n",
      "Baseline Loss: 3.5533 | Actual Loss: 3.4925\n",
      "Baseline Loss: 3.6011 | Actual Loss: 3.5416\n",
      "Baseline Loss: 3.5710 | Actual Loss: 3.3659\n",
      "Baseline Loss: 3.5366 | Actual Loss: 3.4139\n",
      "Baseline Loss: 3.7522 | Actual Loss: 3.6087\n",
      "Baseline Loss: 3.3831 | Actual Loss: 3.2108\n",
      "Baseline Loss: 3.3926 | Actual Loss: 3.2659\n",
      "Baseline Loss: 3.5495 | Actual Loss: 3.2917\n",
      "Baseline Loss: 3.5727 | Actual Loss: 3.4250\n",
      "Baseline Loss: 3.6276 | Actual Loss: 3.5005\n",
      "Baseline Loss: 3.3852 | Actual Loss: 3.3937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 2/1000 [00:01<09:51,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6360 | Actual Loss: 3.5249\n",
      "Baseline Loss: 3.2186 | Actual Loss: 3.1762\n",
      "Epoch 2/1000: Train Loss: 3.4092, Val Loss: 3.3988\n",
      "Baseline Loss: 3.3280 | Actual Loss: 3.2196\n",
      "Baseline Loss: 3.6923 | Actual Loss: 3.5924\n",
      "Baseline Loss: 3.4896 | Actual Loss: 3.4031\n",
      "Baseline Loss: 3.7465 | Actual Loss: 3.6986\n",
      "Baseline Loss: 3.4627 | Actual Loss: 3.3078\n",
      "Baseline Loss: 3.3369 | Actual Loss: 3.2476\n",
      "Baseline Loss: 3.4110 | Actual Loss: 3.2495\n",
      "Baseline Loss: 3.4610 | Actual Loss: 3.3006\n",
      "Baseline Loss: 3.4497 | Actual Loss: 3.3574\n",
      "Baseline Loss: 3.5088 | Actual Loss: 3.2303\n",
      "Baseline Loss: 3.5656 | Actual Loss: 3.2560\n",
      "Baseline Loss: 3.5537 | Actual Loss: 3.2725\n",
      "Baseline Loss: 3.4918 | Actual Loss: 3.2712\n",
      "Baseline Loss: 3.4853 | Actual Loss: 3.3549\n",
      "Baseline Loss: 3.7124 | Actual Loss: 3.6248\n",
      "Baseline Loss: 3.5730 | Actual Loss: 3.1944\n",
      "Baseline Loss: 3.6276 | Actual Loss: 3.4981\n",
      "Baseline Loss: 3.3852 | Actual Loss: 3.1116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 3/1000 [00:01<10:41,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6360 | Actual Loss: 3.3850\n",
      "Baseline Loss: 3.2186 | Actual Loss: 2.9337\n",
      "Epoch 3/1000: Train Loss: 3.3488, Val Loss: 3.2321\n",
      "New best validation loss: 3.2321\n",
      "Baseline Loss: 3.4624 | Actual Loss: 3.0232\n",
      "Baseline Loss: 3.4669 | Actual Loss: 3.2260\n",
      "Baseline Loss: 3.5922 | Actual Loss: 3.0961\n",
      "Baseline Loss: 3.5573 | Actual Loss: 3.1415\n",
      "Baseline Loss: 3.4653 | Actual Loss: 3.0511\n",
      "Baseline Loss: 3.5119 | Actual Loss: 3.0270\n",
      "Baseline Loss: 3.5409 | Actual Loss: 3.0784\n",
      "Baseline Loss: 3.5870 | Actual Loss: 2.9323\n",
      "Baseline Loss: 3.7323 | Actual Loss: 3.4662\n",
      "Baseline Loss: 3.5011 | Actual Loss: 2.9773\n",
      "Baseline Loss: 3.6187 | Actual Loss: 2.9531\n",
      "Baseline Loss: 3.4657 | Actual Loss: 2.8263\n",
      "Baseline Loss: 3.4928 | Actual Loss: 2.9729\n",
      "Baseline Loss: 3.5922 | Actual Loss: 2.7267\n",
      "Baseline Loss: 3.5838 | Actual Loss: 2.5230\n",
      "Baseline Loss: 3.6524 | Actual Loss: 2.4630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 4/1000 [00:02<10:53,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6276 | Actual Loss: 2.6250\n",
      "Baseline Loss: 3.3852 | Actual Loss: 2.6133\n",
      "Baseline Loss: 3.6360 | Actual Loss: 2.8073\n",
      "Baseline Loss: 3.2186 | Actual Loss: 2.6830\n",
      "Epoch 4/1000: Train Loss: 2.9678, Val Loss: 2.6821\n",
      "New best validation loss: 2.6821\n",
      "Baseline Loss: 3.5448 | Actual Loss: 2.4071\n",
      "Baseline Loss: 3.4817 | Actual Loss: 2.5938\n",
      "Baseline Loss: 3.3234 | Actual Loss: 2.6035\n",
      "Baseline Loss: 3.4853 | Actual Loss: 2.6292\n",
      "Baseline Loss: 3.6455 | Actual Loss: 2.4699\n",
      "Baseline Loss: 3.6411 | Actual Loss: 2.3533\n",
      "Baseline Loss: 3.5376 | Actual Loss: 2.3478\n",
      "Baseline Loss: 3.3988 | Actual Loss: 1.9334\n",
      "Baseline Loss: 3.4061 | Actual Loss: 2.4518\n",
      "Baseline Loss: 3.6415 | Actual Loss: 2.3536\n",
      "Baseline Loss: 3.7521 | Actual Loss: 2.2744\n",
      "Baseline Loss: 3.5447 | Actual Loss: 1.7744\n",
      "Baseline Loss: 3.6004 | Actual Loss: 2.7730\n",
      "Baseline Loss: 3.6054 | Actual Loss: 2.0825\n",
      "Baseline Loss: 3.5370 | Actual Loss: 2.0804\n",
      "Baseline Loss: 3.4207 | Actual Loss: 2.3118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 5/1000 [00:03<10:00,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6276 | Actual Loss: 2.5217\n",
      "Baseline Loss: 3.3852 | Actual Loss: 2.4752\n",
      "Baseline Loss: 3.6360 | Actual Loss: 2.2229\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.9753\n",
      "Epoch 5/1000: Train Loss: 2.3400, Val Loss: 2.2988\n",
      "New best validation loss: 2.2988\n",
      "Baseline Loss: 3.3668 | Actual Loss: 1.8179\n",
      "Baseline Loss: 3.8042 | Actual Loss: 1.7202\n",
      "Baseline Loss: 3.5578 | Actual Loss: 1.9463\n",
      "Baseline Loss: 3.3395 | Actual Loss: 2.0190\n",
      "Baseline Loss: 3.4256 | Actual Loss: 1.7030\n",
      "Baseline Loss: 3.5581 | Actual Loss: 2.2344\n",
      "Baseline Loss: 3.3818 | Actual Loss: 1.7236\n",
      "Baseline Loss: 3.7518 | Actual Loss: 1.9834\n",
      "Baseline Loss: 3.6456 | Actual Loss: 1.8632\n",
      "Baseline Loss: 3.6689 | Actual Loss: 1.9468\n",
      "Baseline Loss: 3.7270 | Actual Loss: 2.2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 6/1000 [00:03<10:18,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4843 | Actual Loss: 1.9719\n",
      "Baseline Loss: 3.5539 | Actual Loss: 1.9096\n",
      "Baseline Loss: 3.4659 | Actual Loss: 1.8749\n",
      "Baseline Loss: 3.2602 | Actual Loss: 1.5621\n",
      "Baseline Loss: 3.5835 | Actual Loss: 1.5796\n",
      "Baseline Loss: 3.6276 | Actual Loss: 2.1180\n",
      "Baseline Loss: 3.3852 | Actual Loss: 2.1274\n",
      "Baseline Loss: 3.6360 | Actual Loss: 2.4696\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.7311\n",
      "Epoch 6/1000: Train Loss: 1.8786, Val Loss: 2.1115\n",
      "New best validation loss: 2.1115\n",
      "Baseline Loss: 3.5283 | Actual Loss: 1.6426\n",
      "Baseline Loss: 3.6181 | Actual Loss: 1.6900\n",
      "Baseline Loss: 3.5290 | Actual Loss: 2.1576\n",
      "Baseline Loss: 3.4622 | Actual Loss: 1.4053\n",
      "Baseline Loss: 3.5543 | Actual Loss: 2.0659\n",
      "Baseline Loss: 3.3505 | Actual Loss: 1.9925\n",
      "Baseline Loss: 3.5922 | Actual Loss: 1.4534\n",
      "Baseline Loss: 3.6314 | Actual Loss: 1.9751\n",
      "Baseline Loss: 3.3406 | Actual Loss: 1.4777\n",
      "Baseline Loss: 3.4137 | Actual Loss: 2.1798\n",
      "Baseline Loss: 3.3953 | Actual Loss: 1.9770\n",
      "Baseline Loss: 3.4622 | Actual Loss: 1.7844\n",
      "Baseline Loss: 3.6013 | Actual Loss: 2.1137\n",
      "Baseline Loss: 3.4390 | Actual Loss: 1.7542\n",
      "Baseline Loss: 3.7065 | Actual Loss: 2.3262\n",
      "Baseline Loss: 3.4491 | Actual Loss: 1.4213\n",
      "Baseline Loss: 3.6276 | Actual Loss: 2.0066\n",
      "Baseline Loss: 3.3852 | Actual Loss: 1.5099\n",
      "Baseline Loss: 3.6360 | Actual Loss: 2.8245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 7/1000 [00:04<10:29,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.2186 | Actual Loss: 1.5917\n",
      "Epoch 7/1000: Train Loss: 1.8386, Val Loss: 1.9832\n",
      "New best validation loss: 1.9832\n",
      "Baseline Loss: 3.3897 | Actual Loss: 1.9118\n",
      "Baseline Loss: 3.4967 | Actual Loss: 1.4770\n",
      "Baseline Loss: 3.7679 | Actual Loss: 1.7777\n",
      "Baseline Loss: 3.4216 | Actual Loss: 2.0492\n",
      "Baseline Loss: 3.6004 | Actual Loss: 2.0492\n",
      "Baseline Loss: 3.2390 | Actual Loss: 1.5448\n",
      "Baseline Loss: 3.3999 | Actual Loss: 1.7135\n",
      "Baseline Loss: 3.4397 | Actual Loss: 1.8376\n",
      "Baseline Loss: 3.5209 | Actual Loss: 1.3679\n",
      "Baseline Loss: 3.5298 | Actual Loss: 1.9010\n",
      "Baseline Loss: 3.6409 | Actual Loss: 1.5241\n",
      "Baseline Loss: 3.3926 | Actual Loss: 2.2842\n",
      "Baseline Loss: 3.5165 | Actual Loss: 2.1257\n",
      "Baseline Loss: 3.4141 | Actual Loss: 1.7770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 8/1000 [00:04<10:10,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6732 | Actual Loss: 2.5555\n",
      "Baseline Loss: 3.8495 | Actual Loss: 1.8148\n",
      "Baseline Loss: 3.6276 | Actual Loss: 2.1136\n",
      "Baseline Loss: 3.3852 | Actual Loss: 1.9806\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.7954\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.8009\n",
      "Epoch 8/1000: Train Loss: 1.8569, Val Loss: 1.9226\n",
      "New best validation loss: 1.9226\n",
      "Baseline Loss: 3.4846 | Actual Loss: 1.8590\n",
      "Baseline Loss: 3.4773 | Actual Loss: 1.9658\n",
      "Baseline Loss: 3.4581 | Actual Loss: 1.3125\n",
      "Baseline Loss: 3.5290 | Actual Loss: 1.7096\n",
      "Baseline Loss: 3.4963 | Actual Loss: 1.2795\n",
      "Baseline Loss: 3.6187 | Actual Loss: 1.6711\n",
      "Baseline Loss: 3.4547 | Actual Loss: 1.2106\n",
      "Baseline Loss: 3.5161 | Actual Loss: 2.2509\n",
      "Baseline Loss: 3.5130 | Actual Loss: 1.9332\n",
      "Baseline Loss: 3.6640 | Actual Loss: 2.7954\n",
      "Baseline Loss: 3.6366 | Actual Loss: 2.6846\n",
      "Baseline Loss: 3.5546 | Actual Loss: 1.4993\n",
      "Baseline Loss: 3.5453 | Actual Loss: 2.4337\n",
      "Baseline Loss: 3.3415 | Actual Loss: 1.2994\n",
      "Baseline Loss: 3.4889 | Actual Loss: 1.6918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 9/1000 [00:05<10:27,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3403 | Actual Loss: 2.1555\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.7957\n",
      "Baseline Loss: 3.3852 | Actual Loss: 1.8301\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.9747\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.6946\n",
      "Epoch 9/1000: Train Loss: 1.8595, Val Loss: 1.8238\n",
      "New best validation loss: 1.8238\n",
      "Baseline Loss: 3.5583 | Actual Loss: 1.6943\n",
      "Baseline Loss: 3.4774 | Actual Loss: 1.6073\n",
      "Baseline Loss: 3.7226 | Actual Loss: 1.8412\n",
      "Baseline Loss: 3.6829 | Actual Loss: 2.0990\n",
      "Baseline Loss: 3.3952 | Actual Loss: 2.0666\n",
      "Baseline Loss: 3.5844 | Actual Loss: 1.4220\n",
      "Baseline Loss: 3.5285 | Actual Loss: 1.4900\n",
      "Baseline Loss: 3.3863 | Actual Loss: 1.8379\n",
      "Baseline Loss: 3.4976 | Actual Loss: 1.9798\n",
      "Baseline Loss: 3.5209 | Actual Loss: 1.7765\n",
      "Baseline Loss: 3.5614 | Actual Loss: 1.4731\n",
      "Baseline Loss: 3.5966 | Actual Loss: 1.6483\n",
      "Baseline Loss: 3.4653 | Actual Loss: 1.8640\n",
      "Baseline Loss: 3.8052 | Actual Loss: 1.6378\n",
      "Baseline Loss: 3.5173 | Actual Loss: 2.0885\n",
      "Baseline Loss: 3.3667 | Actual Loss: 2.7231\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.9404\n",
      "Baseline Loss: 3.3852 | Actual Loss: 1.3283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 10/1000 [00:06<10:07,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6360 | Actual Loss: 2.0649\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.3551\n",
      "Epoch 10/1000: Train Loss: 1.8281, Val Loss: 1.6722\n",
      "New best validation loss: 1.6722\n",
      "Baseline Loss: 3.5746 | Actual Loss: 2.2856\n",
      "Baseline Loss: 3.5251 | Actual Loss: 1.7608\n",
      "Baseline Loss: 3.5462 | Actual Loss: 1.8589\n",
      "Baseline Loss: 3.5575 | Actual Loss: 1.5885\n",
      "Baseline Loss: 3.4029 | Actual Loss: 1.3460\n",
      "Baseline Loss: 3.6180 | Actual Loss: 1.9990\n",
      "Baseline Loss: 3.6597 | Actual Loss: 2.2838\n",
      "Baseline Loss: 3.3109 | Actual Loss: 1.3711\n",
      "Baseline Loss: 3.7993 | Actual Loss: 1.7871\n",
      "Baseline Loss: 3.4058 | Actual Loss: 1.6034\n",
      "Baseline Loss: 3.6186 | Actual Loss: 1.1977\n",
      "Baseline Loss: 3.4424 | Actual Loss: 2.0382\n",
      "Baseline Loss: 3.4895 | Actual Loss: 1.4672\n",
      "Baseline Loss: 3.3580 | Actual Loss: 1.9015\n",
      "Baseline Loss: 3.4313 | Actual Loss: 1.5375\n",
      "Baseline Loss: 3.0529 | Actual Loss: 1.4580\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.7711\n",
      "Baseline Loss: 3.3852 | Actual Loss: 1.4221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 11/1000 [00:06<10:12,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6360 | Actual Loss: 2.0440\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.6530\n",
      "Epoch 11/1000: Train Loss: 1.7178, Val Loss: 1.7226\n",
      "Baseline Loss: 3.5839 | Actual Loss: 1.5573\n",
      "Baseline Loss: 3.4471 | Actual Loss: 1.6117\n",
      "Baseline Loss: 3.4280 | Actual Loss: 1.0911\n",
      "Baseline Loss: 3.7571 | Actual Loss: 1.5243\n",
      "Baseline Loss: 3.4504 | Actual Loss: 2.3645\n",
      "Baseline Loss: 3.5878 | Actual Loss: 2.3015\n",
      "Baseline Loss: 3.4890 | Actual Loss: 1.6779\n",
      "Baseline Loss: 3.6003 | Actual Loss: 1.5855\n",
      "Baseline Loss: 3.6187 | Actual Loss: 1.7095\n",
      "Baseline Loss: 3.4969 | Actual Loss: 1.3670\n",
      "Baseline Loss: 3.3952 | Actual Loss: 1.3577\n",
      "Baseline Loss: 3.3514 | Actual Loss: 1.5061\n",
      "Baseline Loss: 3.5249 | Actual Loss: 1.5780\n",
      "Baseline Loss: 3.7427 | Actual Loss: 1.1528\n",
      "Baseline Loss: 3.4890 | Actual Loss: 2.0435\n",
      "Baseline Loss: 3.5292 | Actual Loss: 1.2231\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.9683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 12/1000 [00:07<10:30,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3852 | Actual Loss: 1.3706\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.5692\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.6424\n",
      "Epoch 12/1000: Train Loss: 1.6032, Val Loss: 1.6376\n",
      "New best validation loss: 1.6376\n",
      "Baseline Loss: 3.6415 | Actual Loss: 1.5859\n",
      "Baseline Loss: 3.5622 | Actual Loss: 1.9995\n",
      "Baseline Loss: 3.6785 | Actual Loss: 1.7472\n",
      "Baseline Loss: 3.3749 | Actual Loss: 1.5525\n",
      "Baseline Loss: 3.4771 | Actual Loss: 1.7535\n",
      "Baseline Loss: 3.4426 | Actual Loss: 1.5082\n",
      "Baseline Loss: 3.7028 | Actual Loss: 1.8322\n",
      "Baseline Loss: 3.6974 | Actual Loss: 1.6771\n",
      "Baseline Loss: 3.5652 | Actual Loss: 2.3129\n",
      "Baseline Loss: 3.5537 | Actual Loss: 1.7934\n",
      "Baseline Loss: 3.3672 | Actual Loss: 1.0774\n",
      "Baseline Loss: 3.4888 | Actual Loss: 2.1945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏         | 13/1000 [00:08<10:06,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4177 | Actual Loss: 1.2622\n",
      "Baseline Loss: 3.5092 | Actual Loss: 1.8004\n",
      "Baseline Loss: 3.2950 | Actual Loss: 1.3155\n",
      "Baseline Loss: 3.2195 | Actual Loss: 0.9624\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.7659\n",
      "Baseline Loss: 3.3852 | Actual Loss: 1.5488\n",
      "Baseline Loss: 3.6360 | Actual Loss: 2.4608\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.5484\n",
      "Epoch 13/1000: Train Loss: 1.6484, Val Loss: 1.8310\n",
      "Baseline Loss: 3.5455 | Actual Loss: 1.3684\n",
      "Baseline Loss: 3.4538 | Actual Loss: 1.6435\n",
      "Baseline Loss: 3.4690 | Actual Loss: 2.1600\n",
      "Baseline Loss: 3.5624 | Actual Loss: 2.3582\n",
      "Baseline Loss: 3.6090 | Actual Loss: 1.9207\n",
      "Baseline Loss: 3.4853 | Actual Loss: 1.3437\n",
      "Baseline Loss: 3.4776 | Actual Loss: 1.6309\n",
      "Baseline Loss: 3.4817 | Actual Loss: 0.9407\n",
      "Baseline Loss: 3.6013 | Actual Loss: 1.5503\n",
      "Baseline Loss: 3.7623 | Actual Loss: 1.0937\n",
      "Baseline Loss: 3.4358 | Actual Loss: 1.6131\n",
      "Baseline Loss: 3.3894 | Actual Loss: 1.3676\n",
      "Baseline Loss: 3.5789 | Actual Loss: 1.2588\n",
      "Baseline Loss: 3.4631 | Actual Loss: 1.4746\n",
      "Baseline Loss: 3.4738 | Actual Loss: 1.4007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏         | 14/1000 [00:08<10:11,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6178 | Actual Loss: 1.1740\n",
      "Baseline Loss: 3.6276 | Actual Loss: 2.3262\n",
      "Baseline Loss: 3.3852 | Actual Loss: 1.6318\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.8658\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.6529\n",
      "Epoch 14/1000: Train Loss: 1.5187, Val Loss: 1.8692\n",
      "Baseline Loss: 3.6354 | Actual Loss: 1.7960\n",
      "Baseline Loss: 3.5697 | Actual Loss: 1.0393\n",
      "Baseline Loss: 3.7272 | Actual Loss: 1.5490\n",
      "Baseline Loss: 3.5919 | Actual Loss: 1.4411\n",
      "Baseline Loss: 3.6052 | Actual Loss: 1.1446\n",
      "Baseline Loss: 3.4507 | Actual Loss: 1.2608\n",
      "Baseline Loss: 3.3544 | Actual Loss: 1.4991\n",
      "Baseline Loss: 3.4246 | Actual Loss: 1.6271\n",
      "Baseline Loss: 3.6282 | Actual Loss: 1.1709\n",
      "Baseline Loss: 3.5666 | Actual Loss: 1.8876\n",
      "Baseline Loss: 3.3679 | Actual Loss: 1.6853\n",
      "Baseline Loss: 3.5131 | Actual Loss: 1.3836\n",
      "Baseline Loss: 3.5956 | Actual Loss: 1.4643\n",
      "Baseline Loss: 3.3675 | Actual Loss: 0.9872\n",
      "Baseline Loss: 3.5125 | Actual Loss: 1.7853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 15/1000 [00:09<10:25,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4789 | Actual Loss: 0.9982\n",
      "Baseline Loss: 3.6276 | Actual Loss: 2.0232\n",
      "Baseline Loss: 3.3852 | Actual Loss: 1.1359\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.7894\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.6513\n",
      "Epoch 15/1000: Train Loss: 1.4200, Val Loss: 1.6499\n",
      "Baseline Loss: 3.5253 | Actual Loss: 1.7540\n",
      "Baseline Loss: 3.5085 | Actual Loss: 1.6315\n",
      "Baseline Loss: 3.6182 | Actual Loss: 2.1407\n",
      "Baseline Loss: 3.6826 | Actual Loss: 1.3695\n",
      "Baseline Loss: 3.5409 | Actual Loss: 1.8099\n",
      "Baseline Loss: 3.6600 | Actual Loss: 2.4155\n",
      "Baseline Loss: 3.4321 | Actual Loss: 1.3886\n",
      "Baseline Loss: 3.7273 | Actual Loss: 1.4956\n",
      "Baseline Loss: 3.5568 | Actual Loss: 1.3922\n",
      "Baseline Loss: 3.4254 | Actual Loss: 1.7956\n",
      "Baseline Loss: 3.4199 | Actual Loss: 0.9898\n",
      "Baseline Loss: 3.5413 | Actual Loss: 1.7693\n",
      "Baseline Loss: 3.5535 | Actual Loss: 1.8103\n",
      "Baseline Loss: 3.6593 | Actual Loss: 3.0246\n",
      "Baseline Loss: 3.5323 | Actual Loss: 2.1517\n",
      "Baseline Loss: 3.0217 | Actual Loss: 1.7778\n",
      "Baseline Loss: 3.6276 | Actual Loss: 2.6765\n",
      "Baseline Loss: 3.3852 | Actual Loss: 1.5364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 16/1000 [00:09<10:07,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6360 | Actual Loss: 1.8480\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.5988\n",
      "Epoch 16/1000: Train Loss: 1.7948, Val Loss: 1.9149\n",
      "Baseline Loss: 3.5290 | Actual Loss: 2.4450\n",
      "Baseline Loss: 3.4465 | Actual Loss: 1.9391\n",
      "Baseline Loss: 3.5368 | Actual Loss: 1.7028\n",
      "Baseline Loss: 3.7272 | Actual Loss: 1.4010\n",
      "Baseline Loss: 3.4808 | Actual Loss: 1.7969\n",
      "Baseline Loss: 3.6185 | Actual Loss: 1.5375\n",
      "Baseline Loss: 3.4103 | Actual Loss: 1.2934\n",
      "Baseline Loss: 3.3337 | Actual Loss: 1.2449\n",
      "Baseline Loss: 3.4476 | Actual Loss: 1.9299\n",
      "Baseline Loss: 3.4470 | Actual Loss: 1.6601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 17/1000 [00:10<10:10,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7460 | Actual Loss: 1.0375\n",
      "Baseline Loss: 3.4705 | Actual Loss: 1.3384\n",
      "Baseline Loss: 3.3015 | Actual Loss: 1.5851\n",
      "Baseline Loss: 3.5577 | Actual Loss: 1.3880\n",
      "Baseline Loss: 3.8317 | Actual Loss: 2.6919\n",
      "Baseline Loss: 3.2491 | Actual Loss: 2.4313\n",
      "Baseline Loss: 3.6276 | Actual Loss: 3.1154\n",
      "Baseline Loss: 3.3852 | Actual Loss: 2.2382\n",
      "Baseline Loss: 3.6360 | Actual Loss: 3.1902\n",
      "Baseline Loss: 3.2186 | Actual Loss: 2.2590\n",
      "Epoch 17/1000: Train Loss: 1.7139, Val Loss: 2.7007\n",
      "Baseline Loss: 3.6545 | Actual Loss: 0.9151\n",
      "Baseline Loss: 3.5701 | Actual Loss: 2.5157\n",
      "Baseline Loss: 3.4894 | Actual Loss: 2.2366\n",
      "Baseline Loss: 3.2729 | Actual Loss: 1.6642\n",
      "Baseline Loss: 3.7886 | Actual Loss: 1.3573\n",
      "Baseline Loss: 3.3614 | Actual Loss: 1.1491\n",
      "Baseline Loss: 3.3843 | Actual Loss: 1.3174\n",
      "Baseline Loss: 3.4506 | Actual Loss: 1.2765\n",
      "Baseline Loss: 3.5335 | Actual Loss: 2.2935\n",
      "Baseline Loss: 3.4613 | Actual Loss: 1.4065\n",
      "Baseline Loss: 3.6092 | Actual Loss: 1.5158\n",
      "Baseline Loss: 3.8319 | Actual Loss: 1.6309\n",
      "Baseline Loss: 3.4852 | Actual Loss: 1.4389\n",
      "Baseline Loss: 3.4768 | Actual Loss: 2.1851\n",
      "Baseline Loss: 3.4430 | Actual Loss: 1.5809\n",
      "Baseline Loss: 3.4118 | Actual Loss: 1.8215\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.7493\n",
      "Baseline Loss: 3.3852 | Actual Loss: 1.4615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 18/1000 [00:11<10:36,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6360 | Actual Loss: 1.2467\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.4995\n",
      "Epoch 18/1000: Train Loss: 1.6441, Val Loss: 1.4892\n",
      "New best validation loss: 1.4892\n",
      "Baseline Loss: 3.3371 | Actual Loss: 1.4541\n",
      "Baseline Loss: 3.3447 | Actual Loss: 1.6767\n",
      "Baseline Loss: 3.7126 | Actual Loss: 1.7168\n",
      "Baseline Loss: 3.6922 | Actual Loss: 1.2461\n",
      "Baseline Loss: 3.4470 | Actual Loss: 1.4795\n",
      "Baseline Loss: 3.4537 | Actual Loss: 1.6366\n",
      "Baseline Loss: 3.5960 | Actual Loss: 0.9684\n",
      "Baseline Loss: 3.4033 | Actual Loss: 1.5303\n",
      "Baseline Loss: 3.7668 | Actual Loss: 1.5779\n",
      "Baseline Loss: 3.5629 | Actual Loss: 1.1955\n",
      "Baseline Loss: 3.5294 | Actual Loss: 2.5100\n",
      "Baseline Loss: 3.6016 | Actual Loss: 2.1469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 19/1000 [00:11<10:07,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4846 | Actual Loss: 2.1421\n",
      "Baseline Loss: 3.3208 | Actual Loss: 0.9688\n",
      "Baseline Loss: 3.5745 | Actual Loss: 1.0544\n",
      "Baseline Loss: 3.4780 | Actual Loss: 1.2419\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.6524\n",
      "Baseline Loss: 3.3852 | Actual Loss: 1.4693\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.9464\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.5267\n",
      "Epoch 19/1000: Train Loss: 1.5341, Val Loss: 1.6487\n",
      "Baseline Loss: 3.3822 | Actual Loss: 1.0088\n",
      "Baseline Loss: 3.4102 | Actual Loss: 1.0709\n",
      "Baseline Loss: 3.7073 | Actual Loss: 1.1666\n",
      "Baseline Loss: 3.4280 | Actual Loss: 1.5549\n",
      "Baseline Loss: 3.4659 | Actual Loss: 1.1514\n",
      "Baseline Loss: 3.5419 | Actual Loss: 1.1526\n",
      "Baseline Loss: 3.4122 | Actual Loss: 1.4962\n",
      "Baseline Loss: 3.5373 | Actual Loss: 1.5771\n",
      "Baseline Loss: 3.7680 | Actual Loss: 2.1287\n",
      "Baseline Loss: 3.5705 | Actual Loss: 1.0126\n",
      "Baseline Loss: 3.4654 | Actual Loss: 1.0002\n",
      "Baseline Loss: 3.7941 | Actual Loss: 1.1517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 20/1000 [00:12<10:17,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5617 | Actual Loss: 1.6295\n",
      "Baseline Loss: 3.6461 | Actual Loss: 1.0825\n",
      "Baseline Loss: 3.4977 | Actual Loss: 1.1614\n",
      "Baseline Loss: 3.2569 | Actual Loss: 1.2870\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.7605\n",
      "Baseline Loss: 3.3852 | Actual Loss: 1.0873\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.5963\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.3708\n",
      "Epoch 20/1000: Train Loss: 1.2895, Val Loss: 1.4537\n",
      "New best validation loss: 1.4537\n",
      "Baseline Loss: 3.4845 | Actual Loss: 1.6664\n",
      "Baseline Loss: 3.5661 | Actual Loss: 1.4251\n",
      "Baseline Loss: 3.4511 | Actual Loss: 0.8794\n",
      "Baseline Loss: 3.4656 | Actual Loss: 1.9492\n",
      "Baseline Loss: 3.5705 | Actual Loss: 1.0019\n",
      "Baseline Loss: 3.5444 | Actual Loss: 1.5868\n",
      "Baseline Loss: 3.5625 | Actual Loss: 1.4615\n",
      "Baseline Loss: 3.4507 | Actual Loss: 1.5802\n",
      "Baseline Loss: 3.4972 | Actual Loss: 1.2401\n",
      "Baseline Loss: 3.5247 | Actual Loss: 1.1186\n",
      "Baseline Loss: 3.4846 | Actual Loss: 2.1943\n",
      "Baseline Loss: 3.6181 | Actual Loss: 1.2099\n",
      "Baseline Loss: 3.5701 | Actual Loss: 1.6094\n",
      "Baseline Loss: 3.5623 | Actual Loss: 0.8398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 21/1000 [00:13<10:07,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7524 | Actual Loss: 1.6950\n",
      "Baseline Loss: 3.6527 | Actual Loss: 1.4086\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.6900\n",
      "Baseline Loss: 3.3852 | Actual Loss: 1.9428\n",
      "Baseline Loss: 3.6360 | Actual Loss: 2.3844\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.5022\n",
      "Epoch 21/1000: Train Loss: 1.4291, Val Loss: 1.8799\n",
      "Baseline Loss: 3.4926 | Actual Loss: 1.6907\n",
      "Baseline Loss: 3.4441 | Actual Loss: 1.0791\n",
      "Baseline Loss: 3.6784 | Actual Loss: 1.0776\n",
      "Baseline Loss: 3.6133 | Actual Loss: 0.9439\n",
      "Baseline Loss: 3.4888 | Actual Loss: 1.8604\n",
      "Baseline Loss: 3.5489 | Actual Loss: 1.1758\n",
      "Baseline Loss: 3.6005 | Actual Loss: 1.3654\n",
      "Baseline Loss: 3.3861 | Actual Loss: 2.0944\n",
      "Baseline Loss: 3.5657 | Actual Loss: 1.4345\n",
      "Baseline Loss: 3.7265 | Actual Loss: 1.3104\n",
      "Baseline Loss: 3.4619 | Actual Loss: 1.4788\n",
      "Baseline Loss: 3.7163 | Actual Loss: 1.0521\n",
      "Baseline Loss: 3.5005 | Actual Loss: 1.6107\n",
      "Baseline Loss: 3.4360 | Actual Loss: 1.5931\n",
      "Baseline Loss: 3.5156 | Actual Loss: 1.2538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 22/1000 [00:13<10:10,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.2339 | Actual Loss: 0.7594\n",
      "Baseline Loss: 3.6276 | Actual Loss: 2.6570\n",
      "Baseline Loss: 3.3852 | Actual Loss: 2.2185\n",
      "Baseline Loss: 3.6360 | Actual Loss: 2.2164\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.8684\n",
      "Epoch 22/1000: Train Loss: 1.3613, Val Loss: 2.2401\n",
      "Baseline Loss: 3.8205 | Actual Loss: 0.9403\n",
      "Baseline Loss: 3.3136 | Actual Loss: 1.5397\n",
      "Baseline Loss: 3.5801 | Actual Loss: 1.5757\n",
      "Baseline Loss: 3.5407 | Actual Loss: 1.3895\n",
      "Baseline Loss: 3.2977 | Actual Loss: 1.7941\n",
      "Baseline Loss: 3.5091 | Actual Loss: 1.3618\n",
      "Baseline Loss: 3.5881 | Actual Loss: 1.4752\n",
      "Baseline Loss: 3.8723 | Actual Loss: 2.3644\n",
      "Baseline Loss: 3.7372 | Actual Loss: 1.2895\n",
      "Baseline Loss: 3.4507 | Actual Loss: 1.8045\n",
      "Baseline Loss: 3.4293 | Actual Loss: 1.3898\n",
      "Baseline Loss: 3.4852 | Actual Loss: 1.6017\n",
      "Baseline Loss: 3.3811 | Actual Loss: 1.6926\n",
      "Baseline Loss: 3.4211 | Actual Loss: 1.8087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 23/1000 [00:14<10:21,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4617 | Actual Loss: 1.2046\n",
      "Baseline Loss: 3.2878 | Actual Loss: 1.2125\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.6637\n",
      "Baseline Loss: 3.3852 | Actual Loss: 1.3159\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.3483\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.4527\n",
      "Epoch 23/1000: Train Loss: 1.5278, Val Loss: 1.4451\n",
      "New best validation loss: 1.4451\n",
      "Baseline Loss: 3.6229 | Actual Loss: 1.0829\n",
      "Baseline Loss: 3.6050 | Actual Loss: 1.2602\n",
      "Baseline Loss: 3.8657 | Actual Loss: 2.9932\n",
      "Baseline Loss: 3.5129 | Actual Loss: 1.6279\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.8971\n",
      "Baseline Loss: 3.3747 | Actual Loss: 2.1991\n",
      "Baseline Loss: 3.6180 | Actual Loss: 0.9657\n",
      "Baseline Loss: 3.4212 | Actual Loss: 1.5015\n",
      "Baseline Loss: 3.6738 | Actual Loss: 0.7733\n",
      "Baseline Loss: 3.4741 | Actual Loss: 1.1642\n",
      "Baseline Loss: 3.5132 | Actual Loss: 1.1473\n",
      "Baseline Loss: 3.4696 | Actual Loss: 1.2753\n",
      "Baseline Loss: 3.4744 | Actual Loss: 1.1099\n",
      "Baseline Loss: 3.4204 | Actual Loss: 1.1731\n",
      "Baseline Loss: 3.3654 | Actual Loss: 1.1956\n",
      "Baseline Loss: 2.8812 | Actual Loss: 1.2117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 24/1000 [00:15<10:14,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6276 | Actual Loss: 1.9349\n",
      "Baseline Loss: 3.3852 | Actual Loss: 1.0261\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.2050\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.5408\n",
      "Epoch 24/1000: Train Loss: 1.4111, Val Loss: 1.4267\n",
      "New best validation loss: 1.4267\n",
      "Baseline Loss: 3.4895 | Actual Loss: 1.8902\n",
      "Baseline Loss: 3.4932 | Actual Loss: 1.4418\n",
      "Baseline Loss: 3.7372 | Actual Loss: 1.2304\n",
      "Baseline Loss: 3.4270 | Actual Loss: 1.1981\n",
      "Baseline Loss: 3.4206 | Actual Loss: 1.1577\n",
      "Baseline Loss: 3.6924 | Actual Loss: 1.5644\n",
      "Baseline Loss: 3.5583 | Actual Loss: 2.3852\n",
      "Baseline Loss: 3.5658 | Actual Loss: 1.0922\n",
      "Baseline Loss: 3.5832 | Actual Loss: 1.2783\n",
      "Baseline Loss: 3.5408 | Actual Loss: 1.2957\n",
      "Baseline Loss: 3.6182 | Actual Loss: 1.3496\n",
      "Baseline Loss: 3.7267 | Actual Loss: 1.1424\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.1866\n",
      "Baseline Loss: 3.3887 | Actual Loss: 1.0778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▎         | 25/1000 [00:15<10:30,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4357 | Actual Loss: 1.9891\n",
      "Baseline Loss: 3.4109 | Actual Loss: 0.8920\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.9725\n",
      "Baseline Loss: 3.3852 | Actual Loss: 2.0856\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.8264\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.9017\n",
      "Epoch 25/1000: Train Loss: 1.3857, Val Loss: 1.9465\n",
      "Baseline Loss: 3.4463 | Actual Loss: 1.6063\n",
      "Baseline Loss: 3.4436 | Actual Loss: 1.1611\n",
      "Baseline Loss: 3.5622 | Actual Loss: 3.4119\n",
      "Baseline Loss: 3.4166 | Actual Loss: 1.8079\n",
      "Baseline Loss: 3.4549 | Actual Loss: 1.6524\n",
      "Baseline Loss: 3.5170 | Actual Loss: 1.3157\n",
      "Baseline Loss: 3.6140 | Actual Loss: 1.4872\n",
      "Baseline Loss: 3.4884 | Actual Loss: 1.5293\n",
      "Baseline Loss: 3.4392 | Actual Loss: 1.2560\n",
      "Baseline Loss: 3.6597 | Actual Loss: 1.2381\n",
      "Baseline Loss: 3.6594 | Actual Loss: 1.1718\n",
      "Baseline Loss: 3.5098 | Actual Loss: 0.9666\n",
      "Baseline Loss: 3.5742 | Actual Loss: 1.6848\n",
      "Baseline Loss: 3.5008 | Actual Loss: 1.2645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 26/1000 [00:16<10:44,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6276 | Actual Loss: 2.0460\n",
      "Baseline Loss: 3.2192 | Actual Loss: 1.2068\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.7464\n",
      "Baseline Loss: 3.3852 | Actual Loss: 1.0066\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.7057\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.5985\n",
      "Epoch 26/1000: Train Loss: 1.5504, Val Loss: 1.5143\n",
      "Baseline Loss: 3.6732 | Actual Loss: 1.1305\n",
      "Baseline Loss: 3.6449 | Actual Loss: 1.0388\n",
      "Baseline Loss: 3.4975 | Actual Loss: 1.3219\n",
      "Baseline Loss: 3.6270 | Actual Loss: 0.9964\n",
      "Baseline Loss: 3.6501 | Actual Loss: 0.9677\n",
      "Baseline Loss: 3.5499 | Actual Loss: 1.6732\n",
      "Baseline Loss: 3.4318 | Actual Loss: 1.3127\n",
      "Baseline Loss: 3.5409 | Actual Loss: 2.9646\n",
      "Baseline Loss: 3.3820 | Actual Loss: 1.5204\n",
      "Baseline Loss: 3.3993 | Actual Loss: 1.1110\n",
      "Baseline Loss: 3.7021 | Actual Loss: 1.0354\n",
      "Baseline Loss: 3.5495 | Actual Loss: 1.1904\n",
      "Baseline Loss: 3.5370 | Actual Loss: 1.4203\n",
      "Baseline Loss: 3.3715 | Actual Loss: 1.2174\n",
      "Baseline Loss: 3.3379 | Actual Loss: 1.6936\n",
      "Baseline Loss: 3.4204 | Actual Loss: 1.6412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 27/1000 [00:17<10:27,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6276 | Actual Loss: 1.6263\n",
      "Baseline Loss: 3.3852 | Actual Loss: 1.0359\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.6675\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.4683\n",
      "Epoch 27/1000: Train Loss: 1.3897, Val Loss: 1.4495\n",
      "Baseline Loss: 3.5747 | Actual Loss: 0.9578\n",
      "Baseline Loss: 3.6507 | Actual Loss: 1.5437\n",
      "Baseline Loss: 3.3435 | Actual Loss: 1.6309\n",
      "Baseline Loss: 3.5367 | Actual Loss: 1.0110\n",
      "Baseline Loss: 3.4029 | Actual Loss: 1.2049\n",
      "Baseline Loss: 3.4777 | Actual Loss: 1.3366\n",
      "Baseline Loss: 3.4543 | Actual Loss: 1.3078\n",
      "Baseline Loss: 3.5660 | Actual Loss: 1.3671\n",
      "Baseline Loss: 3.6403 | Actual Loss: 2.5636\n",
      "Baseline Loss: 3.5870 | Actual Loss: 1.2748\n",
      "Baseline Loss: 3.6591 | Actual Loss: 3.2131\n",
      "Baseline Loss: 3.5004 | Actual Loss: 1.3184\n",
      "Baseline Loss: 3.4385 | Actual Loss: 1.4671\n",
      "Baseline Loss: 3.5918 | Actual Loss: 1.1833\n",
      "Baseline Loss: 3.6687 | Actual Loss: 1.4349\n",
      "Baseline Loss: 3.3938 | Actual Loss: 1.3310\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.5349\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.8485\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.8766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 28/1000 [00:17<10:22,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.2186 | Actual Loss: 1.6154\n",
      "Epoch 28/1000: Train Loss: 1.5091, Val Loss: 1.4689\n",
      "Baseline Loss: 3.6980 | Actual Loss: 0.5468\n",
      "Baseline Loss: 3.4847 | Actual Loss: 1.0865\n",
      "Baseline Loss: 3.6186 | Actual Loss: 0.8870\n",
      "Baseline Loss: 3.5746 | Actual Loss: 1.2205\n",
      "Baseline Loss: 3.5124 | Actual Loss: 1.0719\n",
      "Baseline Loss: 3.4551 | Actual Loss: 1.6552\n",
      "Baseline Loss: 3.6973 | Actual Loss: 1.5214\n",
      "Baseline Loss: 3.6186 | Actual Loss: 1.2506\n",
      "Baseline Loss: 3.5047 | Actual Loss: 1.0317\n",
      "Baseline Loss: 3.6014 | Actual Loss: 1.3749\n",
      "Baseline Loss: 3.4203 | Actual Loss: 1.1128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 29/1000 [00:18<10:23,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5294 | Actual Loss: 0.9819\n",
      "Baseline Loss: 3.4901 | Actual Loss: 1.6016\n",
      "Baseline Loss: 3.4738 | Actual Loss: 1.2680\n",
      "Baseline Loss: 3.5660 | Actual Loss: 1.0917\n",
      "Baseline Loss: 3.3657 | Actual Loss: 2.5558\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.4101\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.9849\n",
      "Baseline Loss: 3.6360 | Actual Loss: 2.0061\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.5053\n",
      "Epoch 29/1000: Train Loss: 1.2661, Val Loss: 1.4766\n",
      "Baseline Loss: 3.4814 | Actual Loss: 1.1007\n",
      "Baseline Loss: 3.6507 | Actual Loss: 1.3637\n",
      "Baseline Loss: 3.3240 | Actual Loss: 1.1833\n",
      "Baseline Loss: 3.8045 | Actual Loss: 0.9637\n",
      "Baseline Loss: 3.8102 | Actual Loss: 1.9633\n",
      "Baseline Loss: 3.6978 | Actual Loss: 1.5444\n",
      "Baseline Loss: 3.5737 | Actual Loss: 1.1222\n",
      "Baseline Loss: 3.6136 | Actual Loss: 1.3227\n",
      "Baseline Loss: 3.4630 | Actual Loss: 0.7959\n",
      "Baseline Loss: 3.5087 | Actual Loss: 0.9848\n",
      "Baseline Loss: 3.1809 | Actual Loss: 1.2334\n",
      "Baseline Loss: 3.4359 | Actual Loss: 1.0107\n",
      "Baseline Loss: 3.6826 | Actual Loss: 2.0941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 30/1000 [00:18<10:13,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4593 | Actual Loss: 1.6965\n",
      "Baseline Loss: 3.4537 | Actual Loss: 1.4946\n",
      "Baseline Loss: 3.4021 | Actual Loss: 1.7446\n",
      "Baseline Loss: 3.6276 | Actual Loss: 2.5159\n",
      "Baseline Loss: 3.3852 | Actual Loss: 2.6054\n",
      "Baseline Loss: 3.6360 | Actual Loss: 2.9101\n",
      "Baseline Loss: 3.2186 | Actual Loss: 2.5044\n",
      "Epoch 30/1000: Train Loss: 1.3512, Val Loss: 2.6339\n",
      "Baseline Loss: 3.6226 | Actual Loss: 1.2211\n",
      "Baseline Loss: 3.6786 | Actual Loss: 1.9154\n",
      "Baseline Loss: 3.4744 | Actual Loss: 1.2291\n",
      "Baseline Loss: 3.6594 | Actual Loss: 1.1532\n",
      "Baseline Loss: 3.5789 | Actual Loss: 1.2475\n",
      "Baseline Loss: 3.6642 | Actual Loss: 2.2463\n",
      "Baseline Loss: 3.5248 | Actual Loss: 1.2282\n",
      "Baseline Loss: 3.5006 | Actual Loss: 1.1136\n",
      "Baseline Loss: 3.6147 | Actual Loss: 1.3552\n",
      "Baseline Loss: 3.3883 | Actual Loss: 1.2831\n",
      "Baseline Loss: 3.3287 | Actual Loss: 1.3802\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.9689\n",
      "Baseline Loss: 3.4033 | Actual Loss: 1.3729\n",
      "Baseline Loss: 3.6098 | Actual Loss: 0.8750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 31/1000 [00:19<10:12,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5373 | Actual Loss: 1.1958\n",
      "Baseline Loss: 3.5301 | Actual Loss: 1.5927\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.6307\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.9693\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.6890\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.4308\n",
      "Epoch 31/1000: Train Loss: 1.3361, Val Loss: 1.4300\n",
      "Baseline Loss: 3.4881 | Actual Loss: 1.1062\n",
      "Baseline Loss: 3.3997 | Actual Loss: 1.2137\n",
      "Baseline Loss: 3.5707 | Actual Loss: 1.3798\n",
      "Baseline Loss: 3.5009 | Actual Loss: 0.8793\n",
      "Baseline Loss: 3.8718 | Actual Loss: 1.1782\n",
      "Baseline Loss: 3.5491 | Actual Loss: 2.2871\n",
      "Baseline Loss: 3.4579 | Actual Loss: 1.2790\n",
      "Baseline Loss: 3.6596 | Actual Loss: 1.7471\n",
      "Baseline Loss: 3.4504 | Actual Loss: 1.7241\n",
      "Baseline Loss: 3.3196 | Actual Loss: 0.9828\n",
      "Baseline Loss: 3.5459 | Actual Loss: 1.5824\n",
      "Baseline Loss: 3.3308 | Actual Loss: 1.2344\n",
      "Baseline Loss: 3.6648 | Actual Loss: 2.2031\n",
      "Baseline Loss: 3.3579 | Actual Loss: 1.3547\n",
      "Baseline Loss: 3.5579 | Actual Loss: 1.0171\n",
      "Baseline Loss: 3.6527 | Actual Loss: 0.8741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 32/1000 [00:20<10:07,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6276 | Actual Loss: 1.2747\n",
      "Baseline Loss: 3.3852 | Actual Loss: 1.2793\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.2830\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.4655\n",
      "Epoch 32/1000: Train Loss: 1.3777, Val Loss: 1.3256\n",
      "New best validation loss: 1.3256\n",
      "Baseline Loss: 3.4350 | Actual Loss: 1.4638\n",
      "Baseline Loss: 3.5213 | Actual Loss: 1.2844\n",
      "Baseline Loss: 3.4815 | Actual Loss: 1.2122\n",
      "Baseline Loss: 3.5967 | Actual Loss: 1.2206\n",
      "Baseline Loss: 3.9382 | Actual Loss: 1.3618\n",
      "Baseline Loss: 3.4426 | Actual Loss: 1.3976\n",
      "Baseline Loss: 3.4777 | Actual Loss: 1.3196\n",
      "Baseline Loss: 3.2734 | Actual Loss: 1.3815\n",
      "Baseline Loss: 3.5208 | Actual Loss: 1.1007\n",
      "Baseline Loss: 3.7064 | Actual Loss: 1.5623\n",
      "Baseline Loss: 3.4388 | Actual Loss: 2.5456\n",
      "Baseline Loss: 3.4885 | Actual Loss: 1.4519\n",
      "Baseline Loss: 3.4772 | Actual Loss: 2.5042\n",
      "Baseline Loss: 3.5049 | Actual Loss: 0.5239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 33/1000 [00:20<10:21,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5668 | Actual Loss: 0.9676\n",
      "Baseline Loss: 3.3482 | Actual Loss: 1.6319\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.2907\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.7582\n",
      "Baseline Loss: 3.6360 | Actual Loss: 2.2711\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.8302\n",
      "Epoch 33/1000: Train Loss: 1.4331, Val Loss: 1.5376\n",
      "Baseline Loss: 3.5287 | Actual Loss: 0.7717\n",
      "Baseline Loss: 3.6785 | Actual Loss: 1.3249\n",
      "Baseline Loss: 3.4773 | Actual Loss: 0.7889\n",
      "Baseline Loss: 3.2387 | Actual Loss: 1.9096\n",
      "Baseline Loss: 3.5533 | Actual Loss: 3.6971\n",
      "Baseline Loss: 3.3926 | Actual Loss: 0.7076\n",
      "Baseline Loss: 3.4587 | Actual Loss: 0.7882\n",
      "Baseline Loss: 3.4510 | Actual Loss: 1.6741\n",
      "Baseline Loss: 3.8776 | Actual Loss: 1.6134\n",
      "Baseline Loss: 3.3819 | Actual Loss: 1.4278\n",
      "Baseline Loss: 3.9503 | Actual Loss: 1.1771\n",
      "Baseline Loss: 3.6547 | Actual Loss: 1.1859\n",
      "Baseline Loss: 3.6133 | Actual Loss: 1.0528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 34/1000 [00:21<10:26,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4294 | Actual Loss: 1.2432\n",
      "Baseline Loss: 3.6638 | Actual Loss: 2.0978\n",
      "Baseline Loss: 3.4399 | Actual Loss: 0.6481\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.9202\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.9070\n",
      "Baseline Loss: 3.6360 | Actual Loss: 2.1474\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.5437\n",
      "Epoch 34/1000: Train Loss: 1.3818, Val Loss: 1.6296\n",
      "Baseline Loss: 3.4620 | Actual Loss: 0.8013\n",
      "Baseline Loss: 3.4688 | Actual Loss: 1.1056\n",
      "Baseline Loss: 3.5697 | Actual Loss: 2.8691\n",
      "Baseline Loss: 3.7422 | Actual Loss: 1.7805\n",
      "Baseline Loss: 3.5971 | Actual Loss: 1.5610\n",
      "Baseline Loss: 3.4429 | Actual Loss: 0.9077\n",
      "Baseline Loss: 3.4607 | Actual Loss: 2.0022\n",
      "Baseline Loss: 3.6924 | Actual Loss: 0.9074\n",
      "Baseline Loss: 3.5537 | Actual Loss: 1.1684\n",
      "Baseline Loss: 3.5216 | Actual Loss: 0.9653\n",
      "Baseline Loss: 3.5494 | Actual Loss: 1.1211\n",
      "Baseline Loss: 3.5283 | Actual Loss: 1.5281\n",
      "Baseline Loss: 3.4541 | Actual Loss: 1.5638\n",
      "Baseline Loss: 3.5284 | Actual Loss: 2.1127\n",
      "Baseline Loss: 3.6638 | Actual Loss: 1.0375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 35/1000 [00:22<10:13,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3156 | Actual Loss: 1.2598\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.8383\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.9390\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.9840\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.5492\n",
      "Epoch 35/1000: Train Loss: 1.4182, Val Loss: 1.5776\n",
      "Baseline Loss: 3.5161 | Actual Loss: 1.6595\n",
      "Baseline Loss: 3.4245 | Actual Loss: 1.3283\n",
      "Baseline Loss: 3.3680 | Actual Loss: 1.1198\n",
      "Baseline Loss: 3.4545 | Actual Loss: 1.4455\n",
      "Baseline Loss: 3.4817 | Actual Loss: 0.8634\n",
      "Baseline Loss: 3.8100 | Actual Loss: 1.0735\n",
      "Baseline Loss: 3.4145 | Actual Loss: 1.2866\n",
      "Baseline Loss: 3.5415 | Actual Loss: 1.4015\n",
      "Baseline Loss: 3.6140 | Actual Loss: 0.9553\n",
      "Baseline Loss: 3.5209 | Actual Loss: 2.1520\n",
      "Baseline Loss: 3.5086 | Actual Loss: 1.0704\n",
      "Baseline Loss: 3.6184 | Actual Loss: 1.4191\n",
      "Baseline Loss: 3.4314 | Actual Loss: 0.8557\n",
      "Baseline Loss: 3.5757 | Actual Loss: 1.4595\n",
      "Baseline Loss: 3.4580 | Actual Loss: 0.7991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 36/1000 [00:22<10:11,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3751 | Actual Loss: 1.5586\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.5871\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.9979\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.6319\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.2845\n",
      "Epoch 36/1000: Train Loss: 1.2780, Val Loss: 1.3754\n",
      "Baseline Loss: 3.4549 | Actual Loss: 1.0049\n",
      "Baseline Loss: 3.6097 | Actual Loss: 1.0108\n",
      "Baseline Loss: 3.4772 | Actual Loss: 1.3274\n",
      "Baseline Loss: 3.5243 | Actual Loss: 1.0829\n",
      "Baseline Loss: 3.5338 | Actual Loss: 1.5986\n",
      "Baseline Loss: 3.5416 | Actual Loss: 1.0880\n",
      "Baseline Loss: 3.4441 | Actual Loss: 1.4844\n",
      "Baseline Loss: 3.4354 | Actual Loss: 1.2488\n",
      "Baseline Loss: 3.7219 | Actual Loss: 1.4513\n",
      "Baseline Loss: 3.6361 | Actual Loss: 1.8288\n",
      "Baseline Loss: 3.6968 | Actual Loss: 1.9833\n",
      "Baseline Loss: 3.4217 | Actual Loss: 1.2838\n",
      "Baseline Loss: 3.3892 | Actual Loss: 0.7271\n",
      "Baseline Loss: 3.3517 | Actual Loss: 0.9628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▎         | 37/1000 [00:23<10:20,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5828 | Actual Loss: 1.0432\n",
      "Baseline Loss: 3.5616 | Actual Loss: 1.5078\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.3040\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.9200\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.8994\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.4315\n",
      "Epoch 37/1000: Train Loss: 1.2896, Val Loss: 1.3887\n",
      "Baseline Loss: 3.4970 | Actual Loss: 0.9214\n",
      "Baseline Loss: 3.4358 | Actual Loss: 1.0244\n",
      "Baseline Loss: 3.4960 | Actual Loss: 1.2000\n",
      "Baseline Loss: 3.4251 | Actual Loss: 1.8392\n",
      "Baseline Loss: 3.5283 | Actual Loss: 1.4952\n",
      "Baseline Loss: 3.4437 | Actual Loss: 1.1933\n",
      "Baseline Loss: 3.7525 | Actual Loss: 1.1298\n",
      "Baseline Loss: 3.6731 | Actual Loss: 0.8561\n",
      "Baseline Loss: 3.6091 | Actual Loss: 1.3604\n",
      "Baseline Loss: 3.5917 | Actual Loss: 1.8083\n",
      "Baseline Loss: 3.6405 | Actual Loss: 1.1464\n",
      "Baseline Loss: 3.4209 | Actual Loss: 1.1652\n",
      "Baseline Loss: 3.5050 | Actual Loss: 1.2590\n",
      "Baseline Loss: 3.4251 | Actual Loss: 1.3356\n",
      "Baseline Loss: 3.5875 | Actual Loss: 1.5234\n",
      "Baseline Loss: 2.9819 | Actual Loss: 0.9991\n",
      "Baseline Loss: 3.6276 | Actual Loss: 2.2951\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.8977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 38/1000 [00:24<10:17,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6360 | Actual Loss: 3.1349\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.5135\n",
      "Epoch 38/1000: Train Loss: 1.2660, Val Loss: 1.9603\n",
      "Baseline Loss: 3.7422 | Actual Loss: 0.8845\n",
      "Baseline Loss: 3.6186 | Actual Loss: 1.0945\n",
      "Baseline Loss: 3.5873 | Actual Loss: 1.1345\n",
      "Baseline Loss: 3.6458 | Actual Loss: 0.8566\n",
      "Baseline Loss: 3.5575 | Actual Loss: 1.1926\n",
      "Baseline Loss: 3.3380 | Actual Loss: 1.8179\n",
      "Baseline Loss: 3.3967 | Actual Loss: 1.3468\n",
      "Baseline Loss: 3.3012 | Actual Loss: 0.8998\n",
      "Baseline Loss: 3.4971 | Actual Loss: 0.5685\n",
      "Baseline Loss: 3.6416 | Actual Loss: 1.2660\n",
      "Baseline Loss: 3.4926 | Actual Loss: 1.3852\n",
      "Baseline Loss: 3.6503 | Actual Loss: 3.2426\n",
      "Baseline Loss: 3.3857 | Actual Loss: 1.0823\n",
      "Baseline Loss: 3.5626 | Actual Loss: 0.9199\n",
      "Baseline Loss: 3.4884 | Actual Loss: 1.3502\n",
      "Baseline Loss: 3.2260 | Actual Loss: 2.4469\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.4367\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.8349\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.8599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 39/1000 [00:24<09:51,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.2186 | Actual Loss: 1.2161\n",
      "Epoch 39/1000: Train Loss: 1.3431, Val Loss: 1.3369\n",
      "Baseline Loss: 3.7831 | Actual Loss: 0.8498\n",
      "Baseline Loss: 3.8377 | Actual Loss: 3.1053\n",
      "Baseline Loss: 3.4964 | Actual Loss: 1.4581\n",
      "Baseline Loss: 3.6643 | Actual Loss: 1.5266\n",
      "Baseline Loss: 3.6274 | Actual Loss: 1.1754\n",
      "Baseline Loss: 3.5259 | Actual Loss: 1.0979\n",
      "Baseline Loss: 3.3681 | Actual Loss: 1.0403\n",
      "Baseline Loss: 3.4200 | Actual Loss: 3.4483\n",
      "Baseline Loss: 3.3965 | Actual Loss: 0.9145\n",
      "Baseline Loss: 3.3752 | Actual Loss: 1.4310\n",
      "Baseline Loss: 3.6547 | Actual Loss: 0.9426\n",
      "Baseline Loss: 3.5405 | Actual Loss: 0.7204\n",
      "Baseline Loss: 3.3540 | Actual Loss: 0.9282\n",
      "Baseline Loss: 3.4220 | Actual Loss: 1.0829\n",
      "Baseline Loss: 3.4835 | Actual Loss: 1.5813\n",
      "Baseline Loss: 3.5298 | Actual Loss: 2.0953\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.4680\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.8125\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.6328\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.3000\n",
      "Epoch 40/1000: Train Loss: 1.4624, Val Loss: 1.3033\n",
      "New best validation loss: 1.3033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 40/1000 [00:25<10:14,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4280 | Actual Loss: 1.0879\n",
      "Baseline Loss: 3.4508 | Actual Loss: 1.0942\n",
      "Baseline Loss: 3.5008 | Actual Loss: 0.6884\n",
      "Baseline Loss: 3.4628 | Actual Loss: 0.8534\n",
      "Baseline Loss: 3.4440 | Actual Loss: 1.0879\n",
      "Baseline Loss: 3.6886 | Actual Loss: 1.0324\n",
      "Baseline Loss: 3.6325 | Actual Loss: 1.0709\n",
      "Baseline Loss: 3.6272 | Actual Loss: 0.8385\n",
      "Baseline Loss: 3.5130 | Actual Loss: 1.3048\n",
      "Baseline Loss: 3.6549 | Actual Loss: 0.9530\n",
      "Baseline Loss: 3.4771 | Actual Loss: 0.8153\n",
      "Baseline Loss: 3.5908 | Actual Loss: 2.7415\n",
      "Baseline Loss: 3.4860 | Actual Loss: 1.8578\n",
      "Baseline Loss: 3.4810 | Actual Loss: 1.3108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 41/1000 [00:25<09:45,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6544 | Actual Loss: 2.6972\n",
      "Baseline Loss: 3.4219 | Actual Loss: 0.8700\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.7300\n",
      "Baseline Loss: 3.3852 | Actual Loss: 1.1318\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.7945\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.8691\n",
      "Epoch 41/1000: Train Loss: 1.2690, Val Loss: 1.6314\n",
      "Baseline Loss: 3.7579 | Actual Loss: 0.3620\n",
      "Baseline Loss: 3.4536 | Actual Loss: 1.0900\n",
      "Baseline Loss: 3.5086 | Actual Loss: 0.7422\n",
      "Baseline Loss: 3.3725 | Actual Loss: 1.3420\n",
      "Baseline Loss: 3.5424 | Actual Loss: 1.2419\n",
      "Baseline Loss: 3.5793 | Actual Loss: 1.3325\n",
      "Baseline Loss: 3.4975 | Actual Loss: 0.7118\n",
      "Baseline Loss: 3.5919 | Actual Loss: 2.0902\n",
      "Baseline Loss: 3.6007 | Actual Loss: 0.8458\n",
      "Baseline Loss: 3.5255 | Actual Loss: 1.1718\n",
      "Baseline Loss: 3.6409 | Actual Loss: 3.0266\n",
      "Baseline Loss: 3.6318 | Actual Loss: 1.3359\n",
      "Baseline Loss: 3.3956 | Actual Loss: 1.2883\n",
      "Baseline Loss: 3.6549 | Actual Loss: 1.2182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 42/1000 [00:26<09:53,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6142 | Actual Loss: 1.6060\n",
      "Baseline Loss: 3.0966 | Actual Loss: 1.1646\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.4344\n",
      "Baseline Loss: 3.3852 | Actual Loss: 1.1593\n",
      "Baseline Loss: 3.6360 | Actual Loss: 2.0084\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.4385\n",
      "Epoch 42/1000: Train Loss: 1.2856, Val Loss: 1.5102\n",
      "Baseline Loss: 3.5086 | Actual Loss: 1.3753\n",
      "Baseline Loss: 3.3607 | Actual Loss: 0.9972\n",
      "Baseline Loss: 3.6597 | Actual Loss: 1.8206\n",
      "Baseline Loss: 3.5707 | Actual Loss: 1.0833\n",
      "Baseline Loss: 3.4131 | Actual Loss: 0.7273\n",
      "Baseline Loss: 3.5829 | Actual Loss: 1.0621\n",
      "Baseline Loss: 3.6052 | Actual Loss: 1.2697\n",
      "Baseline Loss: 3.4967 | Actual Loss: 0.9370\n",
      "Baseline Loss: 3.5495 | Actual Loss: 1.0114\n",
      "Baseline Loss: 3.5155 | Actual Loss: 1.0957\n",
      "Baseline Loss: 3.5743 | Actual Loss: 0.9521\n",
      "Baseline Loss: 3.4884 | Actual Loss: 1.1288\n",
      "Baseline Loss: 3.4074 | Actual Loss: 2.0615\n",
      "Baseline Loss: 3.4287 | Actual Loss: 0.7542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 43/1000 [00:27<10:03,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4545 | Actual Loss: 1.0340\n",
      "Baseline Loss: 3.6062 | Actual Loss: 0.3574\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.9237\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.6525\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.3009\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.4308\n",
      "Epoch 43/1000: Train Loss: 1.1042, Val Loss: 1.3270\n",
      "Baseline Loss: 3.6186 | Actual Loss: 1.1433\n",
      "Baseline Loss: 3.5530 | Actual Loss: 1.0475\n",
      "Baseline Loss: 3.4205 | Actual Loss: 1.0193\n",
      "Baseline Loss: 3.4432 | Actual Loss: 0.9998\n",
      "Baseline Loss: 3.4891 | Actual Loss: 1.4297\n",
      "Baseline Loss: 3.4896 | Actual Loss: 0.7786\n",
      "Baseline Loss: 3.5131 | Actual Loss: 0.8776\n",
      "Baseline Loss: 3.6359 | Actual Loss: 0.9799\n",
      "Baseline Loss: 3.5835 | Actual Loss: 0.9834\n",
      "Baseline Loss: 3.7627 | Actual Loss: 0.7440\n",
      "Baseline Loss: 3.3714 | Actual Loss: 0.5508\n",
      "Baseline Loss: 3.3964 | Actual Loss: 1.7409\n",
      "Baseline Loss: 3.5208 | Actual Loss: 0.8095\n",
      "Baseline Loss: 3.6093 | Actual Loss: 1.1196\n",
      "Baseline Loss: 3.3786 | Actual Loss: 1.6831\n",
      "Baseline Loss: 3.6286 | Actual Loss: 0.8177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 44/1000 [00:27<09:45,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6276 | Actual Loss: 1.3240\n",
      "Baseline Loss: 3.3852 | Actual Loss: 1.3113\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.8874\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.3639\n",
      "Epoch 44/1000: Train Loss: 1.0453, Val Loss: 1.4716\n",
      "Baseline Loss: 3.4435 | Actual Loss: 1.3446\n",
      "Baseline Loss: 3.5747 | Actual Loss: 1.0145\n",
      "Baseline Loss: 3.4469 | Actual Loss: 0.8900\n",
      "Baseline Loss: 3.4465 | Actual Loss: 1.2685\n",
      "Baseline Loss: 3.6052 | Actual Loss: 1.2115\n",
      "Baseline Loss: 3.7577 | Actual Loss: 1.1972\n",
      "Baseline Loss: 3.5130 | Actual Loss: 1.3022\n",
      "Baseline Loss: 3.6977 | Actual Loss: 1.9445\n",
      "Baseline Loss: 3.4465 | Actual Loss: 0.8962\n",
      "Baseline Loss: 3.3240 | Actual Loss: 1.3905\n",
      "Baseline Loss: 3.6319 | Actual Loss: 1.8048\n",
      "Baseline Loss: 3.4168 | Actual Loss: 1.0986\n",
      "Baseline Loss: 3.3571 | Actual Loss: 0.7546\n",
      "Baseline Loss: 3.4367 | Actual Loss: 1.0645\n",
      "Baseline Loss: 3.6170 | Actual Loss: 0.8547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 45/1000 [00:28<10:02,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7139 | Actual Loss: 3.4012\n",
      "Baseline Loss: 3.6276 | Actual Loss: 2.2193\n",
      "Baseline Loss: 3.3852 | Actual Loss: 1.0225\n",
      "Baseline Loss: 3.6360 | Actual Loss: 2.2189\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.5180\n",
      "Epoch 45/1000: Train Loss: 1.3399, Val Loss: 1.7447\n",
      "Baseline Loss: 3.5667 | Actual Loss: 0.5374\n",
      "Baseline Loss: 3.5058 | Actual Loss: 0.7421\n",
      "Baseline Loss: 3.2944 | Actual Loss: 0.9464\n",
      "Baseline Loss: 3.6356 | Actual Loss: 1.0497\n",
      "Baseline Loss: 3.4031 | Actual Loss: 0.9714\n",
      "Baseline Loss: 3.5331 | Actual Loss: 0.9503\n",
      "Baseline Loss: 3.4147 | Actual Loss: 0.8207\n",
      "Baseline Loss: 3.6411 | Actual Loss: 3.4184\n",
      "Baseline Loss: 3.3637 | Actual Loss: 1.3863\n",
      "Baseline Loss: 3.5623 | Actual Loss: 2.7436\n",
      "Baseline Loss: 3.3639 | Actual Loss: 1.4335\n",
      "Baseline Loss: 3.4134 | Actual Loss: 1.2210\n",
      "Baseline Loss: 3.7573 | Actual Loss: 1.8786\n",
      "Baseline Loss: 3.5580 | Actual Loss: 1.3916\n",
      "Baseline Loss: 3.4584 | Actual Loss: 0.9962\n",
      "Baseline Loss: 3.6886 | Actual Loss: 1.2363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 46/1000 [00:29<10:02,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6276 | Actual Loss: 1.8494\n",
      "Baseline Loss: 3.3852 | Actual Loss: 1.4640\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.4771\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.3214\n",
      "Epoch 46/1000: Train Loss: 1.3577, Val Loss: 1.5280\n",
      "Baseline Loss: 3.3963 | Actual Loss: 1.6501\n",
      "Baseline Loss: 3.5054 | Actual Loss: 1.8148\n",
      "Baseline Loss: 3.6182 | Actual Loss: 0.6452\n",
      "Baseline Loss: 3.4024 | Actual Loss: 1.7451\n",
      "Baseline Loss: 3.4005 | Actual Loss: 1.4082\n",
      "Baseline Loss: 3.4465 | Actual Loss: 0.8835\n",
      "Baseline Loss: 3.5006 | Actual Loss: 1.2792\n",
      "Baseline Loss: 3.7016 | Actual Loss: 0.8365\n",
      "Baseline Loss: 3.7068 | Actual Loss: 1.3794\n",
      "Baseline Loss: 3.3340 | Actual Loss: 1.1815\n",
      "Baseline Loss: 3.4473 | Actual Loss: 1.1057\n",
      "Baseline Loss: 3.6930 | Actual Loss: 0.8152\n",
      "Baseline Loss: 3.6271 | Actual Loss: 0.9396\n",
      "Baseline Loss: 3.6045 | Actual Loss: 1.2270\n",
      "Baseline Loss: 3.4215 | Actual Loss: 0.8287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 47/1000 [00:29<10:20,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4402 | Actual Loss: 1.9088\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.5154\n",
      "Baseline Loss: 3.3852 | Actual Loss: 1.0650\n",
      "Baseline Loss: 3.6360 | Actual Loss: 2.3865\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.4210\n",
      "Epoch 47/1000: Train Loss: 1.2280, Val Loss: 1.5970\n",
      "Baseline Loss: 3.6412 | Actual Loss: 0.9428\n",
      "Baseline Loss: 3.3889 | Actual Loss: 0.9936\n",
      "Baseline Loss: 3.9076 | Actual Loss: 1.3073\n",
      "Baseline Loss: 3.7996 | Actual Loss: 0.7728\n",
      "Baseline Loss: 3.6462 | Actual Loss: 1.7186\n",
      "Baseline Loss: 3.4578 | Actual Loss: 1.6252\n",
      "Baseline Loss: 3.6498 | Actual Loss: 1.2906\n",
      "Baseline Loss: 3.3282 | Actual Loss: 0.8984\n",
      "Baseline Loss: 3.5447 | Actual Loss: 1.3448\n",
      "Baseline Loss: 3.5249 | Actual Loss: 1.6063\n",
      "Baseline Loss: 3.5795 | Actual Loss: 1.2299\n",
      "Baseline Loss: 3.3918 | Actual Loss: 1.1176\n",
      "Baseline Loss: 3.4100 | Actual Loss: 1.1932\n",
      "Baseline Loss: 3.3997 | Actual Loss: 1.2126\n",
      "Baseline Loss: 3.4773 | Actual Loss: 1.1938\n",
      "Baseline Loss: 3.0192 | Actual Loss: 1.0908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 48/1000 [00:30<10:11,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6276 | Actual Loss: 1.4660\n",
      "Baseline Loss: 3.3852 | Actual Loss: 1.0746\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.2395\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.3044\n",
      "Epoch 48/1000: Train Loss: 1.2211, Val Loss: 1.2711\n",
      "New best validation loss: 1.2711\n",
      "Baseline Loss: 3.4814 | Actual Loss: 0.8727\n",
      "Baseline Loss: 3.4810 | Actual Loss: 1.5958\n",
      "Baseline Loss: 3.2694 | Actual Loss: 1.0763\n",
      "Baseline Loss: 3.5450 | Actual Loss: 1.2475\n",
      "Baseline Loss: 3.4732 | Actual Loss: 2.6067\n",
      "Baseline Loss: 3.5870 | Actual Loss: 1.0713\n",
      "Baseline Loss: 3.7995 | Actual Loss: 3.7319\n",
      "Baseline Loss: 3.4654 | Actual Loss: 0.9509\n",
      "Baseline Loss: 3.4061 | Actual Loss: 1.2208\n",
      "Baseline Loss: 3.6329 | Actual Loss: 1.8836\n",
      "Baseline Loss: 3.6101 | Actual Loss: 1.7499\n",
      "Baseline Loss: 3.6309 | Actual Loss: 1.3630\n",
      "Baseline Loss: 3.5541 | Actual Loss: 0.9996\n",
      "Baseline Loss: 3.7216 | Actual Loss: 1.3553\n",
      "Baseline Loss: 3.4033 | Actual Loss: 2.5762\n",
      "Baseline Loss: 3.4118 | Actual Loss: 0.9177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 49/1000 [00:30<10:10,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6276 | Actual Loss: 1.7311\n",
      "Baseline Loss: 3.3852 | Actual Loss: 1.2265\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.4828\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.4263\n",
      "Epoch 49/1000: Train Loss: 1.5762, Val Loss: 1.4667\n",
      "Baseline Loss: 3.5997 | Actual Loss: 1.3515\n",
      "Baseline Loss: 3.3609 | Actual Loss: 1.0845\n",
      "Baseline Loss: 3.6096 | Actual Loss: 1.2979\n",
      "Baseline Loss: 3.6832 | Actual Loss: 0.9324\n",
      "Baseline Loss: 3.5498 | Actual Loss: 1.3170\n",
      "Baseline Loss: 3.5011 | Actual Loss: 1.0285\n",
      "Baseline Loss: 3.6501 | Actual Loss: 1.1444\n",
      "Baseline Loss: 3.3757 | Actual Loss: 0.9692\n",
      "Baseline Loss: 3.5208 | Actual Loss: 1.3116\n",
      "Baseline Loss: 3.5482 | Actual Loss: 1.8313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 50/1000 [00:31<10:08,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6684 | Actual Loss: 1.1554\n",
      "Baseline Loss: 3.4147 | Actual Loss: 0.6374\n",
      "Baseline Loss: 3.5712 | Actual Loss: 0.6303\n",
      "Baseline Loss: 3.4887 | Actual Loss: 1.1075\n",
      "Baseline Loss: 3.4769 | Actual Loss: 1.8229\n",
      "Baseline Loss: 3.4689 | Actual Loss: 3.1772\n",
      "Baseline Loss: 3.6276 | Actual Loss: 2.5454\n",
      "Baseline Loss: 3.3852 | Actual Loss: 1.7839\n",
      "Baseline Loss: 3.6360 | Actual Loss: 3.7501\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.5642\n",
      "Epoch 50/1000: Train Loss: 1.2999, Val Loss: 2.4109\n",
      "Baseline Loss: 3.4240 | Actual Loss: 1.2172\n",
      "Baseline Loss: 3.6313 | Actual Loss: 1.0077\n",
      "Baseline Loss: 3.5247 | Actual Loss: 0.5509\n",
      "Baseline Loss: 3.3897 | Actual Loss: 1.0374\n",
      "Baseline Loss: 3.5413 | Actual Loss: 0.6249\n",
      "Baseline Loss: 3.5961 | Actual Loss: 1.7717\n",
      "Baseline Loss: 3.7781 | Actual Loss: 0.6224\n",
      "Baseline Loss: 3.6541 | Actual Loss: 1.1177\n",
      "Baseline Loss: 3.5960 | Actual Loss: 1.5628\n",
      "Baseline Loss: 3.3703 | Actual Loss: 1.3272\n",
      "Baseline Loss: 3.4705 | Actual Loss: 1.1554\n",
      "Baseline Loss: 3.5968 | Actual Loss: 1.2210\n",
      "Baseline Loss: 3.5327 | Actual Loss: 0.8765\n",
      "Baseline Loss: 3.4585 | Actual Loss: 0.9145\n",
      "Baseline Loss: 3.6184 | Actual Loss: 2.0388\n",
      "Baseline Loss: 3.1174 | Actual Loss: 1.2759\n",
      "Baseline Loss: 3.6276 | Actual Loss: 2.1345\n",
      "Baseline Loss: 3.3852 | Actual Loss: 2.9419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 51/1000 [00:32<10:17,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6360 | Actual Loss: 4.0090\n",
      "Baseline Loss: 3.2186 | Actual Loss: 2.4050\n",
      "Epoch 51/1000: Train Loss: 1.1451, Val Loss: 2.8726\n",
      "Baseline Loss: 3.3922 | Actual Loss: 2.7145\n",
      "Baseline Loss: 3.6642 | Actual Loss: 3.6266\n",
      "Baseline Loss: 3.4549 | Actual Loss: 2.7545\n",
      "Baseline Loss: 3.4539 | Actual Loss: 3.1410\n",
      "Baseline Loss: 3.6364 | Actual Loss: 2.9153\n",
      "Baseline Loss: 3.4396 | Actual Loss: 2.9138\n",
      "Baseline Loss: 3.3141 | Actual Loss: 0.8584\n",
      "Baseline Loss: 3.5835 | Actual Loss: 1.8781\n",
      "Baseline Loss: 3.4402 | Actual Loss: 0.5212\n",
      "Baseline Loss: 3.8719 | Actual Loss: 3.3898\n",
      "Baseline Loss: 3.6280 | Actual Loss: 0.7672\n",
      "Baseline Loss: 3.6103 | Actual Loss: 1.9887\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.2311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 52/1000 [00:32<09:48,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5663 | Actual Loss: 1.8407\n",
      "Baseline Loss: 3.5579 | Actual Loss: 1.0842\n",
      "Baseline Loss: 3.3664 | Actual Loss: 0.7802\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.6403\n",
      "Baseline Loss: 3.3852 | Actual Loss: 1.3450\n",
      "Baseline Loss: 3.6360 | Actual Loss: 0.8853\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.5471\n",
      "Epoch 52/1000: Train Loss: 2.0253, Val Loss: 1.3544\n",
      "Baseline Loss: 3.5918 | Actual Loss: 1.1432\n",
      "Baseline Loss: 3.4019 | Actual Loss: 1.0975\n",
      "Baseline Loss: 3.5157 | Actual Loss: 1.3520\n",
      "Baseline Loss: 3.6141 | Actual Loss: 0.4389\n",
      "Baseline Loss: 3.1933 | Actual Loss: 2.2772\n",
      "Baseline Loss: 3.5747 | Actual Loss: 1.0841\n",
      "Baseline Loss: 3.5093 | Actual Loss: 0.8220\n",
      "Baseline Loss: 3.4852 | Actual Loss: 1.3727\n",
      "Baseline Loss: 3.4386 | Actual Loss: 0.8896\n",
      "Baseline Loss: 3.4857 | Actual Loss: 0.8574\n",
      "Baseline Loss: 3.5546 | Actual Loss: 1.5505\n",
      "Baseline Loss: 3.4976 | Actual Loss: 1.1506\n",
      "Baseline Loss: 3.8265 | Actual Loss: 0.8872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 53/1000 [00:33<10:02,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4210 | Actual Loss: 1.0475\n",
      "Baseline Loss: 3.5618 | Actual Loss: 1.1086\n",
      "Baseline Loss: 3.4491 | Actual Loss: 2.5370\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.4509\n",
      "Baseline Loss: 3.3852 | Actual Loss: 1.1274\n",
      "Baseline Loss: 3.6360 | Actual Loss: 2.5207\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.3555\n",
      "Epoch 53/1000: Train Loss: 1.2260, Val Loss: 1.6136\n",
      "Baseline Loss: 3.4106 | Actual Loss: 1.0898\n",
      "Baseline Loss: 3.7069 | Actual Loss: 0.5653\n",
      "Baseline Loss: 3.3585 | Actual Loss: 1.0739\n",
      "Baseline Loss: 3.5367 | Actual Loss: 1.1379\n",
      "Baseline Loss: 3.5285 | Actual Loss: 1.0402\n",
      "Baseline Loss: 3.4237 | Actual Loss: 0.8948\n",
      "Baseline Loss: 3.3516 | Actual Loss: 1.3380\n",
      "Baseline Loss: 3.4140 | Actual Loss: 1.4943\n",
      "Baseline Loss: 3.5337 | Actual Loss: 0.7907\n",
      "Baseline Loss: 3.7074 | Actual Loss: 1.1803\n",
      "Baseline Loss: 3.5206 | Actual Loss: 0.7521\n",
      "Baseline Loss: 3.6596 | Actual Loss: 2.0107\n",
      "Baseline Loss: 3.5711 | Actual Loss: 0.5162\n",
      "Baseline Loss: 3.6738 | Actual Loss: 0.6217\n",
      "Baseline Loss: 3.5619 | Actual Loss: 0.8095\n",
      "Baseline Loss: 3.4028 | Actual Loss: 1.2523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 54/1000 [00:34<09:45,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6276 | Actual Loss: 0.8088\n",
      "Baseline Loss: 3.3852 | Actual Loss: 1.0045\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.4218\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.4310\n",
      "Epoch 54/1000: Train Loss: 1.0355, Val Loss: 1.1665\n",
      "New best validation loss: 1.1665\n",
      "Baseline Loss: 3.5456 | Actual Loss: 1.2146\n",
      "Baseline Loss: 3.5283 | Actual Loss: 0.8537\n",
      "Baseline Loss: 3.4590 | Actual Loss: 1.1367\n",
      "Baseline Loss: 3.5700 | Actual Loss: 1.1646\n",
      "Baseline Loss: 3.4769 | Actual Loss: 0.7795\n",
      "Baseline Loss: 3.4839 | Actual Loss: 0.7756\n",
      "Baseline Loss: 3.5573 | Actual Loss: 1.1050\n",
      "Baseline Loss: 3.6177 | Actual Loss: 0.6758\n",
      "Baseline Loss: 3.5539 | Actual Loss: 0.4959\n",
      "Baseline Loss: 3.6738 | Actual Loss: 1.1272\n",
      "Baseline Loss: 3.6140 | Actual Loss: 2.2245\n",
      "Baseline Loss: 3.6057 | Actual Loss: 0.7598\n",
      "Baseline Loss: 3.4932 | Actual Loss: 1.1658\n",
      "Baseline Loss: 3.7073 | Actual Loss: 1.7996\n",
      "Baseline Loss: 3.3119 | Actual Loss: 1.0723\n",
      "Baseline Loss: 3.3935 | Actual Loss: 0.6169\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.7265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 55/1000 [00:34<09:45,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3852 | Actual Loss: 1.0489\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.3760\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.4362\n",
      "Epoch 55/1000: Train Loss: 1.0605, Val Loss: 1.3969\n",
      "Baseline Loss: 3.3674 | Actual Loss: 1.1850\n",
      "Baseline Loss: 3.5208 | Actual Loss: 1.0360\n",
      "Baseline Loss: 3.5620 | Actual Loss: 1.0427\n",
      "Baseline Loss: 3.4665 | Actual Loss: 1.0837\n",
      "Baseline Loss: 3.5663 | Actual Loss: 1.5177\n",
      "Baseline Loss: 3.5746 | Actual Loss: 1.5496\n",
      "Baseline Loss: 3.4065 | Actual Loss: 2.0817\n",
      "Baseline Loss: 3.6681 | Actual Loss: 0.9412\n",
      "Baseline Loss: 3.5292 | Actual Loss: 0.8498\n",
      "Baseline Loss: 3.5623 | Actual Loss: 0.6145\n",
      "Baseline Loss: 3.5366 | Actual Loss: 0.9248\n",
      "Baseline Loss: 3.5577 | Actual Loss: 1.2267\n",
      "Baseline Loss: 3.3649 | Actual Loss: 1.4764\n",
      "Baseline Loss: 3.6008 | Actual Loss: 1.4117\n",
      "Baseline Loss: 3.6977 | Actual Loss: 0.6529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 56/1000 [00:35<10:12,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4128 | Actual Loss: 2.8669\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.2832\n",
      "Baseline Loss: 3.3852 | Actual Loss: 1.1774\n",
      "Baseline Loss: 3.6360 | Actual Loss: 2.0818\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.1036\n",
      "Epoch 56/1000: Train Loss: 1.2788, Val Loss: 1.4115\n",
      "Baseline Loss: 3.5245 | Actual Loss: 1.5884\n",
      "Baseline Loss: 3.5375 | Actual Loss: 1.0369\n",
      "Baseline Loss: 3.4580 | Actual Loss: 0.8041\n",
      "Baseline Loss: 3.7622 | Actual Loss: 1.2194\n",
      "Baseline Loss: 3.6588 | Actual Loss: 0.9285\n",
      "Baseline Loss: 3.4440 | Actual Loss: 1.3024\n",
      "Baseline Loss: 3.3178 | Actual Loss: 0.8599\n",
      "Baseline Loss: 3.5544 | Actual Loss: 1.0029\n",
      "Baseline Loss: 3.6792 | Actual Loss: 1.0639\n",
      "Baseline Loss: 3.5580 | Actual Loss: 1.1266\n",
      "Baseline Loss: 3.3798 | Actual Loss: 1.0112\n",
      "Baseline Loss: 3.3881 | Actual Loss: 0.7662\n",
      "Baseline Loss: 3.5089 | Actual Loss: 0.8699\n",
      "Baseline Loss: 3.7027 | Actual Loss: 0.7784\n",
      "Baseline Loss: 3.2700 | Actual Loss: 0.7094\n",
      "Baseline Loss: 3.6175 | Actual Loss: 3.0425\n",
      "Baseline Loss: 3.6276 | Actual Loss: 2.7597\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.9033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 57/1000 [00:35<09:47,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6360 | Actual Loss: 3.0355\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.6791\n",
      "Epoch 57/1000: Train Loss: 1.1319, Val Loss: 2.0944\n",
      "Baseline Loss: 3.7120 | Actual Loss: 0.5622\n",
      "Baseline Loss: 3.4619 | Actual Loss: 2.8005\n",
      "Baseline Loss: 3.4062 | Actual Loss: 2.5131\n",
      "Baseline Loss: 3.4852 | Actual Loss: 0.8533\n",
      "Baseline Loss: 3.5204 | Actual Loss: 1.4404\n",
      "Baseline Loss: 3.6450 | Actual Loss: 0.8361\n",
      "Baseline Loss: 3.3955 | Actual Loss: 0.9215\n",
      "Baseline Loss: 3.6319 | Actual Loss: 1.5102\n",
      "Baseline Loss: 3.4506 | Actual Loss: 0.6544\n",
      "Baseline Loss: 3.5298 | Actual Loss: 1.2923\n",
      "Baseline Loss: 3.6878 | Actual Loss: 0.7303\n",
      "Baseline Loss: 3.4420 | Actual Loss: 1.6460\n",
      "Baseline Loss: 3.4655 | Actual Loss: 1.0502\n",
      "Baseline Loss: 3.6367 | Actual Loss: 1.0565\n",
      "Baseline Loss: 3.3344 | Actual Loss: 1.5361\n",
      "Baseline Loss: 3.4204 | Actual Loss: 2.6327\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.1836\n",
      "Baseline Loss: 3.3852 | Actual Loss: 1.0578\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.3079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 58/1000 [00:36<09:46,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.2186 | Actual Loss: 1.4496\n",
      "Epoch 58/1000: Train Loss: 1.3772, Val Loss: 1.2497\n",
      "Baseline Loss: 3.4180 | Actual Loss: 1.1290\n",
      "Baseline Loss: 3.7886 | Actual Loss: 1.9101\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.1074\n",
      "Baseline Loss: 3.3857 | Actual Loss: 0.6808\n",
      "Baseline Loss: 3.4853 | Actual Loss: 1.2595\n",
      "Baseline Loss: 3.6007 | Actual Loss: 1.2652\n",
      "Baseline Loss: 3.6447 | Actual Loss: 2.3595\n",
      "Baseline Loss: 3.2574 | Actual Loss: 0.8376\n",
      "Baseline Loss: 3.5373 | Actual Loss: 0.9193\n",
      "Baseline Loss: 3.5706 | Actual Loss: 1.1645\n",
      "Baseline Loss: 3.6015 | Actual Loss: 1.1597\n",
      "Baseline Loss: 3.6324 | Actual Loss: 0.8423\n",
      "Baseline Loss: 3.4216 | Actual Loss: 1.6438\n",
      "Baseline Loss: 3.4241 | Actual Loss: 0.7226\n",
      "Baseline Loss: 3.7171 | Actual Loss: 1.2766\n",
      "Baseline Loss: 3.1370 | Actual Loss: 0.3693\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.3192\n",
      "Baseline Loss: 3.3852 | Actual Loss: 1.1396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 59/1000 [00:37<09:59,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6360 | Actual Loss: 1.5245\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.4143\n",
      "Epoch 59/1000: Train Loss: 1.1655, Val Loss: 1.3494\n",
      "Baseline Loss: 3.8547 | Actual Loss: 0.4152\n",
      "Baseline Loss: 3.7677 | Actual Loss: 1.3188\n",
      "Baseline Loss: 3.4967 | Actual Loss: 0.7701\n",
      "Baseline Loss: 3.6009 | Actual Loss: 0.7686\n",
      "Baseline Loss: 3.6692 | Actual Loss: 3.8071\n",
      "Baseline Loss: 3.3433 | Actual Loss: 1.2930\n",
      "Baseline Loss: 3.4616 | Actual Loss: 2.1501\n",
      "Baseline Loss: 3.3544 | Actual Loss: 1.6809\n",
      "Baseline Loss: 3.4328 | Actual Loss: 1.0551\n",
      "Baseline Loss: 3.6136 | Actual Loss: 1.0436\n",
      "Baseline Loss: 3.5705 | Actual Loss: 0.8757\n",
      "Baseline Loss: 3.3788 | Actual Loss: 1.0393\n",
      "Baseline Loss: 3.4140 | Actual Loss: 0.8502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 60/1000 [00:37<09:34,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6102 | Actual Loss: 1.5698\n",
      "Baseline Loss: 3.4204 | Actual Loss: 1.0010\n",
      "Baseline Loss: 3.4494 | Actual Loss: 1.2122\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.2889\n",
      "Baseline Loss: 3.3852 | Actual Loss: 1.0458\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.1966\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.3964\n",
      "Epoch 60/1000: Train Loss: 1.3032, Val Loss: 1.2319\n",
      "Baseline Loss: 3.4935 | Actual Loss: 1.3656\n",
      "Baseline Loss: 3.5333 | Actual Loss: 1.4849\n",
      "Baseline Loss: 3.5326 | Actual Loss: 0.8910\n",
      "Baseline Loss: 3.5916 | Actual Loss: 1.4691\n",
      "Baseline Loss: 3.4854 | Actual Loss: 1.9084\n",
      "Baseline Loss: 3.4812 | Actual Loss: 0.7916\n",
      "Baseline Loss: 3.4348 | Actual Loss: 0.9240\n",
      "Baseline Loss: 3.5244 | Actual Loss: 0.9268\n",
      "Baseline Loss: 3.5747 | Actual Loss: 0.8308\n",
      "Baseline Loss: 3.5747 | Actual Loss: 1.0773\n",
      "Baseline Loss: 3.7471 | Actual Loss: 0.3100\n",
      "Baseline Loss: 3.4702 | Actual Loss: 1.6135\n",
      "Baseline Loss: 3.5836 | Actual Loss: 1.1101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 61/1000 [00:38<09:55,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3919 | Actual Loss: 1.2327\n",
      "Baseline Loss: 3.4849 | Actual Loss: 0.7965\n",
      "Baseline Loss: 3.5510 | Actual Loss: 1.0738\n",
      "Baseline Loss: 3.6276 | Actual Loss: 2.7148\n",
      "Baseline Loss: 3.3852 | Actual Loss: 1.3067\n",
      "Baseline Loss: 3.6360 | Actual Loss: 2.9327\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.6072\n",
      "Epoch 61/1000: Train Loss: 1.1129, Val Loss: 2.1404\n",
      "Baseline Loss: 3.5247 | Actual Loss: 1.3213\n",
      "Baseline Loss: 3.3703 | Actual Loss: 0.6497\n",
      "Baseline Loss: 3.5877 | Actual Loss: 1.0386\n",
      "Baseline Loss: 3.6174 | Actual Loss: 0.7611\n",
      "Baseline Loss: 3.5289 | Actual Loss: 0.8241\n",
      "Baseline Loss: 3.4362 | Actual Loss: 1.8356\n",
      "Baseline Loss: 3.7119 | Actual Loss: 0.8571\n",
      "Baseline Loss: 3.3926 | Actual Loss: 1.1223\n",
      "Baseline Loss: 3.6929 | Actual Loss: 1.4898\n",
      "Baseline Loss: 3.5656 | Actual Loss: 0.9299\n",
      "Baseline Loss: 3.5710 | Actual Loss: 0.6213\n",
      "Baseline Loss: 3.4501 | Actual Loss: 1.7017\n",
      "Baseline Loss: 3.3813 | Actual Loss: 1.3919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 62/1000 [00:39<10:06,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3749 | Actual Loss: 1.1285\n",
      "Baseline Loss: 3.6142 | Actual Loss: 1.3367\n",
      "Baseline Loss: 3.2584 | Actual Loss: 0.4020\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.0914\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.9274\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.5647\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.3389\n",
      "Epoch 62/1000: Train Loss: 1.0882, Val Loss: 1.2306\n",
      "Baseline Loss: 3.4103 | Actual Loss: 0.9265\n",
      "Baseline Loss: 3.7325 | Actual Loss: 1.0482\n",
      "Baseline Loss: 3.5528 | Actual Loss: 0.7498\n",
      "Baseline Loss: 3.5411 | Actual Loss: 1.6149\n",
      "Baseline Loss: 3.3991 | Actual Loss: 1.1512\n",
      "Baseline Loss: 3.3639 | Actual Loss: 1.0466\n",
      "Baseline Loss: 3.4580 | Actual Loss: 0.9434\n",
      "Baseline Loss: 3.6230 | Actual Loss: 1.5931\n",
      "Baseline Loss: 3.4663 | Actual Loss: 1.8633\n",
      "Baseline Loss: 3.3015 | Actual Loss: 0.8064\n",
      "Baseline Loss: 3.7120 | Actual Loss: 1.0135\n",
      "Baseline Loss: 3.6687 | Actual Loss: 1.3676\n",
      "Baseline Loss: 3.7682 | Actual Loss: 1.1317\n",
      "Baseline Loss: 3.6319 | Actual Loss: 1.0380\n",
      "Baseline Loss: 3.5500 | Actual Loss: 2.5626\n",
      "Baseline Loss: 3.0914 | Actual Loss: 0.6437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 63/1000 [00:39<09:38,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6276 | Actual Loss: 1.1143\n",
      "Baseline Loss: 3.3852 | Actual Loss: 1.1252\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.2755\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.3835\n",
      "Epoch 63/1000: Train Loss: 1.2188, Val Loss: 1.2246\n",
      "Baseline Loss: 3.7075 | Actual Loss: 1.1841\n",
      "Baseline Loss: 3.4545 | Actual Loss: 0.9961\n",
      "Baseline Loss: 3.3355 | Actual Loss: 1.1977\n",
      "Baseline Loss: 3.4624 | Actual Loss: 1.3232\n",
      "Baseline Loss: 3.4432 | Actual Loss: 1.2436\n",
      "Baseline Loss: 3.4739 | Actual Loss: 1.1540\n",
      "Baseline Loss: 3.4894 | Actual Loss: 1.0821\n",
      "Baseline Loss: 3.5574 | Actual Loss: 1.0362\n",
      "Baseline Loss: 3.4655 | Actual Loss: 1.1527\n",
      "Baseline Loss: 3.5873 | Actual Loss: 1.2679\n",
      "Baseline Loss: 3.5671 | Actual Loss: 0.9448\n",
      "Baseline Loss: 3.4926 | Actual Loss: 0.8824\n",
      "Baseline Loss: 3.3619 | Actual Loss: 0.6150\n",
      "Baseline Loss: 3.7125 | Actual Loss: 0.9493\n",
      "Baseline Loss: 3.7316 | Actual Loss: 0.9964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 64/1000 [00:40<09:55,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3931 | Actual Loss: 2.4579\n",
      "Baseline Loss: 3.6276 | Actual Loss: 2.8112\n",
      "Baseline Loss: 3.3852 | Actual Loss: 1.2556\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.4547\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.3470\n",
      "Epoch 64/1000: Train Loss: 1.1552, Val Loss: 1.7171\n",
      "Baseline Loss: 3.4747 | Actual Loss: 0.8738\n",
      "Baseline Loss: 3.7272 | Actual Loss: 2.1734\n",
      "Baseline Loss: 3.6547 | Actual Loss: 1.4399\n",
      "Baseline Loss: 3.4928 | Actual Loss: 1.9884\n",
      "Baseline Loss: 3.4430 | Actual Loss: 1.2883\n",
      "Baseline Loss: 3.6465 | Actual Loss: 1.0336\n",
      "Baseline Loss: 3.4855 | Actual Loss: 0.8323\n",
      "Baseline Loss: 3.4071 | Actual Loss: 0.9567\n",
      "Baseline Loss: 3.6832 | Actual Loss: 0.9101\n",
      "Baseline Loss: 3.5210 | Actual Loss: 1.6318\n",
      "Baseline Loss: 3.4888 | Actual Loss: 0.9919\n",
      "Baseline Loss: 3.4432 | Actual Loss: 1.2223\n",
      "Baseline Loss: 3.5293 | Actual Loss: 1.1178\n",
      "Baseline Loss: 3.6098 | Actual Loss: 1.0565\n",
      "Baseline Loss: 3.6274 | Actual Loss: 0.9319\n",
      "Baseline Loss: 3.1959 | Actual Loss: 0.6925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▋         | 65/1000 [00:41<09:53,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6276 | Actual Loss: 1.5780\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.9556\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.7771\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.3972\n",
      "Epoch 65/1000: Train Loss: 1.1963, Val Loss: 1.4270\n",
      "Baseline Loss: 3.6644 | Actual Loss: 1.0663\n",
      "Baseline Loss: 3.3245 | Actual Loss: 1.6735\n",
      "Baseline Loss: 3.5051 | Actual Loss: 0.9691\n",
      "Baseline Loss: 3.5168 | Actual Loss: 1.4404\n",
      "Baseline Loss: 3.5575 | Actual Loss: 0.6573\n",
      "Baseline Loss: 3.6600 | Actual Loss: 0.9538\n",
      "Baseline Loss: 3.3269 | Actual Loss: 1.3613\n",
      "Baseline Loss: 3.5706 | Actual Loss: 0.8812\n",
      "Baseline Loss: 3.7268 | Actual Loss: 1.5732\n",
      "Baseline Loss: 3.5664 | Actual Loss: 3.2577\n",
      "Baseline Loss: 3.4136 | Actual Loss: 1.9553\n",
      "Baseline Loss: 3.5400 | Actual Loss: 0.9532\n",
      "Baseline Loss: 3.5301 | Actual Loss: 0.9889\n",
      "Baseline Loss: 3.5508 | Actual Loss: 1.3361\n",
      "Baseline Loss: 3.5367 | Actual Loss: 1.0607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 66/1000 [00:41<10:06,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3150 | Actual Loss: 0.8881\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.3873\n",
      "Baseline Loss: 3.3852 | Actual Loss: 1.1231\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.2843\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.3778\n",
      "Epoch 66/1000: Train Loss: 1.3135, Val Loss: 1.2931\n",
      "Baseline Loss: 3.4730 | Actual Loss: 0.9610\n",
      "Baseline Loss: 3.6831 | Actual Loss: 1.3729\n",
      "Baseline Loss: 3.3706 | Actual Loss: 1.4951\n",
      "Baseline Loss: 3.4025 | Actual Loss: 1.0541\n",
      "Baseline Loss: 3.4457 | Actual Loss: 0.6934\n",
      "Baseline Loss: 3.5707 | Actual Loss: 0.9869\n",
      "Baseline Loss: 3.6647 | Actual Loss: 0.9836\n",
      "Baseline Loss: 3.5238 | Actual Loss: 0.6445\n",
      "Baseline Loss: 3.6185 | Actual Loss: 1.1229\n",
      "Baseline Loss: 3.3674 | Actual Loss: 1.2040\n",
      "Baseline Loss: 3.4816 | Actual Loss: 0.5826\n",
      "Baseline Loss: 3.4463 | Actual Loss: 1.3853\n",
      "Baseline Loss: 3.7728 | Actual Loss: 1.0781\n",
      "Baseline Loss: 3.5447 | Actual Loss: 0.5657\n",
      "Baseline Loss: 3.5875 | Actual Loss: 1.4313\n",
      "Baseline Loss: 3.7262 | Actual Loss: 1.8629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 67/1000 [00:42<09:53,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6276 | Actual Loss: 1.3429\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.8866\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.4332\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.2185\n",
      "Epoch 67/1000: Train Loss: 1.0890, Val Loss: 1.2203\n",
      "Baseline Loss: 3.3960 | Actual Loss: 1.1635\n",
      "Baseline Loss: 3.4873 | Actual Loss: 0.9199\n",
      "Baseline Loss: 3.6273 | Actual Loss: 1.7845\n",
      "Baseline Loss: 3.5450 | Actual Loss: 1.3459\n",
      "Baseline Loss: 3.4473 | Actual Loss: 0.9271\n",
      "Baseline Loss: 3.6417 | Actual Loss: 1.4588\n",
      "Baseline Loss: 3.5333 | Actual Loss: 1.6010\n",
      "Baseline Loss: 3.4319 | Actual Loss: 1.0061\n",
      "Baseline Loss: 3.7186 | Actual Loss: 1.3402\n",
      "Baseline Loss: 3.6875 | Actual Loss: 1.0161\n",
      "Baseline Loss: 3.3145 | Actual Loss: 1.3025\n",
      "Baseline Loss: 3.5836 | Actual Loss: 1.4924\n",
      "Baseline Loss: 3.5089 | Actual Loss: 1.3239\n",
      "Baseline Loss: 3.5135 | Actual Loss: 0.9199\n",
      "Baseline Loss: 3.7065 | Actual Loss: 0.8843\n",
      "Baseline Loss: 3.4689 | Actual Loss: 1.5715\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.1938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 68/1000 [00:42<09:54,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3852 | Actual Loss: 0.7021\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.0851\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.3762\n",
      "Epoch 68/1000: Train Loss: 1.2536, Val Loss: 1.0893\n",
      "New best validation loss: 1.0893\n",
      "Baseline Loss: 3.6182 | Actual Loss: 0.8240\n",
      "Baseline Loss: 3.7568 | Actual Loss: 1.1058\n",
      "Baseline Loss: 3.4888 | Actual Loss: 1.2721\n",
      "Baseline Loss: 3.4738 | Actual Loss: 1.0363\n",
      "Baseline Loss: 3.5580 | Actual Loss: 1.0433\n",
      "Baseline Loss: 3.6631 | Actual Loss: 0.6474\n",
      "Baseline Loss: 3.6230 | Actual Loss: 2.6842\n",
      "Baseline Loss: 3.6492 | Actual Loss: 0.9402\n",
      "Baseline Loss: 3.3535 | Actual Loss: 0.8205\n",
      "Baseline Loss: 3.6647 | Actual Loss: 0.8399\n",
      "Baseline Loss: 3.3881 | Actual Loss: 0.7412\n",
      "Baseline Loss: 3.5966 | Actual Loss: 1.1000\n",
      "Baseline Loss: 3.3235 | Actual Loss: 0.9385\n",
      "Baseline Loss: 3.6833 | Actual Loss: 1.4667\n",
      "Baseline Loss: 3.5368 | Actual Loss: 1.6038\n",
      "Baseline Loss: 3.2263 | Actual Loss: 0.3706\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.8447\n",
      "Baseline Loss: 3.3852 | Actual Loss: 2.1301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 69/1000 [00:43<09:48,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6360 | Actual Loss: 2.4129\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.4218\n",
      "Epoch 69/1000: Train Loss: 1.0897, Val Loss: 1.9524\n",
      "Baseline Loss: 3.4661 | Actual Loss: 1.0672\n",
      "Baseline Loss: 3.4621 | Actual Loss: 0.8084\n",
      "Baseline Loss: 3.5968 | Actual Loss: 0.8547\n",
      "Baseline Loss: 3.5378 | Actual Loss: 0.8159\n",
      "Baseline Loss: 3.4697 | Actual Loss: 1.0384\n",
      "Baseline Loss: 3.6192 | Actual Loss: 1.5260\n",
      "Baseline Loss: 3.5088 | Actual Loss: 1.0761\n",
      "Baseline Loss: 3.4663 | Actual Loss: 1.0003\n",
      "Baseline Loss: 3.4724 | Actual Loss: 0.9381\n",
      "Baseline Loss: 3.5671 | Actual Loss: 0.7615\n",
      "Baseline Loss: 3.2665 | Actual Loss: 1.1364\n",
      "Baseline Loss: 3.5092 | Actual Loss: 1.3705\n",
      "Baseline Loss: 3.3074 | Actual Loss: 1.1648\n",
      "Baseline Loss: 3.7320 | Actual Loss: 2.9391\n",
      "Baseline Loss: 3.5666 | Actual Loss: 0.9569\n",
      "Baseline Loss: 3.6889 | Actual Loss: 0.5190\n",
      "Baseline Loss: 3.6276 | Actual Loss: 2.2164\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.9727\n",
      "Baseline Loss: 3.6360 | Actual Loss: 2.2946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 70/1000 [00:44<09:38,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.2186 | Actual Loss: 1.4472\n",
      "Epoch 70/1000: Train Loss: 1.1233, Val Loss: 1.7327\n",
      "Baseline Loss: 3.6502 | Actual Loss: 1.0781\n",
      "Baseline Loss: 3.4542 | Actual Loss: 1.9453\n",
      "Baseline Loss: 3.7170 | Actual Loss: 0.7117\n",
      "Baseline Loss: 3.6148 | Actual Loss: 0.8631\n",
      "Baseline Loss: 3.4934 | Actual Loss: 0.9211\n",
      "Baseline Loss: 3.6975 | Actual Loss: 0.7164\n",
      "Baseline Loss: 3.5746 | Actual Loss: 0.9253\n",
      "Baseline Loss: 3.7941 | Actual Loss: 1.1006\n",
      "Baseline Loss: 3.7477 | Actual Loss: 0.9054\n",
      "Baseline Loss: 3.4070 | Actual Loss: 1.8931\n",
      "Baseline Loss: 3.4143 | Actual Loss: 0.8747\n",
      "Baseline Loss: 3.5715 | Actual Loss: 0.9419\n",
      "Baseline Loss: 3.3678 | Actual Loss: 0.9008\n",
      "Baseline Loss: 3.3317 | Actual Loss: 0.8471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 71/1000 [00:44<09:46,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5016 | Actual Loss: 0.7225\n",
      "Baseline Loss: 3.0969 | Actual Loss: 1.1342\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.7173\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.7920\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.5981\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.1335\n",
      "Epoch 71/1000: Train Loss: 1.0301, Val Loss: 1.3102\n",
      "Baseline Loss: 3.4324 | Actual Loss: 1.0116\n",
      "Baseline Loss: 3.3675 | Actual Loss: 1.1238\n",
      "Baseline Loss: 3.5332 | Actual Loss: 1.9778\n",
      "Baseline Loss: 3.4431 | Actual Loss: 1.4775\n",
      "Baseline Loss: 3.5923 | Actual Loss: 1.0048\n",
      "Baseline Loss: 3.6410 | Actual Loss: 3.5879\n",
      "Baseline Loss: 3.4852 | Actual Loss: 0.7008\n",
      "Baseline Loss: 3.6367 | Actual Loss: 1.0368\n",
      "Baseline Loss: 3.5539 | Actual Loss: 0.8328\n",
      "Baseline Loss: 3.4970 | Actual Loss: 0.8975\n",
      "Baseline Loss: 3.6505 | Actual Loss: 1.1261\n",
      "Baseline Loss: 3.4139 | Actual Loss: 0.9676\n",
      "Baseline Loss: 3.6931 | Actual Loss: 0.6824\n",
      "Baseline Loss: 3.4029 | Actual Loss: 0.6185\n",
      "Baseline Loss: 3.4395 | Actual Loss: 0.5835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 72/1000 [00:45<09:54,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5298 | Actual Loss: 0.4569\n",
      "Baseline Loss: 3.6276 | Actual Loss: 2.3841\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.6730\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.5683\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.1862\n",
      "Epoch 72/1000: Train Loss: 1.1304, Val Loss: 1.4529\n",
      "Baseline Loss: 3.4708 | Actual Loss: 2.2679\n",
      "Baseline Loss: 3.7020 | Actual Loss: 0.5898\n",
      "Baseline Loss: 3.7170 | Actual Loss: 2.5428\n",
      "Baseline Loss: 3.5163 | Actual Loss: 0.8235\n",
      "Baseline Loss: 3.3919 | Actual Loss: 0.9016\n",
      "Baseline Loss: 3.4929 | Actual Loss: 0.8441\n",
      "Baseline Loss: 3.5089 | Actual Loss: 0.8501\n",
      "Baseline Loss: 3.4842 | Actual Loss: 1.4574\n",
      "Baseline Loss: 3.5366 | Actual Loss: 1.1170\n",
      "Baseline Loss: 3.5403 | Actual Loss: 1.6121\n",
      "Baseline Loss: 3.5527 | Actual Loss: 1.2696\n",
      "Baseline Loss: 3.4818 | Actual Loss: 0.5618\n",
      "Baseline Loss: 3.5177 | Actual Loss: 1.8148\n",
      "Baseline Loss: 3.6278 | Actual Loss: 2.6594\n",
      "Baseline Loss: 3.3993 | Actual Loss: 0.9433\n",
      "Baseline Loss: 3.3673 | Actual Loss: 0.7211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 73/1000 [00:46<09:32,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6276 | Actual Loss: 1.5743\n",
      "Baseline Loss: 3.3852 | Actual Loss: 1.0799\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.3620\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.2669\n",
      "Epoch 73/1000: Train Loss: 1.3110, Val Loss: 1.3208\n",
      "Baseline Loss: 3.3239 | Actual Loss: 1.2242\n",
      "Baseline Loss: 3.4899 | Actual Loss: 1.5162\n",
      "Baseline Loss: 3.9819 | Actual Loss: 0.6615\n",
      "Baseline Loss: 3.6628 | Actual Loss: 0.8724\n",
      "Baseline Loss: 3.4031 | Actual Loss: 0.9204\n",
      "Baseline Loss: 3.4773 | Actual Loss: 3.3384\n",
      "Baseline Loss: 3.5619 | Actual Loss: 1.2417\n",
      "Baseline Loss: 3.4577 | Actual Loss: 0.9494\n",
      "Baseline Loss: 3.5577 | Actual Loss: 1.3770\n",
      "Baseline Loss: 3.5662 | Actual Loss: 1.1624\n",
      "Baseline Loss: 3.4095 | Actual Loss: 1.2818\n",
      "Baseline Loss: 3.5128 | Actual Loss: 0.6826\n",
      "Baseline Loss: 3.4578 | Actual Loss: 0.9645\n",
      "Baseline Loss: 3.6786 | Actual Loss: 1.5786\n",
      "Baseline Loss: 3.4534 | Actual Loss: 1.0325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 74/1000 [00:46<09:49,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3147 | Actual Loss: 0.5443\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.2176\n",
      "Baseline Loss: 3.3852 | Actual Loss: 1.0957\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.2803\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.2509\n",
      "Epoch 74/1000: Train Loss: 1.2092, Val Loss: 1.2111\n",
      "Baseline Loss: 3.4323 | Actual Loss: 1.2208\n",
      "Baseline Loss: 3.7522 | Actual Loss: 1.3656\n",
      "Baseline Loss: 3.6929 | Actual Loss: 1.0414\n",
      "Baseline Loss: 3.5747 | Actual Loss: 1.1356\n",
      "Baseline Loss: 3.4805 | Actual Loss: 0.4105\n",
      "Baseline Loss: 3.4284 | Actual Loss: 1.1214\n",
      "Baseline Loss: 3.7081 | Actual Loss: 3.3386\n",
      "Baseline Loss: 3.6175 | Actual Loss: 0.3740\n",
      "Baseline Loss: 3.5368 | Actual Loss: 2.3006\n",
      "Baseline Loss: 3.4100 | Actual Loss: 0.6951\n",
      "Baseline Loss: 3.4329 | Actual Loss: 1.0803\n",
      "Baseline Loss: 3.4583 | Actual Loss: 0.7469\n",
      "Baseline Loss: 3.6782 | Actual Loss: 0.4544\n",
      "Baseline Loss: 3.5282 | Actual Loss: 1.1040\n",
      "Baseline Loss: 3.5966 | Actual Loss: 1.2904\n",
      "Baseline Loss: 3.1590 | Actual Loss: 0.7620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 75/1000 [00:47<09:40,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6276 | Actual Loss: 1.7117\n",
      "Baseline Loss: 3.3852 | Actual Loss: 1.0161\n",
      "Baseline Loss: 3.6360 | Actual Loss: 2.0448\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.3332\n",
      "Epoch 75/1000: Train Loss: 1.1526, Val Loss: 1.5265\n",
      "Baseline Loss: 3.2891 | Actual Loss: 1.1776\n",
      "Baseline Loss: 3.8158 | Actual Loss: 1.7995\n",
      "Baseline Loss: 3.6501 | Actual Loss: 1.5647\n",
      "Baseline Loss: 3.5051 | Actual Loss: 0.5008\n",
      "Baseline Loss: 3.3167 | Actual Loss: 0.6676\n",
      "Baseline Loss: 3.2510 | Actual Loss: 0.6417\n",
      "Baseline Loss: 3.3055 | Actual Loss: 1.0364\n",
      "Baseline Loss: 3.5371 | Actual Loss: 0.8093\n",
      "Baseline Loss: 3.5422 | Actual Loss: 2.0437\n",
      "Baseline Loss: 3.5709 | Actual Loss: 0.6398\n",
      "Baseline Loss: 3.4177 | Actual Loss: 0.7696\n",
      "Baseline Loss: 3.6597 | Actual Loss: 3.4688\n",
      "Baseline Loss: 3.4104 | Actual Loss: 0.8837\n",
      "Baseline Loss: 3.8665 | Actual Loss: 0.9859\n",
      "Baseline Loss: 3.6972 | Actual Loss: 2.1527\n",
      "Baseline Loss: 3.4028 | Actual Loss: 0.4916\n",
      "Baseline Loss: 3.6276 | Actual Loss: 2.3032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 76/1000 [00:48<09:40,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3852 | Actual Loss: 0.8617\n",
      "Baseline Loss: 3.6360 | Actual Loss: 3.4125\n",
      "Baseline Loss: 3.2186 | Actual Loss: 2.2901\n",
      "Epoch 76/1000: Train Loss: 1.2271, Val Loss: 2.2169\n",
      "Baseline Loss: 3.9437 | Actual Loss: 1.2774\n",
      "Baseline Loss: 3.3963 | Actual Loss: 1.1696\n",
      "Baseline Loss: 3.4185 | Actual Loss: 1.5353\n",
      "Baseline Loss: 3.6975 | Actual Loss: 2.3770\n",
      "Baseline Loss: 3.3269 | Actual Loss: 0.6584\n",
      "Baseline Loss: 3.7169 | Actual Loss: 1.1779\n",
      "Baseline Loss: 3.7367 | Actual Loss: 2.0279\n",
      "Baseline Loss: 3.5954 | Actual Loss: 0.4783\n",
      "Baseline Loss: 3.7625 | Actual Loss: 0.7896\n",
      "Baseline Loss: 3.3985 | Actual Loss: 0.8079\n",
      "Baseline Loss: 3.2570 | Actual Loss: 0.9893\n",
      "Baseline Loss: 3.6091 | Actual Loss: 1.3610\n",
      "Baseline Loss: 3.4322 | Actual Loss: 0.9290\n",
      "Baseline Loss: 3.6742 | Actual Loss: 0.4318\n",
      "Baseline Loss: 3.3757 | Actual Loss: 0.9166\n",
      "Baseline Loss: 3.5084 | Actual Loss: 0.9223\n",
      "Baseline Loss: 3.6276 | Actual Loss: 2.2591\n",
      "Baseline Loss: 3.3852 | Actual Loss: 1.1490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 77/1000 [00:48<09:42,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6360 | Actual Loss: 2.3623\n",
      "Baseline Loss: 3.2186 | Actual Loss: 2.1285\n",
      "Epoch 77/1000: Train Loss: 1.1156, Val Loss: 1.9747\n",
      "Baseline Loss: 3.5452 | Actual Loss: 0.4636\n",
      "Baseline Loss: 3.4432 | Actual Loss: 1.1011\n",
      "Baseline Loss: 3.4506 | Actual Loss: 0.7179\n",
      "Baseline Loss: 3.4328 | Actual Loss: 1.4735\n",
      "Baseline Loss: 3.4350 | Actual Loss: 1.5063\n",
      "Baseline Loss: 3.9011 | Actual Loss: 1.3348\n",
      "Baseline Loss: 3.5533 | Actual Loss: 3.5474\n",
      "Baseline Loss: 3.5703 | Actual Loss: 1.8697\n",
      "Baseline Loss: 3.4628 | Actual Loss: 0.9457\n",
      "Baseline Loss: 3.3302 | Actual Loss: 0.8410\n",
      "Baseline Loss: 3.5085 | Actual Loss: 0.9605\n",
      "Baseline Loss: 3.3887 | Actual Loss: 1.2691\n",
      "Baseline Loss: 3.5237 | Actual Loss: 0.9541\n",
      "Baseline Loss: 3.9317 | Actual Loss: 1.1043\n",
      "Baseline Loss: 3.3759 | Actual Loss: 0.5571\n",
      "Baseline Loss: 3.6289 | Actual Loss: 1.3681\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.4588\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.8912\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.1169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 78/1000 [00:49<09:34,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.2186 | Actual Loss: 1.1181\n",
      "Epoch 78/1000: Train Loss: 1.2509, Val Loss: 1.1462\n",
      "Baseline Loss: 3.6359 | Actual Loss: 1.0060\n",
      "Baseline Loss: 3.6008 | Actual Loss: 1.2081\n",
      "Baseline Loss: 3.7323 | Actual Loss: 1.1464\n",
      "Baseline Loss: 3.3509 | Actual Loss: 0.5977\n",
      "Baseline Loss: 3.5835 | Actual Loss: 1.2641\n",
      "Baseline Loss: 3.6971 | Actual Loss: 1.0742\n",
      "Baseline Loss: 3.4815 | Actual Loss: 1.0521\n",
      "Baseline Loss: 3.7785 | Actual Loss: 0.9514\n",
      "Baseline Loss: 3.6743 | Actual Loss: 0.9044\n",
      "Baseline Loss: 3.4113 | Actual Loss: 1.0108\n",
      "Baseline Loss: 3.3275 | Actual Loss: 0.8462\n",
      "Baseline Loss: 3.2564 | Actual Loss: 0.5018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 79/1000 [00:49<09:35,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6550 | Actual Loss: 0.5680\n",
      "Baseline Loss: 3.5088 | Actual Loss: 0.6874\n",
      "Baseline Loss: 3.3546 | Actual Loss: 0.7938\n",
      "Baseline Loss: 3.5298 | Actual Loss: 3.1582\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.7455\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.9891\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.6755\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.5163\n",
      "Epoch 79/1000: Train Loss: 1.0482, Val Loss: 1.4816\n",
      "Baseline Loss: 3.6496 | Actual Loss: 0.4698\n",
      "Baseline Loss: 3.2540 | Actual Loss: 2.0998\n",
      "Baseline Loss: 3.4665 | Actual Loss: 0.8791\n",
      "Baseline Loss: 3.4288 | Actual Loss: 0.5136\n",
      "Baseline Loss: 3.5834 | Actual Loss: 0.9813\n",
      "Baseline Loss: 3.6319 | Actual Loss: 0.9808\n",
      "Baseline Loss: 3.4578 | Actual Loss: 0.4999\n",
      "Baseline Loss: 3.4963 | Actual Loss: 1.1241\n",
      "Baseline Loss: 3.4739 | Actual Loss: 1.0453\n",
      "Baseline Loss: 3.5284 | Actual Loss: 1.4157\n",
      "Baseline Loss: 3.5039 | Actual Loss: 1.0888\n",
      "Baseline Loss: 3.5006 | Actual Loss: 0.8839\n",
      "Baseline Loss: 3.5167 | Actual Loss: 1.2610\n",
      "Baseline Loss: 3.7321 | Actual Loss: 0.9533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 80/1000 [00:50<09:28,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4814 | Actual Loss: 0.9968\n",
      "Baseline Loss: 4.0418 | Actual Loss: 5.5446\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.0934\n",
      "Baseline Loss: 3.3852 | Actual Loss: 1.0759\n",
      "Baseline Loss: 3.6360 | Actual Loss: 0.9002\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.2938\n",
      "Epoch 80/1000: Train Loss: 1.2961, Val Loss: 1.0908\n",
      "Baseline Loss: 3.3040 | Actual Loss: 0.8146\n",
      "Baseline Loss: 3.5210 | Actual Loss: 1.2378\n",
      "Baseline Loss: 3.4966 | Actual Loss: 1.8483\n",
      "Baseline Loss: 3.7369 | Actual Loss: 1.4282\n",
      "Baseline Loss: 3.5083 | Actual Loss: 0.9219\n",
      "Baseline Loss: 3.5009 | Actual Loss: 1.3354\n",
      "Baseline Loss: 3.4236 | Actual Loss: 1.0069\n",
      "Baseline Loss: 3.5398 | Actual Loss: 1.0025\n",
      "Baseline Loss: 3.3541 | Actual Loss: 1.5655\n",
      "Baseline Loss: 3.5709 | Actual Loss: 0.6596\n",
      "Baseline Loss: 3.6229 | Actual Loss: 0.8715\n",
      "Baseline Loss: 3.3508 | Actual Loss: 2.0705\n",
      "Baseline Loss: 3.7832 | Actual Loss: 3.9627\n",
      "Baseline Loss: 3.5960 | Actual Loss: 1.2559\n",
      "Baseline Loss: 3.6683 | Actual Loss: 0.5214\n",
      "Baseline Loss: 3.2744 | Actual Loss: 2.4971\n",
      "Baseline Loss: 3.6276 | Actual Loss: 3.1572\n",
      "Baseline Loss: 3.3852 | Actual Loss: 1.3704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 81/1000 [00:51<09:31,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6360 | Actual Loss: 2.8349\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.5720\n",
      "Epoch 81/1000: Train Loss: 1.4375, Val Loss: 2.2336\n",
      "Baseline Loss: 3.4889 | Actual Loss: 1.8762\n",
      "Baseline Loss: 3.5530 | Actual Loss: 0.8722\n",
      "Baseline Loss: 3.3999 | Actual Loss: 0.9359\n",
      "Baseline Loss: 3.5465 | Actual Loss: 1.0122\n",
      "Baseline Loss: 3.4218 | Actual Loss: 0.7094\n",
      "Baseline Loss: 3.4500 | Actual Loss: 1.2717\n",
      "Baseline Loss: 3.7993 | Actual Loss: 1.3065\n",
      "Baseline Loss: 3.4323 | Actual Loss: 0.9306\n",
      "Baseline Loss: 3.4739 | Actual Loss: 1.0201\n",
      "Baseline Loss: 3.8436 | Actual Loss: 1.2013\n",
      "Baseline Loss: 3.7470 | Actual Loss: 0.6057\n",
      "Baseline Loss: 3.6274 | Actual Loss: 0.7634\n",
      "Baseline Loss: 3.9315 | Actual Loss: 0.6615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 82/1000 [00:51<09:13,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6004 | Actual Loss: 1.3239\n",
      "Baseline Loss: 3.4627 | Actual Loss: 1.4517\n",
      "Baseline Loss: 3.2810 | Actual Loss: 1.4355\n",
      "Baseline Loss: 3.6276 | Actual Loss: 2.7860\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.9336\n",
      "Baseline Loss: 3.6360 | Actual Loss: 2.6005\n",
      "Baseline Loss: 3.2186 | Actual Loss: 2.0612\n",
      "Epoch 82/1000: Train Loss: 1.0861, Val Loss: 2.0953\n",
      "Baseline Loss: 3.9251 | Actual Loss: 5.0038\n",
      "Baseline Loss: 3.6547 | Actual Loss: 0.9437\n",
      "Baseline Loss: 3.5746 | Actual Loss: 1.5073\n",
      "Baseline Loss: 3.5049 | Actual Loss: 0.9158\n",
      "Baseline Loss: 3.5161 | Actual Loss: 0.4288\n",
      "Baseline Loss: 3.4877 | Actual Loss: 0.2896\n",
      "Baseline Loss: 3.6013 | Actual Loss: 0.7884\n",
      "Baseline Loss: 3.2695 | Actual Loss: 0.9577\n",
      "Baseline Loss: 3.5495 | Actual Loss: 0.6690\n",
      "Baseline Loss: 3.4587 | Actual Loss: 0.9756\n",
      "Baseline Loss: 3.7421 | Actual Loss: 1.1332\n",
      "Baseline Loss: 3.5213 | Actual Loss: 1.6873\n",
      "Baseline Loss: 3.3544 | Actual Loss: 1.9082\n",
      "Baseline Loss: 3.3333 | Actual Loss: 1.2899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 83/1000 [00:52<09:30,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6054 | Actual Loss: 0.7462\n",
      "Baseline Loss: 3.4689 | Actual Loss: 1.1071\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.7293\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.7973\n",
      "Baseline Loss: 3.6360 | Actual Loss: 2.2055\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.5243\n",
      "Epoch 83/1000: Train Loss: 1.2720, Val Loss: 1.5641\n",
      "Baseline Loss: 3.5967 | Actual Loss: 3.0789\n",
      "Baseline Loss: 3.4352 | Actual Loss: 0.5104\n",
      "Baseline Loss: 3.5875 | Actual Loss: 2.7703\n",
      "Baseline Loss: 3.6698 | Actual Loss: 0.8157\n",
      "Baseline Loss: 3.6453 | Actual Loss: 0.7263\n",
      "Baseline Loss: 3.7679 | Actual Loss: 2.2178\n",
      "Baseline Loss: 3.4585 | Actual Loss: 0.9871\n",
      "Baseline Loss: 3.5119 | Actual Loss: 0.9699\n",
      "Baseline Loss: 3.1724 | Actual Loss: 1.1295\n",
      "Baseline Loss: 3.4975 | Actual Loss: 1.0568\n",
      "Baseline Loss: 3.6142 | Actual Loss: 0.6260\n",
      "Baseline Loss: 3.4661 | Actual Loss: 1.1307\n",
      "Baseline Loss: 3.3644 | Actual Loss: 0.8129\n",
      "Baseline Loss: 3.6194 | Actual Loss: 1.2553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 84/1000 [00:53<09:46,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6686 | Actual Loss: 1.4387\n",
      "Baseline Loss: 3.3574 | Actual Loss: 0.4126\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.6486\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.9606\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.3525\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.5585\n",
      "Epoch 84/1000: Train Loss: 1.2462, Val Loss: 1.3801\n",
      "Baseline Loss: 3.5415 | Actual Loss: 0.8725\n",
      "Baseline Loss: 3.6320 | Actual Loss: 0.9023\n",
      "Baseline Loss: 3.6236 | Actual Loss: 1.2134\n",
      "Baseline Loss: 3.4397 | Actual Loss: 0.8271\n",
      "Baseline Loss: 3.8426 | Actual Loss: 0.6427\n",
      "Baseline Loss: 3.3408 | Actual Loss: 0.6895\n",
      "Baseline Loss: 3.4504 | Actual Loss: 1.3130\n",
      "Baseline Loss: 3.4971 | Actual Loss: 0.9995\n",
      "Baseline Loss: 3.6780 | Actual Loss: 0.4389\n",
      "Baseline Loss: 3.3848 | Actual Loss: 1.0448\n",
      "Baseline Loss: 3.3889 | Actual Loss: 0.8159\n",
      "Baseline Loss: 3.7427 | Actual Loss: 1.5276\n",
      "Baseline Loss: 3.4657 | Actual Loss: 1.1250\n",
      "Baseline Loss: 3.4965 | Actual Loss: 0.8673\n",
      "Baseline Loss: 3.4971 | Actual Loss: 0.9793\n",
      "Baseline Loss: 3.6645 | Actual Loss: 0.3618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 85/1000 [00:53<09:20,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6276 | Actual Loss: 2.4648\n",
      "Baseline Loss: 3.3852 | Actual Loss: 2.0817\n",
      "Baseline Loss: 3.6360 | Actual Loss: 2.0256\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.4678\n",
      "Epoch 85/1000: Train Loss: 0.9138, Val Loss: 2.0100\n",
      "Baseline Loss: 3.4857 | Actual Loss: 0.7179\n",
      "Baseline Loss: 3.4699 | Actual Loss: 1.0456\n",
      "Baseline Loss: 3.7070 | Actual Loss: 0.4580\n",
      "Baseline Loss: 3.4809 | Actual Loss: 0.9827\n",
      "Baseline Loss: 3.4079 | Actual Loss: 1.6626\n",
      "Baseline Loss: 3.5375 | Actual Loss: 0.6432\n",
      "Baseline Loss: 3.6226 | Actual Loss: 0.5806\n",
      "Baseline Loss: 3.4738 | Actual Loss: 0.5564\n",
      "Baseline Loss: 3.7220 | Actual Loss: 1.0070\n",
      "Baseline Loss: 3.5577 | Actual Loss: 0.5772\n",
      "Baseline Loss: 3.5624 | Actual Loss: 0.8801\n",
      "Baseline Loss: 3.4284 | Actual Loss: 0.6604\n",
      "Baseline Loss: 3.5747 | Actual Loss: 2.8885\n",
      "Baseline Loss: 3.5334 | Actual Loss: 0.8325\n",
      "Baseline Loss: 3.2915 | Actual Loss: 1.5128\n",
      "Baseline Loss: 3.2491 | Actual Loss: 3.3451\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.6627\n",
      "Baseline Loss: 3.3852 | Actual Loss: 1.1946\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.8859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▊         | 86/1000 [00:54<09:20,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.2186 | Actual Loss: 1.8588\n",
      "Epoch 86/1000: Train Loss: 1.1469, Val Loss: 1.6505\n",
      "Baseline Loss: 3.4396 | Actual Loss: 0.7708\n",
      "Baseline Loss: 3.3415 | Actual Loss: 1.2080\n",
      "Baseline Loss: 3.5126 | Actual Loss: 1.1893\n",
      "Baseline Loss: 3.5663 | Actual Loss: 1.6878\n",
      "Baseline Loss: 3.5174 | Actual Loss: 0.4010\n",
      "Baseline Loss: 3.6044 | Actual Loss: 1.0765\n",
      "Baseline Loss: 3.4859 | Actual Loss: 0.6063\n",
      "Baseline Loss: 3.5667 | Actual Loss: 1.0851\n",
      "Baseline Loss: 3.5174 | Actual Loss: 0.6566\n",
      "Baseline Loss: 3.7624 | Actual Loss: 1.8378\n",
      "Baseline Loss: 3.4197 | Actual Loss: 1.0323\n",
      "Baseline Loss: 3.6051 | Actual Loss: 1.0651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▊         | 87/1000 [00:54<09:16,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6051 | Actual Loss: 0.5772\n",
      "Baseline Loss: 3.4432 | Actual Loss: 0.7796\n",
      "Baseline Loss: 3.4919 | Actual Loss: 1.7623\n",
      "Baseline Loss: 3.6524 | Actual Loss: 0.4103\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.3836\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.8046\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.2616\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.5204\n",
      "Epoch 87/1000: Train Loss: 1.0091, Val Loss: 1.2425\n",
      "Baseline Loss: 3.6091 | Actual Loss: 0.5281\n",
      "Baseline Loss: 3.5616 | Actual Loss: 0.7621\n",
      "Baseline Loss: 3.4879 | Actual Loss: 1.4593\n",
      "Baseline Loss: 3.6354 | Actual Loss: 1.0219\n",
      "Baseline Loss: 3.5838 | Actual Loss: 1.0188\n",
      "Baseline Loss: 3.5372 | Actual Loss: 1.0049\n",
      "Baseline Loss: 3.5792 | Actual Loss: 0.7301\n",
      "Baseline Loss: 3.6184 | Actual Loss: 2.5813\n",
      "Baseline Loss: 3.6138 | Actual Loss: 1.3896\n",
      "Baseline Loss: 3.4441 | Actual Loss: 0.5140\n",
      "Baseline Loss: 3.6460 | Actual Loss: 1.5579\n",
      "Baseline Loss: 3.4699 | Actual Loss: 0.8364\n",
      "Baseline Loss: 3.4741 | Actual Loss: 0.8483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 88/1000 [00:55<09:21,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4318 | Actual Loss: 1.1107\n",
      "Baseline Loss: 3.4815 | Actual Loss: 1.0111\n",
      "Baseline Loss: 3.1186 | Actual Loss: 1.1259\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.2204\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.9751\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.6022\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.4082\n",
      "Epoch 88/1000: Train Loss: 1.0938, Val Loss: 1.3015\n",
      "Baseline Loss: 3.7479 | Actual Loss: 3.7150\n",
      "Baseline Loss: 3.3955 | Actual Loss: 0.6647\n",
      "Baseline Loss: 3.4895 | Actual Loss: 0.7546\n",
      "Baseline Loss: 3.7326 | Actual Loss: 1.2665\n",
      "Baseline Loss: 3.5660 | Actual Loss: 1.0263\n",
      "Baseline Loss: 3.3378 | Actual Loss: 0.8507\n",
      "Baseline Loss: 3.5622 | Actual Loss: 0.7325\n",
      "Baseline Loss: 3.3862 | Actual Loss: 1.1663\n",
      "Baseline Loss: 3.6224 | Actual Loss: 0.8194\n",
      "Baseline Loss: 3.4358 | Actual Loss: 1.1072\n",
      "Baseline Loss: 3.4742 | Actual Loss: 0.4427\n",
      "Baseline Loss: 3.7833 | Actual Loss: 4.7856\n",
      "Baseline Loss: 3.2978 | Actual Loss: 1.2422\n",
      "Baseline Loss: 3.6731 | Actual Loss: 1.0987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 89/1000 [00:56<09:35,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5920 | Actual Loss: 3.4428\n",
      "Baseline Loss: 3.2412 | Actual Loss: 4.6578\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.7801\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.9408\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.7994\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.4350\n",
      "Epoch 89/1000: Train Loss: 1.7358, Val Loss: 1.4888\n",
      "Baseline Loss: 3.5583 | Actual Loss: 1.2661\n",
      "Baseline Loss: 3.4699 | Actual Loss: 2.0734\n",
      "Baseline Loss: 3.4772 | Actual Loss: 1.0397\n",
      "Baseline Loss: 3.4246 | Actual Loss: 2.4245\n",
      "Baseline Loss: 3.5783 | Actual Loss: 0.7075\n",
      "Baseline Loss: 3.5209 | Actual Loss: 0.9043\n",
      "Baseline Loss: 3.6040 | Actual Loss: 0.7563\n",
      "Baseline Loss: 3.6234 | Actual Loss: 1.0368\n",
      "Baseline Loss: 3.6551 | Actual Loss: 0.9454\n",
      "Baseline Loss: 3.5049 | Actual Loss: 0.6112\n",
      "Baseline Loss: 3.6585 | Actual Loss: 0.2253\n",
      "Baseline Loss: 3.5533 | Actual Loss: 0.6410\n",
      "Baseline Loss: 3.5707 | Actual Loss: 1.4881\n",
      "Baseline Loss: 3.3046 | Actual Loss: 0.8149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 90/1000 [00:56<09:21,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5170 | Actual Loss: 0.8862\n",
      "Baseline Loss: 3.0976 | Actual Loss: 0.5559\n",
      "Baseline Loss: 3.6276 | Actual Loss: 2.9118\n",
      "Baseline Loss: 3.3852 | Actual Loss: 1.1236\n",
      "Baseline Loss: 3.6360 | Actual Loss: 2.5564\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.9139\n",
      "Epoch 90/1000: Train Loss: 1.0235, Val Loss: 2.1264\n",
      "Baseline Loss: 3.3197 | Actual Loss: 0.8786\n",
      "Baseline Loss: 3.9135 | Actual Loss: 4.0047\n",
      "Baseline Loss: 3.5493 | Actual Loss: 1.0074\n",
      "Baseline Loss: 3.5087 | Actual Loss: 0.5182\n",
      "Baseline Loss: 3.4539 | Actual Loss: 0.8392\n",
      "Baseline Loss: 3.3510 | Actual Loss: 1.8351\n",
      "Baseline Loss: 3.3849 | Actual Loss: 0.3131\n",
      "Baseline Loss: 3.6097 | Actual Loss: 2.3160\n",
      "Baseline Loss: 3.4135 | Actual Loss: 3.0554\n",
      "Baseline Loss: 3.5117 | Actual Loss: 1.0691\n",
      "Baseline Loss: 3.6223 | Actual Loss: 0.3414\n",
      "Baseline Loss: 3.6501 | Actual Loss: 0.5594\n",
      "Baseline Loss: 3.7780 | Actual Loss: 0.7464\n",
      "Baseline Loss: 3.6223 | Actual Loss: 0.4926\n",
      "Baseline Loss: 3.5623 | Actual Loss: 1.1235\n",
      "Baseline Loss: 3.3052 | Actual Loss: 0.5515\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.0015\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.7835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 91/1000 [00:57<09:22,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6360 | Actual Loss: 2.0046\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.3446\n",
      "Epoch 91/1000: Train Loss: 1.2282, Val Loss: 1.2835\n",
      "Baseline Loss: 3.5379 | Actual Loss: 1.1584\n",
      "Baseline Loss: 3.4614 | Actual Loss: 0.5580\n",
      "Baseline Loss: 3.5487 | Actual Loss: 1.4760\n",
      "Baseline Loss: 3.5140 | Actual Loss: 1.0790\n",
      "Baseline Loss: 4.0421 | Actual Loss: 0.9355\n",
      "Baseline Loss: 3.4887 | Actual Loss: 0.5954\n",
      "Baseline Loss: 3.4287 | Actual Loss: 0.3901\n",
      "Baseline Loss: 3.3899 | Actual Loss: 0.7219\n",
      "Baseline Loss: 3.6017 | Actual Loss: 2.5605\n",
      "Baseline Loss: 3.7722 | Actual Loss: 1.4202\n",
      "Baseline Loss: 3.6551 | Actual Loss: 0.5242\n",
      "Baseline Loss: 3.4397 | Actual Loss: 1.1083\n",
      "Baseline Loss: 3.5383 | Actual Loss: 1.0599\n",
      "Baseline Loss: 3.4210 | Actual Loss: 0.8474\n",
      "Baseline Loss: 3.3785 | Actual Loss: 1.7779\n",
      "Baseline Loss: 3.3580 | Actual Loss: 1.8726\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.3900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 92/1000 [00:57<09:42,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3852 | Actual Loss: 0.6153\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.5726\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.6334\n",
      "Epoch 92/1000: Train Loss: 1.1303, Val Loss: 1.3028\n",
      "Baseline Loss: 3.4774 | Actual Loss: 0.7372\n",
      "Baseline Loss: 3.3919 | Actual Loss: 2.4801\n",
      "Baseline Loss: 3.6975 | Actual Loss: 0.6163\n",
      "Baseline Loss: 3.4817 | Actual Loss: 0.8793\n",
      "Baseline Loss: 3.4885 | Actual Loss: 1.2550\n",
      "Baseline Loss: 3.5131 | Actual Loss: 0.2833\n",
      "Baseline Loss: 3.4142 | Actual Loss: 1.7500\n",
      "Baseline Loss: 3.6450 | Actual Loss: 0.5317\n",
      "Baseline Loss: 3.7521 | Actual Loss: 0.6110\n",
      "Baseline Loss: 3.5087 | Actual Loss: 1.0006\n",
      "Baseline Loss: 3.4321 | Actual Loss: 1.2221\n",
      "Baseline Loss: 3.3107 | Actual Loss: 1.1542\n",
      "Baseline Loss: 3.4688 | Actual Loss: 0.6511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 93/1000 [00:58<09:18,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5171 | Actual Loss: 1.0353\n",
      "Baseline Loss: 3.7995 | Actual Loss: 0.6649\n",
      "Baseline Loss: 3.3409 | Actual Loss: 2.4153\n",
      "Baseline Loss: 3.6276 | Actual Loss: 0.8054\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.5702\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.6103\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.3901\n",
      "Epoch 93/1000: Train Loss: 1.0805, Val Loss: 1.0940\n",
      "Baseline Loss: 3.4900 | Actual Loss: 0.6435\n",
      "Baseline Loss: 3.4976 | Actual Loss: 1.2738\n",
      "Baseline Loss: 3.5173 | Actual Loss: 3.4690\n",
      "Baseline Loss: 3.3816 | Actual Loss: 2.6716\n",
      "Baseline Loss: 3.4090 | Actual Loss: 1.0113\n",
      "Baseline Loss: 3.5884 | Actual Loss: 1.1392\n",
      "Baseline Loss: 3.4512 | Actual Loss: 0.6284\n",
      "Baseline Loss: 3.5842 | Actual Loss: 1.1960\n",
      "Baseline Loss: 3.7073 | Actual Loss: 1.3441\n",
      "Baseline Loss: 3.5703 | Actual Loss: 1.0462\n",
      "Baseline Loss: 3.4699 | Actual Loss: 1.0694\n",
      "Baseline Loss: 3.5011 | Actual Loss: 1.2974\n",
      "Baseline Loss: 3.6143 | Actual Loss: 0.5956\n",
      "Baseline Loss: 3.5841 | Actual Loss: 0.9774\n",
      "Baseline Loss: 3.5965 | Actual Loss: 0.8480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 94/1000 [00:59<09:24,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.1517 | Actual Loss: 0.4031\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.9772\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.5997\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.5219\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.4053\n",
      "Epoch 94/1000: Train Loss: 1.2259, Val Loss: 1.3760\n",
      "Baseline Loss: 3.3747 | Actual Loss: 0.7927\n",
      "Baseline Loss: 3.4648 | Actual Loss: 0.5373\n",
      "Baseline Loss: 3.5293 | Actual Loss: 0.9965\n",
      "Baseline Loss: 3.5920 | Actual Loss: 0.8031\n",
      "Baseline Loss: 3.6686 | Actual Loss: 1.7639\n",
      "Baseline Loss: 3.5166 | Actual Loss: 1.7160\n",
      "Baseline Loss: 3.6146 | Actual Loss: 1.0387\n",
      "Baseline Loss: 3.4843 | Actual Loss: 1.2526\n",
      "Baseline Loss: 3.6266 | Actual Loss: 0.7499\n",
      "Baseline Loss: 3.3434 | Actual Loss: 3.1616\n",
      "Baseline Loss: 3.4581 | Actual Loss: 0.2823\n",
      "Baseline Loss: 3.2678 | Actual Loss: 0.3575\n",
      "Baseline Loss: 3.5578 | Actual Loss: 1.4006\n",
      "Baseline Loss: 3.7729 | Actual Loss: 0.9208\n",
      "Baseline Loss: 3.5209 | Actual Loss: 0.7623\n",
      "Baseline Loss: 3.3310 | Actual Loss: 2.2634\n",
      "Baseline Loss: 3.6276 | Actual Loss: 2.0871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 95/1000 [00:59<09:39,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3852 | Actual Loss: 0.5508\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.1871\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.4301\n",
      "Epoch 95/1000: Train Loss: 1.1750, Val Loss: 1.3137\n",
      "Baseline Loss: 3.6185 | Actual Loss: 1.0569\n",
      "Baseline Loss: 3.4461 | Actual Loss: 0.9464\n",
      "Baseline Loss: 3.3140 | Actual Loss: 0.6226\n",
      "Baseline Loss: 3.2416 | Actual Loss: 0.6992\n",
      "Baseline Loss: 3.3926 | Actual Loss: 0.4364\n",
      "Baseline Loss: 3.5792 | Actual Loss: 0.5080\n",
      "Baseline Loss: 3.5540 | Actual Loss: 0.7915\n",
      "Baseline Loss: 3.6510 | Actual Loss: 1.0592\n",
      "Baseline Loss: 3.7572 | Actual Loss: 0.5554\n",
      "Baseline Loss: 3.4611 | Actual Loss: 0.6092\n",
      "Baseline Loss: 3.6546 | Actual Loss: 2.8007\n",
      "Baseline Loss: 3.5331 | Actual Loss: 0.8930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 96/1000 [01:00<09:16,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6547 | Actual Loss: 1.4289\n",
      "Baseline Loss: 3.5092 | Actual Loss: 1.4764\n",
      "Baseline Loss: 3.5411 | Actual Loss: 0.8459\n",
      "Baseline Loss: 3.7018 | Actual Loss: 0.8053\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.8358\n",
      "Baseline Loss: 3.3852 | Actual Loss: 1.0799\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.1640\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.3322\n",
      "Epoch 96/1000: Train Loss: 0.9709, Val Loss: 1.3530\n",
      "Baseline Loss: 3.5248 | Actual Loss: 0.8374\n",
      "Baseline Loss: 3.4710 | Actual Loss: 0.7153\n",
      "Baseline Loss: 3.6643 | Actual Loss: 0.8015\n",
      "Baseline Loss: 3.3540 | Actual Loss: 1.0074\n",
      "Baseline Loss: 3.5250 | Actual Loss: 0.9053\n",
      "Baseline Loss: 3.4247 | Actual Loss: 4.0940\n",
      "Baseline Loss: 3.7996 | Actual Loss: 0.7170\n",
      "Baseline Loss: 3.3887 | Actual Loss: 1.0105\n",
      "Baseline Loss: 3.4999 | Actual Loss: 0.9092\n",
      "Baseline Loss: 3.7120 | Actual Loss: 3.2444\n",
      "Baseline Loss: 3.5747 | Actual Loss: 1.2285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 97/1000 [01:01<09:26,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5662 | Actual Loss: 1.0650\n",
      "Baseline Loss: 3.6922 | Actual Loss: 0.4022\n",
      "Baseline Loss: 3.6929 | Actual Loss: 1.1287\n",
      "Baseline Loss: 3.5049 | Actual Loss: 0.7141\n",
      "Baseline Loss: 3.1818 | Actual Loss: 0.2796\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.7810\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.8136\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.3604\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.4546\n",
      "Epoch 97/1000: Train Loss: 1.1912, Val Loss: 1.3524\n",
      "Baseline Loss: 3.4036 | Actual Loss: 0.8205\n",
      "Baseline Loss: 3.6511 | Actual Loss: 1.4056\n",
      "Baseline Loss: 3.5168 | Actual Loss: 0.8393\n",
      "Baseline Loss: 3.5009 | Actual Loss: 0.6399\n",
      "Baseline Loss: 3.4135 | Actual Loss: 1.1785\n",
      "Baseline Loss: 3.6363 | Actual Loss: 1.8565\n",
      "Baseline Loss: 3.4587 | Actual Loss: 1.0982\n",
      "Baseline Loss: 3.5450 | Actual Loss: 0.9445\n",
      "Baseline Loss: 3.5619 | Actual Loss: 1.2257\n",
      "Baseline Loss: 3.4628 | Actual Loss: 1.2270\n",
      "Baseline Loss: 3.6365 | Actual Loss: 1.0241\n",
      "Baseline Loss: 3.6459 | Actual Loss: 1.1987\n",
      "Baseline Loss: 3.5167 | Actual Loss: 0.8525\n",
      "Baseline Loss: 3.4659 | Actual Loss: 0.6048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 98/1000 [01:01<09:12,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.7832 | Actual Loss: 0.4801\n",
      "Baseline Loss: 3.3313 | Actual Loss: 0.8316\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.2203\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.5613\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.3572\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.4687\n",
      "Epoch 98/1000: Train Loss: 1.0142, Val Loss: 1.1519\n",
      "Baseline Loss: 3.5135 | Actual Loss: 1.0148\n",
      "Baseline Loss: 3.4853 | Actual Loss: 0.8173\n",
      "Baseline Loss: 3.6010 | Actual Loss: 0.8466\n",
      "Baseline Loss: 3.8661 | Actual Loss: 3.5134\n",
      "Baseline Loss: 3.7366 | Actual Loss: 0.7388\n",
      "Baseline Loss: 3.6639 | Actual Loss: 0.8298\n",
      "Baseline Loss: 3.6310 | Actual Loss: 0.9884\n",
      "Baseline Loss: 3.4841 | Actual Loss: 0.4451\n",
      "Baseline Loss: 3.3469 | Actual Loss: 1.2024\n",
      "Baseline Loss: 3.5786 | Actual Loss: 0.8984\n",
      "Baseline Loss: 3.5045 | Actual Loss: 1.2183\n",
      "Baseline Loss: 3.5749 | Actual Loss: 0.9109\n",
      "Baseline Loss: 3.5452 | Actual Loss: 0.7998\n",
      "Baseline Loss: 3.6272 | Actual Loss: 1.0587\n",
      "Baseline Loss: 3.3965 | Actual Loss: 0.7244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|▉         | 99/1000 [01:02<09:16,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 2.8999 | Actual Loss: 1.3153\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.7357\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.6418\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.5314\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.6385\n",
      "Epoch 99/1000: Train Loss: 1.0827, Val Loss: 1.3868\n",
      "Baseline Loss: 3.4656 | Actual Loss: 2.0707\n",
      "Baseline Loss: 3.4091 | Actual Loss: 0.8124\n",
      "Baseline Loss: 3.5409 | Actual Loss: 0.4636\n",
      "Baseline Loss: 3.6234 | Actual Loss: 0.3555\n",
      "Baseline Loss: 3.6645 | Actual Loss: 1.9160\n",
      "Baseline Loss: 3.5790 | Actual Loss: 1.0197\n",
      "Baseline Loss: 3.6877 | Actual Loss: 0.6368\n",
      "Baseline Loss: 3.4319 | Actual Loss: 1.1437\n",
      "Baseline Loss: 3.5695 | Actual Loss: 2.3722\n",
      "Baseline Loss: 3.6223 | Actual Loss: 0.8697\n",
      "Baseline Loss: 3.5048 | Actual Loss: 1.1223\n",
      "Baseline Loss: 3.5751 | Actual Loss: 1.5761\n",
      "Baseline Loss: 3.4429 | Actual Loss: 1.9986\n",
      "Baseline Loss: 3.5093 | Actual Loss: 0.8229\n",
      "Baseline Loss: 3.5499 | Actual Loss: 0.9732\n",
      "Baseline Loss: 3.2026 | Actual Loss: 3.2746\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.7771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 100/1000 [01:02<09:32,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3852 | Actual Loss: 1.0087\n",
      "Baseline Loss: 3.6360 | Actual Loss: 2.6781\n",
      "Baseline Loss: 3.2186 | Actual Loss: 2.1569\n",
      "Epoch 100/1000: Train Loss: 1.3392, Val Loss: 1.9052\n",
      "Baseline Loss: 3.3649 | Actual Loss: 1.7028\n",
      "Baseline Loss: 3.4174 | Actual Loss: 1.0167\n",
      "Baseline Loss: 3.5883 | Actual Loss: 0.4747\n",
      "Baseline Loss: 3.5756 | Actual Loss: 3.2007\n",
      "Baseline Loss: 3.4354 | Actual Loss: 1.2530\n",
      "Baseline Loss: 3.6503 | Actual Loss: 3.6281\n",
      "Baseline Loss: 3.4233 | Actual Loss: 1.0904\n",
      "Baseline Loss: 3.3785 | Actual Loss: 1.3096\n",
      "Baseline Loss: 3.5862 | Actual Loss: 1.4160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 101/1000 [01:03<08:15,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6645 | Actual Loss: 0.4040\n",
      "Baseline Loss: 3.6786 | Actual Loss: 0.6310\n",
      "Baseline Loss: 3.6455 | Actual Loss: 2.1506\n",
      "Baseline Loss: 3.3845 | Actual Loss: 0.7709\n",
      "Baseline Loss: 3.6230 | Actual Loss: 0.7068\n",
      "Baseline Loss: 3.6828 | Actual Loss: 1.2604\n",
      "Baseline Loss: 3.0591 | Actual Loss: 0.5757\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.0432\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.7477\n",
      "Baseline Loss: 3.6360 | Actual Loss: 2.2405\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.3365\n",
      "Epoch 101/1000: Train Loss: 1.3495, Val Loss: 1.3420\n",
      "Baseline Loss: 3.5706 | Actual Loss: 0.9791\n",
      "Baseline Loss: 3.5618 | Actual Loss: 0.9060\n",
      "Baseline Loss: 3.3482 | Actual Loss: 0.7071\n",
      "Baseline Loss: 3.5493 | Actual Loss: 0.4236\n",
      "Baseline Loss: 3.4173 | Actual Loss: 0.9226\n",
      "Baseline Loss: 3.6831 | Actual Loss: 0.5776\n",
      "Baseline Loss: 3.3681 | Actual Loss: 0.8076\n",
      "Baseline Loss: 3.4214 | Actual Loss: 0.8066\n",
      "Baseline Loss: 3.6138 | Actual Loss: 0.6670\n",
      "Baseline Loss: 3.3597 | Actual Loss: 1.1107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 102/1000 [01:03<07:40,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4357 | Actual Loss: 1.0288\n",
      "Baseline Loss: 3.7231 | Actual Loss: 0.8220\n",
      "Baseline Loss: 3.9140 | Actual Loss: 1.5175\n",
      "Baseline Loss: 3.5403 | Actual Loss: 0.9048\n",
      "Baseline Loss: 3.4736 | Actual Loss: 0.7839\n",
      "Baseline Loss: 3.8495 | Actual Loss: 0.9954\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.6934\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.5752\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.5066\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.3099\n",
      "Epoch 102/1000: Train Loss: 0.8725, Val Loss: 1.2713\n",
      "Baseline Loss: 3.3720 | Actual Loss: 0.9683\n",
      "Baseline Loss: 3.7070 | Actual Loss: 1.7101\n",
      "Baseline Loss: 3.2583 | Actual Loss: 0.5531\n",
      "Baseline Loss: 3.6325 | Actual Loss: 0.7278\n",
      "Baseline Loss: 3.4732 | Actual Loss: 0.8757\n",
      "Baseline Loss: 3.4070 | Actual Loss: 0.5475\n",
      "Baseline Loss: 3.4773 | Actual Loss: 0.6051\n",
      "Baseline Loss: 3.5170 | Actual Loss: 0.4571\n",
      "Baseline Loss: 3.4214 | Actual Loss: 1.0101\n",
      "Baseline Loss: 3.4584 | Actual Loss: 0.7068\n",
      "Baseline Loss: 3.6272 | Actual Loss: 1.2417\n",
      "Baseline Loss: 3.6406 | Actual Loss: 1.5089\n",
      "Baseline Loss: 3.5284 | Actual Loss: 0.9964\n",
      "Baseline Loss: 3.8602 | Actual Loss: 0.6638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 103/1000 [01:04<06:56,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4502 | Actual Loss: 1.1427\n",
      "Baseline Loss: 3.6539 | Actual Loss: 0.4008\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.1412\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.5140\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.6906\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.5424\n",
      "Epoch 103/1000: Train Loss: 0.8822, Val Loss: 1.2221\n",
      "Baseline Loss: 3.4888 | Actual Loss: 0.4510\n",
      "Baseline Loss: 3.4173 | Actual Loss: 0.3898\n",
      "Baseline Loss: 3.5495 | Actual Loss: 1.4042\n",
      "Baseline Loss: 3.5405 | Actual Loss: 0.9861\n",
      "Baseline Loss: 3.5711 | Actual Loss: 1.0386\n",
      "Baseline Loss: 3.5488 | Actual Loss: 0.5495\n",
      "Baseline Loss: 3.5375 | Actual Loss: 0.9986\n",
      "Baseline Loss: 3.5452 | Actual Loss: 2.5378\n",
      "Baseline Loss: 3.6818 | Actual Loss: 0.5613\n",
      "Baseline Loss: 3.6631 | Actual Loss: 1.0121\n",
      "Baseline Loss: 3.6645 | Actual Loss: 2.0512\n",
      "Baseline Loss: 3.5538 | Actual Loss: 0.7796\n",
      "Baseline Loss: 3.4357 | Actual Loss: 0.6324\n",
      "Baseline Loss: 3.4619 | Actual Loss: 0.7893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 104/1000 [01:04<06:45,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5836 | Actual Loss: 1.3315\n",
      "Baseline Loss: 3.1874 | Actual Loss: 0.6900\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.3928\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.5514\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.3072\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.4953\n",
      "Epoch 104/1000: Train Loss: 1.0127, Val Loss: 1.1867\n",
      "Baseline Loss: 3.4619 | Actual Loss: 0.8738\n",
      "Baseline Loss: 3.7634 | Actual Loss: 1.2505\n",
      "Baseline Loss: 3.6133 | Actual Loss: 0.4124\n",
      "Baseline Loss: 3.3616 | Actual Loss: 1.0030\n",
      "Baseline Loss: 3.4740 | Actual Loss: 1.1857\n",
      "Baseline Loss: 3.6877 | Actual Loss: 1.0980\n",
      "Baseline Loss: 3.4733 | Actual Loss: 1.2883\n",
      "Baseline Loss: 3.3644 | Actual Loss: 0.6369\n",
      "Baseline Loss: 3.7941 | Actual Loss: 1.4167\n",
      "Baseline Loss: 3.4896 | Actual Loss: 1.0217\n",
      "Baseline Loss: 3.3232 | Actual Loss: 2.2285\n",
      "Baseline Loss: 3.4977 | Actual Loss: 0.5673\n",
      "Baseline Loss: 3.6546 | Actual Loss: 0.8314\n",
      "Baseline Loss: 3.6004 | Actual Loss: 1.1622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 105/1000 [01:04<06:38,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5123 | Actual Loss: 0.2281\n",
      "Baseline Loss: 3.7139 | Actual Loss: 0.3723\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.9547\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.5853\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.4858\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.4561\n",
      "Epoch 105/1000: Train Loss: 0.9736, Val Loss: 1.3705\n",
      "Baseline Loss: 3.8212 | Actual Loss: 1.8393\n",
      "Baseline Loss: 3.7832 | Actual Loss: 3.4732\n",
      "Baseline Loss: 3.4425 | Actual Loss: 0.9232\n",
      "Baseline Loss: 3.4458 | Actual Loss: 1.7238\n",
      "Baseline Loss: 3.5168 | Actual Loss: 0.6413\n",
      "Baseline Loss: 3.4501 | Actual Loss: 0.5153\n",
      "Baseline Loss: 3.6637 | Actual Loss: 0.6809\n",
      "Baseline Loss: 3.3201 | Actual Loss: 0.5989\n",
      "Baseline Loss: 3.4253 | Actual Loss: 0.7367\n",
      "Baseline Loss: 3.5161 | Actual Loss: 0.4232\n",
      "Baseline Loss: 3.4470 | Actual Loss: 1.6564\n",
      "Baseline Loss: 3.6555 | Actual Loss: 1.2245\n",
      "Baseline Loss: 3.5918 | Actual Loss: 1.3122\n",
      "Baseline Loss: 3.4691 | Actual Loss: 1.1445\n",
      "Baseline Loss: 3.5212 | Actual Loss: 0.6184\n",
      "Baseline Loss: 3.3742 | Actual Loss: 0.3460\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.7282\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.6093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 106/1000 [01:05<06:32,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6360 | Actual Loss: 1.7183\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.9878\n",
      "Epoch 106/1000: Train Loss: 1.1161, Val Loss: 1.5109\n",
      "Baseline Loss: 3.3535 | Actual Loss: 0.7839\n",
      "Baseline Loss: 3.5317 | Actual Loss: 1.0534\n",
      "Baseline Loss: 3.5005 | Actual Loss: 1.1772\n",
      "Baseline Loss: 3.2421 | Actual Loss: 1.1045\n",
      "Baseline Loss: 3.7368 | Actual Loss: 0.6326\n",
      "Baseline Loss: 3.6686 | Actual Loss: 1.2094\n",
      "Baseline Loss: 3.6675 | Actual Loss: 0.8561\n",
      "Baseline Loss: 3.5701 | Actual Loss: 0.2581\n",
      "Baseline Loss: 3.4474 | Actual Loss: 2.7322\n",
      "Baseline Loss: 3.7369 | Actual Loss: 0.5126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 107/1000 [01:05<06:07,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5012 | Actual Loss: 0.6930\n",
      "Baseline Loss: 3.6097 | Actual Loss: 0.9525\n",
      "Baseline Loss: 3.6928 | Actual Loss: 0.6124\n",
      "Baseline Loss: 3.3504 | Actual Loss: 0.7436\n",
      "Baseline Loss: 3.6190 | Actual Loss: 2.2441\n",
      "Baseline Loss: 3.0664 | Actual Loss: 0.4627\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.7710\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.6142\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.4566\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.8815\n",
      "Epoch 107/1000: Train Loss: 1.0018, Val Loss: 1.4308\n",
      "Baseline Loss: 3.4323 | Actual Loss: 1.1845\n",
      "Baseline Loss: 3.5292 | Actual Loss: 0.9088\n",
      "Baseline Loss: 3.3075 | Actual Loss: 0.7220\n",
      "Baseline Loss: 3.5705 | Actual Loss: 3.4475\n",
      "Baseline Loss: 3.5544 | Actual Loss: 0.9572\n",
      "Baseline Loss: 3.3784 | Actual Loss: 3.0524\n",
      "Baseline Loss: 3.4929 | Actual Loss: 0.5900\n",
      "Baseline Loss: 3.6144 | Actual Loss: 0.9252\n",
      "Baseline Loss: 3.4695 | Actual Loss: 1.1924\n",
      "Baseline Loss: 3.7468 | Actual Loss: 1.1125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 108/1000 [01:06<06:10,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5287 | Actual Loss: 1.2577\n",
      "Baseline Loss: 3.4931 | Actual Loss: 0.6393\n",
      "Baseline Loss: 3.6137 | Actual Loss: 0.4345\n",
      "Baseline Loss: 3.7072 | Actual Loss: 1.0961\n",
      "Baseline Loss: 3.3709 | Actual Loss: 0.5080\n",
      "Baseline Loss: 3.2804 | Actual Loss: 0.3653\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.6998\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.9140\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.2238\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.4636\n",
      "Epoch 108/1000: Train Loss: 1.1496, Val Loss: 1.3253\n",
      "Baseline Loss: 3.4884 | Actual Loss: 0.6110\n",
      "Baseline Loss: 3.3718 | Actual Loss: 0.9150\n",
      "Baseline Loss: 3.7075 | Actual Loss: 0.5809\n",
      "Baseline Loss: 3.6590 | Actual Loss: 1.1661\n",
      "Baseline Loss: 3.5239 | Actual Loss: 0.6578\n",
      "Baseline Loss: 3.6964 | Actual Loss: 1.0131\n",
      "Baseline Loss: 3.6318 | Actual Loss: 0.7234\n",
      "Baseline Loss: 3.3753 | Actual Loss: 0.7136\n",
      "Baseline Loss: 3.6315 | Actual Loss: 2.5252\n",
      "Baseline Loss: 3.3509 | Actual Loss: 3.7851\n",
      "Baseline Loss: 3.4030 | Actual Loss: 1.4837\n",
      "Baseline Loss: 3.6271 | Actual Loss: 0.8999\n",
      "Baseline Loss: 3.5538 | Actual Loss: 1.4618\n",
      "Baseline Loss: 3.9011 | Actual Loss: 3.0914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 109/1000 [01:06<05:53,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5331 | Actual Loss: 0.4971\n",
      "Baseline Loss: 3.2115 | Actual Loss: 2.6660\n",
      "Baseline Loss: 3.6276 | Actual Loss: 2.0360\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.6588\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.5265\n",
      "Baseline Loss: 3.2186 | Actual Loss: 2.0327\n",
      "Epoch 109/1000: Train Loss: 1.4244, Val Loss: 1.5635\n",
      "Baseline Loss: 3.6009 | Actual Loss: 0.6219\n",
      "Baseline Loss: 3.7728 | Actual Loss: 1.0247\n",
      "Baseline Loss: 3.3243 | Actual Loss: 0.5393\n",
      "Baseline Loss: 3.3615 | Actual Loss: 0.5950\n",
      "Baseline Loss: 3.4972 | Actual Loss: 1.1813\n",
      "Baseline Loss: 3.4107 | Actual Loss: 0.4011\n",
      "Baseline Loss: 3.3016 | Actual Loss: 1.1625\n",
      "Baseline Loss: 3.6186 | Actual Loss: 1.0492\n",
      "Baseline Loss: 3.5094 | Actual Loss: 1.3018\n",
      "Baseline Loss: 3.6369 | Actual Loss: 0.5916\n",
      "Baseline Loss: 3.3610 | Actual Loss: 0.8431\n",
      "Baseline Loss: 3.7127 | Actual Loss: 1.1775\n",
      "Baseline Loss: 3.5923 | Actual Loss: 1.2384\n",
      "Baseline Loss: 3.3371 | Actual Loss: 2.9890\n",
      "Baseline Loss: 3.6267 | Actual Loss: 0.9791\n",
      "Baseline Loss: 3.4015 | Actual Loss: 0.5585\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.6364\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.6094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 110/1000 [01:06<05:59,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6360 | Actual Loss: 1.9986\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.7657\n",
      "Epoch 110/1000: Train Loss: 1.0159, Val Loss: 1.5025\n",
      "Baseline Loss: 3.6975 | Actual Loss: 0.5335\n",
      "Baseline Loss: 3.4657 | Actual Loss: 0.9863\n",
      "Baseline Loss: 3.5258 | Actual Loss: 0.6751\n",
      "Baseline Loss: 3.4662 | Actual Loss: 1.2009\n",
      "Baseline Loss: 3.7627 | Actual Loss: 0.6016\n",
      "Baseline Loss: 3.8371 | Actual Loss: 1.5720\n",
      "Baseline Loss: 3.4434 | Actual Loss: 0.5758\n",
      "Baseline Loss: 3.4544 | Actual Loss: 0.9094\n",
      "Baseline Loss: 3.4139 | Actual Loss: 1.2344\n",
      "Baseline Loss: 3.5917 | Actual Loss: 1.0526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 111/1000 [01:07<05:45,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.4776 | Actual Loss: 1.5252\n",
      "Baseline Loss: 3.2862 | Actual Loss: 3.3129\n",
      "Baseline Loss: 3.4922 | Actual Loss: 1.7033\n",
      "Baseline Loss: 3.5050 | Actual Loss: 0.6946\n",
      "Baseline Loss: 3.7725 | Actual Loss: 1.1227\n",
      "Baseline Loss: 3.3052 | Actual Loss: 3.8268\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.3384\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.4799\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.3344\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.3025\n",
      "Epoch 111/1000: Train Loss: 1.3455, Val Loss: 1.1138\n",
      "Baseline Loss: 3.7941 | Actual Loss: 3.6758\n",
      "Baseline Loss: 3.6272 | Actual Loss: 0.8344\n",
      "Baseline Loss: 3.7323 | Actual Loss: 1.0354\n",
      "Baseline Loss: 3.5625 | Actual Loss: 1.6745\n",
      "Baseline Loss: 3.3843 | Actual Loss: 1.3165\n",
      "Baseline Loss: 3.5873 | Actual Loss: 0.3875\n",
      "Baseline Loss: 3.6138 | Actual Loss: 1.1705\n",
      "Baseline Loss: 3.3779 | Actual Loss: 1.2413\n",
      "Baseline Loss: 3.5203 | Actual Loss: 1.0174\n",
      "Baseline Loss: 3.3547 | Actual Loss: 0.8013\n",
      "Baseline Loss: 3.5751 | Actual Loss: 0.8635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 112/1000 [01:07<05:53,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.6648 | Actual Loss: 0.4600\n",
      "Baseline Loss: 3.4471 | Actual Loss: 0.6477\n",
      "Baseline Loss: 3.4402 | Actual Loss: 2.3586\n",
      "Baseline Loss: 3.3818 | Actual Loss: 1.1069\n",
      "Baseline Loss: 3.1035 | Actual Loss: 0.2828\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.4779\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.6083\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.7490\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.5109\n",
      "Epoch 112/1000: Train Loss: 1.1796, Val Loss: 1.3365\n",
      "Baseline Loss: 3.6133 | Actual Loss: 1.0664\n",
      "Baseline Loss: 3.4628 | Actual Loss: 0.7706\n",
      "Baseline Loss: 3.8595 | Actual Loss: 0.5406\n",
      "Baseline Loss: 3.7996 | Actual Loss: 0.9485\n",
      "Baseline Loss: 3.5527 | Actual Loss: 0.8782\n",
      "Baseline Loss: 3.4547 | Actual Loss: 1.0334\n",
      "Baseline Loss: 3.5617 | Actual Loss: 3.4666\n",
      "Baseline Loss: 3.3743 | Actual Loss: 0.5973\n",
      "Baseline Loss: 3.5123 | Actual Loss: 0.8925\n",
      "Baseline Loss: 3.6458 | Actual Loss: 1.8113\n",
      "Baseline Loss: 3.6133 | Actual Loss: 1.0063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█▏        | 113/1000 [01:08<05:59,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.2595 | Actual Loss: 0.8088\n",
      "Baseline Loss: 3.4656 | Actual Loss: 0.4723\n",
      "Baseline Loss: 3.9886 | Actual Loss: 0.8314\n",
      "Baseline Loss: 3.3057 | Actual Loss: 0.8221\n",
      "Baseline Loss: 3.1818 | Actual Loss: 0.1477\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.5955\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.6047\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.0625\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.5881\n",
      "Epoch 113/1000: Train Loss: 1.0059, Val Loss: 1.2127\n",
      "Baseline Loss: 3.7888 | Actual Loss: 0.5604\n",
      "Baseline Loss: 3.4323 | Actual Loss: 0.4099\n",
      "Baseline Loss: 3.7888 | Actual Loss: 3.7787\n",
      "Baseline Loss: 3.5088 | Actual Loss: 0.8217\n",
      "Baseline Loss: 3.3308 | Actual Loss: 0.3511\n",
      "Baseline Loss: 3.6359 | Actual Loss: 1.2399\n",
      "Baseline Loss: 3.5050 | Actual Loss: 0.8291\n",
      "Baseline Loss: 3.5920 | Actual Loss: 0.9032\n",
      "Baseline Loss: 3.4391 | Actual Loss: 1.3109\n",
      "Baseline Loss: 3.4436 | Actual Loss: 0.7151\n",
      "Baseline Loss: 3.4771 | Actual Loss: 0.9480\n",
      "Baseline Loss: 3.7678 | Actual Loss: 1.4880\n",
      "Baseline Loss: 3.3616 | Actual Loss: 1.1693\n",
      "Baseline Loss: 3.3933 | Actual Loss: 0.6484\n",
      "Baseline Loss: 3.3958 | Actual Loss: 1.3186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█▏        | 114/1000 [01:08<05:44,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5510 | Actual Loss: 0.8307\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.3899\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.5835\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.2982\n",
      "Baseline Loss: 3.2186 | Actual Loss: 2.4788\n",
      "Epoch 114/1000: Train Loss: 1.0827, Val Loss: 1.4376\n",
      "Baseline Loss: 3.6093 | Actual Loss: 1.0834\n",
      "Baseline Loss: 3.6784 | Actual Loss: 1.0404\n",
      "Baseline Loss: 3.4816 | Actual Loss: 0.4574\n",
      "Baseline Loss: 3.7521 | Actual Loss: 0.5083\n",
      "Baseline Loss: 3.4215 | Actual Loss: 0.4892\n",
      "Baseline Loss: 3.3303 | Actual Loss: 0.8647\n",
      "Baseline Loss: 3.6885 | Actual Loss: 0.4452\n",
      "Baseline Loss: 3.5039 | Actual Loss: 0.3542\n",
      "Baseline Loss: 3.6056 | Actual Loss: 1.1914\n",
      "Baseline Loss: 3.4281 | Actual Loss: 0.7282\n",
      "Baseline Loss: 3.6504 | Actual Loss: 3.6738\n",
      "Baseline Loss: 3.5739 | Actual Loss: 1.3702\n",
      "Baseline Loss: 3.4242 | Actual Loss: 2.3419\n",
      "Baseline Loss: 3.5619 | Actual Loss: 0.6588\n",
      "Baseline Loss: 3.4401 | Actual Loss: 1.8110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 115/1000 [01:08<05:53,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3931 | Actual Loss: 0.9806\n",
      "Baseline Loss: 3.6276 | Actual Loss: 2.4458\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.5846\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.1185\n",
      "Baseline Loss: 3.2186 | Actual Loss: 2.3841\n",
      "Epoch 115/1000: Train Loss: 1.1249, Val Loss: 1.6332\n",
      "Baseline Loss: 3.4390 | Actual Loss: 0.9896\n",
      "Baseline Loss: 3.6541 | Actual Loss: 0.5462\n",
      "Baseline Loss: 3.5417 | Actual Loss: 1.0034\n",
      "Baseline Loss: 3.6877 | Actual Loss: 0.9714\n",
      "Baseline Loss: 3.6318 | Actual Loss: 0.8827\n",
      "Baseline Loss: 3.5165 | Actual Loss: 0.6966\n",
      "Baseline Loss: 3.4243 | Actual Loss: 0.8690\n",
      "Baseline Loss: 3.4391 | Actual Loss: 0.5451\n",
      "Baseline Loss: 3.6918 | Actual Loss: 0.4146\n",
      "Baseline Loss: 3.4974 | Actual Loss: 0.5023\n",
      "Baseline Loss: 3.5180 | Actual Loss: 1.9191\n",
      "Baseline Loss: 3.6829 | Actual Loss: 0.6480\n",
      "Baseline Loss: 3.6540 | Actual Loss: 0.9466\n",
      "Baseline Loss: 3.4501 | Actual Loss: 4.2111\n",
      "Baseline Loss: 3.4104 | Actual Loss: 1.0654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 116/1000 [01:09<05:59,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.0775 | Actual Loss: 0.3580\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.5750\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.5690\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.1228\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.4079\n",
      "Epoch 116/1000: Train Loss: 1.0356, Val Loss: 1.1687\n",
      "Baseline Loss: 3.6826 | Actual Loss: 1.3543\n",
      "Baseline Loss: 3.4467 | Actual Loss: 0.4236\n",
      "Baseline Loss: 3.2721 | Actual Loss: 1.8130\n",
      "Baseline Loss: 3.3344 | Actual Loss: 3.4430\n",
      "Baseline Loss: 3.6363 | Actual Loss: 1.2582\n",
      "Baseline Loss: 3.6051 | Actual Loss: 1.0625\n",
      "Baseline Loss: 3.6828 | Actual Loss: 1.3819\n",
      "Baseline Loss: 3.7065 | Actual Loss: 0.7025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 117/1000 [01:09<05:43,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.3399 | Actual Loss: 0.8366\n",
      "Baseline Loss: 3.5499 | Actual Loss: 1.1698\n",
      "Baseline Loss: 3.5669 | Actual Loss: 0.5026\n",
      "Baseline Loss: 3.5292 | Actual Loss: 0.7322\n",
      "Baseline Loss: 3.4435 | Actual Loss: 0.6992\n",
      "Baseline Loss: 3.5373 | Actual Loss: 0.3629\n",
      "Baseline Loss: 3.5619 | Actual Loss: 0.9668\n",
      "Baseline Loss: 3.1196 | Actual Loss: 0.7264\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.2993\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.4825\n",
      "Baseline Loss: 3.6360 | Actual Loss: 1.8364\n",
      "Baseline Loss: 3.2186 | Actual Loss: 2.2900\n",
      "Epoch 117/1000: Train Loss: 1.0897, Val Loss: 1.4770\n",
      "Baseline Loss: 3.5874 | Actual Loss: 0.7994\n",
      "Baseline Loss: 3.5695 | Actual Loss: 0.5472\n",
      "Baseline Loss: 3.6451 | Actual Loss: 1.9021\n",
      "Baseline Loss: 3.6409 | Actual Loss: 1.1935\n",
      "Baseline Loss: 3.5701 | Actual Loss: 0.9035\n",
      "Baseline Loss: 3.4396 | Actual Loss: 0.8721\n",
      "Baseline Loss: 3.4556 | Actual Loss: 0.7844\n",
      "Baseline Loss: 3.4855 | Actual Loss: 2.3909\n",
      "Baseline Loss: 3.4902 | Actual Loss: 1.0565\n",
      "Baseline Loss: 3.6186 | Actual Loss: 1.7346\n",
      "Baseline Loss: 3.4931 | Actual Loss: 2.0639\n",
      "Baseline Loss: 3.5671 | Actual Loss: 1.0907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 117/1000 [01:10<08:48,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Loss: 3.5663 | Actual Loss: 0.5442\n",
      "Baseline Loss: 3.4734 | Actual Loss: 1.1183\n",
      "Baseline Loss: 3.3773 | Actual Loss: 0.5372\n",
      "Baseline Loss: 3.3754 | Actual Loss: 1.7030\n",
      "Baseline Loss: 3.6276 | Actual Loss: 1.8513\n",
      "Baseline Loss: 3.3852 | Actual Loss: 0.6460\n",
      "Baseline Loss: 3.6360 | Actual Loss: 0.9102\n",
      "Baseline Loss: 3.2186 | Actual Loss: 1.4460\n",
      "Epoch 118/1000: Train Loss: 1.2026, Val Loss: 1.2134\n",
      "\n",
      "Early stopping at epoch 118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0892880260944366"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devices = [\"cuda\" if torch.cuda.is_available() else \"cpu\"]\n",
    "model9 = GNNModelWithNewLoss(\n",
    "        num_node_features=data_list[0].x.shape[1],\n",
    "        num_edge_features=data_list[0].edge_attr.shape[1],\n",
    "        num_global_features=data_list[0].global_features.shape[1],\n",
    "        cov_num= 9,\n",
    "        hidden_dim=512,\n",
    "        dropout_rate=0.1,\n",
    "        property_index= 2,\n",
    "        save_path= 'premodels_new/9/9' \n",
    "    ).to(devices[0])\n",
    "\n",
    "model9.train_model(\n",
    "    data_list,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
